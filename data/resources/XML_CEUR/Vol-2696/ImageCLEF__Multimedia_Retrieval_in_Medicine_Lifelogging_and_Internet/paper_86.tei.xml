<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,143.36,115.76,328.61,12.93;1,291.30,133.69,32.60,12.93">SZTAKI @ ImageCLEFmed 2020 Tuberculosis Task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,172.94,172.11,62.86,9.96"><forename type="first">Bence</forename><surname>Lestyan</surname></persName>
							<email>lestyan@ilab.sztaki.hu</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Computer Science and Control (SZTAKI)</orgName>
								<address>
									<addrLine>H-1111, Kende str. 13-17</addrLine>
									<settlement>Budapest</settlement>
									<country key="HU">Hungary</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,246.37,172.11,83.55,9.96"><forename type="first">András</forename><forename type="middle">A</forename><surname>Benczúr</surname></persName>
							<email>benczur@ilab.sztaki.hu</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Computer Science and Control (SZTAKI)</orgName>
								<address>
									<addrLine>H-1111, Kende str. 13-17</addrLine>
									<settlement>Budapest</settlement>
									<country key="HU">Hungary</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Széchenyi University H</orgName>
								<address>
									<addrLine>9026, Egyetem tér 1</addrLine>
									<settlement>Győr</settlement>
									<country key="HU">Hungary</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,366.19,172.11,65.60,9.96"><forename type="first">Bálint</forename><surname>Daróczy</surname></persName>
							<email>daroczyb@ilab.sztaki.hu</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Computer Science and Control (SZTAKI)</orgName>
								<address>
									<addrLine>H-1111, Kende str. 13-17</addrLine>
									<settlement>Budapest</settlement>
									<country key="HU">Hungary</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Széchenyi University H</orgName>
								<address>
									<addrLine>9026, Egyetem tér 1</addrLine>
									<settlement>Győr</settlement>
									<country key="HU">Hungary</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,143.36,115.76,328.61,12.93;1,291.30,133.69,32.60,12.93">SZTAKI @ ImageCLEFmed 2020 Tuberculosis Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">260C7BA5733AE0930EF3CF5FAE923107</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Computed tomography</term>
					<term>Residual networks</term>
					<term>Convolutional networks</term>
					<term>Tuberculosis</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe our submission to the ImageCLEFmed 2020 Tuberculosis task and discuss additional results on the training set with various neural networks. After some centralization and normalization we independently categorized the 2D slices with convolutional neural networks (traditional and residual feed-forward networks) and we aggregated the individual predictions based on the positions of the lung and the slices. Our additional experiments with various aggregation methods indicate that individual slices do not necessary contain enough information about such complex structures.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The goal of the ImageCLEFmed 2020 Tubercolosis task 3 <ref type="bibr" coords="1,399.87,491.55,10.51,9.96" target="#b7">[8,</ref><ref type="bibr" coords="1,415.54,491.55,7.74,9.96" target="#b5">6]</ref> is to detect whether the different parts of the lung are affected by Mycobacterium tuberculosis. The categories are LeftLungAffected, RightLungAffected, CavernsLeft, CavernsRight, PleurisyLeft, PleurisyRight. The data set contain 403 computed tomography scans (CT scans). Out of the 403 CT scans 283 scans are used as a training set with known labels for the participants and 120 CT scans as the test for the competition. For our experiments we split the training set into two subsets (163 as training and 120 as validation set) and evaluated our models on the smaller set. Out of the two lung masks <ref type="bibr" coords="1,320.66,587.19,10.51,9.96" target="#b1">[2,</ref><ref type="bibr" coords="1,334.09,587.19,12.72,9.96" target="#b9">10]</ref> we used the first segmentation method in the aggregation phase of the slice predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Models</head><p>First, we preprocessed individual CT slices. Based on the provided lung masks we centralized and rescaled the slices to lower the resolution from 512x512 to 256x256. Additionally we standard normalized the intensity values, see Fig. <ref type="figure" coords="2,456.74,168.71,3.87,9.96" target="#fig_1">1</ref>. We omitted to apply additional augmentation techniques <ref type="bibr" coords="2,364.34,180.66,15.49,9.96" target="#b10">[11]</ref> e.g. rotation, mirroring or random crop as the position of the lung is crucial. We treated the scoring procedure as a set of binary classification tasks therefore we trained separate neural networks for each category.</p><p>We chose feed-forward neural networks with a single output node to model the categories per slice. Every inner layer included Rectangular Linear Units (ReLU) as non-linear activation functions and we chose sigmoid for the output unit. We built a traditional Convolutional Neural Network (CNN <ref type="bibr" coords="2,424.32,264.86,10.78,9.96" target="#b8">[9]</ref>) with two convolutional layers with 64 5x5 sized filters and a Residual Network (ResNet <ref type="bibr" coords="2,134.77,288.77,10.78,9.96" target="#b4">[5]</ref>) with three residual blocks, for details see Table <ref type="table" coords="2,364.66,288.77,4.98,9.96">1</ref> and Table <ref type="table" coords="2,420.89,288.77,4.98,9.96" target="#tab_1">2</ref> respectively. The residual blocks contained a set of 3x3 sized convolution with 8,32,64 filters per block followed by a second convolution with the same size and a final residual connection and a downsizing unit. Between the two convolutions we used batch normalization and ReLU similarly to the original paper. Before the linear discriminative layer we downsized the tensor with average pooling. Additionally, for the CNN network we applied Dropout <ref type="bibr" coords="2,342.39,360.50,15.49,9.96" target="#b10">[11]</ref> in the second convolutional layer. We evaluated the performance of the models with the log-likelihood of the probability of the original label measured by the activation of the output unit. As an optimization method we used Adam <ref type="bibr" coords="2,349.08,396.37,10.51,9.96" target="#b6">[7]</ref> thus we omitted additional regularization in the loss function.</p><p>We measured the performance of various models on the validation set, a random subset of the training set. In the testing phase we used every training scan with the best settings. We implemented the models in PyTorch framework <ref type="foot" coords="2,134.49,455.80,3.97,4.85" target="#foot_0">4</ref> and did all the experiments in python. Additionally, we used the provided lung masks based on the first automatic segmentation method described in <ref type="bibr" coords="2,443.44,468.61,9.95,9.96" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Aggregation</head><p>We combined the individual predictions of the slices to compute a single score per CT scan. During our experiments we applied various methods to define a single score:</p><p>-Mean score (sc -Mask score (sc 7 ): weighted prediction scores based on the proportion of the actual lung in the slices. The proportion of the lung was the proportion of the lung segment given the mask files. The masks were extracted by a fully automatic lung segmentation method described in <ref type="bibr" coords="3,406.04,154.19,9.95,9.96" target="#b1">[2]</ref>. We used the corresponding masks per lung per task. Table <ref type="table" coords="3,163.39,435.87,3.87,9.96">1</ref>: Convolutional network layout. We denote 2D convolution, maximal pooling <ref type="bibr" coords="3,170.19,447.82,10.51,9.96" target="#b8">[9]</ref> and Dropout <ref type="bibr" coords="3,243.41,447.82,15.49,9.96" target="#b10">[11]</ref> with C, M and DO respectively. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>All of our submitted runs included mean score over the CNN results. Our main submission (#68061) achieved mean AUC of 0.595. The remaining runs contained single category scores with random scores for the rest of the categories (we estimated the AUC as AU C mean * 6 -0.5 * 5)). The estimated per category AUC of our submission can be seen in Table <ref type="table" coords="3,343.81,619.58,3.87,9.96" target="#tab_2">3</ref>. We noticed that two of the categories achieved an AUC under 0.5 thus if we negate the scores the AUC values will flip to the upper half and the adjusted mean AUC will be 0.6548. Important to mention, that these adjustments only provide us information about  <ref type="table" coords="4,281.67,300.37,4.98,9.96" target="#tab_3">4</ref> show the mean AUC results on the validation set and the detailed AUC scores can be seen for the left and right lung in Table <ref type="table" coords="4,162.43,324.29,4.98,9.96" target="#tab_4">5</ref> and in Table <ref type="table" coords="4,231.66,324.29,4.98,9.96" target="#tab_5">6</ref> respectively. The method (mean score of CNN) in our main submission achieved a mean AUC 0.595 on the validation set however the best method (median score of CNN) performed significantly better with AUC of 0.642. If we select the best model (ResNet or CNN) with the median score per category the mean AUC will be similar to the median CNN with 0.659. In comparison, if we select properly both the model and the aggregation method for each category the mean AUC increases to 0.686, a significant gain on the validation set in comparison to the submitted run. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions and Future Work</head><p>In this paper we described our submission and some additional experiments over the data set of the ImageCLEFmed 2020 Tuberculosis task. We trained traditional feed-forward convolutional and residual neural networks over the in- dividual slices of the CT scans and combined the predictions based on the importance of the slices according to their position and how well they represent both of the lungs. We found that median score performed best on average although in some categories the middle slice score or the mask score outperformed other aggregation methods. Both ResNet and traditional CNN performed similarly in our experiments on the validation set while the residual network needed significantly higher computational power. Our simplest run which was submitted to the challenge had very low mean AUC score 0.595 meanwhile with additional aggregations we improved the same method on the validation set to achieve a mean AUC 0.684. We plan to replace 2D convolutions with 3D convolutions to take advantage of the complex structure of CT scans. Additionally, we intend to further expand our experiments with bi-directional Recurrent Neural Networks (RNN <ref type="bibr" coords="5,164.21,493.01,10.78,9.96" target="#b3">[4]</ref>) to read through the CT scans from both ends and classify the sequence as a whole, utilize Markov Random Fields <ref type="bibr" coords="5,355.66,504.96,10.50,9.96" target="#b0">[1]</ref> over the prior predictions and generate additional samples with slice transition refinement with inter-slice reconstruction and with category-wise Generative Adversarial Networks <ref type="bibr" coords="5,457.07,528.87,10.51,9.96" target="#b2">[3]</ref> to boost the training procedure. Based on the submissions of other participants (SenticLab.UAIC mean AUC 0.924 or SDVA-UCSD mean AUC 0.875) we believe individual slice predictions may not be representative enough to describe CT scans as a whole to detect Mycobacterium tuberculosis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Acknowledgement</head><p>The publication was supported by the Hungarian Government project GINOP-2.2. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,216.94,576.19,3.97,4.85;2,221.41,571.94,255.65,9.96;2,140.99,584.40,90.06,9.96;2,231.06,588.66,3.97,4.85;2,235.53,584.40,181.98,9.96;2,140.99,596.87,88.11,9.96;2,229.11,601.12,3.97,4.85;2,233.59,596.87,180.04,9.96;2,140.99,609.33,84.24,9.96;2,225.24,613.59,3.97,4.85;2,229.72,609.33,176.16,9.96;2,140.99,621.81,82.03,9.96;2,223.03,626.06,3.97,4.85;2,227.50,621.81,161.24,9.96;2,140.99,634.27,86.68,9.96;2,227.68,638.52,3.97,4.85;2,232.16,634.27,175.35,9.96"><head></head><label></label><figDesc>1 ): mean of the individual prediction scores of the CT scan. -Maximal score (sc 2 ): maximal prediction score in a CT scan. -Minimal score (sc 3 ): minimal prediction score in a CT scan. -Median score (sc 4 ): median prediction score in a CT scan. -Middle score (sc 5 ): prediction score of the center slice. -Majority vote (sc 6 ): proportion of the positive predictions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,134.77,356.96,346.00,9.96;3,134.77,368.92,67.33,9.96;3,169.34,207.67,276.60,138.44"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Examples of modified CT slices. Note, standard normalization is a linear transformation.</figDesc><graphic coords="3,169.34,207.67,276.60,138.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,134.77,126.69,347.48,183.64"><head>Table 2 :</head><label>2</label><figDesc>Residual network layout.the distinguishing capability of the models (how the model differentiate negative and positive examples), in a realistic scenario the final decisions would be still wrong as without any test data we would not know that we need to flip the scores. During the challenge and afterwards we experimented over the small training (163 CT scans) and validation (120 CT scans) sets with several models and aggregation methods. Table</figDesc><table coords="4,170.29,139.15,274.77,74.67"><row><cell>Layer</cell><cell>#nodes</cell><cell>#parameters</cell><cell>output</cell></row><row><cell>Input layer</cell><cell>16</cell><cell>0.2k</cell><cell>16x256x256</cell></row><row><cell>Residual layer 1</cell><cell></cell><cell>3k</cell><cell>8x256x256</cell></row><row><cell>Residual layer 2</cell><cell></cell><cell>14k</cell><cell>32x128x128</cell></row><row><cell>Residual layer 3</cell><cell></cell><cell>73k</cell><cell>64x64x64</cell></row><row><cell>Average pooling 8x8</cell><cell></cell><cell>0</cell><cell>64x8x8</cell></row><row><cell>Output layer</cell><cell>1</cell><cell>4k</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,202.68,451.08,209.98,109.04"><head>Table 3 :</head><label>3</label><figDesc>Estimated individual AUC values.</figDesc><table coords="4,202.68,463.53,209.98,96.58"><row><cell>category</cell><cell>run</cell><cell>AUC</cell></row><row><cell>Estimated LeftLungAffected</cell><cell>#68052</cell><cell>0.734</cell></row><row><cell>Estimated CavernsLeft</cell><cell>#68055</cell><cell>0.452</cell></row><row><cell>Estimated PleurisyLeft</cell><cell>#68050</cell><cell>0.728</cell></row><row><cell>Estimated RightLungAffected</cell><cell>#68059</cell><cell>0.74</cell></row><row><cell>Estimated CavernsRight</cell><cell>#68049</cell><cell>0.41</cell></row><row><cell>Estimated PleurisyRight</cell><cell>#68058</cell><cell>0.674</cell></row><row><cell>mean</cell><cell>#68061</cell><cell>0.595</cell></row><row><cell>mean adjusted</cell><cell></cell><cell>0.6548</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,199.03,126.69,217.28,196.71"><head>Table 4 :</head><label>4</label><figDesc>Mean AUC results on the validation set.</figDesc><table coords="5,199.03,139.15,217.28,184.25"><row><cell>model</cell><cell>aggregation</cell><cell>mean AUC</cell></row><row><cell>CNN (submitted)</cell><cell>sc1</cell><cell>0.595</cell></row><row><cell>CNN</cell><cell>sc2</cell><cell>0.594</cell></row><row><cell>CNN</cell><cell>sc3</cell><cell>0.614</cell></row><row><cell>CNN</cell><cell>sc4</cell><cell>0.642</cell></row><row><cell>CNN</cell><cell>sc5</cell><cell>0.626</cell></row><row><cell>CNN</cell><cell>sc6</cell><cell>0.558</cell></row><row><cell>CNN</cell><cell>sc7</cell><cell>0.591</cell></row><row><cell>ResNet</cell><cell>sc1</cell><cell>0.620</cell></row><row><cell>ResNet</cell><cell>sc2</cell><cell>0.614</cell></row><row><cell>ResNet</cell><cell>sc3</cell><cell>0.6</cell></row><row><cell>ResNet</cell><cell>sc4</cell><cell>0.584</cell></row><row><cell>ResNet</cell><cell>sc5</cell><cell>0.616</cell></row><row><cell>ResNet</cell><cell>sc6</cell><cell>0.577</cell></row><row><cell>ResNet</cell><cell>sc7</cell><cell>0.614</cell></row><row><cell>Best model</cell><cell>sc4</cell><cell>0.659</cell></row><row><cell>Best model &amp; aggr.</cell><cell></cell><cell>0.686</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,134.76,643.50,347.45,21.91"><head>Table 5 :</head><label>5</label><figDesc>Per category AUC results on the validation set for the left lung. The best results are highlighted in red. by the Higher Education Institutional Excellence Program, and by the Momentum Grant of the Hungarian Academy of Sciences. B.D. was supported by an MTA Premium Postdoctoral Grant 2018.</figDesc><table coords="5,134.76,643.50,347.45,21.91"><row><cell>1-18-2018-00004: AI based lung cancer diagnosis by chest CT, 2018-1.2.1-</cell></row><row><cell>NKP-00008: Exploring the Mathematical Foundations of Artificial Intelligence,</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,134.41,300.72,346.18,186.73"><head>Table 6 :</head><label>6</label><figDesc>Per category AUC results on the validation set for the right lung. The best results are highlighted in red.</figDesc><table coords="7,152.92,325.12,309.50,162.33"><row><cell>model</cell><cell>RightLungAffected</cell><cell>CavernsRight</cell><cell>PleurisyRight</cell></row><row><cell>CNN sc1</cell><cell>0.712</cell><cell>0.543</cell><cell>0.543</cell></row><row><cell>CNN sc2</cell><cell>0.7</cell><cell>0.625</cell><cell>0.581</cell></row><row><cell>CNN sc3</cell><cell>0.693</cell><cell>0.55</cell><cell>0.531</cell></row><row><cell>CNN sc4</cell><cell>0.712</cell><cell>0.525</cell><cell>0.675</cell></row><row><cell>CNN sc5</cell><cell>0.712</cell><cell>0.593</cell><cell>0.631</cell></row><row><cell>CNN sc6</cell><cell>0.5</cell><cell>0.575</cell><cell>0.546</cell></row><row><cell>CNN sc7</cell><cell>0.543</cell><cell>0.581</cell><cell>0.568</cell></row><row><cell>ResNet sc1</cell><cell>0.562</cell><cell>0.6</cell><cell>0.575</cell></row><row><cell>ResNet sc2</cell><cell>0.537</cell><cell>0.612</cell><cell>0.668</cell></row><row><cell>ResNet sc3</cell><cell>0.587</cell><cell>0.543</cell><cell>0.543</cell></row><row><cell>ResNet sc4</cell><cell>0.55</cell><cell>0.587</cell><cell>0.618</cell></row><row><cell>ResNet sc5</cell><cell>0.575</cell><cell>0.593</cell><cell>0.618</cell></row><row><cell>ResNet sc6</cell><cell>0.562</cell><cell>0.578</cell><cell>0.531</cell></row><row><cell>ResNet sc7</cell><cell>0.5</cell><cell>0.581</cell><cell>0.612</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="2,144.73,656.70,89.44,8.27"><p>https://pytorch.org</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.95,141.99,339.17,8.96;8,151.52,152.94,329.41,8.96;8,151.52,163.91,195.74,8.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,307.13,141.99,174.99,8.96;8,151.52,152.94,156.15,8.96">Machine learning based session drop prediction in lte networks and its son aspects</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Daróczy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Vaderna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Benczúr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,328.66,152.94,152.27,8.96;8,151.52,163.91,102.50,8.96">2015 IEEE 81st Vehicular Technology Conference (VTC Spring)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.95,174.87,337.62,8.96;8,151.52,185.82,329.06,8.96;8,151.19,196.78,330.94,8.96;8,151.52,207.75,329.07,8.96;8,151.05,218.70,190.72,8.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,430.12,174.87,50.46,8.96;8,151.52,185.82,216.48,8.96">Efficient and fully automatic segmentation of the lungs in ct volumes</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><forename type="middle">A</forename><surname>Jiménez Del Toro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Depeursinge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,385.23,196.78,96.90,8.96;8,151.52,207.75,247.05,8.96">Proceedings of the VIS-CERAL Anatomy Grand Challenge at the 2015 IEEE ISBI</title>
		<title level="s" coord="8,453.97,207.75,26.62,8.96;8,151.05,218.70,89.74,8.96">CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">O</forename><surname>Goksel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">O</forename><forename type="middle">A</forename><surname>Jiménez Del Toro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Foncubierta-Rodríguez</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<meeting>the VIS-CERAL Anatomy Grand Challenge at the 2015 IEEE ISBI</meeting>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2015-05">May 2015</date>
			<biblScope unit="page" from="31" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.95,229.66,337.64,8.96;8,151.52,240.61,196.73,8.96" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6572</idno>
		<title level="m" coord="8,323.95,229.66,156.64,8.96;8,151.52,240.61,34.85,8.96">Explaining and harnessing adversarial examples</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,142.95,251.58,338.91,8.96;8,151.18,262.54,329.40,8.96;8,151.25,273.49,102.76,8.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,458.66,251.58,23.21,8.96;8,151.18,262.54,88.54,8.96">Lstm: A search space odyssey</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Greff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">K</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Koutník</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">R</forename><surname>Steunebrink</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,245.98,262.54,234.60,8.96">IEEE transactions on neural networks and learning systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2222" to="2232" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.95,284.45,338.91,8.96;8,151.52,295.41,330.84,8.96;8,151.52,306.37,76.78,8.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,291.68,284.45,172.99,8.96">Deep residual learning for image recognition</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,151.52,295.41,326.65,8.96">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.95,317.33,339.16,8.96;8,151.52,328.29,330.34,8.96;8,151.52,339.24,330.35,8.96;8,151.52,350.21,330.34,8.96;8,151.52,361.17,330.34,8.96;8,151.52,372.12,330.59,8.96;8,151.52,383.08,330.60,8.96;8,151.52,394.04,329.05,8.96;8,151.52,405.00,330.85,8.96;8,151.06,415.96,329.53,8.96;8,150.44,426.92,95.76,8.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,300.42,372.12,181.69,8.96;8,151.52,383.08,293.70,8.96">Overview of the ImageCLEF 2020: Multimedia Retrieval in Medical, Lifelogging, Nature, and Internet Applications</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Péteri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">D</forename><surname>Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">T</forename><surname>Ninh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Fichou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Berari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Brie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dogariu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">D</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,467.93,383.08,14.20,8.96;8,151.52,394.04,329.05,8.96;8,151.52,405.00,308.98,8.96">Proceedings of the 11th International Conference of the CLEF Association (CLEF 2020)</title>
		<title level="s" coord="8,180.01,415.96,170.34,8.96">LNCS Lecture Notes in Computer Science</title>
		<meeting>the 11th International Conference of the CLEF Association (CLEF 2020)<address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">September 22-25 2020</date>
			<biblScope unit="volume">12260</biblScope>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="8,142.95,437.87,337.88,8.96;8,151.52,448.84,93.19,8.96" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="8,234.67,437.87,180.38,8.96">Adam: A method for stochastic optimization</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,142.95,459.80,338.91,8.96;8,151.52,470.75,330.85,8.96;8,151.52,481.71,246.97,8.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,151.52,470.75,326.80,8.96">Overview of ImageCLEFtuberculosis 2020 -automatic CT-based report generation</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Tarasau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,165.60,481.71,232.90,8.96">CLEF2020 Working Notes. CEUR Workshop Proceedings</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.95,492.68,337.63,8.96;8,151.52,503.63,298.18,8.96" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,341.36,492.68,139.22,8.96;8,151.52,503.63,85.69,8.96">Gradient-based learning applied to document recognition</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bottou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Haffner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,244.21,503.63,99.66,8.96">Proceedings of the IEEE</title>
		<meeting>the IEEE</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="page" from="2278" to="2324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,514.59,339.51,8.96;8,151.52,525.55,329.07,8.96;8,151.52,536.51,264.04,8.96" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,263.10,514.59,219.03,8.96;8,151.52,525.55,128.54,8.96">Imageclef 2017: Supervoxels and co-occurrence for tuberculosis ct image classification</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,300.13,525.55,180.46,8.96;8,151.52,536.51,77.13,8.96">CLEF2017 Working Notes. CEUR Workshop Proceedings, CEUR</title>
		<meeting><address><addrLine>WS, Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">September 11-14 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,547.47,339.25,8.96;8,151.52,558.43,329.06,8.96;8,151.52,569.38,205.28,8.96" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,151.52,558.43,265.30,8.96">Dropout: a simple way to prevent neural networks from overfitting</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,423.27,558.43,57.32,8.96;8,151.52,569.38,104.05,8.96">The journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1929" to="1958" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
