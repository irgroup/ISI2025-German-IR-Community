<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,177.30,115.96,260.76,12.62;1,138.26,133.89,338.83,12.62;1,219.80,151.82,175.75,12.62">ImageCLEF 2020: Deep Learning for Tuberculosis in Chest CT Image Analysis based on multi-axis projections</title>
				<funder ref="#_bj9pBpc">
					<orgName type="full">Grant for Education and Research in Toyohashi University of Technology</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,225.64,189.50,75.11,8.74"><forename type="first">Tetsuya</forename><surname>Asakawa</surname></persName>
							<email>asakawa@kde.cs.tut.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Toyohashi University of Technology</orgName>
								<address>
									<settlement>Aichi</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,327.91,189.50,57.34,8.74"><forename type="first">Masaki</forename><surname>Aono</surname></persName>
							<email>aono@tut.jp</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Toyohashi University of Technology</orgName>
								<address>
									<settlement>Aichi</settlement>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,177.30,115.96,260.76,12.62;1,138.26,133.89,338.83,12.62;1,219.80,151.82,175.75,12.62">ImageCLEF 2020: Deep Learning for Tuberculosis in Chest CT Image Analysis based on multi-axis projections</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">366D930392359BDB11E78603B85E379E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Computed Tomography</term>
					<term>Tuberculosis</term>
					<term>Deep Learning</term>
					<term>Multilabel classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ImageCLEF 2020 Tuberculosis Task is an example of the challenging research problem in the field of CT image analysis. The purpose of this research is to make accurate estimates for the three labels (affected, pleurisy, caverns) for each of the lungs. We describe the tuberculosis task and approach for chest CT image analysis, then perform multi-label CT image analysis using the task dataset. We propose finetuning deep neural network model that uses inputs from multiple CNN features. In addition, this paper presents two approaches for applying mask data to the extracted 2D image data and for extracting a set of 2D projection images along multi-axis based on the 3D chest CT data. Our submissions on the task test dataset reached a mean AUC value of about 75% and a minimum AUC value of about 69%</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the spread of various virus (such as Tuberculosis, Coronavirus, and Influenza), medical researchers perform to give the necessary treatment for viruses in recent years. However, there is nothing to identify the disease early. Early diagnosis needed to give the necessary treatment, develop specific medicine, and prevent the death of patients. Therefore, several researchers have invested their efforts in recent years, especially within the medical image analysis community. In fact, a task dedicated to the tuberculosis had been adopted as part of the ImageCLEF evaluation campaign in its editions of the four last years <ref type="bibr" coords="1,435.75,579.15,10.35,8.74" target="#b0">[1]</ref>[2][3] <ref type="bibr" coords="1,466.79,579.15,10.35,8.74" target="#b3">[4]</ref>. In ImageCLEF 2020 the main task <ref type="bibr" coords="1,292.15,591.11,9.96,8.74" target="#b4">[5]</ref>, "ImageCLEFmed Tuberculosis" is considered to be CT Report (CTR). In the task, the problem consists of generating an automatic report that includes the following information in binary form (0 or 1): Left Lung Affected, Right Lung Affected, Caverns Left, Caverns Right, Pleurisy Left, Pleurisy Right. The purpose of this research is to automatically analyze the 3D CT images of TB patients to detect semantic information for the type of Tuberculosis.</p><p>In this paper, we also employ a new fine-tuning neural network model which uses features coming from pre-trained CNN models as input. In addition, existing deep learning MODELS had weak classifications, therefore we propose a new fully connected 2 layers. The new contributions of this paper is to propose a novel feature building techniques, which incorporates features from two CNN models to predict Tuberculosis from images, unlike most recent research only concerned with adopting single CNN features. In the following, we first describe the tasks which were conducted in Section 2 followed by dataset of ImageCLEF2020, In Section 3, we introduce masking the dataset, experimental settings, and feature used in this research . In Section 4, we describe experiments we have carried out. In Section 5 we conclude this paper .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dataset of ImageCLEF 2020</head><p>The tuberculosis task of ImageCLEF 2020 Challenge included part of chest in format of 3D CT images <ref type="bibr" coords="2,247.61,373.41,10.20,8.74" target="#b5">[6]</ref> <ref type="bibr" coords="2,257.81,373.41,10.20,8.74" target="#b4">[5]</ref>. A dataset contains the chest CT scan imaging data which included 283 images in the Training (also referred as Development) dataset and 120 in the Test dataset. Since the labels are provided on lung-wise scale rather than CT-wise scale, the total number of cases is virtually increased twice.</p><p>This task participants have to generate automatic lung-wise reports based on CT image data. Each report should include the probability scores (ranging from 0 to 1) for each of the three labels and for each of the lungs (resulting in 6 entries per CT). The resulting list of entries includes: LeftLungAffected, RightLungAffected, CavernsLeft, CavernsRight, PleurisyLeft, PleurisyRight. Table <ref type="table" coords="2,239.87,494.72,4.98,8.74" target="#tab_0">1</ref> shows labels for the chest CT scan in the Training dataset. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Method</head><p>We propose a multi-label analysis system to predict Tuberculosis from CT scan images. The first step is the input data pre-processing. After pre-processing input data, we will describe our deep neural network model that enables the multilabel outputs, given CT scan images. In addition, we add an optional step to the first step. We use a CT scan movie not CT scan images. We will detail our proposed system in the following section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Input Data Pre-processing</head><p>First, we remind the reader that in train and test data, 3D CT scans are provided in compressed Nifti format. We decompressed the files and extracted the slices of x-axis, y-axis, and z-axis from the three dimensions of the 3D image shown in Fig. <ref type="figure" coords="3,155.15,288.87,3.87,8.74" target="#fig_0">1</ref>. For each dimension for each Nifti image, we obtained a number of slices ranging according to the dimension: 512 images for the X and Y dimensions, and from 110 to 250 images for the Z dimension.</p><p>After extracting slices along x-axis, y-axis, and z-axis, we propose to filter the slices of each patient using mask data <ref type="bibr" coords="3,320.07,336.73,10.20,8.74" target="#b6">[7]</ref> <ref type="bibr" coords="3,330.27,336.73,10.20,8.74" target="#b7">[8]</ref>. We extract a filtering CT scan image, as shown in Fig. <ref type="figure" coords="3,236.30,348.68,3.87,8.74" target="#fig_1">2</ref>. Indeed, we can notice that many slices contain relevant information including bone, space, fat, and skin except for the lungs that could help to classify the samples. This is why we added a step to the filter and selected a number of slices per patient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Proposed deep neural network model</head><p>To solve our multi-label problem, we propose new combined neural network models which allow inputs coming from End-to-end (CNN) features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training and Validation sets</head><p>The training dataset consists of 108 891, 77 468, 31 497 images extracted from the filtered CT image for x, y and z axis respectively.</p><p>We have divided the train data into training and validation data with 8:2 ratio in random. CNN features were extracted using pre-trained CNN-based neural networks, including VGG16, ResNet50, NasNet-Large and EfficientNet B07. In order to deal with the above feature, we propose a deep neural network architecture where we allow multiple inputs and a multi-hot vector output.</p><p>Our system incorporates CNN features, which can be extracted using deep convolutional neural networks pre-trained on the ImageNet <ref type="bibr" coords="3,398.33,584.39,10.52,8.74" target="#b8">[9]</ref> such as VGG16 <ref type="bibr" coords="3,134.77,596.34,14.61,8.74" target="#b9">[10]</ref>, ResNet50 <ref type="bibr" coords="3,193.40,596.34,18.37,8.74" target="#b10">[11]</ref>, NasNet-Large <ref type="bibr" coords="3,283.64,596.34,15.50,8.74" target="#b11">[12]</ref> and EfficientNet B07 <ref type="bibr" coords="3,390.96,596.34,17.64,8.74" target="#b12">[13]</ref>. Because of the lack of dataset in visual sentiment analysis, we adopt transfer learning for the feature extraction to prevent over fitting. We decreased the dimensions of fullyconnected layers used in CNN models. In addition, we reduced the vector to 2048 dimensions. This was introduced with the expectation of reducing the number of parameters and unifying the dimensions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Training and Validation sets and Test data</head><p>We employ from the top AUC for four fine-tuning the CNN model from above. As illustrated in Fig. <ref type="figure" coords="4,472.84,460.45,3.87,8.74" target="#fig_2">3</ref>, CNN feature is combined and represented by an integrated feature as a linearly weighted average, where weights are w 3 for CNN features, respectively. CNN feature is passed out on "Fusion" processing to generate the integrated features, followed by "softmax" activation function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Probability of multi-label</head><p>We propose a method illustrated in Algorithm 1. The input is a collection of features extracted from each image with K kinds of sentiments, while the output is a K-dimensional multi-hot vector.</p><p>In Algorithm 1, we assume that the extracted CNN feature is represented by their probabilities. For each Tuberculosis, we sum up the features, followed by median of the result, which is denoted by T k i in Algorithm 1. In short, the vector S i represents the output multi-hot vector. We repeat this computation until all the test (unknown) images are processed.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">AUC of training and validation sets</head><p>The train dataset consists in filtering CT image on x-axis, y-axis, or z-axis. The train dataset consists of 108 891, 77 468, 31 497 images extracted from the filtered CT image for x, y and z axis respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Predicting multi hot vector for an image</head><p>Input: Image data i including K kinds of disease for Lungs Output: Multi hot vector Si 1: for k do range (K): 2:</p><formula xml:id="formula_0" coords="6,138.66,164.84,145.82,18.82">P rob i,k =F eatureExtraction i,k 3:</formula><p>T k i =median(P rob i,k ) 4: end for Here, we have divided the filtering data into training and validation data with 8:2 ratio. We determined the following hyper-parameters; batch size as 256, optimization function as "SGD" with a learning rate of 0.001 and momentum 0.9, and the number of epochs 200. For the implementation, we employ Ten-sorFlow <ref type="bibr" coords="6,166.26,269.60,18.00,8.74" target="#b13">[14]</ref> as our deep learning framework. For the evaluation of multi-label classification, we employ mean Area Under Curve (AUC). Table <ref type="table" coords="6,427.69,281.55,4.98,8.74" target="#tab_1">2</ref> shows the results. Here we compare in terms of AUC for multiple axes. For fine-tuning Ef-ficientNet B07 in x, y, and z-axis, it turns out that our proposed CNN model has the best AUC. Finally, we employ EfficientNet B07 for training and validation sets and test data. The result shows as below (4.2). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">The result for training and validation sets and test data using our proposed model</head><p>The test dataset consists of 46 605, 32 901, 13 938 images extracted from the filtered CT image for x, y and z axis respectively. We expect that our proposed models could give better results after a more advanced data preprocessing including the use of filtering image, and data augmentation for multi-axis. Here, we described above, we employ fine-tuning CNN models in EfficientNet B07 based on multi axis. Table <ref type="table" coords="7,376.95,118.99,4.98,8.74" target="#tab_2">3</ref> shows the results. "xaxis and y-axis" mean the probabilities of x-axis and y-axis. "y-axis and z-axis" mean the probabilities of y-axis and z-axis. "x-axis, y-axis, and z-axis" mean the probabilities of x-axis, y-axis, and z-axis.</p><p>Here we compare in terms of AUC. For z-axis on fine-tuning EfficientNet B07, it turns out that our proposed CNN model has the good mean AUC and minimum AUC. In addition, results of the participants' submissions with the highest AUC values are shown in Table <ref type="table" coords="7,253.21,399.51,4.98,8.74" target="#tab_3">4</ref>  <ref type="bibr" coords="7,262.10,399.51,9.96,8.74" target="#b3">[4]</ref>. Here we compare in terms of mean AUC and minimum AUC. For KDE-lab team, it turns out that our proposed CNN model has the best mean AUC and minimum AUC. The results achieved by our submissions are well ranked compared to those of the top of the list, we can notice that several runs belong to the same teams that had good results, and they probably do not differ too much. Our rank is 5th. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this research, we proposed a model for predicting each of the three labels and for each of the lungs as a multi-label problem from chest CT images. We performed Chest CT Image analysis where we proposed a combined deep neural network model which enabled inputs to come from CNN features. In multilabel Chest CT Image analysis, we also introduced a threshold-based multi-label prediction algorithm. Specifically, after training our deep neural network, we could predict the existence of a disease for given unknown CT scan images.</p><p>Experimental results demonstrate that all our proposed models outperform the individual pre-trained CNN model in terms of mean AUC and minimum AUC.</p><p>In this research, we proposed a model for Tuberculosis CT Image analysis which accurately estimates multi-label problems from given images. The multilabel problems are evoking multiple different types of Tuberculosis findings simultaneously.</p><p>In the future, given an arbitrary CT or X-ray image might be included the optimal weights for the neural networks. Moreover, we hope our proposed model can encourage further research on the early detection of several viruses or unknown diseases. We also expect that our proposed model will be widely used in the field of medical computing.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,200.10,412.16,215.16,7.89;4,165.95,115.86,283.40,281.52"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Extraction by x-axis, y-axis, and z-axis slices.</figDesc><graphic coords="4,165.95,115.86,283.40,281.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,199.21,401.49,216.93,7.89;5,137.60,419.36,340.11,177.55"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Pre-processing of input data using mask data.</figDesc><graphic coords="5,137.60,419.36,340.11,177.55" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,180.11,611.68,255.15,7.89"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Our proposed feature for multi-label feature extraction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,157.42,539.74,300.52,96.81"><head>Table 1 .</head><label>1</label><figDesc>Presence of labels for the chest CT scan in the Training dataset.</figDesc><table coords="2,237.16,560.54,141.04,76.01"><row><cell>Label</cell><cell>In Training set</cell></row><row><cell>LeftLungAffected</cell><cell>211</cell></row><row><cell>RightLungAffected</cell><cell>233</cell></row><row><cell>CavernsLeft</cell><cell>66</cell></row><row><cell>CavernsRight</cell><cell>79</cell></row><row><cell>PleurisyLeft</cell><cell>7</cell></row><row><cell>PleurisyRight</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,134.77,361.33,345.83,172.82"><head>Table 2 .</head><label>2</label><figDesc>Validation accuracy of four models (VGG16, ResNet50, NasNet-Large and EfficientNet B07) on multi-axis projections</figDesc><table coords="6,224.12,393.58,167.11,140.57"><row><cell>axis</cell><cell>Model</cell><cell cols="2">Dimension AUC</cell></row><row><cell></cell><cell>VGG16</cell><cell>2048</cell><cell>0.901</cell></row><row><cell>x-axis</cell><cell>ResNet50 NasNet-Large</cell><cell>2048 2048</cell><cell>0.907 0.905</cell></row><row><cell></cell><cell>EfficientNet B07</cell><cell>2048</cell><cell>0.908</cell></row><row><cell></cell><cell>VGG16</cell><cell>2048</cell><cell>0.916</cell></row><row><cell>y-axis</cell><cell>ResNet50 NasNet-Large</cell><cell>2048 2048</cell><cell>0.917 0.915</cell></row><row><cell></cell><cell>EfficientNet B07</cell><cell>2048</cell><cell>0.918</cell></row><row><cell></cell><cell>VGG16</cell><cell>2048</cell><cell>0.976</cell></row><row><cell>z-axis</cell><cell>ResNet50 NasNet-Large</cell><cell>2048 2048</cell><cell>0.957 0.955</cell></row><row><cell></cell><cell>EfficientNet B07</cell><cell>2048</cell><cell>0.978</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,134.77,238.12,345.83,107.76"><head>Table 3 .</head><label>3</label><figDesc>The results of doing experiment for multi-label classification and AUC for training and validation sets</figDesc><table coords="7,180.96,269.88,253.45,76.01"><row><cell>Model</cell><cell>axis</cell><cell cols="2">meanAUC minAUC</cell></row><row><cell></cell><cell>x-axis</cell><cell>0.633</cell><cell>0.573</cell></row><row><cell></cell><cell>y-axis</cell><cell>0.692</cell><cell>0.635</cell></row><row><cell>EfficientNet B07</cell><cell>z-axis x-axis and y-axis</cell><cell>0.753 0.642</cell><cell>0.698 0.596</cell></row><row><cell></cell><cell>y-axis and z-axis</cell><cell>0.735</cell><cell>0.664</cell></row><row><cell></cell><cell cols="2">x-axis, y-axis, and z-axis 0.654</cell><cell>0.615</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,167.51,502.67,280.33,129.68"><head>Table 4 .</head><label>4</label><figDesc>The best participants' runs submitted for the CTR subtask</figDesc><table coords="7,217.83,523.47,179.70,108.88"><row><cell>Group Name</cell><cell cols="3">Rank meanAUC minAUC</cell></row><row><cell>SenticLab.UAIC</cell><cell>1</cell><cell>0.923</cell><cell>0.885</cell></row><row><cell>agentili</cell><cell>2</cell><cell>0.875</cell><cell>0.811</cell></row><row><cell>chejiao</cell><cell>3</cell><cell>0.791</cell><cell>0.682</cell></row><row><cell cols="2">CompElecEngCU 4</cell><cell>0.767</cell><cell>0.733</cell></row><row><cell>KDE-lab</cell><cell>5</cell><cell>0.753</cell><cell>0.698</cell></row><row><cell>Waqas-sheikh</cell><cell>6</cell><cell>0.705</cell><cell>0.644</cell></row><row><cell>uaic</cell><cell>7</cell><cell>0.659</cell><cell>0.562</cell></row><row><cell>JBTTM</cell><cell>8</cell><cell>0.601</cell><cell>0.432</cell></row><row><cell>sztaki-dsd</cell><cell>9</cell><cell>0.595</cell><cell>0.546</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgment</head><p>A part of this research was carried out with the support of the <rs type="grantName">Grant-in-Aid for Scientific Research (B</rs>) (issue number <rs type="grantNumber">17H01746</rs>), and <rs type="funder">Grant for Education and Research in Toyohashi University of Technology</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_bj9pBpc">
					<idno type="grant-number">17H01746</idno>
					<orgName type="grant-name">Grant-in-Aid for Scientific Research (B</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.96,461.43,337.63,7.86;8,151.52,472.39,329.08,7.86;8,151.52,483.35,329.08,7.86;8,151.52,494.31,329.08,7.86;8,151.52,505.27,35.40,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,222.30,472.39,258.30,7.86;8,151.52,483.35,123.59,7.86">Overview of ImageCLEFtuberculosis 2017 -predicting tuberculosis type and drug resistances</title>
		<author>
			<persName coords=""><forename type="first">Yashin</forename><surname>Dicente</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cid</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><surname>Kalinovsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vitali</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vassili</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<ptr target="CEUR-WS.org&lt;http://ceur-ws.org&gt;" />
	</analytic>
	<monogr>
		<title level="m" coord="8,296.35,483.35,184.25,7.86;8,151.52,494.31,46.41,7.86">CLEF2017 Working Notes, CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">September 11-14 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,515.28,337.64,7.86;8,151.52,526.24,329.08,7.86;8,151.52,537.20,329.07,7.86;8,151.52,548.16,329.07,7.86;8,151.52,559.11,329.08,7.86;8,151.52,570.07,329.08,7.86;8,151.52,581.03,329.07,7.86;8,151.52,591.99,329.07,7.86;8,151.52,602.95,114.76,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,254.39,559.11,226.21,7.86;8,151.52,570.07,39.80,7.86">Overview of ImageCLEF 2018: Challenges, datasets and evaluation</title>
		<author>
			<persName coords=""><forename type="first">Bogdan</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mauricio</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alba</forename><surname>García Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carsten</forename><surname>Eickhoff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vincent</forename><surname>Andrearczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yashin</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vitali</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vassili</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sadid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuan</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oladimeji</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joey</forename><surname>Farri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthew</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Duc-Tien</forename><surname>Lungren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luca</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liting</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mathias</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cathal</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Gurrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,210.36,570.07,270.23,7.86;8,151.52,581.03,329.07,7.86;8,151.52,591.99,52.78,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction, Proceedings of the Ninth International Conference of the CLEF Association (CLEF 2018)</title>
		<title level="s" coord="8,383.22,591.99,97.37,7.86;8,151.52,602.95,71.32,7.86">LNCS Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Avignon, France</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">September 10-14 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,612.96,337.64,7.86;8,151.52,623.92,329.07,7.86;8,151.52,634.88,329.07,7.86;8,151.52,645.84,329.08,7.86;8,151.52,656.80,329.08,7.86;9,151.52,119.67,329.08,7.86;9,151.52,130.63,329.07,7.86;9,151.52,141.59,329.08,7.86;9,151.52,152.55,329.07,7.86;9,151.52,163.51,329.07,7.86;9,151.52,174.47,329.07,7.86;9,151.52,185.43,329.07,7.86;9,151.52,196.39,212.37,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,246.84,141.59,233.76,7.86;9,151.52,152.55,329.07,7.86;9,151.52,163.51,63.60,7.86">ImageCLEF 2019: Multimedia Retrieval in Medicine, Lifelogging, Security and Nature: Multimedia Retrieval in Medicine, Lifelogging, Security and Nature</title>
		<author>
			<persName coords=""><forename type="first">Bogdan</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Renaud</forename><surname>Péteri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yashin</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vitali</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vassili</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dzmitri</forename><surname>Klimuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aleh</forename><surname>Tarasau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Asma</forename><surname>Ben Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sadid</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vivek</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joey</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dina</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Duc-Tien</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luca</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Minh-Triet</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mathias</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cathal</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Obioma</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christoph</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alba</forename><surname>García Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Narciso</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ergina</forename><surname>Kavallieratou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Roberto Del Blanco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Cuevas Rodríguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nikos</forename><surname>Vasillopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Konstantinos</forename><surname>Karampidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jon</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrian</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antonio</forename><surname>Campello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,239.31,163.51,241.28,7.86;9,151.52,174.47,42.80,7.86;9,268.71,174.47,211.88,7.86;9,151.52,185.43,146.00,7.86">Proceedings of the 10th International Conference of the CLEF Association (CLEF 2019)</title>
		<title level="s" coord="9,151.52,196.39,168.93,7.86">LNCS Lecture Notes in Computer Science</title>
		<meeting>the 10th International Conference of the CLEF Association (CLEF 2019)<address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-12">September 9-12 2019</date>
			<biblScope unit="volume">2380</biblScope>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="9,142.96,207.36,337.64,7.86;9,151.52,218.32,329.07,7.86;9,151.52,229.28,329.07,7.86;9,151.52,240.24,244.97,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,204.16,218.32,276.43,7.86;9,151.52,229.28,94.85,7.86">Medical image understanding: Overview of the ImageCLEFmed 2020 concept prediction task</title>
		<author>
			<persName coords=""><forename type="first">Obioma</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christoph</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alba</forename><surname>García Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="9,270.06,229.28,206.31,7.86">CLEF2020 Working Notes, Workshop Proceedings</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">September 22-25 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,251.22,337.64,7.86;9,151.52,262.17,329.08,7.86;9,151.52,273.13,329.08,7.86;9,151.52,284.09,329.07,7.86;9,151.52,295.05,329.08,7.86;9,151.52,306.01,329.08,7.86;9,151.52,316.97,329.07,7.86;9,151.52,327.93,329.09,7.86;9,151.52,338.89,329.07,7.86;9,151.52,349.85,329.07,7.86;9,151.52,360.80,329.07,7.86;9,151.52,371.76,329.07,7.86;9,151.52,382.72,71.21,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,251.15,327.93,229.45,7.86;9,151.52,338.89,238.66,7.86">Overview of the ImageCLEF 2020: Multimedia Retrieval in Medical, Lifelogging, Nature, and Internet Applications</title>
		<author>
			<persName coords=""><forename type="first">Bogdan</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Renaud</forename><surname>Péteri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Asma</forename><surname>Ben Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vivek</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sadid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dina</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Serge</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vitali</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yashin</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vassili</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Obioma</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christoph</forename><forename type="middle">M</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alba</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Van-Tu</forename><surname>García Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tu-Khiem</forename><surname>Ninh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liting</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luca</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pål</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Minh-Triet</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mathias</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cathal</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Duc-Tien</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jon</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrian</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antonio</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dimitri</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Raul</forename><surname>Fichou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Berari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mihai</forename><surname>Brie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liviu</forename><surname>Dogariu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mihai</forename><surname>Daniel S ¸tefan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Constantin</forename><surname>Gabriel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,413.48,338.89,67.11,7.86;9,151.52,349.85,216.59,7.86;9,181.53,360.80,294.87,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<title level="s" coord="9,338.85,371.76,141.74,7.86;9,151.52,382.72,27.78,7.86">LNCS Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">September 22-25 2020</date>
			<biblScope unit="volume">12260</biblScope>
		</imprint>
	</monogr>
	<note>the 11th International Conference of the CLEF Association (CLEF 2020)</note>
</biblStruct>

<biblStruct coords="9,142.96,393.70,337.64,7.86;9,151.52,404.66,329.08,7.86;9,151.52,415.62,329.08,7.86;9,151.52,426.57,329.08,7.86;9,151.52,437.53,91.48,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,273.60,404.66,206.99,7.86;9,151.52,415.62,137.84,7.86">Overview of ImageCLEFtuberculosis 2020 -automatic CT-based report generation</title>
		<author>
			<persName coords=""><forename type="first">Serge</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vitali</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yashin</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aleh</forename><surname>Tarasau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vassili</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<ptr target="CEUR-WS.org&lt;http://ceur-ws.org&gt;" />
	</analytic>
	<monogr>
		<title level="m" coord="9,311.33,415.62,169.27,7.86;9,151.52,426.57,69.59,7.86">CLEF2020 Working Notes, CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">September 22-25 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,448.51,337.64,7.86;9,151.52,459.47,329.07,7.86;9,151.52,470.43,329.08,7.86;9,151.52,481.39,329.08,7.86;9,151.52,492.35,329.07,7.86;9,151.52,503.30,120.31,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,225.99,459.47,254.61,7.86;9,151.52,470.43,30.51,7.86">Efficient and fully automatic segmentation of the lungs in ct volumes</title>
		<author>
			<persName coords=""><forename type="first">Yashin</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Oscar</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alfonso Jiménez</forename><surname>Del Toro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrien</forename><surname>Depeursinge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,317.77,481.39,162.83,7.86;9,151.52,492.35,298.54,7.86">Proceedings of the VISCERAL Anatomy Grand Challenge at the 2015 IEEE ISBI, CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">Orcun</forename><surname>Goksel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Oscar</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">Alfonso Jiménez</forename><surname>Del Toro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Antonio</forename><surname>Foncubierta-Rodríguez</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</editor>
		<meeting>the VISCERAL Anatomy Grand Challenge at the 2015 IEEE ISBI, CEUR Workshop Proceedings</meeting>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2015-05">May 2015</date>
			<biblScope unit="page" from="31" to="35" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,514.28,337.63,7.86;9,151.52,525.24,329.07,7.86;9,151.52,536.20,329.06,7.86;9,151.52,547.16,329.07,7.86;9,151.52,558.12,327.08,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,323.40,514.28,157.19,7.86;9,151.52,525.24,206.15,7.86">Imageclef 2017: Supervoxels and cooccurrence for tuberculosis CT image classification</title>
		<author>
			<persName coords=""><forename type="first">Vitali</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vassili</forename><surname>Kovalev</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="9,379.62,536.20,100.96,7.86;9,151.52,547.16,212.97,7.86">Working Notes of CLEF 2017 -Conference and Labs of the Evaluation Forum</title>
		<title level="s" coord="9,267.94,558.12,145.11,7.86">CEUR Workshop Proceedings. CEUR</title>
		<editor>
			<persName><forename type="first">Linda</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Lorraine</forename><surname>Goeuriot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thomas</forename><surname>Mandl</surname></persName>
		</editor>
		<meeting><address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">September 11-14, 2017. 2017</date>
			<biblScope unit="volume">1866</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,569.09,337.63,7.86;9,151.52,580.05,329.07,7.86;9,151.52,591.01,329.08,7.86;9,151.52,601.97,294.95,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,267.64,591.01,208.76,7.86">ImageNet Large Scale Visual Recognition Challenge</title>
		<author>
			<persName coords=""><forename type="first">Olga</forename><surname>Russakovsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jia</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hao</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jonathan</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sanjeev</forename><surname>Satheesh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sean</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhiheng</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrej</forename><surname>Karpathy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aditya</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Li</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,151.52,601.97,200.28,7.86">International Journal of Computer Vision (IJCV)</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="211" to="252" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,612.95,337.98,7.86;9,151.52,623.90,142.43,7.86" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="9,327.39,612.95,153.20,7.86;9,151.52,623.90,114.45,7.86">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName coords=""><forename type="first">Karen</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,634.88,337.98,7.86;9,151.52,645.84,329.07,7.86;9,151.52,656.80,127.87,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,391.23,634.88,89.37,7.86;9,151.52,645.84,85.33,7.86">Deep residual learning for image recognition</title>
		<author>
			<persName coords=""><forename type="first">Kaiming</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiangyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shaoqing</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jian</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,269.73,645.84,210.86,7.86;9,151.52,656.80,80.55,7.86">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016-06">2016. Jun 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,119.67,337.98,7.86;10,151.52,130.63,329.07,7.86;10,151.52,141.59,227.72,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,418.81,119.67,61.79,7.86;10,151.52,130.63,203.90,7.86">Learning transferable architectures for scalable image recognition</title>
		<author>
			<persName coords=""><forename type="first">Barret</forename><surname>Zoph</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vijay</forename><surname>Vasudevan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jonathon</forename><surname>Shlens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Quoc</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,386.35,130.63,94.25,7.86;10,151.52,141.59,181.56,7.86">IEEE/CVF Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2018-06">2018. Jun 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,152.55,337.99,7.86;10,151.52,163.51,189.45,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,283.35,152.55,197.26,7.86;10,151.52,163.51,95.95,7.86">Efficientnet: Rethinking model scaling for convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">Mingxing</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Quoc</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,255.80,163.51,24.16,7.86">ICML</title>
		<imprint>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,174.47,218.56,7.86" xml:id="b13">
	<monogr>
		<ptr target="https://github.com/tensorflow" />
		<title level="m" coord="10,186.13,174.47,41.50,7.86">Tensorflow</title>
		<imprint/>
		<respStmt>
			<orgName>Google</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
