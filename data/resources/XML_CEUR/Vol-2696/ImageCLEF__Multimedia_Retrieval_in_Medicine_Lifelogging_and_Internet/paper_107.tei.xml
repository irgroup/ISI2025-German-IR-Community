<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,149.92,115.96,315.52,12.62;1,138.92,133.89,337.50,12.62">ImageCLEF 2020: Image Caption Prediction using Multilabel Convolutional Neural Network</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,136.18,171.56,76.29,8.74"><forename type="first">Sarada</forename><forename type="middle">Devi</forename><surname>Arul</surname></persName>
							<email>sarada1806@cse.ssn.edu.in</email>
							<affiliation key="aff0">
								<orgName type="department">Department of CSE</orgName>
								<orgName type="institution">SSN College of Engineering</orgName>
								<address>
									<postCode>-603110</postCode>
									<settlement>Kalavakkam</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,309.11,171.56,82.83,8.74"><forename type="first">Kavitha</forename><surname>Srinivasan</surname></persName>
							<email>kavithas@ssn.edu.in</email>
							<affiliation key="aff0">
								<orgName type="department">Department of CSE</orgName>
								<orgName type="institution">SSN College of Engineering</orgName>
								<address>
									<postCode>-603110</postCode>
									<settlement>Kalavakkam</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,149.92,115.96,315.52,12.62;1,138.92,133.89,337.50,12.62">ImageCLEF 2020: Image Caption Prediction using Multilabel Convolutional Neural Network</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E578E194D12D54E9F674782552DB3BC0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Radiology images</term>
					<term>Caption detection</term>
					<term>Preprocessing</term>
					<term>Multilabel CNN</term>
					<term>F1 score</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Radiology imaging encompasses different imaging modalities and the images are acquired from the human body for diagnostic and treatment purpose. The different imaging modalities are Computed Tomography (CT), Ultrasound, X-Ray, Positron Emission Tomography (PET), Magnetic Resonance Imaging (MRI), Angiography and Cardiac Output (CO). These images are used to identify the disease types and its stages. In this paper, an automatic caption detection technique for multi modality radiology images of various disease types and organs is implemented and explained for the task of ImageCLEF 2020. This research work includes dataset collection, preprocessing of the dataset and caption prediction using multilabel Convolutional Neural Network (CNN). The correctness of the predicted captions is validated using the metric, F1 Score. The result obtained from the proposed model for the test set is 13.46%. The achieved result is at 42nd position in the overall leaderboard of the ImageCLEF 2020 caption -concept detection for radiology images.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Medical imaging or radiology imaging can be acquired using various modalities like Computed Tomography (CT), Ultrasound, X-Ray, Positron Emission Tomography (PET), Magnetic Resonance Imaging (MRI), Angiography and Cardiac Output (CO) <ref type="bibr" coords="1,237.57,532.21,9.96,8.74" target="#b2">[3]</ref>. The applications of the radiology imaging include classification, prediction, information extraction, information retrieval, concept detection etc.</p><p>Image Caption identification is a kind of concept detection or prediction application. Captioning task can be carried out for natural images and medical images. In natural images, major features like colour and shape are extracted for caption identification <ref type="bibr" coords="1,245.91,603.94,9.96,8.74" target="#b1">[2]</ref>. However in case of medical images it is tedious to extract the important features, so the identification result is not accurate. Also, interpreting and summarizing the insights gained from medical images such as radiology output is a time-consuming task and requires highly trained experts <ref type="bibr" coords="2,134.77,142.90,9.96,8.74" target="#b0">[1]</ref>. To address these issues, the automatic generation of captions for different modalities becomes an important task in reality <ref type="bibr" coords="2,351.80,154.86,10.52,8.74" target="#b1">[2,</ref><ref type="bibr" coords="2,366.28,154.86,7.01,8.74" target="#b7">8]</ref>. In this paper, a multilabel Convolutional Neural Network (CNN) approach for caption prediction is discussed with results. This work is a subtask of the medical tasks of ImageCLEF 2020 and establishes detection of captions for multimodality radiology images.</p><p>The sections includes the following: Section 1 gives a brief introduction about the necessity to perform caption prediction. Section 2 describes about the dataset which includes radiology images of various modalities and Section 2.1 details about the data preprocessing procedures. Section 3 explains the proposed model using multilabel convolutional neural network along with the parameters for analysis. In Section 4, the results are discussed. Finally, Section 5 concludes this paper with further refinement of the proposed model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dataset</head><p>In this edition of ImageCLEF 2020, for concept detection a total of 84,257 radiology images are given, out of which 64,753 are training images, 15970 are for validation and 3534 are for testing the model <ref type="bibr" coords="2,353.35,354.11,15.50,8.74" target="#b12">[13,</ref><ref type="bibr" coords="2,372.51,354.11,11.62,8.74" target="#b13">14]</ref>. All these images are present in any one of the seven modality folders namely, Computed Tomography (CT), Ultrasound, X-Ray, Positron Emission Tomography (PET), Magnetic Resonance Imaging (MRI), Angiography and Cardiac Output (CO). Similarly the captions of the images of seven modalities are given in seven excel sheets appropriately. In Figure <ref type="figure" coords="2,245.40,413.89,3.87,8.74" target="#fig_0">1</ref>, sample image for each modality is shown with its corresponding image id of the given dataset for each modality <ref type="bibr" coords="2,408.10,425.84,15.50,8.74" target="#b12">[13,</ref><ref type="bibr" coords="2,426.92,425.84,11.62,8.74" target="#b13">14]</ref>. On further analysis of dataset, the maximum number of captions per image is nearly 140 and each image is of different size, are the challenges in generating the relevant captions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data Preprocessing</head><p>Preprocessing of Text In the given dataset single file is present for text. This file includes image id and their corresponding caption unique id in sorted order. Using these labels one of the inputs for multilabel CNN is created. The input file is created in excel format, where the caption id as header and rows are filled with the image id of that particular modality alone. For each image id, one hot vector form <ref type="bibr" coords="4,189.15,198.95,15.50,8.74" target="#b10">[11]</ref> is created in such a way that the captions of specific columns are made as 1 and others as 0. Similarly, this is carried out for all the seven modalitites. Therefore, 7 different sized one hot vectors are derived. The one hot vector sizes for angiography, CO, CT, PET, MRI, X-Ray and Ultrasound modalities are 2578, 1675, 3013, 1491, 2980, 2986 and 2877 respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preprocessing of Images</head><p>The radiology images of the given 7 modalities are of varying sizes. But, the images of same dimension must be given as input to the CNN. Therefore, resizing of the image is carried out in such a way that all the images are of same width and height i.e (600, 600), since most of the images in the dataset are of that size only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodolgy</head><p>Initially, CNN approach is applied to predict the image captions. The conventional CNN usually takes the folder name as captions, where as the given clef 2020 dataset comprises of more than one label for each image. Hence, it generates inappropriate captions and also only single caption per image. To address this issue, a multilabel CNN is proposed for this task. The given dataset has multiple modalities and maximum of 140 captions for each image <ref type="bibr" coords="4,426.71,440.82,9.96,8.74" target="#b5">[6]</ref>. The layers chosen for the proposed model are convolutional layer, max pooling layer, flattening layer and dense layer.</p><p>Import Keras and other packages that are required in building the CNN like Sequential, Convolution2D, MaxPooling2D, Flatten and Dense layer. Build the model using the Sequential.add() function. Four convolutional layers are added with the filter size as 16, 16, 32 and 32 respectively and the kernel size as <ref type="bibr" coords="4,134.77,524.56,11.62,8.74" target="#b2">(3,</ref><ref type="bibr" coords="4,146.39,524.56,7.75,8.74" target="#b2">3)</ref>. These layers are used to extract the high-level features such as edges and boundaries from the input image <ref type="bibr" coords="4,283.20,536.51,9.96,8.74" target="#b4">[5]</ref>. Add a pooling layer with a size of (2, 2), to reduce the spatial size of the representation of input image. One flatten layer is added to generate a vector from the fully connected layers and the last dense layer outputs as either 1 or 0.</p><p>Finally, the output nodes are fixed in the last layer based on the one hot vector size for each of the seven modality <ref type="bibr" coords="4,312.30,596.34,14.61,8.74" target="#b10">[11]</ref>. Each output node belongs to some class. Categorical crossentropy loss function is used, since it is more suitable for multiclass classification <ref type="bibr" coords="4,238.18,620.25,10.52,8.74" target="#b8">[9,</ref><ref type="bibr" coords="4,251.45,620.25,11.62,8.74" target="#b11">12]</ref>. The sigmoid activation function used on the final layer converts each score of the final node between 0 to 1 independent of the other score. If the score of the particular class is more than 0.5, the data is classified into that class. And there could be multiple classes having a score of more than 0.5 independently. Thus the data could be classified into multiple classes. In Figure <ref type="figure" coords="5,134.77,130.95,3.87,8.74" target="#fig_1">2</ref>, the sample image (ROCO2 CLEF 05873) from Cardiac Output modality is given as input to the model for caption prediction. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiment and Results</head><p>CNN model has many hyperparameters to build it efficiently. By fixing them appropriately, the results can be improved.</p><p>To make the decision on fixing the layers of convolution, visualisation can be carried out. After visualization, four convolutional layers are fixed, since the boundaries and edges of the image is more visible than the three layers. In Figure <ref type="figure" coords="5,134.77,532.98,3.87,8.74" target="#fig_2">3</ref>, the input image with image id ROCO2 CLEF 05865 from CO modality is given for understanding and visualizing the effect of convolution layers.  The multilabel CNN model with the specific hyperparameters <ref type="bibr" coords="7,433.61,118.99,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="7,448.77,118.99,12.73,8.74" target="#b9">10]</ref> has been evaluated using the given dataset and appropriate performance metrics <ref type="bibr" coords="7,134.77,142.90,14.61,8.74" target="#b11">[12]</ref>. All the seven folders are trained with 3 epochs to build the seven different models. Testing is done with their respective models and the captions are obtained. The resulted accuracy of training and validation set are 0.4034 and 0.2478 respectively. For the test set, the F1 score obtained is 0.1346 in a single run and ranked as 42nd in the leaderboard of the ImageCLEF 2020 caption task. The F1 score is comparatively very less, because only 20 captions are used in the prediction of test set. The main challenges of this task are: large dataset with images of different characterstics, implementation of one hot vector with sparse data, maximum number of captions is around 140, training model needs more time, if the internet is used for execution it becomes still more tedious process, needs high requirements in terms of hardware like memory, processor etc for better computability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>In this paper, an automatic caption prediction for multimodality radiology images is implemented and explained for the given ImageCLEF 2020 task dataset using multilabel CNN. The dataset is preprocessed in both text and image aspects, and the maximum number of captions per image is identified. From the number of captions identified, one hot vector is derived for every modality and training of the model is carried out. The model is evaluated using F1 metric for the test set (3534 images), which resulted in 13.46%. The limitations of the work are number of captions used in testing and hyperparameters of the multilabel CNN model.</p><p>In future, the prediction results can be improved further based on the dataset, methods to modify the one hot vector in an efficient way and advanced deep learning techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgement</head><p>Our profound gratitude to SSN College of Engineering, Department of CSE, for allowing us to utilize the High Performance Computing Laboratory and GPU Server for the execution of this challenge successfully.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,134.77,576.85,345.83,7.89;3,134.77,587.83,345.82,7.86;3,134.77,598.79,345.83,7.86;3,134.77,609.75,296.89,7.86;3,134.77,160.64,345.85,401.44"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Radiology images of seven modalities with image id and modality a) ROCO2 CLEF 00001 Angiography b) ROCO2 CLEF 05850 CO c) ROCO2 CLEF 06406 CT d) ROCO2 CLEF 45724 PET e) ROCO2 CLEF 31429 MRI f) ROCO2 CLEF 57063 XRAY g) ROCO2 CLEF 46300 Ultrasound</figDesc><graphic coords="3,134.77,160.64,345.85,401.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,222.75,395.58,169.85,7.89;5,134.77,174.32,345.82,206.49"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Overall process of multilabel CNN</figDesc><graphic coords="5,134.77,174.32,345.82,206.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,218.39,620.85,178.58,7.89;6,134.77,334.14,345.82,271.94"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Visualisation of Convolutional layers</figDesc><graphic coords="6,134.77,334.14,345.82,271.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,145.40,457.89,307.74,114.99"><head>Table 1 .</head><label>1</label><figDesc>Distribution of dataset across 7 modalities</figDesc><table coords="2,145.40,487.91,307.74,84.97"><row><cell>Modality</cell><cell>Training</cell><cell>Validation</cell><cell>Test</cell><cell>Total</cell></row><row><cell>Angiography</cell><cell>4713</cell><cell>1132</cell><cell>325</cell><cell>6170</cell></row><row><cell>Cardiac Output</cell><cell>487</cell><cell>73</cell><cell>49</cell><cell>609</cell></row><row><cell>CT</cell><cell>20031</cell><cell>4992</cell><cell>1140</cell><cell>26163</cell></row><row><cell>MRI</cell><cell>11,447</cell><cell>2848</cell><cell>562</cell><cell>14857</cell></row><row><cell>PET</cell><cell>502</cell><cell>74</cell><cell>38</cell><cell>614</cell></row><row><cell>Ultrasound</cell><cell>8629</cell><cell>2134</cell><cell>502</cell><cell>11265</cell></row><row><cell>X-Ray</cell><cell>18944</cell><cell>4717</cell><cell>918</cell><cell>24579</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,200.91,150.09,213.55,105.77"><head>Table 2 .</head><label>2</label><figDesc>CNN hyperparameters.</figDesc><table coords="6,200.91,170.89,213.55,84.97"><row><cell>Hyperparameters</cell><cell>Values</cell></row><row><cell cols="2">No. of Convolutional layer 4</cell></row><row><cell cols="2">No. of filters in each layer 16, 16, 32, 32</cell></row><row><cell>Pooling function</cell><cell>max</cell></row><row><cell>Activation function</cell><cell>relu, sigmoid</cell></row><row><cell>No. of epochs</cell><cell>3</cell></row><row><cell>Loss type</cell><cell>categorical cross entrophy</cell></row><row><cell>Optimizer</cell><cell>adam</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,138.35,580.73,342.24,7.86;7,146.91,591.69,333.68,7.86;7,146.91,602.65,333.68,7.86;7,146.91,613.61,132.06,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,146.91,591.69,333.68,7.86;7,146.91,602.65,121.13,7.86">Overview of ImageCLEFcaption 2017-Image Caption Prediction and Concept Detection for Biomedical Images</title>
		<author>
			<persName coords=""><forename type="first">Carsten</forename><surname>Eickhoff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Immanuel</forename><surname>Schwall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alba</forename><forename type="middle">G</forename><surname>Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,291.33,602.65,189.27,7.86;7,146.91,613.61,46.41,7.86">CLEF 2017 Working Notes. CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,623.92,342.25,7.86;7,146.91,634.88,333.68,7.86;7,146.91,645.84,333.68,7.86;7,146.91,656.80,149.26,7.86" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="7,363.51,634.88,117.08,7.86;7,146.91,645.84,329.26,7.86">Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures</title>
		<author>
			<persName coords=""><forename type="first">Raffaella</forename><surname>Bernardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ruket</forename><surname>Cakici</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Desmond</forename><surname>Elliott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aykut</forename><surname>Erdem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Erkut</forename><surname>Erdem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Frank</forename><surname>Keller Keller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrian</forename><forename type="middle">Muscatbarbara</forename><surname>Plank</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1601.03896v2</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,119.67,342.24,7.86;8,146.91,130.63,242.63,7.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="8,311.22,119.67,169.36,7.86;8,146.91,130.63,65.55,7.86">On the Automatic Generation of Medical Imaging Reports</title>
		<author>
			<persName coords=""><forename type="first">Baoyu</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pengtao</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eric</forename><forename type="middle">P</forename><surname>Xing</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1711.08195v3</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2577" to="2586" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,141.59,342.24,7.86;8,146.91,152.55,333.68,7.86;8,146.91,163.51,248.91,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,146.91,152.55,239.48,7.86">Overview of the ImageCLEF 2018 Caption Prediction Tasks</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Alba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carsten</forename><surname>Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vincent</forename><surname>Eickhoff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Andrearczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,407.11,152.55,73.48,7.86;8,146.91,163.51,163.27,7.86">CLEF 2018 Working Notes. CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,174.47,342.25,7.86;8,146.91,185.43,232.08,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,343.83,174.47,136.77,7.86;8,146.91,185.43,32.75,7.86">Comparison of Image Captioning Methods</title>
		<author>
			<persName coords=""><forename type="first">Jeel</forename><surname>Sukhadiya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Harsh</forename><surname>Pandya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vedant</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,201.49,185.43,25.60,7.86">IJEDR</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="43" to="48" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,196.39,342.24,7.86;8,146.91,207.34,333.68,7.86;8,146.91,218.30,205.09,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,332.26,196.39,148.33,7.86;8,146.91,207.34,199.57,7.86">ImageSem at ImageCLEF 2018 Caption Task: Image Retrieval and Transfer Learning</title>
		<author>
			<persName coords=""><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xuwen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhen</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiao</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,368.23,207.34,112.36,7.86;8,146.91,218.30,119.44,7.86">CLEF 2018 Working Notes. CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,229.26,342.24,7.86;8,146.91,240.22,333.68,7.86;8,146.91,251.18,233.55,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,252.41,229.26,228.18,7.86;8,146.91,240.22,233.21,7.86">A Cross Modal Deep Learning Based Approach for Caption Prediction and Concept Detection by CS Morgan State</title>
		<author>
			<persName coords=""><forename type="first">Md</forename><surname>Mahmudur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rahman</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,399.23,240.22,81.36,7.86;8,146.91,251.18,147.90,7.86">CLEF 2018 Working Notes. CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,262.14,342.24,7.86;8,146.91,273.10,333.68,7.86;8,146.91,284.06,270.69,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,146.91,273.10,262.13,7.86">Overview of the ImageCLEFmed 2019 Concept Detection Task</title>
		<author>
			<persName coords=""><forename type="first">Obioma</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christoph</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alba</forename><forename type="middle">G</forename><surname>Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,433.09,273.10,47.50,7.86;8,146.91,284.06,185.04,7.86">CLEF 2019 Working Notes. CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,295.02,342.24,7.86;8,146.91,305.98,333.68,7.86;8,146.91,316.93,132.06,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,389.10,295.02,91.49,7.86;8,146.91,305.98,101.96,7.86">AUEB NLP Group at ImageCLEFmed Caption</title>
		<author>
			<persName coords=""><forename type="first">Vasiliki</forename><surname>Kougia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Pavlopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ion</forename><surname>Androutsopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,292.21,305.98,188.38,7.86;8,146.91,316.93,46.41,7.86">CLEF 2019 Working Notes. CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,327.89,337.97,7.86;8,146.91,338.85,333.68,7.86;8,146.91,349.81,270.69,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,336.82,327.89,143.77,7.86;8,146.91,338.85,265.09,7.86">ImageSem at ImageCLEFmed Caption 2019 Task: a Two-stage Medical Concept Detection Strategy</title>
		<author>
			<persName coords=""><forename type="first">Zhen</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xuwen</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jiao</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,433.97,338.85,46.62,7.86;8,146.91,349.81,185.04,7.86">CLEF 2019 Working Notes. CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,360.77,337.98,7.86;8,146.91,371.73,333.67,7.86;8,146.91,382.69,333.67,7.86;8,146.91,393.65,153.62,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,146.91,371.73,333.67,7.86;8,146.91,382.69,142.65,7.86">Concept detection based on Multi-label Classification and Image Captioning Approach DAMO at ImageCLEF 2019</title>
		<author>
			<persName coords=""><forename type="first">Jing</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chao</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yu</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ying</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xuansong</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiansheng</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,310.98,382.69,169.60,7.86;8,146.91,393.65,67.97,7.86">CLEF 2019 Working Notes. CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,404.61,337.98,7.86;8,146.91,415.56,333.67,7.86;8,146.91,426.52,333.68,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,399.10,404.61,81.49,7.86;8,146.91,415.56,329.36,7.86">Biomedical Concept Detection in Medical Images: MQ-CSIRO at 2019 ImageCLEFmed Caption Task</title>
		<author>
			<persName coords=""><forename type="first">Sonit</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sarvnaz</forename><surname>Karimi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kevin</forename><surname>Ho-Shon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Len</forename><surname>Hamey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,160.95,426.52,234.07,7.86">CLEF 2019 Working Notes. CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,437.48,337.98,7.86;8,146.91,448.44,333.68,7.86;8,146.91,459.40,333.68,7.86;8,146.91,470.36,303.89,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,146.91,448.44,333.68,7.86;8,146.91,459.40,57.36,7.86">Overview of the ImageCLEFmed 2020 Concept Prediction Task: Medical Image Understanding</title>
		<author>
			<persName coords=""><forename type="first">Obioma</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christoph</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alba</forename><forename type="middle">G</forename><surname>Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<ptr target="org" />
	</analytic>
	<monogr>
		<title level="m" coord="8,224.03,459.40,226.92,7.86">CLEF2020 Working Notes. CEUR Workshop Proceedings</title>
		<title level="s" coord="8,235.43,470.36,43.39,7.86">CEUR-WS.</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020-09-22">2020. September 22-25, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,481.32,337.97,7.86;8,146.91,492.28,333.68,7.86;8,146.91,503.24,333.67,7.86;8,146.91,514.19,333.68,7.86;8,146.91,525.15,333.68,7.86;8,146.91,536.11,333.68,7.86;8,146.91,547.07,333.67,8.29;8,146.91,558.03,333.68,7.86;8,146.91,568.99,333.68,7.86;8,146.91,579.95,333.68,7.86;8,146.91,590.91,333.68,7.86;8,146.91,601.87,281.49,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,181.71,558.03,298.89,7.86;8,146.91,568.99,189.93,7.86">Overview of the ImageCLEF 2020: Multimedia Retrieval in Lifelogging, Medical, Nature, and Internet Applications In</title>
		<author>
			<persName coords=""><forename type="first">Bogdan</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Renaud</forename><surname>Péteri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Asma</forename><surname>Ben Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vivek</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sadid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dina</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Serge</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vitali</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yashin</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vassili</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Obioma</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christoph</forename><forename type="middle">M</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alba</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Van-Tu</forename><surname>García Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tu-Khiem</forename><surname>Ninh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liting</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luca</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pål</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Minh-Triet</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mathias</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cathal</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Duc-Tien</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jon</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrian</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antonio</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dimitri</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Raul</forename><surname>Fichou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Berari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mihai</forename><surname>Brie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liviu</forename><surname>Dogariu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Daniel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mihai</forename><surname>Gabriel Constantin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,344.60,568.99,135.99,7.86;8,146.91,579.95,333.68,7.86;8,146.91,590.91,182.57,7.86">Proceedings of the 11th International Conference of the CLEF Association (CLEF 2020)</title>
		<title level="s" coord="8,423.33,590.91,57.26,7.86;8,146.91,601.87,107.98,7.86">LNCS Lecture Notes in Computer Science</title>
		<meeting>the 11th International Conference of the CLEF Association (CLEF 2020)<address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">September 22-25, 2020</date>
			<biblScope unit="volume">12260</biblScope>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="8,142.62,612.82,337.98,7.86;8,146.91,623.78,333.68,7.86;8,146.91,634.74,333.68,7.86;8,146.91,645.70,153.62,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,453.20,612.82,27.39,7.86;8,146.91,623.78,333.68,7.86;8,146.91,634.74,143.35,7.86">Image-CLEF 2019: A 2D Convolutional Neural Network Approach for Severity Scoring of Lung Tuberculosis using CT Images</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kavitha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">R</forename><surname>Nandhinee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Harshana</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">S</forename><surname>Srividya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Harrinei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,311.60,634.74,168.99,7.86;8,146.91,645.70,67.97,7.86">CLEF 2019 Working Notes. CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
