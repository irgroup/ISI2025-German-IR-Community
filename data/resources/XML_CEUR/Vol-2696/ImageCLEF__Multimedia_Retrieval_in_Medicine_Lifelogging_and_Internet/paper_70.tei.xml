<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,157.22,152.79,280.87,12.64;1,132.50,170.79,330.20,12.64;1,126.74,188.79,341.70,12.64;1,273.89,206.79,47.41,12.64">ImageCLEF2020: Laterality-Reduction Three-Dimensional CBAM-Resnet with Balanced Sampler for Multi-Binary Classification of Tuberculosis and CT Auto Reports</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,128.66,245.97,33.61,8.96"><forename type="first">Xing</forename><surname>Lu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>San Diego</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,233.33,245.97,54.96,8.96"><forename type="first">Eric</forename><forename type="middle">Y</forename><surname>Chang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">San Diego VA Health Care System</orgName>
								<address>
									<settlement>San Diego</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>San Diego</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,365.95,245.97,49.69,8.96"><forename type="first">Zhaohui</forename><surname>Liu</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">RIMAG Medical Imaging Corporation</orgName>
								<address>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,195.73,257.49,33.46,8.96"><forename type="first">Nan</forename><surname>Hsu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>San Diego</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,300.15,257.49,35.79,8.96"><forename type="first">Jiang</forename><surname>Du</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>San Diego</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,407.09,257.49,37.16,8.96;1,248.21,269.01,27.75,8.96"><forename type="first">Amilcare</forename><surname>Gentili</surname></persName>
							<email>agentili@ucsd.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">San Diego VA Health Care System</orgName>
								<address>
									<settlement>San Diego</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>San Diego</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,157.22,152.79,280.87,12.64;1,132.50,170.79,330.20,12.64;1,126.74,188.79,341.70,12.64;1,273.89,206.79,47.41,12.64">ImageCLEF2020: Laterality-Reduction Three-Dimensional CBAM-Resnet with Balanced Sampler for Multi-Binary Classification of Tuberculosis and CT Auto Reports</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CEC9201FB00FBA5C82D840A7C2455206</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Tuberculosis</term>
					<term>Convolutional Neural Network</term>
					<term>Laterality-Reduction</term>
					<term>Dataset Imbalance</term>
					<term>Attention Mechanism</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Detection and characterization of tuberculosis and the evaluation of lesion characteristics are challenging. In an effort to provide a solution for a classification task of tuberculosis findings, we proposed a laterality-reduction 3D CBAM Resnet with balanced-sampler strategy. With proper usage of both provided masks, each side of the lung was cropped, masked, and rearranged so that laterality could be neglected, and dataset size doubled. Balanced sampler in each batch sampler was also used in this study to address the data imbalance problem. CBAM was used to add an attention mechanism in each block of the Resnet to further improve the performance of the CNN.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Tuberculosis (TB) is a bacterial infection caused by the germ Mycobacterium tuberculosis and is a leading cause of death from infectious disease worldwide. An epidemic in many developing regions, such as Africa and Southeast Asia, it was responsible for 1.6 million deaths in 2017 alone. There are different manifestations of TB which require different treatments, making the detection and characterization of TB disease and -the evaluation of lesion characteristics critically important tasks in the monitoring, control, and treatment of this disease. An accurate and automated method for the classification of TB from CT images may be especially useful in regions of the world with few radiologists.</p><p>The ImageCLEF 2020 Tuberculosis -CT report challenge <ref type="bibr" coords="2,378.41,150.42,11.58,8.96" target="#b0">[1,</ref><ref type="bibr" coords="2,389.99,150.42,7.72,8.96" target="#b1">2]</ref> was concentrated on the automated CT report generation task. This year, three labels for each side of the lungs were provided, namely labeling for the presence of TB lesions, pleurisy, and caverns. In addition, a dataset containing chest CT scans of 403 TB patients (283 for training and 120 for testing) was provided.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data</head><p>The dataset provided for the CT report task training contained a total of 283 patients, with labeling provided for six categories. As seen in Figure <ref type="figure" coords="2,371.33,287.49,3.73,8.96" target="#fig_0">1</ref>(a), the training dataset distribution of pathology was quite unbalanced, with "lung affected" at both sides being the most commonly seen label, caverns being seen less, and pleurisy being the most rarely observed condition. 17 sub-category combinations of the six categories are shown in Figure <ref type="figure" coords="2,191.95,335.39,3.83,9.05" target="#fig_0">1</ref>(b), with "lung affected for both sides" (represented by [1,1,0,0,0,0]) as the sub-category with the most dataset counts of 73. By neglecting the laterality of the lungs and re-arranging the dataset, we found that the dataset counts doubled to 576, but the categories for classification were sharply reduced from six to three, as shown in Figure <ref type="figure" coords="3,275.00,174.42,3.71,8.96" target="#fig_0">1</ref>(c). When combining these resulting three categories, there were only five sub-categories, as shown in Figure <ref type="figure" coords="3,374.82,186.32,15.39,9.05" target="#fig_0">1(d)</ref>. The "lung affected by lesion" category (represented by [1,0,0]) had the most counts of 288, while lung with all three pathologies present had the fewest counts of 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Pre-processing</head><p>To perform laterality-reduction, it was necessary to properly obtain images from both sides of the lungs from the original dataset. Laterality-reduction images were obtained according to the algorithm pipeline as shown in Figure <ref type="figure" coords="3,360.18,284.49,3.76,8.96" target="#fig_1">2</ref>. The images for the Im-ageCLEF tuberculosis task were provided as NIFTI 3D datasets. Two versions of lung segmentation masks were also provided <ref type="bibr" coords="3,290.49,308.49,10.89,8.96" target="#b2">[3,</ref><ref type="bibr" coords="3,301.38,308.49,7.26,8.96" target="#b3">4]</ref>. The first version of segmentation (denoted as Mask 1) provided more accurate masks, containing masks for left and right laterality individually (values equal 1 for left and 2 for right), but in the most severe TB cases, there was a tendency to miss large abnormal regions of lungs. On the other hand, the second segmentation (denoted as Mask 2) provided less precise bounds, but was more stable in terms of including lesion areas, though it contained the entire lung area (including both left and right sides of the lungs). In order to take advantages of both masks, a two-step mask-cropping algorithm was proposed in this study. As shown in Figure <ref type="figure" coords="3,298.49,647.18,3.76,8.96" target="#fig_1">2</ref>, both segmentation versions were used to generate a laterality-reduction lung segmentation. First, the original NIFTI-formatted dataset was transformed into image data using the NiBabel package <ref type="bibr" coords="3,392.45,671.18,10.87,8.96" target="#b4">[5]</ref>. Then, the reformatted images were adjusted to three different window levels, namely baseline, lung, and soft tissue, and then normalized. For baseline window level, the foreground was obtained via the otsu_thresholding algorithm provided in openCV package <ref type="bibr" coords="4,422.27,162.42,11.15,8.96" target="#b5">[6]</ref>; for lung and soft tissue, the image levels were set as [-600,1500] and [50,350], respectively. Then, images were normalized to [0,1] with their mean and std value. Afterward, each laterality of the images was cropped according to Mask 1. For the left laterality of the lungs, the right boundary of the lungs was found and used to crop the left side from the images at stage 1. Similarly, the right laterality used the left boundary to obtain the right side from the images at stage 1. Finally, all three windows and levels of laterality-reduction data were saved, and annotation file was rearranged for use in further training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Network Design and Training Strategy</head><p>As shown in Figure <ref type="figure" coords="4,204.43,296.49,3.76,8.96" target="#fig_2">3</ref>, a 3D convolutional block attention module (CBAM)-Resnet was designed to train the model for 3-class binary classification based on the PyTorch framework. A standard 3D-resnet34 <ref type="bibr" coords="4,272.64,320.49,11.69,8.96" target="#b6">[7]</ref> was used as the convolutional neural network backbone, with three fc layers to be the classifier. CBAM <ref type="bibr" coords="4,362.10,332.49,11.81,8.96" target="#b7">[8]</ref> was used to implement channel and spatial attention mechanisms for each block of the Resnet. Sigmoid was used as the activation function for binary classification. To train the neural network, we used a workstation with 4 Nvidia GTX 1080 Ti video cards, 128 GB RAM, and a 1 TB solid state drive. The training dataset was randomly split to form a validation cohort comprised of 20% of the original dataset. During the training process, to avoid over-fitting, image augmentation and balanced sampler were implemented in each batch. For each batch, 12 datasets that were fed into the network were dynamically generated from saved metadata with different window levels as a single channel and were interpolated into a 3*64*256*256 size torch tensor. For the image augmentation, traditional data augmentation methods, including brightness, shear, scale, and flip were applied. The balanced sampler strategy was adopted during the training process, which equalized the data sampled from all three classes for each batch <ref type="bibr" coords="5,148.91,174.42,10.61,8.96" target="#b8">[9]</ref>.</p><p>Binary CrossEntroy (BCE) was used as the baseline for the multi-binary classification loss. Then, to improve the performance of the network, weighted BCE loss was applied to let the network focus more on the "lung affected" and "caverns" categories. Weighted focal loss was also applied in order to let the network focus further on more difficult examples <ref type="bibr" coords="5,199.84,234.42,15.43,8.96" target="#b9">[10]</ref>. All losses were realized on the PyTorch platform according to equations ( <ref type="formula" coords="5,169.44,246.45,3.86,8.96">1</ref>) and ( <ref type="formula" coords="5,200.22,246.45,3.62,8.96" target="#formula_1">2</ref>):</p><formula xml:id="formula_0" coords="5,156.14,270.41,314.56,37.56">loss ùëìùëúùëêùëéùëô (ùëô ùëèùëêùëí , ùõº, ùõæ) = Œ±(1 -ùëô ùëèùëêùëí ) ùëü ùëô ùëèùëêùëí (1) ùëô ùëèùëêùëí (o, t, w) = -1/n ‚àë ùë§[ùëñ] * (ùë°[ùëñ] * log(ùëú[ùëñ]) + (1 -ùë°[ùëñ])log(1 -ùëú[ùëñ])) ùëñ .</formula><p>(</p><formula xml:id="formula_1" coords="5,461.76,296.80,8.92,10.21">)<label>2</label></formula><p>Here, o means calculated output, t means target, and w means weights of classes. When ùõº = 1 and ùõæ = 0, loss ùëìùëúùëêùëéùëô is the same with BCE loss. In this study, w equals [4, 2, 1] ùõæ = 2 for focal loss.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Results</head><p>In order to find the best combination of techniques for submission, we tested various combinations using half of the dataset with 20 epochs of training. For each epoch, half of the dataset was randomly selected for training. The experiments were conducted with and without balanced sampling, with and without CBAM, and with various losses (i.e., BCE, wBCE, wFocal). During the training, epochs with the best mean AUC value were saved. Then, models of different experiments were evaluated using the same validation dataset, with the results shown in Figure <ref type="figure" coords="5,288.53,496.67,3.71,8.96" target="#fig_3">4</ref>.  A comparison of experiment results is also summarized in Table <ref type="table" coords="6,384.92,380.01,3.94,8.96" target="#tab_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Inference and Submission</head><p>The provided TST dataset included 120 image files for testing. With our pre-processing pipeline, the TST data were cropped according to the provided Mask 1 and Mask 2 to generate 240 laterality-reduction image files. After prediction by the trained model, the results were rearranged so that both lateralities of one patient were combined again according to the requirement and saved as the .txt file to be submitted. As different techniques were applied, thus generating different results, some results were ensembled in order to generate better results. Ensembling results of weighted binary cross-entropy loss and weighted focal loss gave the best mean AUC. Test time augmentation was also attempted, and although it produced the best minimum AUC, it did not have the best mean AUC. A detailed description of our submissions is as follows:</p><p>For submission ID 67838, the technique used was cbam + balanced sampler + wBCE, number of epochs was 60, and the best model with validation mean AUC of 0.916 was saved and used. The mean AUC obtained on the TST dataset was 0.872, with min AUC of 0.810.</p><p>For submission ID 67839, the technique used was cbam + balanced sampler + wFocal, number of epochs was 60, and the best model with validation mean AUC of 0.918 was saved and used. The mean AUC obtained on the TST dataset was 0.874, with min AUC of 0.809.</p><p>For submission ID 67920, the technique used was cbam + balanced sampler + Focal, number of epochs was 48, and the best model with validation mean AUC of 0.907 was saved and submitted. The mean AUC obtained on the TST dataset was 0.832, with min AUC of 0.779.</p><p>For submission ID 67921, the technique used was cbam + balanced sampler + BCE, number of epochs was 48, and the best model with validation mean AUC of 0.86 was saved and submitted. The mean AUC obtained on the TST dataset was 0.737, with min AUC of 0.708.</p><p>For submission ID 67950, the submitted results were a combination of submission IDs 67838 and 67839. A mean AUC of 0.875 was achieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion and Conclusion</head><p>In an effort to provide a CNN solution for a multi-binary classification task of tuberculosis findings, we proposed a laterality-reduction 3D CBAM Resnet. As severe class imbalance exists in the dataset provided, we tried several techniques to improve the model performance. First, with proper usage of both provided masks, each side of the lungs was cropped, masked, and rearranged so that laterality could be neglected. By cropping each side of the lungs, task number was reduced from six binary classifications to three, but the size of datasets doubled. Balanced sampler in each batch sampler was also used in this study to address the data imbalance problem. CBAM was used to add an attention mechanism in each block of the Resnet to further improve the performance of the CNN. Modified binary focal loss was also realized in the PyTorch framework to allow the network to focus on more difficult examples. Using all the aforementioned techniques, we achieved a mean AUC of 0.875 in the evaluation of the test dataset, and placed second in this competition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Perspectives for Future Work</head><p>In this study, we only tested Resnet-based CNN architecture, as there was a limited timeframe and as the 3D dataset-based CNN was slow to train. In the future, more CNN architectures should be tested, such as 3D Resnet 50, 3D Resnet 101, 3D Densenet <ref type="bibr" coords="7,451.52,660.50,15.35,8.96" target="#b10">[11]</ref>, 3D Efficientnet <ref type="bibr" coords="7,188.35,672.50,15.40,8.96" target="#b11">[12]</ref>, etc. Besides, even with our best performing model, the overfit still existed during training. While this was mostly due to the limited training dataset, additional image augmentation techniques, such as non-linear transformation, contrast random adjusting, channel shuffling, etc. could be tested in the future to obtain even better results. Additionally, because we did not perform the k-fold cross-validation, the training and validation dataset used in this study contained some bias in the distribution of the category. In the future, at least a 5-fold cross-validation will be performed, and the results will be ensembled to form the final model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,130.22,622.27,334.81,8.10;2,131.06,633.10,332.77,8.18;2,126.02,644.23,343.18,8.10;2,217.85,655.27,159.56,8.10;2,124.70,368.40,345.90,244.80"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. TB2020 dataset statistics. (a) Original dataset with six categories, (b) 17 sub-category combinations with "lung affected with both sides" showing the most counts, (c) dataset after laterality-reduction with laterality neglected in three categories, and (d) dataset for all sub-category combinations after laterality-reduction.</figDesc><graphic coords="2,124.70,368.40,345.90,244.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,142.82,612.07,309.65,8.10;3,136.05,389.40,345.90,200.60"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Pipeline for the proposed 2-step laterality-reduction segmentation of the lungs.</figDesc><graphic coords="3,136.05,389.40,345.90,200.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,126.74,555.88,341.66,8.10;4,125.42,566.92,344.08,8.10;4,161.06,577.99,273.12,8.10;4,124.70,377.40,345.90,169.35"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Proposed laterality-reduction 3D CBAM-Resnet architecture. Each laterality of original data is cropped and masked, then fed into a 3D Resnet for training and inference. Each block of the Resnet is modified with convolutional block attention module (CBAM).</figDesc><graphic coords="4,124.70,377.40,345.90,169.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,136.10,508.67,334.13,8.96;5,124.70,520.67,345.69,8.96;5,124.70,532.67,345.68,8.96;5,124.70,544.67,345.82,8.96;5,124.70,556.67,345.86,8.96;5,124.70,568.70,268.26,8.96"><head>Fig. 4 .</head><label>4</label><figDesc>(a) and (b), which show techniques without and with balanced sampler (bsmp), demonstrate that mean AUC is significantly improved from 0.678 to 0.838. With CBAM in (c), the mean AUC is slightly improved to 0.844. With wBCE and wFocal as the loss instead of BCE in (d) and (e), the mean AUC is improved to 0.885 and 0.892. Then, with the full dataset used as the training dataset, the mean AUC combined with wFocal achieved the highest mean AUC score of 0.916.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="6,128.78,334.82,337.46,8.10;6,125.18,345.86,344.99,8.10;6,190.61,356.90,214.14,8.10;6,124.70,147.40,345.90,178.05"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Model performance comparison of different combinations of the techniques, including without cbam, without balanced sampler (bsmp), and with different losses (i.e., binary cross entropy (bce), focal losses, weighted bce, and weighted focal)</figDesc><graphic coords="6,124.70,147.40,345.90,178.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,134.18,403.96,330.60,121.47"><head>Table 1 .</head><label>1</label><figDesc>Experimental Results Summary</figDesc><table coords="6,134.18,420.95,330.60,104.48"><row><cell></cell><cell cols="2">Experiments</cell><cell></cell><cell></cell><cell>Metrics</cell><cell></cell></row><row><cell>CBAM</cell><cell>Balanced Sampler</cell><cell>Loss</cell><cell>Dataset Scale</cell><cell>Loss</cell><cell cols="2">Min AUC Mean AUC</cell></row><row><cell></cell><cell></cell><cell>BCE</cell><cell>Half</cell><cell>0.458</cell><cell>0.55</cell><cell>0.678</cell></row><row><cell></cell><cell>‚àö</cell><cell>BCE</cell><cell>Half</cell><cell>0.553</cell><cell>0.76</cell><cell>0.838</cell></row><row><cell>‚àö</cell><cell>‚àö</cell><cell>BCE</cell><cell>Half</cell><cell>0.387</cell><cell>0.81</cell><cell>0.844</cell></row><row><cell>‚àö</cell><cell>‚àö</cell><cell>wBCE</cell><cell>Half</cell><cell>0.343</cell><cell>0.83</cell><cell>0.885</cell></row><row><cell>‚àö</cell><cell>‚àö</cell><cell>wFocal</cell><cell>Half</cell><cell>0.367</cell><cell>0.87</cell><cell>0.892</cell></row><row><cell>‚àö</cell><cell>‚àö</cell><cell>wFocal</cell><cell>Full</cell><cell>0.302</cell><cell>0.90</cell><cell>0.916</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,132.67,273.02,338.18,8.10;8,141.74,284.06,329.09,8.10;8,141.74,294.98,328.88,8.10;8,141.74,306.02,189.14,8.10" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,449.86,273.02,20.99,8.10;8,141.74,284.06,309.97,8.10">Overview of ImageCLEF tuberculosis 2020 -automatic CT-based report generation</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Tarasau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>M√ºller</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org" />
	</analytic>
	<monogr>
		<title level="m" coord="8,141.74,294.98,213.39,8.10">CLEF2020 Working Notes. CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Thessaloniki, Greece, CEUR-WS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">September 22-25, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.67,317.06,338.13,8.10;8,141.74,327.98,328.99,8.10;8,141.74,339.02,328.92,8.10;8,141.74,350.06,328.94,8.10;8,141.74,360.98,328.70,8.10;8,141.74,372.02,328.86,8.10;8,141.74,383.06,328.72,8.10;8,141.74,393.98,328.56,8.10;8,141.74,405.04,328.78,8.10;8,141.74,416.08,88.07,8.10" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,424.88,360.98,45.57,8.10;8,141.74,372.02,328.86,8.10;8,141.74,383.06,33.89,8.10">Overview of the ImageCLEF 2020: Multimedia retrieval in medical, lifelogging, nature, and internet applications</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>M√ºller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Peteri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">D</forename><surname>Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">T</forename><surname>Ninh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Fichou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Berari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Brie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dogariu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">D</forename><surname>Stefan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">G</forename><surname>Constantin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,193.53,383.06,254.78,8.10;8,195.91,393.98,274.39,8.10;8,141.74,405.04,25.04,8.10">Proceedings of the 11th International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="8,278.87,405.04,154.27,8.10">LNCS Lecture Notes in Computer Science</title>
		<meeting>the 11th International Conference of the CLEF Association (CLEF<address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020-09-22">2020. September 22-25 2020</date>
			<biblScope unit="volume">12260</biblScope>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="8,132.67,427.00,338.01,8.10;8,141.74,438.04,328.97,8.10;8,141.74,449.08,329.01,8.10;8,141.74,460.00,328.93,8.10;8,141.74,471.04,144.33,8.10" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,403.71,427.00,66.96,8.10;8,141.74,438.04,183.71,8.10">Efficient and fully automatic segmentation of the lungs in CT volumes</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Dicente Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><forename type="middle">A</forename><surname>Jim√©nez Del Toro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Depeursinge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>M√ºller</surname></persName>
		</author>
		<ptr target=")31-35" />
	</analytic>
	<monogr>
		<title level="m" coord="8,314.11,449.08,156.64,8.10;8,141.74,460.00,294.19,8.10">Proceedings of the VISCERAL Anatomy Grand Challenge at the 2015 IEEE ISBI. CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">O</forename><surname>Goksel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">O</forename><forename type="middle">A</forename><surname>Jimenez Del Toro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Foncubierta-Rodriguez</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>M√ºller</surname></persName>
		</editor>
		<meeting>the VISCERAL Anatomy Grand Challenge at the 2015 IEEE ISBI. CEUR Workshop Proceedings, CEUR</meeting>
		<imprint>
			<date type="published" when="2015-05">May 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.67,482.08,338.03,8.10;8,141.74,493.00,328.93,8.10;8,141.74,504.04,283.52,8.10" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,240.54,482.08,230.15,8.10;8,141.74,493.00,86.49,8.10">Imageclef 2017: Supervoxels and co-occurrence for tuberculosis CT image classification</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<ptr target=".org&lt;http://ceur-ws.org&gt;" />
	</analytic>
	<monogr>
		<title level="m" coord="8,251.34,493.00,215.49,8.10">CLEF2017 Working Notes. CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Dublin, Ireland, CEUR-WS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">September 11-14, 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.67,515.08,338.02,8.10;8,141.74,526.00,78.62,8.10" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,162.14,526.00,23.90,8.10">Zenodo</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brett</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hanke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Markiewicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-A</forename><surname>C√¥t√©</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cheng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,423.33,515.08,43.72,8.10">nipy/nibabel</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.67,537.04,337.99,8.10;8,141.74,548.08,41.85,8.10" xml:id="b5">
	<monogr>
		<ptr target="https://docs.opencv.org/master/d7/d4d/tutorial_py_thresh-olding.html" />
		<title level="m" coord="8,141.74,537.04,111.52,8.10">OpenCV: Image Thresholding</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.67,559.00,338.01,8.10;8,141.74,570.07,24.09,8.10" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,260.45,559.00,168.84,8.10">Deep Residual Learning for Image Recognition</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,444.91,559.00,25.76,8.10">CVPR</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.67,581.11,337.85,8.10;8,141.74,592.03,52.65,8.10" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,291.17,581.11,175.05,8.10">CBAM: Convolutional Block Attention Module</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Woo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">S</forename><surname>Kweon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,141.74,592.03,26.25,8.10">ECCV</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.67,603.07,312.13,8.10" xml:id="b8">
	<monogr>
		<ptr target="https://github.com/ufoym/imbalanced-dataset-sampler" />
		<title level="m" coord="8,141.74,603.07,101.69,8.10">Imbalanced Dataset Sampler</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.40,614.11,338.29,8.10;8,141.74,625.03,62.34,8.10" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,336.28,614.11,130.90,8.10">Focal loss for dense object detection</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Doll√°r</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,154.08,625.03,23.75,8.10">ICCV</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.40,636.07,338.25,8.10;8,141.74,647.11,91.62,8.10" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,346.63,636.07,124.02,8.10;8,141.74,647.11,33.16,8.10">Densely Connected Convolutional Networks</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Van Der Maaten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">Q</forename><surname>Weinberger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,181.32,647.11,25.76,8.10">CVPR</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.40,658.03,338.16,8.10;8,141.74,669.07,77.62,8.10" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="8,209.81,658.03,260.75,8.10;8,141.74,669.07,20.28,8.10">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>ICML</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
