<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,163.70,115.96,287.96,12.62;1,274.40,133.89,66.57,12.62">Automatic Coral Detection using Neural Networks</title>
				<funder ref="#_tBtpKc4">
					<orgName type="full">University of West Bohemia</orgName>
				</funder>
				<funder ref="#_es5SHaA">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,139.70,172.27,53.53,8.74"><forename type="first">Ivan</forename><surname>Gruber</surname></persName>
							<email>grubiv@ntis.zcu.cz</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Cybernetics 2</orgName>
								<address>
									<addrLine>Univerzitní 8</addrLine>
									<postCode>301 00</postCode>
									<settlement>Plzeň</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,321.65,172.27,57.73,8.74"><forename type="first">Jakub</forename><surname>Straka</surname></persName>
							<email>strakajk@students.zcu.cz</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Applied Sciences</orgName>
								<orgName type="institution">University of West Bohemia</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">New Technologies for the Information Society</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,163.70,115.96,287.96,12.62;1,274.40,133.89,66.57,12.62">Automatic Coral Detection using Neural Networks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">348CCF03060CC4297DE86E7BA0E1C970</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Object detection</term>
					<term>Semantic segmentation</term>
					<term>Coral localization</term>
					<term>Convolutional neural networks</term>
					<term>Machine learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents methods that were utilized in the Im-ageCLEFcoral 2020 challenge. The challenge contains two following subtasks: automatic coral reef annotation and localization, and automatic coral reef image pixel-wise parsing. In the first subtask, we tested two methods -SSD, and Mask R-CNN. In the second subtask, we tested only Mask R-CNN. Performance improvements were achieved by careful cleaning of the dataset and by both offline and online data augmentations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With changes in world climate in recent years, the danger of losing coral reefs and the ecosystem they support is increasing. Therefore, detailed monitoring of these ecosystems can be critical for their future. However, because of the complexity of coral images, they are very difficult for people to annotate, which opens possibilities for automatic detection.</p><p>Within the ImageCLEFcoral 2020 challenge <ref type="bibr" coords="1,339.41,507.42,10.52,8.74" target="#b4">[5,</ref><ref type="bibr" coords="1,351.59,507.42,7.01,8.74" target="#b0">1]</ref>, authors provide 440 images with ground-truth annotations. The challenge contains two subtasks. The first task is the classic detection task, whereas the success is considered each detection with Intersection over Union (IoU) equal or bigger than 0.5. The second task is semantic parsing of the corals in the input image.</p><p>For the first subtask, we tested two detection methods, one single-shot detector -SSD <ref type="bibr" coords="1,195.06,579.86,10.52,8.74" target="#b5">[6]</ref> and one two-shot detector -Mask R-CNN <ref type="bibr" coords="1,402.70,579.86,9.96,8.74" target="#b3">[4]</ref>. In the second subtask, we utilized Mask R-CNN, because it also provides semantic parsing information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>The data for this task originates from a growing, large-scale collection of images taken from coral reefs around the world as part of a coral reef monitoring project with the Marine Technology Research Unit at the University of Essex. The dataset contains 440 images in total with ground-truth annotations for 13 coral classes.</p><p>The provided dataset is challenging from many different perspectives. First, each image contains a large number of different corals, to be more specific 28 on average. Second, the large imbalance in the total number of instances among coral classes occurs. Third, there exists big intra-class variability in appearance and size, see Fig. <ref type="figure" coords="2,212.22,251.46,3.87,8.74" target="#fig_0">1</ref>. Third, the quality of images is highly inconsistent and some images are very blurry. Last but not least, during a hand-made inspection, we revealed that approximately 120 images are rotated by 180 degrees with respect to the groundtruth annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data preprocessing</head><p>In the first step, we address the rotation problem mentioned above and rotate all the images to the correct orientation. In the next step, the database was split into two subsets -train, and validation set. Due to the big imbalance between classes, during the splitting, we focused to preserve class distribution across both of the sets. Our goal was split to split the dataset in the way, that the train set contains approximately 85% of the images and validation set the rest. The final split with respect to the classes, after which the train set contains 371 images, and the validation set 69 images, can be found in Table <ref type="table" coords="3,380.62,154.86,3.87,8.74" target="#tab_0">1</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Data augmentation</head><p>To enrich and expand our train set, we utilize data augmentations. Primary, standard augmentations common for computer vision tasks were used, to be more specific, random horizontal flip, random vertical flip, random crop with resize, and Gaussian blur. Moreover, during the data analysis, we noticed, that two different light 'themes' are common -the blue one, and the green one. We simulate this effect by using a color filter, see Fig <ref type="figure" coords="4,352.98,154.86,3.87,8.74" target="#fig_1">2</ref>.</p><p>We tested both offline (before the training) and also online (during the training) augmentations, however, we reached better results using online augmentations during the experiments. A comparison of the influence of distinct online data augmentation on mean average precision (mAP) on our validation set can be found in Table <ref type="table" coords="4,215.30,214.85,3.87,8.74" target="#tab_1">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods and experimental setup</head><p>We tested two detection models -SSD <ref type="bibr" coords="4,308.07,406.42,9.96,8.74" target="#b5">[6]</ref>, and Mask R-CNN <ref type="bibr" coords="4,408.26,406.42,9.96,8.74" target="#b3">[4]</ref>. Both models were pretrained on Pascal VOC 2007 dataset <ref type="bibr" coords="4,344.75,418.37,9.96,8.74" target="#b2">[3]</ref>. For both models, we used standard implementation in Keras <ref type="bibr" coords="4,287.41,430.33,9.96,8.74" target="#b1">[2]</ref>. All the images were resized to the resolution 1024 × 1024 pixels during the Mask R-CNN training and to 512 × 512 pixels during the SSD training. Both tested methods were trained with a batch size of 1 during 200 epochs using SGD optimizer with an initial learning rate l = 0.0001 and step decay d = 0.1 after 100 epochs. For the purpose of challenge, we choose the model with best mAP on the validation set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>We evaluate both trained models on the validation set. Exemplary results on the validation set can be found in Fig. <ref type="figure" coords="4,284.25,572.21,3.87,8.74" target="#fig_2">3</ref>. Mask R-CNN detects much more bounding boxes than SSD, however, the majority of them are false positives. To be more specific, on the validation set, Mask R-CNN detects 2148 bounding boxes, but only 44.7% are true positives. On the other hand, SSD detects only 1029, but 71.3% are true positives.</p><p>Detailed comparison of average precision in the localization subtask for individual classes can be found in Table <ref type="table" coords="4,313.11,644.16,3.87,8.74" target="#tab_2">3</ref>. It should be noted that neither of the models were able to learn to detect five of the low frequent class. On the other hand, both models reach very good results for class Sponge barrel despite the fact its fifth least frequent class. We argue this occurs because of its big dissimilarity from other classes.</p><p>Mean average precision (mAP) on our validation set and the challenge test set can be found in Table <ref type="table" coords="5,245.74,620.25,3.87,8.74" target="#tab_3">4</ref>. In the localization subtask, SSD overcomes Mask R-CNN. Both models surprisingly over-performed on the test set by a large margin. Unfortunately, due to the test set access limitation, we can only guess, why this phenomenon happened. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we present working notes from ImageCLEFcoral 2020 challenge. We employed two detection methods, both of them based on neural networks, SSD, and Mask R-CNN. In the localization subtask, SSD reached better mAP by a large margin. Despite the fact reached results were mediocre, we believe that with more advanced state-of-the-art detection methods, it is possible to reach satisfactory results. Other future improvements we see in an expansion of the training set, or utilizing knowledge distillation approach.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,217.50,498.87,180.36,7.89;2,134.77,283.20,345.82,200.90"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Examples of different class instances.</figDesc><graphic coords="2,134.77,283.20,345.82,200.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,134.77,570.43,345.83,7.89;3,134.77,581.41,185.22,7.86;3,134.77,426.27,345.72,129.39"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Example of augmentation using a color filter. Original image (left) and image after augmentation using a color filter (right).</figDesc><graphic coords="3,134.77,426.27,345.72,129.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,134.77,495.34,345.83,7.89;5,134.77,506.33,150.18,7.86;5,152.06,115.84,311.26,364.74"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Exemplary results on the validation set. Ground truth (top row), Mask R-CNN (middle row) and SSD (bottom row).</figDesc><graphic coords="5,152.06,115.84,311.26,364.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,134.77,184.48,345.83,198.23"><head>Table 1 .</head><label>1</label><figDesc>The training and the validation set split. Total number of instances with percentage information in brackets.</figDesc><table coords="3,146.87,216.21,318.54,166.49"><row><cell>Class</cell><cell>Total number of instances</cell><cell>Instances in the train set (%)</cell><cell>Instances in the validation set (%)</cell></row><row><cell>Hard coral branching</cell><cell>1181</cell><cell>893 (76)</cell><cell>288 (24)</cell></row><row><cell>Hard coral submassive</cell><cell>198</cell><cell>172 (87)</cell><cell>26 (13)</cell></row><row><cell>Hard coral boulder</cell><cell>1642</cell><cell>1364 (83)</cell><cell>278 (17)</cell></row><row><cell>Hard coral encrusting</cell><cell>946</cell><cell>816 (86)</cell><cell>130 (14)</cell></row><row><cell>Hard coral table</cell><cell>21</cell><cell>18 (86)</cell><cell>3 (14)</cell></row><row><cell>Hard coral foliose</cell><cell>177</cell><cell>153 (86)</cell><cell>24 (14)</cell></row><row><cell>Hard coral mushroom</cell><cell>233</cell><cell>179 (80)</cell><cell>44 (20)</cell></row><row><cell>Soft coral</cell><cell>5663</cell><cell>4459 (79)</cell><cell>1204 (21)</cell></row><row><cell>Soft coral gorgonian</cell><cell>90</cell><cell>79 (88)</cell><cell>11 (12)</cell></row><row><cell>Sponge</cell><cell>1691</cell><cell>1514 (90)</cell><cell>177 (10)</cell></row><row><cell>Sponge barrel</cell><cell>139</cell><cell>107 (77)</cell><cell>32 (23)</cell></row><row><cell>Fire coral millepora</cell><cell>19</cell><cell>16 (84)</cell><cell>3 (16)</cell></row><row><cell>Algae macro or leaves</cell><cell>92</cell><cell>78 (85)</cell><cell>14 (15)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,134.77,244.85,345.83,85.55"><head>Table 2 .</head><label>2</label><figDesc>The comparison of augmentations for both models on our validation set (localization task).</figDesc><table coords="4,158.91,277.08,294.46,53.32"><row><cell>Method</cell><cell cols="2">Mask R-CNN mAP SSD mAP</cell></row><row><cell>W/O augmentations</cell><cell>6.94</cell><cell>4.44</cell></row><row><cell>Flip, Color filter</cell><cell>8.12</cell><cell>-</cell></row><row><cell>Flip, Color filter, Blur</cell><cell>9.84</cell><cell>-</cell></row><row><cell>Flip, Color filter, Blur, Random crop</cell><cell>10.18</cell><cell>14.94</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,134.77,116.41,345.83,198.87"><head>Table 3 .</head><label>3</label><figDesc>Comparison of average precision (AP) for individual classes on the validation set in the localization subtask.</figDesc><table coords="6,215.45,146.40,181.39,168.89"><row><cell>Class</cell><cell cols="2">Mask R-CNN SSD</cell></row><row><cell>Hard coral branching</cell><cell>19.56</cell><cell>23.13</cell></row><row><cell>Hard coral submassive</cell><cell>0.00</cell><cell>0.00</cell></row><row><cell>Hard coral boulder</cell><cell>25.76</cell><cell>33.29</cell></row><row><cell>Hard coral encrusting</cell><cell>2.35</cell><cell>5.48</cell></row><row><cell>Hard coral tablet</cell><cell>0.00</cell><cell>0.00</cell></row><row><cell>Hard coral foliose</cell><cell>8.33</cell><cell>14.24</cell></row><row><cell>Hard coral mushroom</cell><cell>5.91</cell><cell>15.91</cell></row><row><cell>Soft coral</cell><cell>44.97</cell><cell>34.41</cell></row><row><cell>Soft coral gorgonian</cell><cell>0.00</cell><cell>0.00</cell></row><row><cell>Sponge</cell><cell>3.52</cell><cell>5.55</cell></row><row><cell>Sponge barrel</cell><cell>21.98</cell><cell>62.17</cell></row><row><cell>Fire coral millepora</cell><cell>0.00</cell><cell>0.00</cell></row><row><cell>Algae macro or leaves</cell><cell>0.00</cell><cell>0.00</cell></row><row><cell>mAP</cell><cell>10.18</cell><cell>14.94</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,134.77,328.63,345.82,71.95"><head>Table 4 .</head><label>4</label><figDesc>Results comparison for both models on our validation set and the challenge test set.</figDesc><table coords="6,186.74,358.62,238.80,41.96"><row><cell>Method</cell><cell>Task</cell><cell cols="2">Validation mAP Test mAP</cell></row><row><cell cols="2">Mask R-CNN localization</cell><cell>10.18</cell><cell>24.3</cell></row><row><cell cols="2">Mask R-CNN segmentation</cell><cell>10.29</cell><cell>30.4</cell></row><row><cell>SSD</cell><cell>localozation</cell><cell>14.94</cell><cell>49.0</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement: The work has been supported by the grant of the <rs type="funder">University of West Bohemia</rs>, project No. <rs type="grantNumber">SGS-2019-027</rs>. Moreover, access to computing and storage facilities owned by parties and projects contributing to the <rs type="institution">National Grid Infrastructure MetaCentrum</rs> provided under the programme "<rs type="projectName">Projects of Large Research, Development, and Innovations Infrastructures</rs>" (<rs type="grantNumber">CESNET LM2015042</rs>), is greatly appreciated.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_tBtpKc4">
					<idno type="grant-number">SGS-2019-027</idno>
					<orgName type="project" subtype="full">Projects of Large Research, Development, and Innovations Infrastructures</orgName>
				</org>
				<org type="funding" xml:id="_es5SHaA">
					<idno type="grant-number">CESNET LM2015042</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,138.35,645.84,342.24,7.86;6,146.91,656.80,333.68,7.86;7,146.91,119.67,333.68,7.86;7,146.91,130.63,88.33,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,201.05,656.80,279.54,7.86;7,146.91,119.67,69.56,7.86">Overview of the ImageCLEFcoral 2020 task: Automated coral reef image annotation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">G</forename><surname>Clift</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>García Seco De Herrera</surname></persName>
		</author>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="7,239.90,119.67,106.60,7.86">CLEF2020 Working Notes</title>
		<title level="s" coord="7,354.85,119.67,125.75,7.86;7,146.91,130.63,21.70,7.86">CEUR Workshop Proceedings, CEUR</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,141.59,216.43,8.11" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Chollet</surname></persName>
		</author>
		<ptr target="https://keras.io" />
		<title level="m" coord="7,222.05,141.59,21.39,7.86">Keras</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,152.55,342.25,7.86;7,146.91,163.51,333.68,7.86;7,146.91,174.47,244.13,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,441.72,152.55,38.88,7.86;7,146.91,163.51,149.21,7.86">The PAS-CAL Visual Object Classes Challenge</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<ptr target="http://www.pascal-network.org/challenges/VOC/voc2007/workshop/index.html" />
	</analytic>
	<monogr>
		<title level="m" coord="7,324.09,163.51,71.14,7.86">VOC2007) Results</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,185.43,342.24,7.86;7,146.91,196.39,293.35,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,337.77,185.43,44.87,7.86">Mask r-cnn</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Dollár</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,404.94,185.43,75.65,7.86;7,146.91,196.39,200.57,7.86">Proceedings of the IEEE international conference on computer vision</title>
		<meeting>the IEEE international conference on computer vision</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2961" to="2969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,207.34,342.25,7.86;7,146.91,218.30,333.68,7.86;7,146.91,229.26,333.67,7.86;7,146.91,240.22,333.68,7.86;7,146.91,251.18,333.67,7.86;7,146.91,262.14,333.68,7.86;7,146.91,273.10,333.67,7.86;7,146.91,284.06,333.68,7.86;7,146.91,295.02,333.68,7.86;7,146.91,305.98,333.68,7.86;7,146.91,316.93,34.31,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,292.74,262.14,187.85,7.86;7,146.91,273.10,258.96,7.86">Overview of the ImageCLEF 2020: Multimedia retrieval in lifelogging, medical, nature, and internet applications</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Péteri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">D</forename><surname>Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">T</forename><surname>Ninh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Fichou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Berari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Brie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dogariu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">D</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,426.43,273.10,54.16,7.86;7,146.91,284.06,333.68,7.86;7,146.91,295.02,256.57,7.86">Proceedings of the 11th International Conference of the CLEF Association (CLEF 2020)</title>
		<title level="s" coord="7,456.14,295.02,24.45,7.86;7,146.91,305.98,140.67,7.86">LNCS Lecture Notes in Computer Science</title>
		<meeting>the 11th International Conference of the CLEF Association (CLEF 2020)<address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">September 22-25 2020</date>
			<biblScope unit="volume">12260</biblScope>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="7,138.35,327.89,342.24,7.86;7,146.91,338.85,333.68,7.86;7,146.91,349.81,91.18,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,464.16,327.89,16.43,7.86;7,146.91,338.85,121.35,7.86">Ssd: Single shot multibox detector</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Anguelov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Erhan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Reed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">Y</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C</forename><surname>Berg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,291.91,338.85,167.82,7.86">European conference on computer vision</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="21" to="37" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
