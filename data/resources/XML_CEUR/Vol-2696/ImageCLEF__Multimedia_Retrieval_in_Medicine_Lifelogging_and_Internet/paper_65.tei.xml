<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,172.99,115.96,269.38,12.62;1,201.64,133.89,212.06,12.62;1,214.63,151.82,186.10,12.62">Overview of ImageCLEF Lifelog 2020: Lifelog Moment Retrieval and Sport Performance Lifelog</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,142.37,189.49,57.01,8.74"><forename type="first">Van-Tu</forename><surname>Ninh</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Dublin City University</orgName>
								<address>
									<settlement>Dublin</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,209.94,189.49,57.98,8.74"><forename type="first">Tu-Khiem</forename><surname>Le</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Dublin City University</orgName>
								<address>
									<settlement>Dublin</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,278.47,189.49,51.62,8.74"><forename type="first">Liting</forename><surname>Zhou</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Dublin City University</orgName>
								<address>
									<settlement>Dublin</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,340.64,189.49,46.86,8.74"><forename type="first">Luca</forename><surname>Piras</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Pluribus One &amp; University of Cagliari</orgName>
								<address>
									<settlement>Cagliari</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,398.05,189.49,67.69,8.74"><forename type="first">Michael</forename><surname>Riegler</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Simula Metropolitan Center for Digital Engineering</orgName>
								<address>
									<settlement>Oslo</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,153.43,201.45,60.82,8.74"><forename type="first">PÃ¥l</forename><surname>Halvorsen</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Simula Metropolitan Center for Digital Engineering</orgName>
								<address>
									<settlement>Oslo</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,224.81,201.45,55.55,8.74"><forename type="first">Mathias</forename><surname>Lux</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">ITEC</orgName>
								<orgName type="institution">Klagenfurt University</orgName>
								<address>
									<settlement>Klagenfurt</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,290.91,201.45,71.73,8.74"><forename type="first">Minh-Triet</forename><surname>Tran</surname></persName>
							<affiliation key="aff5">
								<orgName type="department">University of Science</orgName>
								<orgName type="institution">VNU-HCM</orgName>
								<address>
									<addrLine>Ho Chi</addrLine>
									<settlement>Minh City</settlement>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,373.20,201.45,62.12,8.74"><forename type="first">Cathal</forename><surname>Gurrin</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Dublin City University</orgName>
								<address>
									<settlement>Dublin</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,274.10,213.40,83.10,8.74"><forename type="first">Tien</forename><surname>Dang-Nguyen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Bergen</orgName>
								<address>
									<settlement>Bergen</settlement>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,172.99,115.96,269.38,12.62;1,201.64,133.89,212.06,12.62;1,214.63,151.82,186.10,12.62">Overview of ImageCLEF Lifelog 2020: Lifelog Moment Retrieval and Sport Performance Lifelog</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">48874A8CC6964746604D6A8BE03E4EB5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the fourth edition of Lifelog challenges in ImageCLEF 2020. In this edition, the Lifelog challenges consist of two tasks which are Lifelog Moments Retrieval (LMRT) and Sport Performance Lifelog (SPLL). While the Lifelog Moments Retrieval challenge follows the same format of the previous edition, its data is a larger multimodal dataset based on the merger of three previous NT-CIR Lifelog datasets, which contain approximately 191,439 images with corresponding visual concepts and other related metadata. The Sport Performance Lifelog, which is a brand new challenge, is composed of three subtasks that focus on predicting the expected performance of athletes who trained for a sport event. In summary, the ImageCLEF Lifelog 2020 receives 50 runs from six teams in total with competitive results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Due to the widely use of wearable devices, digital sensors, and smart phones which capture photos, biometric signals, and location information passively, a huge amount of daily-life data is recorded by many people everyday. As a result, there is an ever increasing reserach effort into developing methodologies for exploiting the potential of this data. Such lifelog data has been used for many retrieval and analytics challenges since the inaugoral NTCIR-12 -Lifelog task <ref type="bibr" coords="1,470.07,567.82,10.52,8.74" target="#b5">[6]</ref> in 2016.</p><p>There have been many reserch tasks addressed by these challenges, such as lifelog retrieval, data segmentation, data enhancement/annotation and interactive retrieval. Specifically in the ImageCLEF lifelog challenge, we note a number of different tasks, such as the Solve My Life Puzzle task in 2019 <ref type="bibr" coords="2,427.72,118.99,9.96,8.74" target="#b4">[5]</ref>, Activity of Daily Living Understanding task in 2018 <ref type="bibr" coords="2,330.28,130.95,9.96,8.74" target="#b3">[4]</ref>, or Lifelog Summarization task in 2017 <ref type="bibr" coords="2,170.95,142.90,9.96,8.74" target="#b2">[3]</ref>. Therefore, in the fourth edition of ImageCLEFlifelog tasks hosted in ImageCLEF 2020 <ref type="bibr" coords="2,227.10,154.86,14.61,8.74" target="#b11">[12]</ref>, the organizers both propose a brand-new task which monitors the wellbeing and predicts the expected performance of the athletes training for a sporting event, as well as continuing to maintain the core Lifelog Retrieval Moments task with enriched dataset in terms of visual concepts, annotations, and scale.</p><p>Details of the two challenges and the data employed are provided in section 2. In section 3, submissions and results are presented and discussed. In final section 4, the paper is concluded with the discussion of final remarks and future work.</p><p>2 Overview of the Task</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Motivation and Objectives</head><p>Personal lifelog data is continually increasing in volume due to the popularity of personal wearable/portable devices for health monitoring and life recording such as smartphones, smart watches, fitness bands, video cameras, biometric data devices and GPS or location devices. As a huge amount of data is created daily, there is a need for a systems that can analyse the data, index, categorize, summarize to gain deep insights from the data and support a user in some positive way.</p><p>Although many related workshops of lifelogging were held successfully for years such as three editions of NTCIR, annual Lifelog Search Challenge (LSC), and ImageCLEFlifelog 2019, we still aim to bring the attention of lifelogging to not only research groups but also to diverse audiences. Nevertheless, we continue to maintain the core task to encourage research groups to propose creative retrieval approaches to lifelog data, as well as nominating a new task to introduce a new challenge to the research community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Challenge Description</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lifelog Moment Retrieval Task (LMRT)</head><p>In this task, the participants were required to retrieve a number of specific moments in a lifelogger's life. Moments are defined as "semantic events, or activities that happened throughout the day" <ref type="bibr" coords="2,295.21,572.43,9.96,8.74" target="#b4">[5]</ref>. For example, a participant would have been required to find and return relevant moments for the query "Find the moment(s) when the lifelogger was having an ice cream on the beach". In this edition, particular attention was to be paid to the diversification of the selected moments with respect to the target scenario. The ground truth for this subtask was created using a manual annotation process and aimed towards compete relevance judgements. Figure <ref type="figure" coords="2,251.83,644.16,4.98,8.74" target="#fig_0">1</ref> illustrates some examples of the moments when the lifelogger was shopping in a toy shop. In addition, listings 1 and 2 show all the </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sport Performance Lifelog (SPLL)</head><p>Given a dataset of 16 people who train for a 5km run for the sport event (e.g., daily sleeping patterns, daily heart rate, sport activities, and image logs of all food consumed during the training period), participants are required to predict the expected performance (e.g., estimated finishing time, average heart rate and calories consumption) of the trained athlete.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Datasets</head><p>LMRT Task: The data is a combination of three previously released datasets of NTCIR-Lifelog Tasks: NTCIR-12 <ref type="bibr" coords="5,298.87,493.97,9.96,8.74" target="#b5">[6]</ref>, NTCIR-13 <ref type="bibr" coords="5,366.96,493.97,9.96,8.74" target="#b6">[7]</ref>, and NTCIR-14 <ref type="bibr" coords="5,455.47,493.97,9.96,8.74" target="#b7">[8]</ref>. It is a large multimodal lifelog data of 114 days from one lifelogger whose dates range from 2015 to 2018. It contains five main data types which are multimedia content, biometrics data, location and GPS, human activity data, and visual concepts and annotations of non-text multimedia content. Details of each type of data are as follows:</p><p>-Multimedia Content: Most of this data are non-annotated egocentric photos captured passively by two wearable digital cameras: OMG Autographer and Narrative Clip<ref type="foot" coords="5,232.13,597.78,3.97,6.12" target="#foot_0">1</ref> . The lifelogger wore the device for 16-18 hours per day to capture a complete visual trace of daily life with about 2-3 photos captured per minute during waking hours. The photo data was manually redacted to remove identifiable content and faces <ref type="bibr" coords="5,315.89,635.22,9.96,8.74" target="#b8">[9]</ref>.  <ref type="bibr" coords="6,221.98,424.38,15.50,8.74" target="#b24">[25]</ref> as in the latest edition. For visual object detection, we employed Mask R-CNN <ref type="bibr" coords="6,260.61,436.34,15.50,8.74" target="#b9">[10]</ref> pre-trained on 80 items of MSCOCO dataset <ref type="bibr" coords="6,151.70,448.29,15.50,8.74" target="#b14">[15]</ref> which is used to provide the category of visual objects in the image as well as its bounding boxes.</p><p>Format of the metadata. The metadata was stored in a csv files, which was called the metadata table. The structure and meaning of each field in the table are described in Table <ref type="table" coords="6,260.73,504.81,3.87,8.74" target="#tab_2">3</ref>. Additionally, visual categories and concepts descriptors are also provided in the visual concepts table. The format of it could be found in Table <ref type="table" coords="6,215.30,528.72,3.87,8.74" target="#tab_3">4</ref>.</p><p>SPLL Task: The data was gathered using three different approaches: wearable devices (Fitbtit Fitness Tracker (Fitbit Versa), Google Forms, and PMSYS. Biometric data of an individual (training athlete) is recorded using Fitbit Fitness Tracker, including 13 different fields of information such as daily heart rate, calories, daily sleeping patterns, sport activities, etc. Google Forms were used to collect information of meals, drinks, medications, etc. At the same time, information of subjective wellness, injuries, and training load was recorded by PMSYS system. In addition, image-logs of food consumed during the training period from at least 2 participants and self reported data like mode, stress, fatigue, readiness to train and other measurements also used for professional soccer teams <ref type="bibr" coords="7,462.33,118.99,14.61,8.74" target="#b22">[23]</ref>. The data was approved by the Norwegian Center for Research Data with proper copyright and ethical approval to release. Statistics of the ImageCLEFlifelog 2020 SPLL data is shown in table <ref type="table" coords="7,285.56,154.86,3.87,8.74" target="#tab_1">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Performance Measures</head><p>LMRT: Classic metrics are employed to assess the performance of this LMRT task. These metrics include:</p><p>-Cluster Recall at X (CR@X) -a metric that assesses how many different clusters from the ground truth are represented among the top X results; -Precision at X (P@X) -measures the number of relevant photos among the top X results; -F1-measure at X (F1@X) -the harmonic mean of the previous two.</p><p>Various cut off points are considered, e.g., X=5, 10, 20, 30, 40, 50. Official ranking metrics are the F1-measure@10, which gives equal importance to diversity (via CR@10) and relevance (via P@10). In particular, the final score to rank submissions of participants is the average F1-measure@10 of ten queries, which provides information of general performance of each interactive system for all 10 queries.</p><p>Participants were allowed to undertake the sub-tasks in an interactive or automatic manner. For interactive submissions, a maximum of five minutes of search time was allowed per topic. In particular, methods that allowed interaction with real users (via Relevance Feedback (RF), for example), i.e., beside of the best performance, the way of interaction (like number of iterations using RF), or innovation level of the method (for example, new way to interact with real users) were encouraged.</p><p>SPLL: For this task, we employ two evaluation metrics to rank the submissions of participants. The primary score is to check how accurately the participants can predict whether it was an improvement or a deterioration after the training process by comparing the sign of the actual change value to the predicted one. The secondary score is the absolute difference between the actual change and the predicted one. The primary score is ranked in descending order, and if there is a draw in the primary score, the secondary score is used to re-rank the teams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Ground Truth Format</head><p>LMRT Task. The development ground truth for the LMRT task was provided in two individual txt files: one file for the cluster ground truth and one file for the relevant image ground truth.</p><p>In the cluster ground-truth file, each line corresponded to a cluster where the first value was the topic id, followed by the cluster id number. Lines were separated by an end-of-line character (carriage return). An example is presented below:</p><formula xml:id="formula_0" coords="10,140.99,174.87,26.76,68.69">-1, 1 -1, 2 -... -2, 1 -2, 2 -...</formula><p>In the relevant ground-truth file, the first value on each line was the topic id, followed by a unique photo id which is image name without the extension, and then followed by the cluster id number (that corresponded to the values in the cluster ground-truth file) separated by comma. Each line corresponded to the ground truth of one image and lines were separated by an end-of-line character (carriage return). An example is presented below: </p><formula xml:id="formula_1" coords="10,140.99,336.64,18.46,8.77">-1,</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SPLL Task.</head><p>The ground truth was provided in one txt file. For each line in this file, the first value was the id of the sub-task which is 1, 2 or 3 (since the SPLL task is split into three sub-tasks), followed by the id of individual (p01, p02, ..., p16), followed by the actual change in the status of the individual after the training period. Although the three sub-tasks has different requirements, their output format is the same, which is a number indicating the change before and after training with preceding '+' sign if the change is an increase, or '-' sign if the change is a decrease. If there is no change after the training process, a 0 value without a preceding sign is also allowed. Values in each line were separated by comma. Lines were separated by and end-of-line character (carriage return). An example is shown below:</p><p>-1, p01, +8 -1, p10, +86 -... Table <ref type="table" coords="11,199.46,115.91,4.13,7.89">5</ref>. Official results of the ImageCLEFlifelog 2020 LMRT task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Team</head><p>Run P@10 CR@10 F1@10 Team Run P@10 CR@10 F1@10 3 Evaluation Results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Participating Groups and Runs Submitted</head><p>This year, we obtained 50 valid submissions in both two tasks of ImageCLE-Flifelog tasks from 6 teams, which is not as high as in previous year. However, the results of these submissions show a significant improvement in the final scores compared to ImageCLEFlifelog 2019. In particular, there were 38 submissions in LMRT with 6 teams participating in the task, while only one non-organizer team submitted 10 runs in SPLL task. The submitted runs and their results are summarised in Tables <ref type="table" coords="11,232.65,568.39,4.98,8.74">5</ref> and<ref type="table" coords="11,260.32,568.39,3.87,8.74" target="#tab_6">6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>In this section we provide a short description of all submitted approaches followed by the official result of the task. The Organizer team continue to provided a baseline approach for the LMRT task with a web-based interactive search engine, which is an improved version of LIFER 2.0 system <ref type="bibr" coords="12,228.35,343.06,15.50,8.74" target="#b17">[18]</ref> which was used at ImageCLEFlifelog 2019. The interactive elements of this system comprise three features: free-text querying and filterinf, visual similarity image search, and elastic sequencing to view nearby moments. The system, which focuses on experimenting the efficiency of free-text query features, is an early version of LifeSeeker 2.0 interactive search engine <ref type="bibr" coords="12,134.77,402.84,14.61,8.74" target="#b13">[14]</ref>. For the query processing procedure, the authors use natural language processing to parse the query into meaningful terms and employ Bag-of-Words to retrieve and rank relevant documents. The dictionary in Bag-of-Words is split into three dictionaries for filtering by using terms matching: time, location, and visual concepts. The authors extract more detailed visual concepts inferred from deep neural networks pre-trained on Visual Genome dataset <ref type="bibr" coords="12,410.92,462.61,15.50,8.74" target="#b12">[13]</ref> which were shown to be extremely useful for the retrieval process. For the SPLL task, the organizer team provided baseline approaches for all three sub-tasks, which used the exercise data from Fitbit Tracker, self-reporting, and food-images only. The authors propose a naive solution which computes the difference between consecutive rows of data from exercise activities and self-reporting including distance, exercise duration, calories, and weight; then categorises them into positive and negative groups based on sign of the value ('+' or '-') and calculate the average of the two groups. Finally, they sum the two average to obtain the results.</p><p>In addition, they also try to build a Linear Regression Model to predict the pace change and a Convolutional Neural Network to detect the type of food for manual calories inference.</p><p>The REGIM-Lab approaches the LMRT Task with the same strategies as their work in ImageCLEFlifelog 2019 <ref type="bibr" coords="12,304.34,620.25,9.96,8.74" target="#b0">[1]</ref>, which used the ground truth of the development dataset from both LMRT 2019 and LMRT 2020 to automatically categorise images into categories for deep neural network fine-tuning with Mo-bileNet v2 and DenseNet and visual concepts clustering. However, the difference is that they use Elastic Search and Kibana Query Language (KBL) to perform retrieval on image concepts and metadata instead Apache Cassandra and Cassandra Query Language (CQL). Moreover, they attempt to enrich more visual concepts using YOLO v3 <ref type="bibr" coords="13,250.51,154.86,15.50,8.74" target="#b18">[19]</ref> trained on OpenImage dataset. They also treat the textual queries with three-word embedding models built from scratch which are Word2vec, FastText, and Glove HCMUS focused on the LMRT task only this year. Their retrieval system has three components which are query by caption, query by similar image, and query by place and time from the metadata. For query by caption, they encoded images using Faster R-CNN <ref type="bibr" coords="13,263.14,230.29,15.50,8.74" target="#b19">[20]</ref> to extract object-level features, then applied self-attention to learn interaction between them. For query sentence, they used RoBerta model <ref type="bibr" coords="13,202.89,254.20,15.50,8.74" target="#b15">[16]</ref> to encode sentences. Finally, two feed forward networks were deployed to map image and text features to the common space correspondingly. Therefore, when a sentence is given, their model ranked all images based on cosine distance between the encoded images and the encoded query sentence to find the most relevant images to the description of the sentence. For query by similar image, the same strategy was applied with ResNet152 image encoder <ref type="bibr" coords="13,134.77,325.93,15.50,8.74" target="#b10">[11]</ref> instead of Faster R-CNN. For query by place and time from metadata, they simply find all moments based on the given semantic locations and view the images which are before and after a specific moments. DCU-DDTeam interactive search engine is the improved version of their MysceÃ¡l system in LSC'20 <ref type="bibr" coords="13,255.17,377.45,15.50,8.74" target="#b23">[24]</ref> and follows the same pipeline. The visual concepts of each image are the combination of the given metadata and outputs from DeepLabv3+ <ref type="bibr" coords="13,194.11,401.36,10.52,8.74" target="#b1">[2]</ref> and the enriched metadata extracted from Microsoft Computer Vision API. These annotations, along with other information such as locations and time, were then indexed in the Elastic Search. The input query is analyzed to extract the main information and enlarged by their expansion mechanism. They are then combined with the indexed database to find matching images which are then ordered by their ranking function. In this version, they introduced three changes in the previous system including visual similarity, the user interface, and the summary panel. The visual similarities between images were measured by using cosine distance between visual features composed of SIFT <ref type="bibr" coords="13,134.77,508.96,15.50,8.74" target="#b16">[17]</ref> and VGG16 features. For the user interface, the authors remove the triad of searching bars as in the original version and reorganised the interface to explore cluster events more efficiently. The summary panel consists of the "Word List" panel which is the area on the screen showing the results of their query expansion with adjustable scores allowing the user to emphasize the concepts that they need to retrieve.</p><p>The BIDAL team is the only non-organizer team participating in both the LMRT and SPLL tasks. For the LMRT task, the authors generated clusters by employing a scene recognition model trained on the Google Fixmatch method <ref type="bibr" coords="13,134.77,620.25,14.61,8.74" target="#b21">[22]</ref>. They then used an attention mechanism to match the input query with the correct samples, which were then utilized to find other relevant moments. For the SPLL task, they summarized information from various interval attributes, removed several unnecessary attributes, and generated some new attributes. Then, they trained several typical time-series neural network structure including Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) using the generated attributes or a set of attributes, or some pre-defined seeding attributes.</p><p>The UA.PT Bioinformatics team continued to employ the approaches from last year challenge <ref type="bibr" coords="14,218.04,179.01,15.50,8.74" target="#b20">[21]</ref> to test the performance of their automatic lifelog search engine in the attempt to enrich visual concepts and labels by utilising many different object detection networks including Faster R-CNN and Yolov3 <ref type="bibr" coords="14,445.20,202.92,15.50,8.74" target="#b18">[19]</ref> pretrained on COCO dataset <ref type="bibr" coords="14,250.13,214.88,14.61,8.74" target="#b14">[15]</ref>. The image retrieval procedure was then done on a text-based vector space by computing similarity score between the text labels extracted from the images and and the visual concepts. Finally, a threshold was set to choose the results for each topic. As the results prove that this automatic approach did not work, the authors developed a web-based interactive search engine with a timestamp-clustering visualization to select the moments instead of defining a threshold to choose the results automatically. The algorithms for searching relevant moments are mostly the same as automatic approach except for three new features which are: narrowing searching items by text matching between manually analysed query and the indexed database containing concepts of each image.</p><p>The official results are summarised in Tables <ref type="table" coords="14,341.25,346.62,4.98,8.74">5</ref> and<ref type="table" coords="14,367.01,346.62,3.87,8.74" target="#tab_6">6</ref>. There are six teams participating in the LMRT task with the highest F1@10 score of 0.81 was achieved by HCMUS (Table <ref type="table" coords="14,220.15,370.53,3.87,8.74">5</ref>). Most of the teams tried to enrich the visual concepts by deploying different CNNs for objects and places detection, then performing text analysis on the query and text matching. Some additional features were also added in most interactive systems such as searching for visually similar images, terms weighting for results re-ranking, context understanding before performing search, etc. The highest scoring approach by the HCMUS team, considered visual vector features extracted from CNNs when making the comparison between feature vectors to find relative moments.</p><p>In the SPLL task, only one non-organizer team participated and they managed to achieve good scores. For the prediction of performance change, their approach gained 0.82 and 128.0 in terms of prediction accuracy and L1 distance between the prediction value and actual change respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussions and Conclusions</head><p>In the ImageCLEFlifelog 2020, most of the submitted results managed to gain high scores in both tasks. Although the set of topics for LMRT task is different from previous edition, participants managed to search for the relative moments on a large-scale dataset while still achieving higher scores than the results in previous edition. This proves that the proposed features and query mechanisms actually enhance the performance of their retrieval systems. Most of the teams enrich semantic visual concepts using many different CNNs pretrained on different datasets such as COCO, OpenImage, and Visual Genome before indexing and querying; retrieve relative images based on text matching and text retrieval algorithms; perform visual similar image search. We also note many interesting approaches from teams to enhance the affordance and interaction of the retrieval systems, including integrating filter mechanism into free-text search, considering adding visual vector features into the final encoded vector, clustering images into events, etc.</p><p>Regarding the number of teams and submitted runs, only 6 teams participated in the LMRT task, including an organizer team, which produced 50 submissions in total. Each team was allowed to submit up to 10 runs. For the LMRT task, among five teams which participated in ImageCLEFlifelog 2019 (including the organizer team), four teams managed to obtain better results with the highest F1-score up to 0.81. The mean (SD) increase of final F1-score from these five teams is 0.25 (0.18). The new team from Dublin City University also managed to achieve the 4th rank with a 0.48 F1-score. For the SPLL task, as the task is new, only one team from The Big Data Analytics Laboratory submitted 10 runs. Their best submission achieves an accuracy of performance change and the absolute difference between the prediction and actual change are 0.82 and 128 respectively, which is a good result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Acknowledgement</head><p>This publication has emanated from research supported in party by research grants from Irish Research Council (IRC) under Grant Number GOIPG/2016/741 and Science Foundation Ireland under grant numbers SFI/12/RC/2289 and SFI/13/RC/2106.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,134.77,298.08,345.82,7.89;5,134.77,309.06,237.01,7.86;5,142.26,202.90,107.20,80.40"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Examples from the results of the query: 'Show all moment I was looking at items in a toyshop where various toys are being examined.'</figDesc><graphic coords="5,142.26,202.90,107.20,80.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,140.99,115.91,339.60,317.21"><head>Table 1 .</head><label>1</label><figDesc>Statistics of ImageCLEFlifelog 2020 LMRT Data</figDesc><table coords="6,140.99,136.29,339.60,296.83"><row><cell>Characters</cell><cell>Size</cell></row><row><cell>Number of Lifeloggers</cell><cell>1</cell></row><row><cell>Number of Days</cell><cell>114 days</cell></row><row><cell>Size of the Collection</cell><cell>37.1 GB</cell></row><row><cell>Number of Images</cell><cell>191,439 images</cell></row><row><cell>Number of Locations</cell><cell>166 semantic locations</cell></row><row><cell>Number of LMRT dev queries</cell><cell>10 queries</cell></row><row><cell>Number of LMRT test queries</cell><cell>10 queries</cell></row><row><cell cols="2">-Biometrics Data: This data contains heart rate, calories, and movement</cell></row><row><cell cols="2">speed using a Fitbit fitness tracker 2 . The lifelogger wore the Fitbit wearable</cell></row><row><cell cols="2">device everyday for 24 hours so as to record continuous biometrics data.</cell></row><row><cell cols="2">-Location and GPS: 166 semantic locations as well as GPS data (with and</cell></row><row><cell cols="2">without location name) are recorded using both Moves app and smartphones.</cell></row><row><cell cols="2">The GPS plays an important role to infer the time zone of lifelogger's current</cell></row><row><cell cols="2">location to convert the time of different wearable devices into one standard</cell></row><row><cell>timestamp.</cell><cell></cell></row><row><cell cols="2">-Human Activity Data: This data is recorded by the Moves app which</cell></row><row><cell cols="2">also provide some annotated semantic locations. It consists of four types of</cell></row><row><cell cols="2">activities which are walking, running, transport, and airplane.</cell></row><row><cell cols="2">-Visual Concepts and Annotations: The passively auto-captured images</cell></row><row><cell cols="2">are passed through two deep neural networks to extract visual concepts</cell></row><row><cell cols="2">about scenes and visual objects. For scene identification, we still employ</cell></row><row><cell>the PlacesCNN</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,140.93,183.82,333.22,285.32"><head>Table 2 .</head><label>2</label><figDesc>Statistics of ImageCLEFlifelog 2020 SPLL Data</figDesc><table coords="7,140.93,204.19,333.22,264.95"><row><cell>Catgories</cell><cell cols="2">Approach Rate of entries</cell><cell>Number of entries</cell></row><row><cell>Calories</cell><cell>Fitbit</cell><cell>Per minute</cell><cell>3377529</cell></row><row><cell>Steps</cell><cell>Fitbit</cell><cell>Per minute</cell><cell>1534705</cell></row><row><cell>Distance</cell><cell>Fitbit</cell><cell>Per minute</cell><cell>1534705</cell></row><row><cell>Sleep</cell><cell>Fitbit</cell><cell>When it happens</cell><cell>2064</cell></row><row><cell></cell><cell></cell><cell>(usually daily)</cell><cell></cell></row><row><cell>Lightly active minutes</cell><cell>Fitbit</cell><cell>Per day</cell><cell>2244</cell></row><row><cell>Moderately active min-</cell><cell>Fitbit</cell><cell>Per day</cell><cell>2396</cell></row><row><cell>utes</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Very active minutes</cell><cell>Fitbit</cell><cell>Per day</cell><cell>2396</cell></row><row><cell>Sedentary minutes</cell><cell>Fitbit</cell><cell>Perday</cell><cell>2396</cell></row><row><cell>Heart rate</cell><cell>Fitbit</cell><cell>Per 5 seconds</cell><cell>20991392</cell></row><row><cell cols="2">Time in heart rate zones Fitbit</cell><cell>Per day</cell><cell>2178</cell></row><row><cell>Resting heart rate</cell><cell>Fitbit</cell><cell>Per day</cell><cell>1803</cell></row><row><cell>Exercise</cell><cell>Fitbit</cell><cell>When it happens</cell><cell>2440</cell></row><row><cell></cell><cell></cell><cell>100 entries per</cell><cell></cell></row><row><cell></cell><cell></cell><cell>file</cell><cell></cell></row><row><cell>Sleep score</cell><cell>Fibtit</cell><cell>When it happens</cell><cell>1836</cell></row><row><cell></cell><cell></cell><cell>(usually daily)</cell><cell></cell></row><row><cell>Google Forms reporting</cell><cell>Google</cell><cell>Per day</cell><cell>1569</cell></row><row><cell></cell><cell>Form</cell><cell></cell><cell></cell></row><row><cell>Wellness</cell><cell>PMSYS</cell><cell>Per day</cell><cell>1747</cell></row><row><cell>Injury</cell><cell>PMSYS</cell><cell>Per day</cell><cell>225</cell></row><row><cell>SRPE</cell><cell>PMSYS</cell><cell>Per day</cell><cell>783</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,140.74,115.91,327.36,402.48"><head>Table 3 .</head><label>3</label><figDesc>Structure of metadata table.</figDesc><table coords="8,140.74,138.38,327.36,380.01"><row><cell>Field name</cell><cell>Meaning</cell><cell>Example</cell></row><row><cell>minute ID</cell><cell>Identity field for every minute</cell><cell>20180503 0000</cell></row><row><cell>utc time</cell><cell>UTC Time with format:</cell><cell>UTC 2018-05-03 00:00</cell></row><row><cell></cell><cell>UTC YYYY-MM-</cell><cell></cell></row><row><cell></cell><cell>DD HH:MM UTC</cell><cell></cell></row><row><cell>local time</cell><cell>Local time in lifelogger's timezone</cell><cell>2018-05-03 01:00</cell></row><row><cell></cell><cell>(combined from lifelogger's smart</cell><cell></cell></row><row><cell></cell><cell>phone and other applications):</cell><cell></cell></row><row><cell></cell><cell>YYYY-MM-DD HH:MM</cell><cell></cell></row><row><cell>timezone</cell><cell>The name of lifelogger's timezone</cell><cell>Europe/Dublin</cell></row><row><cell>lat</cell><cell>Latitude of lifelogger's position</cell><cell>53.386881</cell></row><row><cell>lon</cell><cell>Longitude of lifelogger's position</cell><cell>-6.15843</cell></row><row><cell>semantic name</cell><cell>The name of the place</cell><cell>Home</cell></row><row><cell></cell><cell>corresponding to lifelogger's</cell><cell></cell></row><row><cell></cell><cell>position</cell><cell></cell></row><row><cell>elevation</cell><cell>Information of the floors that the</cell><cell>69</cell></row><row><cell></cell><cell>lifelogger went up estimated by</cell><cell></cell></row><row><cell></cell><cell>Fitbit</cell><cell></cell></row><row><cell>speed</cell><cell>The current speed when the</cell><cell>14.5</cell></row><row><cell></cell><cell>lifelogging was moving</cell><cell></cell></row><row><cell>activity type</cell><cell>The activity that lifelogger was</cell><cell>walking, transport</cell></row><row><cell></cell><cell>doing at that time</cell><cell></cell></row><row><cell>calories</cell><cell>The number of calories collected</cell><cell>1.17349994</cell></row><row><cell></cell><cell>by wearable devices</cell><cell></cell></row><row><cell>heart rate</cell><cell>The heart rate of volunteer at that</cell><cell>73</cell></row><row><cell></cell><cell>time collected by wearable devices</cell><cell></cell></row><row><cell>steps</cell><cell>The number of lifelogger's steps</cell><cell>14</cell></row><row><cell></cell><cell>collected by wearable devices</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,151.16,115.91,309.21,329.27"><head>Table 4 .</head><label>4</label><figDesc>Structure of the Visual Concepts table.</figDesc><table coords="9,151.16,138.59,309.21,306.59"><row><cell>Field name</cell><cell>Meaning</cell><cell>Example</cell></row><row><cell>minute id</cell><cell>Identity field for every</cell><cell>20180503 0000</cell></row><row><cell></cell><cell>image, including images</cell><cell></cell></row><row><cell></cell><cell>from wearable camera and</cell><cell></cell></row><row><cell></cell><cell>smart phone camera</cell><cell></cell></row><row><cell>utc time</cell><cell>UTC Time with format:</cell><cell>UTC 2018-05-</cell></row><row><cell></cell><cell>UTC YYYY-MM-</cell><cell>03 00:00</cell></row><row><cell></cell><cell>DD HH:MM</cell><cell></cell></row><row><cell>image path</cell><cell>Image path to the</cell><cell></cell></row><row><cell></cell><cell>corresponding image</cell><cell></cell></row><row><cell>attribute top1 to</cell><cell>The top 10 attributes</cell><cell>no horizon,</cell></row><row><cell>attribute top10 (top</cell><cell>predicted by using the</cell><cell>man-made, metal,</cell></row><row><cell>10 attributes)</cell><cell>PlaceCNN, trained on</cell><cell>indoor lighting</cell></row><row><cell></cell><cell>SUNattribute dataset</cell><cell></cell></row><row><cell>category topXX,</cell><cell>The top 05 categories and</cell><cell>chemistry lab, 0.082</cell></row><row><cell>category topXX score</cell><cell>their scores predicted by</cell><cell></cell></row><row><cell>(top 05 categories)</cell><cell>using the PlaceCNN,</cell><cell></cell></row><row><cell></cell><cell>trained on Place 365</cell><cell></cell></row><row><cell></cell><cell>dataset.</cell><cell></cell></row><row><cell>concept class topXX,</cell><cell>Class name, bounding box</cell><cell>person, 0.987673</cell></row><row><cell>concept score topXX,</cell><cell>and score of the top 25</cell><cell>508.568878</cell></row><row><cell>concept bbox topXX,</cell><cell>objects with the highest</cell><cell>171.124496</cell></row><row><cell>(top 25 concepts)</cell><cell>score in each image. They</cell><cell>513.541748</cell></row><row><cell></cell><cell>are predicted by using</cell><cell>395.073303</cell></row><row><cell></cell><cell>Mask R-CNN, trained on</cell><cell></cell></row><row><cell></cell><cell>the COCO dataset</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="12,140.03,115.91,335.29,196.86"><head>Table 6 .</head><label>6</label><figDesc>Official Results of the ImageCLEFlifelog 2020 SPLL Task.</figDesc><table coords="12,140.03,136.29,294.72,165.53"><row><cell>Team</cell><cell>Run</cell><cell cols="2">Primary Score Secondary Score</cell></row><row><cell cols="2">Organiser RUN1 *</cell><cell>0.47</cell><cell>313.30</cell></row><row><cell></cell><cell>RUN2 *</cell><cell>0.41</cell><cell>203.10</cell></row><row><cell>BIDAL</cell><cell>RUN1</cell><cell>0.77</cell><cell>306.90</cell></row><row><cell></cell><cell>RUN2</cell><cell>0.52</cell><cell>309.10</cell></row><row><cell></cell><cell>RUN3</cell><cell>0.59</cell><cell>254.70</cell></row><row><cell></cell><cell>RUN4</cell><cell>0.59</cell><cell>372.60</cell></row><row><cell></cell><cell>RUN5</cell><cell>0.53</cell><cell>375.20</cell></row><row><cell></cell><cell>RUN6</cell><cell>0.65</cell><cell>319.60</cell></row><row><cell></cell><cell>RUN7</cell><cell>0.71</cell><cell>250.20</cell></row><row><cell></cell><cell>RUN8</cell><cell>0.82</cell><cell>245.60</cell></row><row><cell></cell><cell>RUN9</cell><cell>0.82</cell><cell>128.00</cell></row><row><cell></cell><cell>RUN10</cell><cell>0.65</cell><cell>112.00</cell></row><row><cell>Notes:</cell><cell></cell><cell></cell><cell></cell></row></table><note coords="12,168.50,292.19,3.65,5.24;12,175.72,293.95,299.60,7.86;12,182.43,304.91,250.50,7.86"><p>* submissions from the organizer teams are just for reference. The results in this paper are official version of ImageCLEFlifelog 2020 tasks.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="5,144.73,656.80,137.29,7.86"><p>Narrative Clip and Narrative Clip</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="5,292.77,656.80,102.70,7.86"><p>-http://getnarrative.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2" coords="6,144.73,656.80,251.90,7.86"><p>Fitbit Fitness Tracker (FitBit Versa) -https://www.fitbit.com</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="15,142.96,462.40,337.64,7.86;15,151.52,473.36,161.47,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="15,366.40,462.40,114.19,7.86;15,151.52,473.36,86.39,7.86">Big data for lifelog moments retrieval improvement</title>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">B</forename><surname>Abdallah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Feki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">B</forename><surname>Amar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,259.62,473.36,24.70,7.86">CLEF</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.96,483.91,337.64,7.86;15,151.52,494.87,325.00,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="15,392.99,483.91,87.61,7.86;15,151.52,494.87,248.41,7.86">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,421.36,494.87,26.49,7.86">ECCV</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.96,505.42,337.64,7.86;15,151.52,516.38,329.07,7.86;15,151.52,527.34,25.60,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="15,151.52,516.38,282.34,7.86">Overview of imagecleflifelog 2017: Lifelog retrieval and summarization</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Boato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,455.90,516.38,24.70,7.86">CLEF</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.96,537.89,337.64,7.86;15,151.52,548.85,329.07,7.86;15,151.52,559.81,67.45,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="15,442.93,537.89,37.66,7.86;15,151.52,548.85,325.51,7.86">Overview of imagecleflifelog 2018: Daily living understanding and lifelog moment retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,165.60,559.81,24.69,7.86">CLEF</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.96,570.35,337.63,7.86;15,151.52,581.31,329.07,7.86;15,151.52,592.27,168.62,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="15,247.27,581.31,233.32,7.86;15,151.52,592.27,94.53,7.86">Overview of imagecleflifelog 2019: Solve my life puzzle and lifelog moment retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">T</forename><surname>Ninh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,266.76,592.27,24.70,7.86">CLEF</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.96,602.82,337.64,7.86;15,151.52,613.78,122.28,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="15,398.34,602.82,82.26,7.86;15,151.52,613.78,42.29,7.86">Overview of ntcir-12 lifelog task</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Joho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hopfgartner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Albatal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,214.81,613.78,30.33,7.86">NTCIR</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.96,624.33,337.64,7.86;15,151.52,635.29,225.75,7.86" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="15,212.07,635.29,136.54,7.86">Overview of ntcir-13 lifelog-2 task</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Joho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hopfgartner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Albatal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.96,645.84,337.63,7.86;15,151.52,656.80,309.40,7.86" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="15,279.84,656.80,152.42,7.86">Overview of the ntcir-14 lifelog-3 task</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Joho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hopfgartner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">T</forename><surname>Ninh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Albatal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Healy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.96,119.67,337.63,7.86;16,151.52,130.63,133.08,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="16,326.37,119.67,119.11,7.86">Lifelogging: Personal big data</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">F</forename><surname>Smeaton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Doherty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,452.82,119.67,27.77,7.86;16,151.52,130.63,68.06,7.86">Found. Trends Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1" to="125" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,140.82,337.97,7.86;16,151.52,151.78,278.10,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="16,349.10,140.82,44.58,7.86">Mask r-cnn</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gkioxari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>DollÃ¡r</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,422.80,140.82,57.79,7.86;16,151.52,151.78,189.01,7.86">IEEE International Conference on Computer Vision (ICCV)</title>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="2980" to="2988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,161.96,337.98,7.86;16,151.52,172.92,329.07,7.86;16,151.52,183.88,60.92,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="16,299.05,161.96,177.61,7.86">Deep residual learning for image recognition</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,172.83,172.92,292.08,7.86">IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="770" to="778" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,194.07,337.98,7.86;16,151.52,205.03,329.07,7.86;16,151.52,215.99,329.07,7.86;16,151.52,226.94,329.07,7.86;16,151.52,237.90,329.07,7.86;16,151.52,248.86,329.07,7.86;16,151.52,259.82,329.07,7.86;16,151.52,270.78,329.07,7.86;16,151.52,281.74,329.07,7.86;16,151.52,292.70,329.07,7.86;16,151.52,303.66,34.31,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="16,295.04,248.86,185.55,7.86;16,151.52,259.82,255.37,7.86">Overview of the ImageCLEF 2020: Multimedia retrieval in lifelogging, medical, nature, and internet applications</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>MÃ¼ller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>PÃ©teri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">D</forename><surname>Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">T</forename><surname>Ninh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Fichou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Berari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Brie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dogariu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">D</forename><surname>Constantin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,426.43,259.82,54.16,7.86;16,151.52,270.78,329.07,7.86;16,151.52,281.74,253.34,7.86">Proceedings of the 11th International Conference of the CLEF Association (CLEF 2020)</title>
		<title level="s" coord="16,456.14,281.74,24.45,7.86;16,151.52,292.70,138.63,7.86">LNCS Lecture Notes in Computer Science</title>
		<meeting>the 11th International Conference of the CLEF Association (CLEF 2020)<address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">September 22-25 2020</date>
			<biblScope unit="volume">12260</biblScope>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="16,142.62,313.84,337.98,7.86;16,151.52,324.80,329.07,7.86;16,151.52,335.76,329.07,7.86;16,151.52,346.72,234.22,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="16,420.20,324.80,60.39,7.86;16,151.52,335.76,310.30,7.86">Visual genome: Connecting language and vision using crowdsourced dense image annotations</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Groth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hata</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kravitz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Kalantidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Shamma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,469.07,335.76,11.52,7.86;16,151.52,346.72,159.98,7.86">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="page" from="32" to="73" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,356.90,337.98,7.86;16,151.52,367.86,329.07,7.86;16,151.52,378.82,268.53,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="16,198.35,367.86,207.93,7.86">Lifeseeker 2.0: Interactive lifelog search engine at lsc</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">T</forename><surname>Ninh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">A</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Healy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,432.51,367.86,48.08,7.86;16,151.52,378.82,239.85,7.86">Proceedings of the Third Annual Workshop on Lifelog Search Challenge</title>
		<meeting>the Third Annual Workshop on Lifelog Search Challenge</meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,389.01,337.98,7.86;16,151.52,399.97,329.07,7.86;16,151.52,410.93,25.60,7.86" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="16,209.68,399.97,177.29,7.86">Microsoft coco: Common objects in context</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Maire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">J</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hays</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ramanan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>DollÃ¡r</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Zitnick</surname></persName>
		</author>
		<idno>ArXiv abs/1405.0312</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,421.11,337.98,7.86;16,151.52,432.07,329.07,7.86;16,151.52,443.03,160.85,7.86" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="16,282.11,432.07,198.48,7.86;16,151.52,443.03,34.83,7.86">Roberta: A robustly optimized bert pretraining approach</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno>ArXiv abs/1907.11692</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,453.22,337.98,7.86;16,151.52,464.18,185.56,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="16,193.30,453.22,227.75,7.86">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,428.35,453.22,52.25,7.86;16,151.52,464.18,112.86,7.86">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">91</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,474.36,337.97,7.86;16,151.52,485.32,329.07,7.86;16,151.52,496.28,208.94,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="16,254.22,485.32,226.37,7.86;16,151.52,496.28,134.12,7.86">Lifer 2.0: Discovering personal lifelog insights using an interactive lifelog retrieval system</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">T</forename><surname>Ninh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,307.08,496.28,24.70,7.86">CLEF</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,506.46,337.97,7.86;16,151.52,517.42,90.67,7.86" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="16,277.57,506.46,164.92,7.86">Yolov3: An incremental improvement</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Redmon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<idno>ArXiv abs/1804.02767</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,527.61,337.98,7.86;16,151.52,538.57,329.07,7.86;16,151.52,549.53,188.41,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="16,322.26,527.61,158.33,7.86;16,151.52,538.57,160.77,7.86">Faster r-cnn: Towards real-time object detection with region proposal networks</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">B</forename><surname>Girshick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,319.87,538.57,160.73,7.86;16,151.52,549.53,100.36,7.86">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1137" to="1149" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,559.71,337.97,7.86;16,151.52,570.67,329.07,7.86;16,151.52,581.63,85.37,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="16,321.67,559.71,158.92,7.86;16,151.52,570.67,329.07,7.86;16,151.52,581.63,11.14,7.86">Ua.pt bioinformatics at imageclef 2019: Lifelog moment retrieval based on image annotation and natural language processing</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ribeiro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">J R</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Oliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,183.52,581.63,24.70,7.86">CLEF</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,591.82,337.97,7.86;16,151.52,602.78,329.07,7.86;16,151.52,613.73,232.10,7.86" xml:id="b21">
	<monogr>
		<title level="m" type="main" coord="16,263.13,602.78,217.47,7.86;16,151.52,613.73,106.44,7.86">Fixmatch: Simplifying semi-supervised learning with consistency and confidence</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Berthelot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Carlini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">D</forename><surname>Cubuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kurakin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Raffel</surname></persName>
		</author>
		<idno>ArXiv abs/2001.07685</idno>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,623.92,337.98,7.86;16,151.52,634.88,329.07,7.86;16,151.52,645.84,329.07,7.86;16,151.52,656.80,286.59,7.86" xml:id="b22">
	<monogr>
		<title level="m" type="main" coord="16,261.18,656.80,135.97,7.86">Pmdata: A sports logging dataset</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Thambawita</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hicks</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Borgli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Pettersen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Kupka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Stensland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">M</forename><surname>GrÃ¸nli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">M</forename><surname>Fredriksen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Eg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fagernes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Biorn-Hansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hammer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,119.67,337.97,7.86;17,151.52,130.63,329.07,7.86;17,151.52,141.59,183.77,7.86" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="17,384.80,119.67,95.79,7.86;17,151.52,130.63,178.33,7.86">MyscÃ©al: An experimental interactive lifelog retrieval system for lsc</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">T</forename><surname>Binh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,347.15,130.63,133.45,7.86;17,151.52,141.59,155.10,7.86">Proceedings of the Third Annual Workshop on Lifelog Search Challenge</title>
		<meeting>the Third Annual Workshop on Lifelog Search Challenge</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,152.55,337.97,7.86;17,151.52,163.51,329.07,7.86;17,151.52,174.47,111.11,7.86" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="17,399.52,152.55,81.07,7.86;17,151.52,163.51,145.67,7.86">Places: A 10 million image database for scene recognition</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lapedriza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Khosla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,303.98,163.51,176.62,7.86;17,151.52,174.47,82.44,7.86">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
