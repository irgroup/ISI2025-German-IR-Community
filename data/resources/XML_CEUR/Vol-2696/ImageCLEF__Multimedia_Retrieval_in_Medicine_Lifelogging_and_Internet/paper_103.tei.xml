<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,145.56,115.90,324.23,12.68;1,190.92,133.83,233.52,12.68;1,229.92,151.77,155.52,12.68">An Experiment in Interactive Retrieval for the Lifelog Moment Retrieval Task at ImageCLEFlifelog2020</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,223.72,189.43,66.98,8.80"><forename type="first">Ly-Duyen</forename><surname>Tran</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Dublin City University</orgName>
								<address>
									<settlement>Dublin</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,301.26,189.43,83.14,8.80"><forename type="first">Manh-Duy</forename><surname>Nguyen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Dublin City University</orgName>
								<address>
									<settlement>Dublin</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,217.89,201.39,70.41,8.80"><forename type="first">Binh</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">AISIA Research Lab</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Science</orgName>
								<address>
									<addrLine>Ho Chi</addrLine>
									<settlement>Minh City</settlement>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Vietnam National University</orgName>
								<address>
									<addrLine>Ho Chi</addrLine>
									<settlement>Minh City</settlement>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,330.90,201.39,62.10,8.80"><forename type="first">Cathal</forename><surname>Gurrin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Dublin City University</orgName>
								<address>
									<settlement>Dublin</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,145.56,115.90,324.23,12.68;1,190.92,133.83,233.52,12.68;1,229.92,151.77,155.52,12.68">An Experiment in Interactive Retrieval for the Lifelog Moment Retrieval Task at ImageCLEFlifelog2020</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5579CC0D14B3FC374FF82CEF6D4D1964</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The development of technology has led to an increase in mobile devices' use to keep track of individual daily activities, as known as Lifelogging. Lifelogging has raised many research challenges, one of which is how to retrieve a specific moment in response to a user's information need. This paper presents an efficient interactive search engine for large multimodal lifelog data which is evaluated in the ImageCLEFlifelog2020 Lifelog Moment Retrieval task (LMRT). The system is the modified version of the Myscéal demonstrator used in the Lifelog Search Challenge 2020, with the addition of visual similarity and a new method of visualising results. In interactive experimentation, our system achieved an F1@10 score of 0.48 in the official submission but can be significantly improved by implementing a number of post-processing steps.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As defined in <ref type="bibr" coords="1,198.07,472.30,9.96,8.80" target="#b7">[8]</ref>, lifelogging refers to the process of using technology to keep a log of one's daily activities using various media, such as images, location, or biometrics. The stored data is called a lifelog and can help its owners understand their activities and recall some memorable moments in their lives. In order to be useful to the individual, a lifelog should have some form of retrieval tool that can assist them in seeking remembered information. Many collaborative benchmarking fora have been started to assist the research community to make progress, buy defining research challenges and releasing test collections. For example, the NTCIR Lifelog task (from 2015-2019) <ref type="bibr" coords="1,299.56,567.94,9.96,8.80" target="#b4">[5]</ref>, the Lifelog Search Challenge (LSC) <ref type="bibr" coords="1,470.08,567.94,10.51,8.80" target="#b6">[7]</ref> since 2018 and the ImageCLEFlifelog <ref type="bibr" coords="1,303.08,579.89,15.49,8.80" target="#b14">[15]</ref> are all examples of such fora. Given the volumes of lifelog data that an individual can generate, any retrieval system needs to provide accurate retrieval facilities in a timely manner. Additionally, such a tool should have a user-friendly design that can help users to operate efficiently. The ImageCLEFlifelog2020 Lifelog Moment Retrieval task (LMRT) <ref type="bibr" coords="2,134.77,130.89,14.61,8.80" target="#b14">[15]</ref>, which is one of four main tasks in the ImageCLEF2020 campaign <ref type="bibr" coords="2,451.79,130.89,9.96,8.80" target="#b8">[9]</ref>, requires participating interactive retrieval systems to retrieve all possible images matching given topics and do this within a time-limit of five minutes per topic.</p><p>In this paper, we address this ad-hoc interactive retrieval challenge for lifelogs by enhancing the performance of our pre-existing lifelog retrieval system Myscéal <ref type="bibr" coords="2,134.77,191.92,14.61,8.80" target="#b17">[18]</ref>. Since the challenge of LMRT is to find all the moments of interest that match the information need, we implemented visual similarity matching, to assist the user to find visually related content to one positive example. We also added an extra faceted window in the user interface to show a detailed summary of the retrieved results and to provide the user with a result filtering mechanism. Additionally, the ranked result display area has been adjusted to be suitable for the LMRT objectives. Consequently, the contribution of this paper is twofold; firstly in describing the enhanced version of Myscéal, and secondly in describing the result of an interactive retrieval experiment to evaluate the performance of the new system with three types of users; an expert user (the system developer) who is familiar with the tool, a knowledgeable user (the owner) of the dataset who is a novice user, and a full novice user who does not know the tool or the dataset. Finally, we report on the automatic offline post-processing steps and show that they can improve the scoring metrics significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>There have been a number of interactive lifelog retrieval systems described in the literature. One of the pioneers in this field, Doherty et. al. <ref type="bibr" coords="2,380.49,427.65,10.51,8.80" target="#b3">[4]</ref> supported similarity search through event archives by using a simple color-based descriptor. Meanwhile, LEMoRe <ref type="bibr" coords="2,205.72,451.56,14.61,8.80" target="#b15">[16]</ref>, being an example of a more recent system, introduced the concept of integrating images with their semantic context and applied natural language processing to handle textual queries. The top three systems in Image-CLEFlifelog 2019 LMRT <ref type="bibr" coords="2,246.03,487.43,10.51,8.80" target="#b1">[2]</ref> last year also followed a similar idea. The HCMUS team <ref type="bibr" coords="2,159.41,499.38,15.49,8.80" target="#b10">[11]</ref> annotated each image with its concepts along with the inferred colour of detected objects. Moreover, they extended the semantic concepts with the lifelogger's habits and activities. The BIDAL team <ref type="bibr" coords="2,343.72,523.29,10.51,8.80" target="#b2">[3]</ref> used the concepts and other textual information to generate the Bag-of-Word (BOW) vectors representing each image. They then combined the BOW vector generated from the query and used them to find suitable images. In contrast, The ZJUTCVR team <ref type="bibr" coords="2,432.91,559.16,15.49,8.80" target="#b19">[20]</ref> viewed the challenge as a classification problem with additional pre-processing steps to remove the blurred images.</p><p>Our prior system at the LSC'20 <ref type="bibr" coords="2,298.03,596.28,9.96,8.80" target="#b5">[6]</ref>, Myscéal <ref type="bibr" coords="2,354.90,596.28,15.49,8.80" target="#b17">[18]</ref> approached the issue as a traditional text search challenge, in which visual concept annotations and various forms of metadata were indexed as if conventional text. For this task, we implemented two new features (described in the next section) and removed some functions that we think not useful for this LMRT challenge. We also evaluated the system by designing the experiments with three users representing three different usage scenarios. Finally, the post-processing steps were applied to achieve a higher score specifically for the challenge scoring mechanism.</p><p>3 Our Interactive Retrieval System</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">System Overview</head><p>The modified Myscéal retained the processing pipeline of the original version as depicted in Figure <ref type="figure" coords="3,216.85,212.56,3.87,8.80">1</ref>, which follows a typical structure for a lifelog search engine as introduced in <ref type="bibr" coords="3,210.25,224.51,14.61,8.80" target="#b18">[19]</ref>. The visual concepts of each image were initially derived from the given metadata and augmented with the output of the object detector from DeepLabv3+ <ref type="bibr" coords="3,217.84,248.42,9.96,8.80" target="#b0">[1]</ref>. Those annotations, along with other information such as locations and time, were then indexed in the open-source search engine (Elas-ticSearch). The input query was analysed to extract the primary information and enlarged by our expansion mechanism (see section 3.4), then matched with our inverted index to find the potentially relevant images that were ordered by the ranking function and presented to the user. The readers are referred to the original work in <ref type="bibr" coords="3,206.76,320.15,14.61,8.80" target="#b17">[18]</ref>, which describes in detail how this process operates.</p><p>In this version, besides the concepts detected from the descriptor, we employed the Microsoft Computer Vision API<ref type="foot" coords="3,321.58,342.51,3.97,6.16" target="#foot_0">1</ref> service to enrich the visual annotations further. To provide an optimized interactive retrieval system for LMRT, we introduced three updates to the previous system; visual similarity, user interface, and summary panel. We will now describe each of these components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Visual Similarity</head><p>The Myscéal system was developed for the LSC'20 challenge, which required participants to find any single relevant image for a given topic as fast as possible. The ImageCLEFlifelog2020 LMRT task is different in that it seeks a list of suitable images for a given query. This is a subtle difference that requires a different retrieval engine. Firstly we implemented a visual similarity feature to facilitate the user in finding all visually similar images to any given image. We measured the similarities between images by using the cosine distance of their visual features, which comprised SIFT <ref type="bibr" coords="3,326.74,509.43,16.38,8.80" target="#b11">[12,</ref><ref type="bibr" coords="3,343.11,509.43,12.28,8.80" target="#b12">13,</ref><ref type="bibr" coords="3,355.40,509.43,12.28,8.80" target="#b13">14]</ref> and VGG16 <ref type="bibr" coords="3,425.29,509.43,15.49,8.80" target="#b16">[17]</ref> features. We did not include visual concept descriptions because the intention of visual similarities is to provide users a different way of searching that is independent as possible to the text-based retrieval. To ensure real-time retrieval, we made this process offline and indexed a list of similar images of each image in the ElasticSearch engine prior to accepting any user queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">User Interface</head><p>The LSC'20 challenge included topics that had a definite temporal element (e.g. going to the cafe after work), which was not expected in the LMRT topics, hence Fig. <ref type="figure" coords="4,153.44,232.52,3.87,8.80">1</ref>: Our system's pipeline included the offline data indexing stage and the online retrieval stage. ElasticSearch was used to store the annotations including detected objects and visual similar photos extracted from every image and its metadata. In the retrieval phase, a query given by users is firstly expanded to include more information, then is compared with the data in the storage and shown to users.</p><p>we replaced the temporal query mechanism of Myscéal with a more conventional search box for users to enter the query. Whenever the user submits the query, the retrieval results are shown in the middle of the screen in a ranked list, supporting both vertical and horizontal scrolling. Each row contains concatenated grouped images, which are in decreasing order to the similarity to the query and grouped by day. Each group represents a moment or an activity in which there are many visually similar images. This structure not only reduces the visual and cognitive load on a user, but it also allows for a higher level of recall. This is because the user will have a clearer view with less identical images leading to have more time and high chances to spot out relevant photos in the ranked list.</p><p>Clicking on an image in the ranked list opens a detail window containing all images taken on the same day in an event-level view. This event view, as illustrated in 3, is arranged with three parts to show the hierarchy of event grouping. Visually similar images (in the first row) are grouped together and their thumbnail is shown as one item on the second row; the bottom row indicates the broadest level of grouping: each image in this row is a thumbnail of an activity that happens in the same location (walking in the airport, sitting inside the airplane). Using this, the user can browse the images through the day at a faster pace.</p><p>There is also a small visual similarity icon at the bottom of each image that allows users to open the similarity window listing all similar photos of the selected image. Every image in this window contains a button that opens the similarity panel.</p><p>On the top-right pane of the user interface, we show the "Saved scenes" section. Whenever users find a relevant image, they can save that photo quickly with the help of the saving icon appearing at the bottom of every image. The bottom-right map panel, which remains the same as the previous version, works as a location filter, or illustrates the location of an image. Additionally, we introduced a new "Word List" panel appearing in the same area with the "Saved scenes" panel. This feature will list all concepts used in the retrieval system and their scores so that users can adjust (e.g., increase the scores, or remove the concepts) to have better results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Word List Panel</head><p>The word list and their corresponding scores comprise the query expansion process, as introduced in <ref type="bibr" coords="5,231.39,475.80,14.61,8.80" target="#b17">[18]</ref>. We employed heuristic rules to assign scores to each word in the expansion list: (1) A word will have the score of α if it is an exact match of the user query; (2) if the word is the result of the synonym, hypernym or hyponym expansion, we assign its score β; (3) if the word is the result of the Word2Vec similarity expansion, assign the similarity score; and (4) if the word is the result of multiple expansion (i.e., it is similar to several words), the final score will be the highest one. Furthermore, to reduce the workload on the search engine and not confuse users by showing a long list of words, only 20 highest scoring words were chosen. We set α = 3, β = 0.95 after some empirical trials.</p><p>In addition to the scoring word lists, we also provided a quick summary of the results by displaying the most frequently occurring visual concepts. This way, users can choose to remove some of the irrelevant contexts. For example, searching for kitchen might result in a distracting amount of images that show a window. Meanwhile, the user wants to look for something from another point of view. Using the summary feature, the user can remove the window to have a more focused result view.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 3: Events view windows 4 User Experiments Setup</head><p>To evaluate the system's performance, we designed a user experiment by asking three users, the expert system creator, the knowledgeable data owner, and a novice user, representing three use-cases. The developer would know clearly and could operate the system in the best way, while the data owner, or lifelogger, was expected to know the answers to all topics. In contrast, the novice user was not familiar with either the system or the dataset. All users had a maximum of 5 minutes to solve each query, which did not include the time for reading the topic. Prior to the experiment, all users were given the opportunity to familiarise themselves with the system by processing some sample topics under the guidance of the system creators. After finishing each query, users were required to record their searching time, displayed on the system, the distance of mouse movement on the screen (measured in meters), the number of mouse clicks, and the number of keystrokes (all gathered using a third-party tool). The three users were encouraged to utilize the entire 5 minutes to retrieve images from as many relevant events as possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">LMRT Task</head><p>Evaluation of system performance (user performance) is via three metrics suggested by the LMRT organizers; Precision at 10 (P@10), Cluster Recall at 10 (CR@10), and the F1 Score at 10 (F1@10). Since the users were instructed to focus on finding images from all relevant events instead of selecting all images in a single event, the post-processing steps are necessary to improve the recall score in LMRT. For each selected image, we expanded the result by finding all similar photos within a given temporal window to augment the submitted results. After performing the expansion for all images, we rearranged the result by moving the user-selected images in each cluster to the top rank to ensure a higher P@10 score. All of the steps described above were processed automatically offline after the users finished their search sessions. The F 1@10 scores <ref type="bibr" coords="7,389.89,190.66,15.49,8.80" target="#b14">[15]</ref> for each user are shown in the Table <ref type="table" coords="7,222.62,202.62,3.87,8.80">1</ref>. Please note that we present both the raw user runs and the expanded post-processed runs separately and that the official runs were the raw-runs.</p><p>Table <ref type="table" coords="7,161.86,277.43,3.87,8.80">1</ref>: F 1@10 scores of three users (U1: Expert, U2: Owner, U3: Novice). The Raw column indicates the original result from users and the Post column shows the score after applying post-processing steps. The dot means the user could not find the answer for that question. Numbers with the * are the highest number in that topic. The experimental results indicate that the lifelogger, who knows best about the dataset, got the highest overall score among all users in both the original and the refined answers. The authors of the system also obtained a comparable score and even achieved the same as the data owner after the post-processing step. The average F 1@10 score of the novice user was lower than the others with 0.21 and 0.39 for the raw and the modified result, respectively. One possible reason is this user was not successful in solving nearly half of the tasks in the challenge. The post-processing stage had a significant impact on the score as it improved the overall value by at least 30%. It could boost the original to the absolute value of 1 as two steps were expected to capture full precision and recall criterion. There were, however, some queries that remained the same after the second stage. Another interesting detail was that the system creator had four topics whose scores were higher than others, while that of the lifelogger was just three.</p><p>The detailed distribution of the precision and recall of each user is illustrated in Figure <ref type="figure" coords="8,179.01,154.80,3.87,8.80">4</ref>. There was a significant improvement in the precision score of the developer and the novice user. It was because they only submitted a few images within a cluster to spend more time discovering more groups leading to not enough answers for the evaluation, hence getting the low P@10 in the initial submission. The retrieving behaviors of these two users also allowed them to found out many distinct events and ranked them at the top places in the submitted results hence gained sufficient CR@10 scores. Therefore the refining steps almost had no impact on this metric and the CR@10 of both volunteers slightly remained. In contrast, the lifelogger tended to select all relevant images he saw on the screen making the answers from different clusters were not in the top 10 anymore. The post-processing algorithm could fix this issue by rearranging the results and improving the scores shown in Figure <ref type="figure" coords="8,352.20,286.31,8.85,8.80">4b</ref>. Fig. <ref type="figure" coords="8,153.44,464.55,3.87,8.80">4</ref>: Precision at 10 (P@10) and Cluster Recall at 10 (CR@10) of three users (U1: Developer, U2: Lifelogger, U3: Novice) for the original compared to the post-processing answers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">User Experiments</head><p>We asked the users to keep track of their searching time, the distance of the mouse movement (in meters), number of mouse clicks, and the number of keystrokes after they finished a question. We illustrate these results in Figure <ref type="figure" coords="8,427.51,584.33,3.87,8.80" target="#fig_3">5</ref>.</p><p>All participants tended to utilize the entire five minutes for doing a query as they are suggested. It is apparent that the lifelogger needed a shorter time to finish some topics than two others because this user already had unique information about the collection and hence could form better queries and knew when to stop searching. The mouse's distance moving on the screen, and the number of clicks reflected how users interacted with the user interface were also measured.</p><p>The former measurement of the author and the novice were similar while the data owner had a slightly higher number due to the larger widescreen monitor used in the experiment (note that screen-size has an effect). This statistic indicated the simplicity of our interface design. All features were shown clearly on the screen, and even those not familiar with the system could operate effectively. The lifelogger and the author clicked much more than the novice user. It may come from the fact that they both had sufficient experience to carefully check each image's full information prior to selecting it. In contrast, we observed that the novice user only checked the results on the main screen but not into the photo's details. The number of keystrokes of the developer was lower than that of the novice as the author knew what were the suitable keywords to find the answer, while the latter user had tried many concepts to be able to get the result. It was noticeable that the data owner had used a keyboard less frequently compared to other users when he did the experiment with the least number of keystrokes.  The experiments showed that the expert user could achieve a similar result of the lifelogger who owns the dataset and also is the target of the system. Knowing the data well becomes the most significant advantage in the experiment. For instance, in the topic "Find the moment when u1 was looking at lifelog data on a large touchscreen on the wall", the lifelogger did it instantly by using his prior knowledge to search for the particular location where this event took place. Meanwhile, both the creator of the system and the novice user did not have such insights. However, this merit was not enough to secure getting the high score as sometimes the data owner missed some relevant events in a topic. This issue is reasonable when a lifelogger usually has a massive dataset, and it is onerous to remember precisely without losing any moment within it. The system, in this scenario, could help its user to solve this problem. The first topic "Find the moment when u1 was attending a praying rite with other people in the church" witnessed the developer and the novice user gain a higher score than the lifelogger. The user experiment implied that there was almost no difference in the system manipulation between users. However, we have a noticeable gap in the scores of novice users compared to others. Another notable point is that the lifelogger and the novice users rarely used the "Word list" panel but tried to search for other concepts. This is perhaps an indication that the panel was not intuitive for non-expert users and that the users could have benefited from more training on the use of the system.</p><p>Considering opportunities for improvement, firstly the location information in the dataset seems to vary in accuracy, as stated by the lifelogger while testing. This issue became a critical problem when users wanted to retrieve within the specific area, such as a bus stop near their houses in topic 3 or churches in topic 1. Additionally, the detected concepts from Microsoft API service appeared with many too specific terms leading to the decrease in the precision while searching. There is a need for grouping these concepts to make the system more efficient. Another thing is that our object descriptor cannot recognize the colors well in the images, which is an essential feature in some cases like topic 10. In this work, we used this attribute from the Microsoft service, but it can be improvable by retraining our descriptor in some public datasets supporting these characteristics <ref type="bibr" coords="10,134.77,545.17,14.61,8.80">[10]</ref>.</p><p>In this paper, we aimed to solve the challenge of retrieving an exact moment in a lifelogger lifetime from the large scale multimodal dataset. Our system is modified from the previous version, which combined the retrained images descriptor with the query expansion mechanism, by updating the additional visual similarity functions and reorganizing the user interface to be suitable for the ImageCLEFlifelog2020 LMRT challenge. The user experiment revealed that our simple designed system could be operated easily by the novice user. The system, being utilized in the best way, can help the developer obtain equivalent results with the lifelogger after our post-processing stage.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,134.77,294.92,345.83,8.80;5,134.77,306.87,345.83,8.80;5,134.77,318.83,345.82,8.80;5,134.77,330.78,21.06,8.80;5,143.41,115.83,328.54,167.62"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Our main user interface with the search bar on the top and the main panel below for showing the result. The top-right area presents the "Word list" panel while the map indicating the geospatial location of photos is at the bottom-right area.</figDesc><graphic coords="5,143.41,115.83,328.54,167.62" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="9,134.77,612.40,345.83,8.80;9,134.77,624.36,155.93,8.80;9,139.09,464.37,164.26,119.63"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: The evaluation of how three users (U1: Developer, U2: Lifelogger, U3: Novice) interacted with our system.</figDesc><graphic coords="9,139.09,464.37,164.26,119.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="6,143.41,115.83,328.54,185.04"><head></head><label></label><figDesc></figDesc><graphic coords="6,143.41,115.83,328.54,185.04" type="bitmap" /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,144.73,646.48,292.78,7.47;3,144.73,657.44,75.80,7.47"><p>https://azure.microsoft.com/en-us/services/cognitive-services/ computer-vision/</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This publication has emanated from research supported in party by research grants from Science Foundation Ireland under grant numbers SFI/12/RC/2289, SFI/13/RC/2106, 18/CRT/6223 and 18/CRT/6224. We acknowledge the support and input of the DCU ethics committee and the risk &amp; compliance officer.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="11,142.95,238.18,337.64,7.92;11,151.52,249.14,329.08,7.92;11,151.52,260.10,298.79,7.92" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,392.97,238.18,87.62,7.92;11,151.52,249.14,248.85,7.92">Encoder-decoder with atrous separable convolution for semantic image segmentation</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Papandreou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,421.95,249.14,58.65,7.92;11,151.52,260.10,213.77,7.92">Proceedings of the European conference on computer vision (ECCV)</title>
		<meeting>the European conference on computer vision (ECCV)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="801" to="818" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.95,271.32,337.64,7.92;11,151.52,282.28,329.07,7.92;11,151.52,293.24,329.08,7.92;11,151.52,304.20,162.71,7.92" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,272.49,282.28,208.10,7.92;11,151.52,293.24,126.41,7.92">Overview of imagecleflifelog 2019: solve my life puzzle and lifelog moment retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">T</forename><surname>Ninh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,298.71,293.24,104.56,7.92">CLEF2019 Working Notes</title>
		<title level="s" coord="11,410.61,293.24,69.98,7.92;11,151.52,304.20,46.41,7.92">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">2380</biblScope>
			<biblScope unit="page" from="9" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.95,315.42,337.64,7.92;11,151.52,326.38,329.08,7.92;11,151.52,337.34,329.07,7.92;11,151.52,348.30,41.48,7.92" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,334.40,315.42,146.19,7.92;11,151.52,326.38,264.43,7.92">Bidal@ imagecleflifelog2019: the role of content and context of daily activities in insights from lifelogs</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">K</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">D</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Zettsu</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org" />
	</analytic>
	<monogr>
		<title level="m" coord="11,437.47,326.38,43.12,7.92;11,151.52,337.34,58.58,7.92">CLEF2019 Working Notes</title>
		<title level="s" coord="11,217.70,337.34,168.56,7.92">CEUR Workshop Proceedings, CEUR-WS</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.95,359.52,337.64,7.92;11,151.52,370.48,329.08,7.92;11,151.52,381.44,262.47,7.92" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,242.68,370.48,237.92,7.92;11,151.52,381.44,35.13,7.92">Experiences of aiding autobiographical memory using the sensecam</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Doherty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Pauly-Takacs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Caprani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Moulin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">E</forename><surname>O'connor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">F</forename><surname>Smeaton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,194.11,381.44,121.61,7.92">Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="151" to="174" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.95,392.67,337.64,7.92;11,151.52,403.63,329.07,7.92;11,151.52,414.59,329.07,7.92;11,151.52,425.54,76.78,7.92" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,409.24,392.67,71.35,7.92;11,151.52,403.63,153.40,7.92">Ntcir lifelog: The first test collection for lifelog research</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Joho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hopfgartner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Albatal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,327.27,403.63,153.32,7.92;11,151.52,414.59,325.19,7.92">Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval</title>
		<meeting>the 39th International ACM SIGIR conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="705" to="708" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.95,436.77,337.64,7.92;11,151.52,447.73,329.07,7.92;11,151.52,458.69,329.07,7.92;11,151.52,469.65,168.04,7.92" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,321.84,447.73,158.75,7.92;11,151.52,458.69,96.12,7.92">Introduction to the third annual lifelog search challenge (lsc&apos;20)</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">T</forename><surname>Ninh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">Þ</forename><surname>Jónsson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lokoš</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Hürst</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Schoeffmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,268.53,458.69,212.06,7.92;11,151.52,469.65,84.31,7.92">Proceedings of the 2020 International Conference on Multimedia Retrieval</title>
		<meeting>the 2020 International Conference on Multimedia Retrieval</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="584" to="585" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.95,480.87,337.64,7.92;11,151.52,491.83,329.08,7.92;11,151.52,502.79,329.08,7.92;11,151.52,513.75,234.22,7.92" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,374.31,491.83,106.29,7.92;11,151.52,502.79,252.72,7.92">Comparing approaches to interactive lifelog search at the lifelog search challenge (lsc2018)</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Schoeffmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Joho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Leibetseder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Duane</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Tien</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,410.68,502.79,69.92,7.92;11,151.52,513.75,157.45,7.92">ITE Transactions on Media Technology and Applications</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="46" to="59" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.95,524.97,337.64,7.92;11,151.52,535.93,280.56,7.92" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,356.14,524.97,120.36,7.92">Lifelogging: Personal big data</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">F</forename><surname>Smeaton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Doherty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,151.52,535.93,203.78,7.92">Foundations and Trends R in information retrieval</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="125" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.95,547.16,337.64,7.92;11,151.52,558.11,329.07,7.92;11,151.52,569.07,329.07,7.92;11,151.52,580.03,329.07,7.92;11,151.52,590.99,329.07,7.92;11,151.52,601.95,329.07,7.92;11,151.52,612.91,329.07,7.92;11,151.52,623.87,329.08,7.92;11,151.52,634.83,329.07,7.92;11,151.52,645.79,329.07,7.92;12,134.77,119.62,11.77,7.92" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,295.05,601.95,185.54,7.92;11,151.52,612.91,255.37,7.92">Overview of the ImageCLEF 2020: Multimedia retrieval in lifelogging, medical, nature, and internet applications</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ionescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Péteri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Abacha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Datla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kozlovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Liauchuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">D</forename><surname>Cid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kovalev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Pelka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">T</forename><surname>Ninh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chamberlain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Campello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Fichou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Berari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Brie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dogariu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">D</forename><surname>Ştefan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">G</forename><surname>Constantin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,426.44,612.91,54.15,7.92;11,151.52,623.87,329.08,7.92;11,151.52,634.83,253.34,7.92">Proceedings of the 11th International Conference of the CLEF Association (CLEF 2020)</title>
		<title level="s" coord="11,456.15,634.83,24.44,7.92;11,151.52,645.79,138.63,7.92">LNCS Lecture Notes in Computer Science</title>
		<meeting>the 11th International Conference of the CLEF Association (CLEF 2020)<address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date>September 22-10</date>
			<biblScope unit="volume">12260</biblScope>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="12,151.51,119.62,329.08,7.92;12,151.52,130.58,329.07,7.92;12,151.52,141.54,329.07,7.92;12,151.52,152.50,150.30,7.92" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,334.41,130.58,146.18,7.92;12,151.52,141.54,226.07,7.92">Visual genome: Connecting language and vision using crowdsourced dense image annotations</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Krishna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Groth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hata</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kravitz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Kalantidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Shamma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,385.32,141.54,95.27,7.92;12,151.52,152.50,64.32,7.92">International journal of computer vision</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="32" to="73" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,163.46,337.98,7.92;12,151.52,174.42,329.07,7.92;12,151.52,185.37,329.07,7.92;12,151.52,196.33,106.30,7.92" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,361.66,163.46,118.93,7.92;12,151.52,174.42,325.08,7.92">Lifelog moment retrieval with advanced semantic extraction and flexible moment visualization for exploration</title>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">K</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org" />
	</analytic>
	<monogr>
		<title level="m" coord="12,166.93,185.37,283.16,7.92">CLEF2019 Working Notes. CEUR Workshop Proceedings, CEURWS</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,207.29,337.98,7.92;12,151.52,218.25,329.08,7.92;12,151.52,229.21,92.13,7.92" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,201.91,207.29,210.54,7.92">Object recognition from local scale-invariant features</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,432.53,207.29,48.06,7.92;12,151.52,218.25,278.17,7.92">Proceedings of the Seventh IEEE International Conference on Computer Vision</title>
		<meeting>the Seventh IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1150" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,240.17,337.98,7.92;12,151.52,251.13,244.11,7.92" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,205.64,240.17,234.10,7.92">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,448.33,240.17,32.26,7.92;12,151.52,251.13,138.93,7.92">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004-11">Nov 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,262.09,337.98,7.92;12,151.52,273.05,329.08,7.92;12,151.52,284.00,177.25,7.92" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,262.07,262.09,218.52,7.92;12,151.52,273.05,54.96,7.92">Creating efficient visual codebook ensembles for object categorization</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">L</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,214.25,273.05,266.34,7.92;12,151.52,284.00,86.66,7.92">IEEE Transactions on Systems, Man, and Cybernetics -Part A: Systems and Humans</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="238" to="253" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,294.96,337.97,7.92;12,151.52,305.92,329.07,7.92;12,151.52,316.88,329.07,7.92;12,151.52,327.84,329.07,7.92;12,151.52,338.80,220.14,7.92" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="12,349.62,305.92,130.97,7.92;12,151.52,316.88,261.15,7.92">Overview of ImageCLEF Lifelog 2020:Lifelog Moment Retrieval and Sport Performance Lifelog</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">T</forename><surname>Ninh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">K</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Piras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Halvorsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<ptr target="org&lt;http://ceur-ws.org&gt;" />
	</analytic>
	<monogr>
		<title level="m" coord="12,437.47,316.88,43.12,7.92;12,151.52,327.84,61.28,7.92">CLEF2020 Working Notes</title>
		<title level="s" coord="12,223.10,327.84,179.08,7.92">CEUR Workshop Proceedings, CEUR-WS.</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">September 22-25 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,349.76,337.98,7.92;12,151.52,360.72,329.07,7.92;12,151.52,371.68,329.07,7.92;12,151.52,382.63,108.67,7.92" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="12,200.34,360.72,280.26,7.92;12,151.52,371.68,15.40,7.92">Lemore: A lifelog engine for moments retrieval at the ntcir-lifelog lsat task</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>De Oliveira Barra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cartas Ayala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bolaños</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dimiccoli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Giró Nieto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Radeva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,187.19,371.68,293.40,7.92;12,151.52,382.63,80.01,7.92">Proceedings of the 12th NTCIR Conference on Evaluation of Information Access Technologies</title>
		<meeting>the 12th NTCIR Conference on Evaluation of Information Access Technologies</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,393.59,337.98,7.92;12,151.52,404.55,231.21,7.92" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="12,278.92,393.59,201.67,7.92;12,151.52,404.55,69.80,7.92">Very deep convolutional networks for large-scale image recognition</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Simonyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1409.1556</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,142.61,415.51,337.98,7.92;12,151.52,426.47,329.07,7.92;12,151.52,437.43,260.50,7.92" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="12,398.90,415.51,81.69,7.92;12,151.52,426.47,206.35,7.92">Myscéal: An experimental interactive lifelog retrieval system for lsc&apos;20</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">D</forename><surname>Tran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">T</forename><surname>Binh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,379.14,426.47,101.46,7.92;12,151.52,437.43,185.67,7.92">Proceedings of the Third Annual Workshop on Lifelog Search Challenge</title>
		<meeting>the Third Annual Workshop on Lifelog Search Challenge</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="23" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,448.39,337.98,7.92;12,151.52,459.35,329.07,7.92;12,151.52,470.31,111.63,7.92" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="12,328.15,448.39,152.44,7.92;12,151.52,459.35,46.39,7.92">A baseline search engine for personal life archives</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">T</forename><surname>Dang-Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,219.91,459.35,260.68,7.92;12,151.52,470.31,37.27,7.92">Proceedings of the 2nd Workshop on Lifelogging Tools and Applications</title>
		<meeting>the 2nd Workshop on Lifelogging Tools and Applications</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="21" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,481.26,337.97,7.92;12,151.52,492.22,329.07,7.92;12,151.52,503.18,149.57,7.92" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="12,258.11,481.26,222.47,7.92;12,151.52,492.22,43.39,7.92">Zjutcvr team at imagecleflifelog2019 lifelog moment retrieval task</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Xia</surname></persName>
		</author>
		<ptr target="http://ceur-ws.org" />
	</analytic>
	<monogr>
		<title level="m" coord="12,215.04,492.22,103.61,7.92">CLEF2019 Working Notes</title>
		<title level="s" coord="12,325.51,492.22,155.08,7.92;12,151.52,503.18,11.43,7.92">CEUR Workshop Proceedings, CEUR-WS</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
