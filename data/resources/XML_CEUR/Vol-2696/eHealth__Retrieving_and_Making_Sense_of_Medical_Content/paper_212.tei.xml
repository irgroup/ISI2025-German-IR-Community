<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,152.77,115.96,309.83,12.62;1,150.89,133.89,313.57,12.62;1,231.86,151.82,151.65,12.62;1,150.43,171.66,314.50,10.52">Multilingual ICD-10 Code Assignment with Transformer Architectures using MIMIC-III Discharge Summaries FHDO Biomedical Computer Science Group (BCSG)</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,215.18,207.69,71.15,8.74"><forename type="first">Henning</forename><surname>Sch√§fer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Arts Dortmund (FHDO)</orgName>
								<orgName type="institution">University of Applied Sciences</orgName>
								<address>
									<addrLine>Emil-Figge Str. 42</addrLine>
									<postCode>44227</postCode>
									<settlement>Dortmund</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,208.43,219.65,100.45,8.74"><forename type="first">Christoph</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
							<email>christoph.friedrich@fh-dortmund.de</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Computer Science</orgName>
								<orgName type="department" key="dep2">Arts Dortmund (FHDO)</orgName>
								<orgName type="institution">University of Applied Sciences</orgName>
								<address>
									<addrLine>Emil-Figge Str. 42</addrLine>
									<postCode>44227</postCode>
									<settlement>Dortmund</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Institute for Medical Informatics, Biometry and Epidemiology</orgName>
								<orgName type="institution">University Hospital Essen</orgName>
								<address>
									<settlement>Essen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,152.77,115.96,309.83,12.62;1,150.89,133.89,313.57,12.62;1,231.86,151.82,151.65,12.62;1,150.43,171.66,314.50,10.52">Multilingual ICD-10 Code Assignment with Transformer Architectures using MIMIC-III Discharge Summaries FHDO Biomedical Computer Science Group (BCSG)</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">506ECF0E1EC0FB3BE15AD15B0879E9E0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>BioBERT</term>
					<term>MIMIC-III</term>
					<term>Apriori</term>
					<term>XLNet</term>
					<term>ICD-10 Code Conversion</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this work, we present the participation of FHDO Biomedical Computer Science Group (BCSG) to the CLEF eHealth challenge 2020 Task 1 on automatic assignment of ICD-10 codes (CIE-10 in the Spanish translation) to clinical case studies. Training data has been augmented with documents from the Medical Information Mart for Intensive Care (MIMIC-III), a critical care database. ICD-10 CM General Equivalence Mappings (GEMs) were subsequently used to convert the codification from ICD-9 to ICD-10. Recent state-of-the-art Transformer-based models, such as BioBERT and ClinicalBERT are compared to the Generalized Autoregressive Pretraining for Language Understanding (XLNet) model. Finally, the apriori algorithm has been applied to build association rules by finding frequent item sets. An ensemble of BioBERT and XLNet achieved a mean Average Precision (MAP) score of 0.259 (0.306 for the subset of codes only present in the training and validation sets).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper describes the participation of FHDO Biomedical Computer Science Group (BCSG) to the Conference and Labs of the Evaluation Forum (CLEF) eHealth 2020 Task 1 Subtask 1 on Multilingual Information Extraction (IE), which focuses on International Statistical Classification of Diseases (ICD) coding for clinical textual data in Spanish <ref type="bibr" coords="1,310.04,615.24,15.50,8.74" target="#b19">[20,</ref><ref type="bibr" coords="1,325.54,615.24,11.62,8.74" target="#b11">12]</ref>. Diagnostic codes are used as a billing mechanism in the Electronic Health Record (EHR) and can be used for automatic semantic indexing of clinical documents, but also to facilitate decision support systems that aim to help clinical coders by suggesting a relevant subset of potential codes for selection. The problem can be described as a mapping from natural language free-texts to medical concepts such that, given a new document, the system can assign multiple codes to it.</p><p>In terms of application in the biomedical field, Bidirectional Encoder Representations from Transformers (BERT) has only recently been used for ICD code assignment tasks, such as classifying German animal experiments in CLEF eHealth 2019 <ref type="bibr" coords="2,195.10,226.79,11.62,8.74" target="#b2">[3,</ref><ref type="bibr" coords="2,206.72,226.79,11.62,8.74" target="#b26">27,</ref><ref type="bibr" coords="2,218.35,226.79,11.62,8.74" target="#b24">25]</ref>. While it has proven to work well on assigning a smaller subset of ICD codes, it is uncertain how Transformer architecture models can perform on arbitrary long clinical text and in solving extreme multi-label classification problems with a high average amount of assigned codes per document.</p><p>CLEF eHealth tracks feature the classification of multilingual clinical documents using ICD codes since 2016 <ref type="bibr" coords="2,282.10,286.76,16.13,8.74" target="#b21">[22,</ref><ref type="bibr" coords="2,298.23,286.76,12.10,8.74" target="#b22">23,</ref><ref type="bibr" coords="2,310.33,286.76,12.10,8.74" target="#b23">24,</ref><ref type="bibr" coords="2,322.42,286.76,12.10,8.74" target="#b24">25]</ref>. This work enriches training data with the Medical Information Mart for Intensive Care (MIMIC-III) database and compares BERT based models with XLNet <ref type="bibr" coords="2,326.19,310.67,14.61,8.74" target="#b31">[32]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>A hierarchy-based approach with Support Vector Machines (SVM) <ref type="bibr" coords="2,425.16,368.41,9.96,8.74" target="#b7">[8]</ref>, using the 'is-a' relationship between ICD-9 codes to model label dependencies has been an early approach to ICD coding <ref type="bibr" coords="2,268.25,392.32,14.61,8.74" target="#b25">[26]</ref>. The hierarchy-based classifier surpassed the flat SVM, which did not consider code dependencies. Other approaches identified label density and label noise as useful features <ref type="bibr" coords="2,350.95,416.23,14.61,8.74" target="#b28">[29]</ref>, while others empirically evaluated the simultaneous occurrence of labels <ref type="bibr" coords="2,345.03,428.19,14.61,8.74" target="#b15">[16]</ref>.</p><p>ML-NET <ref type="bibr" coords="2,192.21,440.34,15.50,8.74" target="#b9">[10]</ref> followed the hierarchy-based approach and extended the coding of documents. Its deep neural network consists of an additional network for estimating the number of labels. Instead of separating relevant vs. irrelevant labels by a threshold value, a network for predicting the number of labels was built by using the document vector as input.</p><p>Baumel et al. <ref type="bibr" coords="2,210.42,500.31,10.52,8.74" target="#b3">[4]</ref> evaluated 4 different models for ICD code assignment using data from MIMIC-II and MIMIC-III data sets. They presented a continuous bag-of-word model <ref type="bibr" coords="2,218.91,524.22,15.50,8.74" target="#b18">[19]</ref> (CBOW), a convolutional neural network, an SVM oneversus-all model and a bidirectional gated-recurrent unit model with hierarchical attention (HA-GRU).</p><p>Another proposed model is a code-wise attention network <ref type="bibr" coords="2,404.25,560.28,14.61,8.74" target="#b20">[21]</ref>, where attention mechanisms are used to extract n-grams from the text that are influential in predicting each code.</p><p>Unified Medical Language System (UMLS) <ref type="bibr" coords="2,335.20,596.34,10.52,8.74" target="#b4">[5]</ref> mapping and word embeddings have shown to be effective within text classification in the biomedical domain and improved results in automatic ICD coding <ref type="bibr" coords="2,325.30,620.25,14.61,8.74" target="#b27">[28]</ref>. The embeddings were selected by sequentially mapping discharge summaries to UMLS biomedical concepts in an approach to enrich word representations and to eliminate variations caused by tense, abbreviations and/or spelling mistakes.</p><p>For training data, two different sources were used: The offical CodiEsp dataset<ref type="foot" coords="3,476.12,140.55,3.97,6.12" target="#foot_0">3</ref> with manually generated ICD-10 codifications, and the MIMIC-III database with the older ICD-9 classification system in use, which are mappable to discharge summaries <ref type="bibr" coords="3,183.40,177.99,14.61,8.74" target="#b14">[15]</ref>. When exploring other additional resources, such as the abstracts collected from Lilacs and Ibecs<ref type="foot" coords="3,272.55,188.37,3.97,6.12" target="#foot_1">4</ref> , the MIMIC-III database was selected as the main data source for augmentation, because it seems to be the most similar database compared to the CodiEsp corpus. Among the free text narrative structured documents describing hospital courses, it has a high average amount of manually assigned codes per document coming from real-world EHRs. With the decision to use the MIMIC-III dataset for augmentation it was also decided to focus on the English translated documents of CodiEsp corpus. A key difference between the two data sources is that the codification for CodiEsp is a semantic mapping of concepts, where the assigned codes do not have to be based on medical outcome. For example, a negative serum test (as seen in Listing 1.1) for CodiEsp still results in appropriately assigned ICD-10 codes, whereas it would not appear on MIMIC-III.</p><p>Listing 1.1. Excerpt of CodiESP Document with id S0211-69952009000500014-1, showing results of a blood serum test and codification (Assigned Codes List: r80.9, r20.2, b19.20, b19.10, r23.8, r60.0, r10.9, r19.7, m25.50, l98.9, b20).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>[ . . . ]</head><p>On p h y s i c a l e x a m i n a t i o n : b l o o d p r e s s u r e 104/76 mmHg, BMI 2 7 , minimal edema i n l o w e r l i m b s and p a p u l e s i n e l b o w s and arms . Blood count and c o a g u l a t i o n were normal , c r e a t i n i n e 0 . 9 mg/ dl , t o t a l c h o l e s t e r o l 238 mg/ dl , t r i g l y c e r i d e s 104 mg/ dl , t o t a l p r o t e i n 6 . 5 g / d l and albumin 3 . 6 g / d l . A n t i c a r d i o l i p i n a n t i b o d i e s a n t i c a r d i o l i p i n : S e r o l o g y a g a i n s t HBV, HCV and HIV was n e g a t i v e .</p><p>[ . . . ]</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">CodiEsp Corpus</head><p>The CodiEsp corpus consists of 1,000 clinical case studies manually selected by a practicing physician and a clinical documentarian <ref type="bibr" coords="3,382.61,555.24,14.61,8.74" target="#b19">[20]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">MIMIC-III Corpus</head><p>The MIMIC-III database comprises de-identified records from Beth Israel Deaconess Medical Center intensive care unit (ICU) stays, collected between 2001 and 2012. It contains 59,652 discharge summaries with an average of 11.48 codes assigned per document. It has 119,171 unique tokens with 1,947 tokens and 112 sentences on average. The dataset is in principle very well suited but has some characteristics that need to be adapted. The coding system is ICD-9, which has to be converted to ICD-10 accordingly to match the CodiEsp codification. In addition, the dataset only contains summaries of intensive care unit stays, which on average exceed the maximum length of tokens available for Transformer architectures. After conversion, the dataset contains 5,447 distinct codes as seen in Figure <ref type="figure" coords="4,177.83,294.43,20.34,8.74" target="#fig_4">1 (b)</ref>.</p><p>Segmentation For BERT <ref type="bibr" coords="4,256.09,321.37,10.52,8.74" target="#b8">[9]</ref> models, the maximum length of a sequence after tokenizing is 512, resulting in an effective limit of 510 tokens for the input layer after subtracting the [CLS] and [SEP] tokens. Because MIMIC-III discharge summaries have an average length of 1,947 tokens (see Table <ref type="table" coords="4,393.37,357.24,4.43,8.74" target="#tab_1">1</ref>) with only 11.67 % of all documents not exceeding 510 tokens, the data has to be truncated in order to fit into the Transformer model.</p><p>A simple approach as supposed by Sun et. al. <ref type="bibr" coords="4,364.25,393.10,15.50,8.74" target="#b29">[30]</ref> would be to only use the first 510 tokens (head-only) or to use the last 510 tokens (tail-only) of a document, but none of them seem to be appropriate for truncating clinical text without losing relevant information.</p><p>When inspecting the summaries, even though they are free text narratives, a fixed structure has been identified in most of the documents: They usually start with a Chief Complaint followed by a historical Background section, which may include History of Present Illness, Past Medical History, Social History and Family History. During Diagnostics and Pertinent Results, the structure is no longer as consistent and different sections appear, which are more dependent on the individual case. From the middle towards the end of the documents there is a section called Brief Hospital Course, which summarizes the ICU stay followed by discharge condition instructions and/or followup instructions.</p><p>In early experiments, the effect of using different segments was evaluated. Here, it was found that using the first 510 tokens (head-only) of discharge summaries decreased the performance in comparison to using the last 510 tokens (tail-only). It can be assumed that this is because the background history, which comes at the top of the documents, is not as relevant to the clinical coding as the narrative over the actual present hospital course. It was decided to remove content up to the Brief Hospital Course section and sequentially use the remaining document up to whatever fits into 510 tokens. 7, 822 documents were omitted where this section was not present, resulting in 13 % loss of data. Descriptive statistics of the segmented corpus can be seen in Table <ref type="table" coords="4,377.55,656.12,3.87,8.74" target="#tab_1">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Transformer architecture and BERT</head><p>BERT and Transformer <ref type="bibr" coords="5,240.23,632.21,10.52,8.74" target="#b8">[9]</ref> have proven to be extremely effective in many downstream natural language processing (NLP) tasks. While it works well on assigning a smaller subset of ICD codes <ref type="bibr" coords="5,265.64,656.12,11.14,8.74" target="#b2">[3,</ref><ref type="bibr" coords="5,276.78,656.12,11.14,8.74" target="#b26">27]</ref>, it is uncertain how BERT models can work     with clinical texts of any length and in solving extreme multi-label classification problems with a high average number of assigned codes per document. Though the MIMIC-III augmentation does not fit into the token limitation without clipping documents, the Transformer architecture offers good innovations that can be practical in the classification of clinical text. The word tokenizer allows words that are outside the vocabulary to be represented by word pieces instead of simply assigning them to an unknown token, which is why it was selected for the first tests. This feature is particularly useful for discharge summaries, as spelling mistakes and non-standard abbreviations are common.</p><p>Bidirectional Encoder Representations from Transformers for Biomedical Text Mining (BioBERT) <ref type="bibr" coords="6,223.64,644.16,15.50,8.74" target="#b17">[18]</ref> and ClinicalBERT <ref type="bibr" coords="6,328.03,644.16,10.52,8.74" target="#b1">[2]</ref> have the same architecture but are pre-trained on large-scale biomedical corpora. BioBERT has been pre-trained on PubMed abstracts<ref type="foot" coords="7,227.32,117.42,3.97,6.12" target="#foot_2">5</ref> and PMC <ref type="foot" coords="7,276.61,117.42,3.97,6.12" target="#foot_3">6</ref> full-text articles. Bio ClinicalBERT<ref type="foot" coords="7,437.42,117.42,3.97,6.12" target="#foot_4">7</ref> is an extended model that was also pre-trained on all notes from MIMIC-III (880M words). The Bio ClinicalBERT model was selected because of the larger pretraining.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">XLNet</head><p>The recently proposed Generalized Autoregressive Pretraining for Language Understanding (XLNet) model <ref type="bibr" coords="7,261.20,217.92,15.50,8.74" target="#b31">[32]</ref> is an autoregressive language model (LM). It is important to note that although BERT and XLNet have many similarities, there are some differences that need to be explained. Here, autoregressive means that XLNet makes use of the TransformerXL <ref type="bibr" coords="7,337.81,253.78,15.50,8.74" target="#b13">[14]</ref> to capture information from previous sequences in order to process the current sequence, and achieving the regressive effect at the sequence level. XLNet uses relative position coding and a permutation LM, by factorizing the output with all possible permutations.</p><p>The permutation effect is limited to words which are "attended" to. This is done by changing the attention mask prior to the attention softmax while keeping track of the positional information in a sequence. For example, during pre-training, to predict a token t, the attention mask is set to minimum numbers for tokens that appear after position i &gt; t. Only the tokens before and including t on the current factorization are used to compute the attention. The advantage is that the tokens that come before t change with each permutation, but their positions within the sequence are kept constant, allowing XLNet to capture bidirectional context.</p><p>XLNet implements the Multi-head attention, which is slightly different from the one in BERT, where it is known that it generates a query Q, a key K, and a value V projection of each word in the input sentence. For each query Q, the Multi-head attention Layer uses K to compute an attention score for each value vector V and then sums the value vectors into a single representation using the attention weights <ref type="bibr" coords="7,213.13,469.23,9.96,8.74" target="#b6">[7]</ref>.</p><p>For XLNet, linear layers are used to map the input to the Multi-head attention layer directly. This results in mapping the input into smaller space with the same number of dimensions that add up to the original dimension as known for BERT. This allows each word to attend more to other words and not only to itself, which results in a final richer representation of each word.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Preprocessing</head><p>Because the discharge summaries were de-identified free text narratives, additional pre-processing steps were taken to convert them into a sequence of sentences, removing all numbers, and name placeholders. Leading and trailing spaces, quotations and semicolons have also been removed. For the CodiESP corpus, no pre-processing was applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Training the models</head><p>The experiments were done with the PyTorch-transformers implementations of BERT and XLNet 8 . The overall end-to-end training process can be seen in Figure <ref type="figure" coords="8,134.77,204.86,3.87,8.74" target="#fig_5">2</ref>. The models were fine-tuned on all layers without freezing. As proposed by the original papers <ref type="bibr" coords="8,201.07,216.82,11.15,8.74" target="#b8">[9,</ref><ref type="bibr" coords="8,212.22,216.82,11.15,8.74" target="#b31">32]</ref>, Adam <ref type="bibr" coords="8,258.41,216.82,15.50,8.74" target="#b16">[17]</ref> was used in early experiments as the optimizier, but was then replaced by the Layerwise Adaptive Large Batch (LAMB) optimizer <ref type="bibr" coords="8,134.77,240.73,15.50,8.74" target="#b32">[33]</ref> because it resulted in a slightly reduced training time. The hyperparameters have been selected and optimized based on the development set performance. Using a learning rate of 7e-4 or 6e-4 resulted in the best scores, though the Transformer model seems to react very sensitively to the use of different learning rates, because selecting different settings often led to poor results.</p><p>Different warmup schedules were tried, but had no impact on the results. Among the two versions of BERT cased and uncased, it was found that overall the uncased version works slightly better. However, the difference is still very small. For XLNet, the only available version is cased. The base version of XLNet was preferred over the large version due to computational expense. The training batch size was 8 for XLNet and 16 for BERT models. To produce the ranking of the codes, Binary cross-entropy with logits was used to obtain confidence for each ICD-10 code during inference. They were then ordered by confidence and cut off with a threshold of t = 0.4. The prediction pipeline of the BERT model including the association rules is shown in figure <ref type="figure" coords="8,349.29,408.12,3.87,8.74" target="#fig_6">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Apriori Association Rules</head><p>The apriori algorithm <ref type="bibr" coords="8,236.09,458.12,10.52,8.74" target="#b0">[1]</ref> has been used to find frequent itemsets in a list of transactions but recently has also been in use to find association rules and label co-occurrences in clinical text, such as in autopsy reports <ref type="bibr" coords="8,385.68,482.03,14.61,8.74" target="#b10">[11]</ref>. Association rules can be obtained with the support and confidence parameter, where the support of a set of items is the probability that this set of items occurs in a transaction. Confidence refers to the likelihood that an item B will also be purchased when item A is purchased. It can be calculated by dividing the number of transactions where A and B are bought together by the total number of transactions where A is bought. To identify and explore co-occurrences, a low min support (0.02) value has been used on the CodiEsp train and development set. The resulting apriori association rules as seen in Figure <ref type="figure" coords="8,316.11,577.67,4.98,8.74">6</ref> have been plotted with the arulesviz [13] R package. The graph shows 59 rules.</p><p>One example for a relation is Hepatitis B and C as shown by the rule that connects b19.10 and b19.20. When exploring the data, it was found that this rule refers to serology tests, that often include test results for different viruses, such as hepatitis B and C. An example can be seen in Listing 1.1. Another confident  rule is that localized enlarged lymph nodes (r59.0 and r59.9) links to unspecified fever (r50.9), which then links to unspecified pain (r52). As such rules should be covered by the trained model, not that many different rulesets have been tested and added during inference.</p><p>However, the 11-ruleset as seen in Figure <ref type="figure" coords="10,343.47,166.81,4.98,8.74">5</ref> improved the mean Average Precision (MAP) results on the development set between 0 % to 1.2 % depending on model and was therefore added to final submission if missed out. The submission guideline requires that the prediction is ordered by confidence. Because the predicted confidence cannot be compared with apriori support or confidence values and because the confidence of the primary model was not high enough, the association rule codes were added at the end. They were ranked by highest level of support.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussion</head><p>Figure <ref type="figure" coords="10,166.15,306.29,4.98,8.74">4</ref> shows experimental runs on the development set for the tested models with different pre-trained embeddings and different frequent Top code subsets. This results in different enriched training data and also in a different amount of labels a model is able to predict. A comparison of how many documents end up in the training data can be seen in Table <ref type="table" coords="10,340.41,354.11,3.87,8.74">3</ref>. The final best results on the development set for each model can be seen in Table <ref type="table" coords="10,367.91,366.07,3.87,8.74">2</ref>.</p><p>While the F1-Score is superior on models which are only able to predict the Top 50 frequent codes, the MAP score penalises this behaviour on the full set, because not only the classification but also the positional ranking is taken into consideration. When matching the Top 50 most frequent codes with MIMIC-III there is not enough data available for augmentation (363 additional documents). Starting with the Top 100 most frequent codes, improvements coming from the additional data can be seen. The augmentation improves the reported MAP score by 0.097 (0.128 F1) for the XLNet model. Increasing the training data further increases recall, but decreases precision.</p><p>The final test set results for evaluation were reported by the task organisers and can be seen in Table <ref type="table" coords="10,240.34,497.57,3.87,8.74">4</ref>. On the test set, the Bio ClinicalBERT model achieved the overall best performance for a single model with a MAP score of 0.259. XLNet on Top 100 frequent codes achieved the best performance in precision.</p><p>When the goldstandard for the test set was released, it was evaluated how many of the unseen codes would have been explainable by keeping the remaining annotated codes of each MIMIC-III document within the training data (Knowledge Discovery). Figure <ref type="figure" coords="10,242.42,569.31,22.10,8.74" target="#fig_4">1 (d)</ref> shows that for the Top 100 most frequent codes training set, 56 distinct unseen codes would have been explainable. Here, a small performance improvement can be expected, but it is noteworthy that only a few of the codes were seen more than once in the test data (76 appearances in total). Because they were unseen before, it can be assumed that these are codes with rare appearances. It can be concluded that more resources are needed to be able to explain the full code set. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>This work compared BERT based models with XLNet. The effect of enriching training data with documents from MIMIC-III was evaluated. Here, it was found that the MIMIC-III augmentation with code conversion was able to improve the results compared to using only the stock data set. The apriori algorithm has been applied to build and explore association rules by finding frequent item sets. The 11-ruleset was able to improve the mean Average Precision (MAP) results on the development set between 0 % and 1.2 %. Among the submitted models, the ensemble of BioBERT and XLNet achieved the highest mean Average Precision (MAP) score of 0.259 (0.306 for the subset of codes only present in the train and validation sets). In terms of single model performance, the Bio ClinicalBERT model achieved overall best performance. The XLNet, even though pre-trained on generic text has the highest precision value on the test set and overall best performance on the development set.</p><p>Though the models are still far from achieving good results on the full label set, the task has been very challenging with many possible labels, given only a relatively small dataset. It was found that the large MIMIC-III database is not able to cover all unseen codes, so it can be concluded that more resources are needed to be able to explain the full code set.</p><p>In future work, XLNets attention should be further evaluated because the sequence dependency on the hidden states of previous sequences can be adjusted by a memory length hyper-parameter. It will be interesting to tune and see the impact of this parameter, but also to test and see how a domain-specific XLNet model performs when pre-trained on large biomedical data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,164.57,167.74,13.26,9.85;6,266.43,167.74,9.94,9.85;6,224.42,167.74,9.94,9.85;6,179.16,231.02,43.67,11.83;6,228.79,214.83,25.63,11.83;6,142.32,258.43,144.80,7.86;6,142.32,269.38,51.65,7.86"><head></head><label></label><figDesc>CodiEsp Train Dev and Test Distribution.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,340.73,181.98,11.65,8.66;6,433.13,179.00,8.74,8.66;6,392.59,176.04,8.74,8.66;6,412.99,224.18,8.74,8.66;6,388.17,214.14,8.74,8.66;6,420.43,203.21,8.74,8.66;6,398.05,194.95,8.74,8.66;6,305.36,130.95,38.28,10.39;6,431.69,149.55,38.38,10.39;6,398.49,233.37,22.53,10.39;6,305.56,258.43,167.48,7.86;6,305.56,269.38,53.56,7.86"><head></head><label></label><figDesc>MIMIC-III and CodiEsp Train Dev and Test Set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,176.71,328.24,8.90,8.82;6,252.18,374.02,8.90,8.82;6,215.79,352.26,8.90,8.82;6,241.82,342.86,5.93,8.82;6,225.73,343.81,5.93,8.82;6,142.14,299.89,38.97,10.58;6,242.35,328.77,41.87,10.58;6,227.67,413.82,22.93,10.58;6,142.32,438.84,144.80,7.86;6,142.32,449.80,90.85,7.86"><head></head><label></label><figDesc>MIMIC-III with 50 % in Top 100 CodiEsp and Test Set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="6,335.24,344.48,8.94,8.86;6,424.63,337.13,11.92,8.86;6,372.45,337.13,8.94,8.86;6,381.44,400.90,8.94,8.86;6,360.67,373.53,5.96,8.86;6,401.31,370.43,8.94,8.86;6,377.42,359.08,8.94,8.86;6,305.46,312.04,39.15,10.63;6,430.61,300.88,39.26,10.63;6,379.42,413.50,23.04,10.63;6,305.56,438.84,167.48,7.86;6,305.56,449.80,152.94,7.86"><head></head><label></label><figDesc>MIMIC-III with 50 % in Top 100 CodiEsp and Train Dev and Test Set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="6,134.77,470.25,345.83,7.89;6,134.77,481.23,135.72,7.86"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Venn diagrams showing the distribution of the number of distinct ICD-10 codes for different datasets and subsets.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="9,134.77,322.96,345.82,7.89;9,134.77,333.94,345.83,7.86;9,134.77,344.90,237.36,7.86"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Workflow of end-to-end training process. Unannotated pre-training (on large corpora) and annotated fine-tuning with combined resources (CodiEsp and MIMIC-III). The weights from pre-training phase were transferred.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="9,134.77,618.91,345.83,7.89;9,134.77,629.90,345.83,7.86;9,134.77,640.85,321.43,7.86"><head>Fig. 3 .</head><label>3</label><figDesc>Fig.3. Inference for BERT models with apriori association rules. The text-input is classified with BCELoss function to get probabilities for all available ICD codes. The confidence must be at least t = 0.4 (threshold) to count as a positive ICD code.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="12,134.77,599.38,345.82,7.89;12,134.77,610.37,183.30,7.86"><head>Fig. 5 .Fig. 6 .</head><label>56</label><figDesc>Fig. 5. Graph for 11 ICD-10 apriori association rules. Size: min support(0.03) min confidence(0.3), Color: lift(1.393-20.294).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,134.77,115.91,345.83,447.58"><head>Table 1 .</head><label>1</label><figDesc>MIMIC-III, CodiESP Training and Development dataset descriptive statistics. (*) denotes the segmented corpus. These codes are less generic, apply to the ICU cases and are not covered by the smaller CodiEsp corpus. To make the data augmentation more practical, only documents where 50 % or more of the assigned codes are present in the Top 100, Top 250 or Top 500 frequent codes of the CodiEsp training and development set were used (impact on training size can be seen in Table3). Only discharge summaries containing the Brief Hospital Course section were selected by using a regular expression match, resulting in 51,830 out of 59,652 available documents.Available data augmentation increases when changing the Top frequent code amount, because the criteria/matching rule, if a document has 50 % or more codes is less strict, resulting in more MIMIC-III documents ending up in training data. Increasing the augmentation data in that way increases recall, but reduces precision (see Table4). A good compromise was to create a model that is able to predict the Top 100 frequent codes in CodiEsp.</figDesc><table coords="5,147.32,148.17,320.71,84.97"><row><cell></cell><cell cols="3">MIMIC-III MIMIC-III* CodiESP Train Dev</cell></row><row><cell cols="2">Number of records with ICD code 59,652</cell><cell>51,830</cell><cell>750</cell></row><row><cell>Number of unique tokens</cell><cell cols="2">1,091,025 276,500</cell><cell>26,696</cell></row><row><cell>Number of bigrams</cell><cell cols="2">10,609,279 2,846,377</cell><cell>114,846</cell></row><row><cell>Number of trigrams</cell><cell cols="2">27,814,651 7,873,155</cell><cell>180,650</cell></row><row><cell>Avg. number of tokens / record</cell><cell>1,947</cell><cell>427</cell><cell>301</cell></row><row><cell cols="2">Avg. number of sentences / record 112</cell><cell>39</cell><cell>19</cell></row><row><cell>Avg. number of labels / record</cell><cell>11.48</cell><cell>11.45</cell><cell>11.09</cell></row></table><note coords="5,134.77,261.13,345.83,8.77;5,134.77,273.11,345.82,8.74;5,134.77,285.07,345.82,8.74;5,134.77,297.02,345.83,8.74;5,134.77,308.98,345.82,8.74;5,134.77,320.93,205.43,8.74;5,134.77,351.37,345.83,8.77;5,134.77,363.35,345.83,8.74;5,134.77,375.31,345.83,8.74;5,134.77,387.26,345.82,8.74;5,134.77,399.22,51.26,8.74"><p><p><p><p><p><p><p><p>ICD-9 code Conversion with General Equivalence Mappings ICD-9 codes of the MIMIC-III database have been converted to ICD-10 using the publicly available ICD-10 CM General Equivalence Mappings (GEMs)</p><ref type="bibr" coords="5,428.23,285.07,9.96,8.74" target="#b5">[6]</ref></p>. Turer et al. assessed the reliability of conversion between ICD-9 and ICD-10 and found that manual coding from the forward GEMs and backward GEMs were reproducible by 85.2 % and 90.4 % respectively</p><ref type="bibr" coords="5,321.93,320.93,14.61,8.74" target="#b30">[31]</ref></p>.</p>Data Selection Because of the different data sources and MIMIC-III being limited to ICU cases, both datasets have been compared in terms of their distinct code subsets. As seen in Figure</p>1</p>(b), the MIMIC-III data contains 4,156 unique ICD-10 codes that are not present in the CodiEsp train, development, and testset.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="3,144.73,645.84,281.44,8.12"><p>https://doi.org/10.5281/zenodo.3625746, last accessed 2020-07-17</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="3,144.73,656.80,281.44,8.12"><p>https://doi.org/10.5281/zenodo.3606625, last accessed 2020-07-17</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="7,144.73,623.92,253.18,8.12"><p>https://pubmed.ncbi.nlm.nih.gov/, last accessed 2020-07-17</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3" coords="7,144.73,634.88,257.89,8.12"><p>https://www.ncbi.nlm.nih.gov/pmc/, last accessed 2020-07-17</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4" coords="7,144.73,645.84,335.86,8.12;7,144.73,656.80,70.76,7.86"><p>https://huggingface.co/emilyalsentzer/Bio_Discharge_Summary_BERT, last accessed 2020-07-17</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="14,142.96,220.56,337.64,7.86;14,151.52,231.52,329.07,7.86;14,151.52,242.48,118.27,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="14,258.94,220.56,181.12,7.86">Fast algorithms for mining association rules</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Srikant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,463.04,220.56,17.56,7.86;14,151.52,231.52,323.94,7.86">Proceedings of the 20th International Conference on Very Large Data Bases (VLDB)</title>
		<meeting>the 20th International Conference on Very Large Data Bases (VLDB)</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">1215</biblScope>
			<biblScope unit="page" from="487" to="499" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,253.24,337.64,7.86;14,151.52,264.20,329.07,7.86;14,151.52,275.16,329.07,7.86;14,151.52,286.12,329.07,7.86;14,151.52,297.08,158.52,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="14,210.94,264.20,184.98,7.86">Publicly available clinical BERT embeddings</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Alsentzer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Boag</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">H</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Naumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mc-Dermott</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W19-1909</idno>
		<ptr target="https://doi.org/10.18653/v1/W19-1909" />
	</analytic>
	<monogr>
		<title level="m" coord="14,420.55,264.20,60.04,7.86;14,151.52,275.16,237.84,7.86">Proceedings of the 2nd Clinical Natural Language Processing Workshop</title>
		<meeting>the 2nd Clinical Natural Language Processing Workshop<address><addrLine>Minneapolis, Minnesota, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06">Jun 2019</date>
			<biblScope unit="page" from="72" to="78" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,307.84,337.63,7.86;14,151.52,318.80,329.07,7.86;14,151.52,329.76,329.07,7.86;14,151.52,340.72,89.86,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="14,179.22,318.80,301.38,7.86;14,151.52,329.76,71.64,7.86">MLT-DFKI at CLEF eHealth 2019: Multi-label Classification of ICD-10 Codes with BERT</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Amin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Dunfield</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vechkaeva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">A</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">K</forename><surname>Wixted</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,246.69,329.76,233.90,7.86;14,151.52,340.72,61.20,7.86">Working Notes of Conference and Labs of the Evaluation (CLEF) Forum</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,351.49,337.64,7.86;14,151.52,362.45,329.07,7.86;14,151.52,373.41,277.62,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="14,436.05,351.49,44.54,7.86;14,151.52,362.45,263.84,7.86">Multi-label classification of patient notes: case study on ICD code assignment</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Baumel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Nassour-Kassis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Elhadad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Elhadad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,436.70,362.45,43.89,7.86;14,151.52,373.41,248.95,7.86">Workshops at the thirty-second AAAI conference on artificial intelligence</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,384.17,337.63,7.86;14,151.52,395.10,318.01,7.89" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="14,227.46,384.17,253.13,7.86;14,151.52,395.13,91.63,7.86">The unified medical language system (UMLS): integrating biomedical terminology</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Bodenreider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,250.36,395.13,88.22,7.86">Nucleic acids research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">suppl 1</biblScope>
			<biblScope unit="page" from="267" to="D270" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,405.90,337.64,7.86;14,151.52,416.83,211.33,7.89" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="14,207.43,405.90,273.16,7.86;14,151.52,416.86,44.50,7.86">ICD-10 general equivalence mappings: Bridging the translation gap from ICD-9</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">R</forename><surname>Butler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,203.63,416.86,76.42,7.86">Journal of AHIMA</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="84" to="86" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,427.62,337.63,7.86;14,151.52,438.58,329.07,7.86;14,151.52,449.54,329.07,7.86;14,151.52,460.50,202.04,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="14,364.77,427.62,115.82,7.86;14,151.52,438.58,138.75,7.86">What Does BERT Look at? An Analysis of BERT&apos;s Attention</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Khandelwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W19-4828</idno>
		<ptr target="https://doi.org/10.18653/v1/W19-4828" />
	</analytic>
	<monogr>
		<title level="m" coord="14,313.72,438.58,166.87,7.86;14,151.52,449.54,273.04,7.86">Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</title>
		<meeting>the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP</meeting>
		<imprint>
			<date type="published" when="2019-01">01 2019</date>
			<biblScope unit="page" from="276" to="286" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,471.24,337.63,7.89;14,151.52,482.22,25.60,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="14,245.59,471.27,96.81,7.86">Support-vector networks</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,349.28,471.27,68.70,7.86">Machine learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,492.99,337.63,7.86;14,151.52,503.92,323.13,7.89" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="14,338.64,492.99,141.95,7.86;14,151.52,503.95,187.97,7.86">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno>CoRR abs/1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,514.72,337.97,7.86;14,151.52,525.68,329.07,7.86;14,151.52,536.61,329.07,7.89;14,151.52,547.59,153.41,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="14,415.42,514.72,65.17,7.86;14,151.52,525.68,287.93,7.86">ML-Net: multilabel classification of biomedical texts with deep neural networks</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.1093/jamia/ocz085</idno>
		<ptr target="https://doi.org/10.1093/jamia/ocz085" />
	</analytic>
	<monogr>
		<title level="j" coord="14,450.24,525.68,30.35,7.86;14,151.52,536.63,212.01,7.86">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1279" to="1285" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,558.36,337.98,7.86;14,151.52,569.32,329.07,7.86;14,151.52,580.25,293.10,7.89" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="14,353.07,558.36,127.52,7.86;14,151.52,569.32,235.46,7.86">Deep neural models for ICD-10 coding of death certificates and autopsy reports in free-text</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Duarte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">S</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Silva</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jbi.2018.02.011</idno>
		<ptr target="https://doi.org/10.1016/j.jbi.2018.02.011" />
	</analytic>
	<monogr>
		<title level="j" coord="14,393.21,569.32,87.38,7.86;14,151.52,580.28,45.64,7.86">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="64" to="77" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,591.04,337.98,7.86;14,151.52,602.00,329.07,7.86;14,151.52,612.96,329.07,7.86;14,151.52,623.92,329.07,7.86;14,151.52,634.88,329.07,7.86;14,151.52,645.84,329.07,7.86;14,151.52,656.80,148.63,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="14,357.72,602.00,122.87,7.86;14,151.52,612.96,80.83,7.86">Overview of the CLEF eHealth Evaluation Lab 2020</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Miranda-Escalada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Krallinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Pasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Saez Gonzales</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Viviani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,466.39,623.92,14.21,7.86;14,151.52,634.88,329.07,7.86;14,151.52,645.84,298.47,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction: Proceedings of the Eleventh International Conference of the CLEF Association (CLEF</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Joho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Lioma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>N√©v√©ol</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="volume">number</biblScope>
			<biblScope unit="page">12260</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,119.67,337.98,7.86;15,151.52,130.63,162.09,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="15,271.99,119.67,208.61,7.86;15,151.52,130.63,31.50,7.86">arulesviz: Visualizing association rules and frequent itemsets</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hahsler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chelluboina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,190.02,130.63,72.39,7.86">R package version</title>
		<imprint>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="page" from="1" to="5" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,141.60,337.97,7.86;15,151.52,152.56,329.07,7.86;15,151.52,163.52,329.07,7.86;15,151.52,174.48,155.32,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="15,254.83,141.60,225.75,7.86;15,151.52,152.56,28.67,7.86">Universal language model fine-tuning for text classification</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ruder</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P18-1031</idno>
		<ptr target="https://doi.org/10.18653/v1/P18-1031" />
	</analytic>
	<monogr>
		<title level="m" coord="15,205.77,152.56,274.82,7.86;15,151.52,163.52,109.03,7.86">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018-01">01 2018</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="328" to="339" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct coords="15,142.62,185.45,337.97,7.86;15,151.52,196.41,329.07,7.86;15,151.52,207.34,219.67,7.89" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="15,357.42,196.41,123.17,7.86;15,151.52,207.37,83.94,7.86">MIMIC-III, a freely accessible critical care database</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">J</forename><surname>Pollard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">L</forename><surname>Li-Wei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Moody</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Szolovits</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Celi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">G</forename><surname>Mark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,242.76,207.37,57.08,7.86">Scientific data</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,218.34,337.97,7.86;15,151.52,229.30,329.07,7.86;15,151.52,240.23,329.07,7.89" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="15,287.23,218.34,193.36,7.86;15,151.52,229.30,272.73,7.86">An empirical evaluation of supervised learning approaches in assigning diagnosis codes to electronic medical records</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kavuluru</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rios</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.artmed.2015.04.007</idno>
		<ptr target="https://doi.org/10.1016/j.artmed.2015.04.007" />
	</analytic>
	<monogr>
		<title level="j" coord="15,430.82,229.30,49.77,7.86;15,151.52,240.26,86.85,7.86">Artificial Intelligence in Medicine</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">05</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,251.23,337.98,7.86;15,151.52,262.19,329.07,7.86;15,151.52,273.14,329.07,7.86;15,151.52,284.10,25.60,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="15,244.82,251.23,182.98,7.86">Adam: A method for stochastic optimization</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,240.03,262.19,240.56,7.86;15,151.52,273.14,42.85,7.86">3rd International Conference on Learning Representations, ICLR 2015</title>
		<title level="s" coord="15,358.32,273.14,122.27,7.86">Conference Track Proceedings</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</editor>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">May 7-9, 2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,295.07,337.98,7.86;15,151.52,306.03,329.07,7.86;15,151.52,316.99,280.90,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="15,430.36,295.07,50.23,7.86;15,151.52,306.03,324.76,7.86">BioBERT: a pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/btz682</idno>
		<ptr target="https://doi.org/10.1093/bioinformatics/btz682" />
	</analytic>
	<monogr>
		<title level="j" coord="15,151.52,316.99,58.56,7.86">Bioinformatics</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,327.96,337.97,7.86;15,151.52,338.92,329.07,7.86;15,151.52,349.88,290.51,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="15,343.93,327.96,136.66,7.86;15,151.52,338.92,112.23,7.86">Efficient Estimation of Word Representations in Vector Space</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno>abs/1301.3781</idno>
	</analytic>
	<monogr>
		<title level="m" coord="15,285.08,338.92,195.51,7.86;15,151.52,349.88,71.01,7.86">1st International Conference on Learning Representations (ICLR)</title>
		<meeting><address><addrLine>Scottsdale, Arizona, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,360.85,337.98,7.86;15,151.52,371.81,329.07,7.86;15,151.52,382.77,329.07,7.86;15,151.52,393.73,329.07,7.86;15,151.52,404.69,76.75,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="15,151.52,371.81,329.07,7.86;15,151.52,382.77,249.95,7.86">Overview of automatic clinical coding: annotations, guidelines, and solutions for non-english clinical cases at codiesp track of CLEF eHealth</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Miranda-Escalada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gonzalez-Agirre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Armengol-Estap√©</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Krallinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,446.52,382.77,34.07,7.86;15,151.52,393.73,329.07,7.86;15,151.52,404.69,48.07,7.86">Working Notes of Conference and Labs of the Evaluation (CLEF) Forum. CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,415.66,337.97,7.86;15,151.52,426.61,329.07,7.86;15,151.52,437.57,329.07,7.86;15,151.52,448.53,329.07,7.86;15,151.52,459.49,155.96,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="15,433.10,415.66,47.49,7.86;15,151.52,426.61,201.68,7.86">Explainable Prediction of Medical Codes from Clinical Text</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mullenbach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wiegreffe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Duke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Eisenstein</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N18-1100</idno>
		<ptr target="https://doi.org/10.18653/v1/N18-1100" />
	</analytic>
	<monogr>
		<title level="m" coord="15,378.58,426.61,102.01,7.86;15,151.52,437.57,329.07,7.86;15,151.52,448.53,226.21,7.86">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1101" to="1111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,470.46,337.97,7.86;15,151.52,481.42,329.07,7.86;15,151.52,492.38,329.07,7.86;15,151.52,503.31,78.56,7.89" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="15,380.84,481.42,99.75,7.86;15,151.52,492.38,181.52,7.86">Clinical Information Extraction at the CLEF eHealth Evaluation lab</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>N√©v√©ol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lavergne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Tannier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zweigenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,359.83,492.38,120.76,7.86">CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="volume">1609</biblScope>
			<biblScope unit="page" from="28" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,514.31,337.98,7.86;15,151.52,525.27,329.07,7.86;15,151.52,536.23,329.07,7.86;15,151.52,547.19,329.07,7.86;15,151.52,558.14,181.66,7.86" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="15,294.36,525.27,186.23,7.86;15,151.52,536.23,329.07,7.86;15,151.52,547.19,25.36,7.86">CLEF eHealth 2017 Multilingual Information Extraction task Overview: ICD10 Coding of Death Certificates in English and French</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>N√©v√©ol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grouin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lavergne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Rondet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zweigenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,201.27,547.19,279.32,7.86;15,151.52,558.14,152.99,7.86">Working Notes of Conference and Labs of the Evaluation (CLEF) Forum. CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,569.11,337.98,7.86;15,151.52,580.07,329.07,7.86;15,151.52,591.03,329.07,7.86;15,151.52,601.99,329.07,7.86;15,151.52,612.95,181.66,7.86" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="15,277.75,580.07,202.84,7.86;15,151.52,591.03,329.07,7.86;15,151.52,601.99,43.17,7.86">CLEF eHealth 2018 Multilingual Information Extraction Task Overview: ICD10 Coding of Death Certificates in French, Hungarian and Italian</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>N√©v√©ol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Grippo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Morgand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Orsi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Pelikan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ramadier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zweigenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,215.35,601.99,265.24,7.86;15,151.52,612.95,152.99,7.86">Working Notes of Conference and Labs of the Evaluation (CLEF) Forum. CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,623.92,337.97,7.86;15,151.52,634.88,329.07,7.86;15,151.52,645.84,329.07,7.86;15,151.52,656.80,149.77,7.86" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="15,197.81,634.88,282.79,7.86;15,151.52,645.84,14.75,7.86">Overview of the CLEF eHealth 2019 multilingual information extraction</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Butzke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>D√∂rendahl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Leich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Hummel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sch√∂nfelder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Grune</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,186.41,645.84,294.18,7.86;15,151.52,656.80,121.10,7.86">Working Notes of Conference and Labs of the Evaluation (CLEF) Forum. CEUR Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,119.67,337.97,7.86;16,151.52,130.63,329.07,7.86;16,151.52,141.57,238.35,7.89" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="16,151.52,130.63,234.09,7.86">Diagnosis code assignment: models and evaluation metrics</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Perotte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Pivovarov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Natarajan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Weiskopf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Elhadad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,392.72,130.63,87.87,7.86;16,151.52,141.59,146.34,7.86">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="231" to="237" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,152.55,337.98,7.86;16,151.52,163.51,329.07,7.86;16,151.52,174.47,323.73,7.86" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="16,348.65,152.55,131.94,7.86;16,151.52,163.51,311.41,7.86">Classifying German Animal Experiment Summaries with Multi-lingual BERT at CLEF eHealth 2019 Task 1</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>S√§nger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kittner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Leser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,151.52,174.47,295.07,7.86">Working Notes of Conference and Labs of the Evaluation (CLEF) Forum</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,185.43,337.97,7.86;16,151.52,196.39,329.07,7.86;16,151.52,207.34,329.07,7.86;16,151.52,218.30,154.48,7.86" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="16,268.36,185.43,212.23,7.86;16,151.52,196.39,232.79,7.86">UMLS mapping and Word embeddings for ICD code assignment using the MIMIC-III intensive care database</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sch√§fer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Friedrich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,408.04,196.39,72.55,7.86;16,151.52,207.34,329.07,7.86;16,151.52,218.30,32.25,7.86">2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="6089" to="6092" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,229.26,337.98,7.86;16,151.52,240.22,329.07,7.86;16,151.52,251.15,243.60,7.89" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="16,370.22,229.26,110.37,7.86;16,151.52,240.22,280.81,7.86">A comparison of multi-label feature selection methods using the problem transformation approach</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Spola√¥r</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>Cherman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">C</forename><surname>Monard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,440.00,240.22,40.60,7.86;16,151.52,251.18,158.06,7.86">Electronic Notes in Theoretical Computer Science</title>
		<imprint>
			<biblScope unit="volume">292</biblScope>
			<biblScope unit="page" from="135" to="151" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,262.14,337.98,7.86;16,151.52,273.10,329.07,7.86;16,151.52,284.06,62.50,7.86" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="16,297.17,262.14,183.42,7.86">How to fine-tune BERT for text classification?</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,164.78,273.10,259.88,7.86">China National Conference on Chinese Computational Linguistics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="194" to="206" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,295.02,337.97,7.86;16,151.52,305.98,329.07,7.86;16,151.52,316.91,329.07,7.89;16,151.52,327.89,60.92,7.86" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="16,405.69,295.02,74.90,7.86;16,151.52,305.98,329.07,7.86;16,151.52,316.93,60.05,7.86">ICD-10-CM Crosswalks in the primary care setting: assessing reliability of the GEMs and reimbursement mappings</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">W</forename><surname>Turer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">D</forename><surname>Zuckowsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">J</forename><surname>Causey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">T</forename><surname>Rosenbloom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,219.50,316.93,232.78,7.86">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="417" to="425" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,338.85,337.97,7.86;16,151.52,349.81,329.07,7.86;16,151.52,360.77,329.07,7.86;16,151.52,371.73,329.07,7.86;16,151.52,382.69,172.94,7.86" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="16,450.77,338.85,29.82,7.86;16,151.52,349.81,273.24,7.86">XLNet: Generalized Autoregressive Pretraining for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,177.22,371.73,283.25,7.86">Advances in Neural Information Processing Systems 32: NeurIPS 2019</title>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Larochelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Beygelzimer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Alch√©-Buc</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Fox</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<meeting><address><addrLine>Vancouver, BC, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5754" to="5764" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,393.65,337.98,7.86;16,151.52,404.61,329.07,7.86;16,151.52,415.56,329.07,7.86;16,151.52,426.52,58.36,7.86" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="16,263.56,404.61,217.04,7.86;16,151.52,415.56,84.15,7.86">Large Batch Optimization for Deep Learning: Training BERT in 76 minutes</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Reddi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hseu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bhojanapalli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Demmel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Keutzer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Hsieh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,258.90,415.56,221.70,7.86;16,151.52,426.52,29.69,7.86">International Conference on Learning Representations (ICLR)</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
