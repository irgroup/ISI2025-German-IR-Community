<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,159.38,115.96,296.59,12.62;1,166.23,133.89,282.90,12.62;1,189.47,151.82,236.40,12.62">An Extended Overview of the CLEF 2020 ChEMU Lab: Information Extraction of Chemical Reactions from Patents</title>
				<funder ref="#_QrhgjEc">
					<orgName type="full">Australian Research Council Linkage</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,165.05,189.49,49.12,8.74"><forename type="first">Jiayuan</forename><surname>He</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,224.73,189.49,79.01,8.74"><forename type="first">Dat</forename><forename type="middle">Quoc</forename><surname>Nguyen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff7">
								<orgName type="institution">VinAI Research</orgName>
								<address>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,320.63,189.49,78.63,8.74"><forename type="first">Saber</forename><forename type="middle">A</forename><surname>Akhondi</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Elsevier BV</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,409.81,189.49,40.49,8.74;1,137.13,201.45,59.97,8.74"><forename type="first">Christian</forename><surname>Druckenbrodt</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Elsevier Information Systems GmbH</orgName>
								<address>
									<settlement>Frankfurt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,207.65,201.45,65.90,8.74"><forename type="first">Camilo</forename><surname>Thorne</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Elsevier Information Systems GmbH</orgName>
								<address>
									<settlement>Frankfurt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,284.10,201.45,61.69,8.74"><forename type="first">Ralph</forename><surname>Hoessel</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Elsevier Information Systems GmbH</orgName>
								<address>
									<settlement>Frankfurt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,356.35,201.45,54.83,8.74"><forename type="first">Zubair</forename><surname>Afzal</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Elsevier BV</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,421.73,201.45,49.27,8.74"><forename type="first">Zenan</forename><surname>Zhai</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,135.63,213.40,59.50,8.74"><forename type="first">Biaoyan</forename><surname>Fang</surname></persName>
							<email>biaoyanf@student.unimelb.edu.au</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,205.68,213.40,75.36,8.74"><forename type="first">Hiyori</forename><surname>Yoshikawa</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">Fujitsu Laboratories Ltd</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,297.93,213.40,70.88,8.74"><forename type="first">Ameer</forename><surname>Albahem</surname></persName>
							<email>ameer.albahem@rmit.edu.au</email>
							<affiliation key="aff3">
								<orgName type="institution">RMIT University</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,379.36,213.40,54.66,8.74"><forename type="first">Jingqi</forename><surname>Wang</surname></persName>
							<email>jingqi.wang@melaxtech.com</email>
							<affiliation key="aff5">
								<orgName type="institution">Melax Technologies, Inc</orgName>
								<address>
									<settlement>Houston</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,444.58,213.40,35.15,8.74;1,145.49,225.36,17.30,8.74"><forename type="first">Yuankai</forename><surname>Ren</surname></persName>
							<affiliation key="aff6">
								<orgName type="institution">Nantong University</orgName>
								<address>
									<settlement>Nantong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,173.34,225.36,44.84,8.74"><forename type="first">Zhi</forename><surname>Zhang</surname></persName>
							<affiliation key="aff6">
								<orgName type="institution">Nantong University</orgName>
								<address>
									<settlement>Nantong</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,228.73,225.36,63.10,8.74"><forename type="first">Yaoyun</forename><surname>Zhang</surname></persName>
							<email>yaoyun.zhang@melaxtech.com</email>
							<affiliation key="aff5">
								<orgName type="institution">Melax Technologies, Inc</orgName>
								<address>
									<settlement>Houston</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,302.38,225.36,69.05,8.74"><forename type="first">Mai</forename><forename type="middle">Hoang</forename><surname>Dao</surname></persName>
							<affiliation key="aff7">
								<orgName type="institution">VinAI Research</orgName>
								<address>
									<country key="VN">Vietnam</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,381.99,225.36,50.45,8.74"><forename type="first">Pedro</forename><surname>Ruas</surname></persName>
							<affiliation key="aff8">
								<orgName type="department">LASIGE</orgName>
								<orgName type="institution">Universidade de Lisboa</orgName>
								<address>
									<settlement>Lisbon</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,442.99,225.36,26.87,8.74;1,134.77,237.31,40.35,8.74"><forename type="first">Andre</forename><surname>Lamurias</surname></persName>
							<email>alamurias@lasige.di.fc.ul.pt</email>
							<affiliation key="aff8">
								<orgName type="department">LASIGE</orgName>
								<orgName type="institution">Universidade de Lisboa</orgName>
								<address>
									<settlement>Lisbon</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,185.60,237.31,82.81,8.74"><forename type="first">Francisco</forename><forename type="middle">M</forename><surname>Couto</surname></persName>
							<email>fcouto@fc.ul.pt</email>
							<affiliation key="aff8">
								<orgName type="department">LASIGE</orgName>
								<orgName type="institution">Universidade de Lisboa</orgName>
								<address>
									<settlement>Lisbon</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,278.89,237.31,60.41,8.74"><forename type="first">Jenny</forename><surname>Copara</surname></persName>
							<email>jenny.copara@hesge.ch</email>
							<affiliation key="aff9">
								<orgName type="department">Uni. of Applied Sciences</orgName>
								<orgName type="institution">Arts of Western Switzerland</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff10">
								<orgName type="institution">Swiss Institute of Bioinformatics</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff11">
								<orgName type="institution">University of Geneva</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,374.38,237.31,55.29,8.74"><forename type="first">Nona</forename><surname>Naderi</surname></persName>
							<email>nona.naderi@hesge.ch</email>
							<affiliation key="aff9">
								<orgName type="department">Uni. of Applied Sciences</orgName>
								<orgName type="institution">Arts of Western Switzerland</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff10">
								<orgName type="institution">Swiss Institute of Bioinformatics</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,454.44,237.31,26.15,8.74;1,139.23,249.27,31.83,8.74"><forename type="first">Julien</forename><surname>Knafou</surname></persName>
							<email>julien.knafou@hesge.ch</email>
							<affiliation key="aff9">
								<orgName type="department">Uni. of Applied Sciences</orgName>
								<orgName type="institution">Arts of Western Switzerland</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff10">
								<orgName type="institution">Swiss Institute of Bioinformatics</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff11">
								<orgName type="institution">University of Geneva</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,206.19,249.27,57.31,8.74"><forename type="first">Patrick</forename><surname>Ruch</surname></persName>
							<email>patrick.ruch@hesge.ch</email>
							<affiliation key="aff9">
								<orgName type="department">Uni. of Applied Sciences</orgName>
								<orgName type="institution">Arts of Western Switzerland</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff10">
								<orgName type="institution">Swiss Institute of Bioinformatics</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,288.34,249.27,73.56,8.74"><forename type="first">Douglas</forename><surname>Teodoro</surname></persName>
							<email>douglas.teodoro@hesge.ch</email>
							<affiliation key="aff9">
								<orgName type="department">Uni. of Applied Sciences</orgName>
								<orgName type="institution">Arts of Western Switzerland</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff10">
								<orgName type="institution">Swiss Institute of Bioinformatics</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,386.74,249.27,53.69,8.74"><forename type="first">Daniel</forename><surname>Lowe</surname></persName>
							<email>daniel@minesoft.com</email>
						</author>
						<author>
							<persName coords="1,454.96,249.27,21.17,8.74;1,138.50,261.22,37.36,8.74"><forename type="first">John</forename><surname>Mayfield</surname></persName>
							<affiliation key="aff13">
								<orgName type="institution">NextMove Software</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,190.39,261.22,77.54,8.74"><forename type="first">Abdullatif</forename><surname>Köksal</surname></persName>
							<email>abdullatif.koksal@boun.edu.tr</email>
							<affiliation key="aff14">
								<orgName type="institution">Bogaziçi University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,282.46,261.22,59.37,8.74"><forename type="first">Hilal</forename><surname>Dönmez</surname></persName>
							<email>hilal.donmez@boun.edu.tr</email>
							<affiliation key="aff14">
								<orgName type="institution">Bogaziçi University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,356.35,258.70,59.39,11.26"><forename type="first">Elif</forename><surname>Özkırımlı</surname></persName>
							<email>elif.ozkirimli@boun.edu.tr</email>
							<affiliation key="aff14">
								<orgName type="institution">Bogaziçi University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
							<affiliation key="aff15">
								<orgName type="department">Data and Analytics</orgName>
								<orgName type="institution">F. Hoffmann-La Roche AG</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,440.57,261.22,36.28,8.74;1,145.23,270.66,25.21,8.74"><forename type="first">Arzucan</forename><surname>Özgür</surname></persName>
							<email>arzucan.ozgur@boun.edu.tr</email>
							<affiliation key="aff14">
								<orgName type="institution">Bogaziçi University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,184.97,273.18,89.91,8.74"><forename type="first">Darshini</forename><surname>Mahendran</surname></persName>
							<email>mahendrand@vcu.edu</email>
							<affiliation key="aff16">
								<orgName type="institution">Virginia Common Wealth University</orgName>
								<address>
									<settlement>Richmond</settlement>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,289.41,273.18,73.81,8.74"><forename type="first">Gabrielle</forename><surname>Gurdin</surname></persName>
							<email>gurding@vcu.edu</email>
							<affiliation key="aff16">
								<orgName type="institution">Virginia Common Wealth University</orgName>
								<address>
									<settlement>Richmond</settlement>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,377.75,273.18,82.56,8.74"><forename type="first">Nastassja</forename><surname>Lewinski</surname></persName>
							<email>nalewinski@vcu.edu</email>
							<affiliation key="aff16">
								<orgName type="institution">Virginia Common Wealth University</orgName>
								<address>
									<settlement>Richmond</settlement>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,150.25,285.13,65.67,8.74"><forename type="first">Christina</forename><surname>Tang</surname></persName>
							<email>ctang2@vcu.edu</email>
							<affiliation key="aff16">
								<orgName type="institution">Virginia Common Wealth University</orgName>
								<address>
									<settlement>Richmond</settlement>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,230.45,285.13,85.74,8.74"><forename type="first">Bridget</forename><forename type="middle">T</forename><surname>Mcinnes</surname></persName>
							<email>btmcinnes@vcu.edu</email>
							<affiliation key="aff16">
								<orgName type="institution">Virginia Common Wealth University</orgName>
								<address>
									<settlement>Richmond</settlement>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,330.71,285.13,61.33,8.74;1,396.61,283.56,7.94,6.12"><forename type="first">Malarkodi</forename><forename type="middle">C S</forename><surname>18</surname></persName>
							<email>csmalarkodi@gmail.com</email>
							<affiliation key="aff17">
								<orgName type="institution">MIT Campus of Anna University</orgName>
								<address>
									<settlement>Chennai</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,411.13,285.13,53.97,8.74"><forename type="first">Pattabhi</forename><surname>Rk</surname></persName>
							<email>pattabhi@au-kbc.org</email>
						</author>
						<author>
							<persName coords="1,177.80,297.09,84.41,8.74"><forename type="first">Sobha</forename><forename type="middle">Lalitha</forename><surname>Devi</surname></persName>
							<affiliation key="aff17">
								<orgName type="institution">MIT Campus of Anna University</orgName>
								<address>
									<settlement>Chennai</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,276.74,297.09,81.53,8.74"><forename type="first">Lawrence</forename><surname>Cavedon</surname></persName>
							<email>lawrence.cavedon@rmit.edu.au</email>
							<affiliation key="aff3">
								<orgName type="institution">RMIT University</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff17">
								<orgName type="institution">MIT Campus of Anna University</orgName>
								<address>
									<settlement>Chennai</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,368.82,297.09,55.12,8.74"><forename type="first">Trevor</forename><surname>Cohn</surname></persName>
							<email>john@nextmovesoftware.com</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,434.51,297.09,37.64,8.74;1,232.57,309.04,35.84,8.74"><forename type="first">Timothy</forename><surname>Baldwin</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,298.34,309.04,67.11,8.74"><forename type="first">Karin</forename><surname>Verspoor</surname></persName>
							<email>karin.verspoor@unimelb.edu.auzenan.zhai</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff12">
								<address>
									<addrLine>13 Minesoft</addrLine>
									<settlement>Cambridge</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,159.38,115.96,296.59,12.62;1,166.23,133.89,282.90,12.62;1,189.47,151.82,236.40,12.62">An Extended Overview of the CLEF 2020 ChEMU Lab: Information Extraction of Chemical Reactions from Patents</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">50B7AE9E55AA5C4C60BB45D760A4373B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Named entity recognition</term>
					<term>Event extraction</term>
					<term>Information extraction</term>
					<term>Chemical reactions</term>
					<term>Patent text mining</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The discovery of new chemical compounds is perceived as a key driver of the chemistry industry and many other economic sectors. The information about the new discoveries are usually disclosed in scientific literature and in particular, in chemical patents, since patents are often the first venues where the new chemical compounds are publicized. Despite the significance of the information provided in chemical patents, extracting the information from patents is costly due to the large volume of existing patents and its drastic expansion rate. The Cheminformatics Elsevier Melbourne University (ChEMU) evaluation lab 2020, part of the Conference and Labs of the Evaluation Forum 2020 (CLEF2020), provides a platform to advance the state-of-the-arts in automatic information extraction systems over chemical patents. In particular, we focus on extracting synthesis process of new chemical compounds from chemical patents. Using the ChEMU corpus of 1500 "snippets" (text segments) sampled from 170 patent documents and annotated by chemical experts, we defined two key information extraction tasks. Task 1 targets at chemical named entity recognition, i.e., the identification of chemical compounds and their specific roles in chemical reactions. Task 2 targets at event extraction, i.e., the identification of reaction steps, relating the chemical compounds involved in a chemical reaction. In this paper, we provide an overview of our ChEMU2020 lab. Herein, we describe the resources created for the two tasks, the evaluation methodology adopted, and participants results. We also provide a brief summary of the methods employed by participants of this lab and the results obtained across 46 runs from 11 teams, finding that several submissions achieve substantially better results than the baseline methods prepared by the organizers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="22" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="23" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="24" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="25" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="26" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="27" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="28" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="29" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="30" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="31" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Chemical patents represent as an indispensable source information about new discoveries in chemistry. They are usually the first venues where new chemical compounds are disclosed <ref type="bibr" coords="2,248.24,519.47,11.62,8.74" target="#b5">[7,</ref><ref type="bibr" coords="2,259.86,519.47,11.62,8.74" target="#b38">40]</ref> and can lead general scientific literature (e.g., journal articles) by up-to 3 years. In addition, chemical patents usually contain much more comprehensive information about the synthesis process of new chemical compounds including their reaction steps and experimental conditions for compound synthesis and mode of action. These details are crucial for the understanding of compound prior art, and provide a means for novelty checking and validation <ref type="bibr" coords="2,200.35,591.21,10.52,8.74" target="#b3">[5,</ref><ref type="bibr" coords="2,210.87,591.21,7.01,8.74" target="#b4">6]</ref>.</p><p>Although the information in chemical patents are of significant research and commercial value, extracting such information is nontrivial, since the large vol-ume of existing patents and its drastic expansion rate has made manual annotation costly and time-consuming <ref type="bibr" coords="3,282.86,130.95,14.61,8.74" target="#b27">[29]</ref>. Natural language processing (NLP) refer to techniques that allow computers to automatically analyze and process natural unstructured language data, and it has enjoyed great success over the past decades <ref type="bibr" coords="3,170.78,166.81,15.50,8.74" target="#b28">[30,</ref><ref type="bibr" coords="3,186.27,166.81,11.62,8.74" target="#b42">44]</ref>. In light of this, researchers have been actively exploring the possible application of NLP techniques to patent text mining, so as to alleviate the time-consuming efforts of manual annotation by chemical experts and scale the information extraction process over chemical patents.</p><p>The ChEMU (Cheminformatics Elsevier Melbourne University) lab aims to provide a platform for worldwide experts in both NLP and chemistry to develop automated information extraction methods over chemical patents, and to advance the state-of-the-arts in this area. As a first running of ChEMU, our ChEMU2020 lab focuses on extraction of chemical reactions from patents <ref type="bibr" coords="3,449.60,268.22,15.50,8.74" target="#b30">[32,</ref><ref type="bibr" coords="3,465.10,268.22,11.62,8.74" target="#b12">14]</ref>. Specifically, we provided two information extraction tasks that are crucial steps for chemical reaction extraction. The first task, named entity recognition, requires the identification of essential elements of chemical reactions, such as chemical compounds involved, conditions at which reactions are carried out, and yields of reactions. We go beyond identifying named entities and also require identification of their specific roles in chemical reactions. The second task, event extraction, requires the identification of specific event steps that are performed in a chemical reaction.</p><p>In collaboration with chemical domain experts, we have prepared a highquality annotated data set of 1,500 segments of chemical patent texts specifically targeting these two tasks. The 1,500 segments are sampled from 170 chemical patents, and each segment contains a meaningful chemical reaction. Annotations including entities and event steps are firstly prepared by three chemical experts and then merged to gold-standards.</p><p>The ChEMU2020 lab has received considerable interest, attracting 37 registrants from 13 countries including Portugal, Switzerland, Germany, India, Japan, United States, China, and United Kingdom. Specifically, we received 26 runs (1 post-evaluation submission) from 11 teams in Task 1, 10 runs from 5 teams in Task 2, and 10 runs from 4 teams in the task of end-to-end systems (a pipeline combining Task 1 and 2), respectively. Several teams achieved exciting results, outperforming baseline models significantly. In particular, submissions from a team from the company Melax Technologies (from Houston, TX, USA) ranked first in all 3 tasks. The rest of the paper is structured as follows. We first introduce the corpus we created for use in the lab in Sect. 2. Then we give an overview of the tasks and tracks in Sect. 3, and discuss the evaluation framework used in the lab in Sect. 4. We present the overall evaluation results in Sect. 5 and introduce the participants' approaches in Sect. 6, comparing them in Sect. 7. Conclusions are presented in Sect. 8. Note that this paper is an extension of our previous overview paper <ref type="bibr" coords="3,162.46,644.16,15.50,8.74" target="#b12">[14]</ref> and thereby Sect. 2 to 4 here are repeated from that paper; our focus is to provide additional methodological detail.</p><p>The annotated corpus prepared for the ChEMU shared task consists of 1,500 patent snippets (text segments) that were sampled from 170 English document patents from the European Patent Office and the United States Patent and Trademark Office. Each snippet contains a meaningful description of a chemical reaction <ref type="bibr" coords="4,172.98,191.39,14.61,8.74" target="#b45">[47]</ref>.</p><p>The corpus was based on information captured in the Reaxys R database. <ref type="foot" coords="4,476.12,201.90,3.97,6.12" target="#foot_0">1</ref>This resource contains details of chemical reactions identified through a mostly manual process of extracting key reaction details from sources including patents and scientific publications, dubbed "excerption" <ref type="bibr" coords="4,347.71,239.34,14.61,8.74" target="#b18">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Annotation Process</head><p>To prepare the gold-standard annotations for the extracted patent snippets, multiple domain experts with rich expert knowledge in chemistry were invited to assist with corpus annotation. A silver-standard annotation set was first generated by mapping the records from the Reaxys database back to the source patents from which the records were originally extracted. This was done by scanning the patent texts for mentions of relevant entities. Since the original records are only linked to the IDs of source patents and do not provide the precise locations of excerpted entities or event steps, these annotations needed to be manually reviewed to produce higher-quality annotations. Two domain experts manually and independently reviewed all patent snippets, correcting location information of the annotations in silver-standard annotations and adding more annotations. Their annotations were then evaluated by measuring their inter-annotator agreement (IAA) <ref type="bibr" coords="4,190.24,433.95,9.96,8.74" target="#b6">[8]</ref>, and thereafter merged by a third domain expert who acted as an adjudicator, to resolve differences. More details about the quality evaluation over the annotations and the harmonization process will be provided in a more in-depth paper to follow.</p><p>We present an example of a patent snippet in Fig. <ref type="figure" coords="4,372.42,481.90,3.88,8.74" target="#fig_0">1</ref>. This snippet describes the synthesis of a particular chemical compound, named N-((5-(hydrazinecarbonyl) pyridin-2-yl)methyl)-1-methyl-N-phenylpiperidine-4-carboxamide. The synthesis process consists of an ordered sequence of reaction steps: (1) dissolving the chemical compound synthesized in step 3 and hydrazine monohydrate in ethanol; <ref type="bibr" coords="4,467.86,529.72,12.73,8.74" target="#b1">(2)</ref> heating the solution under reflux; (3) cooling the solution to room temperature; (4) concentrating the cooled mixture under reduced pressure; (5) purification of the concentrate by column chromatography; and (6) concentration of the purified product to get the title compound.</p><p>This shared task aims at extraction of chemical reactions from chemical patents, e.g., extracting the above synthesis steps given the patent snippet in Fig. <ref type="figure" coords="4,155.27,613.54,3.87,8.74" target="#fig_0">1</ref>. To achieve this goal, it is crucial for us to first identify the entities that are involved in these reaction steps (e.g., hydrazine monohydrate and ethanol) An example snippet <ref type="bibr" coords="5,152.06,141.41,4.10,7.86">[</ref>Step 4] Synthesis of N-((5-(hydrazinecarbonyl)pyridin-2-yl)methyl)-1-methyl-N-phenylpiperidine-4-carboxamide Methyl 6-((1-methyl-N-phenylpiperidine-4-carboxamido)methyl)nicotinate (0.120 g, 0.327 mmol), synthesized in step 3, and hydrazine monohydrate (0.079 mL, 1.633 mmol) were dissolved in ethanol (10 mL) at room temperature, and the solution was heated under reflux for 12 hours, and then cooled to room temperature to terminate the reaction. The reaction mixture was concentrated under reduced pressure to remove the solvent, and the concentrate was purified by column chromatography (SiO2, 4 g cartridge; methanol/dichloromethane = from 5% to 30%) and concentrated to give the title compound (0.115 g, 95.8%) as a foam solid. and then determine the relations between the involved entities (e.g., hydrazine monohydrate is dissolved in ethanol). Thus, our annotation process consists of two steps: named entity annotations and relation annotations. Next, we describe the two steps of annotations in Sect. 2.2 and Sect. 2.3, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Named Entity Annotations</head><p>Four categories of entities are annotated over the corpus: (1) chemical compounds that are involved in a chemical reaction; (2) conditions under which a chemical reaction is carried out; (3) yields obtained for the final chemical product; and (4) example labels that are associated with reaction specifications.</p><p>Ten labels are further defined under the above four categories. We define five different roles that a chemical compound can play within a chemical reaction, corresponding to five labels under this category: STARTING MATERIAL, REAGENT CATALYST, REACTION PRODUCT, SOLVENT, and OTHER COMPOUND. For example, the chemical compound "ethanol" in Fig. <ref type="figure" coords="5,450.36,506.24,4.98,8.74" target="#fig_0">1</ref> must be annotated with the label "SOLVENT".</p><p>We also define two labels under the category of conditions: TIME and TEM-PERATURE; and two labels under the category of yields: YIELD PERCENT and YIELD OTHER. The definitions of all resultant labels are summarized in Table <ref type="table" coords="5,161.07,566.41,3.87,8.74" target="#tab_0">1</ref>. Interested readers may find more information about the labels in <ref type="bibr" coords="5,446.82,566.41,15.50,8.74" target="#b30">[32]</ref> and examples of named entity annotations in the Task 1-NER annotation guidelines <ref type="bibr" coords="5,157.51,590.32,14.61,8.74" target="#b43">[45]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Relation Annotations</head><p>A chemical reaction step typically involves an action and chemical compound(s) on which the action takes effect. We therefore treat the extraction of a reaction step as a two-stage task: (1) identification of a trigger word that indicates a chemical reaction step; and (2) identification of the relation between a trigger word and chemical compound(s) that is(are) linked to the trigger word. In addition, we observe that it is also crucial for us to link an action to the conditions under which the action is carried out, and resultant yields from the action, in order to fully quantify a reaction step. Thus, annotations in this step are performed to identify the relations between actions (trigger words) and all arguments that are involved in the reaction steps, i.e., chemical compounds, conditions, and yields. The relation between an event trigger word and a chemical compound.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ArgM</head><p>The relation between an event trigger word and a temperature, time, or yield entity. We define two types of trigger words: WORKUP which refers to an event step where a chemical compound is isolated/purified, and REACTION STEP which refers to an event step that is involved in the conversion from a starting material to an end product. When labelling event arguments, we adapt semantic argument role labels Arg1 and ArgM from the Proposition Bank <ref type="bibr" coords="7,428.71,400.08,15.50,8.74" target="#b31">[33]</ref> to label the relations between the trigger words and other arguments. Specifically, the label Arg1 refers to the relation between an event trigger word and a chemical compound. Here, Arg1 represents argument roles of being causally affected by another participant in the event <ref type="bibr" coords="7,274.24,447.90,14.61,8.74" target="#b14">[16]</ref>. ArgM represents adjunct roles with respect to an event, used to label the relation between a trigger word and a temperature, time or yield entity. The definitions of trigger word types and relation types are summarized in Table <ref type="table" coords="7,231.01,483.77,3.87,8.74" target="#tab_0">1</ref>. Detailed annotation guidelines for relation annotation are available online <ref type="bibr" coords="7,221.69,495.72,14.60,8.74" target="#b43">[45]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Snippet Annotation Format</head><p>The gold-standard annotations for the data set were delivered in the BRAT standoff format <ref type="bibr" coords="7,205.37,560.48,14.61,8.74" target="#b40">[42]</ref>. For each snippet, two files were delivered: a text file (.txt) containing the original texts in the snippet, and a paired annotation file (.ann) containing all the annotations that have been made for that text, including entities, trigger words, and event steps. Continuing with the above snippet example, we present the formatted annotations for the highlighted sentence in Tables <ref type="table" coords="7,475.61,608.30,4.98,8.74" target="#tab_1">2</ref> and<ref type="table" coords="7,153.91,620.25,3.87,8.74" target="#tab_2">3</ref>. For ease of presentation, we show the annotated named entities and trigger words in Table <ref type="table" coords="7,218.67,632.21,4.98,8.74" target="#tab_1">2</ref> and the annotated event steps in Table <ref type="table" coords="7,400.23,632.21,3.87,8.74" target="#tab_2">3</ref>. Specifically, two entities (i.e., T1 and T2) and one trigger word are included in Table <ref type="table" coords="7,434.88,644.16,3.87,8.74" target="#tab_1">2</ref>, and two event steps are included in Table <ref type="table" coords="7,281.57,656.12,3.87,8.74" target="#tab_2">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Data Partitions</head><p>We randomly partitioned the whole data set into three splits for training, development and test purposes, with a ratio of 0.6/0.15/0.25. The training and development sets were released to participants for model development. Note that participants are allowed to use the combination of training and development sets and to use their own partitions to build models. The test set is withheld for use in the formal evaluation. The statistics of the three splits including their number of snippets, total number of sentences, and number of words per snippet, are summarized in Table <ref type="table" coords="8,229.22,227.72,3.87,8.74" target="#tab_3">4</ref>.</p><p>To ensure a fair split of data as much as possible, we conduct two statistical tests on the resultant train/dev/test splits. In the first test, we compare the distributions of entity labels (ten classes of entities in Task 1 and two classes of trigger words in Task 2) within train/dev/test sets, to make sure that the three sets of snippets have similar distributions over labels. The distributions are summarize in Table <ref type="table" coords="8,238.69,300.47,3.87,8.74" target="#tab_4">5</ref>, where each cell represents the proportion (e.g., 0.038) of an entity label (e.g., EXAMPLE LABEL) in the gold annotations of a data split (e.g., Train). The results in Table <ref type="table" coords="8,306.75,324.38,4.98,8.74" target="#tab_4">5</ref> confirm that the label distributions in the three splits are similar. Only some slight fluctuations ( 0.004) across the three splits are observed for each label.</p><p>We further compare the International Patent Classification (IPC) <ref type="bibr" coords="8,440.49,361.27,10.52,8.74" target="#b2">[3]</ref> distributions of the training, development and test sets. The IPC information of each patent snippet reflects the application category of the original patent. For example, the IPC code "A61K" represents the category of patents that are for preparations for medical, dental, or toilet purposes. Patents with different IPCs may be written in different ways and may differ in the vocabulary. Thus, they may differ in their linguistic characteristics. For each patent snippet, we extract the primary IPC of its corresponding source patent, and summarize the IPC distributions of the snippets in train/dev/test sets in Table <ref type="table" coords="8,396.45,456.91,3.87,8.74" target="#tab_5">6</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The Tasks</head><p>We provide two tasks in ChEMU lab: Task 1-Named Entity Recognition (NER), and Task 2-Event Extraction (EE). We also host a third track where participants can work on building end-to-end systems addressing both tasks jointly. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task 1: Named Entity Recognition</head><p>In order to understand and extract a chemical reaction from natural language texts, the first essential step is to identify the entities that are involved in the chemical reaction. The first task aims to accomplish this step by identifying the ten types of entities described in Sect. 2.2. The task requires the detection of the entity names in patent snippets and the assignment of correct labels to the detected entities (see Table <ref type="table" coords="9,290.22,427.17,3.87,8.74" target="#tab_0">1</ref>). For example, given a detected chemical compound, the task requires the identification of both its text span and its specific type according to the role in which it plays within a chemical reaction description.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Task 2: Event Extraction</head><p>A chemical reaction usually consists of an ordered sequence of event steps that transforms a starting product to an end product, such as the five reaction steps in the synthesis process of the chemical compound described in the example in Figure <ref type="figure" coords="9,178.66,548.52,3.87,8.74" target="#fig_0">1</ref>. The event extraction task (Task 2) targets identifying these event steps.</p><p>Similarly to conventional event extraction problems <ref type="bibr" coords="9,371.62,572.43,14.61,8.74" target="#b15">[17]</ref>, Task 2 involves three subtasks: event trigger word detection, event typing and argument prediction. First, it requires the detection of event trigger words and assignment of correct labels for the trigger words. Second, it requires the determination of argument entities that are associated with the trigger words, i.e., which entities identified in Task 1 participate in event or reaction steps. This is done by labelling the connections between event trigger words and their arguments. Given an event trigger word e and a set S of arguments that participate in e, Task 2 requires the In the track for Task 2, the gold standard entities in snippets are assumed to be known input. While in a real-world use of an event extraction system, gold standard entities would not typically be available, this framework allowed participants to focus on event extraction in isolation of the NER task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Task 3: End-to-End Systems</head><p>We also hosted a third track which allows participants to develop end-to-end systems that address both tasks simultaneously, i.e., the extraction of reaction events including their constituent entities directly from chemical patent snippets. This is a more realistic scenario for an event extraction system to be applied for large-scale annotation of events.</p><p>In the testing stage, participants in this track were provided only with the text of a patent, and were required to identify the named entities defined in Table <ref type="table" coords="10,161.88,533.02,3.87,8.74" target="#tab_0">1</ref>, the trigger words defined in Sect. 3.2, and the event steps involving the entities, that is, the reaction steps. Proposed models in this track were evaluated against the events that they predict for the test snippets, which is the same as in Task 2. However, a major difference between this track and Task 2 is that the gold named entities were not provided but rather had to be predicted by the systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Track overview</head><p>We illustrate the workflows of the three tracks in Fig. <ref type="figure" coords="10,378.62,644.16,4.98,8.74" target="#fig_1">2</ref> using as example the sentence highlighted in Fig 1 . In Task 1-NER-, participants need to identify entities that defined in Table <ref type="table" coords="11,270.17,118.99,3.87,8.74" target="#tab_0">1</ref>, e.g., the text span "ethanol" is identified as "SOLVENT". In Task 2-EE-, participants are provided with the three gold standard entities in the sentence. They are required to firstly identify the trigger words and their types (e.g., the text span "dissolved" is identified as "REAC-TION STEP") and then identify the relations between the trigger words and the provided entities (e.g., a directed link from "dissolved" to "ethanol" is added and labeled as "ARG1"). In the track of end-to-end systems, participants are only provided with the original text. They are required to identify both the entities and the trigger words, and predict the event steps directly from the text. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Organization of Tracks</head><p>Training stage. In the training stage, the training and development data sets were released to all participants for model development. To accommodate the needs of participants in different tracks, two different versions of training data, namely Data-NER and Data-EE, were provided. Data-NER was prepared for participants in Task 1, where the gold-standard entities defined in Table <ref type="table" coords="11,452.70,566.70,4.98,8.74" target="#tab_0">1</ref> were included. Data-EE was prepared for Tasks 2 and 3, where both the gold-standard entities, annotated trigger words and entity relations were included.</p><p>Testing stage. Since the gold-standard entities need to be provided to participants in Task 2, the testing stage of Task 2 was delayed until after the testing of Tasks 1 and 3 are completed, in order to prevent any leakage of information. Therefore, the testing stage consists of two phases. In the first phase, the text (.txt) files of all test snippets were released. Participants in Task 1 are required to use the released patent texts to predict the entities as defined in Table <ref type="table" coords="12,472.85,130.95,3.87,8.74" target="#tab_0">1</ref>. Participants in Task 3 were required to also predict the trigger words and entity relations defined in Sect. 3.2. In the second phase, the gold-standard entities of all test snippets were released. Participants in Task 2 can use the released goldstandard entities, along with the text files released in the first phase, to predict the event steps in test snippets. Submission website. A submission website has been developed, which allows participants to submit their runs during the testing stage. <ref type="foot" coords="12,399.91,231.07,3.97,6.12" target="#foot_2">2</ref> In addition, the website offers several important functions to facilitate organizing the lab.</p><p>First, it hosts the download links for the training, development, and test data sets so that participants can access the data sets conveniently. Second, it allows participants to test the performance (against the development set) of their models before the testing stage starts, which also offers a chance for participants to familiarize themselves with the evaluation tool BRATEval <ref type="bibr" coords="12,414.36,304.39,10.52,8.74" target="#b0">[1]</ref> (detailed in Sect. 4). The website also hosts a private leaderboard for each team that ranks all runs submitted by each team, and a public leaderboard that ranks all runs that have been made public by teams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation Framework</head><p>In this section, we describe the evaluation framework of the ChEMU lab. We introduce three baseline algorithms for Task 1, Task 2, and end-to-end systems, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evaluation Methods</head><p>We use BRATEval <ref type="bibr" coords="12,218.55,470.08,10.52,8.74" target="#b0">[1]</ref> to evaluate all the runs that we receive. Three metrics are used to evaluate the performance of all the submissions for Task 1: Precision, Recall, and F 1 -score. Specifically, given a predicted entity and a ground-truth entity, we treat the two entities as a match if (1) the types associated with the two entities match; and (2) their text spans match. The overall Precision, Recall, and F 1 -score are computed by micro-averaging all instances (entities).</p><p>In addition, we exploit two different matching criteria, exact-match and relaxed-match, when comparing the texts spans of two entities. Here, the exactmatch criterion means that we consider that the text span of an entity matches with that of another entity if both the starting and the end offsets of their spans match. The relaxed-match criterion means that we consider that the text span of one entity matches with that of another entity as long as their text spans overlap.</p><p>The submissions for Task 2 and end-to-end systems are evaluated using Precision, Recall, and F 1 -score by comparing the predicted events and gold standard events. We consider two events as a match if (1) their trigger words and event types are the same; and (2) the entities involved in the two events match. Here, we follow the method in Task 1 to test whether two entities match. This means that the matching criteria of exact-match and relaxed-match are also applied in the evaluation of Task 2 and of end-to-end systems. Note that the relaxed-match will only be applied when matching the spans of two entities; it does not relax the requirement that the entity type of predicted and ground truth entities must agree. Since Task 2 provides gold entities but not event triggers with their ground truth spans, the relaxed-match only reflects the accuracy of spans of predicted trigger words.</p><p>To somewhat accommodate a relaxed form of entity type matching, we also evaluate submissions in Task 1-NER using a set of high-level labels shown in the hierarchical structure of entity classes in Fig. <ref type="figure" coords="13,369.21,270.77,3.87,8.74" target="#fig_2">3</ref>. The higher-level labels used are highlighted in grey. In this set of evaluations, given a predicted entity and a ground-truth entity, we consider that their labels match as long as their corresponding high-level labels match. For example, suppose we get as predicted entity "STARTING MATERIAL, [335, 351), boron tribromide" while the (correct) ground-truth entity instead reads "REAGENT CATALYST, [335, 351), boron tribromide", where each entity is presented in the form of "TYPE, SPAN, TEXT". In the evaluation framework described earlier this example will be counted as a mismatch. However, in this additional set of entity type relaxed evaluations we consider the two entities as a match, since both labels "START-ING MATERIAL" and "REAGENT CATALYST" specialize their parent label "COMPOUND". </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Baselines</head><p>We released one baseline method for each task as a benchmark method. Specifically, the baseline for Task 1 is based on retraining BANNER <ref type="bibr" coords="14,408.11,167.92,15.50,8.74" target="#b19">[21]</ref> on the training and development data; the baseline for Task 2 is a co-occurrence method; and the baseline for end-to-end systems is a two-stage algorithm that first uses BAN-NER to identify entities in the input and then uses the co-occurrence method to extract events. BANNER. BANNER is a named entity recognition tool for bio-medical data. In this baseline, we first use the GENIA Sentence Splitter (GeniaSS) <ref type="bibr" coords="14,465.09,243.06,15.50,8.74" target="#b36">[38]</ref> to split input texts into separate sentences. The resulting sentences are then fed into BANNER, which predicts the named entities using three steps, namely tokenization, feature generation, and entity labelling. A simple tokenizer is used to break sentences into either a contiguous block of letters and/or digits or a single punctuation mark. BANNER uses a conditional random field (CRF) implementation derived from the MALLET toolkit<ref type="foot" coords="14,358.09,313.22,3.97,6.12" target="#foot_3">3</ref> for feature generation and token labelling. The set of machine learning features used consist primarily of orthographic, morphological and shallow syntax features.</p><p>Co-occurrence Method. This method first creates a dictionary D e for the observed trigger words and their corresponding types from the training and development sets. For example, if a word "added" is annotated as a trigger word with the label of "WORKUP" in the training set, we add an entry added, WORKUP to D e . In the case where the same word has been observed to appear as both types of "WORKUP" and "REACTION STEP", we only keep as entry in D its most frequent label. The method also creates an event dictionary D r for the observed event types in the training and development sets. For example, if an event ARG1, E1, E2 is observed where "E1" corresponds to trigger word "added" of type "WORKUP" and "E2" corresponds to entity "water" of type "OTHER COMPOUND", we add an entry ARG1, WORKUP, OTHER COMPOUND to D r .</p><p>To predict events, this method first identifies all trigger words in the test set using D e . It then extracts two events ARG1, T1, T2 and ARGM, T1, T2 for a trigger word "E1" and an entity "E2" if (1) they co-occur in the same sentence; and (2) the relation type ARGx, T1, T2 is included in D r . Here, "ARGx" can be "ARG1" or "ARGM", and "T1" and "T2" are the entity types of "E1" and "E2" respectively. BANNER + Co-occurrence Method. The above two baselines are combined to form a two-stage method for end-to-end systems. This baseline first uses BANNER to identify all the entities in Task 1. Then it utilizes the co-occurrence method to predict events, except that gold standard entities are replaced with the entities predicted by BANNER in the first stage.</p><p>In total, 39 teams registered for the ChEMU shared task, of which 36 teams registered for Task 1, 31 teams registered for Task 2, and 28 teams registered for both tasks. The 39 teams are spread across 13 different countries, from both the academic and industry research communities. In this section, we report the results of all the runs that we received for each task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Task 1-Named Entity Recognition</head><p>Task 1 received considerable interest with the submission of 25 runs from 11 teams. The 11 teams include 1 team from Germany (OntoChem), 3 teams from India (AUKBC, SSN NLP and JU INDIA), 1 team from Switzerland (BiTeM), 1 team from Portugal (Lasige BioTM), 1 team from Russia (KFU NLP), 1 team from the United Kingdom (NextMove Software/Minesoft), 2 teams from the United States of America (Melaxtech and NLP@VCU), and 1 team from Vietnam (VinAI). We evaluate the performance of all 25 runs, comparing their predicted entities with the ground-truth entities of the patent snippets in the test set. We report the performances of all runs under both matching criteria in terms of three metrics, namely Precision, Recall, and F 1 -score.</p><p>We report the overall performance of all runs in Table <ref type="table" coords="15,400.15,354.08,3.87,8.74">7</ref>. The baseline of Task 1 achieves 0.8893 in F 1 -score under exact match. Nine runs outperform the baseline in terms of F 1 -score under exact match. The best run was submitted by team Melaxtech, achieving a high F 1 -score of 0.9570. There were sixteen runs with an F 1 -score greater than 0.90 under relaxed-match. However, under exact-match, only seven runs surpassed 0.90 in F 1 -score. This difference between exact-match and relaxed-match may be related to the long text spans of chemical compounds, which is one of the main challenges in NER tasks in the domain of chemical documents.</p><p>Next, we evaluate the performance of all 25 runs using the high-level labels in Fig. <ref type="figure" coords="15,166.84,473.63,4.98,8.74" target="#fig_2">3</ref> (highlighted in grey). We report the performances of all runs in terms of Precision, Recall, and F 1 -score in Table <ref type="table" coords="15,322.19,485.59,3.87,8.74" target="#tab_6">8</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Task 2-Event Extraction</head><p>We received 10 runs from five teams. Specifically, the five teams include 1 team from Portugal (Lasige BioTM), 1 team from Turkey (BOUN REX), 1 team from the United Kingdom (NextMove Software/Minesoft) and 2 teams from the United States of America (Melaxtech and NLP@VCU). We evaluate all runs using the metrics Precision, Recall, and F 1 -score. Again, we utilize the two matching criteria, namely exact-match and relaxed-match, when comparing the trigger words in the submitted runs and ground-truth data.</p><p>The overall performance of each run is summarized in Table <ref type="table" coords="15,411.10,615.08,3.87,8.74" target="#tab_7">9</ref>. <ref type="foot" coords="15,418.86,613.50,3.97,6.12" target="#foot_4">4</ref> The baseline (co-occurrence method) scored relatively high in Recall, i.e, 0.8861. This was Table <ref type="table" coords="16,163.23,145.55,4.13,7.89">7</ref>. Overall performance of all runs in Task 1-Named Entity Recognition. Here, P, R, and F represents the Precision, Recall, and F1-score, respectively. For each metric, we highlight the best result in bold and the second best result in italic. The results are ordered by their performance in terms of F1-score under exact-match. * This run was received after evaluation phase and thus was not included in official results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>Exact expected, since the co-occurrence method aggressively extracts all possible events within a sentence. However, the F 1 -score was low due to its low Precision score.</p><p>Here, all runs outperform the baseline in terms of F 1 -score under exact-match. Melaxtech ranks first among all official runs in this task, with an F 1 -score of 0.9536. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">End-to-end Systems</head><p>We received 10 end-to-end system runs from four teams. The four teams include The four teams include 1 team from Turkey (BOUN REX), 1 team from the United Kingdom (NextMove Software/Minesoft) and 2 teams from the United States of America (Melaxtech and NLP@VCU). The overall performance of all runs is summarized in Table <ref type="table" coords="18,417.84,544.71,9.96,8.74" target="#tab_0">10</ref> in terms of Precision, Recall, and F 1 -score under both exact-match and relaxed-match. <ref type="foot" coords="18,476.12,555.09,3.97,6.12" target="#foot_5">5</ref>Since gold entities are not provided in this task, the average performance of the runs in this task are slightly lower than those in Task 2. Note that the Recall scores of most runs are substantially lower than their Precision scores. This may reveal that the task of identifying a relation from a chemical patent is harder Table <ref type="table" coords="19,164.15,115.91,9.04,7.89" target="#tab_0">10</ref>. Overall performance of all runs in end-to-end systems. Here, P, R, and F represent the Precision, Recall, and F1-score, respectively. For each metric, we highlight the best result in bold and the second best result in italics. The results are ordered by their performance in terms of F1-score under exact-match.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>Exact </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Overview of Participants' Approaches</head><p>We received 8 paper submissions from participating teams, namely BiTeM, VinAI, BOUN-REX, NextMove/Minesoft, NLP@VCU, AU-KBC, LasigBioTM, and MelaxTech. In this section, we present an overview of the approaches proposed by these teams. We start by introducing the approach of each team first.</p><p>Then we discuss the differences between these approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">BiTeM</head><p>To tackle the complexities of chemical patent narratives, the BiTeM team explored the power of ensemble of deep neural language models based on transformer architectures to extract information in chemical patents <ref type="bibr" coords="19,423.50,565.78,14.61,8.74" target="#b8">[10]</ref>. Using a majority vote strategy <ref type="bibr" coords="19,233.55,577.74,9.96,8.74" target="#b7">[9]</ref>, their approach combined end-to-end architectures, including Bidirectional Encoder Representations from Transformers (BERT) models (including both base/large and cased/uncased) <ref type="bibr" coords="19,350.98,601.65,14.61,8.74" target="#b10">[12]</ref>, the ChemBERTa model<ref type="foot" coords="19,473.36,600.07,3.97,6.12" target="#foot_6">6</ref> , and a model based on Convolutional Neural Network (CNN) <ref type="bibr" coords="19,404.13,613.60,15.50,8.74" target="#b20">[22]</ref> fed with contextualized embedding vectors provided by BERT model. To learn to classify chemical entities in patent passages, the language models were fine-tuned to categorize tokens using training examples of the ChEMU NER task. The best model proposed by BiTeM -an ensemble of BERT-base cased and uncased, and a CNN -achieved 92.3% of exact F 1 -score and 96.24% of relaxed F 1 -score in the test phase, outperforming the exact F 1 -score of the best individual model (BERT-base cased) by 1.3% and the challenge's baseline by 3.4%. The results of BiTeM team show that ensemble of contextualized language models could be used to effectively detect chemical entities in patent narratives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">VinAI</head><p>Following <ref type="bibr" coords="20,179.28,240.74,14.61,8.74" target="#b46">[48]</ref>, the VinAI system employed the well-known BiLSTM-CNN-CRF model <ref type="bibr" coords="20,163.95,252.70,15.50,8.74" target="#b24">[26]</ref> with additional contextualized word embeddings. In particular, given an input sequence of words, VinAI represented each word token by concatenating its corresponding pre-trained word embedding, CNN-based character-level word embedding <ref type="bibr" coords="20,212.69,288.56,15.50,8.74" target="#b24">[26]</ref> and contextualized word embedding. Here, VinAI used the pre-trained word embeddings released by <ref type="bibr" coords="20,337.36,300.52,14.61,8.74" target="#b46">[48]</ref>, which are trained on a corpus of 84K chemical patents using the Word2Vec skip-gram model <ref type="bibr" coords="20,436.27,312.47,14.61,8.74" target="#b26">[28]</ref>. Also, VinAI employed the contextualized word embeddings generated by a pre-trained ELMo language model <ref type="bibr" coords="20,235.10,336.38,15.50,8.74" target="#b33">[35]</ref> which is trained using the same corpus of 84K chemical patents <ref type="bibr" coords="20,190.21,348.34,14.61,8.74" target="#b46">[48]</ref>. 7 Then the concatenated word representations are fed into a BiLSTM encoder to extract latent feature vectors for input words. Each latent feature vector is then linearly transformed before being fed into a linear-chain CRF layer for NER label prediction <ref type="bibr" coords="20,291.06,384.21,14.61,8.74" target="#b17">[19]</ref>. VinAI achieved very high performance, officially ranking second with regards to both exact-and relaxed-match F 1 -scores at 94.33% and 96.84%, respectively. In a post-evaluation phase, fixing a mapping bug which converted the column-based format into the brat standoff format helped VinAI to obtain higher results: an exact-match F 1 -score at 95.21% and especially a relaxed-match F 1 -score at 97.26%, thus achieving the highest relaxed-match F 1 -score compared with all other participating systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">BOUN-REX</head><p>The BOUN-REX system addressed the event extraction task with two steps: the detection of trigger word and its trigger type, and identification of the event type.</p><p>A pre-trained transformer-based model, BioBERT, was used for the detection of trigger words (and the exact types of the detected trigger words) whereas the event type is determined using a rule-based method. Specifically, to pre-process the dataset, the documents were first split into sentences via GENIA Sentence Splitter. After constructing sentence-entity pairs for each entity, events and trigger words were predicted from the given sentence-entity pairs. Start and end markers were also introduced for each entity to indicate position of an entity in a sentence. A pre-trained transformer-based architecture was constructed as a base model to extract a fixed-length relation representation and token representations from an input sentence with entity markers. The fixed-length relation representation was utilized to detect the type of the trigger word. In addition, a trigger word span model was also constructed to predict the probabilities of start and end markers of trigger words with the token representations. The system trained using an AdamW optimizer, achieving the best performance of an F 1 score at 0.7234 using exact match.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4">NextMove Software/Minesoft</head><p>Lowe and Mayfield <ref type="bibr" coords="21,220.13,214.21,15.50,8.74" target="#b22">[24]</ref> used an approach utilizing grammars both for recognizing entities and for determining the relationships between entities. The toolkit LeadMine was first used to recognized chemicals and physical quantities, which is achieved by employing efficient matching against extensive grammars that describe these entity types. These entities were used as the highest priority tagger in an enhanced version of ChemicalTagger, with ChemicalTagger's default rule based tokenization being adjusted such that each LeadMine entity was a single token. Remaining tokens were assigned tags from pattern matches, or failing that assigned a part of speech tag. The pattern matches notably are how the reaction action trigger words are detected. An Antlr grammar arranges the tagged tokens into a parse tree which groups at various levels of granularity, e.g. all tokens for a particular reaction action will be grouped. The parse tree is used to determine which chemicals are solvents or involved in workup actions. The chemical structures (determined from the names), is used to assign chemical role information, both by inspection of the individual compounds and through whole reaction analysis techniques like NameRxn and atom-atom mapping. From analysis of the whole reaction the stoichiometry of the reaction is determined, hence distinguishing catalysts from starting materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5">VLP@VCU</head><p>VLP@VCU team participated in two tasks: Task 1-NER and Task 2-EE. For Task 1, the VLP@VCU team identified the named entities using BiLSTM units with a Conditational Random Graph (CRF) output layer. The inputs to this model are pre-trained word embeddings <ref type="bibr" coords="21,311.33,500.70,15.50,8.74" target="#b30">[32]</ref> in combination with character embeddings. These embeddings are concatenated and then passed through the BiL-STM network. The VLP@VCU system achieved an overall performance with a precision, recall and F 1 -score at 0.87, 0.86, and 0.87 in terms of exact match, and a precision, recall and F 1 -score of 0.95, 0.99, and 0.97 in terms of relaxed match.</p><p>For Task 2-EE, the VLP@VCU team explored two methods to identify the chemical arguments between the trigger words and the entities. First, a rule-based method was explored, which uses a breadth-first search to find the closest occurrence of the trigger word on either side of the entity. Second, a CNNbased model was explored. This model performs a binary classification to identify whether there is a relation or not for each Trigger word-Entity pair. The sentence containing the Trigger word-Entity pair is first extracted and then divided into five segments, where each segment is represented by a k × N matrix. Here, k represents the latent dimensionality of the pre-trained word embeddings <ref type="bibr" coords="22,465.09,118.99,15.50,8.74" target="#b30">[32]</ref> and N is the number of words in the segment. A separate convolution unit is constructed for each segment, the outputs of which are then flattened, concatenated, and fed into the fully connected feedforward layer. Finally, the output of the fully connected feedforward layer is fed into a softmax layer, which performs the final classification. This CNN-based method obtained higher performance with a precision, recall and F 1 -score of 0.80, 0.54 and 0.65, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6">AU-KBC</head><p>The AU-KBC team submitted two systems that were developed with two different Machine Learning (ML) techniques: CRFs and Artificial Neural Networks (ANNs). A two-stage pre-processing was done on the training and development data sets: (1) a formatting stage that consists of three steps, i.e., sentence splitting, tokenization, and conversion of data format to column; and (2) a data annotation stage, where the data is annotated for syntactic information, including Part-of-Speech (PoS) and Phrase Chunk information (noun phrase, verb phrase). To extract the PoS and chunk information, an open source tool, fnTBL <ref type="bibr" coords="22,452.13,321.80,14.61,8.74" target="#b29">[31]</ref>, is used. Three types of features were used for training: (a) word-level features, (b) grammatical features, and (c) functional terms features. Specifically, word-level features include orthographical features (e.g., capitalization, Greek words, and combination of digits, symbols, and words) and morphological features (e.g., common prefixes and suffixes of chemical entities). Grammatical features include word, Part-of-Speech (PoS), chunks and combination of PoS and chunks. Functional terms were used to help identify the biological named entities and assign them with correct labels. After extraction of these linguistic features, two models based on CRF and ANN are built to address Task 1. Note that the two models only utilized the training data provided in the task and did not rely on any external resources or leverage pre-trained language models. Specifically, the CRF++ tool <ref type="bibr" coords="22,216.20,465.26,10.52,8.74" target="#b1">[2]</ref> was used for developing the CRF model and the ANN model was implemented using the scikit python package. The ANN model is a Multi-Layer Perceptron (MLP), where ReLU activation function was used. The stochastic gradient Adam optimizer was used for optimizing weights of the ANN model. We obtained an F 1 -score of 0.6640 using CRFs and F 1 -score of 0.3764 using ANN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.7">LasigBioTM</head><p>To address Task 1, the LasigBioTM team fine-tuned the BioBERT NER model in the train set plus half of the development set (Note that the data was converted to the IOB2 format), and applied the fine-tuned model into the second half of the development set for recognizing and locating named entities. The team also developed a module to handle the BioBERT output and to generate the annotation files in the BRAT format and then submitted them to the competition page for evaluation, obtaining an F 1 -score of 0.9524 using the exact matching criterion and a F 1 -score of 0.9904 using the relaxed matching criterion on development data. In the testing phase, the team fine-tuned the model again, but using all the documents belonging to the train and the development sets. For Task 2, the team considered the BioBERT NER model jointly with the BioBERT RE model. They followed a similar approach as for Task 1 to detect the trigger words. To further extract the relations between triggers and entities, the team performed sentence segmentation of the train and the development sets and, if a trigger word and an entity were present in a given sentence, a relation was assumed to exist between them if it was referred in the respective annotation file. The BioBERT RE model was also fine-tuned using the sentences of the train and the development sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.8">MelaxTech</head><p>The MelaxTech system is a hybrid combination of deep learning models and pattern-based rules for this task. For deep learning, a language model of patents with chemical reactions was first built. Specifically, the BioBERT <ref type="bibr" coords="23,431.67,300.88,14.61,8.74" target="#b21">[23]</ref>, a pretrained biomedical language model (a bidirectional encoder representation for biomedical text), was used as the basis for training a language model of patents. Based on BERT <ref type="bibr" coords="23,211.96,336.75,14.61,8.74" target="#b10">[12]</ref>, a language model pre-trained on large scale open text, BioBERT was further refined using the biomedical literature in PubMed and PMC. For this study, BioBERT was retrained on patent data to generate a new language model of Patent BioBERT. For the NER subtask, Patent BioBERT was fine-tuned using the Bi-LSTM-CRF (Bi-directional Long-Short-Term-Memory Conditional-Random-Field) algorithm <ref type="bibr" coords="23,301.70,396.52,14.61,8.74" target="#b24">[26]</ref>. Next, several rules based on observed patterns in the training data were used in a post-processing step. For example, rules were defined to differentiate STARTING MATERIAL and OTHER COM-POUND based on the relative positions and total number of EXAMPLE LABEL occurrences. For the event extraction subtask, the event triggers were first identified as named entities together with other semantic roles in chemical reaction, using the same approach as in the NER subtask. Next, a binary classifier was built by fine-tuning Patent BioBERT to recognize relations between event triggers and semantic roles in the same sentence. Some event triggers and their linked semantic roles were present in different sentences, or different clauses in long complex sentences. Their relations were not identified using the deep learning-based model. Therefore, post-processing rules were designed based on patterns observed in the training data, and applied to recover some of these false negative relations. The proposed approaches demonstrated promising results, which achieved top ranks in both subtasks, with the best F 1 -score of 0.957 for entity recognition and the best F 1 -score of 0.9536 for event extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion</head><p>Different approaches were explored by the participating teams. In Table <ref type="table" coords="23,453.12,632.21,8.49,8.74" target="#tab_9">11</ref>, we summarize the key strategies in terms of three aspects: tokenization method, token representations, and core model architecture.</p><p>For teams who participated in Tasks 2 and 3, a common two-step strategy was adopted for relation extraction: (1) identify trigger words; and (2) extract the relation between identified trigger words and entities. The first step is essentially an NER task, and the second step is a relation extraction task. As such, NER models were used by all these teams for Tasks 2 and 3 as well as by the teams participating in Task 1. Therefore, in what follows, we first discuss and compare the approaches of all teams without considering the target tasks, subsequently considering relation extraction approaches. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Tokenization</head><p>Tokenization is an important data pre-processing step that splits input texts into words/subwords, i.e., tokens. We identify three general types of tokenization methods used by participants: (1) rule based tokenization; (2) dictionary based tokenization; and (3) subword based tokenization. Specifically, rule based tokenization applies pre-defined rules to split texts into tokens. The rules applied can be as simple as "white-space tokenization", but can also be a complex mixture of a set of carefully designed rules (e.g., based on language-specific grammar rules and common prefixes). Dictionary based tokenization requires the construction of a vocabulary and the text splitting is performed by matching the input text with the existing tokens in the constructed vocabulary. Subword tokenization allows a token to be a sub-string of a word, i.e., subword units. It relies on the principle that most common words should be left as is, but rare words should be decomposed in meaningful subword units. Popular subword tokenization methods include WordPiece <ref type="bibr" coords="25,281.65,316.87,15.50,8.74" target="#b37">[39]</ref> and Byte Pair Encoding (BPE) <ref type="bibr" coords="25,443.97,316.87,14.61,8.74" target="#b34">[36]</ref>. For each participating team, we consider whether their approach belong to one or multiple of the three categories, and summarize our findings in Table <ref type="table" coords="25,432.67,340.78,8.49,8.74" target="#tab_9">11</ref>. Finally, we also indicate whether their tokenization methods consider domain-specific knowledge in Table <ref type="table" coords="25,221.94,364.69,8.49,8.74" target="#tab_9">11</ref>.</p><p>Four teams utilized tokenization methods that are purely rule-based. Specifically, VinAI used Oscar4 tokenizer <ref type="bibr" coords="25,292.14,393.10,14.61,8.74" target="#b13">[15]</ref>. This tokenizer is particularly designed for chemical texts, and is made up by a set of pattern matching rules (e.g., prefix matching) that are designed based on domain knowledge from chemical experts. NLP@VCU used Spacy tokenizer [4], which consists of a collection of complex normalization and segmentation logic and has been proven to work well with general English corpus. NextMove/Minesoft used a combination of Os-car4 and LeadMine <ref type="bibr" coords="25,223.07,464.84,15.50,8.74" target="#b23">[25]</ref> tokenzier. LeadMine was first run on untokenized text to identify entities using auxiliary grammars or dictionaries. Oscar4 was then used for general tokenization but is adjusted so that each entity recognized by LeadMine corresponds to exactly one token. Four teams, BiTeM, BOUN-REX, LasigBioTM, and MelaxTech, chose to leverage the pre-trained model BERT (or variants of BERT) to address our tasks, and thus, the four teams used the subword-based tokenizer, WordPiece, that is built-in within BERT. BOUN-REX, LasigBioTM and MelaxTech used BioBERT model which is language model pretrained on biomedical texts. Since this model is a continual training based on the original BERT model, the vocabulary used in BioBERT does not differ from BERT, i.e., domain-specific tokenization is not used. However, since MelaxTech performed a pre-tokenization using a toolkit CLAMP <ref type="bibr" coords="25,368.98,596.34,14.61,8.74" target="#b39">[41]</ref>, we consider their approach as domain-specific, since CLAMP is tailored for clinical texts. BiTeM used the model ChemBERTa that is pre-trained on ZINC corpus. It is unclear yet whether the tokenization is domain-specific due to the lack of documentation of ChemBERTa. Finally, since WordPiece needs an extra pre-tokenization step, we consider it as a hybrid of rule-based and subword-based method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Representations</head><p>When transforming tokens into machine-readable representations, two types of methods are used: <ref type="bibr" coords="26,218.76,150.70,12.73,8.74" target="#b0">(1)</ref> feature extraction that represents tokens with their linguistic characteristics such as word-level features (e.g., morphological features) and grammatical features (e.g., PoS tags); and (2) embedding methods in which token representations are randomly initialized as numerical vectors (or initialized from pre-trained embeddings) and then learned (or fine-tuned) from provided training data. Two teams, NextMove/Minesoft and AU-KBC adopted the first strategy and the other teams adopted the second strategy. Among the teams that used embeddings to represent tokens, two teams, VinAI and VLP@VCU further added character-level embeddings to their systems. All of these six teams used pre-trained embeddings, and five teams used embeddings that are pre-trained for related domains: VinAI and NLP@VCU used the embeddings that are pretrained on chemical patents <ref type="bibr" coords="26,256.44,282.21,14.61,8.74" target="#b46">[48]</ref>, BOUN-REX and LasigBioTM used the embeddings from BioBERT model that are pre-trained on PubMed corpus. MexlaxTech also used embeddings from BioBERT, but they further tuned the embeddings using the patent documents released in the test phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Model Architecture</head><p>Various architectures were employed by participating teams. Four teams, BiTeM, BOUN-REX, LasigBioTM, and MelaxTech developed their systems based on transformers <ref type="bibr" coords="26,194.54,391.46,14.61,8.74" target="#b41">[43]</ref>. BiTem submitted an additional run using an ensemble of a Transformer-based model and a CNN-based model. They also had a third run that is built based on CRF. The other two teams MelaxTech and BOUN-REX added rule-based techniques into their systems. MelaxTech added several pattern-matching rules in their post-processing step. BOUN-REX focused on Task 2 and their system used rule based methods to determine the event type of each detected event. Two teams, VinAI and NLP@VCU, used the architecture of BiLSTM-CNN-CRF for Task 1. NLP@VCU also participated in Task 2 and they proposed two systems based on rules, and CNN architecture, respectively. NextMove/Minesoft utilized Chemical Tagger <ref type="bibr" coords="26,392.33,499.05,14.61,8.74" target="#b11">[13]</ref>, a model based on Finite State Machine (FSM), and a set of comprehensive rules are applied to generate predictions. AU-KBC proposed two systems for Task 1, based on multi-layer perceptron and CRF, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Approaches to relation extraction</head><p>Four of the above teams participated in Task 2 or Task 3. As mentioned before, these teams utilized their NER models for trigger word detection. Thus, here, we only discuss their approaches for relation extraction assuming that the trigger words and entities are known.</p><p>NextMove/Minesoft again made use of ChemicalTagger for event extraction. ChemicalTagger is able to recognize WORKUP and REACTION STEP words, thus, assignment of relationships were achieved by associating all entities in a ChemicalTagger action phrase with the trigger word responsible for the action phrase. A set of post-processing rules were also applied to enhance the accuracy of ChemicalTagger.</p><p>LasigBioTM, NLP@VCU, and MelaxTech formulated the task of relation extraction as a binary classification problem. That is, given each candidate pair of trigger word and named entity that co-locate within an input sentence, the goal of the task is to determine whether the candidate pair of entities are related or not.</p><p>LasigBioTM developed a BioBERT-based model to accomplish this classification. The input of BioBERT is the sentence containing the candidate pair but the trigger word and named entity of the candidate pair were replaced with the tags "@TRIGGER$" and "@LABEL$", respectively. The output of BioBERT is modified as a binary classification layer which aims to predict the existence of relation for the candidate pair.</p><p>NLP@VCU proposed two systems for relation extraction. Their first system is a rule-based system. Given a named entity, a relation is extracted between the named entity and its nearest trigger word. Their second system is developed based on CNNs. They split the sentence containing the candidate pair into five segments: the sequence of tokens before/between/after the candidate pair, the trigger word, and the named entity of the candidate pair. Separate convolutional units were used to learn the latent representations of the five segments, and a final output layer was used to determine if the candidate pair is related or not.</p><p>MelaxTech continued the use of the BioBERT model re-trained on the patent texts released during the test phase. Similar to LasigBioTM, the input to their model is the sentence containing the candidate pair but only the candidate named entity is generalized by its semantic type in the sentences. Furthermore, rules were also applied in the post-processing step to recover false negative relations with a long distance, including relations across clauses and across sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5">Summary of observations</head><p>The various approaches adopted by teams and the resulting performances have provided us with valuable experiences in how to address the tasks and what choices of methods are more suitable for our tasks.</p><p>Tokenization. In general, domain-specific tokenization tools perform better than tokenization methods that are for general English corpus. This is as expected since the vocabulary of chemical patents contains a large number of domain-specific terminology, and a machine can better understand and learn the characteristics of input texts if the texts are split into meaningful tokens. Another observation is that subword-based tokenization may contribute to overall accuracy. Chemical names are usually long, which make subword-based tokenization a suitable method for breaking down long chemical names. But further investigation is needed to support this claim.</p><p>Representation. Pre-trained embeddings are shown to be effective in enhancing system performances. Specifically, the Melaxtech and Lasige BioTM systems are based on BioBERT model <ref type="bibr" coords="27,305.37,656.12,15.50,8.74" target="#b21">[23]</ref> and ranked the first and third place in Task 1. The VinAI system leveraged embeddings pre-trained on chemical patents <ref type="bibr" coords="28,169.98,130.95,15.50,8.74" target="#b46">[48]</ref> and ranked second place. Character-level embeddings are also beneficial, shown by the ablation study in <ref type="bibr" coords="28,304.79,142.90,15.50,8.74" target="#b9">[11]</ref> and <ref type="bibr" coords="28,342.98,142.90,14.61,8.74" target="#b25">[27]</ref>.</p><p>Model Architecture. The most popular choice of model is BERT <ref type="bibr" coords="28,462.32,155.35,14.61,8.74" target="#b10">[12]</ref>, which is based on Transformer <ref type="bibr" coords="28,267.00,167.30,14.61,8.74" target="#b41">[43]</ref>. The model has demonstrated its effectiveness in sequence learning again. The Melaxtech system adopted this architecture and ranked first place in all three tasks. However, it is also worthwhile to note that the architecture of BiLSTM-CNN-CRF is still very competitive with BERT. The VinAI system ranked the first place in F 1 -score when relaxed-match is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusions</head><p>This paper presents a general overview of the activities and outcomes of the ChEMU 2020 evaluation lab. The ChEMU lab targets two important information extraction tasks applied to chemical patents: (1) named entity recognition, which aims to identify chemical compounds and their specific roles in chemical reactions; and (2) event extraction, which aims to identify the single event steps that form a chemical reaction.</p><p>We received registrations from 39 teams and 46 runs from 11 teams across all tasks and tracks, and 8 teams have contributed detailed system descriptions for their methods. The evaluation results show that many effective solutions have been proposed, with systems achieving excellent performance on each task, up to nearly 0.98 macro-averaged F 1 -score on the NER task (and up to 0.99 F 1 -score on a relaxed match), 0.95 F 1 -score on the isolated relation extraction task, and around 0.92 F 1 -score for the end-to-end systems. These results strongly outperformed baselines.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,186.42,285.95,242.53,7.89"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. An example snippet with key focus text highlighted.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="11,134.77,436.89,345.82,7.89;11,134.77,447.87,246.22,7.86;11,134.77,245.93,354.34,176.19"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Illustration of the three tasks. Shaded text spans represents annotated entities or trigger words. Arrows represent relations between entities.</figDesc><graphic coords="11,134.77,245.93,354.34,176.19" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="13,150.45,624.04,314.45,7.89;13,194.29,448.38,226.77,160.89"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Illustration of the hierarchical NER class structure used in evaluation.</figDesc><graphic coords="13,194.29,448.38,226.77,160.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,136.20,271.90,342.95,350.24"><head>Table 1 .</head><label>1</label><figDesc>Definitions of entity and relation types, i.e., labels, in Task 1 and Task 2.</figDesc><table coords="6,136.20,297.42,342.95,324.72"><row><cell>Label</cell><cell>Definition</cell></row><row><cell>Entity Annotations</cell><cell></cell></row><row><cell>STARTING MATERIAL</cell><cell>A substance that is consumed in the course of a</cell></row><row><cell></cell><cell>chemical reaction providing atoms to products is</cell></row><row><cell></cell><cell>considered as starting material.</cell></row><row><cell>REAGENT CATALYST</cell><cell>A reagent is a compound added to a system to cause</cell></row><row><cell></cell><cell>or help with a chemical reaction.</cell></row><row><cell>REACTION PRODUCT</cell><cell>A product is a substance that is formed during a</cell></row><row><cell></cell><cell>chemical reaction.</cell></row><row><cell>SOLVENT</cell><cell>A solvent is a chemical entity that dissolves a solute</cell></row><row><cell></cell><cell>resulting in a solution.</cell></row><row><cell>OTHER COMPOUND</cell><cell>Other chemical compounds that are not the</cell></row><row><cell></cell><cell>products, starting materials, reagents, catalysts and</cell></row><row><cell></cell><cell>solvents.</cell></row><row><cell>TIME</cell><cell>The reaction time of the reaction.</cell></row><row><cell>TEMPERATURE</cell><cell>The temperature at which the reaction was carried</cell></row><row><cell></cell><cell>out.</cell></row><row><cell>YIELD PERCENT</cell><cell>Yield given in percent values.</cell></row><row><cell>YIELD OTHER</cell><cell>Yields provided in other units than %.</cell></row><row><cell>EXAMPLE LABEL</cell><cell>A label associated with a reaction specification.</cell></row><row><cell>Relation Annotations</cell><cell></cell></row><row><cell>WORKUP</cell><cell>An event step which is a manipulation required to</cell></row><row><cell></cell><cell>isolate and purify the product of a chemical reaction.</cell></row><row><cell>REACTION STEP</cell><cell>An event within which starting materials are</cell></row><row><cell></cell><cell>converted into the product.</cell></row><row><cell>Arg1</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,134.77,115.91,345.82,89.29"><head>Table 2 .</head><label>2</label><figDesc>The annotated entities and trigger words of the snippet example in BRAT standoff format<ref type="bibr" coords="7,199.86,126.90,13.52,7.86" target="#b40">[42]</ref>.</figDesc><table coords="7,146.05,152.89,301.56,52.32"><row><cell>ID</cell><cell>Entity Type</cell><cell>Offsets</cell><cell>Text Span</cell></row><row><cell>T1</cell><cell>TEMPERATURE</cell><cell>313 329</cell><cell>room temperature</cell></row><row><cell>T2</cell><cell>REAGENT CATALYST</cell><cell>231 252</cell><cell>hydrazine monohydrate</cell></row><row><cell>T3</cell><cell>REACTION STEP</cell><cell>281 290</cell><cell>dissolved</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,134.77,223.05,345.83,98.06"><head>Table 3 .</head><label>3</label><figDesc>The annotated relations of the snippet example in BRAT standoff format<ref type="bibr" coords="7,463.70,223.08,13.52,7.86" target="#b40">[42]</ref>.</figDesc><table coords="7,134.77,234.04,345.83,87.08"><row><cell cols="4">Building on the annotations in Table 2, we see that R6 expresses the relation between</cell></row><row><cell cols="4">a compound participating as a reagent (T2) in the T3 "dissolved" reaction step, and</cell></row><row><cell cols="4">R8 captures the temperature (T1) at which that step occurred.</cell></row><row><cell>ID</cell><cell>Event Type</cell><cell>Entity 1</cell><cell>Entity 2</cell></row><row><cell>R6</cell><cell>Arg1</cell><cell>T3</cell><cell>T2</cell></row><row><cell>R8</cell><cell>ArgM</cell><cell>T3</cell><cell>T1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,181.82,580.37,240.24,77.84"><head>Table 4 .</head><label>4</label><figDesc>Summary of data set statistics.</figDesc><table coords="8,181.82,605.89,240.24,52.32"><row><cell cols="2">Data Split # snippets</cell><cell>#sentences</cell><cell># words/snippet</cell></row><row><cell>Train</cell><cell>900</cell><cell>5,911</cell><cell>112.16</cell></row><row><cell>Dev</cell><cell>225</cell><cell>1,402</cell><cell>104.00</cell></row><row><cell>Test</cell><cell>375</cell><cell>2,363</cell><cell>108.63</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,140.00,115.91,332.30,201.19"><head>Table 5 .</head><label>5</label><figDesc>Distributions of entity labels in the training, development, and test sets.</figDesc><table coords="9,158.83,141.43,274.37,175.68"><row><cell>Entity Label</cell><cell>Train</cell><cell>Dev.</cell><cell>Test</cell><cell>Mean</cell></row><row><cell>EXAMPLE LABEL</cell><cell>0.038</cell><cell>0.040</cell><cell>0.037</cell><cell>0.038</cell></row><row><cell>OTHER COMPOUND</cell><cell>0.200</cell><cell>0.198</cell><cell>0.205</cell><cell>0.201</cell></row><row><cell>REACTION PRODUCT</cell><cell>0.088</cell><cell>0.093</cell><cell>0.091</cell><cell>0.091</cell></row><row><cell>REAGENT CATALYST</cell><cell>0.055</cell><cell>0.053</cell><cell>0.053</cell><cell>0.054</cell></row><row><cell>SOLVENT</cell><cell>0.049</cell><cell>0.046</cell><cell>0.045</cell><cell>0.047</cell></row><row><cell>STARTING MATERIAL</cell><cell>0.076</cell><cell>0.076</cell><cell>0.075</cell><cell>0.076</cell></row><row><cell>TEMPERATURE</cell><cell>0.065</cell><cell>0.064</cell><cell>0.065</cell><cell>0.065</cell></row><row><cell>TIME</cell><cell>0.046</cell><cell>0.046</cell><cell>0.048</cell><cell>0.047</cell></row><row><cell>YIELD OTHER</cell><cell>0.046</cell><cell>0.048</cell><cell>0.047</cell><cell>0.047</cell></row><row><cell>YIELD PERCENT</cell><cell>0.041</cell><cell>0.042</cell><cell>0.041</cell><cell>0.041</cell></row><row><cell>REACTION STEP</cell><cell>0.164</cell><cell>0.163</cell><cell>0.160</cell><cell>0.162</cell></row><row><cell>WORKUP</cell><cell>0.132</cell><cell>0.132</cell><cell>0.133</cell><cell>0.132</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="10,134.77,116.41,345.83,242.17"><head>Table 6 .</head><label>6</label><figDesc>Distributions of International Patent Classifications (IPCs) in the training, development, and test sets. Only dominating IPC groups that take up more than 1 percent of a data split are included in this table.</figDesc><table coords="10,175.53,163.85,226.80,131.22"><row><cell>IPC Train</cell><cell>Dev.</cell><cell>Test</cell><cell>Mean</cell></row><row><cell>A61K 0.277</cell><cell>0.278</cell><cell>0.295</cell><cell>0.283</cell></row><row><cell>A61P 0.129</cell><cell>0.134</cell><cell>0.113</cell><cell>0.125</cell></row><row><cell>C07C 0.063</cell><cell>0.045</cell><cell>0.060</cell><cell>0.056</cell></row><row><cell>C07D 0.439</cell><cell>0.444</cell><cell>0.437</cell><cell>0.440</cell></row><row><cell>C07F 0.011</cell><cell>0.009</cell><cell>0.010</cell><cell>0.010</cell></row><row><cell>C07K 0.013</cell><cell>0.012</cell><cell>0.008</cell><cell>0.011</cell></row><row><cell>C09K 0.012</cell><cell>0.021</cell><cell>0.011</cell><cell>0.015</cell></row><row><cell>G03F 0.012</cell><cell>0.019</cell><cell>0.014</cell><cell>0.015</cell></row><row><cell>H01L 0.019</cell><cell>0.021</cell><cell>0.019</cell><cell>0.020</cell></row></table><note coords="10,134.77,325.93,345.83,8.74;10,134.77,337.89,345.82,8.74;10,134.77,349.84,345.83,8.74"><p>creation of |S| relation entries connecting e to an argument entity in S. Here, |S| represents the cardinality of the set S. Finally, Task 2 requires the assignment of correct relation type labels (Arg1 or ArgM) to each of the detected relations.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="16,136.24,215.67,336.11,412.57"><head>Table 8 .</head><label>8</label><figDesc>Overall performance of all runs in Task 1-Named Entity Recognition where the set of high-level labels in Fig.3is used. Here, P, R, and F represents the Precision, Recall, and F1-score, respectively. For each metric, we highlight the best result in bold and the second best result in italic. The results are ordered by their performance in terms of F1-score under exact-match. * This run was received after evaluation phase and thus was not included in official results.</figDesc><table coords="16,136.24,215.67,336.11,412.57"><row><cell></cell><cell></cell><cell>-Match</cell><cell></cell><cell cols="3">Relaxed-Match</cell></row><row><cell></cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>P</cell><cell>R</cell><cell>F</cell></row><row><cell>Melaxtech-run1</cell><cell cols="6">0.9571 0.9570 0.9570 0.9690 0.9687 0.9688</cell></row><row><cell>Melaxtech-run2</cell><cell cols="3">0.9587 0.9529 0.9558</cell><cell>0.9697</cell><cell>0.9637</cell><cell>0.9667</cell></row><row><cell>Melaxtech-run3</cell><cell>0.9572</cell><cell>0.9510</cell><cell>0.9541</cell><cell>0.9688</cell><cell>0.9624</cell><cell>0.9656</cell></row><row><cell>VinAI-run2  *</cell><cell>0.9538</cell><cell>0.9504</cell><cell cols="4">0.9521 0.9737 0.9716 0.9726</cell></row><row><cell>VinAI-run1</cell><cell>0.9462</cell><cell>0.9405</cell><cell cols="2">0.9433 0.9707</cell><cell>0.9661</cell><cell>0.9684</cell></row><row><cell>Lasige BioTM-run1</cell><cell>0.9327</cell><cell>0.9457</cell><cell>0.9392</cell><cell>0.9590</cell><cell>0.9671</cell><cell>0.9630</cell></row><row><cell>BiTeM-run3</cell><cell>0.9378</cell><cell>0.9087</cell><cell>0.9230</cell><cell>0.9692</cell><cell>0.9558</cell><cell>0.9624</cell></row><row><cell>BiTeM-run2</cell><cell>0.9083</cell><cell>0.9114</cell><cell>0.9098</cell><cell>0.9510</cell><cell>0.9684</cell><cell>0.9596</cell></row><row><cell cols="2">NextMove/Minesoft-run1 0.9042</cell><cell>0.8924</cell><cell>0.8983</cell><cell>0.9301</cell><cell>0.9181</cell><cell>0.9240</cell></row><row><cell cols="2">NextMove/Minesoft-run2 0.9037</cell><cell>0.8918</cell><cell>0.8977</cell><cell>0.9294</cell><cell>0.9178</cell><cell>0.9236</cell></row><row><cell>Baseline</cell><cell>0.9071</cell><cell>0.8723</cell><cell>0.8893</cell><cell>0.9219</cell><cell>0.8893</cell><cell>0.9053</cell></row><row><cell>NLP@VCU-run1</cell><cell>0.8747</cell><cell>0.8570</cell><cell>0.8658</cell><cell>0.9524</cell><cell>0.9513</cell><cell>0.9518</cell></row><row><cell>KFU NLP-run1</cell><cell>0.8930</cell><cell>0.8386</cell><cell>0.8649</cell><cell>0.9701</cell><cell>0.9255</cell><cell>0.9473</cell></row><row><cell>NLP@VCU-run2</cell><cell>0.8705</cell><cell>0.8502</cell><cell>0.8602</cell><cell>0.9490</cell><cell>0.9446</cell><cell>0.9468</cell></row><row><cell>NLP@VCU-run3</cell><cell>0.8665</cell><cell>0.8514</cell><cell>0.8589</cell><cell>0.9486</cell><cell>0.9528</cell><cell>0.9507</cell></row><row><cell>KFU NLP-run2</cell><cell>0.8579</cell><cell>0.8329</cell><cell>0.8452</cell><cell>0.9690</cell><cell>0.9395</cell><cell>0.9540</cell></row><row><cell cols="2">NextMove/Minesoft-run3 0.8281</cell><cell>0.8083</cell><cell>0.8181</cell><cell>0.8543</cell><cell>0.8350</cell><cell>0.8445</cell></row><row><cell>KFU NLP-run3</cell><cell>0.8197</cell><cell>0.8027</cell><cell>0.8111</cell><cell>0.9579</cell><cell>0.9350</cell><cell>0.9463</cell></row><row><cell>BiTeM-run1</cell><cell>0.8330</cell><cell>0.7799</cell><cell>0.8056</cell><cell>0.8882</cell><cell>0.8492</cell><cell>0.8683</cell></row><row><cell>OntoChem-run1</cell><cell>0.7927</cell><cell>0.5983</cell><cell>0.6819</cell><cell>0.8441</cell><cell>0.6364</cell><cell>0.7257</cell></row><row><cell>AUKBC-run1</cell><cell>0.6763</cell><cell>0.4074</cell><cell>0.5085</cell><cell>0.8793</cell><cell>0.5334</cell><cell>0.6640</cell></row><row><cell>AUKBC-run2</cell><cell>0.4895</cell><cell>0.1913</cell><cell>0.2751</cell><cell>0.6686</cell><cell>0.2619</cell><cell>0.3764</cell></row><row><cell>SSN NLP-run1</cell><cell>0.2923</cell><cell>0.1911</cell><cell>0.2311</cell><cell>0.8633</cell><cell>0.4930</cell><cell>0.6276</cell></row><row><cell>SSN NLP-run2</cell><cell>0.2908</cell><cell>0.1911</cell><cell>0.2307</cell><cell>0.8595</cell><cell>0.4932</cell><cell>0.6267</cell></row><row><cell>JU INDIA-run1</cell><cell>0.1411</cell><cell>0.0824</cell><cell>0.1041</cell><cell>0.2522</cell><cell>0.1470</cell><cell>0.1857</cell></row><row><cell>JU INDIA-run2</cell><cell>0.0322</cell><cell>0.0151</cell><cell>0.0206</cell><cell>0.1513</cell><cell>0.0710</cell><cell>0.0966</cell></row><row><cell>JU INDIA-run3</cell><cell>0.0322</cell><cell>0.0151</cell><cell>0.0206</cell><cell>0.1513</cell><cell>0.0710</cell><cell>0.0966</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="18,134.77,196.46,345.83,229.14"><head>Table 9 .</head><label>9</label><figDesc>Overall performance of all runs in Task 2-Event Extraction. Here, P, R, and F represent the Precision, Recall, and F1-score, respectively. For each metric, we highlight the best result in bold and the second best result in italics. The results are ordered by their performance in terms of F1-score under exact-match.</figDesc><table coords="18,136.24,255.63,336.11,169.98"><row><cell>Run</cell><cell>P</cell><cell>Exact-Match R</cell><cell>F</cell><cell>P</cell><cell cols="3">Relaxed-Match R</cell><cell>F</cell></row><row><cell>Melaxtech-run1</cell><cell cols="7">0.9568 0.9504 0.9536 0.9580 0.9516 0.9548</cell></row><row><cell>Melaxtech-run2</cell><cell cols="7">0.9619 0.9402 0.9509 0.9632 0.9414 0.9522</cell></row><row><cell>Melaxtech-run3</cell><cell cols="2">0.9522 0.9437</cell><cell>0.9479</cell><cell cols="3">0.9534 0.9449</cell><cell>0.9491</cell></row><row><cell cols="2">NextMove/Minesoft-run1 0.9441</cell><cell>0.8556</cell><cell>0.8977</cell><cell cols="2">0.9441</cell><cell>0.8556</cell><cell>0.8977</cell></row><row><cell cols="2">NextMove/Minesoft-run2 0.8746</cell><cell>0.7816</cell><cell>0.8255</cell><cell cols="2">0.8909</cell><cell>0.7983</cell><cell>0.8420</cell></row><row><cell>BOUN REX-run1</cell><cell>0.7610</cell><cell>0.6893</cell><cell>0.7234</cell><cell cols="2">0.7610</cell><cell>0.6893</cell><cell>0.7234</cell></row><row><cell>NLP@VCU-run1</cell><cell>0.8056</cell><cell>0.5449</cell><cell>0.6501</cell><cell cols="2">0.8059</cell><cell>0.5451</cell><cell>0.6503</cell></row><row><cell>NLP@VCU-run2</cell><cell>0.5120</cell><cell>0.7153</cell><cell>0.5968</cell><cell cols="2">0.5125</cell><cell>0.7160</cell><cell>0.5974</cell></row><row><cell>NLP@VCU-run3</cell><cell>0.5085</cell><cell>0.7126</cell><cell>0.5935</cell><cell cols="2">0.5090</cell><cell>0.7133</cell><cell>0.5941</cell></row><row><cell>Baseline</cell><cell>0.2431</cell><cell>0.8861</cell><cell>0.3815</cell><cell cols="2">0.2431</cell><cell>0.8863</cell><cell>0.3816</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="24,134.77,254.52,345.82,370.75"><head>Table 11 .</head><label>11</label><figDesc>Summary</figDesc><table coords="24,134.77,254.55,345.82,370.72"><row><cell cols="2">of participants' approaches. [10]: BiTeM; [11]: VinAI; [18]: BOUN-</cell></row><row><cell cols="2">REX; [24]: NextMove/Minesoft; [27]: NLP@VCU; [34]: AU-KBC; [37]: LasigBioTM;</cell></row><row><cell>and [46]: MelaxTech.</cell><cell></cell></row><row><cell>Characteristics</cell><cell>[10] [11] [18] [24] [27] [34] [37] [46]</cell></row><row><cell>Tokenization</cell><cell></cell></row><row><cell>Rule-based</cell><cell></cell></row><row><cell>Dictionary-based</cell><cell></cell></row><row><cell>Subword-based</cell><cell></cell></row><row><cell>Chemistry domain-specific</cell><cell></cell></row><row><cell>Representation</cell><cell></cell></row><row><cell>Embeddings</cell><cell></cell></row><row><cell>Character-level</cell><cell></cell></row><row><cell>Pre-trained</cell><cell></cell></row><row><cell>Chemistry domain-specific</cell><cell></cell></row><row><cell>Features</cell><cell></cell></row><row><cell>PoS</cell><cell></cell></row><row><cell>Phrase</cell><cell></cell></row><row><cell>Model Architecture</cell><cell></cell></row><row><cell>Transformer</cell><cell></cell></row><row><cell>Bi-LSTM</cell><cell></cell></row><row><cell>CNN</cell><cell></cell></row><row><cell>MLP</cell><cell></cell></row><row><cell>CRF</cell><cell></cell></row><row><cell>FSM</cell><cell></cell></row><row><cell>Rule based</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,144.73,645.84,135.84,8.12;4,281.81,644.59,4.83,4.35;4,291.80,645.57,50.29,8.13"><p>https://www.reaxys.com Reaxys R Copyright c</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2020" xml:id="foot_1" coords="4,366.51,645.84,114.08,7.86;4,144.73,656.80,331.21,7.86"><p>Elsevier Limited except certain content provided by third parties. Reaxys is a trademark of Elsevier Limited.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2" coords="12,144.73,657.44,150.64,7.47"><p>http://chemu.eng.unimelb.edu.au/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3" coords="14,144.73,657.44,127.10,7.47"><p>http://mallet.cs.umass.edu/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4" coords="15,144.73,645.84,335.86,7.86;15,144.73,656.80,150.70,7.86"><p>The run that we received from team Lasige BioTM is not included in the table due to a technical issue found in this run.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5" coords="18,144.73,623.92,335.86,7.86;18,144.73,634.88,335.86,7.86;18,144.73,645.84,335.87,7.86;18,144.73,656.80,79.30,7.86"><p>The run that we received from the Lasige BioTM team is not included in the table as there was a technical issue in this run. Two runs from Melaxtech, Melaxtech-run2 and Melaxtech-run3, had very low performance, due to an error in their data pre-processing step.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_6" coords="19,144.73,657.44,274.02,7.47"><p>https://github.com/seyonechithrananda/bert-loves-chemistry</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We are grateful for the detailed excerption and annotation work of the domain experts that support Reaxys, and the support of <rs type="person">Ivan Krstic</rs>, Director of <rs type="affiliation">Chemistry Solutions at Elsevier. Funding</rs> for the ChEMU project is provided by an <rs type="funder">Australian Research Council Linkage</rs> Project, project number <rs type="grantNumber">LP160101469</rs>, and Elsevier.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_QrhgjEc">
					<idno type="grant-number">LP160101469</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="28,142.96,600.54,337.64,8.12;28,151.52,612.14,51.78,7.47" xml:id="b0">
	<monogr>
		<ptr target="https://bitbucket.org/nicta_biomed/brateval/src/master/" />
		<title level="m" coord="28,151.53,600.54,112.09,7.86">BRATEval evaluation tool</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="28,142.96,622.95,318.27,8.12" xml:id="b1">
	<monogr>
		<ptr target="https://taku910.github.io/crfpp/" />
		<title level="m" coord="28,151.53,622.95,64.41,7.86">CRF++ Toolkit</title>
		<imprint>
			<date type="published" when="2020-06-23">2020-06-23</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="28,142.96,634.39,337.64,8.12;28,151.52,646.00,32.95,7.47;28,139.37,656.80,222.26,8.12" xml:id="b2">
	<monogr>
		<ptr target="https://spacy.io/api/tokenizer" />
		<title level="m" coord="28,151.53,634.39,144.50,7.86">International Patent Classification</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.96,119.67,337.64,7.86;29,151.52,130.63,329.07,7.86;29,151.52,141.57,329.07,7.89;29,151.52,152.55,25.60,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="29,437.84,130.63,42.75,7.86;29,151.52,141.59,223.19,7.86">Annotated chemical patent corpus: a gold standard for text mining</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Akhondi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G</forename><surname>Klenner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tyrchan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">K</forename><surname>Manchala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Boppana</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zimmermann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Jagarlapudi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sayle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Kors</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="29,382.03,141.59,41.16,7.86">PLoS One</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page">107477</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.96,162.74,337.64,7.86;29,151.52,173.70,329.07,7.86;29,151.52,184.63,233.23,7.89" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="29,338.59,173.70,142.00,7.86;29,151.52,184.65,135.89,7.86">Automatic identification of relevant chemical compounds from patents</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Akhondi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Rey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schwörer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Maier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Toomey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Nau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Ilchmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sheehan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Irmer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bobach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="29,294.49,184.65,37.30,7.86">Database</title>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.96,194.84,337.64,7.86;29,151.52,205.77,290.23,7.89" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="29,207.85,194.84,272.75,7.86;29,151.52,205.80,90.02,7.86">Patents: A unique source for scientific technical information in chemistry related industry?</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bregonje</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="29,244.62,205.80,105.12,7.86">World Patent Information</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="309" to="315" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.96,215.99,337.63,7.86;29,151.52,226.92,179.79,7.89" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="29,202.19,215.99,250.47,7.86">Assessing agreement on classification tasks: The kappa statistic</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carletta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="29,458.58,215.99,22.02,7.86;29,151.52,226.94,87.77,7.86">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="249" to="254" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.96,237.13,337.64,7.86;29,151.52,248.09,329.07,7.86;29,151.52,256.78,329.07,10.13;29,151.52,270.01,329.07,7.86;29,151.52,278.70,329.07,10.13;29,151.52,289.66,329.07,10.13;29,151.52,302.88,60.28,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="29,440.15,237.13,40.45,7.86;29,151.52,248.09,285.07,7.86;29,458.27,248.09,22.32,7.86;29,151.52,256.78,270.67,10.13">Contextualized french language models for biomedical named entity recognition</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Copara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Knafou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Naderi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Moro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ruch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Teodoro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="29,447.70,270.01,32.89,7.86;29,151.52,278.70,329.07,10.13;29,151.52,289.66,95.54,10.13">Rencontre des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (R ÉCITAL</title>
		<title level="s" coord="29,310.23,289.66,120.63,10.13">Atelier D Éfi Fouille de Textes</title>
		<imprint>
			<publisher>ATALA</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="36" to="48" />
		</imprint>
	</monogr>
	<note>Actes de la 6e conférence conjointe Journées d&apos; Études sur la Parole (JEP. 31e édition. 27e édition. 22e édition</note>
</biblStruct>

<biblStruct coords="29,142.62,313.07,337.98,7.86;29,151.52,324.03,329.07,7.86;29,151.52,334.99,307.08,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="29,379.93,313.07,100.66,7.86;29,151.52,324.03,271.68,7.86">Named entity recognition in chemical patents using ensemble of contextual language models</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Copara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Naderi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Knafou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ruch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Teodoro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="29,446.53,324.03,34.06,7.86;29,151.52,334.99,278.41,7.86">Working Notes of CLEF 2020-Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.62,345.17,337.98,7.86;29,151.52,356.13,329.07,7.86;29,151.52,367.09,242.91,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="29,259.58,345.17,221.01,7.86;29,151.52,356.13,210.37,7.86">VinAI at ChEMU 2020: An accurate system for named entity recognition in chemical reactions from patents</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">H</forename><surname>Dao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="29,382.77,356.13,97.83,7.86;29,151.52,367.09,214.23,7.86">Working Notes of CLEF 2020-Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.62,377.28,337.97,7.86;29,151.52,388.24,329.07,7.86;29,151.52,399.19,86.01,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="29,346.99,377.28,133.60,7.86;29,151.52,388.24,188.45,7.86">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="29,361.63,388.24,113.25,7.86">Proceedings of NAACL-HLT</title>
		<meeting>NAACL-HLT</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.62,409.38,337.97,7.86;29,151.52,420.31,329.07,7.89" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="29,383.20,409.38,97.39,7.86;29,151.52,420.34,148.62,7.86">ChemicalTagger: A tool for semantic text-mining in chemistry</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Hawizy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Jessop</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Murray-Rust</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="29,306.93,420.34,108.66,7.86">Journal of cheminformatics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">17</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.62,430.53,337.97,7.86;29,151.52,441.48,329.07,7.86;29,151.52,452.44,329.07,7.86;29,151.52,463.40,329.07,7.86;29,151.52,474.36,329.07,7.86;29,151.52,485.32,329.07,7.86;29,151.52,496.28,138.06,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="29,275.69,452.44,204.90,7.86;29,151.52,463.40,217.03,7.86">Overview of chemu 2020: Named entity recognition and event extraction of chemical reactions from patents</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Akhondi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Druckenbrodt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Hoessel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Afzal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Yoshikawa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Albahem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Cavedon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Verspoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="29,388.01,463.40,92.58,7.86;29,151.52,474.36,329.07,7.86;29,151.52,485.32,243.36,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction. Proceedings of the Eleventh International Conference of the CLEF Association (CLEF 2020)</title>
		<title level="s" coord="29,450.23,485.32,30.36,7.86;29,151.52,496.28,109.39,7.86">Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12260</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.62,506.46,337.97,7.86;29,151.52,517.42,329.07,7.86;29,151.52,528.36,69.81,7.89" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="29,465.23,506.46,15.36,7.86;29,151.52,517.42,214.16,7.86">OS-CAR4: a flexible architecture for chemical text-mining</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Jessop</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">L</forename><surname>Willighagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Hawizy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Murray-Rust</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="29,372.26,517.42,108.32,7.86">Journal of cheminformatics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.62,538.57,337.97,7.86;29,151.52,549.53,322.68,7.86" xml:id="b14">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Martin</surname></persName>
		</author>
		<title level="m" coord="29,262.46,538.57,218.13,7.86;29,151.52,549.53,187.25,7.86">Speech &amp; Language Processing, 3rd edition, chap. Semantic Role Labeling and Argument Structure</title>
		<imprint>
			<publisher>Pearson Education India</publisher>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.62,559.71,337.98,7.86;29,151.52,570.67,329.07,7.86;29,151.52,581.63,202.38,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="29,382.84,559.71,97.75,7.86;29,151.52,570.67,129.06,7.86">Overview of BioNLP&apos;09 shared task on event extraction</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Kano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="29,303.45,570.67,177.14,7.86;29,151.52,581.63,137.10,7.86">Proceedings of the BioNLP 2009 workshop companion volume for shared task</title>
		<meeting>the BioNLP 2009 workshop companion volume for shared task</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.62,589.55,337.97,10.13;29,151.52,602.78,329.07,7.86;29,151.52,613.73,329.07,7.86;29,151.52,624.69,25.60,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="29,369.03,591.82,111.55,7.86;29,151.52,602.78,309.53,7.86">BOUN-REX at CLEF-2020 ChEMU Task 2: Evaluating Pretrained Transformers for Event Extraction</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Köksal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hilal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Özgür</forename><surname>Özkırımlı Elif</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Arzucan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="29,151.52,613.73,329.07,7.86">Working Notes of CLEF 2020-Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.62,634.88,337.98,7.86;29,151.52,645.84,329.07,7.86;29,151.52,656.80,307.13,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="29,340.80,634.88,139.79,7.86;29,151.52,645.84,247.10,7.86">Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="29,421.43,645.84,59.16,7.86;29,151.52,656.80,223.04,7.86">Proceedings of the 18th International Conference on Machine Learning</title>
		<meeting>the 18th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,142.62,119.67,337.98,7.86;30,151.52,130.63,329.07,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="30,412.24,119.67,68.35,7.86;30,151.52,130.63,133.57,7.86">Method and software for extracting chemical data</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">J</forename><surname>Lawson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Roller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Grotz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Wisniewski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goebels</surname></persName>
		</author>
		<idno>DE102005020083A1</idno>
	</analytic>
	<monogr>
		<title level="j" coord="30,292.23,130.63,72.47,7.86">German patent no</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,142.62,141.60,337.97,7.86;30,151.52,152.56,329.07,7.86;30,151.52,163.52,130.32,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="30,259.23,141.60,221.36,7.86;30,151.52,152.56,117.17,7.86">BANNER: an executable survey of advances in biomedical named entity recognition</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Leaman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gonzalez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="30,290.45,152.56,149.53,7.86">Pacific Symposium on Biocomputing</title>
		<imprint>
			<publisher>World Scientific</publisher>
			<date type="published" when="2008">2008. 2008</date>
			<biblScope unit="page" from="652" to="663" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,142.62,174.49,337.98,7.86;30,151.52,185.44,176.47,7.86" xml:id="b20">
	<monogr>
		<title level="m" type="main" coord="30,196.93,174.49,180.61,7.86">Generalization and network design strategies</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<idno>CRG- TR-89-4</idno>
		<imprint>
			<date type="published" when="1989-06">June 1989</date>
		</imprint>
		<respStmt>
			<orgName>University of Toronto</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="30,142.62,196.41,337.97,7.86;30,151.52,207.37,329.07,7.86;30,151.52,218.30,159.79,7.89" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="30,438.58,196.41,42.01,7.86;30,151.52,207.37,324.76,7.86">Biobert: a pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="30,151.52,218.33,58.56,7.86">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1234" to="1240" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,142.62,229.30,337.97,7.86;30,151.52,240.26,329.07,7.86;30,151.52,251.22,25.60,7.86" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="30,247.54,229.30,213.89,7.86">Extraction of reactions from patents using grammars</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mayfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="30,151.52,240.26,329.07,7.86">Working Notes of CLEF 2020-Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,142.62,262.18,337.98,7.86;30,151.52,273.12,268.71,7.89" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="30,257.63,262.18,222.96,7.86;30,151.52,273.14,80.83,7.86">LeadMine: a grammar and dictionary driven approach to entity recognition</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">A</forename><surname>Sayle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="30,239.35,273.14,109.53,7.86">Journal of cheminformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,142.62,284.11,337.98,7.86;30,151.52,295.07,329.07,7.86;30,151.52,306.03,169.18,7.86" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="30,228.41,284.11,252.19,7.86;30,151.52,295.07,16.51,7.86">End-to-end sequence labeling via bi-directional LSTM-CNNs-CRF</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="30,190.95,295.07,289.64,7.86;30,151.52,306.03,76.28,7.86">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1064" to="1074" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,142.62,316.99,337.97,7.86;30,151.52,327.95,329.07,7.86;30,151.52,338.91,215.26,7.86" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="30,405.69,316.99,74.90,7.86;30,151.52,327.95,183.53,7.86">NLPatVCU CLEF 2020 ChEMU Shared Task System Description</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mahendran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gurdin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Lewinski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="30,354.71,327.95,125.88,7.86;30,151.52,338.91,186.58,7.86">Working Notes of CLEF 2020-Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,142.62,349.88,337.97,7.86;30,151.52,360.84,329.07,7.86;30,151.52,371.80,217.12,7.86" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="30,407.41,349.88,73.17,7.86;30,151.52,360.84,232.55,7.86">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="30,404.48,360.84,76.12,7.86;30,151.52,371.80,123.83,7.86">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="page" from="3111" to="3119" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,142.62,382.76,337.97,7.86;30,151.52,393.72,329.07,7.86;30,151.52,404.68,329.07,7.86;30,151.52,415.62,185.27,7.89" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="30,246.92,393.72,233.67,7.86;30,151.52,404.68,302.24,7.86">Making every SAR point count: the development of Chemistry Connect for the large-scale integration of structure and bioactivity data</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Petrov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Southan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Kjellberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Kogej</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tyrchan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Varkonyi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">H</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="30,460.22,404.68,20.37,7.86;30,151.52,415.64,67.02,7.86">Drug Discovery Today</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">23-24</biblScope>
			<biblScope unit="page" from="1019" to="1030" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,142.62,426.61,337.98,7.86;30,151.52,437.57,329.07,7.86;30,151.52,448.53,97.80,7.86" xml:id="b28">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hoogeveen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mubarak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Verspoor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1912.00730</idno>
		<title level="m" coord="30,207.20,437.57,209.15,7.86">Semeval-2017 task 3: Community question answering</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="30,142.62,459.49,337.98,7.86;30,151.52,470.45,329.07,7.86;30,151.52,481.41,276.63,7.86" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="30,240.16,459.49,184.65,7.86">Transformation-based learning in the fast lane</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Ngai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Florian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="30,445.37,459.49,35.22,7.86;30,151.52,470.45,329.07,7.86;30,151.52,481.41,211.26,7.86">Proceedings of the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies</title>
		<meeting>the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,142.62,492.38,337.98,7.86;30,151.52,503.34,329.07,7.86;30,151.52,514.30,329.07,7.86;30,151.52,525.26,329.07,7.86;30,151.52,536.22,60.92,7.86" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="30,413.51,503.34,67.08,7.86;30,151.52,514.30,324.95,7.86">ChEMU: Named Entity Recognition and Event Extraction of Chemical Reactions from Patents</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Yoshikawa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Druckenbrodt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Hoessel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Akhondi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Verspoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="30,166.35,525.26,293.75,7.86">Proceedings of the 42nd European Conference on Information Retrieval</title>
		<meeting>the 42nd European Conference on Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="572" to="579" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,142.62,547.18,337.97,7.86;30,151.52,558.12,266.95,7.89" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="30,306.09,547.18,174.50,7.86;30,151.52,558.14,66.24,7.86">The proposition bank: An annotated corpus of semantic roles</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Gildea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kingsbury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="30,224.35,558.14,106.72,7.86">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="106" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,142.62,569.11,337.98,7.86;30,151.52,580.07,329.07,7.86;30,151.52,591.03,215.26,7.86" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="30,324.58,569.11,156.01,7.86;30,151.52,580.07,151.14,7.86">CLRG ChemNER: A Chemical Named Entity Recognizer @ ChEMU CLEF</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">C</forename><surname>Pattabhi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lalitha Devi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="30,347.20,580.07,133.39,7.86;30,151.52,591.03,186.58,7.86">Working Notes of CLEF 2020-Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,142.62,601.99,337.98,7.86;30,151.52,612.95,329.07,7.86;30,151.52,623.91,329.07,7.86;30,151.52,634.87,134.87,7.86" xml:id="b33">
	<analytic>
		<title level="a" type="main" coord="30,195.75,612.95,167.04,7.86">Deep contextualized word representations</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="30,384.19,612.95,96.40,7.86;30,151.52,623.91,329.07,7.86;30,151.52,634.87,41.98,7.86">Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>the 2018 Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,142.62,645.84,337.97,7.86;30,151.52,656.77,295.44,7.89" xml:id="b34">
	<analytic>
		<title level="a" type="main" coord="30,442.07,645.84,38.52,7.86;30,151.52,656.80,172.97,7.86">Language models are unsupervised multitask learners</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Child</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Amodei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="30,331.32,656.80,53.37,7.86">OpenAI Blog</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,142.62,119.67,337.97,7.86;31,151.52,130.63,329.07,7.86;31,151.52,141.59,329.07,7.86;31,151.52,152.55,281.17,7.86" xml:id="b35">
	<analytic>
		<title level="a" type="main" coord="31,307.51,119.67,173.07,7.86;31,151.52,130.63,329.07,7.86;31,151.52,141.59,245.12,7.86">LasigeBioTM team at CLEF2020 ChEMU evaluation lab: Named Entity Recognition and Event extraction from chemical reactions described in patents using BioBERT NER and RE</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ruas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lamurias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M</forename><surname>Couto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="31,420.08,141.59,60.51,7.86;31,151.52,152.55,252.51,7.86">Working Notes of CLEF 2020-Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,142.62,163.51,337.98,7.86;31,151.52,174.47,329.07,7.86;31,151.52,185.43,329.07,7.86;31,151.52,196.39,125.19,7.86" xml:id="b36">
	<analytic>
		<title level="a" type="main" coord="31,151.52,174.47,329.07,7.86;31,151.52,185.43,66.16,7.86">AKANE system: protein-protein interaction pairs in BioCreAtIvE2 challenge, PPI-IPS subtask</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Saetre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yoshida</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Yakushiji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Miyao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Matsubayashi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ohta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="31,239.86,185.43,236.23,7.86">Proceedings of the second BioCreative challenge workshop</title>
		<meeting>the second BioCreative challenge workshop<address><addrLine>Madrid</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">209</biblScope>
			<biblScope unit="page">212</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,142.62,207.34,337.98,7.86;31,151.52,218.30,329.07,7.86;31,151.52,229.26,113.78,7.86" xml:id="b37">
	<analytic>
		<title level="a" type="main" coord="31,272.85,207.34,138.86,7.86">Japanese and korean voice search</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Nakajima</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="31,458.45,207.34,22.14,7.86;31,151.52,218.30,324.28,7.86">IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012. 2012</date>
			<biblScope unit="page" from="5149" to="5152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,142.62,240.22,337.97,7.86;31,151.52,251.18,329.07,7.86;31,151.52,262.11,285.28,7.89" xml:id="b38">
	<analytic>
		<title level="a" type="main" coord="31,368.63,240.22,111.96,7.86;31,151.52,251.18,329.07,7.86;31,151.52,262.14,92.97,7.86">Managing expectations: assessment of chemistry databases generated by automated extraction of chemical structures from patents</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Senger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bartek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Papadatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gaulton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="31,251.58,262.14,112.34,7.86">Journal of Cheminformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,142.62,273.10,337.98,7.86;31,151.52,284.06,329.07,7.86;31,151.52,294.99,329.07,7.89;31,151.52,305.98,42.49,7.86" xml:id="b39">
	<analytic>
		<title level="a" type="main" coord="31,441.94,273.10,38.65,7.86;31,151.52,284.06,329.07,7.86;31,151.52,295.02,33.92,7.86">CLAMPa toolkit for efficiently building customized clinical natural language processing pipelines</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Soysal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Pakhomov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="31,193.15,295.02,236.18,7.86">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="331" to="336" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,142.62,316.93,337.98,7.86;31,151.52,327.89,329.07,7.86;31,151.52,338.85,329.07,7.86;31,151.52,349.81,189.15,7.86" xml:id="b40">
	<analytic>
		<title level="a" type="main" coord="31,451.93,316.93,28.66,7.86;31,151.52,327.89,200.08,7.86">BRAT: a web-based tool for NLP-assisted text annotation</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Stenetorp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Pyysalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Topić</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ohta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ananiadou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tsujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="31,372.35,327.89,108.24,7.86;31,151.52,338.85,329.07,7.86;31,151.52,349.81,105.46,7.86">Proceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="102" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,142.62,360.77,337.97,7.86;31,151.52,371.73,329.07,7.86;31,151.52,382.69,167.19,7.86" xml:id="b41">
	<analytic>
		<title level="a" type="main" coord="31,228.73,371.73,100.53,7.86">Attention is all you need</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="31,351.88,371.73,128.71,7.86;31,151.52,382.69,73.89,7.86">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="page" from="5998" to="6008" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,142.62,393.65,271.76,7.86" xml:id="b42">
	<monogr>
		<title level="m" type="main" coord="31,218.94,393.65,166.77,7.86">Contextually-dependent lexical semantics</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Verspoor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,142.62,404.61,337.97,7.86;31,151.52,415.56,329.07,7.86;31,151.52,426.52,186.37,7.86" xml:id="b43">
	<monogr>
		<title level="m" type="main" coord="31,241.29,415.56,239.30,7.86;31,151.52,426.52,28.04,7.86">ChEMU dataset for information extraction from chemical patents</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Verspoor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Akhondi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Druckenbrodt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Hoessel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhai</surname></persName>
		</author>
		<idno type="DOI">10.17632/wy6745bjfj.1</idno>
		<ptr target="https://doi.org/10.17632/wy6745bjfj" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="31,142.62,437.48,337.98,7.86;31,151.52,448.44,329.07,7.86;31,151.52,459.40,270.67,7.86" xml:id="b44">
	<analytic>
		<title level="a" type="main" coord="31,324.57,437.48,156.02,7.86;31,151.52,448.44,238.58,7.86">Melaxtech: A report for CLEF 2020 -ChEMU Task of Chemical Reaction Extraction from Patent</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="31,410.79,448.44,69.81,7.86;31,151.52,459.40,242.01,7.86">Working Notes of CLEF 2020-Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,142.62,470.36,337.98,7.86;31,151.52,481.32,329.07,7.86;31,151.52,492.28,329.07,7.86;31,151.52,503.24,128.61,7.86" xml:id="b45">
	<analytic>
		<title level="a" type="main" coord="31,281.60,481.32,161.46,7.86">Detecting Chemical Reactions in Patents</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Yoshikawa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Druckenbrodt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Akhondi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Verspoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="31,463.03,481.32,17.56,7.86;31,151.52,492.28,329.07,7.86;31,151.52,503.24,44.67,7.86">Proceedings of the 17th Annual Workshop of the Australasian Language Technology Association</title>
		<meeting>the 17th Annual Workshop of the Australasian Language Technology Association</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="100" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="31,142.62,514.19,337.98,7.86;31,151.52,525.15,329.07,7.86;31,151.52,536.11,329.07,7.86;31,151.52,547.07,329.07,7.86;31,151.52,558.03,25.60,7.86" xml:id="b46">
	<analytic>
		<title level="a" type="main" coord="31,246.12,525.15,234.47,7.86;31,151.52,536.11,154.18,7.86">Improving Chemical Named Entity Recognition in Patents with Contextualized Word Embeddings</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Akhondi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Druckenbrodt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gregory</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Verspoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="31,325.84,536.11,154.75,7.86;31,151.52,547.07,90.93,7.86">Proceedings of the 18th BioNLP Workshop and Shared Task</title>
		<meeting>the 18th BioNLP Workshop and Shared Task</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="328" to="338" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
