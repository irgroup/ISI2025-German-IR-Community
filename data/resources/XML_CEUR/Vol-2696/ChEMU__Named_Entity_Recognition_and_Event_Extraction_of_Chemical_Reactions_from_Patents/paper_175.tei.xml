<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,158.55,115.96,298.26,12.62;1,143.28,133.89,328.80,12.62;1,162.39,151.82,290.57,12.62;1,142.72,169.76,329.92,12.62;1,296.36,187.69,22.63,12.62">LasigeBioTM team at CLEF2020 ChEMU evaluation lab: Named Entity Recognition and Event extraction from chemical reactions described in patents using BioBERT NER and RE</title>
				<funder ref="#_WY2Daq9">
					<orgName type="full">FCT</orgName>
				</funder>
				<funder ref="#_ujRm4Du">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,189.93,225.36,48.31,8.74"><forename type="first">Pedro</forename><surname>Ruas</surname></persName>
							<email>psruas@fc.ul.ptalamurias@lasige.di.fc.ul.ptfcouto@di.fc.ul.pt</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">LASIGE</orgName>
								<orgName type="department" key="dep2">Faculdade de Ciências</orgName>
								<orgName type="institution">Universidade de Lisboa</orgName>
								<address>
									<postCode>1749-016</postCode>
									<settlement>Lisbon</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,246.46,225.36,68.51,8.74"><forename type="first">Andre</forename><surname>Lamurias</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">LASIGE</orgName>
								<orgName type="department" key="dep2">Faculdade de Ciências</orgName>
								<orgName type="institution">Universidade de Lisboa</orgName>
								<address>
									<postCode>1749-016</postCode>
									<settlement>Lisbon</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,342.47,225.36,82.96,8.74"><forename type="first">Francisco</forename><forename type="middle">M</forename><surname>Couto</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">LASIGE</orgName>
								<orgName type="department" key="dep2">Faculdade de Ciências</orgName>
								<orgName type="institution">Universidade de Lisboa</orgName>
								<address>
									<postCode>1749-016</postCode>
									<settlement>Lisbon</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,158.55,115.96,298.26,12.62;1,143.28,133.89,328.80,12.62;1,162.39,151.82,290.57,12.62;1,142.72,169.76,329.92,12.62;1,296.36,187.69,22.63,12.62">LasigeBioTM team at CLEF2020 ChEMU evaluation lab: Named Entity Recognition and Event extraction from chemical reactions described in patents using BioBERT NER and RE</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">928C33F7A6B17779AB7154DF6003E19B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This manuscript describes the participation of the Lasige-BioTM team in the NER and EE tasks of the ChEMU evaluation lab. We have fine-tuned the BioBERT NER model to locate and tag named entities and the BioBERT RE model to detect relations between trigger words and named entities. For the NER task, we obtained a F1-score of 0.9392 (exact matching) and 0.9630 (relaxed matching), which was an improvement over the baseline approach and achieving the 3rd best team result. For the EE task, we were not able to produce all the required annotation files due to the dimension of the test set and, consequently, we did not obtain results in time to submit to the competition. However, we obtained an accuracy of 0.9849 when we applied the BioBERT RE model on the development set.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Chemical patents are a valuable source of information for chemical research. Every year, thousands of patents are registered, increasing the already large wealth of information available. Considering only the European Patent Office (EPO) and the year 2019, there were 7697 new patents filled in the "Pharmaceuticals" category and 6197 in the "Organic fine chemistry" category 1 . The manual analysis of these documents is costly, both in terms of time and effort, so it is necessary to develop text mining approaches to extract information in a more efficient way.</p><p>There are some challenges associated with patent text, like the presence of longer sentences, the use of specific terminology, the complexity of the syntactic Category Entity type Chemical entity "REACTION PRODUCT" "STARTING MATERIAL" "REAGENT CATALYST" "SOLVENT" "OTHER COMPOUND" Reaction property "TEMPERATURE" "TIME" "YIELD PERCENT" "YIELD OTHER" Reaction label "EXAMPLE LABEL" Table <ref type="table" coords="2,165.27,238.65,4.13,7.89">1</ref>. Entity types and the respective broad category in which they are included.</p><p>structure, which limits the performance of general text mining models, usually developed for news text <ref type="bibr" coords="2,245.53,292.65,9.96,8.74" target="#b2">[3]</ref>. In addition, chemical patents typically contain a large number of chemical compounds with a complex structure, which originates ambiguity if, for example, we aim to link those entities to a reference knowledge base <ref type="bibr" coords="2,156.96,328.51,9.96,8.74" target="#b0">[1]</ref>.</p><p>The ChEMU evaluation lab <ref type="bibr" coords="2,273.08,340.47,10.52,8.74" target="#b6">[7]</ref> proposed the chemical named entity recognition (NER) task and the chemical reaction event extraction (EE) task on a large corpus of chemical patents.</p><p>Language representation models, like Bidirectional Encoder Representations from Transformers (BERT) <ref type="bibr" coords="2,257.87,388.29,9.96,8.74" target="#b1">[2]</ref>, have shown state-of-the-art performance across several natural language processing tasks, including Named Entity Recognition (NER) and Relation Extraction (RE). The goal of NER is to find in a given text the location of named entities and to classify them according to pre-defined types. Several works have described the application of BERT to the NER task <ref type="bibr" coords="2,470.08,436.11,10.52,8.74" target="#b5">[6,</ref><ref type="bibr" coords="2,134.77,448.06,7.01,8.74" target="#b8">9]</ref>. In turn, the goal of the RE task is the detection and classification of semantic relations between two given entities in a text, and BERT has also been applied to this task <ref type="bibr" coords="2,187.73,471.97,9.96,8.74">[8]</ref>.</p><p>We describe here our approach to Task 1 (NER) and Task 2 (EE) of ChEMU, which consisted of the application of the BioBERT NER model for Task 1 and modelling Task 2 as a joint NER + RE task, in which we applied the BioBERT NER and the BioBERT RE models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Task 1 -NER</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data preparation</head><p>The objective of the task was to recognise named entities related to chemical reactions in patents and to tag them according to ten different types:</p><p>We used a rule-based tokenizer proposed by one of the BioBERT authors 2 which uses regular expressions. We started by tokenizing the text of the docu-ments belonging to the released train (900 documents) and development (225 documents) sets. Each token was then tagged according to the IOB2 notation. The separator between each sentence was an empty line. For each set, there was a file that included all tokens, one per line, and the respective tags. These files were the input for fine-tuning the model we have used, which is detailed in the next section. When the test set was released, we applied the same process to the respective documents.</p><p>Model We used BioBERT <ref type="bibr" coords="3,254.00,235.74,9.96,8.74" target="#b4">[5]</ref>, which consists of the BERT model pre-trained on several general corpora (English Wikipedia and BooksCorpus) and additionally in biomedical-specific corpora (PubMed abstracts and PMC full-text articles). The results reported by the authors show that BioBERT achieves better performance in the NER of biomedical entities in comparison with the classical implementation of BERT <ref type="bibr" coords="3,248.09,295.51,9.96,8.74" target="#b4">[5]</ref>.</p><p>We fine-tuned the BioBERT NER model using the files corresponding to the competition datasets converted to the IOB2 notation, more concretely, 900 documents in the train set and 113 randomly chosen documents in the development set. We changed the training batch size from 32 to 24 to lower the memory requirements. To lower the required time for training, we used the pre-trained weights "BioBERT-Base v1.0 (+ PubMed 200K)", which corresponds to the smallest vocabulary available for BioBERT. The number of training epochs, the learning rate and the maximum sequence length were set to the default values, respectively, 10.0, 1 -5 and 128. We did not have time to explore different values for the referred hyper-parameters, so we opted for the default values as it was the safest approach (with exception of the training batch size).</p><p>Then, we applied the fine-tuned model to recognise the entities and to predict the respective type in the remaining 112 documents of the development set that had not been previously used (inference mode). We used the same values for the hyper-parameters. We developed a module to process the BioBERT NER output and to generate the respective annotation files according to the BRAT standoff format<ref type="foot" coords="3,201.25,503.23,3.97,6.12" target="#foot_1">3</ref> . We submitted the resulting annotation files to the competition page and obtained a F1-score of 0.9524 using the exact matching criterion and a F1-score of 0.9904 using the relaxed matching criterion. Given these results, we fine-tuned again the model, but this time using all documents belonging to the train (900) and the development (225) sets.</p><p>With the release of the test set, we applied the fine-tuned model to the converted file containing the tokenized text. We maintained the previous values used in inference mode for all hyper-parameters, with the exception of the maximum sequence length, which we changed from 128 to 384, due to the presence of longer sentences in the test set when comparing with the train and the development sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Task 2 -Event extraction</head><p>Data preparation Our approach was to model the Task 2 as a joint NER and RE task. The goal was to detect trigger words and to recognise arguments involving trigger words and the entities described in Task 1. We followed a similar approach for the Task 1 and converted both the documents of the train and the development sets to the IOB2 format. But in this case, we only considered the annotations relative to event trigger words, i.e., words associated with individual steps in the context of the reaction. These event trigger words belonged to two additional entity types not present in Task 1: "REACTION STEP" and "WORKUP". Like in the Task 1, for each set there was a file that included all tokens and the respective tags.</p><p>For the RE part of the task, there were two labels for a relation between an event trigger words and a chemical entity: "ARG1", to label a relation between a trigger word and a chemical entity, and "ARGM", to label a relation between a trigger word an adjunct entity, like temperature, yield or time. First, we performed sentence segmentation of the text present in the documents of the train and the development sets and, for each sentence containing at least a trigger word and an entity, we assumed that it could potentially contain a relation. For sentence segmentation, we used the same script referred in the Task 1, which consists of a rule-based model proposed by one of the BioBERT authors. In each sentence, the trigger word and the entity were replaced, respectively, by the tags "@TRIGGER$" and "@LABEL$". If the trigger word and the entity were effectively part of an argument in the gold standard annotations, the sentence would be assigned the label "1", otherwise the label would be "0". Besides, if in a given sentence, for example, there were present a trigger word and two different entities, the sentence would appear in two different lines of the final file, each one associated with a trigger word -entity pair. At the end, for each set we obtained a file containing a sentence per line, with the respective relation label and the tags @TRIGGER$ and @LABEL$ in the correct position.</p><p>Model For the NER step, we fine-tuned the BioBERT NER model using the files corresponding to the documents of the train (900) and development (225) sets converted to the IOB2 notation. We used the same hyper-parameter values for fine-tuning as described in Task 1. The documents of the test set were also converted into a single file according to the IOB2 notation and the approach was similar to that of Task 1.</p><p>For the RE step, we considered the files containing the sentences of the train in the format described above to fine-tune the BioBERT RE model. We used the pre-trained weights "BioBERT-Base v1.0 (+ PubMed 200K) and changed the batch size from 32 to 24. The number of training epochs, the learning rate and the maximum sequence length were set to the default values, respectively, 3.0, 2 -5 and 128. We evaluated the fine-tuned model on the development set and obtained an accuracy of 0.9849. We fine-tuned again the model using all the sentences in the train and development sets. We applied the fine-tuned model to predict the relation labels in the converted documents of the test set only</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Exact evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relaxed evaluation Model</head><p>Precision Recall F1-score Precision Recall F1-score Baseline 0.9071 0.9071 0.8893 0.9219 0.8723 0.9053 LasigeBioTM 0.9327 0.9457 0.9392 0.9590 0.9671 0.9630 Table <ref type="table" coords="5,163.87,171.60,4.13,7.89">2</ref>. Task 1 (NER) evaluation using the exact and the relaxed matching criteria considering all entity types. The performance of the baseline approach and our approach are shown in terms of Precision, Recall and F1-score. The highest values for each metric in the exact and relaxed evaluations are highlighted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Exact evaluation</head><p>Relaxed  <ref type="table" coords="5,165.39,386.04,4.13,7.89">3</ref>. Task 1 (NER) evaluation using the exact and relaxed matching criteria according to each entity type. The performance of our approach is shown in terms of Precision, Recall and F1-score. The highest values for each metric in the exact and relaxed evaluations are highlighted.</p><p>changing the maximum sequence length from 128 to 384. At last, we developed a module to import the output of the RE model of BioBERT and to determine the type of the argument: "ARG1" if the relation was between a trigger word and a chemical entity, "ARGM" if the relation was between a trigger word and an adjunct entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>The evaluation results for Task 1 (NER) are available in Table <ref type="table" coords="5,411.64,616.10,4.98,8.74">2</ref> and the Table <ref type="table" coords="5,134.77,628.05,4.98,8.74">3</ref> shows the results for the task according to each entity type.</p><p>For Task 2 (EE) we did not obtain any results for the test set, but we obtained an accuracy of 0.9849 when we applied the BioBERT model on the dev set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Task 1 (NER)</head><p>Overall, the results obtained for this task, both using exact (F1-score of 0.9392) and relaxed matching (F1-score of 0.9630) criteria were positive. Comparing with the baseline approach, we obtained a higher F1-score, both considering the exact matching (+0.0499) and the relaxed matching (+0.0577) criteria. These results represent the 3rd best position in terms of team results and the 5th best position in the overall submission rank.</p><p>The good performance of the BioBERT model is due to the fact that it produces contextualised word representations that consider both the left and the right contexts of the words. The meaning of the words is usually related with the context where they appear, i.e., a given word can have two (or more) different meanings in different contexts. This is particularly relevant for chemical compounds, which can have different roles according to the reaction (i.e. the context) in which they participate. The BioBERT NER model obtained higher F1-score when recognising the entities of the type "YIELD PERCENT", both using the exact (0.9910) and the relaxed matching (0.9987) criteria. This is related with the fact that this type of entities always included the character "%" in their surface form after a numerical value (for example, "53%"), which was an immutable pattern easily recognisable. In the other hand, the model obtained the lowest results when recognising the entities of the type "REACTION PRODUCT" using the exact matching criteria (F1-score of 0.8625) and the entities of the type "REACTION CATALYST" using the relaxed matching (F1-score of 0.9118). There was more ambiguity associated with these two types of entities (and also with the entities of the type "STARTING MATERIAL") since they were related with chemical compounds, which can have different roles. This means that, for example, the chemical compound "4-nitropyridin-2-amine" can be the reaction product of a given reaction but in other reaction can participate as the reaction catalyst or as the starting chemical compound. The BioBERT NER model was able to correctly recognise almost all entities belonging to these types, however, the fact that it was originally pre-trained on scientific articles and general corpora and not on patents including chemical compounds, prevented an even higher performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Task 2 (EE)</head><p>The test set was too large (10000 documents) when comparing with the other sets, and the text of the documents was significantly larger too: the average number of characters present in the documents of the test set was 61002, whereas in the documents of the train and development sets was 835 and 772, respectively. This difference increased the required time to fine-tune and apply our model. Due to the limited time participants had to submit the results, we were only able to produce annotations for 1126 documents out of the necessary 10000 comprising the test set.</p><p>The entities and events to extract were located in the description of chemical reactions within the patents text. So the inclusion of a module able to detect the chemical reactions within the text would filter out irrelevant text and, consequently, would allow a faster application of our approach, which would be specially relevant for Task 2.</p><p>As it was previously referred, instead of using BioBERT, a model pre-trained directly over chemical patents text would possibly obtain higher performance in both tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In Task 1 (NER), we obtained a F1-score of 0.9392 (exact matching) and 0.9630 (relaxed matching), which corresponds, respectively, to an increase of 0.0499 and 0.0577 over the baseline performance and to the 3rd best performing system. For Task 2 we were not able to produce results due to the lack of time to apply our approach over the entire test set. Consequently, our future work will focus mainly on the resolution of the problems associated with the poor performance in this task. First, we will explore other RE systems, like for example "BO-LSTM" <ref type="bibr" coords="7,193.74,341.91,9.96,8.74" target="#b3">[4]</ref>. Second, we will apply a module like Yoshikawa et al. <ref type="bibr" coords="7,437.64,341.91,15.50,8.74" target="#b9">[10]</ref> to extract the specific snippets describing chemical reactions within the patents text. The machine learning model (BiLSTM-CRF) proposed by the authors obtained a significantly higher performance in the extraction of chemical reactions comparing with simpler baseline approaches, including a rule-based model, which we expect will enhance our approach.</p></div>			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="2,144.73,657.44,325.80,7.47"><p>https://github.com/dmis-lab/biobert/issues/107#issuecomment-615558492</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="3,144.73,657.44,174.17,7.47"><p>https://brat.nlplab.org/standoff.html</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This project was supported by <rs type="funder">FCT</rs> through funding of the <rs type="projectName">DeST: Deep Se-manticTagger</rs> project, ref. <rs type="grantNumber">PTDC/CCI-BIO/28685/2017</rs>, and the <rs type="projectName">LASIGE Re-</rs>searchUnit, ref. <rs type="grantNumber">UIDB/00408/2020</rs></p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_WY2Daq9">
					<idno type="grant-number">PTDC/CCI-BIO/28685/2017</idno>
					<orgName type="project" subtype="full">DeST: Deep Se-manticTagger</orgName>
				</org>
				<org type="funded-project" xml:id="_ujRm4Du">
					<idno type="grant-number">UIDB/00408/2020</idno>
					<orgName type="project" subtype="full">LASIGE Re-</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,142.96,536.34,337.64,7.86;7,151.52,547.30,329.07,7.86;7,151.52,558.23,329.07,7.89;7,151.52,569.22,232.79,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,455.76,547.30,24.83,7.86;7,151.52,558.26,252.86,7.86">Annotated chemical patent corpus: A gold standard for text mining</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Akhondi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G</forename><surname>Klenner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tyrchan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">K</forename><surname>Manchala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Boppana</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zimmermann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Jagarlapudi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sayle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Kors</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Muresan</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0107477</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0107477" />
	</analytic>
	<monogr>
		<title level="j" coord="7,412.08,558.26,45.49,7.86">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,580.15,337.63,7.86;7,151.52,591.11,329.07,8.12;7,151.52,602.71,84.73,7.47" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="7,347.54,580.15,133.05,7.86;7,151.52,591.11,214.03,7.86">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1810.04805" />
		<imprint>
			<date type="published" when="2018-10">oct 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,612.99,337.64,7.86;7,151.52,623.95,320.18,8.12" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cinciruk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Walsh</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1605.01744" />
		<title level="m" coord="7,297.12,612.99,183.47,7.86;7,151.52,623.95,139.95,7.86">Improving Automated Patent Claim Parsing: Dataset, System, and Experiments</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,634.88,337.63,7.86;7,151.52,645.84,329.07,7.86;7,151.52,656.77,319.40,7.89" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,372.62,634.88,107.97,7.86;7,151.52,645.84,299.79,7.86">BO-LSTM: Classifying relations via long short-term memory networks along biomedical ontologies</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lamurias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Sousa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M</forename><surname>Couto</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12859-018-2584-5</idno>
		<ptr target="https://doi.org/10.1186/s12859-018-2584-5" />
	</analytic>
	<monogr>
		<title level="j" coord="7,458.96,645.84,21.63,7.86;7,151.52,656.80,58.56,7.86">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,119.67,337.64,7.86;8,151.52,130.63,329.07,7.86;8,151.52,141.57,329.07,7.89;8,151.52,152.55,188.04,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,151.52,130.63,329.07,7.86;8,151.52,141.59,128.44,7.86">BioBERT: A pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<idno type="DOI">10.1093/bioinformatics/btz682</idno>
		<ptr target="https://doi.org/10.1093/bioinformatics/btz682" />
	</analytic>
	<monogr>
		<title level="j" coord="8,295.07,141.59,58.56,7.86">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1234" to="1240" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,163.51,337.64,7.86;8,151.52,174.47,171.54,7.86" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="8,325.90,163.51,154.70,7.86;8,151.52,174.47,94.23,7.86">Towards Lingua Franca Named Entity Recognition with BERT</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Awasthy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Florian</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">Tech. rep</note>
</biblStruct>

<biblStruct coords="8,142.96,185.43,337.63,7.86;8,151.52,196.39,329.07,7.86;8,151.52,207.34,329.07,7.86;8,151.52,218.30,329.07,7.86;8,151.52,229.24,329.07,7.89;8,151.52,240.22,171.84,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,413.51,196.39,67.08,7.86;8,151.52,207.34,304.17,7.86">ChEMU: Named entity recognition and event extraction of chemical reactions from patents</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Yoshikawa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Druckenbrodt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Hoessel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Akhondi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Verspoor</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-45442-5</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-45442-5" />
	</analytic>
	<monogr>
		<title level="j" coord="8,463.57,207.34,17.03,7.86;8,151.52,218.30,132.61,7.86;8,383.30,229.24,24.63,7.89">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">12036</biblScope>
			<biblScope unit="page" from="572" to="579" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>LNCS</note>
</biblStruct>

<biblStruct coords="8,142.96,251.18,337.64,7.86;8,151.52,262.14,329.08,7.86;8,151.52,273.10,154.17,7.86" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="8,365.28,251.18,115.31,7.86;8,151.52,262.14,239.09,7.86">Deep Bidirectional Transformers for Relation Extraction without Supervision</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Papanikolaou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pierleoni</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d19-6108</idno>
		<ptr target="https://doi.org/10.18653/v1/d19-6108" />
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="67" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,284.06,337.64,7.86;8,151.52,295.02,329.07,7.86;8,151.52,305.98,329.07,8.11;8,151.52,317.58,176.16,7.47" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="8,255.69,284.06,224.90,7.86;8,151.52,295.02,298.64,7.86">Transfer Learning in Biomedical Natural Language Processing: An Evaluation of BERT and ELMo on Ten Benchmarking Datasets</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/w19-5006</idno>
		<ptr target="https://www.mendeley.com/catalogue/2347f426-b409-3772-9174-688480ed2a76/" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,327.89,337.98,7.86;8,151.52,338.85,329.07,7.86;8,151.52,349.81,329.07,7.86;8,151.52,360.77,329.07,8.12;8,151.52,372.37,38.16,7.47" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,288.32,338.85,166.83,7.86">Detecting Chemical Reactions in Patents</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Yoshikawa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Druckenbrodt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Akhondi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Verspoor</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/U19-1014" />
	</analytic>
	<monogr>
		<title level="m" coord="8,463.04,338.85,17.56,7.86;8,151.52,349.81,329.07,7.86;8,151.52,360.77,93.87,7.86">Proceedings of the The 17th Annual Workshop of the Australasian Language Technology Association (3)</title>
		<meeting>the The 17th Annual Workshop of the Australasian Language Technology Association (3)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="100" to="110" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
