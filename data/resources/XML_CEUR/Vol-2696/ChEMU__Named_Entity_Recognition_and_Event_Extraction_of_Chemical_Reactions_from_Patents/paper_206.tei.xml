<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,150.84,115.96,313.67,12.62;1,144.89,133.89,325.57,12.62;1,270.28,151.82,74.79,12.62">BOUN-REX at CLEF-2020 ChEMU Task 2: Evaluating Pretrained Transformers for Event Extraction</title>
				<funder ref="#_rs24p3u">
					<orgName type="full">Turkish Academy of Sciences</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,140.93,190.28,59.36,8.74"><forename type="first">Hilal</forename><surname>Dönmez</surname></persName>
							<email>hilal.donmez@boun.edu.tr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Engineering</orgName>
								<orgName type="institution">Bogaziçi University</orgName>
								<address>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,215.42,190.28,77.54,8.74"><forename type="first">Abdullatif</forename><surname>Köksal</surname></persName>
							<email>abdullatif.koksal@boun.edu.tr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Engineering</orgName>
								<orgName type="institution">Bogaziçi University</orgName>
								<address>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,308.10,190.28,59.39,8.74"><forename type="first">Elif</forename><surname>Ozkirimli</surname></persName>
							<email>elif.ozkirimli@boun.edu.tr</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Chemical Engineering</orgName>
								<orgName type="institution">Bogaziçi University</orgName>
								<address>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Pharma International Informatics Data and Analytics Chapter</orgName>
								<orgName type="institution">F. Hoffmann-La Roche AG</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,403.77,187.77,66.19,11.26"><forename type="first">Arzucan</forename><surname>Özgür</surname></persName>
							<email>arzucan.ozgur@boun.edu.tr</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Engineering</orgName>
								<orgName type="institution">Bogaziçi University</orgName>
								<address>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,150.84,115.96,313.67,12.62;1,144.89,133.89,325.57,12.62;1,270.28,151.82,74.79,12.62">BOUN-REX at CLEF-2020 ChEMU Task 2: Evaluating Pretrained Transformers for Event Extraction</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">99A4D81D55C1E4CF08A6F4A674FC4B16</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we describe our models and results designated for CLEF-2020 ChEMU Task 2 [4], event extraction for chemical patent documents. We make use of the recent advances in pretrained transformer architectures such as BERT and BioBERT. We compare several transformers with different settings in order to improve performance. Our best performing model with BioBERT transformer architecture and AdamW optimizer achieves 0.7234 exact F1 score on the test dataset.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Chemical information in patents is an essential resource for researchers working on chemical exploration and reactions. As the number of patents grows rapidly, Natural Language Processing (NLP) approaches are widely used to extract chemical information from patents so as to reduce the time and effort spent. Most previous studies on chemical information extraction focus on chemical named entity recognition (NER) <ref type="bibr" coords="1,246.36,492.55,10.52,8.74" target="#b5">[6]</ref> thanks to publicly available annotated corpora. On the other hand, there is a limited number of studies on chemical event extraction from patents.</p><p>Event extraction from patents contains detection of event trigger word, event trigger type, and event type. Figure <ref type="figure" coords="1,288.79,541.17,4.98,8.74" target="#fig_0">1</ref> illustrates an example sentence of the event extraction task in the dataset released by Cheminformatics Elsevier Melbourne University (ChEMU). In this example, room temperature and 30 minutes are given as entities with their corresponding types: TEMPERATURE and TIME. After stirred is detected as a trigger word for both entities, two event types (both of type ARGM) are determined separately according to the relevant entity type. In this work, we investigated the impact of various transformer architectures with different parameters on event extraction from patents by conducting several experiments. We also explored the effects of the pretraining corpus of transformers by comparing BERT <ref type="bibr" coords="2,263.75,238.92,10.52,8.74" target="#b1">[2]</ref> and BioBERT <ref type="bibr" coords="2,342.44,238.92,9.96,8.74" target="#b6">[7]</ref>. Besides, we investigated the significance of different optimizers such as Adam, AdamW, and SGD for the finetuning of transformers for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Determining the semantic relation between entities is an important scientific problem in various domains such as biomedical text, digital text, and governmental documents. Recently, deep neural networks have been widely used to identify the relations between entities. Previous research studies that use deep learning for relation extraction make use of CNN <ref type="bibr" coords="2,353.25,365.95,15.50,8.74" target="#b16">[17]</ref> and RNN <ref type="bibr" coords="2,417.45,365.95,15.50,8.74" target="#b19">[20]</ref> models by taking sentence representations with word vectors such as Word2Vec <ref type="bibr" coords="2,444.92,377.90,15.50,8.74" target="#b10">[11]</ref> and GloVe <ref type="bibr" coords="2,165.93,389.86,15.50,8.74" target="#b12">[13]</ref> in order to extract features automatically instead of hand-crafted features <ref type="bibr" coords="2,171.95,401.81,9.96,8.74" target="#b4">[5]</ref>. Recent studies on relation extraction have been based on the transformer architecture <ref type="bibr" coords="2,222.01,413.77,15.50,8.74" target="#b14">[15]</ref> trained on large amounts of unlabeled data to improve the state-of-the-art on several natural language processing tasks. In <ref type="bibr" coords="2,433.32,425.73,14.61,8.74" target="#b18">[19]</ref>, a pretrained transformer model is utilized to extract efficient relation representations from text.</p><p>In event extraction, earlier neural network models enhanced CNN <ref type="bibr" coords="2,445.17,461.59,15.50,8.74" target="#b11">[12]</ref> and RNN <ref type="bibr" coords="2,159.78,473.55,15.50,8.74" target="#b17">[18]</ref> with different kinds of word representations to determine the locations and types of trigger words. In addition, structured information benefiting from dependency trees <ref type="bibr" coords="2,214.82,497.46,10.52,8.74" target="#b7">[8]</ref> and knowledge bases <ref type="bibr" coords="2,326.16,497.46,10.52,8.74" target="#b8">[9]</ref> is exploited by neural networks to improve event extraction performance. Lately, pretrained transformer based models have gained popularity for event extraction. In <ref type="bibr" coords="2,382.21,521.37,14.61,8.74" target="#b15">[16]</ref>, trigger and argument extractor models obtain feature representations using BERT, a pretrained transformer model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology and Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data</head><p>We use the dataset released for the ChEMU tasks on information extraction from chemical patents. The dataset contains chemical patent documents with annotation files for training, development, and test sets. Entities with their types and relations between these entities are included in the annotation files. There are 10 different types of entity annotations for the Event Extraction Task in ChEMU. Table <ref type="table" coords="3,204.36,130.95,4.98,8.74" target="#tab_0">1</ref> shows the annotated types of entities in the dataset. The event extraction problem focuses on event trigger word detection, trigger type detection, and event type prediction. Event trigger words whose types are REACTION STEP or WORKUP are identified and the chemical entity arguments of the events are determined. The relation between an argument and a trigger word is labeled as a semantic argument role label, which is Arg1 or ArgM. The relation between a trigger word and a temperature, time or yield entity is labeled as ArgM, whereas the relation between a trigger word and an entity having one of the other entity types is labeled as Arg1. Table <ref type="table" coords="3,436.37,387.18,4.98,8.74" target="#tab_1">2</ref> contains the statistics of the ChEMU Dataset. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Preprocessing</head><p>Our preprocessing steps involve sentence splitting and adding entity markers.</p><p>For simplicity, we consider the relations that are present in single sentences, and we split the documents into sentences via the GENIA Sentence Splitter <ref type="bibr" coords="4,444.88,187.99,14.61,8.74" target="#b13">[14]</ref>. For each entity in a sentence, we construct sentence-entity pairs and predict events and trigger words from these pairs. On the other hand, there are 121 entities that have relations with more than one trigger word in our training set. We ignore these kinds of entities for event trigger word detection.</p><p>We need to explicitly identify an entity to find the corresponding relation and trigger word in a sentence. Therefore, we add specific markers called &lt;E&gt; and &lt;/E&gt; before and after the entities for the model to identify the entities by following the discussion in <ref type="bibr" coords="4,267.22,300.62,9.96,8.74" target="#b0">[1]</ref>. Moreover, we create different representations for each sentence having more than one entity by applying the marker method. Hence, the sentence representation is distinct for each entity in the same sentence having more than one entities. The following examples show that there are two different representations for hexanes and silica, which are located in the same sentence.</p><p>-The solvent was removed in vacuo, and the crude product was purified by flash chromatography (silica, 100% &lt;E&gt; hexanes &lt;/E&gt; to 9:1 hexanes/EtOAc) to give a pale-yellow viscous oil (3.83 g, 86%).</p><p>-The solvent was removed in vacuo, and the crude product was purified by flash chromatography (&lt;E&gt; silica &lt;/E&gt;, 100% hexanes to 9:1 hexanes/EtOAc) to give a pale-yellow viscous oil (3.83 g, 86%).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Model</head><p>Problem Definition: For a given sentence S with an entity e t with type t, the objectives are to find the trigger word in S, its type including None, and the relation between the trigger word and e t from a set of predefined event types. As event types are determined according to entity types, we do not make a model for event type detection. Hence, we focus on trigger type and trigger word detection. If there is a trigger word for an entity in a given sentence, the event type is found by simple rules. Two objectives are selected to address this problem. Our base model is a transformer-based pretrained architecture, which extracts a fixed-length sentence representation and token representations from an input sentence with entity markers indicating the entity's location. The fixed-length sentence representation is utilized to detect the type of the trigger word in the sentence with a given annotated entity. If there is a trigger word in the sentence, the event type is determined by the type of the given entity from a simple lookup table shown in Table <ref type="table" coords="5,204.01,384.44,3.87,8.74" target="#tab_2">3</ref>.</p><p>We propose an approach similar to question answering methods <ref type="bibr" coords="5,436.81,410.03,10.52,8.74" target="#b1">[2]</ref> to find the span of the trigger word. Our trigger word span model predicts probabilities of start and end tags with the token representations which are produced by the transformer-based pretrained architecture. Trigger word span is the sequence between tokens with the highest start and end probabilities.</p><p>Our proposed architecture is jointly trained, as shown in Figure <ref type="figure" coords="5,431.47,483.45,3.87,8.74" target="#fig_1">2</ref>. Different pretrained transformers with several optimizers, learning rates, and weight decays are evaluated on the development set by exact F1 scores. The considered settings are summarized below. The configuration for our best model is shown in bold.</p><p>-Transformer Architectures: BioBERT  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>We compare our results with pretrained transformer architectures with different settings. We evaluate the final performance of our model with exact F1 and relax F1 scores given in <ref type="bibr" coords="6,234.13,492.04,9.96,8.74" target="#b3">[4]</ref>. Furthermore, the F1 score for trigger type detection and the accuracy for trigger word span detection are also presented. We report our results by taking the average scores of 10 runs to decrease the effect of high variance in transformers architectures, as stated in <ref type="bibr" coords="6,359.09,527.91,9.96,8.74" target="#b2">[3]</ref>. As shown in Table <ref type="table" coords="7,236.48,118.99,3.87,8.74" target="#tab_4">4</ref>, the best performing pretrained transformer model is BioBERT with AdamW optimizer, even though the complexities of BERT Large and BioBERT Large are higher than BioBERT. BERT Large and BioBERT Large have 24 layers, 16 heads, and 340 million parameters while BioBERT has 12 layers, 12 heads, and 110 million parameters. Besides, while BERT Large is pretrained on English Wikipedia and Book Corpus, BioBERT and BioBERT Large are pretrained on additional resources, i.e., Pubmed Abstracts and PMC full-text articles. Table <ref type="table" coords="7,200.28,202.68,4.98,8.74" target="#tab_4">4</ref> shows that BioBERT and BioBERT perform better than BERT Large . Our results suggest that the domain similarity between chemical patent documents and the pretraining corpus BioBERT and BioBERT Large leads to better performance. In <ref type="bibr" coords="7,273.10,238.55,14.61,8.74" target="#b9">[10]</ref>, it is shown that the generalization capability of the AdamW optimizer is better than the Adam and SGD optimizers and our results support this claim. There are two different objectives, namely trigger type detection and trigger word span detection, in our final architecture. Table <ref type="table" coords="7,372.71,465.51,4.98,8.74" target="#tab_5">5</ref> contains the results of the two objectives separately on the development set. The trigger type detection model achieves 0.9848 F1 score, whereas the accuracy of our trigger word span model is 0.9524. Our final model's performance is summarized in Table <ref type="table" coords="7,395.50,644.16,4.98,8.74" target="#tab_6">6</ref> for all objectives: trigger word, trigger type and event type detections. It achieves 0.7407 and 0.7234 in the main metric (exact F1) on the development and test sets, consecutively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>In this paper, we introduce a transformer based approach for event extraction in chemical patent documents. We compare several pretrained transformer models with different settings and show that BioBERT's performance with the AdamW optimizer is better than both BERT Large and BioBERT Large for this task. Finally, we report our best model's performance separately on the trigger type and trigger word span detection tasks. Our best model, BioBERT, achieves 0.7234 exact F1 score on the test set.</p><p>As future work, we plan to extend our study to enable the detection of multiple trigger words in a sentence by using a sequence labeling setup with the BIO encoding. Thus, we will consider entities having relations with more than one trigger word. In addition, we will design a two-stage model that firstly detects the trigger word span and then classifies the trigger type as an alternative to our jointly trained model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,179.89,167.46,255.57,7.89"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. An event extraction example from the ChEMU Dataset</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,134.77,343.21,345.83,7.89;6,134.77,354.19,345.82,7.86;6,134.77,365.15,345.83,7.86;6,134.77,376.11,46.80,7.86;6,234.85,376.11,245.74,7.86;6,134.77,387.07,330.34,7.86;6,225.14,230.83,219.81,61.11"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Our final model with trigger type detection and trigger word span model. wi's represent wordpieces constructed from the tokenizer of the pretrained transformer. CLS and SEP are special tokens used as a fixed-length sentence representation and as a separator, Trigger type detection is used to classify the type of the trigger word. Trigger word span model finds the span of the trigger word in the sentence.</figDesc><graphic coords="6,225.14,230.83,219.81,61.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,177.19,168.99,242.30,85.45"><head>Table 1 .</head><label>1</label><figDesc>Annotated Entity Types in Chemical Patents</figDesc><table coords="3,177.19,189.76,232.01,64.68"><row><cell cols="2">Entity Types</cell></row><row><cell>REACTION PRODUCT</cell><cell>STARTING MATERIAL</cell></row><row><cell>REAGENT CATALYST</cell><cell>SOLVENT</cell></row><row><cell>OTHER COMPOUND</cell><cell>EXAMPLE LABEL</cell></row><row><cell>TEMPERATURE</cell><cell>TIME</cell></row><row><cell>YIELD PERCENT</cell><cell>YIELD OTHER</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,134.77,435.24,345.83,147.86"><head>Table 2 .</head><label>2</label><figDesc>Statistics of the ChEMU Dataset. Chemical patent documents are split into sentences via GENIA Sentence Splitter<ref type="bibr" coords="3,296.39,446.22,13.52,7.86" target="#b12">[13]</ref>. The gold standard labels for the test set are not available at this time. Therefore, the corresponding entries in the table are marked with '-'.</figDesc><table coords="3,168.85,487.14,259.07,95.96"><row><cell></cell><cell>Train Set</cell><cell>Development</cell><cell>Test Set</cell></row><row><cell></cell><cell></cell><cell>Set</cell><cell></cell></row><row><cell># of documents</cell><cell>900 4</cell><cell>225</cell><cell>9999</cell></row><row><cell># of entities</cell><cell>16343</cell><cell>3843</cell><cell>4575980</cell></row><row><cell># of trigger words</cell><cell>6867</cell><cell>1605</cell><cell>-</cell></row><row><cell># of relations</cell><cell>14310</cell><cell>3332</cell><cell>-</cell></row><row><cell cols="2"># of Arg1 relations 9703</cell><cell>2247</cell><cell>-</cell></row><row><cell cols="2"># of ArgM relations 4607</cell><cell>1085</cell><cell>-</cell></row><row><cell># of sentences</cell><cell>5974</cell><cell>1418</cell><cell>3942870</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,205.54,115.91,198.67,139.05"><head>Table 3 .</head><label>3</label><figDesc>Lookup table for event types</figDesc><table coords="5,205.54,136.68,198.67,118.28"><row><cell>Entity Types</cell><cell>Event Type</cell></row><row><cell>REACTION PRODUCT</cell><cell></cell></row><row><cell>STARTING MATERIAL</cell><cell></cell></row><row><cell>REAGENT CATALYST</cell><cell>Arg1</cell></row><row><cell>SOLVENT</cell><cell></cell></row><row><cell>OTHER COMPOUND</cell><cell></cell></row><row><cell>EXAMPLE LABEL</cell><cell></cell></row><row><cell>TEMPERATURE</cell><cell></cell></row><row><cell>TIME</cell><cell>ArgM</cell></row><row><cell>YIELD PERCENT</cell><cell></cell></row><row><cell>YIELD OTHER</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,134.77,577.12,345.83,72.90"><head>Table 4 .</head><label>4</label><figDesc>Exact F1 scores of pretrained transformer architectures with different optimizers on the development set.</figDesc><table coords="6,167.43,608.85,261.73,41.16"><row><cell>Optimizer</cell><cell>BioBERT</cell><cell cols="2">BioBERT Large BERT Large</cell></row><row><cell>AdamW</cell><cell>0.7367</cell><cell>0.7332</cell><cell>0.7329</cell></row><row><cell>Adam</cell><cell>0.7351</cell><cell>0.7227</cell><cell>0.7042</cell></row><row><cell>SGD</cell><cell>0.7292</cell><cell>0.7177</cell><cell>0.6755</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,134.77,295.25,345.83,117.13"><head>Table 5 .</head><label>5</label><figDesc>F1 score for trigger type detection and accuracy for trigger word span detection on the development set.</figDesc><table coords="7,166.70,326.98,274.60,85.40"><row><cell>Module</cell><cell>Class</cell><cell>BioBERT+AdamW</cell></row><row><cell></cell><cell>All</cell><cell>0.9848</cell></row><row><cell>Trigger Type Detection</cell><cell>None Reaction Step</cell><cell>0.9735 0.9885</cell></row><row><cell></cell><cell>Workup</cell><cell>0.9822</cell></row><row><cell></cell><cell>Both</cell><cell>0.9524</cell></row><row><cell>Trigger Word Span</cell><cell>Start</cell><cell>0.9591</cell></row><row><cell></cell><cell>End</cell><cell>0.9567</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="7,134.77,532.23,345.82,70.75"><head>Table 6 .</head><label>6</label><figDesc>Our final model's precision, recall, and F1 scores on the development and test sets.</figDesc><table coords="7,136.32,561.82,325.80,41.16"><row><cell></cell><cell cols="2">Precision</cell><cell></cell><cell>Recall</cell><cell></cell><cell>F1</cell></row><row><cell></cell><cell>Exact</cell><cell>Relax</cell><cell>Exact</cell><cell>Relax</cell><cell>Exact</cell><cell>Relax</cell></row><row><cell cols="2">Development Set 0.7690</cell><cell>0.7700</cell><cell>0.7069</cell><cell>0.7072</cell><cell>0.7367</cell><cell>0.7372</cell></row><row><cell>Test Set</cell><cell>0.7610</cell><cell>0.7610</cell><cell>0.6893</cell><cell>0.6893</cell><cell>0.7234</cell><cell>0.7234</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="3,144.73,645.84,335.86,7.86;3,144.73,656.80,130.19,7.86"><p>We were able to use 713 out of the 900 documents in the train set due to a problem during the downloading process.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1" coords="5,144.73,635.53,240.08,7.47"><p>https://huggingface.co/monologg/biobert_v1.1_pubmed</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2" coords="5,144.73,646.48,184.08,7.47"><p>https://github.com/google-research/bert</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_3" coords="5,144.73,657.44,240.08,7.47"><p>https://huggingface.co/trisongz/biobert_large_cased</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6">Acknowledgements</head><p><rs type="grantName">GEBIP Award</rs> of the <rs type="funder">Turkish Academy of Sciences</rs> (to A.O.) is gratefully acknowledged.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_rs24p3u">
					<orgName type="grant-name">GEBIP Award</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.96,490.95,337.64,7.86;8,151.52,501.91,329.07,7.86;8,151.52,512.87,329.07,7.86;8,151.52,523.83,329.07,7.86;8,151.52,534.79,329.07,8.12;8,151.52,546.39,85.23,7.47" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,442.71,490.95,37.88,7.86;8,151.52,501.91,251.65,7.86">Matching the blanks: Distributional similarity for relation learning</title>
		<author>
			<persName coords=""><forename type="first">Baldini</forename><surname>Soares</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kwiatkowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-1279</idno>
		<ptr target="https://www.aclweb.org/anthology/P19-1279" />
	</analytic>
	<monogr>
		<title level="m" coord="8,432.52,501.91,48.07,7.86;8,151.52,512.87,329.07,7.86;8,151.52,523.83,13.15,7.86">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07">Jul 2019</date>
			<biblScope unit="page" from="2895" to="2905" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,557.44,337.64,7.86;8,151.52,568.40,329.07,7.86;8,151.52,579.35,329.07,7.86;8,151.52,590.31,329.07,7.86;8,151.52,601.27,329.07,7.86;8,151.52,612.23,329.07,8.12;8,151.52,623.84,137.01,7.47" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,364.92,557.44,115.67,7.86;8,151.52,568.40,213.60,7.86">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/N19-1423</idno>
		<ptr target="https://www.aclweb.org/anthology/N19-1423" />
	</analytic>
	<monogr>
		<title level="m" coord="8,385.79,568.40,94.80,7.86;8,151.52,579.35,329.07,7.86;8,151.52,590.31,205.37,7.86;8,255.69,601.27,173.46,7.86">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06">Jun 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Association for Computational Linguistics</note>
</biblStruct>

<biblStruct coords="8,142.96,634.88,337.64,7.86;8,151.52,645.84,329.07,7.86;8,151.52,656.80,199.03,7.86" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dodge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Ilharco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Farhadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Smith</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.06305</idno>
		<title level="m" coord="8,459.73,634.88,20.87,7.86;8,151.52,645.84,329.07,7.86;8,151.52,656.80,32.81,7.86">Finetuning pretrained language models: Weight initializations, data orders, and early stopping</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,142.96,119.67,337.63,7.86;9,151.52,130.63,329.07,7.86;9,151.52,141.59,329.07,7.86;9,151.52,152.55,329.07,7.86;9,151.52,163.51,329.07,7.86;9,151.52,174.47,329.07,7.86;9,151.52,185.43,329.07,7.86;9,151.52,196.39,325.82,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,259.97,141.59,220.63,7.86;9,151.52,152.55,202.50,7.86">Overview of chemu 2020: Named entity recognition and event extraction of chemical reactions from patents</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">Q</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Akhondi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Druckenbrodt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Thorne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Hoessel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Afzal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Yoshikawa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Albahem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Cavedon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Cohn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Verspoor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,260.76,174.47,219.84,7.86;9,151.52,185.43,329.07,7.86;9,151.52,196.39,77.53,7.86">Proceedings of the Eleventh International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="9,305.85,196.39,142.82,7.86">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Joho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Lioma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the Eleventh International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="volume">12260</biblScope>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="9,142.96,207.36,337.63,7.86;9,151.52,218.31,329.07,7.86;9,151.52,229.27,224.29,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,215.39,207.36,265.20,7.86;9,151.52,218.31,166.90,7.86">Combining lexical, syntactic, and semantic features with maximum entropy models for information extraction</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kambhatla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,338.98,218.31,141.61,7.86;9,151.52,229.27,140.54,7.86">Proceedings of the ACL Interactive Poster and Demonstration Sessions</title>
		<meeting>the ACL Interactive Poster and Demonstration Sessions</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="178" to="181" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,240.24,337.64,7.86;9,151.52,251.20,329.07,7.86;9,151.52,262.13,303.87,7.89" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,301.26,251.20,179.33,7.86;9,151.52,262.16,114.66,7.86">The chemdner corpus of chemicals and drugs and its annotation principles</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Krallinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Rabal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Leitner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Vazquez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Salgado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Leaman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,272.98,262.16,109.52,7.86">Journal of cheminformatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,273.13,337.63,7.86;9,151.52,284.09,329.07,7.86;9,151.52,295.02,159.79,7.89" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,438.58,273.13,42.01,7.86;9,151.52,284.09,324.76,7.86">Biobert: a pre-trained biomedical language representation model for biomedical text mining</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yoon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>So</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,151.52,295.05,58.56,7.86">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1234" to="1240" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,306.02,337.64,7.86;9,151.52,316.98,329.07,7.86;9,151.52,327.94,329.07,7.86;9,151.52,338.89,270.73,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,285.01,306.02,195.58,7.86;9,151.52,316.98,63.44,7.86">Biomedical event extraction based on knowledgedriven tree-lstm</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,237.21,316.98,243.38,7.86;9,151.52,327.94,329.07,7.86;9,151.52,338.89,30.54,7.86">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1421" to="1430" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="9,142.96,349.86,337.63,7.86;9,151.52,360.82,329.07,7.86;9,151.52,371.78,329.07,7.86;9,151.52,382.74,25.60,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,333.88,349.86,146.71,7.86;9,151.52,360.82,94.94,7.86">Leveraging framenet to improve automatic event detection</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,268.90,360.82,211.69,7.86;9,151.52,371.78,160.30,7.86">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="2134" to="2143" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct coords="9,142.62,393.71,337.97,7.86;9,151.52,404.67,191.40,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,255.94,393.71,152.34,7.86">Decoupled weight decay regularization</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Loshchilov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hutter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,428.35,393.71,52.24,7.86;9,151.52,404.67,162.74,7.86">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,415.64,337.98,7.86;9,151.52,426.60,263.42,7.86" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<title level="m" coord="9,341.33,415.64,139.26,7.86;9,151.52,426.60,101.88,7.86">Efficient estimation of word representations in vector space</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,142.62,437.57,337.97,7.86;9,151.52,448.53,329.07,7.86;9,151.52,459.48,329.07,7.86;9,151.52,470.44,329.07,7.86;9,151.52,481.40,25.60,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,274.86,437.57,205.73,7.86;9,151.52,448.53,107.49,7.86">Event detection and domain adaptation with convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">H</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,282.75,448.53,197.84,7.86;9,151.52,459.48,329.07,7.86;9,151.52,470.44,164.82,7.86">Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</title>
		<meeting>the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="365" to="371" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct coords="9,142.62,492.37,337.97,7.86;9,151.52,503.33,329.07,7.86;9,151.52,514.29,264.56,8.12" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,329.82,492.37,150.77,7.86;9,151.52,503.33,35.30,7.86">Glove: Global vectors for word representation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/D14-1162" />
	</analytic>
	<monogr>
		<title level="m" coord="9,208.20,503.33,250.94,7.86">Empirical Methods in Natural Language Processing (EMNLP)</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,525.26,337.98,7.86;9,151.52,536.22,329.07,7.86;9,151.52,547.18,329.07,7.86;9,151.52,558.14,88.34,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,151.52,536.22,329.07,7.86;9,151.52,547.18,28.98,7.86">Akane system: protein-protein interaction pairs in biocreative2 challenge, ppi-ips subtask</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Saetre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yoshida</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Yakushiji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Miyao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Matsubayashi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ohta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="9,203.32,547.18,234.39,7.86">Proceedings of the second biocreative challenge workshop</title>
		<imprint>
			<biblScope unit="volume">209</biblScope>
			<biblScope unit="page">212</biblScope>
			<date type="published" when="2007">2007</date>
			<pubPlace>Madrid</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,569.11,337.97,7.86;9,151.52,580.04,308.53,7.89" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="9,226.83,580.06,98.00,7.86">Attention is all you need</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno>ArXiv abs/1706.03762</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,591.03,337.97,7.86;9,151.52,601.99,329.07,7.86;9,151.52,612.95,288.08,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,326.67,591.03,153.92,7.86;9,151.52,601.99,142.09,7.86">Exploring pre-trained language models for event extraction and generation</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Kan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,315.53,601.99,165.06,7.86;9,151.52,612.95,195.18,7.86">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5284" to="5294" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.62,623.92,337.98,7.86;9,151.52,634.88,329.07,7.86;9,151.52,645.84,329.07,7.86;9,151.52,656.80,25.60,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,340.43,623.92,140.17,7.86;9,151.52,634.88,107.85,7.86">Relation classification via convolutional deep neural network</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zeng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,282.04,634.88,198.55,7.86;9,151.52,645.84,264.60,7.86">Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</title>
		<meeting>COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="2335" to="2344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,119.67,337.97,7.86;10,151.52,130.63,329.07,7.86;10,151.52,141.59,100.39,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="10,273.19,119.67,207.40,7.86;10,151.52,130.63,108.40,7.86">Learning target-dependent sentence representations for chinese event detection</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,282.98,130.63,176.87,7.86">China Conference on Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="251" to="262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,152.55,337.97,7.86;10,151.52,163.51,292.84,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="10,296.25,152.55,184.34,7.86;10,151.52,163.51,21.35,7.86">Improving relation classification by entity pair graph</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,194.29,163.51,156.76,7.86">Asian Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1156" to="1171" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,174.47,337.98,7.86;10,151.52,185.43,329.07,7.86;10,151.52,196.39,329.07,7.86;10,151.52,207.34,168.66,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="10,383.58,174.47,97.01,7.86;10,151.52,185.43,261.06,7.86">Attention-based bidirectional long short-term memory networks for relation classification</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Xu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,432.52,185.43,48.07,7.86;10,151.52,196.39,306.54,7.86">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="207" to="212" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
