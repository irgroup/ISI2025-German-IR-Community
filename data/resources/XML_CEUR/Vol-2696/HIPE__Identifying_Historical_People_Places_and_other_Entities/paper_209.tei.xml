<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,157.02,115.96,301.32,12.62;1,149.37,133.89,316.62,12.62;1,244.99,151.82,125.38,12.62">Named Entity Recognition and Linking on Historical Newspapers: UvA.ILPS &amp; REL at CLEF HIPE 2020</title>
				<funder ref="#_Wdbhua9">
					<orgName type="full">NWO Innovational</orgName>
				</funder>
				<funder ref="#_nZP5AzV #_FtQtmHn #_RHbNEFZ">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,157.11,189.49,75.49,8.74"><forename type="first">Vera</forename><surname>Provatorova</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,243.16,189.49,84.13,8.74"><forename type="first">Svitlana</forename><surname>Vakulenko</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,337.85,189.49,86.87,8.74"><forename type="first">Evangelos</forename><surname>Kanoulas</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,435.27,189.49,22.97,8.74;1,221.89,201.45,39.24,8.74"><forename type="first">Koen</forename><surname>Dercksen</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Radboud University</orgName>
								<address>
									<settlement>Nijmegen</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,291.06,201.45,97.94,8.74"><forename type="first">Johannes</forename><forename type="middle">M</forename><surname>Van Hulst</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Radboud University</orgName>
								<address>
									<settlement>Nijmegen</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,157.02,115.96,301.32,12.62;1,149.37,133.89,316.62,12.62;1,244.99,151.82,125.38,12.62">Named Entity Recognition and Linking on Historical Newspapers: UvA.ILPS &amp; REL at CLEF HIPE 2020</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F46CCDE4CFA59937FB084D3D9701DE87</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Named Entity Linking â€¢ Named Entity Recognition</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our submission to the CLEF HIPE 2020 shared task on identifying named entities in multi-lingual historical newspapers in French, German and English. The subtasks we addressed in our submission include coarse-grained named entity recognition, entity mention detection and entity linking. For the task of named entity recognition we used an ensemble of fine-tuned BERT models; entity linking was approached by three different methods: (1) a simple method relying on ElasticSearch retrieval scores, (2) an approach based on contextualised text embeddings, and (3) REL, a modular entity linking system based on several state-of-the-art components.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Named entity identification is an important task in information extraction. Detecting, classifying and linking named entities helps to enable semantic search, which can be used for different domain applications, such as digital humanities <ref type="bibr" coords="1,152.08,484.48,14.60,8.74" target="#b13">[13]</ref>. One example is information retrieval from historical corpora. Identifying entities in historical documents poses several important challenges due to the nature of historical texts. These challenges include OCR errors in document scans, historical spelling variations and semantic shifts <ref type="bibr" coords="1,344.38,520.34,15.50,8.74" target="#b12">[12,</ref><ref type="bibr" coords="1,361.54,520.34,7.01,8.74" target="#b4">5]</ref>. This paper describes the submissions prepared by our joint team from the University of Amsterdam and Radboud University for the CLEF HIPE shared task. The main focus of CLEF HIPE is on systematic evaluation of named entity recognition and linking methods on multilingual diachronic historical data <ref type="bibr" coords="1,341.39,568.16,9.96,8.74" target="#b5">[6]</ref>. The shared task consists of several subtasks grouped into five bundles. Every team was allowed to submit one bundle per language, with the exception of bundle 5 (named entity linking given canonical mention spans), which was evaluated separately and could be combined with any other bundle.</p><p>Our submission targeted three of the subtasks in HIPE: (1) coarse-grained named entity recognition (NERC), (2) end-to-end named entity linking (NEL) using a modified NERC task for entity mention detection, and (3) named entity linking using mention spans provided by the organisers (NEL-only). Entity mention detection in this case was a supplementary task: it was not evaluated directly within the system submissions, but served as a preparation step for NEL in the setting of bundle 2, where entity mention boundaries were not given in the test data. In all the subtasks, we only considered the literal sense of the entities.</p><p>For the first phase of the shared task, we designed solutions for English, German and French languages within bundle 2, which included identifying, classifying and linking coarse-grained entities. For the second phase, bundle 5, we focused on one language only (English) and compared our results to the out-ofthe-box tool, Radboud Entity Linker (REL) <ref type="bibr" coords="2,330.45,262.46,14.61,8.74" target="#b10">[10]</ref>, as a competitive baseline.</p><p>2 Bundle 2: Named Entity Recognition and Linking</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Experimental setup</head><p>Datasets and resources. The dataset provided by the CLEF HIPE organisers consists of diachronically organised digitised historical newspaper articles in English, German and French. The data is annotated using the standard inside-outside-beginning (IOB) format and presented as tab-separated values, where each row corresponds to a single token.</p><p>While validation datasets are provided for all of the three languages, training data are only available for German and French. To provide the token classification model with a sufficient amount of training data for English, we used CoNLL-03 <ref type="bibr" coords="2,183.47,430.18,15.50,8.74" target="#b14">[14]</ref> as an auxiliary dataset.</p><p>Approach. We consider both NERC and entity mention detection tasks as instances of the sequence classification task. For the NERC task, 5 entity types (org, pers, prod, loc, and time) form 11 classes when annotated in the IOB format: each of the types has its "B-" and "I-" labels corresponding to the tokens at the beginning and inside of an entity (e.g., "B-pers" and "I-pers"), while the "O" label marks the remaining tokens which are outside of named entities. For mention detection, 3 classes are considered: "B-entity", "I-entity", and "O". To perform sequence classification, we fine-tuned two pretrained BERT models <ref type="bibr" coords="2,470.08,536.57,10.52,8.74" target="#b2">[3]</ref> provided by the Hugging Face Transformers library <ref type="bibr" coords="2,364.59,548.52,14.61,8.74" target="#b15">[15]</ref>: bert-base-cased for English and bert-base-multilingual-cased for French and German. To improve robustness of the approach, we used a majority vote ensemble of 5 model instances per language fine-tuned on the training data with different numbers of epochs, as well as different random seed values, where 5 â‰¤ num epochs â‰¤ 9 and random seed = 42 + num epochs.</p><p>To perform entity linking, we used ElasticSearch <ref type="bibr" coords="2,370.43,620.25,10.52,8.74" target="#b3">[4]</ref> to index all Wikidata entity labels and search for each of the entity mentions extracted from the input data to retrieve candidate entities. All the retrieved entities were included as candidates, without filtering on type. Candidate entity ranking was performed based on ElasticSearch retrieval scores combined with several heuristics, preferring precise matching and shorter entity IDs (assuming that the entities with shorter IDs that were added to Wikidata earlier are typically more general and therefore more likely to be correct in many cases). We used the latest Wikidata dump from 9th of March 2020 which contains more than 55M entities. An important limitation of our approach is that it relied solely on the Englishlanguage labels, which is likely to hinder its performance on some of the named entities that vary across languages, such as "Geneva" in English versus "Genf" in German.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Results and discussion</head><p>The submissions were evaluated with the HIPE scorer, which is provided by the shared task organisers and available on github. 3 The scores achieved by our submissions on the NERC task are presented in Table <ref type="table" coords="3,373.70,285.10,3.87,8.74" target="#tab_0">1</ref>. The baseline provided by the HIPE organisers for the NERC-coarse task uses a traditional CRF sequence classification method. The top solution for all languages is developed by the L3i team, with extra layers added on top of several pre-trained BERT models and trained in a multi-task learning setting to minimize the impact of OCR-generated noise, historical spelling variations and other challenges specific to the data <ref type="bibr" coords="3,293.60,479.59,9.96,8.74" target="#b1">[2]</ref>. Our approach outperforms the baseline but achieves significantly lower results in comparison with the top solution. It shows that, while transformer-based approaches are a promising direction for named entity recognition, using a majority vote ensemble of fine-tuned models without any extra modifications is not likely to be sufficient for the setting of noisy historical data. For the end-to-end NEL task, the HIPE baseline is AIDA-light trained on English Wikipedia. The best solution was submitted by the L3i team using entity embeddings trained on Wikipedia and Wikidata, combined with probabilistic mapping. The results achieved by our submissions are presented in Table <ref type="table" coords="4,456.31,154.86,4.98,8.74" target="#tab_1">2</ref> and compared with these two approaches.</p><p>For English and German, our submission scores above the baseline but far below the top solution, which is not surprising given the simplicity of our approach. For French the recall values of our submission are below the baseline. We assume that the main reason for this performance drop is due to the fact that most of the French entities could not be found in the English-only Wikidata index used in our system. We conclude that the bottleneck of our approach is the entity retrieval rather than entity mention detection.</p><p>3 Bundle 5: Named Entity Linking with Correct Mention Spans</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental setup</head><p>Datasets and resources. Our system runs were prepared using the same HIPE corpora as in bundle 2, with no extra training data. The algorithm designed for the first two runs used pre-trained contextualised Flair string embeddings <ref type="bibr" coords="4,470.07,367.64,10.52,8.74" target="#b0">[1]</ref> provided by the task organisers.</p><p>Methods. For the first two runs, candidate entity retrieval was done the same way as in bundle 2. To perform candidate entity ranking, we calculated cosine similarity between contextual embeddings of a sentence containing the target entity mention and a modified sentence, where the target entity mention is replaced with candidate entity description extracted from Wikidata. For example, if the target sentence is "We went to London for a weekend" and a candidate entity is Q84 with the label London and the description "capital and largest city of the United Kingdom", then the modified sentence would be "We went to capital and largest city of the United Kingdom for a weekend". The idea behind our approach resides upon two basic assumptions: (1) Wikidata entity descriptions are semantically similar to the corresponding entity labels, and (2) contextualised string embeddings capture similarity between entity descriptions and entity labels. After calculating the cosine similarity score, it is multiplied by the Levenshtein similarity ratio between target and candidate entity labels to prefer precise matching where possible. In the example above, if one of the candidates is Q23306: Greater London then its score would be multiplied by sim('London', 'Greater London') = 0.6, while the score for Q84: London would remain the same, as sim('London', 'London') = 1. The similarity ratio was calculated using the FuzzyWuzzy string matching library <ref type="bibr" coords="4,429.91,620.03,9.96,8.74" target="#b6">[7]</ref>.</p><p>After using the resulting score to rank the list of candidate entities, a NIL value is inserted to the list before the first candidate that has a score below threshold. We chose the threshold value of 0.7 after tuning this parameter on the development set. For submission 2 only, we added historical spelling variations to the step of candidate retrieval using Natas library that performs historical normalisation via neural machine translation <ref type="bibr" coords="5,333.66,142.90,9.96,8.74" target="#b9">[9]</ref>.</p><p>The third run was prepared using REL [10] -a modular system that is based on several state-of-the-art components, available as a Python library as well as a web API<ref type="foot" coords="5,213.10,179.44,3.97,6.12" target="#foot_0">4</ref> . Entity linking in REL is divided into three components: (i) mention detection, (ii) candidate selection, and (iii) entity disambiguation. For this submission, mention detection was skipped since the mention spans were already provided by the organisers as the ground truth. Candidate selection consists of retrieving seven candidates for each mention. The first four candidates are retrieved based on the co-occurence probability of entities given a specific mention (a so called p(e|m) index ). The remaining three are selected based on their contextual similarity to the mention in an embedding space.</p><p>Entity disambiguation decisions are made by combining local compatibility (which includes prior importance and contextual similarity) and coherence with the other entity linking decisions in a document (global context).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results and discussion</head><p>Run 1: Baseline. While the results @1 are below the HIPE baseline (Table <ref type="table" coords="5,468.97,375.05,3.87,8.74" target="#tab_2">3</ref>), the performance @3 and @5 is better (Table <ref type="table" coords="5,328.05,387.01,3.87,8.74" target="#tab_3">4</ref>). Similar results were achieved on the development set: while the correct entity would often make it to the top-5 or top-3 of the ranked candidate list, it was rarely selected by the algorithm as the most relevant answer, and the difference between candidate scores was usually small. The algorithm was not directly optimised for top-1 candidate selection. Another obstacle for the algorithm was NIL detection: as 30% of the mentions were not linkable <ref type="bibr" coords="5,209.63,458.74,9.96,8.74" target="#b5">[6]</ref>, simply adding the NIL value to the ranked list of candidates based on the fixed threshold value was not a sufficient approach and resulted in an overwhelming number of false positives. Run 2: Historical normalisation. Adding extra candidate entities by means of historical normalisation in the second submission has resulted in more false positives and slightly decreased overall performance in comparison to the first submission. A likely explanation is that the normalisation algorithm was focusing on infrequent historical spellings <ref type="bibr" coords="6,280.23,275.17,9.96,8.74" target="#b9">[9]</ref>, most of which are not likely to be present in the HIPE dataset.</p><p>Run 3: REL. REL performs very well and takes the second place in the scoring table, which is rather remarkable for an out-of-the box linking system. We showed that REL provides a strong baseline for the NEL task on historical documents, demonstrating the state-of-the-art performance that can be reached without accounting for additional properties, such as OCR errors and language change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and future work</head><p>Our contributions within the CLEF HIPE shared task approached coarse-grained named entity recognition (NERC) and two settings of entity linking: end-to-end and NEL-only. The results for NERC show that although fine-tuning BERT models for sequence classification is enough to outperform the baselines for all three languages, achieving top performance requires extra modifications in order to deal with the challenges specific to historical data. The NEL results show that, while using an embedding-based approach that takes historical spelling variations into account is better than relying solely on ElasticSearch retrieval scores, this approach is clearly outperformed by REL, as well as by many other solutions -mostly due to its poor performance on NIL prediction and an overwhelming number of false positives on the candidate selection step. REL, in its turn, proves very efficient in the setting of the shared task, even without specifically addressing the challenges of the historical data.</p><p>There are several possible directions for future work considering all the subtasks that we approached in the context of the shared task:</p><p>Entity recognition and classification. Some examples of the ways to achieve improvements over the state-of-the-art sequence classification methods within the given task setup include (i) performing a more extensive parameter search for the Transformer models; (ii) fine-tuning more advanced pre-trained models (such as RoBERTa <ref type="bibr" coords="6,218.17,644.16,14.76,8.74" target="#b11">[11]</ref>), and (iii) reducing the impact of the noise in the training data by using OCR correction algorithms, such as <ref type="bibr" coords="6,356.32,656.12,9.96,8.74" target="#b7">[8]</ref>.</p><p>Entity linking. Since the task of entity linking consists of several steps, including candidate generation and entity disambiguation, we see further opportunities for improvement on each of these steps. Firstly, candidate generation can be improved to increase recall. One of the ways to achieve this goal is to use OCR correction as a pre-processing step in the algorithm. Secondly, entity disambiguation should be improved upon in order to increase precision by decreasing the number of false positives. We consider graph-based disambiguation methods as a promising research direction. Thirdly, using entity types as features instead of only relying on mention boundaries could also improve entity disambiguation in the end-to-end setting.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,138.51,317.27,338.18,73.90"><head>Table 1 .</head><label>1</label><figDesc>NERC-coarse results (literal sense, micro average) .623 .641 .786 .775 .797 .840 .831 .849 .921 .912 .931 .797 .790 .805 .878 .870 .886 UvA.ILPS .473 .443 .508 .678 .635 .728 .686 .656 .719 .830 .794 .869 .526 .499 .556 .726 .689 .768 baseline HIPE .405 .531 .327 .562 .736 .454 .646 .693 .606 .769 .825 .721 .476 .643 .378 .585 .790 .464</figDesc><table coords="3,144.85,338.26,327.82,34.52"><row><cell>English</cell><cell></cell><cell>French</cell><cell></cell><cell>German</cell><cell></cell></row><row><cell>strict</cell><cell>fuzzy</cell><cell>strict</cell><cell>fuzzy</cell><cell>strict</cell><cell>fuzzy</cell></row><row><cell cols="6">F P R F P R F P R F P R F P R F P R</cell></row><row><cell>best HIPE .632</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,138.51,571.54,338.33,73.92"><head>Table 2 .</head><label>2</label><figDesc>End-to-end NEL results (literal sense, micro average) .523 .539 .531 .523 .539 .594 .602 .598 .613 .622 .617 .534 .531 .538 .557 .553 .561 UvA.ILPS .300 .249 .375 .300 .249 .375 .251 .352 .195 .252 .353 .196 .254 .241 .269 .264 .250 .279 baseline HIPE .220 .263 .239 .220 .263 .239 .206 .342 .257 .257 .358 .270 .173 .187 .180 .188 .203 .195</figDesc><table coords="3,144.86,592.53,327.97,34.54"><row><cell cols="2">English</cell><cell cols="2">French</cell><cell cols="2">German</cell></row><row><cell>strict @1</cell><cell>relaxed @1</cell><cell>strict @1</cell><cell>relaxed @1</cell><cell>strict @1</cell><cell>relaxed @1</cell></row><row><cell cols="6">F P R F P R F P R F P R F P R F P R</cell></row><row><cell>best HIPE .531</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,183.80,520.13,247.76,105.27"><head>Table 3 .</head><label>3</label><figDesc>Named entity linking results (English, literal sense)</figDesc><table coords="5,213.07,551.39,189.21,74.01"><row><cell></cell><cell>strict @1</cell><cell>fuzzy @1</cell></row><row><cell></cell><cell cols="2">F P R F P R</cell></row><row><cell>best HIPE</cell><cell cols="2">.633 .685 .658 .633 .685 .658</cell></row><row><cell>Run #3 REL</cell><cell cols="2">.593 .607 .580 .593 .607 .580</cell></row><row><cell cols="3">Run #1 Baseline .367 .365 .369 .367 .365 .369</cell></row><row><cell cols="3">Run #2 Historical .348 .344 .353 .348 .344 .353</cell></row><row><cell>baseline HIPE</cell><cell cols="2">.506 .506 .506 .506 .506 .506</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,183.04,116.41,249.29,72.40"><head>Table 4 .</head><label>4</label><figDesc>NEL-only results @3 and @5 (English, literal sense)</figDesc><table coords="6,213.07,147.67,189.21,41.14"><row><cell>@3</cell><cell>@5</cell></row><row><cell cols="2">F P R F P R</cell></row><row><cell cols="2">Run #1 Baseline .463 .467 .465 .552 .557 .555</cell></row><row><cell cols="2">Run #2 Historical .451 .463 .457 .540 .555 .548</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="5,144.73,656.80,143.55,7.86"><p>https://github.com/informagi/REL</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This research was supported by the <rs type="funder">NWO Innovational</rs> <rs type="programName">Research Incentives Scheme Vidi</rs> (<rs type="grantNumber">016.Vidi.189.039</rs>), the <rs type="projectName">NWO Smart Culture -Big Data / Digital Humanities</rs> (<rs type="grantNumber">314-99-301</rs>), the <rs type="grantNumber">H2020-EU.3.4</rs>. -<rs type="projectName">SOCIETAL CHALLENGES -Smart, Green And Integrated Transport</rs> (<rs type="grantNumber">814961</rs>) the <rs type="programName">Google Faculty Research Awards program</rs>. All content represents the opinion of the authors, which is not necessarily shared or endorsed by their respective employers and/or sponsors.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_Wdbhua9">
					<idno type="grant-number">016.Vidi.189.039</idno>
					<orgName type="project" subtype="full">NWO Smart Culture -Big Data / Digital Humanities</orgName>
					<orgName type="program" subtype="full">Research Incentives Scheme Vidi</orgName>
				</org>
				<org type="funding" xml:id="_nZP5AzV">
					<idno type="grant-number">314-99-301</idno>
				</org>
				<org type="funded-project" xml:id="_FtQtmHn">
					<idno type="grant-number">H2020-EU.3.4</idno>
					<orgName type="project" subtype="full">SOCIETAL CHALLENGES -Smart, Green And Integrated Transport</orgName>
				</org>
				<org type="funding" xml:id="_RHbNEFZ">
					<idno type="grant-number">814961</idno>
					<orgName type="program" subtype="full">Google Faculty Research Awards program</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,142.96,394.66,337.63,7.86;7,151.52,405.62,329.07,7.86;7,151.52,416.58,329.07,7.86;7,151.52,427.54,190.17,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,458.68,394.66,21.91,7.86;7,151.52,405.62,204.75,7.86">Flair: An easy-to-use framework for state-of-the-art nlp</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Blythe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Schweter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,380.22,405.62,100.38,7.86;7,151.52,416.58,329.07,7.86;7,151.52,427.54,115.21,7.86">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="54" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,438.32,337.63,7.86;7,151.52,449.28,329.07,7.86;7,151.52,460.24,329.07,7.86;7,151.52,471.20,329.07,7.86;7,151.52,482.15,199.86,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,244.97,449.28,235.63,7.86;7,151.52,460.24,109.04,7.86">Robust Named Entity Recognition and Linking on Historical Multilingual Documents</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Boros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Linhares Pontes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Cabrera-Diego</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hamdi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>SidÃ¨re</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,176.95,471.20,303.64,7.86;7,151.52,482.15,119.03,7.86">CLEF 2020 Working Notes. Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>NÃ©vÃ©ol</surname></persName>
		</editor>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,492.94,337.63,7.86;7,151.52,503.90,329.07,7.86;7,151.52,514.86,25.60,7.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="7,346.99,492.94,133.60,7.86;7,151.52,503.90,189.89,7.86">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="7,142.96,525.64,337.63,7.86;7,151.52,536.57,228.38,7.89" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,257.84,525.64,222.75,7.86;7,151.52,536.60,106.03,7.86">Elasticsearch: An advanced and quick search technique to handle voluminous data</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S</forename><surname>Divya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">K</forename><surname>Goyal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,264.72,536.60,43.82,7.86">Compusoft</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">171</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,547.38,337.63,7.86;7,151.52,558.34,329.07,7.86;7,151.52,569.30,231.67,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,378.25,547.38,102.34,7.86;7,151.52,558.34,133.60,7.86">Diachronic Evaluation of NER Systems on Old Newspapers</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Colavizza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Rochat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Kaplan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,306.07,558.34,174.52,7.86;7,151.52,569.30,101.52,7.86">Proceedings of the 13th Conference on Natural Language Processing</title>
		<meeting>the 13th Conference on Natural Language Processing<address><addrLine>KONVENS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="97" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,591.04,337.64,7.86;7,151.52,602.00,329.07,7.86;7,151.52,612.96,329.07,7.86;7,151.52,623.92,329.07,7.86;7,151.52,634.88,329.07,7.86;7,151.52,645.84,329.07,7.86;7,151.52,656.80,202.68,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,402.56,591.04,78.04,7.86;7,151.52,602.00,310.64,7.86">Overview of CLEF HIPE 2020: Named Entity Recognition and Linking on Historical Newspapers</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>FlÃ¼ckiger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clematide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,385.32,623.92,95.27,7.86;7,151.52,634.88,329.07,7.86;7,151.52,645.84,205.76,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction. Proceedings of the 11th International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="7,388.20,645.84,92.40,7.86;7,151.52,656.80,81.27,7.86">Lecture Notes in Computer Science (LNCS</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Joho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Lioma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>NÃ©vÃ©ol</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="volume">12260</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,119.67,337.63,7.86;8,151.52,130.63,56.83,7.86" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cohen</surname></persName>
		</author>
		<title level="m" coord="8,320.72,119.67,159.87,7.86;8,151.52,130.63,28.15,7.86">Fuzzywuzzy: Fuzzy string matching in python</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,141.59,337.63,7.86;8,151.52,152.55,329.07,7.86;8,151.52,163.51,329.07,7.86;8,151.52,174.47,139.11,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,284.79,141.59,195.80,7.86;8,151.52,152.55,248.47,7.86">From the paft to the fiiture: a fully automatic NMT and word embeddings method for OCR post-correction</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>HÃ¤mÃ¤lÃ¤inen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hengchen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,421.70,152.55,58.89,7.86;8,151.52,163.51,329.07,7.86;8,151.52,174.47,53.11,7.86">Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP</title>
		<meeting>the International Conference on Recent Advances in Natural Language Processing (RANLP</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="431" to="436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,295.23,174.47,185.36,7.86;8,151.52,185.43,183.49,7.86" xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Incoma Ltd</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/R19-1051" />
		<imprint>
			<date type="published" when="2019-09">Sep 2019</date>
			<pubPlace>Varna, Bulgaria</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,196.39,337.63,7.86;8,151.52,207.34,329.07,7.86;8,151.52,218.30,329.07,7.86;8,151.52,229.26,329.07,7.86;8,151.52,240.22,311.78,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,415.54,196.39,65.05,7.86;8,151.52,207.34,158.90,7.86">Revisiting NMT for normalization of early English letters</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>HÃ¤mÃ¤lÃ¤inen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>SÃ¤ily</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rueter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tiedemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>MÃ¤kelÃ¤</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/W19-2509" />
	</analytic>
	<monogr>
		<title level="m" coord="8,329.40,207.34,151.19,7.86;8,151.52,218.30,329.07,7.86;8,151.52,229.26,105.82,7.86">Proceedings of the 3rd Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature</title>
		<meeting>the 3rd Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature<address><addrLine>Minneapolis, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06">Jun 2019</date>
			<biblScope unit="page" from="71" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,251.18,337.97,7.86;8,151.52,262.14,329.07,7.86;8,151.52,273.10,329.07,7.86;8,151.52,284.06,96.69,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,419.15,251.18,61.44,7.86;8,151.52,262.14,161.40,7.86">REL: An entity linker standing on the shoulders of giants</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Van Hulst</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hasibi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Dercksen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>De Vries</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,332.50,262.14,148.09,7.86;8,151.52,273.10,329.07,7.86;8,151.52,284.06,39.61,7.86">Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. SIGIR &apos;20</title>
		<meeting>the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. SIGIR &apos;20</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,295.02,337.98,7.86;8,151.52,305.98,329.07,7.86;8,151.52,316.93,201.31,7.86" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="8,282.11,305.98,198.48,7.86;8,151.52,316.93,34.83,7.86">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="8,142.62,327.89,337.98,7.86;8,151.52,338.83,207.59,7.89" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,215.68,327.89,187.58,7.86">Natural language processing for historical texts</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Piotrowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,409.65,327.89,70.95,7.86;8,151.52,338.85,130.10,7.86">Synthesis lectures on human language technologies</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="157" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,349.81,337.98,7.86;8,151.52,360.77,329.07,7.86;8,151.52,371.73,124.85,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,466.50,349.81,14.10,7.86;8,151.52,360.77,295.21,7.86">Art DATIS: Improving search in multilingual corpora to support art historians</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Provatorova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Carlgren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>DuprÃ©</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hendriksen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,453.07,360.77,27.52,7.86;8,151.52,371.73,81.33,7.86">Digital Humanities Benelux</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,382.69,337.98,7.86;8,151.52,393.65,329.07,7.86;8,151.52,404.61,329.07,7.86;8,151.52,415.56,217.40,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,317.53,382.69,163.06,7.86;8,151.52,393.65,214.49,7.86">Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition</title>
		<author>
			<persName coords=""><forename type="first">Tjong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sang</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">F</forename><surname>De Meulder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/W03-0419" />
	</analytic>
	<monogr>
		<title level="m" coord="8,386.62,393.65,93.97,7.86;8,151.52,404.61,275.10,7.86">Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003</title>
		<meeting>the Seventh Conference on Natural Language Learning at HLT-NAACL 2003</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="142" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,426.52,337.98,7.86;8,151.52,437.48,329.07,7.86;8,151.52,448.44,266.43,7.86" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="8,329.61,437.48,150.97,7.86;8,151.52,448.44,141.33,7.86">Huggingface&apos;s transformers: State-ofthe-art natural language processing</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<idno>arXiv-1910</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">ArXiv</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
