<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,221.24,115.96,172.88,12.62;1,156.74,132.99,301.87,12.62">IRISA System for Entity Detection and Linking at CLEF HIPE 2020</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,268.62,170.17,65.92,8.74"><forename type="first">Cheikh</forename><surname>Brahim</surname></persName>
							<email>cheikh-brahim.el-vaigh@inria.fr</email>
						</author>
						<author>
							<persName coords="1,337.19,170.17,9.55,8.74;1,134.77,181.53,24.91,8.74"><forename type="first">El</forename><surname>Vaigh</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">INRIA</orgName>
								<orgName type="institution" key="instit2">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,169.52,181.53,120.68,8.74"><forename type="first">Guillaume</forename><surname>Le Noé-Bienvenu</surname></persName>
							<email>guillaume.le-noe-bienvenu@irisa.fr</email>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,300.05,181.53,80.29,8.74"><forename type="first">Guillaume</forename><surname>Gravier</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">CNRS</orgName>
								<orgName type="institution" key="instit2">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,408.83,181.53,67.28,8.74"><forename type="first">Pascale</forename><surname>Sébillot</surname></persName>
							<email>pascale.sebillot@irisa.fr</email>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">INSA Rennes</orgName>
								<orgName type="institution" key="instit2">IRISA</orgName>
								<address>
									<settlement>Rennes</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,221.24,115.96,172.88,12.62;1,156.74,132.99,301.87,12.62">IRISA System for Entity Detection and Linking at CLEF HIPE 2020</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B8DE551E12A65E853409E17480CF160C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Named entity recognition</term>
					<term>CRF</term>
					<term>Collective entity linking</term>
					<term>WRSM entity relatedness measure</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This note describes IRISA's system for the task of named entity processing on historical newspapers in French. Following a standard entity detection and linking pipeline, our system implements three steps to solve the named entity linking task. Named Entity Recognition (NER) is first performed to identify the entity mentions in a document based on a Conditional Random Fields classifier. Candidate entities from Wikidata are then generated for each mention found, using simple search. Finally, every mention is linked to one of its candidate entities in a so-called linking step leveraging various string metrics and the semantic structure of Wikidata to improve on the linking decisions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Entity linking is a core task in textual document processing, which consists in identifying the entities of a knowledge base (KB) that are mentioned in a text. For instance, approaches from the literature implement three stages to solve mention ambiguity in texts. The first stage consists in the detection of named entities within the text and is known as named entities recognition (NER). To further link the mention found in the text, candidate entities are generated for each mention detected in the first stage. Finally, every mention is linked to one of its candidate entities in a so-called linking step. This last step can be performed independently for each individual mention, or collectively for all mentions at once. In the first case, every mention in a text is assumed to be independent from other mentions and is linked to a candidate entity on sole basis of some similarity between the mention and the candidate entities, so-called local scores. By contrast, for collective entity linking, entity mentions and the corresponding entities are not assumed independent one from another but somehow semantically related within a (coherent) document, i.e., mention-to-entity linking decisions are interdependent. In this case, the local mention-entity scores are complemented with global scores reflecting to which extent the candidate entities chosen for the mentions under consideration are related in the KB, according to a so-called entity relatedness measure. The last two stages of the pipeline are also known as named entity linking (NEL).</p><p>In the context of the shared task CLEF HIPE 2020 -Identifying Historical People, Places and other Entities-which is a named entity processing on historical newspapers in French, German and English <ref type="bibr" coords="2,326.50,188.34,9.96,8.74" target="#b2">[3]</ref>, entity linking techniques can be used to retrieve entities from text. CLEF HIPE 2020 is organised as a CLEF 2020 evaluation Lab. However, the historical context makes the linking task harder since texts considered are the results of an optical character recognition (OCR) algorithm which introduces noise. Therefore, we leveraged various features to reduce the impact of the OCR *noise* on named entity processing.</p><p>Our system for CLEF HIPE 2020 follows a standard pipeline for entity linking and implements three separate stages:</p><p>1. We devise a NER stage on top of the baseline provided by CLEF HIPE 2020 organizers. This system used Conditional Random Fields (CRFs) to detect and classify named entities. We added several features that we found effective for the task of NER. 2. The generation step consists in looking to Wikidata directly when searching entities similar to a given mention. As a lookup in the heavy database (CLEF HIPE 2020 Wikidata dump) is costly in time, we performed automatic searches for the entity mentions using online Wikidata. Note that this search is based on Wikidata indexing algorithm. 3. The linking step is to decide which candidate should be retained for each mention within a document. We tried to link the mentions separately or collectively, training a classifier to predict if a mention is related to one of its candidate entities. The former is based solely on the similarity between a given mention and its candidate entities. The latter which performs the linking collectively for all the mentions at once, beside the previous similarity metrics, makes use of the entity relatedness measure WSRM that we have proposed in <ref type="bibr" coords="2,408.74,456.78,9.96,8.74" target="#b3">[4]</ref>. 4. The collective linking setup gave the best results and was ranked second for the bundle2 of the shared task CLEF HIPE 2020.</p><p>Our source code, datasets and experimental results are made available online for reproducibility purposes <ref type="foot" coords="2,239.46,506.65,3.97,6.12" target="#foot_0">5</ref> . The note is organized as follows. We give the description of our method in Sec. 2. Then we group the experimental results in Sec. 3 before discussing the perspectives and conclude in Sec. 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Architecture</head><p>This section gives the description of our system. We distinguish two independent tasks for named entity processing, namely the NER and the NEL. Our solutions for the NER and the NEL are described respectively in Sec. 2.1 and Sec. 2.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">NER</head><p>The NER task aims at detecting the surface forms in a text that correspond to named entities and at classifying those forms as a type (PER, LOC, ORG, TIME, PROD). The NER system that we developed originally came from the NER baseline provided by the organizing team of the evaluation campaign CLEF HIPE 2020. This system used Conditional Random Fields (CRFs) based on a Python implementation <ref type="bibr" coords="3,204.81,198.27,10.52,8.74" target="#b0">[1]</ref> to detect and classify named entities. The features used in this system, as well as the ones we have chosen are described in Table <ref type="table" coords="3,415.22,209.63,3.87,8.74">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">NEL</head><p>In the NEL stage, we assume that the annotations are known for the mentions (person, organization, location, etc.) for each document. Those annotations are provided by the NER system described in Sec. 2.1 or by an oracle NER. For the candidate generation stage we rely on a simple Wikidata web search. The candidate selection stage accounts for the WSRM entity relatedness measure between candidate entities within the document in an efficient manner, relying here on Wikidata, the KB provided by CLEF HIPE 2020 for named entity processing (see <ref type="bibr" coords="3,154.08,344.07,10.52,8.74" target="#b3">[4]</ref> for details on the measure). These different steps are described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Candidate Entities Generation</head><p>To generate candidate entities from the KB for each mention in a document, we chose a simple yet efficient method exploiting the index of Wikidata. For each mention found by the NER phase, we perform online search using Wikidata web pages. We limit ourselves to the top 10 ranked candidate entities. The motivation behind our choice is to speed up the candidate entities generation step as a lookup in the heavy Wikidata dump is costly in time compared to simple web search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Local Scores</head><p>The local scores depict the similarity between a mention and its candidate entities. If we assume the mentions to be independent in text, the linking problem can be formalized as</p><formula xml:id="formula_0" coords="3,267.91,513.09,212.68,16.07">ê = argmax ei φ(m,e i )<label>(1)</label></formula><p>where e i is a candidate entity, m is an entity mention, and φ is the local score function. We tried several metrics for φ. Beside the longest contiguous matching sub-sequence, we tried a Levenshtein distance to handle the OCR noise, Wikipedia popularity <ref type="bibr" coords="3,182.38,566.88,10.96,8.74" target="#b1">[2,</ref><ref type="bibr" coords="3,193.34,566.88,7.31,8.74" target="#b4">5]</ref> and the cosine similarity based on a word embedding model, similar to the Skip-gram embedding model <ref type="bibr" coords="3,305.74,578.24,9.96,8.74" target="#b5">[6]</ref>.</p><p>Collective Entity Linking In a collective NEL setup, the local score is complemented with a global score accounting for the intricate interrelationships that candidate entities of the different mentions may share. The latter is known as an entity relatedness measure and used to assess entity relationships in the KB, which will allow to estimate the interdependence of the mentions in the text. The CEL problem can be thus formalized as</p><formula xml:id="formula_1" coords="4,188.80,129.18,287.54,33.76">(ê 1 ,...,ê n ) = argmax e1,...,n   n i=1 φ(m i ,e i )+ n i=1 n j=1,j =i ψ(e i ,e j )   (<label>2</label></formula><formula xml:id="formula_2" coords="4,476.35,142.79,4.24,8.74">)</formula><p>where n is the total number of mentions in a text and ψ(e i ,e j ) donates the entity relatedness measure. In the collective linking version of our system, we used the semantic entity relatedness measure WSRM <ref type="bibr" coords="4,350.29,189.86,10.52,8.74" target="#b3">[4]</ref> which weights the relation between entities, where the more relations between the entities, the stronger their relationship. Formally, is defined between two entities e i and e j as </p><formula xml:id="formula_3" coords="4,230.96,231.08,4.26,8.74">(</formula><p>where E denotes the set of entities in the KB and |S| the cardinality of the set S.</p><p>Because the directions of the relations are somewhat arbitrary in KBs, depending on how the relation vocabulary was designed (think about the publishes and publishedBy symmetric RDF properties), we use a symmetric version of WSRM defined as ψ(e i ,e j ) = 1 2 (WSRM(e i ,e j )+WSRM(e j ,e i )) .</p><p>Using the NEL Output to Correct the NER Predictions We also exploited the output of the NEL in order to enhance the NER results. First, we used the type (obtained from Wikidata) of the entities retrieved by the NEL and forwarded it to the NER stage, which can be updated accordingly. Then we leveraged WSRM <ref type="bibr" coords="4,470.08,390.90,10.52,8.74" target="#b3">[4]</ref> to retrieve, for each entity found by the NEL, a list of potential related entities from the KB. We argue that if an entity is mentioned in the text, its related entities in the KB should be also mentioned in that text. Our aim is to exploit the semantics of the KB for the NER task. Those information provided by the NEL are used as pseudo-labels or features in the CRF to supervise the NER.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>Experimental validation was conducted on the CLEF HIPE 2020 French corpus to assess the quality of our system. The dataset is described in Sec. 3.1. Results for the NER are provided in Sec. 3.2, and in Sec. 3.3 for the NEL. Due to the high number of results given by the CLEF HIPE 2020 scorer, we decided to focus only on a couple of them, that were given in the produced json file: NE-COARSE-LIT -ALL -strict -F1 micro and NE-COARSE-LIT -ALLent type -F1 micro.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset</head><p>The evaluation corpus is composed of newspaper articles sampled among several Swiss, Luxembourgish and American historical newspapers on a diachronic basis. This corpus is digitised based on an OCR algorithm which hightails the historical context of the evaluation campaign. The time-span of the whole corpus goes from Feature Was on baseline Kept the token in lowercase yes yes the last 3 letters of the token yes yes the last 2 letters of the token yes yes a boolean on whether the token is in uppercase yes yes a boolean on whether the token is in titlecase yes yes a boolean on whether the token is a digit yes yes the correct spelling of the word using an open-source library Table <ref type="table" coords="5,223.64,385.95,4.13,7.89">1</ref>. The list of the features we tested for the NER.</p><p>1798 until 2018. We used only the French version of the corpus composed of a train, a validation and a test sets<ref type="foot" coords="5,278.37,438.03,3.97,6.12" target="#foot_1">6</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results of the NER</head><p>The NER classifier described in Sec. 2.1 is trained on the CLEF HIPE 2020 dataset. We added several features to the ones of the baseline. We performed a random search to select the best features while controlling the overfitting. We provide the list of the features used in Tab. 1 and the list of the best hyper-parameters in Tab. 2. The system was trained on the train file and then tested on the dev and test files provided by the organizers.</p><p>We compared our NER system with the baseline provided by the CLEF HIPE 2020 organizers on the validation set (dev file). The results are gathered in Tab. <ref type="bibr" coords="5,472.84,569.65,3.87,8.74" target="#b2">3</ref>. We can see that our NER system outperforms the baseline. We believe that its good performance is due to the choice of the selected features, e.g., the use of the tokens present in the text as features for the classifier. The fine tuning of the hyper-parameters of our CRF also partly explains the results better than those of the baseline. The results of our system on the test file are gathered in Tab. 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parameter</head><p>Best value found c1, the coefficient for L1 regularization, between 0 and 1 0.1798 c2, the coefficient for L2 regularization, between 0 and 1 0.0551 min freq, cut-off threshold for occurrence frequency of a feature, between 0 and 1 0 max iterations, the maximum number of iterations for optimization algorithm, between 100 and 1000 192 all possible transitions false num memories, the number of limited memories for approximating the inverse Hessian matrix, between 4 and 8 4</p><p>Table <ref type="table" coords="6,247.52,224.21,4.13,7.89">2</ref>. The best parameters for the CRF. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Baseline Irisa Team</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results of the NEL</head><p>Results of the entity linking process evaluated in terms of micro-averaged F1 classification scores are reported in Tab. 4. The three systems that we submitted to CLEF HIPE 2020 were ranked second (team7 results). We first evaluated the entity linking based on the sole use of the local scores donated by team7 bundle2 fr 1. Second, we added the global score devising a collective entity linking which we named team7 bundle2 fr 2. And finally, we changed the collective linking system to filter the non-linkable mentions (NIL) based on a threshold, meaning we only link a mention to a candidate entity if the prior probability is below a fixed threshold (here 0.5). We can see that the collective linking gave the best results, while the collective linking with a fixed threshold is worse than the non-collective one. These results show the benefit of the collective linking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Supervising the NER with the NEL</head><p>A few experiments have been carried out to exploit the outputs of the NEL in order to enhance the NER results. The first one consisted in using the types of the entities found by the NEL to change the NER labels; e.g., if the NER detects the entity 'Europe' and classifies it as 'PERS', the NEL links it to 'Q46' and gives the information that the type of 'Q46' is 'LOC'. The second consisted in generating closely related entities to the ones found by the NEL. We found that the output of the NEL stage can correct the NER, but can also introduce too much noise. Despite not being able to directly incorporate the output of the NEL with the existing features, we believe that applying a major vote between the different versions of the NER-with and without the NEL output-can lead to an increase of the accuracy of the NER. Nonetheless, our system opened the door to incorporate the semantics of the KB into the NER task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We built an entity processing system based on a CRF classifier for the NER task, and a collective entity linking system for the NEL one, exploiting the WSRM entity relatedness measure that we have proposed in <ref type="bibr" coords="7,352.28,340.46,9.96,8.74" target="#b3">[4]</ref>. Our system was evaluated on the CLEF HIPE 2020 French dataset. Though initially expected, we did not succeed in incorporating the output of the NEL to correct the NER step, but we paved the way to fully use the KB semantics in the NER task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,235.22,231.08,31.91,9.65;4,280.84,224.34,83.21,9.65;4,269.43,254.39,17.69,6.12;4,287.50,240.44,87.95,9.65;4,381.63,231.08,2.77,8.74"><head></head><label></label><figDesc>e i ,e j ) = |{r | (e i ,r,e j ) ∈ KB}| e ∈E |{r | (e i ,r ,e ) ∈ KB}| ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,136.16,267.06,328.77,195.19"><head>Table 3 .</head><label>3</label><figDesc>Scores of NER systems on the test and dev file.</figDesc><table coords="6,136.16,267.06,328.77,195.19"><row><cell></cell><cell>Task</cell><cell></cell><cell></cell><cell>F1</cell><cell>F1 Precision Recall</cell></row><row><cell>Dev file</cell><cell cols="3">NERC coarse French strict (literal sense) NERC coarse French fuzzy (literal sense)</cell><cell cols="2">0.622 0.716 0.735 0.821</cell><cell>0.768 0.671 0.880 0.769</cell></row><row><cell>Test file</cell><cell cols="3">NERC coarse French strict (literal sense) NERC coarse French fuzzy (literal sense)</cell><cell>--</cell><cell>0.668 0.784</cell><cell>0.705 0.634 0.828 0.744</cell></row><row><cell></cell><cell cols="2">Rank Team name</cell><cell>System</cell><cell cols="2">F1 Precision Recall</cell></row><row><cell></cell><cell>1</cell><cell>L3i</cell><cell cols="2">team10 bundle1 fr 3 0.598</cell><cell>0.594</cell><cell>0.602</cell></row><row><cell></cell><cell>2</cell><cell>L3i</cell><cell cols="2">team10 bundle1 fr 1 0.597</cell><cell>0.592</cell><cell>0.601</cell></row><row><cell></cell><cell>3</cell><cell>L3i</cell><cell cols="2">team10 bundle1 fr 2 0.597</cell><cell>0.592</cell><cell>0.602</cell></row><row><cell></cell><cell>4</cell><cell>IRISA</cell><cell cols="2">team7 bundle2 fr 2 0.421</cell><cell>0.446</cell><cell>0.399</cell></row><row><cell></cell><cell>5</cell><cell>IRISA</cell><cell cols="2">team7 bundle2 fr 1 0.419</cell><cell>0.450</cell><cell>0.393</cell></row><row><cell></cell><cell>6</cell><cell>IRISA</cell><cell cols="2">team7 bundle2 fr 3 0.413</cell><cell>0.437</cell><cell>0.391</cell></row><row><cell></cell><cell>7</cell><cell>SBB</cell><cell cols="2">team33 bundle2 fr 1 0.407</cell><cell>0.594</cell><cell>0.310</cell></row><row><cell></cell><cell>8</cell><cell cols="3">UvA.ILPS team31 bundle2 fr 2 0.251</cell><cell>0.352</cell><cell>0.195</cell></row><row><cell></cell><cell>9</cell><cell>ERTIM</cell><cell cols="2">team16 bundle1 fr 1 0.108</cell><cell>0.150</cell><cell>0.084</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,134.77,465.61,345.82,18.30"><head>Table 4 .</head><label>4</label><figDesc>Linking accuracy (F1 score) on the CLEF HIPE 2020 French dataset for bundle 2.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_0" coords="2,144.73,657.44,193.00,7.47"><p>https://gitlab.inria.fr/celvaigh/hipe2020</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_1" coords="5,144.73,646.39,335.87,8.12;5,144.73,657.44,132.80,7.47"><p>Details statistics about the data can be found at https://impresso.github.io/ CLEF-HIPE-2020/datasets.html</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,138.35,428.76,342.24,7.86;7,146.91,439.17,333.68,7.86;7,146.91,449.59,333.67,7.86;7,146.91,460.00,333.68,7.86;7,146.91,470.41,333.68,7.86;7,146.91,480.82,236.26,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,262.98,449.59,217.61,7.86;7,146.91,460.00,114.64,7.86">API design for machine learning software: Experiences from the scikit-learn project</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Buitinck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Louppe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Niculae</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Grobler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Layton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Holt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,284.21,460.00,196.38,7.86;7,146.91,470.41,333.68,7.86;7,146.91,480.82,154.01,7.86">European Conference on Machine Learning and Principles and Practices of Knowledge Discovery in Databases Workshop: Languages for Data Mining and Machine Learning</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="108" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,491.23,342.24,7.86;7,146.91,501.61,333.68,7.89" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,236.59,491.23,244.01,7.86;7,146.91,501.64,11.14,7.86">A joint model for entity analysis: coreference, typing, and linking</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,163.86,501.64,244.73,7.86">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="477" to="490" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,512.05,342.24,7.86;7,146.91,522.46,333.68,7.86;7,146.91,532.87,110.43,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,381.73,512.05,98.86,7.86;7,146.91,522.46,284.90,7.86">Overview of CLEF HIPE 2020: Named entity recognition and linking on historical newspapers</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Flückiger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clematide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,455.89,522.46,24.70,7.86;7,146.91,532.87,22.78,7.86">CLEF HIPE</title>
		<imprint>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="page" from="1" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,543.28,342.25,7.86;7,146.91,553.70,333.67,7.86;7,146.91,564.11,221.20,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,388.78,543.28,91.82,7.86;7,146.91,553.70,172.97,7.86">Using knowledge base semantics in context-aware entity linking</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">B</forename><surname>El Vaigh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Goasdoué</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gravier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sébillot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,345.23,553.70,135.36,7.86;7,146.91,564.11,47.77,7.86">ACM Symposium on Document Engineering</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,574.52,342.24,7.86;7,146.91,584.93,333.68,7.86;7,146.91,595.34,333.68,7.86;7,146.91,605.75,181.53,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,322.16,574.52,158.43,7.86;7,146.91,584.93,177.45,7.86">Capturing semantic similarity for entity linking with convolutional neural networks</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Francis-Landau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Durrett</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,349.39,584.93,131.21,7.86;7,146.91,595.34,333.68,7.86;7,146.91,605.75,90.19,7.86">15th Annual Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1256" to="1261" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,616.16,342.24,7.86;7,146.91,626.57,333.68,7.86;7,146.91,636.98,217.45,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,406.99,616.16,73.60,7.86;7,146.91,626.57,234.34,7.86">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,402.17,626.57,78.42,7.86;7,146.91,636.98,125.81,7.86">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
