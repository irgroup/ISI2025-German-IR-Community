<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,213.51,118.17,53.81,11.22;1,150.99,133.83,313.37,12.68;1,155.98,151.77,303.40,12.68;1,235.77,169.70,143.82,12.68">SinNer</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,163.48,207.62,112.99,8.80"><forename type="first">Pedro</forename><forename type="middle">Javier</forename><surname>Ortiz Suárez</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">ALMAnaCH</orgName>
								<orgName type="institution" key="instit2">Inria</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Sorbonne Université</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,380.59,207.62,64.05,8.80"><forename type="first">Yoann</forename><surname>Dupont</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">STIH</orgName>
								<orgName type="institution">Sorbonne Université</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,239.89,219.57,56.92,8.80"><forename type="first">Gaël</forename><surname>Lejeune</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">STIH</orgName>
								<orgName type="institution">Sorbonne Université</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,326.74,219.57,44.26,8.80"><forename type="first">Tian</forename><surname>Tian</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">STIH</orgName>
								<orgName type="institution">Sorbonne Université</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,213.51,118.17,53.81,11.22;1,150.99,133.83,313.37,12.68;1,155.98,151.77,303.40,12.68;1,235.77,169.70,143.82,12.68">SinNer</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4F61C1A461AB11965346475C14AB3FD8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Named Entity Recognition</term>
					<term>Historical Texts</term>
					<term>German</term>
					<term>French</term>
					<term>ELMo</term>
					<term>CRFs.</term>
					<term>Sentence Segmentation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this article we present the approaches developed by the Sorbonne-INRIA for NER (SinNer) team for the CLEF-HIPE 2020 challenge on Named Entity Processing on old newspapers. The challenge proposed various tasks for three languages, among them we focused on Named Entity Recognition coarse-grained in French and German texts. The best system we proposed ranked third for these two languages, it uses FastText embeddings and Elmo language models (FrELMo and German ELMo). We combine several word representations in order to enhance the quality of the results for all NE types. We show that reconstruction of sentence segments has an important impact on the results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Among the aspects for which Natural Language Processing (NLP) can be useful for Digital Humanities (DH) figures prominently Named Entity Recognition. This task interests researchers for numerous reasons since the application can be pretty wide. We can cite genealogy or history for which finding mentions of persons and places in texts is very useful. Researchers in digital literature have shown a great interest in NER since it can help for instance to highlight the path of different characters in a book or in a book series. There can be cross-fertilization between NER and DH since some researchers showed that some particular properties of literature can help to build better NER systems <ref type="bibr" coords="2,134.77,118.93,9.96,8.80" target="#b0">[1]</ref>. Apart from literature, NER can also be used more generally to help refine queries to assist browsing in newspaper collections <ref type="bibr" coords="2,360.99,130.89,14.61,8.80" target="#b19">[20]</ref>. Like other NLP tasks, NER quality will suffer from different problems related to variations in the input data: variation in languages (multilinguality), variation in the quality of the data (OCR errors mainly) and specificity of the application domain (literature vs. epidemic surveillance for instance). These difficulties can be connected with the challenges for low-level NLP tasks highlighted by Dale et al. <ref type="bibr" coords="2,397.54,190.66,9.96,8.80" target="#b2">[3]</ref>. In CLEF-HIPE shared task <ref type="bibr" coords="2,188.87,202.62,9.96,8.80" target="#b5">[6]</ref>, the variation in language and in text quality will be the main problems even if the specificity of the application can be of great interest.</p><p>NER in old documents represent an interesting challenge for NLP since it is usually necessary to process documents that show different kind of variations as compared to the particular laboratory conditions on which NER systems are trained. Most NER systems are usually designed to process clean data. Additionally, there is the multilingual issue since NER systems have been designed primarily for English, with assumptions on the availability of data on the one hand and on the universal nature of some linguistic properties on the other hand.</p><p>The fact that the texts processed in Digital Humanities are usually not borndigital is very important since, even after OCR post-correction, it is very likely that some noise would be found in the text. Other difficulties will arise as well in those type of documents. The variation in language is one of them since contemporary English will clearly not be the most frequent language. It is interesting for researchers to check how much diachronic variation has an influence on NER systems <ref type="bibr" coords="2,171.72,382.43,9.96,8.80" target="#b4">[5]</ref>. It makes it even more important to work on multilingual NER and to build architectures that need less training data <ref type="bibr" coords="2,364.00,394.38,14.60,8.80" target="#b25">[26]</ref>. More generally, NER in ancient texts represents a great opportunity for NLP to compare to main approaches to handle variation in texts: adapting the texts to an existing architecture via modernization or normalization <ref type="bibr" coords="2,325.59,430.25,15.49,8.80" target="#b16">[17]</ref> or adapting the pipeline to non standard data (OCR noise, language variants. . . ) via domain adaptation or data augmentation techniques <ref type="bibr" coords="2,246.32,454.16,9.96,8.80" target="#b8">[9]</ref>.</p><p>In Section 2 we present a brief state-of-the-art for Named Entity Recognition with a focus on digitized documents. Section 3 and 4 are respectively devoted to the description of the dataset of CLEF-HIPE 2020 shared task and the methods we developed to extract NE for French and German. The results of our systems are described in Section 5 and in Section 6 we give some conclusions and perspectives for this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work on Named Entity Recognition</head><p>Named Entity Recognition came into light as a prerequisite for designing robust Information Extraction (IE) systems in the MUC conferences <ref type="bibr" coords="2,398.14,596.28,14.61,8.80" target="#b10">[11]</ref>. This task soon began to be treated independently from IE since it can serve multiple purposes, like Information retrieval or Media Monitoring for instance <ref type="bibr" coords="2,391.93,620.19,14.61,8.80" target="#b33">[34]</ref>. As such, shared task specifically dedicated to NER started to rise like the CoNLL 2003 shared task <ref type="bibr" coords="2,156.38,644.10,14.61,8.80" target="#b31">[32]</ref>. Two main paths were followed by the community: (i) since NER was at first used for general purposes, domain extension start to gain interest <ref type="bibr" coords="2,451.18,656.06,9.96,8.80" target="#b6">[7]</ref>; (ii) since the majority of NER systems were designed for English, the extension to novel languages (including low resource languages) became of importance <ref type="bibr" coords="3,458.44,130.89,14.61,8.80" target="#b27">[28]</ref>.</p><p>One can say that NER followed the different trends in NLP. The first approaches were based on gazeeters and handcrafted rules. Initially NER was considered to be solved by a patient process involving careful syntactic analysis <ref type="bibr" coords="3,462.34,168.29,14.61,8.80" target="#b11">[12]</ref>. Supervised learning approaches came to fashion with the increase of available data and the rise of shared tasks on NER. Decision trees and Markov models were soon outperformed by Condition Random Fields (CRF). Thanks to its ability to model dependencies and to take advantage of the sequentiality of textual data, CRF helped to set new state-of-the-art results in the domain <ref type="bibr" coords="3,440.31,228.06,9.96,8.80" target="#b7">[8]</ref>. Since supervised learning results were bound by the size of training data, lighter approaches were tested in the beginning of the 2000's, among them we can cite weakly supervision <ref type="bibr" coords="3,219.85,263.93,15.49,8.80" target="#b32">[33]</ref> and active learning <ref type="bibr" coords="3,325.01,263.93,14.61,8.80" target="#b28">[29]</ref>.</p><p>During a time, most of promising approaches involved an addition to improve CRFs : word embeddings <ref type="bibr" coords="3,249.16,289.37,14.61,8.80" target="#b23">[24]</ref>, (bi-)LSTMs <ref type="bibr" coords="3,326.41,289.37,15.49,8.80" target="#b14">[15]</ref> or contextual embeddings <ref type="bibr" coords="3,462.33,289.37,14.61,8.80" target="#b24">[25]</ref>. More recently, the improvements in contextual word embeddings made the CRFs disappear as standalone models for systems reaching state-of-the-art results, see <ref type="bibr" coords="3,134.77,325.23,15.49,8.80" target="#b29">[30]</ref> for a review on the subject and a very interesting discussion on the limits attained by state-of-the-art systems, the Glass Ceiling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset for the CLEF-HIPE shared task</head><p>The dataset of the CLEF-HIPE shared task contains newspaper articles of 17th-20th century. The text is an output of an OCR software, then tokenised and annotated with labels corresponding to each sub-task. This pecularity of historical documents will be detailed later in this section. The corpus provided for French and German both contained training data (train) and development data (dev) whereas, for English only development data was provided for the shared task. For this reason, we chose to work on French and German only. Table <ref type="table" coords="3,475.61,480.02,4.98,8.80" target="#tab_0">1</ref> shows some statistics of this dataset. The size of the train dataset was twice higher for French than for German whereas the development sets have roughly the same size. As usual in NER, persons (Pers) and locations (Loc) are the most frequent entity types. Table <ref type="table" coords="4,176.53,118.93,4.98,8.80" target="#tab_2">2</ref> shows an excerpt of the train dataset (CoNLL format). For each document, general information were provided. Among them, newspaper and date may have been features useful for recognising entities but we did not take advantage of it. Each document was composed of segments, starting with "# segment . . . " corresponding to lines in the original documents. Each segment is tokenized in order to correspond to the CoNLL format with one token per line. These two notions, segments and tokens, are very important since they do not always match the type of unit usually processed in NLP pipelines. Segments seldom correspond to sentences so that there is a need to concatenate the segments to get the raw text and then segment it into sentences. This is very interesting since it gets us close to real-world conditions rather than laboratory conditions, and we show in Section 5.2 that this segment vs. sentence question has an important influence on the results. Regarding tokens, the tokenization is obviously not perfect. We can see that there are non-standard words and bad tokenization due to the OCR output (in red in Table <ref type="table" coords="4,235.91,286.31,3.87,8.80" target="#tab_2">2</ref>). If we concatenate the tokens we get the sequence "Su. _sss allemands" instead of "Suisse allemande". These non-standard words make the Named Entity Recognition task more complicated and, again, more realistic.   <ref type="bibr" coords="4,328.56,580.72,10.51,8.80" target="#b3">[4]</ref> is a free NLP tool that relies on linear-chain CRFs <ref type="bibr" coords="4,218.67,592.67,15.49,8.80" target="#b13">[14]</ref> to perform tagging. SEM uses Wapiti [16] v1.5.0<ref type="foot" coords="4,462.65,591.12,3.97,6.16" target="#foot_2">6</ref> as linear-chain CRFs implementation. For this particular NER task, SEM uses the following features:</p><formula xml:id="formula_0" coords="4,144.61,464.88,288.19,41.87">O O O O O _ _ _ serons O O O O O O _ _ _ heureux O O O O O O _ _ _ de O O O O O O _ _ _ publier O O O O O O _ _ _ . . .</formula><p>token, prefix/suffix from 1 to 5 and a Boolean isDigit features in a <ref type="bibr" coords="5,454.94,118.93,25.65,8.80">[-2, 2]</ref> window; previous/next common noun in sentence; -10 gazetteers (including NE lists and trigger words for NEs) applied with some priority rules in a [-2, 2] window; a "fill-in-the-gaps" gazetteers feature where tokens not found in any gazetteer are replaced by their POS, as described in <ref type="bibr" coords="5,350.61,192.85,14.61,8.80" target="#b26">[27]</ref>. This feature used token unigrams and token bigrams in a [-2, 2] a window. tag unigrams and bigrams.</p><p>We trained a CLEF HIPE specific model by optimizing L1 and L2 penalties on the development set. The metric used to estimate convergence of the model is the error on the development set (1 -accuracy). For French, our optimal L1 and L2 penalties were 0.5 and 0.0001 respectively (default Wapiti parameters). For German, our optimal L1 and L2 penalties were 1.0 and 0.0001 respectively.</p><p>One interest of SEM is that it has a built-in sentence tokenizer for French using a rule-based approach. By default, CLEF-HIPE provides a newline segmentation that is the output of the OCR. As a result, some NE mentions span across multiple segments, making it very hard to identify them correctly. It is to be expected that models trained (and labelling on) sentences would yield better performances than those trained (and labelling on) segments. SEM makes it simple to switch between different sequence segmentations, which allowed us to label sentences and output segments. SEM's sentence segmentation engine works using mainly local rules to determine whether a token is the last of a sequence (eg: is a dot preceded by a known title abbreviation?). It also uses non-local rules to remember whether a token is between parentheses or French quotes to not segment automatically within them. Since we work at token level, we had to adapt some rules to fit CLEF-HIPE tokenization. For example, SEM decides at tokenization stage whether a dot is a strong punctuation or part of a larger token, as for abbreviations. This has the advantage of making sentence segmentation easier. CLEF-HIPE tokenization systematically separates dots, so we adapted some sentence segmentation rules, for example: we decided not to consider a dot as a sentence terminator if the previous token was in a lexica of titles or functions. No specific handling of OCR errors were done. Another interest is that SEM has an NE mention broadcasting process. Mentions found at least once in a document are used as a gazetteer to tag unlabeled mentions within said document. When a new mention overlaps and is strictly longer than an already found mention, the new mention will replace the previous one in the document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Contextualized word embeddings</head><p>Embeddings from Language Models (ELMo) <ref type="bibr" coords="5,335.60,632.15,15.49,8.80" target="#b24">[25]</ref> is a Language Model, i.e, a model that given a sequence of N tokens, (t 1 , t 2 , ..., t N ), computes the probability of the sequence by modeling the probability of token t k given the history (t 1 , ..., t k-1 ):</p><formula xml:id="formula_1" coords="6,212.79,130.28,189.78,30.55">p(t 1 , t 2 , . . . , t N ) = N k=1 p(t k | t 1 , t 2 , . . . , t k-1 ).</formula><p>However, ELMo in particular uses a bidirectional language model (biLM) consisting of L LSTM layers, that is, it combines both a forward and a backward language model jointly maximizing the log likelihood of the forward and backward directions:</p><formula xml:id="formula_2" coords="6,213.15,221.13,190.72,47.49">N k=1 ( log p(t k | t 1 , . . . , t k-1 ; Θ x , - → Θ LST M , Θ s ) + log p(t k | t k+1 , . . . , t N ; Θ x , ← - Θ LST M , Θ s ) ) .</formula><p>where at each position k, each LSTM layer l outputs a context-dependent representation -→ h LM k,l with l = 1, . . . , L for a forward LSTM, and</p><formula xml:id="formula_3" coords="6,134.77,286.47,345.82,28.52">← - h LM k,l of t k given (t k+1 , . . . , t N ) for a backward LSTM.</formula><p>ELMo also computes a context-independent token representation x LM k via token embeddings or via a CNN over characters. ELMo then ties the parameters for the token representation (Θ x ) and Softmax layer (Θ s ) in the forward and backward direction while maintaining separate parameters for the LSTMs in each direction.</p><p>ELMo is a task specific combination of the intermediate layer representations in the biLM, that is, for each token t k , a L-layer biLM computes a set of 2L + 1 representations</p><formula xml:id="formula_4" coords="6,221.07,416.53,173.23,34.22">R k = {x LM k , - → h LM k,l , ← - h LM k,l | l = 1, . . . , L} = {h LM k,l | l = 0, . . . , L},</formula><p>where h LM k,0 is the token layer and</p><formula xml:id="formula_5" coords="6,260.06,480.07,95.23,17.54">h LM k,l = [ - → h LM k,l ; ← - h LM k,l ],</formula><p>for each biLSTM layer.</p><p>When included in a downstream model, as it is the case in this paper, ELMo collapses all L layers in R into a single vector ELMo k = E(R k ; Θ e ), generally computing a task specific weighting of all biLM layers:</p><formula xml:id="formula_6" coords="6,235.77,562.34,143.82,48.26">ELMo task k = E(R k ; Θ task ) = γ task L l=0 s task l h LM k,l .</formula><p>applying layer normalization to each biLM layer before weighting. Following <ref type="bibr" coords="6,195.52,632.15,14.61,8.80" target="#b24">[25]</ref>, we use in this paper ELMo models where L = 2, i.e., the ELMo architecture involves a character-level CNN layer followed by a 2-layer biLSTM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">ELMo-LSTM-CRF (run1 and run2)</head><p>The LSTM-CRF is a model originally proposed by Lample et al. <ref type="bibr" coords="7,418.71,137.74,15.49,8.80" target="#b14">[15]</ref> it consists of a Bi-LSTM encoder pre-appended by both character level word embeddings and pre-trained word embeddings, and a CRF decoder layer. For our experiments, we follow the same approach as Ortiz Suárez et al. <ref type="bibr" coords="7,404.38,173.60,15.49,8.80" target="#b20">[21]</ref> by using the Bi-LSTM-CRF implementation of Straková et al. <ref type="bibr" coords="7,352.59,185.56,15.49,8.80" target="#b30">[31]</ref> which is open source and readily available <ref type="foot" coords="7,206.62,195.96,3.97,6.16" target="#foot_3">7</ref> , and pre-appending contextualized word-embeddings to the model. For French we pre-append the FrELMo model <ref type="bibr" coords="7,367.15,209.47,14.61,8.80" target="#b20">[21]</ref>, which is the standard ELMo <ref type="bibr" coords="7,166.34,221.42,15.49,8.80" target="#b24">[25]</ref> implementation<ref type="foot" coords="7,254.07,219.87,3.97,6.16" target="#foot_4">8</ref> trained on the French OSCAR<ref type="foot" coords="7,400.69,219.87,3.97,6.16" target="#foot_5">9</ref> corpus <ref type="bibr" coords="7,442.38,221.42,15.49,8.80" target="#b21">[22]</ref>  <ref type="bibr" coords="7,462.33,221.42,14.61,8.80" target="#b22">[23]</ref>. For German we pre-append the German ELMo <ref type="bibr" coords="7,340.71,233.38,14.61,8.80" target="#b18">[19]</ref>, which is again the standard ELMo implementation but trained on the German Wikipedia.</p><p>Contrary to the approach of Ortiz Suárez et al. <ref type="bibr" coords="7,373.83,257.29,14.61,8.80" target="#b20">[21]</ref>, we do not use the CamemBERT model <ref type="bibr" coords="7,230.45,269.25,15.49,8.80" target="#b17">[18]</ref> for French or the German BERT <ref type="bibr" coords="7,402.64,269.25,9.96,8.80" target="#b1">[2]</ref>. Both of these models are BERT-based and as such they are limited to a 512-token contextualized window. Moreover, they both use SentencePiece <ref type="bibr" coords="7,373.56,293.16,15.49,8.80" target="#b12">[13]</ref> meaning that tokens are actually subwords, which considerably increases the number of tokens per sentence, specially for the longer ones, thus decreasing the contextual windows of both CamemBERT and the German BERT. SentencePiece also introduces the problem of a fixed-size vocabulary, which in the case of this shared task might negatively impact the performance of said models, as they could struggle handling OCR problems or just non-standard vocabulary. Since our main goal was to reconstruct the sentences and use long contextualized sequences we opted to use ELMo which can easily handle longer sequences with it's standard implementation and actually has a dynamic vocabulary thanks to the CNN character embedding layer, thus it might be better equipped to handle non-standard orthography and OCR problems.</p><p>For the fixed word embeddings we used the Common Crawl-based FastText embeddings <ref type="bibr" coords="7,189.58,448.57,15.49,8.80" target="#b9">[10]</ref> originally trained by Facebook as opposed to the embeddings provided by the HIPE shared task, as we obtained better dev scores using the original FastText embeddings for both French and German.</p><p>We used the standard hyperparameters originally<ref type="foot" coords="7,367.21,482.88,7.94,6.16" target="#foot_6">10</ref> used by Straková et al. <ref type="bibr" coords="7,134.77,496.39,14.61,8.80" target="#b30">[31]</ref>. Namely a batch size of 8, a dropout of 0.5, a learning rate of 0.001 and 10 epochs. The difference between run 1 and 2, is that run 1 uses the data as is, while run 2 uses the reconstructed sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results and Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Official shared task results</head><p>The results of our 3 runs compared to the best run on the NERC-coarse sharedtask for French and German are given in Table <ref type="table" coords="7,354.38,604.61,4.98,8.80">3</ref> (strict scenario). For both tasks, we are the third best ranking team. We only did very minimal adaptation of existing systems. We did not modify tokenization for any language. The most notable change was to use custom sentence segmentation instead of given segments for French and using some additional lexica as features for our CRF model in German (for French, we only used existing SEM lexica). Other than that, we only optimized hyper-parameters on the dev set. This clearly illustrates the power of contextual embeddings and today's neural network architectures. This is encouraging in terms of usability of SotA models on real-world data. Table <ref type="table" coords="8,163.91,344.72,4.13,7.93">3</ref>. Strict results for our systems compared to the winning system (micro measures)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Study of sequence segmentation</head><p>In this section, we evaluate the influence of sequence segmentation on system performances. This evaluation is done for French only, as we used SEM to provide sentence segmentation and SEM could only provide a proper sentence segmentation for that language. As can be seen in table <ref type="table" coords="8,344.52,476.47,3.87,8.80" target="#tab_4">4</ref>, sentence segmentation allows to improve results by 3.5 F1 points. This is due to the fact that some entities were split across multiple segments in the original data. Using a custom sentence segmentation allows to have entities in a single sequence. This segmentation is applied both with training data and evaluation data, so that our systems can access a more proper context for named entities. The cost of using another segmentation is relatively cheap, as SEM can process nearly 1GB of raw text per hour.</p><p>A per entity comparison is also available in Table <ref type="table" coords="8,375.27,572.37,3.87,8.80" target="#tab_4">4</ref>. One can see that the improvement of sentence segmentation is not very significant for locations (Loc). It is due to two facts : (i) locations are usually small in number of tokens and therefore less prone to be separated in two segments and (ii) there was less room from improvement since they were the easiest entity type to detect (86.35% F1-score). To the contrary, entities of type "product" (Prod), usually longer in tokens, were very hard to predict with only 48.57% F1-measure and benefited the most from segmentation in sentences (+16 percentage points in F1-measure). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">To dev or not to dev?</head><p>In Table <ref type="table" coords="9,175.84,290.71,4.98,8.80" target="#tab_5">5</ref> we show the results that could have been obtained by training the Bi-LSTM model on both train and dev dataset. We used the same hyperparameters as we did for our official run. Despite the fact that it does not ensure the robustness of the system, the added-value seem to be quite disappointing <ref type="foot" coords="9,456.69,325.02,7.94,6.16" target="#foot_7">11</ref> . In German the gain may be a bit more significant, probably due to the smaller size of the training dataset.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this article we presented three methods developed for the Named Entity Recognition task in French and German historical newspapers. The first method relied on linear-chain CRFs while the other two methods use a Bidirectional LSTM and a bidirectional Language Model (ELMo). The later outperformed the CRF model and achieved rank 3 on the NER task in both French and German. We also showed that the type of sequences used has a significant influence on the results. When we segment in sentences rather than using the segments of the dataset as it is the results are systematically much better, with an exception for locations where the gain is marginal. This proves that sentence segmentation remains a key component of efficient NLP architectures, in particular for models taking advantage of the context. As a future work it would be interesting to assess the importance of noise in the data. For instance, by comparing the results of NER on texts obtained via different OCR tools. The influence of the qualitative jumps in the data, which is common in Digital Humanities, is an important aspect to evaluate the robustness of the system in real-world conditions rather than laboratory conditions. We also plan to provide an in-depth analysis of the impact of word embeddings and neural architecture, as we only provided our best results in this paper.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="9,183.02,394.50,30.68,6.63"><head></head><label></label><figDesc>metric</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,144.07,567.46,327.22,85.50"><head>Table 1 .</head><label>1</label><figDesc>Statistics on the training and development data in French and German</figDesc><table coords="3,152.42,567.46,310.51,72.51"><row><cell></cell><cell cols="3">Tokens Documents Segments</cell><cell cols="2">Labeled named entities</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Pers Loc Org Time Prod</cell></row><row><cell cols="2">Train Fr 166217</cell><cell>158</cell><cell cols="2">19183 3067 2513 833</cell><cell>273</cell><cell>198</cell></row><row><cell>Dev Fr</cell><cell>37592</cell><cell>43</cell><cell>4423</cell><cell>771 677 158</cell><cell>69</cell><cell>48</cell></row><row><cell cols="2">Train De 86960</cell><cell>104</cell><cell cols="2">10353 1747 1170 358</cell><cell>118</cell><cell>112</cell></row><row><cell>Dev De</cell><cell>36175</cell><cell>40</cell><cell>4186</cell><cell>664 428 172</cell><cell>73</cell><cell>53</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,134.77,508.69,339.15,80.82"><head>Table 2 .</head><label>2</label><figDesc>Example extracted from the French training dataset 4 CRFs and Contextualized Word Embeddings for NER</figDesc><table coords="4,134.77,562.81,190.08,26.70"><row><cell>4.1 CRF model (run3)</cell></row><row><cell>SEM (Segmenteur-Étiqueteur Markovien) 45</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,134.77,122.16,345.82,113.98"><head>Table 4 .</head><label>4</label><figDesc>Comparison between segments and sentences on French dev dataset (run 1), strict scenario</figDesc><table coords="9,141.50,122.16,331.41,89.83"><row><cell>Type</cell><cell></cell><cell>P</cell><cell></cell><cell>R</cell><cell></cell><cell>F1</cell></row><row><cell></cell><cell>Segments</cell><cell>Sentences</cell><cell>Segments</cell><cell>Sentences</cell><cell>Segments</cell><cell>Sentences</cell></row><row><cell>Loc</cell><cell cols="2">85.21 87.73 (+2.52)</cell><cell>87.52</cell><cell>87.08 (-0.44)</cell><cell cols="2">86.35 87.41 (+1.06)</cell></row><row><cell>Org</cell><cell cols="2">70.62 71.33 (+0.71)</cell><cell cols="2">62.78 65.64 (+2.86)</cell><cell cols="2">66.47 68.37 (+1.90)</cell></row><row><cell>Pers</cell><cell cols="2">80.24 84.64 (+4.40)</cell><cell cols="2">76.88 82.09 (+5.21)</cell><cell cols="2">78.52 83.35 (+4.83)</cell></row><row><cell>Prod</cell><cell cols="2">62.96 75.86 (+12.90)</cell><cell cols="2">39.53 56.41 (+16.88)</cell><cell cols="2">48.57 64.71 (+16.14)</cell></row><row><cell>Time</cell><cell cols="2">86.21 90.91 (+4.70)</cell><cell cols="2">78.12 87.72 (+9.60)</cell><cell cols="2">81.97 89.29 (+7.32)</cell></row><row><cell>Global</cell><cell cols="2">81.03 84.46 (+3.43)</cell><cell cols="2">81.61 84.46 (+2.85)</cell><cell cols="2">79.52 83.01 (+3.49)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="9,134.77,389.03,345.83,84.24"><head>Table 5 .</head><label>5</label><figDesc>Results obtained on the test set (strict metric) with only the train set (not to dev) and with train+dev sets (to dev) with our best system (run 2)</figDesc><table coords="9,183.02,389.03,247.41,59.76"><row><cell></cell><cell cols="2">french</cell><cell cols="2">german</cell></row><row><cell></cell><cell>not to dev</cell><cell>to dev</cell><cell>not to dev</cell><cell>to dev</cell></row><row><cell>P</cell><cell>78.8</cell><cell>79.5 (+0.7)</cell><cell>65.8</cell><cell>68.2 (+2.4)</cell></row><row><cell>R</cell><cell>80.2</cell><cell>80.7 (+0.5)</cell><cell>65.8</cell><cell>66.1 (+0.3)</cell></row><row><cell>F1</cell><cell>79.5</cell><cell>80.1 (+0.6)</cell><cell>65.8</cell><cell>67.1 (+1.3)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="4,144.73,634.83,211.71,8.17"><p>available at: https://github.com/YoannDupont/SEM</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1" coords="4,144.73,645.79,205.45,7.92"><p>translates to: Markovian Tokenizer-Tagger (MTT).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2" coords="4,144.73,656.74,197.59,8.17"><p>available at: https://github.com/Jekub/Wapiti</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_3" coords="7,144.73,623.87,253.45,8.17"><p>Available at: https://github.com/ufal/acl2019_nested_ner.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_4" coords="7,144.73,634.83,213.75,8.17"><p>Available at: https://github.com/allenai/bilm-tf</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_5" coords="7,144.73,645.79,166.68,8.17"><p>Available at: https://oscar-corpus.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_6" coords="7,144.73,657.44,327.29,7.47"><p>https://github.com/ufal/acl2019_nested_ner/blob/master/tagger.py#L484.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_7" coords="9,144.73,645.79,335.86,7.92;9,144.73,656.74,37.88,7.92"><p>In particular, if we consider that it would not have given us a better ranking on any language.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,142.95,300.30,337.64,7.92;10,151.52,311.26,329.07,7.92;10,151.52,322.22,294.80,7.92" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,324.57,300.30,156.02,7.92;10,151.52,311.26,99.87,7.92">Bootstrapped text-level named entity recognition for literature</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Brooke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hammond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,273.98,311.26,206.61,7.92;10,151.52,322.22,138.48,7.92">Proc. of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="344" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.95,333.75,337.64,8.17;10,151.52,344.71,142.11,8.17" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Möller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pietsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Soni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Yeung</surname></persName>
		</author>
		<ptr target="https://deepset.ai/german-bert" />
		<title level="m" coord="10,393.14,333.75,51.54,7.92">German bert</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.95,356.25,337.64,7.92;10,151.52,367.21,132.74,7.92" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="10,299.22,356.25,177.28,7.92">Handbook of Natural Language Processing</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">L</forename><surname>Somers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Moisl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Marcel Dekker, Inc</publisher>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.95,378.74,337.63,7.92;10,151.52,389.70,329.07,7.92;10,151.52,400.66,226.42,7.92" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,204.59,378.74,276.00,7.92;10,151.52,389.70,156.15,7.92">Exploration de traits pour la reconnaissance d&apos;entités nommées du français par apprentissage automatique</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Dupont</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,329.15,389.70,151.44,7.92;10,151.52,400.66,169.70,7.92">24e Conférence sur le Traitement Automatique des Langues Naturelles (TALN)</title>
		<imprint>
			<biblScope unit="page">42</biblScope>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.95,412.19,337.63,7.92;10,151.52,423.15,329.07,7.92;10,151.52,434.11,195.90,7.92" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,362.27,412.19,118.32,7.92;10,151.52,423.15,109.32,7.92">Diachronic evaluation of NER systems on old newspapers</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Colavizza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Rochat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Kaplan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,269.28,423.15,211.30,7.92;10,151.52,434.11,42.49,7.92">Proc. of the 13th Conference on Natural Language Processing</title>
		<meeting>of the 13th Conference on Natural Language essing<address><addrLine>KONVENS</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="page" from="97" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.95,445.65,337.64,7.92;10,151.52,456.61,329.07,7.92;10,151.52,467.56,329.07,7.92;10,151.52,478.52,271.25,7.92" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,391.70,445.65,88.89,7.92;10,151.52,456.61,287.03,7.92">Extended Overview of CLEF HIPE 2020: Named Entity Processing on Historical Newspapers</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Flückiger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clematide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,361.89,467.56,118.70,7.92;10,151.52,478.52,190.44,7.92">Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.95,490.06,337.64,7.92;10,151.52,501.02,329.07,7.92;10,151.52,511.98,25.59,7.92" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,194.83,490.06,243.89,7.92">A framework for named entity recognition in the open domain</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,459.20,490.06,21.39,7.92;10,151.52,501.02,271.42,7.92">Proc. of the Recent Advances in Natural Language Processing (RANLP)</title>
		<meeting>of the Recent Advances in Natural Language essing (RANLP)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="137" to="144" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.95,523.51,337.64,7.92;10,151.52,534.47,329.07,7.92;10,151.52,545.43,320.26,7.92" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,317.62,523.51,162.97,7.92;10,151.52,534.47,203.90,7.92">Incorporating non-local information into information extraction systems by Gibbs sampling</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Grenager</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,377.75,534.47,102.83,7.92;10,151.52,545.43,217.15,7.92">Proc. of the 43rd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>of the 43rd Annual Meeting on Association for Computational Linguistics<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="363" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.95,556.96,337.63,7.92;10,151.52,567.92,329.07,7.92;10,151.52,578.88,315.14,7.92" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,195.18,567.92,281.31,7.92">End-to-end named entity and semantic concept extraction from speech</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ghannay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Caubrière</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Estève</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Camelin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Simonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Laurent</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Morin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,165.60,578.88,185.21,7.92">IEEE Spoken Language Technology Workshop</title>
		<meeting><address><addrLine>Athens, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-12">Dec 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,590.42,337.97,7.92;10,151.52,601.37,329.07,7.92;10,151.52,612.33,329.08,7.92;10,151.52,623.29,192.75,7.92" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,403.48,590.42,77.11,7.92;10,151.52,601.37,86.30,7.92">Learning word vectors for 157 languages</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,258.75,601.37,221.83,7.92;10,151.52,612.33,329.08,7.92;10,151.52,623.29,69.07,7.92">Proc. of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018). European Language Resources Association (ELRA)</title>
		<meeting>of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018). European Language Resources Association (ELRA)<address><addrLine>Miyazaki, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-05">May 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,634.83,337.98,7.92;10,151.52,645.79,329.07,7.92;10,151.52,656.74,159.93,7.92" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,275.52,634.83,132.62,7.92">Design of the MUC-6 evaluation</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Sundheim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,431.04,634.83,49.55,7.92;10,151.52,645.79,173.82,7.92;10,370.43,645.79,41.37,7.92">Proc. of the 6th Conference on Message Understanding</title>
		<meeting>of the 6th Conference on Message Understanding<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="1" to="11" />
		</imprint>
	</monogr>
	<note>MUC6 &apos;95</note>
</biblStruct>

<biblStruct coords="11,142.61,119.62,337.98,7.92;11,151.52,130.58,329.07,7.92;11,151.52,141.54,130.75,7.92" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,204.47,119.62,169.01,7.92">The generic information extraction system</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Hobbs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,394.59,119.62,86.00,7.92;11,151.52,130.58,137.99,7.92;11,337.05,130.58,40.65,7.92">Proc. of the 5th Conference on Message Understanding</title>
		<meeting>of the 5th Conference on Message Understanding<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="87" to="91" />
		</imprint>
	</monogr>
	<note>MUC5 &apos;93</note>
</biblStruct>

<biblStruct coords="11,142.61,151.51,337.98,7.92;11,151.52,162.47,329.07,7.92;11,151.52,173.43,329.07,7.92;11,151.52,184.39,329.08,7.92;11,151.52,195.35,329.07,8.17;11,151.52,207.01,165.22,7.47" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,265.13,151.51,215.46,7.92;11,151.52,162.47,256.30,7.92">SentencePiece: A simple and language independent subword tokenizer and detokenizer for neural text processing</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Richardson</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D18-2012</idno>
		<ptr target="https://www.aclweb.org/anthology/D18-2012" />
	</analytic>
	<monogr>
		<title level="m" coord="11,432.53,162.47,48.06,7.92;11,151.52,173.43,329.07,7.92;11,151.52,184.39,113.15,7.92">Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</title>
		<meeting>the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations<address><addrLine>Brussels, Belgium</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-11">Nov 2018</date>
			<biblScope unit="page" from="66" to="71" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,216.28,337.98,7.92;11,151.52,227.24,329.08,7.92;11,151.52,238.20,329.07,7.92;11,151.52,249.16,204.27,7.92" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,342.15,216.28,138.44,7.92;11,151.52,227.24,233.07,7.92">Conditional random fields: Probabilistic models for segmenting and labeling sequence data</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">C N</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,406.75,227.24,73.85,7.92;11,151.52,238.20,267.17,7.92">Proc. of the Eighteenth International Conference on Machine Learning (ICML) 2001</title>
		<meeting>of the Eighteenth International Conference on Machine Learning (ICML) 2001<address><addrLine>Williamstown, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Williams College</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="282" to="289" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,259.14,337.98,7.92;11,151.52,270.09,329.07,7.92;11,151.52,281.05,329.07,7.92;11,151.52,292.01,284.54,7.92" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,453.70,259.14,26.89,7.92;11,151.52,270.09,166.97,7.92">Neural architectures for named entity recognition</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,339.07,270.09,141.52,7.92;11,151.52,281.05,329.07,7.92;11,151.52,292.01,90.78,7.92">Proc. of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2016-06">Jun 2016</date>
			<biblScope unit="page" from="260" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,301.99,337.98,7.92;11,151.52,312.95,329.07,7.92;11,151.52,323.90,236.57,7.92" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,298.66,301.99,126.16,7.92">Practical very large scale CRFs</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lavergne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Cappé</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Yvon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,448.12,301.99,32.47,7.92;11,151.52,312.95,308.44,7.92">Proc. of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 48th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="504" to="513" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,333.88,337.97,7.92;11,151.52,344.83,286.56,7.93" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="11,233.69,333.88,246.89,7.92;11,151.52,344.84,102.38,7.92">TaggerOne: joint named entity recognition and normalization with semi-Markov Models</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Leaman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,261.44,344.84,58.55,7.92">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">18</biblScope>
			<biblScope unit="page" from="2839" to="2846" />
			<date type="published" when="2016-06">06 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,354.81,337.98,7.92;11,151.52,365.77,329.07,7.92;11,151.52,376.73,329.08,7.92;11,151.52,387.69,329.07,7.92;11,151.52,398.65,329.07,8.17;11,151.52,410.31,146.39,7.47" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="11,278.35,365.77,183.78,7.92">CamemBERT: a tasty French language model</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Ortiz Suárez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Dupont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Romary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">É</forename><surname>De La Clergerie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Seddah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Sagot</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.645</idno>
		<ptr target="https://www.aclweb.org/anthology/2020.acl-main.645" />
	</analytic>
	<monogr>
		<title level="m" coord="11,151.52,376.73,329.08,7.92;11,151.52,387.69,41.97,7.92">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07">Jul 2020</date>
			<biblScope unit="page" from="7203" to="7219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,419.58,28.35,7.92;11,187.45,419.58,10.63,7.92;11,214.57,419.58,32.33,7.92;11,263.39,419.58,25.08,7.92;11,304.96,419.58,25.09,7.92;11,346.53,419.58,28.15,7.92;11,391.17,420.28,89.41,7.47;11,151.52,431.24,234.10,7.47" xml:id="b18">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>May</surname></persName>
		</author>
		<ptr target="https://github.com/t-systems-on-site-services-gmbh/german-elmo-model" />
		<title level="m" coord="11,214.57,419.58,32.33,7.92;11,263.39,419.58,25.08,7.92;11,304.96,419.58,25.09,7.92">German ELMo Model</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,440.52,337.98,7.92;11,151.52,451.48,329.07,7.92;11,151.52,462.44,25.59,7.92" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="11,378.13,440.52,102.47,7.92;11,151.52,451.48,230.09,7.92">Large-scale refinement of digital historic newspapers with named entity recognition</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Neudecker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Wilms</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Faber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Van Veen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,402.46,451.48,78.13,7.92">Proc. of IFLA 2014</title>
		<meeting>of IFLA 2014</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,472.41,337.98,7.92;11,151.52,483.37,329.07,7.92;11,151.52,494.33,329.07,7.92;11,151.52,505.29,238.60,7.92" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="11,423.31,472.41,57.28,7.92;11,151.52,483.37,231.99,7.92">Establishing a new state-of-the-art for French named entity recognition</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Ortiz Suárez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Dupont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Romary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Sagot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,406.26,483.37,74.33,7.92;11,151.52,494.33,194.83,7.92">Proc. of The 12th Language Resources and Evaluation Conference</title>
		<meeting>of The 12th Language Resources and Evaluation Conference<address><addrLine>Marseille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020-05">May 2020</date>
			<biblScope unit="page" from="4631" to="4638" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,515.26,337.98,7.92;11,151.52,526.22,329.07,7.92;11,151.52,537.18,329.08,7.92;11,151.52,548.14,329.08,7.92;11,151.52,559.10,329.07,8.17;11,151.52,570.76,146.39,7.47" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="11,340.42,515.26,140.17,7.92;11,151.52,526.22,250.13,7.92">A monolingual approach to contextualized word embeddings for mid-resource languages</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Ortiz Suárez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Romary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Sagot</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2020.acl-main.156</idno>
		<ptr target="https://www.aclweb.org/anthology/2020.acl-main.156" />
	</analytic>
	<monogr>
		<title level="m" coord="11,432.53,526.22,48.06,7.92;11,151.52,537.18,329.08,7.92;11,151.52,548.14,28.75,7.92">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Online</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2020-07">Jul 2020</date>
			<biblScope unit="page" from="1703" to="1714" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,580.03,337.97,7.92;11,151.52,590.99,329.07,7.92;11,151.52,601.95,329.08,7.92;11,151.52,612.91,329.07,7.92;11,151.52,623.87,329.07,7.92;11,151.52,634.83,329.07,7.92;11,151.52,645.79,329.07,7.92;11,151.52,657.44,231.60,7.47" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="11,326.22,580.03,154.37,7.92;11,151.52,590.99,222.08,7.92">Asynchronous pipelines for processing huge corpora on medium to low resource infrastructures</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Ortiz Suárez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Sagot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Romary</surname></persName>
		</author>
		<idno type="DOI">10.14618/ids-pub-9021</idno>
		<ptr target="http://nbn-resolving.de/urn:nbn:de:bsz:mh39-90215" />
	</analytic>
	<monogr>
		<title level="m" coord="11,190.44,612.91,290.15,7.92;11,151.52,623.87,39.92,7.92;11,243.30,623.87,237.29,7.92;11,151.52,634.83,158.16,7.92">Proceedings of the Workshop on Challenges in the Management of Large Corpora (CMLC-7) 2019</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Bański</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Barbaresi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Biber</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Breiteneder</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Clematide</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Kupietz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Lüngen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Iliadi</surname></persName>
		</editor>
		<meeting>the Workshop on Challenges in the Management of Large Corpora (CMLC-7) 2019<address><addrLine>Cardiff; Mannheim</addrLine></address></meeting>
		<imprint>
			<publisher>Leibniz-Institut für Deutsche Sprache</publisher>
			<date type="published" when="2019-07-22">22nd July 2019. 2019</date>
			<biblScope unit="page" from="9" to="16" />
		</imprint>
	</monogr>
	<note>7th Workshop on the Challenges in the Management of Large Corpora (CMLC-7)</note>
</biblStruct>

<biblStruct coords="12,142.61,119.62,337.97,7.92;12,151.52,130.58,329.07,7.92;12,151.52,141.54,294.78,7.92" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="12,318.52,119.62,162.07,7.92;12,151.52,130.58,93.43,7.92">Lexicon infused phrase embeddings for named entity resolution</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,265.05,130.58,215.54,7.92;12,151.52,141.54,109.45,7.92">Proc. of the Eighteenth Conference on Computational Natural Language Learning</title>
		<meeting>of the Eighteenth Conference on Computational Natural Language Learning<address><addrLine>Ann Arbor, Michigan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-06">Jun 2014</date>
			<biblScope unit="page" from="78" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,152.50,337.97,7.92;12,151.52,163.46,329.07,7.92;12,151.52,174.42,329.08,7.92;12,151.52,185.37,169.88,7.92" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="12,165.50,163.46,166.64,7.92">Deep contextualized word representations</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,353.31,163.46,127.28,7.92;12,151.52,174.42,310.00,7.92">Proc. of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics<address><addrLine>New Orleans, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-06">Jun 2018</date>
			<biblScope unit="page" from="2227" to="2237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,196.33,337.97,7.92;12,151.52,207.29,329.07,7.92;12,151.52,218.25,316.44,7.92" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="12,275.18,196.33,160.38,7.92">Massively multilingual transfer for NER</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rahimi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,459.20,196.33,21.38,7.92;12,151.52,207.29,309.47,7.92">Proc. of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07">Jul 2019</date>
			<biblScope unit="page" from="151" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,229.21,337.98,7.92;12,151.52,240.17,225.46,7.92" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="12,262.45,229.21,218.14,7.92;12,151.52,240.17,137.84,7.92">Reconnaissance robuste d&apos;entités nommées sur de la parole transcrite automatiquement</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Raymond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Fayolle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,311.08,240.17,26.60,7.92">TALN&apos;</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,251.13,337.98,7.92;12,151.52,262.09,329.08,7.92;12,151.52,273.05,294.38,7.92" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="12,203.07,251.13,258.66,7.92">Adapting an NER-system for German to the biomedical domain</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rössler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,151.52,262.09,329.08,7.92;12,151.52,273.05,131.80,7.92">Proc. of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications</title>
		<meeting>of the International Joint Workshop on Natural Language essing in Biomedicine and its Applications<address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="95" to="98" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,284.00,337.97,7.92;12,151.52,294.96,329.07,7.92;12,151.52,305.92,326.03,7.92" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="12,348.49,284.00,132.10,7.92;12,151.52,294.96,133.26,7.92">Multi-criteria-based active learning for named entity recognition</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,308.13,294.96,172.45,7.92;12,151.52,305.92,168.77,7.92">Proc. of the 42nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 42nd Annual Meeting of the Association for Computational Linguistics<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="589" to="596" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,316.88,337.97,7.92;12,151.52,327.84,329.07,7.92;12,151.52,338.80,308.17,7.92" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="12,452.18,316.88,28.41,7.92;12,151.52,327.84,177.85,7.92">Named entity recognition -is there a glass ceiling?</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Stanislawek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Wróblewska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Wójcicka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ziembicki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Biecek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,347.98,327.84,132.61,7.92;12,151.52,338.80,172.91,7.92">Proc. of the 23rd Conference on Computational Natural Language Learning</title>
		<meeting>of the 23rd Conference on Computational Natural Language Learning<address><addrLine>Hong Kong</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="624" to="633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,349.76,337.98,7.92;12,151.52,360.72,329.07,7.92;12,151.52,371.68,223.16,7.92" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="12,296.22,349.76,184.37,7.92;12,151.52,360.72,48.50,7.92">Neural architectures for nested NER through linearization</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Straková</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Straka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hajic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,219.16,360.72,261.43,7.92;12,151.52,371.68,41.97,7.92">Proc. of the 57th Conference of the Association for Computational Linguistics</title>
		<meeting>of the 57th Conference of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5326" to="5331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,382.63,337.98,7.92;12,151.52,393.59,329.08,7.92;12,151.52,404.55,325.86,7.92" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="12,317.53,382.63,163.06,7.92;12,151.52,393.59,219.96,7.92">Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition</title>
		<author>
			<persName coords=""><forename type="first">Tjong</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sang</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">F</forename><surname>De Meulder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,394.84,393.59,85.75,7.92;12,151.52,404.55,169.62,7.92">Proc. of the Seventh Conference on Natural Language Learning</title>
		<meeting>of the Seventh Conference on Natural Language Learning<address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<publisher>CONLL</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">03</biblScope>
			<biblScope unit="page" from="142" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,415.51,337.97,7.92;12,151.52,426.47,329.08,7.92;12,151.52,437.43,320.53,7.92" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="12,216.27,415.51,207.73,7.92">Counter-training in discovery of semantic patterns</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Yangarber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,447.51,415.51,33.07,7.92;12,151.52,426.47,308.29,7.92">Proc. of the 41st Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 41st Annual Meeting of the Association for Computational Linguistics<address><addrLine>Sapporo, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003-07">Jul 2003</date>
			<biblScope unit="page" from="343" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,448.39,337.97,7.92;12,151.52,459.35,329.07,7.92;12,151.52,470.31,58.35,7.92" xml:id="b33">
	<analytic>
		<title level="a" type="main" coord="12,305.64,448.39,170.33,7.92">Unsupervised learning of generalized names</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Yangarber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,176.16,459.35,299.83,7.92">Proc. of the International Conference on Computational Linguistics (ICCL)</title>
		<meeting>of the International Conference on Computational Linguistics (ICCL)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="1" to="7" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
