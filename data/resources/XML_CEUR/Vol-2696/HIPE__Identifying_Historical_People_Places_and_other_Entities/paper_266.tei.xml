<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,138.86,115.90,337.63,12.68;1,246.71,133.83,121.92,12.68">DeLFT and entity-fishing : Tools for CLEF HIPE 2020 Shared Task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,138.59,172.45,65.65,8.80"><forename type="first">Tanti</forename><surname>Kristanti</surname></persName>
							<email>tanti.kristanti@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">Inria</orgName>
								<address>
									<settlement>Paris</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,317.26,172.45,72.27,8.80"><forename type="first">Laurent</forename><surname>Romary</surname></persName>
							<email>laurent.romary@inria.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">Inria</orgName>
								<address>
									<settlement>Paris</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,138.86,115.90,337.63,12.68;1,246.71,133.83,121.92,12.68">DeLFT and entity-fishing : Tools for CLEF HIPE 2020 Shared Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5815B76ABAA69715E4802D0BE94C6958</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>entity recognition</term>
					<term>entity linking</term>
					<term>machine learning</term>
					<term>deep learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This article presents an overview of approaches and results during our participation in the CLEF HIPE 2020 NERC-COARSE-LIT and EL-ONLY tasks for English and French. For these two tasks, we use two systems: 1) DeLFT, a Deep Learning framework for text processing; 2) entity-fishing, generic named entity recognition and disambiguation service deployed in the technical framework of INRIA.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Named Entity Recognition (NER) refers to the task of identifying text spans that mention named entities and classifying them into predefined classes (e.g., person, location, organization). Whereas, Entity Linking (EL) refers to the task of detecting textual entity mentions and matching them to corresponding entries within knowledge bases (e.g., Wikipedia, Wikidata). Over the past few years, traditional machine learning-based (i.e., rule-based, unsupervised, and featurebased supervised learning) approaches have evolved into deep learning (DL) approaches, yielding state-of-the-art performances <ref type="bibr" coords="1,351.86,491.27,10.51,8.80" target="#b5">[7,</ref><ref type="bibr" coords="1,364.03,491.27,7.75,8.80" target="#b6">8,</ref><ref type="bibr" coords="1,373.44,491.27,11.62,8.80" target="#b19">21]</ref>. For our participation in the CLEF HIPE 2020 shared task, we use two different systems that implement non-neural machine learning (ML) and DL approaches.</p><p>In HIPE, a shared task dedicated to the evaluation of named entity (NE) processing on historical newspapers in French, German, and English <ref type="bibr" coords="1,432.35,540.04,9.96,8.80" target="#b3">[5]</ref>, we participated in two different NERC-COARSE-LIT and EL-ONLY tasks by using two systems: DeLFT and entity-fishing. Deep Learning Framework for Text (DeLFT) is a framework for text processing, which re-implements standard state-of-the-art DL architectures. Meanwhile, entity-fishing is a generic named entity recognition and disambiguation (NERD) system, which applies supervised machine learning based on Random Forest and Gradient Tree Boosting exploiting various features.</p><p>Both DeLFT<ref type="foot" coords="2,206.40,117.38,3.97,6.16" target="#foot_0">1</ref> and entity-fishing<ref type="foot" coords="2,290.63,117.38,3.97,6.16" target="#foot_1">2</ref> are open-source systems under an Apache 2 license. Codes, models, and resources that are publicly available through the Github repository allow users and contributors, including us, to use existing services and models and to contribute to system and model improvements and tests. With the use of DeLFT, our goal is to re-build DL-based models for recognizing mentions within English and French HIPE historical corpus belonging to Person (pers), Location (LOC), Organization (ORG), Product (PROD), and Time (TIME) classes. Meanwhile, with entity-fishing service, we use the service to disambiguate provided mentions within French and English HIPE data against Wikidata entries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Tools</head><p>This section provides a general description of the two systems we use, DeLFT and entity-fishing. For a better understanding of technical discussions, it is advisable to refer directly to their repositories and documentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">DeLFT</head><p>Deep Learning Framework for Text (DeLFT) is an open-source framework for text processing, including sequence labeling (e.g., NE tagging) and text classification problems. This Keras and TensorFlow framework re-implements standard state-of-the-art DL architectures for text processing.</p><p>DeLFT supports many DL architectures (e.g., Bidirectional LSTMs and Conditional Random Fields <ref type="bibr" coords="2,239.91,412.45,9.96,8.80" target="#b6">[8]</ref>, Bidirectional LSTM and Convolutional Neural Networks <ref type="bibr" coords="2,163.41,424.40,9.96,8.80" target="#b1">[2]</ref>, Bidirectional Gated Recurrent Unit <ref type="bibr" coords="2,340.13,424.40,15.49,8.80" target="#b13">[15]</ref>) and contextualized embeddings (e.g., ELMo, BERT). For using the desired pre-trained word embeddings, we need to provide them from the source separately. DeLFT then loads and manages these embeddings by compiling at the very first access to be stored in a database.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">entity-fishing</head><p>entity-fishing is a generic NERD system against Wikidata. Deployed as part of the French national infrastructure Huma-Num<ref type="foot" coords="2,349.75,530.75,3.97,6.16" target="#foot_2">3</ref> , the service provides a standardized interface, open and flexible architecture, allowing easy deployment, including in digital humanities contexts. Initiated in the context of the EU FP7 Cendari project from 2013 to 2016, entity-fishing aimed at setting up a digital research environment for historians of the medieval and WWI periods to access archival contents and acquire numerous assets or entities information <ref type="bibr" coords="2,439.57,592.08,9.96,8.80" target="#b4">[6]</ref>.</p><p>In general, entity-fishing has three phases: language identification, mention recognition, and entity resolution. First, language identification is necessary for selecting appropriate utilities for text processing (e.g., tokenizer, sentence segmentation) and a specific Wikipedia from the knowledge base. Second, mention recognition has the responsibility to extract entity mentions from the input.</p><p>To support the generic nature, even though prepared with a set of recognizers, entity-fishing provides the possibility for users to extend with additional ones.</p><p>entity-fishing supports traditional mention extractors: named entity recognition, Wikipedia lookup, acronym extraction. For NER, entity-fishing uses grobidner. grobid-ner<ref type="foot" coords="3,199.49,201.45,3.97,6.16" target="#foot_3">4</ref> is a library for processing texts, extracting named entities, and classifying these entities into 27 classes (e.g., person, location, media, organization, period) using a Conditional Random Field (CRF) statistical model. Meanwhile, Wikipedia lookup is complementary to the machine learning NER approach. The lookup attempts to find all mentions that correspond to either a title or an anchor in Wikipedia using an N-gram-based matching approach. For the acronyms, entity-fishing treats them as mentions and uses the base for disambiguation. The resolved entity is then further propagated in the text for each occurrence of the acronym. The result of the mention recognition step is an aggregated list of objects containing raw values from the original text, their actual positions, and NER classes (within the 27 classes).</p><p>Lastly, entity resolution is the process of matching entity mentions to their corresponding Wikidata entries. The entity resolution has three stages: candidate generation, candidate ranking, candidate selector. In the candidate generation phase, each mention has a list of possible candidates for the disambiguation. Then, in the candidate ranking, each candidate is assigned a confidence score calculated as regression probability using various features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Auxiliary Resources</head><p>We use external datasets and embeddings in addition to those provided by the HIPE organizers.</p><p>Datasets The HIPE corpus consists of training, dev, and test datasets for each task and language. However, since for English, HIPE does not provide the training data, we use a pre-trained CoNLL-2012 (based on Ontonotes 5.0) <ref type="bibr" coords="3,465.10,516.01,15.49,8.80" target="#b15">[17]</ref> model and test the model with the HIPE test data.</p><p>Moreover, motivated by the promising French model results published by DeLFT, we use the annotated <ref type="bibr" coords="3,264.92,552.26,15.49,8.80" target="#b17">[19]</ref> French TreeBank (FTB) corpus and the HIPE data to re-build and benchmark the NER French model. This French journalistic genre corpus from the year 1990 is the annotated 2007 version of the FTB treebank containing the span, the literal type, sometimes completed with a subtype, and Aleda unique identifier of each mention. They use seven basic classes: Person, Location, Organization, Company, Product, POI (Point of Interest), and FictionChar (fictional character). FTB corpus contains 11,636 manually annotated mentions with the distribution of 3,761 location names, 3,357 company names, 2,381 organization names, 2,025 person names, 67 product names, 29 fictional character names, and 15 POIs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Word Embeddings</head><p>We use various static word embeddings: Global Vectors for Word Representation (GloVe) <ref type="bibr" coords="4,284.11,176.11,14.61,8.80" target="#b12">[14]</ref>, English fastText Common Crawl <ref type="bibr" coords="4,452.93,176.11,10.51,8.80" target="#b0">[1,</ref><ref type="bibr" coords="4,465.10,176.11,11.62,8.80" target="#b9">11]</ref>, and French Wikipedia fastText. <ref type="foot" coords="4,275.74,186.51,3.97,6.16" target="#foot_4">5</ref> We also use ELMo <ref type="bibr" coords="4,372.80,188.07,15.49,8.80" target="#b14">[16]</ref> contextualized word representations for English<ref type="foot" coords="4,251.35,198.47,3.97,6.16" target="#foot_5">6</ref> and French<ref type="foot" coords="4,307.73,198.47,3.97,6.16" target="#foot_6">7</ref> .  <ref type="bibr" coords="4,200.77,442.76,7.18,6.62" target="#b6">[8]</ref> 90.94 --Ma and Hovy (2016) <ref type="bibr" coords="4,200.10,450.84,10.57,6.62" target="#b8">[10]</ref> 91.21 --Chiu and Eric (2016) <ref type="bibr" coords="4,201.53,458.93,7.18,6.62" target="#b1">[2]</ref> 91.62 86.28 -Peters, et al. (2018) <ref type="bibr" coords="4,197.23,467.01,10.57,6.62" target="#b14">[16]</ref> 92.22 --Devlin, et al. (2018) <ref type="bibr" coords="4,198.12,475.10,7.18,6.62" target="#b2">[4]</ref> 92.80 -non neural achitectures Ratinov and Roth (2009) <ref type="bibr" coords="4,213.31,491.86,10.57,6.62" target="#b16">[18]</ref> 90.80 --Passos, et al. (2014) <ref type="bibr" coords="4,198.04,499.95,10.57,6.62" target="#b11">[13]</ref> 90.90 82.30 -Luo, et al. (2015) <ref type="bibr" coords="4,190.19,508.03,7.18,6.62" target="#b7">[9]</ref> 89.90 --Luo, et al. (2015) + linking <ref type="bibr" coords="4,220.21,516.12,7.18,6.62" target="#b7">[9]</ref> 91.20 --</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Benchmarking NER Models</head><p>Machine learning approaches have dominated NER, but the trend is towards neural network architectures that achieve state-of-the-art performances. For this reason, we compare several published NER systems as well as DeLFT pretrained models against various corpora (i.e., CoNLL-2003, CoNLL-2012, FTB) and present them in Table <ref type="table" coords="5,253.27,142.84,3.87,8.80" target="#tab_0">1</ref>.</p><p>[18] non-neural machine learning system achieves a 90.80 F1-score on CoNLL-2003. <ref type="bibr" coords="5,162.17,167.09,15.49,8.80" target="#b11">[13]</ref> improves with 90.90 on CoNLL-2003 and 82.30 on Ontonotes 5.0. Although <ref type="bibr" coords="5,180.58,179.05,10.51,8.80" target="#b7">[9]</ref> exceeds the previous achievements with their NERD system, which pushes the F1-score to 91.20. Nevertheless, their NER pure system reaches 89.90.</p><p>Meanwhile, for neural architectures, <ref type="bibr" coords="5,309.37,203.30,10.51,8.80" target="#b6">[8]</ref> reaches a 90.94 F1-score on CoNLL-2003, then <ref type="bibr" coords="5,182.95,215.25,15.49,8.80" target="#b8">[10]</ref> improves the results. <ref type="bibr" coords="5,294.20,215.25,10.51,8.80" target="#b1">[2]</ref> reports an F1-score of 91.62 on CoNLL-2003 and 86.28 on OntoNotes 5.0. <ref type="bibr" coords="5,282.28,227.21,15.49,8.80" target="#b14">[16]</ref> ELMo enhanced bidirectional LSTM with a CRF layer (BiLSTM-CRF) achieves an averaged F1-score of 92.22 over five runs. <ref type="bibr" coords="5,159.94,251.12,10.51,8.80" target="#b2">[4]</ref> has a competitive performance with state-of-the-art systems where its BERT LARGE fine-tuning approach tested on CoNLL-2003 reaches 92.80.</p><p>DeLFT has reimplemented neural architectures for NER <ref type="bibr" coords="5,395.01,275.37,9.96,8.80">[3]</ref>. Table <ref type="table" coords="5,437.68,275.37,4.98,8.80" target="#tab_0">1</ref> presents reported best F1-scores over ten runs for the English model using CoNLL From these results, we learn that DL-based systems have better performance than conventional machine learning systems. The use of contextualized word embeddings within the BiLSTM-CRF architecture improves the scores. The results in the CoNLL-2003 column also show that ELMo-based models give better F1-score than BERT-based models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Work Phases</head><p>In general, the HIPE shared task contains two tasks:</p><p>1. Named Entity Recognition and Classification (NERC): the recognition and classification of entity mentions with predefined high-level (i.e., pers, org, prod, loc, time), finer-grained, or nested entity classes. 2. Named Entity Linking (NEL): the task of matching identified entity mentions to Wikidata entries, with or without prior knowledge of mention types and boundaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Named Entity Recognition and Classification (NERC)</head><p>Although the English model built with the CoNLL-2003 dataset is promising, this model does not support the Time (Date) entities. Moreover, since HIPE does not provide training data for English, we use a CoNLL-2012 pre-trained model within the BiLSTM-CRF architecture, and ELMo contextualized word embeddings. For the French model, we enrich the French HIPE (i.e., the version 1.2 train and dev) dataset with annotated FTB data.</p><p>For training the models, we follow the default hyper-parameters<ref type="foot" coords="6,429.63,212.86,3.97,6.16" target="#foot_7">8</ref> as applied for other pre-trained sequence labeling models in DeLFT, except for the batch size and maximum epoch, we follow as indicates here. <ref type="foot" coords="6,369.02,236.77,3.97,6.16" target="#foot_8">9</ref>Challenges Combining data from different environments poses challenges, particularly with the reason of different NE class definitions as well as annotation guidelines. CoNLL-2012 define 18 classes. FTB corpus comes with seven NE classes. Meanwhile, HIPE uses five classes.</p><p>HIPE annotates absolute dates without months and hours, which confirms to the CoNLL-2012 DATE class. Furthermore, the HIPE Location (loc) entities suites with those belonging to CoNLL-2012 FAC (i.e., buildings, airports, highways, bridges), GPE (i.e., countries, cities, states), and LOCATION (i.e., non-GPE locations, mountain ranges, bodies of water) entities. It's also challenging to search the equivalence of the HIPE PROD entities, which we understand as media products since CoNLL-2012 classifies them in the ORG class.</p><p>Experiments We benchmarked the French NER trained with the HIPE data (i.e., train and dev v-1.2) only and the HIPE plus additional FTB data. The only HIPE model achieved an F1-score of 85.71 on the dev set. Meanwhile, the enriched model performs better with an increase of 3 scores into 88.46.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Named Entity Linking</head><p>For the NEL task, we use entity extraction and disambiguation services provided by entity-fishing. There are several ways to access these services; however, the most straightforward way is to use the service RESTful web services. <ref type="foot" coords="6,436.03,539.09,7.94,6.16" target="#foot_9">10</ref>First, we collect the text from the HIPE data. Then, we include this text as part of the JSON input query. The entity-fishing query processing service takes as input a JSON structured query and returns the JSON query enriched with a list of identified and, when possible, disambiguated entities. The JSON query format for the response file is identical to the input query. The client must respect the JSON query format, which is as follow:</p><p>Table 2 lists the best system, our system, and the baseline results for the NE-COARSE-LIT and EL-ONLY tasks.<ref type="foot" coords="8,241.35,148.75,7.30,5.22" target="#foot_10">11</ref> Our NER system performs worse than the L3i system. However, we perform better than the provided baseline, which is a CRF sequence classifier. We have an exception to the French NE-COARSE-LIT-strict result, which is slightly below the baseline F1-score.</p><p>It turns out that our EL system, especially for English, performs better than the L3i team and the aidalight-baseline, which corresponds to <ref type="bibr" coords="8,369.76,204.69,13.51,8.97" target="#b10">[12]</ref>. Our French EL system is better than the L3i EL system in terms of recall but rather appalling in terms of precision.</p><p>Table <ref type="table" coords="8,175.96,237.57,4.61,8.97" target="#tab_1">3</ref> and Table <ref type="table" coords="8,229.61,237.57,4.61,8.97" target="#tab_2">4</ref> present our English and French NER and EL performance on the HIPE test data with detailed information on false positive and false negative numbers. Strict NER, which is a more demanding task, performs worse than fuzzy NER. Looking further at each class, we highlight that there are considerably misclassified PROD entities and thus contribute to numerous false negatives. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lang Evaluation</head><p>Label P R F1 TP FP FN EN NEL-LIT-micro-fuzzy-@1 ALL 0.633 0.685 0.658 305 177 140 EN NEL-LIT-micro-fuzzy-relaxed-@1 ALL 0.633 0.685 0.658 305 177 140 EN NEL-LIT-micro-fuzzy-relaxed-@3 ALL 0.633 0.685 0.65 305 177 140 EN NEL-LIT-micro-fuzzy-relaxed-@5 ALL 0.633 0.685 0.658 305 177 140 FR NEL-LIT-micro-fuzzy-@1 ALL 0.585 0.65 0.616 1039 737 560 FR NEL-LIT-micro-fuzzy-relaxed-@1 ALL 0.604 0.67 0.635 1072 704 527 FR NEL-LIT-micro-fuzzy-relaxed-@3 ALL 0.604 0.67 0.635 1072 704 527 FR NEL-LIT-micro-fuzzy-relaxed-@5 ALL 0.604 0.67 0.635 1072 704 527</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>As our participation in the HIPE shared task, we highlight that the quantity and quality of data need are essential for the NERC and the NEL tasks. Further, although</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,452.93,287.32,27.67,8.80;5,134.77,299.28,275.03,8.80;5,149.71,311.57,330.88,8.80;5,134.77,323.53,345.83,8.80;5,134.77,335.48,345.82,8.80;5,134.77,347.44,345.82,8.80;5,134.77,359.39,345.83,8.80;5,134.77,371.35,345.82,8.80;5,134.77,383.30,345.83,8.80;5,134.77,395.26,345.83,8.80;5,134.77,407.21,345.83,8.80;5,134.77,419.17,25.45,8.80;5,149.71,431.46,330.88,8.80;5,134.77,443.42,345.82,8.80;5,134.77,455.37,279.00,8.80"><head></head><label></label><figDesc>-2003 and CoNLL-2012 and the French model using the FTB corpus. The model trained with CoNLL-2003 within the BiLSTM-CRF architecture and GloVe word embedding, tested against the test set, achieves a 91.35 F1score. The result is improving with GloVe combined with ELMo. Within BERT architecture and the CRF activation layer for fine-tuning, the model achieves an average of 91.20 F1-score. The best F1-score on CoNLL-2003 is 93.09 when using both train and validation datasets within a BiLSTM-CRF architecture, coupled with GloVe and ELMo embeddings. Meanwhile, the CoNLL-2012-based model within the BiLSTM-CRF architecture and the fastText embedding achieves an F1-score of 87.01. The involvement of ELMo increases the score by 2 points to 89.01. The French model trained with the FTB corpus within the BiLSTM-CRF architecture and French Wikipedia fastText reaches an 87.45 F1-score. Meanwhile, with the use of French ELMo, the score is improving into 89.23.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,134.77,232.32,345.82,217.05"><head>Table 1 .</head><label>1</label><figDesc>Comparison of DeLFT NER models with various feature sets and other published systems.</figDesc><table coords="4,136.09,263.70,343.20,185.68"><row><cell>Model</cell><cell cols="3">CoNLL-2003 [20] Ontonotes 5.0 [17] FTB [19] F1-score</cell></row><row><cell cols="2">DeLFT models [3]</cell><cell></cell><cell></cell></row><row><cell>CoNLL-2003-BiLSTM-CRF + GloVe</cell><cell>91.35</cell><cell>-</cell><cell>-</cell></row><row><cell>CoNLL-2003-BiLSTM-CRF + GloVe + ELMo</cell><cell>92.71</cell><cell>-</cell><cell>-</cell></row><row><cell>CoNLL-2003-BiLSTM-CRF + GloVe + ELMo + valid set</cell><cell>93.09</cell><cell>-</cell><cell>-</cell></row><row><cell>CoNLL-2003-BiLSTM-CNN-CRF + GloVe</cell><cell>91.07</cell><cell>-</cell><cell>-</cell></row><row><cell>CoNLL-2003-BiLSTM-CNN-CRF + GloVe + ELMo</cell><cell>92.57</cell><cell>-</cell><cell>-</cell></row><row><cell>CoNLL-2003-BiLSTM-CNN-CRF + GloVe + ELMo + valid set</cell><cell>93.04</cell><cell>-</cell><cell>-</cell></row><row><cell>CoNLL-2003-BiLSTM-CNN + GloVe</cell><cell>89.47</cell><cell>-</cell><cell>-</cell></row><row><cell>CoNLL-2003-BiLSTM-CNN + GloVe + ELMo</cell><cell>92.00</cell><cell>-</cell><cell>-</cell></row><row><cell>CoNLL-2003-BiLSTM-CNN + GloVe + ELMo + valid set</cell><cell>92.16</cell><cell>-</cell><cell>-</cell></row><row><cell>CoNLL-2003-BiGRU-CRF + GloVe</cell><cell>90.72</cell><cell>-</cell><cell>-</cell></row><row><cell>CoNLL-2003-BiGRU-CRF + GloVe + ELMo</cell><cell>92.44</cell><cell>-</cell><cell>-</cell></row><row><cell>CoNLL-2003-BiGRU-CRF + GloVe + ELMo + valid set</cell><cell>92.71</cell><cell>-</cell><cell>-</cell></row><row><cell>CoNLL-2003-BERT-base</cell><cell>90.90</cell><cell>-</cell><cell>-</cell></row><row><cell>CoNLL-2003-BERT-base + CRF</cell><cell>91.20</cell><cell>-</cell><cell>-</cell></row><row><cell>CoNLL-2012-BiLSTM-CRF + fastText</cell><cell>-</cell><cell>87.01</cell><cell>-</cell></row><row><cell>CoNLL-2012-BiLSTM-CRF + fastText + ELMo</cell><cell>-</cell><cell>89.01</cell><cell>-</cell></row><row><cell>FTB-BiLSTM-CRF + fastText</cell><cell>-</cell><cell>-</cell><cell>87.45</cell></row><row><cell>FTB-BiLSTM-CRF + fastText + ELMo</cell><cell>-</cell><cell>-</cell><cell>89.23</cell></row><row><cell cols="2">neural achitectures</cell><cell></cell><cell></cell></row><row><cell>Lample, et al. (2016)</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,136.70,310.48,341.96,76.93"><head>Table 3 .</head><label>3</label><figDesc>NERC-COARSE-LIT results on the HIPE test data. EN NE-COARSE-LIT-micro-fuzzy ALL 0.568 0.746 0.645 335 255 114 EN NE-COARSE-LIT-micro-strict ALL 0.461 0.606 0.524 272 318 177 FR NE-COARSE-LIT-micro-fuzzy ALL 0.755 0.842 0.796 1347 438 253 FR NE-COARSE-LIT-micro-strict ALL 0.605 0.675 0.638 1080 705 520</figDesc><table coords="8,136.70,330.20,341.96,8.55"><row><cell>Lang Evaluation</cell><cell>Label P</cell><cell>R</cell><cell>F1 TP FP FN</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,241.70,430.74,131.96,8.97"><head>Table 4 .</head><label>4</label><figDesc>EL-ONLY-LIT results.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,634.28,139.04,8.97"><p>https://github.com/kermitt2/delft</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,144.73,645.24,173.39,8.97"><p>https://github.com/kermitt2/entity-fishing</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,144.73,656.20,111.66,8.97"><p>https://www.huma-num.fr/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="3,144.73,656.20,162.37,8.97"><p>https://github.com/kermitt2/grobid-ner</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="4,144.73,634.28,260.18,8.97"><p>https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki.fr.vec</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="4,144.73,645.24,251.12,8.97"><p>https://s3-us-west-2.amazonaws.com/allennlp/models/ELMo/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="4,144.73,656.20,206.65,8.97"><p>https://traces1.inria.fr/oscar/files/models/cc/fr.zip</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7" coords="6,144.73,634.28,333.05,8.97"><p>https://github.com/kermitt2/delft/blob/master/delft/sequenceLabelling/config.py</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8" coords="6,144.73,645.24,249.98,8.97"><p>https://github.com/kermitt2/delft/blob/master/nerTagger.py</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_9" coords="6,144.73,656.20,208.47,8.97"><p>https://nerd.readthedocs.io/en/latest/restAPI.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_10" coords="8,144.73,645.24,296.23,8.97;8,144.73,656.20,145.58,8.97"><p>https://github.com/impresso/CLEF-HIPE-2020/blob/master/evaluationresults/ranking_summary_final.md</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements We thank the anonymous reviewers for their insightful comments.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>{ "text": "The text to be processed.", "shortText": "term1 term2 ...", "termVector": [ { "term": "term1", "score": 0.3 }, { "term": "term2", "score": 0.1 } ], "language": { "lang": "en" }, "entities": [], "mentions": ["ner","wikipedia"], "nbest": 0, "sentence": false, "customisation": "generic", "processSentence": [], "structure": "grobid" } Table <ref type="table" coords="7,164.56,421.51,4.13,7.93">2</ref>. NERC-COARSE-LIT and EL-ONLY results compared to the best system and the baseline. Our results are highlighted. NEL-LIT-micro-fuzzy-@1 0.593 0.593 0.593 EN aidalight-baseline NEL-LIT-micro-fuzzy-@1 0.506 0.506 0.506 FR L3i</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lang Team</head><p>NEL-LIT-micro-fuzzy-@1 0.64 0.638 0.639 FR Inria-DeLFT NEL-LIT-micro-fuzzy-@1 0.585 0.65 0.616 FR aidalight-baseline NEL-LIT-micro-fuzzy-@1 0.502 0.495 0.498</p><p>DeLFT and entity-fishing achieve good F1-scores, their performance is quite sensitive to noise data.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="9,142.95,221.39,337.64,8.97;9,151.52,232.35,329.07,8.97;9,151.52,243.30,88.79,8.97" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,364.60,221.39,115.99,8.97;9,151.52,232.35,81.77,8.97">Enriching word vectors with subword information</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,240.53,232.35,240.06,8.97;9,151.52,243.30,13.87,8.97">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.95,254.01,337.64,8.97;9,151.52,264.97,325.43,8.97" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,252.65,254.01,223.84,8.97">Named entity recognition with bidirectional lstm-cnns</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Nichols</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,151.52,264.97,250.51,8.97">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="357" to="370" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.95,286.38,337.64,8.97;9,151.52,297.34,329.07,8.97;9,151.52,308.30,25.59,8.97" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="9,346.99,286.38,133.60,8.97;9,151.52,297.34,189.90,8.97">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,142.95,319.00,337.63,8.97;9,151.52,329.96,329.07,8.97;9,151.52,340.92,329.07,8.97;9,151.52,351.88,329.07,8.97;9,151.52,362.84,329.07,8.97;9,151.52,373.80,329.07,8.97;9,151.52,384.76,178.04,8.97" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,402.56,319.00,78.03,8.97;9,151.52,329.96,310.64,8.97">Overview of CLEF HIPE 2020: Named Entity Recognition and Linking on Historical Newspapers</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Flückiger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clematide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,363.80,351.88,116.79,8.97;9,151.52,362.84,329.07,8.97;9,151.52,373.80,183.42,8.97">Proceedings of the 11th International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="9,367.41,373.80,113.18,8.97;9,151.52,384.76,56.66,8.97">Lecture Notes in Computer Science (LNCS</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Joho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Lioma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<meeting>the 11th International Conference of the CLEF Association (CLEF</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="volume">12260</biblScope>
		</imprint>
	</monogr>
	<note>Experimental IR Meets Multilinguality, Multimodality, and Interaction</note>
</biblStruct>

<biblStruct coords="9,142.95,395.46,337.64,8.97;9,151.52,406.42,329.07,8.97;9,151.52,417.38,159.28,8.97" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,257.62,395.46,222.97,8.97;9,151.52,406.42,67.26,8.97">entity-fishing: a DARIAH entity recognition and disambiguation service</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Foppiano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Romary</surname></persName>
		</author>
		<ptr target="https://hal.inria.fr/hal-01812100" />
	</analytic>
	<monogr>
		<title level="m" coord="9,240.59,406.42,153.98,8.97">Digital Scholarship in the Humanities</title>
		<meeting><address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-09">Sep 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.95,428.09,337.64,8.97;9,151.52,439.05,329.07,8.97;9,151.52,450.00,89.43,8.97" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,403.58,428.09,77.01,8.97;9,151.52,439.05,262.60,8.97">Deep learning with word embeddings improves biomedical named entity recognition</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Habibi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">L</forename><surname>Wiegandt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Leser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,422.05,439.05,58.54,8.97">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="37" to="48" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.95,460.71,337.63,8.97;9,151.52,471.67,329.08,8.97" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="9,453.69,460.71,26.89,8.97;9,151.52,471.67,165.51,8.97">Neural architectures for named entity recognition</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ballesteros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Subramanian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kawakami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.01360</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,142.95,482.37,337.64,8.97;9,151.52,493.33,329.07,8.97;9,151.52,504.29,124.89,8.97" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,304.84,482.37,171.50,8.97">Joint entity recognition and disambiguation</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,164.91,493.33,315.68,8.97;9,151.52,504.29,40.95,8.97">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="879" to="888" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,515.00,337.98,8.97;9,151.52,525.96,159.01,8.97" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.01354</idno>
		<title level="m" coord="9,229.13,515.00,247.56,8.97">End-to-end sequence labeling via bi-directional lstm-cnns-crf</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,142.61,536.66,337.97,8.97;9,151.52,547.62,329.07,8.97" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Puhrsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.09405</idno>
		<title level="m" coord="9,413.03,536.66,67.56,8.97;9,151.52,547.62,163.70,8.97">Advances in pretraining distributed word representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,142.61,558.33,337.98,8.97;9,151.52,569.29,205.15,8.97" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,367.43,558.33,113.17,8.97;9,151.52,569.29,115.58,8.97">Aida-light: High-throughput named-entity disambiguation</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">B</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Theobald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,274.42,569.29,29.17,8.97">LDOW</title>
		<imprint>
			<biblScope unit="volume">1184</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,579.99,337.97,8.97;9,151.52,590.95,255.57,8.97" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1404.5367</idno>
		<title level="m" coord="9,318.52,579.99,162.07,8.97;9,151.52,590.95,94.28,8.97">Lexicon infused phrase embeddings for named entity resolution</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,142.61,601.66,337.98,8.97;9,151.52,612.62,329.07,8.97;9,151.52,623.57,215.23,8.97" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,329.82,601.66,150.78,8.97;9,151.52,612.62,35.29,8.97">Glove: Global vectors for word representation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,207.70,612.62,272.89,8.97;9,151.52,623.57,120.75,8.97">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,634.28,337.98,8.97;9,151.52,645.24,329.07,8.97;9,151.52,656.20,25.59,8.97" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="9,377.68,634.28,102.91,8.97;9,151.52,645.24,182.83,8.97">Semi-supervised sequence tagging with bidirectional language models</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Ammar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bhagavatula</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Power</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.00108</idno>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,142.61,119.07,337.98,8.97;10,151.52,130.03,329.07,8.97;10,151.52,140.99,97.78,8.97" xml:id="b14">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Iyyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gardner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.05365</idno>
		<title level="m" coord="10,227.52,130.03,179.35,8.97">Deep contextualized word representations</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="10,142.61,151.95,337.97,8.97;10,151.52,162.91,329.07,8.97;10,151.52,173.87,249.49,8.97" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,408.05,151.95,72.54,8.97;10,151.52,162.91,263.54,8.97">Conll-2012 shared task: Modeling multilingual unrestricted coreference in ontonotes</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Pradhan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moschitti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Uryupina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,437.26,162.91,43.32,8.97;10,151.52,173.87,179.16,8.97">Joint Conference on EMNLP and CoNLL-Shared Task</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,184.83,337.98,8.97;10,151.52,195.79,329.07,8.97;10,151.52,206.74,220.88,8.97" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,240.58,184.83,240.01,8.97;10,151.52,195.79,22.37,8.97">Design challenges and misconceptions in named entity recognition</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ratinov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,196.40,195.79,284.19,8.97;10,151.52,206.74,136.35,8.97">Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL-2009)</title>
		<meeting>the Thirteenth Conference on Computational Natural Language Learning (CoNLL-2009)</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="147" to="155" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,217.70,337.98,8.97;10,151.52,228.66,329.07,8.97;10,151.52,239.62,329.07,8.97;10,151.52,250.58,329.08,8.97;10,151.52,261.54,131.63,8.97" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="10,293.68,217.70,186.91,8.97;10,151.52,228.66,108.57,8.97">Annotation référentielle du Corpus Arboré de Paris 7 en entités nommées</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Sagot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Richard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Stern</surname></persName>
		</author>
		<ptr target="https://hal.inria.fr/hal-00703108" />
	</analytic>
	<monogr>
		<title level="m" coord="10,151.52,239.62,329.07,8.97;10,151.52,250.58,148.06,8.97">Traitement Automatique des Langues Naturelles (TALN). Actes de la conférence conjointe JEP-TALN-RECITAL 2012</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Antoniadis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Blanchon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Sérasset</surname></persName>
		</editor>
		<meeting><address><addrLine>Grenoble, France</addrLine></address></meeting>
		<imprint>
			<publisher>TALN</publisher>
			<date type="published" when="2012-06">Jun 2012</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,272.50,337.98,8.97;10,151.52,283.46,292.93,8.97" xml:id="b18">
	<monogr>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">F</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>De Meulder</surname></persName>
		</author>
		<idno>arXiv preprint cs/0306050</idno>
		<title level="m" coord="10,265.16,272.50,215.44,8.97;10,151.52,283.46,151.46,8.97">Introduction to the conll-2003 shared task: Languageindependent named entity recognition</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,294.42,337.98,8.97;10,151.52,305.38,252.01,8.97" xml:id="b19">
	<monogr>
		<title level="m" type="main" coord="10,285.12,294.42,195.47,8.97;10,151.52,305.38,85.41,8.97">Boosting named entity recognition with neural character embeddings</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">N D</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Guimaraes</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1505.05008</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
