<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,143.81,115.90,327.74,12.68;1,173.69,133.83,261.75,12.68">Robust Named Entity Recognition and Linking on Historical Multilingual Documents</title>
				<funder ref="#_UxKyys4 #_CDv8h8b">
					<orgName type="full">European Union</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,224.85,171.50,71.18,8.80"><forename type="first">Emanuela</forename><surname>Boros</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of La Rochelle</orgName>
								<address>
									<addrLine>L3i</addrLine>
									<postCode>F-17000</postCode>
									<settlement>La Rochelle</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,212.00,183.45,96.89,8.80"><forename type="first">Elvys</forename><forename type="middle">Linhares</forename><surname>Pontes</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of La Rochelle</orgName>
								<address>
									<addrLine>L3i</addrLine>
									<postCode>F-17000</postCode>
									<settlement>La Rochelle</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,201.45,195.41,118.00,8.80"><forename type="first">Luis</forename><forename type="middle">Adrián</forename><surname>Cabrera-Diego</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of La Rochelle</orgName>
								<address>
									<addrLine>L3i</addrLine>
									<postCode>F-17000</postCode>
									<settlement>La Rochelle</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,228.63,207.36,63.63,8.80"><forename type="first">Ahmed</forename><surname>Hamdi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of La Rochelle</orgName>
								<address>
									<addrLine>L3i</addrLine>
									<postCode>F-17000</postCode>
									<settlement>La Rochelle</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,222.96,219.32,68.63,8.80"><forename type="first">Jose</forename><forename type="middle">G</forename><surname>Moreno</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of La Rochelle</orgName>
								<address>
									<addrLine>L3i</addrLine>
									<postCode>F-17000</postCode>
									<settlement>La Rochelle</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">UMR 5505</orgName>
								<orgName type="institution" key="instit1">University of Toulouse</orgName>
								<orgName type="institution" key="instit2">IRIT</orgName>
								<orgName type="institution" key="instit3">CNRS</orgName>
								<address>
									<postCode>F-31000</postCode>
									<settlement>Toulouse</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,263.76,231.27,61.22,8.80"><forename type="first">Nicolas</forename><surname>Sidère</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of La Rochelle</orgName>
								<address>
									<addrLine>L3i</addrLine>
									<postCode>F-17000</postCode>
									<settlement>La Rochelle</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,227.59,243.23,68.48,8.80"><forename type="first">Antoine</forename><surname>Doucet</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of La Rochelle</orgName>
								<address>
									<addrLine>L3i</addrLine>
									<postCode>F-17000</postCode>
									<settlement>La Rochelle</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,143.81,115.90,327.74,12.68;1,173.69,133.83,261.75,12.68">Robust Named Entity Recognition and Linking on Historical Multilingual Documents</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A745BC3E079EAE310EDC9969F749A209</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Information Extraction</term>
					<term>Named Entity Recognition</term>
					<term>Entity Linking</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper summarizes the participation of the L3i laboratory of the University of La Rochelle in the Identifying Historical People, Places, and other Entities (HIPE) evaluation campaign of CLEF 2020. Our participation relies on two neural models, one for named entity recognition and classification (NERC) and another one for entity linking (EL). We carefully pre-processed inputs to mitigate its flaws, notably in terms of segmentation. Our submitted runs cover all languages (English, French, and German) and sub-tasks proposed in the lab: NERC, endto-end EL, and EL-only. Our submissions obtained top performance in 50 out of the 52 scoreboards proposed by the lab organizers. In further detail, out of 70 runs submitted by 13 participants, our approaches obtained the best score for all metrics in all three languages both for NERC and for end-to-end EL. It also obtained the best score for all metrics in French and German for EL-only.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Identifying historical people, places and other entities is a key task in the automatic understanding of historical newspapers. However, the use of electronic formats for storing text content is relatively new in comparison to the origins of newspapers. For instance, in Europe, the first newspapers appeared at the beginning of the 17 th century <ref type="bibr" coords="2,273.44,142.84,14.61,8.80" target="#b24">[25]</ref>. Electronic text files started to be widely used since the adoption of operating systems such as MS-DOS in the 1980s <ref type="bibr" coords="2,467.31,154.80,9.96,8.80" target="#b1">[2]</ref>. Thus, in the absence of electronic versions of historical newspapers, a common strategy is to recognize the text from digital images of newspapers using optical character recognition (OCR) techniques. In this context, the HIPE 2020 lab at CLEF presented an evaluation campaign with the goal of assessing the recent advances in two major NLP tasks, named entity recognition and classification (NERC) and entity linking (EL), in the context of historical newspapers <ref type="bibr" coords="2,467.31,226.53,9.96,8.80" target="#b4">[5]</ref>. This paper presents the participation of the Laboratoire Informatique, Image et Interaction (L3i laboratory) at the University of La Rochelle at CLEF HIPE 2020. We developed two new models for NERC and EL. Despite the fact that both models are based on neural networks, there are strong differences between them. Our NERC model is mainly based on the transformer architecture <ref type="bibr" coords="2,465.10,286.31,15.49,8.80" target="#b23">[24]</ref> while our EL model is based on a BiLSTM architecture <ref type="bibr" coords="2,384.06,298.26,14.61,8.80" target="#b9">[10]</ref>. Our main contributions are three-fold: <ref type="bibr" coords="2,235.00,310.22,12.73,8.80" target="#b0">(1)</ref> we propose a pre-processing strategy to mitigate the characteristics of input documents, <ref type="bibr" coords="2,288.64,322.17,12.73,8.80" target="#b1">(2)</ref> we extend a transformer-based model for NERC, and <ref type="bibr" coords="2,188.14,334.13,12.73,8.80" target="#b2">(3)</ref> we adapt an EL model to a multilingual context. Official results of our participation show the effectiveness of our models over the CLEF HIPE 2020 benchmark.</p><p>The remaining of the paper is organized as follows: Section 2 presents the task and the used corpus. Section 3 presents the global architecture of our participation, Section 4.1 presents the pre-processing strategy, while Sections 4 and 5 present individually our NERC and EL systems respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">HIPE Corpus and HIPE Evaluation</head><p>The HIPE corpus <ref type="bibr" coords="2,211.62,459.21,10.51,8.80" target="#b3">[4]</ref> is a collection of digitized documents covering three different languages: English, French, and German. The documents come from archives of several Swiss, Luxembourgish, and American newspapers. The dataset was annotated according to the HIPE annotation guidelines <ref type="bibr" coords="2,382.28,495.07,10.51,8.80" target="#b5">[6]</ref> which derived from the Quaero<ref type="foot" coords="2,183.49,505.47,3.97,6.16" target="#foot_0">3</ref> annotation guide.</p><p>The corpus uses the IOB format with hierarchical information and, provides training, development, and test datasets for each language, except for English. In the case of the latter, the organizers provided only partitions for development and test. In Table <ref type="table" coords="2,218.42,554.85,3.87,8.80" target="#tab_0">1</ref>, we present the statistics regarding the number of named entities found in each dataset. See <ref type="bibr" coords="2,282.39,566.81,10.51,8.80" target="#b2">[3]</ref> for a more detailed description of the HIPE dataset.</p><p>Regarding the HIPE evaluation, it consists in assessing both tasks, NERC and EL, in terms of Precision (P), Recall (R), and F-measure (F1) at macro and micro levels <ref type="bibr" coords="2,210.28,614.63,15.49,8.80" target="#b13">[14,</ref><ref type="bibr" coords="2,229.71,614.63,7.01,8.80" target="#b2">3]</ref>. Two evaluation scenarios are considered: strict (exact boundary matching) and relaxed (fuzzy boundary matching).  In Figure <ref type="figure" coords="3,181.60,262.26,3.87,8.80" target="#fig_0">1</ref>, we present the global architecture of our end-to-end NERC-EL model composed of three elements. The first one is a pre-processing module, which reformats the input provided by the organizers. The second element is the NERC module, where we predict the named entities for each language, English, French, and German. The third element is the EL module, where we disambiguate the named entities, and we link them to the Wikidata. In the following sections, we will describe in-depth each of the modules showed in Figure <ref type="figure" coords="3,212.17,514.73,3.87,8.80" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HIPE format</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pre-processing</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sentence</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Named Entity Recognition and Classification (NERC)</head><p>In CLEF HIPE 2020, the NERC task consists in the recognition and classification of entities, such as people and locations, within historical multilingual newspapers. According to the organizers <ref type="bibr" coords="3,320.33,598.60,9.96,8.80" target="#b2">[3]</ref>, it is composed of two sub-tasks with different levels of difficulty:</p><p>-Sub-task 1.1 -NERC coarse-grained: the identification and categorization of entity mentions according to high-level entity types, Person, Location, Organization, Product, and Time.</p><p>-Sub-task 1.2 -NERC fine-grained: the recognition and classification of entity mentions at different levels, finer-grained entity types and nested entities, up to one level of depth. It also consists in detecting the components belonging to an entity mention, such as its function, title, honorifics, and name.</p><p>Due to the complexity and characteristics of both coarse-grained and finegrained NERC sub-tasks, we propose the use of a hierarchical, multitask learning approach consisting in a fine-tuned encoder based on Bidirectional Encoder Representations from Transformers (BERT) <ref type="bibr" coords="4,313.70,212.14,9.96,8.80" target="#b0">[1]</ref>. Our approach includes the use of a stack of Transformer <ref type="bibr" coords="4,228.60,224.09,15.49,8.80" target="#b23">[24]</ref> blocks on top of the BERT model for the French and German languages. The multitask prediction layer consists of six separate conditional random field (CRF) layers. The architecture of the model is presented in Figure <ref type="figure" coords="4,177.82,259.96,3.87,8.80" target="#fig_2">2</ref>.  We decided to use BERT not only because it is easy to fine-tune, but it has also proved to be one of the most performing technologies in multiple NLP tasks <ref type="bibr" coords="4,134.77,536.51,10.51,8.80" target="#b0">[1,</ref><ref type="bibr" coords="4,148.94,536.51,12.73,8.80" target="#b11">12,</ref><ref type="bibr" coords="4,165.34,536.51,11.62,8.80" target="#b19">20]</ref>. However, while BERT had a major impact in the NLP community, its ability to handle noisy inputs is still an open question <ref type="bibr" coords="4,398.37,548.46,15.49,8.80" target="#b22">[23]</ref> or at least requires the addition of complementary methods <ref type="bibr" coords="4,347.26,560.42,15.49,8.80" target="#b15">[16,</ref><ref type="bibr" coords="4,367.01,560.42,11.62,8.80" target="#b18">19]</ref>. More specifically, the built-in tokenizer used by BERT first performs simple white-space tokenization, then applies a Byte Pair Encoding (BPE) based WordPiece tokenization <ref type="bibr" coords="4,451.79,584.33,14.61,8.80" target="#b26">[27]</ref>. A word can be split into character n-grams (e.g. "compatibility" → "com", "##pa", "##ti", "##bility"), where "##" is a special symbol for representing the presence of a sub-word that was recognized. Between the types of OCR errors that can be encountered, the character insertion modification has the minimum influence <ref type="bibr" coords="4,167.96,644.10,14.61,8.80" target="#b22">[23]</ref>, because the tokenization at the sub-word level of BERT would not change much in some cases, such as "practically" → "practicaally", but the sub-stitution and deletion errors can hurt the performance of the tokenizer the most due to the generation of uncommon samples, as such as "professionalism" → "pr9fessi9nalism". Thus, these new noisy tokens could influence the performance of BERT-based models <ref type="foot" coords="5,234.89,153.24,3.97,6.16" target="#foot_1">4</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>HIPE format</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pre-processing</head><p>The added layers consist in a stack of Transformer blocks (Transformer encoders). As proposed in <ref type="bibr" coords="5,244.20,178.71,14.61,8.80" target="#b23">[24]</ref>, this model is a deep learning architecture based on multi-head attention mechanisms with sinusoidal position embeddings<ref type="foot" coords="5,453.23,189.11,3.97,6.16" target="#foot_2">5</ref> . It is composed of a stack of identical layers. Each layer has two sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-wise fully connected feed-forward network. A residual connection is around each of the two sub-layers, followed by layer normalization. All sub-layers in the model, as well as the embedding layers, produce outputs of dimension 512.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data Pre-processing</head><p>The HIPE dataset has three different levels of segmentation: article-level, linelevel, and newspaper-level. Figure <ref type="figure" coords="5,284.95,306.42,4.98,8.80" target="#fig_3">3</ref> shows an example of the segmentation proposed in the HIPE dataset. Since BERT is able to consume only a limited context of tokens (512) and a line-level context would have been too short to grasp, we segment the articles at sentence level. We reconstructed the original text, including hyphenated words, using the miscellaneous annotated column that indicates if a word is split into two or more text lines. Then, the reconstructed text was passed through Freeling 4.1 <ref type="bibr" coords="5,150.81,505.96,15.49,8.80" target="#b17">[18]</ref> which determined the boundaries of each sentence. <ref type="foot" coords="5,390.85,504.41,3.97,6.16" target="#foot_3">6</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Parameters</head><p>For the German NERC, we chose as a pre-trained model the bert-base-germaneuropeana. This BERT model was trained using the open-source corpus Euro-peana newspapers 7 <ref type="bibr" coords="6,220.58,118.93,14.61,8.80" target="#b16">[17]</ref>. It has been used in other NERC systems for contemporary and historical German texts <ref type="bibr" coords="6,283.79,130.89,15.49,8.80" target="#b21">[22,</ref><ref type="bibr" coords="6,303.02,130.89,11.62,8.80" target="#b20">21]</ref>. Moreover, it has shown an improvement with respect to other NERC systems.</p><p>For the French NERC, we relied on a pre-trained CamemBERT <ref type="bibr" coords="6,432.60,154.80,15.49,8.80" target="#b14">[15]</ref> model, specifically on the large version, camembert-large. Unlike BERT, this French version makes use of a whole-word masking and SentencePiece tokenization <ref type="bibr" coords="6,462.33,178.71,14.61,8.80" target="#b10">[11]</ref>. Additionally, for camembert-large, we found that fine-tuning was sometimes unstable on small datasets, so we ran several random restarts and selected the best model on the development set.</p><p>For the English NERC, since no training data was provided, we tackled the task with two approaches. The first one was to train the NERC using the English CoNLL 2003 dataset and the bert-large-cased model. The second approach was to use the German and French training data and the pre-trained multilingual BERT model, bert-base-multilingual-cased.</p><p>We denote the number of layers (i.e., Transformer blocks) as L, the hidden size as H, and the number of self-attention heads as A. bert-base has L=12, H=768, A=12, bert-large and camembert-large, L=24, H=1024, A=16. In all the cases, the top Transformer blocks have L=1 for 1×Transf and L=2 for 2×Transf, H=128, A=12, chosen empirically.</p><p>The BERT-based encoders are fine-tuned on the task during training. For training, we followed the selection of parameters presented in <ref type="bibr" coords="6,419.09,358.04,9.96,8.80" target="#b0">[1]</ref>. We found that a 2 × 10 -5 learning rate and a mini-batch of dimension 4 for German and English, and 2 for French, provide the most stable and consistent convergence across all experiments as evaluated on the development set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Experiments</head><p>The experiments consider two configurations of our previously described model. The first one consists in using only the BERT encoder along with the CRF layers. The second configuration adds the Transformer blocks to the BERT encoder and the CRF layers. In Table <ref type="table" coords="6,246.90,479.58,3.87,8.80" target="#tab_2">2</ref>, we present these experiments per language.</p><p>-RUN1: for German, French, and English, the models consist in only the finetuning BERT and the CRF layers, with the difference that, for English, we use the CoNLL dataset, and the fine-tuned BERT encoder is the English bert-large-cased -RUN2: for German and French, the models consist in only the fine-tuning BERT, two stacked Transformer blocks, and the CRF layers, while for English, the model is bert-large-cased -RUN3: for English, the model is the one used in RUN1, with the difference that the training data consists of the French and German training data, and the fine-tuned BERT encoder is bert-base-multilingual-cased  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results</head><p>From the results in Table <ref type="table" coords="8,244.11,137.65,3.87,8.80" target="#tab_2">2</ref>, we can see the evidence that the BERT-based models with n×Transf achieve, for both German and French languages, higher fuzzy and strict performance values than the stand-alone BERT model. For a more qualitative analysis, we examine the number of unrecognized words by the pre-trained BERT-based models that were added to the specific tokenizers (WordPiece for BERT and SentencePiece for CamemBERT). Following this observation, we notice that there is a tendency of performance increase of around 1 percentage F1 points for the n×Transf models (RUN2 for German and French). In Table <ref type="table" coords="8,235.78,233.30,3.87,8.80" target="#tab_3">3</ref>, the highest values for all the coarse and fine metrics are presented.</p><p>In the case of English, when comparing RUN1 and RUN2, where the CoNLL 2003 dataset was used for training, with RUN3, where only HIPE German and French datasets were used, we notice that the F1 values are usually degraded by the use of modern datasets in the training process.</p><p>In summary, the methods that performed the best for the NERC task were the BERT-based models with n stacked Transformers for German and French. For English, the transfer learning from these two languages was clearly better than the models trained on modern English data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Entity Linking (EL)</head><p>Regarding EL, in CLEF HIPE 2020, the task consists in the disambiguation of named entities using two settings:</p><p>-End-to-end EL: We do not have prior knowledge of the named entities. Thus, we rely on the information obtained from the NERC system. -EL-only: We have access to the ground-truth regarding named entities, i.e. types and boundaries.</p><p>In both settings, it is necessary to take into account literal and metonymic senses. Furthermore, all the disambiguated named entities have to be linked to the Wikidata knowledge base (KB).</p><p>Our EL system is the composition and improvement of two EL approaches (Figure <ref type="figure" coords="8,171.19,526.75,3.87,8.80">4</ref>). First, we make use of the methodology proposed by <ref type="bibr" coords="8,426.30,526.75,10.51,8.80" target="#b6">[7]</ref> to create entity embeddings. Second, we utilize the EL architecture proposed by <ref type="bibr" coords="8,452.31,538.71,15.49,8.80" target="#b9">[10]</ref> to disambiguate the candidates. We have modified both EL approaches to support the multilingual aspect of the CLEF HIPE 2020 task.</p><p>More precisely, our approach consists of the following four steps which will be elaborated in the subsequent sections: Fig. <ref type="figure" coords="9,174.60,271.37,3.87,8.80">4</ref>: The proposed model <ref type="bibr" coords="9,278.15,271.37,15.49,8.80" target="#b9">[10]</ref> for EL and the post-processing steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Building Resources</head><p>We build a KB for English, French, and German, in order to have a richer KB following these steps:</p><p>-Retrieve the last language version of the Wikipedia dump.</p><p>-Extract titles and ids of Wikipedia pages.</p><p>-Extract list of disambiguation pages and redirection pages.</p><p>-Calculate the probability entity-map p(e|m) that analyzes how an entity e is related to a mention m based on the number of times that mention refers to that entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Entity Embeddings</head><p>We also build a dataset to train entity embeddings for each language, in which case, we use the methodology proposed by <ref type="bibr" coords="9,318.63,476.29,9.96,8.80" target="#b6">[7]</ref>. First, we generate two conditional probability distributions per language: the positive distribution, which is a probability approximation based on word-entity co-occurrence counts (i.e. which words appear in the context of an entity) and the negative one, which was calculated by randomly sampling context windows that were unrelated to a specific entity. Both probability distributions were used for word embeddings alignment with respect to an entity embedding. The positive distribution is expected to approach the embeddings of the co-occurring words with the embedding vector of the entity. While the negative probability distribution is used to distance the embeddings of words that are not related to an entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Entity Disambiguation</head><p>For the entity disambiguation, our model is based on Kolitsas et al.'s work <ref type="bibr" coords="9,462.33,632.15,14.61,8.80" target="#b9">[10]</ref>, an end-to-end EL model that jointly performs entity linking and entity disambiguation. Besides the simplicity of the model brought by the joint-learning, the model also takes advantage of the fact that it does not require complex engineered features. First, for recognizing all entity mentions in a document, Kolitsas et al. proposed an empirical probabilistic entity-map 8 p(e|m) to analyze each span m and select top entities e that might be referred by this mention in p(e|m).</p><p>The end-to-end EL model starts by encoding every token in the text input by concatenating word and character embeddings that are fed into a Bidirectional Long Short Term Memory (BiLSTM) network. This representation is used to project mentions of this document into a shared dimensional space with the same size as the entity embeddings. These embeddings are fixed continuous entity representations generated separately, namely in the same manner as presented in <ref type="bibr" coords="10,146.38,251.69,9.96,8.80" target="#b6">[7]</ref>, and aforementioned in Section 5.2. For analyzing long context dependencies of mentions, the authors used the attention model proposed by <ref type="bibr" coords="10,262.31,634.44,10.51,8.80" target="#b6">[7]</ref> that produces one context embedding per men-tion based on informative context words that are related to at least one of the candidate entities. Next, the local score for each mention is determined by the combination of the log p(e|m), the similarity between the analyzed mention and each candidate entity embeddings, and the long-range context attention for the target mention. Finally, a top layer in the neural network promotes the coherence among disambiguated entities inside the same document. Additionally, we provide the five best candidate entities for a mention based on the probability entity-map p(e|m).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Candidates Filtering</head><p>To improve the accuracy of the candidates provided by the EL system, we created a filtering tool based on heuristics and the DBpedia hierarchical structure <ref type="bibr" coords="11,460.52,260.00,14.61,8.80" target="#b12">[13]</ref>.</p><p>Specifically, we used the DBpedia structure to manually specify subsets that represented each named entity type. For instance, the entity type location was associated with categories such as "dbo:Location" and "dbo:Settlement".</p><p>These categories were used to determine whether a candidate provided by the EL system had to be positioned at the bottom of the rankings. In other words, candidates that according to DBpedia did not belong to the named entity type were positioned at the bottom of the ranking. <ref type="foot" coords="11,337.60,342.13,3.97,6.16" target="#foot_4">9</ref> For those candidates matching the named entity type<ref type="foot" coords="11,233.32,354.09,7.94,6.16" target="#foot_5">10</ref> , we extracted their name in the language of analysis. This name was compared with the entity entry using Fuzzy Wuzzy Weighted Ratio <ref type="foot" coords="11,158.70,378.00,7.94,6.16" target="#foot_6">11</ref> . The most similar candidate to the entity entry was considered to be the most suitable candidate and was positioned at the top.</p><p>In the case of person-type entities, we requested to DBpedia their date of birth and extract the year if it was possible. <ref type="foot" coords="11,324.02,413.86,7.94,6.16" target="#foot_7">12</ref> Then, we compared the extracted year of birth with the newspaper publication year, which was provided by the organizers, plus ten years more. If the person entity was born ten years after the publication of the newspaper, we removed completely the candidate.</p><p>Furthermore, we created a heuristic that consisted in adding NIL as the last possible candidate. This was done for each named entity unless the EL system proposed candidates with a type different from the named entity one. In this last case, a NIL was inserted between the different types of candidates. For example, if the location "Paris, France" had four candidates entries of type LOC, PERS, LOC, the filter would sort them as LOC, LOC, NIL, PERS. When the EL system proposed only candidates that were different from the named entity type, the filter would position on first place a NIL. These heuristics were based on the idea that if the EL system could not provide a candidate of the same type to the named entity, we might be dealing with an entity without an entry in Wikidata.</p><p>For RUN3 in the EL-only task, which will be described in Section 5.5, we proposed as well a filter based on DBpedia along with Wikidata. The reason is that the former indexes only a subset of the latter. Thus, to improve the filter, we decided to use Wikidata as a backup knowledge base.</p><p>To access DBpedia <ref type="foot" coords="12,232.52,141.47,7.94,6.16" target="#foot_8">13</ref> and Wikidata<ref type="foot" coords="12,304.57,141.47,7.94,6.16" target="#foot_9">14</ref> , we utilized their respective SPARQL Endpoint query service. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Experiments</head><p>Both entity embeddings and the end-to-end EL method used the pre-trained multilingual MUSE <ref type="foot" coords="12,203.03,459.45,7.94,6.16" target="#foot_10">15</ref> word embeddings of size 300 for all languages in the dataset. We chose the size of 50 for the character embeddings. The German and French models were trained on the HIPE split (Table <ref type="table" coords="12,337.97,484.92,3.87,8.80" target="#tab_0">1</ref>. As the HIPE dataset does not contain training data for English, we trained our English model on the AIDA dataset <ref type="bibr" coords="12,169.68,508.83,9.96,8.80" target="#b8">[9]</ref>. In order to overcome or reduce OCR problems, we analyzed several mention variations in order to improve the matching with candidates within the probability entity-map. More precisely, we analyze the following variations: concatenation, lowercase, no punctuation, and the Levenshtein distance between a mention and all candidate mentions within the probability table. In the metonymic sense, the approach used was to annotate the corpus consisted in copying the candidates used for the literal sense.</p><p>We implemented three configurations of our EL approach for the EL-only task:</p><p>-RUN1: for German, French, and English, the output is composed of the candidate entities proposed by <ref type="bibr" coords="13,287.97,130.89,14.61,8.80" target="#b9">[10]</ref>. -RUN2: for German, French, and English, the output is composed of the five most frequent candidate entities related to a mention. -RUN3: for German, French, and English, the output is composed of the candidate entities proposed by <ref type="bibr" coords="13,293.82,177.26,15.49,8.80" target="#b9">[10]</ref> and the ten most frequent candidate entities related to a mention. For this run, the filter used not only information from DBpedia but also from Wikidata as indicated in Section 5.4.</p><p>We also made three configurations of our end-to-end NERC-EL architecture to recognize and disambiguate entities:</p><p>-RUN1: for German, French, and English, the output is composed of entities of NERC RUN1 and the disambiguation method of EL RUN1. -RUN2: for German, French, and English, the output is composed of entities of NERC RUN2 and the disambiguation method of EL RUN1. -RUN3: for German and French, the output is composed of entities of NERC RUN1 and the disambiguation method of EL RUN2. For English, the output is composed of entities of NERC RUN3 and the disambiguation method of EL RUN1.</p><p>All runs analyze the mention variations and use the filter to select the best five candidate entities among all selected candidate entities by each run. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.6">Results</head><p>For the EL without prior knowledge of mention types and boundaries, our EL approach depends on the performance of our NERC system to recognize and classify the type of entities in historical documents. The results on all the languages are presented in Table <ref type="table" coords="14,234.78,118.93,3.87,8.80" target="#tab_4">4</ref>. While RUN1 achieved the best results for metonymic, RUN3 outperformed the other configurations on the literal analysis.</p><p>For EL with prior knowledge of mention types and boundaries, our system has access to the ground-truth of NERC entities, i.e. correct span and NERC type for all mentions. Table <ref type="table" coords="14,262.85,166.75,4.98,8.80" target="#tab_5">5</ref> shows the results. As expected, our EL system achieved better results with the ground-truth information (improvement up to 0.09 and 0.31 in the F1 values for literal and metonymic, respectively). All runs achieved similar results for all languages, with the RUN1 being slightly superior to the other runs for literal and metonymic analysis.</p><p>The use of the filter based on DBpedia and Wikidata reduced the performance of the EL system in English and French. This might be due to the increment of noise, such as names of disambiguation pages. 16 Our filter analyses all candidate entities for each mention to order the list of candidates based on their NERC types and names. Since RUN1 and RUN2 provide up to five candidate entities for each mention, these runs are more likely than RUN3 to provide a NIL entry for a mention. For RUN3, the filtering process has a higher probability to find a candidate of the same named entity type as the mention and disambiguates this mention to a less frequent candidate entity in a KB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>For the participation of our team (L3i) to the HIPE lab at CLEF 2020, we proposed two neural-based methods for the tasks of NERC and EL. We conclude, for NERC, that the proposed models generally performed well, and that the stacked transformer-based model with a BERT fine-tuned model and additional transformer layers better learned the characteristics of the HIPE historical dataset.</p><p>For EL, our neural model combined with the filtering process analyzed the historical mentions and disambiguated them to the Wikidata KB. Combining information from Wikipedia, Wikidata, and DBpedia allowed a thorough analysis of the characteristics of the entities and helped our method to correctly disambiguate mentions in historical documents.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,161.81,479.83,288.41,8.80"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Global architecture of the NERC and EL proposed models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,157.88,371.17,14.12,2.80;4,154.77,376.73,20.35,2.80;4,150.47,353.30,28.94,2.80;4,166.83,300.33,17.65,3.50;4,169.14,305.89,13.04,3.50;4,245.20,306.82,16.12,5.60;4,283.21,385.06,10.43,2.80;4,277.48,390.62,21.91,2.80;4,199.97,366.40,25.65,2.80;4,199.97,357.27,25.65,2.80;4,202.61,338.61,20.75,2.80;4,205.26,343.37,15.46,2.80;4,236.66,340.99,67.38,3.20;4,204.83,319.55,13.13,2.80;4,244.29,319.55,12.04,2.80;4,286.45,319.55,12.69,2.80;4,209.75,375.14,5.67,2.80;4,249.46,375.14,5.67,2.80;4,287.97,353.30,5.67,2.80;4,239.28,366.40,25.65,2.80;4,238.88,357.27,25.65,2.80;4,221.70,375.14,13.55,2.80;4,261.41,375.14,13.55,2.80;4,299.13,353.30,13.55,2.80;4,134.77,407.23,179.83,7.92;4,134.77,418.19,135.08,7.92;4,372.36,307.55,48.68,5.15;4,382.57,346.30,28.83,3.35;4,352.76,360.63,23.78,3.35;4,382.86,372.33,28.83,3.35;4,378.56,332.84,36.84,3.35;4,342.00,322.04,13.14,2.58;4,357.24,313.82,6.18,3.35;4,394.17,313.82,7.40,3.35;4,427.05,313.82,11.42,3.35;4,342.71,325.25,12.23,2.58;4,385.24,360.63,55.96,3.35;4,342.65,385.00,5.54,12.03;4,364.10,393.40,2.96,3.35;4,396.05,393.40,12.48,3.35;4,428.74,393.40,11.06,3.35;4,359.27,295.43,74.25,5.15;4,314.60,407.53,166.00,7.92;4,314.60,418.49,25.60,7.92"><head></head><label></label><figDesc>NERC architecture for all the languages, including the pre-processing step. Detailed model proposed for each language.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,134.77,439.42,345.82,8.80;4,134.77,451.37,345.83,8.80;4,134.77,463.33,345.82,8.80;4,134.77,475.28,191.09,8.80"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: The main architecture of the BERT-based model and the additional Transformers (a) is composed of modules stacked on top of each other multiple times. The transformer encoder module (b) mainly consists of multi-head attention and pointwise feed-forward layers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,134.77,377.71,345.83,8.80;5,134.77,389.66,345.82,8.80;5,134.77,401.62,345.82,8.80;5,134.77,413.57,345.82,8.80;5,134.77,425.53,185.62,8.80"><head>Fig. 3 :</head><label>3</label><figDesc>Fig. 3: An example of a French instance from the training data. The upper sentence shows the provided input and the lower sentence contains no OCR errors. "#" represents the segmentation at line-level in historical newspapers. The arrows indicate the matching between the provided sentence and the correct sentence to highlight the OCR limitations.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="8,138.97,606.63,303.44,8.81;8,138.97,618.28,341.61,8.81;8,151.70,630.24,130.12,8.80;8,138.97,641.89,285.86,8.81;8,138.97,653.54,341.62,8.81;8,151.70,665.51,143.54,8.80;9,284.20,120.55,12.09,8.98;9,225.45,142.07,29.06,5.73;9,247.86,192.37,19.72,4.17;9,250.84,200.64,13.77,4.17;9,211.49,192.37,24.49,4.17;9,210.50,200.64,26.47,4.17;9,309.88,207.74,19.83,4.17;9,305.59,216.01,28.40,4.17;9,300.60,174.04,38.41,4.17;9,309.73,182.32,20.14,4.17;9,252.83,240.84,31.07,4.17;9,260.21,249.12,16.31,4.17;9,225.35,162.81,29.29,4.17;9,230.57,171.08,18.84,4.17;9,310.27,240.84,19.06,4.17;9,307.73,249.12,24.15,4.17;9,348.63,244.98,18.00,4.17;9,272.18,138.57,19.55,4.17;9,310.83,138.57,17.92,4.17;9,345.82,137.98,18.90,4.17;9,384.67,193.60,20.41,5.04;9,386.83,233.52,19.62,5.21;9,384.67,221.98,20.40,5.04"><head>1 . 2 . 3 . 4 .</head><label>1234</label><figDesc>Building resources: the setup of a knowledge base per language. Entity embeddings: the creation of entity feature representations based on the model proposed by<ref type="bibr" coords="8,268.54,630.24,9.96,8.80" target="#b6">[7]</ref>. Entity disambiguation: the main end-to-end EL model<ref type="bibr" coords="8,406.57,641.90,14.61,8.80" target="#b9">[10]</ref>. Candidates filtering: the post-processing step where several filtering techniques are proposed and studied.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="10,134.77,575.77,345.83,8.80;10,134.77,587.73,345.82,8.80;10,134.77,599.68,89.49,8.80;10,152.06,284.96,311.25,279.35"><head>Fig. 5 :</head><label>5</label><figDesc>Fig. 5: Global model architecture for the mention "The New York Times". The final score is used for both mention linking and entity disambiguation decisions (Kolitsas et al. [10]).</figDesc><graphic coords="10,152.06,284.96,311.25,279.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,134.77,127.30,345.82,84.62"><head>Table 1 :</head><label>1</label><figDesc>Number of entities for the training, development, and test sets in HIPE 2020 corpora.</figDesc><table coords="3,223.73,163.85,167.89,48.08"><row><cell>Splits</cell><cell cols="3">German English French</cell></row><row><cell>training</cell><cell>3,505</cell><cell>-</cell><cell>6,885</cell></row><row><cell>development</cell><cell>1,390</cell><cell>967</cell><cell>1,723</cell></row><row><cell>test</cell><cell>1,147</cell><cell>449</cell><cell>1,600</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,136.16,127.30,339.11,98.17"><head>Table 2 :</head><label>2</label><figDesc>The NERC participating COARSE-LIT results for all runs.</figDesc><table coords="7,136.16,139.64,339.11,85.83"><row><cell cols="2">Runs Metrics</cell><cell>P</cell><cell cols="2">German R F1</cell><cell>P</cell><cell>French R</cell><cell>F1</cell><cell>P</cell><cell>English R F1</cell></row><row><cell>RUN1</cell><cell cols="8">micro-fuzzy 0.838 0.886 0.861 0.909 0.926 0.917 0.775 0.797 0.786 micro-strict 0.764 0.807 0.785 0.823 0.839 0.831 0.623 0.641 0.632</cell></row><row><cell>RUN2</cell><cell cols="2">micro-fuzzy 0.87 micro-strict 0.79</cell><cell cols="6">0.886 0.878 0.912 0.931 0.921 0.774 0.786 0.78 0.805 0.797 0.831 0.849 0.84 0.621 0.63 0.625</cell></row><row><cell>RUN3</cell><cell cols="2">micro-fuzzy -micro-strict -</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>0.794 0.817 0.806 0.617 0.635 0.626</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,134.77,251.23,345.82,376.72"><head>Table 3 :</head><label>3</label><figDesc>The NERC participating results (all metrics) for the best performing run for each language.</figDesc><table coords="7,136.16,275.52,339.99,352.43"><row><cell>Metrics</cell><cell>P</cell><cell cols="2">German R F1</cell><cell>P</cell><cell>French R</cell><cell>F1</cell><cell>P</cell><cell>English R F1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">COARSE-LIT</cell><cell></cell></row><row><cell>micro-fuzzy</cell><cell>0.87</cell><cell cols="7">0.886 0.878 0.912 0.931 0.921 0.794 0.817 0.806</cell></row><row><cell>micro-strict</cell><cell>0.79</cell><cell cols="5">0.805 0.797 0.831 0.849 0.84</cell><cell cols="2">0.617 0.635 0.626</cell></row><row><cell cols="9">macro_doc-fuzzy 0.879 0.876 0.871 0.933 0.939 0.934 0.782 0.797 0.798</cell></row><row><cell cols="9">macro_doc-strict 0.782 0.781 0.777 0.852 0.859 0.854 0.635 0.64 0.644</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">COARSE-METO</cell><cell></cell></row><row><cell>micro-fuzzy</cell><cell cols="2">0.626 0.78</cell><cell cols="3">0.694 0.676 0.67</cell><cell cols="2">0.673 1.0</cell><cell>0.12 0.214</cell></row><row><cell>micro-strict</cell><cell cols="8">0.571 0.712 0.634 0.658 0.652 0.655 0.667 0.08 0.143</cell></row><row><cell cols="8">macro_doc-fuzzy 0.558 0.678 0.686 0.628 0.732 0.718 1.0</cell><cell>0.075 0.533</cell></row><row><cell cols="6">macro_doc-strict 0.525 0.637 0.645 0.624 0.73</cell><cell cols="2">0.715 0.5</cell><cell>0.05 0.333</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">FINE-COMP</cell><cell></cell></row><row><cell>micro-fuzzy</cell><cell cols="7">0.654 0.768 0.707 0.751 0.827 0.787 0</cell><cell>0</cell><cell>0</cell></row><row><cell>micro-strict</cell><cell cols="7">0.595 0.698 0.642 0.661 0.728 0.693 0</cell><cell>0</cell><cell>0</cell></row><row><cell cols="8">macro_doc-fuzzy 0.609 0.719 0.678 0.773 0.833 0.809 0</cell><cell>0</cell><cell>0</cell></row><row><cell cols="8">macro_doc-strict 0.559 0.649 0.618 0.703 0.757 0.735 0</cell><cell>0</cell><cell>0</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">FINE-LIT</cell><cell></cell></row><row><cell>micro-fuzzy</cell><cell cols="8">0.734 0.813 0.771 0.843 0.869 0.856 0.733 0.817 0.773</cell></row><row><cell>micro-strict</cell><cell cols="8">0.629 0.697 0.661 0.772 0.797 0.784 0.547 0.61 0.577</cell></row><row><cell cols="9">macro_doc-fuzzy 0.754 0.813 0.776 0.871 0.883 0.875 0.742 0.798 0.774</cell></row><row><cell cols="6">macro_doc-strict 0.644 0.694 0.663 0.799 0.81</cell><cell cols="3">0.803 0.584 0.614 0.602</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">FINE-METO</cell><cell></cell></row><row><cell>micro-fuzzy</cell><cell cols="7">0.659 0.771 0.711 0.626 0.688 0.655 1.0</cell><cell>0.16 0.276</cell></row><row><cell>micro-strict</cell><cell cols="7">0.601 0.703 0.648 0.618 0.679 0.647 0.75</cell><cell>0.12 0.207</cell></row><row><cell cols="6">macro_doc-fuzzy 0.595 0.659 0.705 0.558 0.7</cell><cell cols="2">0.687 1.0</cell><cell>0.108 0.522</cell></row><row><cell cols="9">macro_doc-strict 0.562 0.618 0.664 0.556 0.698 0.686 0.667 0.083 0.389</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">NESTED</cell><cell></cell></row><row><cell>micro-fuzzy</cell><cell cols="7">0.588 0.411 0.484 0.366 0.415 0.389 0</cell><cell>0</cell><cell>0</cell></row><row><cell>micro-strict</cell><cell>0.49</cell><cell cols="6">0.342 0.403 0.333 0.378 0.354 0</cell><cell>0</cell><cell>0</cell></row><row><cell cols="8">macro_doc-fuzzy 0.339 0.326 0.413 0.502 0.484 0.521 0</cell><cell>0</cell><cell>0</cell></row><row><cell cols="8">macro_doc-strict 0.229 0.159 0.252 0.476 0.456 0.491 0</cell><cell>0</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="12,135.15,198.28,345.07,187.83"><head>Table 4 :</head><label>4</label><figDesc>EL results without prior knowledge of mention types and boundaries.</figDesc><table coords="12,136.34,210.62,341.33,175.50"><row><cell cols="2">Runs Metrics</cell><cell>P</cell><cell>English R</cell><cell>F1</cell><cell>P</cell><cell>French R F1</cell><cell>P</cell><cell>German R F1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Literal</cell><cell></cell><cell></cell></row><row><cell>RUN1</cell><cell cols="8">micro-strict 0.514 0.533 0.523 0.592 0.601 0.597 0.508 0.529 0.518 micro-relaxed 0.514 0.533 0.523 0.612 0.621 0.617 0.53 0.552 0.541</cell></row><row><cell>RUN2</cell><cell cols="8">micro-strict 0.496 0.506 0.501 0.592 0.602 0.597 0.531 0.538 0.534 micro-relaxed 0.496 0.506 0.501 0.612 0.622 0.617 0.553 0.561 0.557</cell></row><row><cell>RUN3</cell><cell cols="8">micro-strict 0.523 0.539 0.531 0.594 0.602 0.598 0.502 0.528 0.515 micro-relaxed 0.523 0.539 0.531 0.613 0.622 0.617 0.524 0.55 0.537</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Metonymic</cell><cell></cell><cell></cell></row><row><cell>RUN1</cell><cell cols="3">micro-strict 0.172 0.2 micro-relaxed 0.172 0.2</cell><cell cols="5">0.185 0.236 0.402 0.297 0.324 0.508 0.396 0.185 0.366 0.625 0.462 0.384 0.602 0.469</cell></row><row><cell>RUN2</cell><cell cols="3">micro-strict 0.062 0.04 micro-relaxed 0.062 0.04</cell><cell cols="5">0.049 0.217 0.339 0.265 0.324 0.508 0.396 0.049 0.343 0.536 0.418 0.384 0.602 0.469</cell></row><row><cell>RUN3</cell><cell cols="3">micro-strict 0.059 0.04 micro-relaxed 0.059 0.04</cell><cell cols="5">0.048 0.236 0.402 0.297 0.308 0.508 0.383 0.048 0.366 0.625 0.462 0.364 0.602 0.454</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="13,136.34,399.13,341.33,187.83"><head>Table 5 :</head><label>5</label><figDesc>EL results with prior knowledge of mention types and boundaries.</figDesc><table coords="13,136.34,411.46,341.33,175.50"><row><cell cols="2">Runs Metrics</cell><cell>P</cell><cell>English R</cell><cell>F1</cell><cell>P</cell><cell>French R F1</cell><cell>P</cell><cell>German R F1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Literal</cell><cell></cell><cell></cell></row><row><cell>RUN1</cell><cell cols="8">micro-strict 0.593 0.593 0.593 0.64 0.638 0.639 0.565 0.564 0.565 micro-relaxed 0.593 0.593 0.593 0.66 0.657 0.659 0.588 0.587 0.587</cell></row><row><cell>RUN2</cell><cell cols="8">micro-strict 0.593 0.593 0.593 0.635 0.632 0.633 0.564 0.563 0.564 micro-relaxed 0.593 0.593 0.593 0.654 0.652 0.653 0.587 0.586 0.586</cell></row><row><cell>RUN3</cell><cell cols="2">micro-strict 0.58 micro-relaxed 0.58</cell><cell>0.58 0.58</cell><cell cols="5">0.58 0.633 0.63 0.632 0.581 0.582 0.582 0.58 0.653 0.65 0.652 0.601 0.602 0.602</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Metonymic</cell><cell></cell><cell></cell></row><row><cell>RUN1</cell><cell cols="3">micro-strict 0.286 0.48 micro-relaxed 0.286 0.48</cell><cell cols="5">0.358 0.303 0.446 0.361 0.443 0.627 0.519 0.358 0.461 0.679 0.549 0.515 0.729 0.604</cell></row><row><cell>RUN2</cell><cell cols="3">micro-strict 0.286 0.48 micro-relaxed 0.286 0.48</cell><cell cols="5">0.358 0.303 0.446 0.361 0.443 0.627 0.519 0.358 0.461 0.679 0.549 0.515 0.729 0.604</cell></row><row><cell>RUN3</cell><cell cols="3">micro-strict 0.286 0.48 micro-relaxed 0.286 0.48</cell><cell cols="5">0.358 0.297 0.438 0.354 0.431 0.61 0.505 0.358 0.455 0.67 0.542 0.485 0.686 0.568</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="2,144.73,645.79,335.86,7.92;2,144.73,656.74,65.01,7.92"><p>Quaero guidelines: http://www.quaero.org/media/files/bibliographie/quaero-guideannotation-2011</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="5,144.73,580.03,335.86,7.92;5,144.73,590.99,335.86,7.92;5,144.73,601.95,335.87,7.92"><p>To increase the chances for misspelled, non-canonical, or new words to be recognized, we enrich the vocabulary of the tokenizer with these tokens, while allowing not only the BERT encoder but also the added Transformer layers to learn them from scratch.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="5,144.73,612.91,335.86,7.92;5,144.73,623.87,335.86,7.92"><p>In our implementation, we used learned absolute positional embeddings<ref type="bibr" coords="5,436.12,612.91,9.73,7.92" target="#b7">[8]</ref> instead, as suggested by<ref type="bibr" coords="5,209.48,623.87,13.51,7.92" target="#b25">[26]</ref>.<ref type="bibr" coords="5,229.13,623.87,14.33,7.92" target="#b23">[24]</ref> found that both versions produced nearly identical results.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3" coords="5,144.73,634.83,335.87,7.92;5,144.73,645.79,335.86,7.92;5,144.73,656.74,276.68,7.92"><p>It should be noted, that the segmentation using Freeling was not flawless. For instance, certain abbreviations were unknown by the tool. Thus, in some cases, Freeling oversegmented the sentences. Nonetheless, these errors were ignored.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_4" coords="11,144.73,612.91,281.43,7.92"><p>This included candidates that could not be found in DBpedia as well.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_5" coords="11,144.73,623.87,335.86,7.92;11,144.73,634.83,91.58,7.92"><p>In the case the literal and metonymic entities types were discordant, we considered both types as possible.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_6" coords="11,144.73,645.79,133.39,7.92"><p>github.com/seatgeek/fuzzywuzzy</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_7" coords="11,144.73,656.74,316.97,7.92"><p>Certain person-type entities, such as music bands, do not have a date of birth.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_8" coords="12,144.73,634.83,161.59,7.92"><p>wiki.dbpedia.org/public-sparql-endpoint</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_9" coords="12,144.73,645.79,74.26,7.92"><p>query.wikidata.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_10" coords="12,144.73,656.74,181.21,7.92"><p>https://github.com/facebookresearch/MUSE</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>This work has been supported by the <rs type="funder">European Union</rs>'s <rs type="programName">Horizon 2020 research and innovation program</rs> under grants <rs type="grantNumber">770299</rs> (NewsEye) and <rs type="grantNumber">825153</rs> (Embeddia).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_UxKyys4">
					<idno type="grant-number">770299</idno>
					<orgName type="program" subtype="full">Horizon 2020 research and innovation program</orgName>
				</org>
				<org type="funding" xml:id="_CDv8h8b">
					<idno type="grant-number">825153</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="15,155.24,170.74,325.35,8.80;15,155.24,182.69,325.35,8.80;15,155.24,194.65,325.35,8.80;15,155.24,206.61,229.63,8.80" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="15,381.31,170.74,99.28,8.80;15,155.24,182.69,251.81,8.80">BERT: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,428.63,182.69,51.96,8.80;15,155.24,194.65,325.35,8.80;15,155.24,206.61,129.23,8.80">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,155.24,218.12,325.36,8.80;15,155.24,230.08,47.59,8.80" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="15,211.44,218.12,145.15,8.80">Advanced MS-DOS Programming</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Duncan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>Microsoft Press</publisher>
			<pubPlace>Redmond, WA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,155.24,241.59,325.36,8.80;15,155.24,253.55,325.35,8.80;15,155.24,265.50,325.35,8.80;15,155.24,277.46,325.35,8.80;15,155.24,289.41,266.99,8.80" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="15,412.13,241.59,68.47,8.80;15,155.24,253.55,325.35,8.80;15,155.24,265.50,90.02,8.80">Introducing the CLEF 2020 HIPE shared task: Named entity recognition and linking on historical newspapers</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bircher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clematide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,332.83,277.46,143.91,8.80">Advances in information retrieval</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Jose</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Yilmaz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Magalhães</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Castells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Silva</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Martins</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="524" to="532" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,155.24,300.93,325.35,8.80;15,155.24,312.88,325.35,8.80;15,155.24,324.84,325.35,8.80;15,155.24,336.79,83.00,8.80" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="15,155.24,312.88,305.39,8.80">Language resources for historical newspapers: the impresso collection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clematide</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">B</forename><surname>Ströbel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Barman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,155.24,324.84,320.75,8.80">Proceedings of The 12th Language Resources and Evaluation Conference</title>
		<meeting>The 12th Language Resources and Evaluation Conference</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="958" to="968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,155.24,348.31,325.35,8.80;15,155.24,360.26,325.35,8.80;15,155.24,372.22,325.35,8.80;15,155.24,384.17,325.35,8.80;15,155.24,396.13,216.03,8.80" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="15,439.23,348.31,41.36,8.80;15,155.24,360.26,325.35,8.80;15,155.24,372.22,49.42,8.80">Extended Overview of CLEF HIPE 2020: Named Entity Processing on Historical Newspapers</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Flückiger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clematide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,155.24,384.17,325.35,8.80;15,155.24,396.13,128.66,8.80">CLEF 2020 Working Notes. Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,155.24,407.64,325.35,8.80;15,155.24,419.60,325.35,8.80;15,155.24,431.55,206.48,8.80" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="15,155.24,419.60,302.11,8.80">Impresso named entity annotation guidelines (version 2</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Flückiger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clematide</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.3604227</idno>
		<ptr target="https://doi.org/10.5281/zenodo.3604227" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,155.24,443.07,325.35,8.80;15,155.24,455.02,325.35,8.80;15,155.24,466.98,238.38,8.80" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="15,273.91,443.07,206.67,8.80;15,155.24,455.02,52.49,8.80">Deep joint entity disambiguation with local neural attention</title>
		<author>
			<persName coords=""><forename type="first">O</forename><forename type="middle">E</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,229.34,455.02,251.25,8.80;15,155.24,466.98,137.67,8.80">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="2619" to="2629" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,155.24,478.49,325.35,8.80;15,155.24,490.45,325.35,8.80;15,155.24,502.40,27.67,8.80" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gehring</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Grangier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Yarats</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">N</forename><surname>Dauphin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.03122</idno>
		<title level="m" coord="15,449.88,478.49,30.71,8.80;15,155.24,490.45,171.68,8.80">Convolutional sequence to sequence learning</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="15,155.24,513.92,325.35,8.80;15,155.24,525.87,325.35,8.80;15,155.24,537.83,325.35,8.80;15,155.24,549.78,325.35,8.80;15,155.24,561.74,27.67,8.80" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="15,314.92,525.87,165.67,8.80;15,155.24,537.83,46.35,8.80">Robust disambiguation of named entities in text</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Yosef</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Bordino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fürstenau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pinkal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Spaniol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Taneva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Thater</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,224.42,537.83,256.17,8.80;15,155.24,549.78,140.75,8.80">Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2011 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Edinburgh, Scotland, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="782" to="792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,155.24,573.25,325.35,8.80;15,155.24,585.21,325.35,8.80;15,155.24,597.16,155.66,8.80" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="15,336.17,573.25,140.37,8.80">End-to-end neural entity linking</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kolitsas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><forename type="middle">E</forename><surname>Ganea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,171.73,585.21,308.86,8.80;15,155.24,597.16,64.76,8.80">Proceedings of the 22nd Conference on Computational Natural Language Learning</title>
		<meeting>the 22nd Conference on Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="519" to="529" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,155.24,608.68,325.35,8.80;15,155.24,620.63,325.36,8.80;15,155.24,632.59,144.22,8.80" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="15,272.13,608.68,208.46,8.80;15,155.24,620.63,292.52,8.80">Sentencepiece: A simple and language independent subword tokenizer and detokenizer for neural text processing</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Kudo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Richardson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1808.06226</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="15,155.24,644.10,325.35,8.80;15,155.24,656.06,144.22,8.80" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="15,270.88,644.10,177.76,8.80">Cross-lingual language model pretraining</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Lample</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1901.07291</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="16,155.24,118.93,325.35,8.80;16,155.24,130.89,325.35,8.80;16,155.24,142.83,325.35,8.81;16,155.24,154.80,197.63,8.80" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="16,442.41,130.89,38.18,8.80;16,155.24,142.84,300.82,8.80">DBpedia -a large-scale, multilingual knowledge base extracted from wikipedia</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Isele</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jakob</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jentzsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kontokostas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">N</forename><surname>Mendes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hellmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Morsey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">V</forename><surname>Kleef</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bizer</surname></persName>
		</author>
		<idno type="DOI">10.3233/SW-140134</idno>
		<ptr target="https://doi.org/10.3233/SW-140134" />
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="167" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,155.24,166.69,325.35,8.80;16,155.24,178.64,325.35,8.80;16,155.24,190.60,217.91,8.80" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="16,426.17,166.69,54.42,8.80;16,155.24,178.64,154.66,8.80">Performance measures for information extraction</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Makhoul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Kubala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weischedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,332.80,178.64,147.79,8.80;16,155.24,190.60,63.34,8.80">Proceedings of DARPA broadcast news workshop</title>
		<meeting>DARPA broadcast news workshop<address><addrLine>Herndon, VA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="249" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,155.24,202.49,325.35,8.80;16,155.24,214.44,325.35,8.80;16,155.24,226.40,204.30,8.80" xml:id="b14">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J O</forename><surname>Suárez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Dupont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Romary</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">É</forename><forename type="middle">V</forename><surname>De La Clergerie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Seddah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Sagot</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1911.03894</idno>
		<title level="m" coord="16,314.60,214.44,165.99,8.80;16,155.24,226.40,24.21,8.80">Camembert: a tasty french language model</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="16,155.24,238.29,325.35,8.80;16,155.24,250.24,325.35,8.80;16,155.24,262.20,138.34,8.80" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="16,303.30,238.29,172.83,8.80">Enhancing bert for lexical normalization</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Sagot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Seddah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,171.57,250.24,287.16,8.80">Proceedings of the 5th Workshop on Noisy User-generated Text</title>
		<meeting>the 5th Workshop on Noisy User-generated Text<address><addrLine>W-NUT</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="297" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,155.24,274.09,325.35,8.80;16,155.24,286.04,325.35,8.80;16,155.24,298.00,325.36,8.80;16,155.24,309.95,325.35,8.80;16,155.24,322.68,214.89,8.30" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="16,225.27,274.09,255.32,8.80;16,155.24,286.04,47.66,8.80">An open corpus for named entity recognition in historic newspapers</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Neudecker</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/L16-1689" />
	</analytic>
	<monogr>
		<title level="m" coord="16,225.52,286.04,255.07,8.80;16,155.24,298.00,199.56,8.80">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)<address><addrLine>Portorož, Slovenia</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA)</publisher>
			<date type="published" when="2016-05">May 2016</date>
			<biblScope unit="page" from="4348" to="4352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,155.24,333.80,325.35,8.80;16,155.24,345.75,325.35,8.80;16,155.24,357.71,325.36,8.80;16,155.24,369.66,325.35,8.80;16,155.24,381.62,281.46,8.80" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="16,278.40,333.80,198.01,8.80">FreeLing 3.0: Towards Wider Multilinguality</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Padró</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stanilovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,398.88,357.71,81.72,8.80;16,155.24,369.66,325.35,8.80;16,155.24,381.62,45.69,8.80">Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC&apos;12)</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Calzolari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Choukri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Declerck</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">U</forename><surname>Doğan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Maegaard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Mariani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Moreno</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Odijk</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Piperidis</surname></persName>
		</editor>
		<meeting>the Eight International Conference on Language Resources and Evaluation (LREC&apos;12)<address><addrLine>Istanbul, Turkey</addrLine></address></meeting>
		<imprint>
			<publisher>ELRA</publisher>
			<date type="published" when="2012-05">May 2012</date>
			<biblScope unit="page" from="2473" to="2479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,155.24,393.51,325.35,8.80;16,155.24,405.46,325.35,8.80;16,155.24,417.42,325.35,8.80;16,155.24,429.37,27.67,8.80" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="16,326.13,393.51,154.46,8.80;16,155.24,405.46,126.01,8.80">Combating adversarial misspellings with robust word recognition</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Pruthi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Dhingra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">C</forename><surname>Lipton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,304.65,405.46,175.94,8.80;16,155.24,417.42,184.93,8.80">57th Annual Meeting of the Association for Computational Linguistics (ACL 2019)</title>
		<meeting><address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="5582" to="5591" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,155.24,441.26,325.35,8.80;16,155.24,453.22,237.55,8.80" xml:id="b19">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<title level="m" coord="16,415.32,441.26,65.28,8.80;16,155.24,453.22,206.57,8.80">Improving language understanding by generative pre-training</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,155.24,465.11,325.35,8.80;16,155.24,477.06,325.35,8.80;16,155.24,489.02,278.83,8.80" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="16,246.96,465.11,212.84,8.80">A named entity recognition shootout for german</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Riedl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Padó</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,155.24,477.06,325.35,8.80;16,155.24,489.02,74.95,8.80">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 56th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="120" to="125" />
		</imprint>
	</monogr>
	<note>Short Papers</note>
</biblStruct>

<biblStruct coords="16,155.24,500.90,325.35,8.80;16,155.24,512.86,210.13,8.80" xml:id="b21">
	<monogr>
		<title level="m" type="main" coord="16,256.91,500.90,223.68,8.80;16,155.24,512.86,29.90,8.80">Towards robust named entity recognition for historic german</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Schweter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Baiter</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.07592</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="16,155.24,524.75,325.35,8.80;16,155.24,536.70,325.35,8.80;16,155.24,548.66,229.83,8.80" xml:id="b22">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hashimoto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Asai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xiong</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2003.04985</idno>
		<title level="m" coord="16,459.28,524.75,21.30,8.80;16,155.24,536.70,325.35,8.80;16,155.24,548.66,50.43,8.80">Advbert: Bert is not robust on misspellings! generating nature adversarial samples on bert</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="16,155.24,560.55,325.35,8.80;16,155.24,572.50,325.35,8.80;16,155.24,584.46,234.67,8.80" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="16,269.91,572.50,105.35,8.80">Attention is all you need</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ł</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,398.06,572.50,82.53,8.80;16,155.24,584.46,133.84,8.80">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="page" from="5998" to="6008" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,155.24,596.35,325.35,8.80;16,155.24,608.29,151.95,8.81" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="16,203.76,596.35,249.26,8.80">Strassburg, 1605: The origins of the newspaper in europe</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,461.13,596.35,19.46,8.80;16,155.24,608.30,52.37,8.80">German history</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="387" to="412" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,155.24,620.19,325.35,8.80;16,155.24,632.15,325.35,8.80;16,155.24,644.09,325.36,8.81;16,155.24,656.06,27.67,8.80" xml:id="b25">
	<monogr>
		<title level="m" type="main" coord="16,371.45,632.15,109.14,8.80;16,155.24,644.10,209.81,8.80">Huggingface&apos;s transformers: State-of-the-art natural language processing</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Brew</surname></persName>
		</author>
		<idno>ArXiv abs/1910.03771</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,155.24,118.93,325.35,8.80;17,155.24,130.89,325.35,8.80;17,155.24,142.84,325.35,8.80;17,155.24,154.80,225.13,8.80" xml:id="b26">
	<monogr>
		<title level="m" type="main" coord="17,391.40,130.89,89.19,8.80;17,155.24,142.84,325.35,8.80;17,155.24,154.80,45.73,8.80">Google&apos;s neural machine translation system: Bridging the gap between human and machine translation</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schuster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Norouzi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Krikun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Macherey</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.08144</idno>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
