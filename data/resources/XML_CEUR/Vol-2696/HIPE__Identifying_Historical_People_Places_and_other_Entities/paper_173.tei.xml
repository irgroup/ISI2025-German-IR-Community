<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,142.07,115.96,331.21,12.62;1,151.62,133.89,312.12,12.62;1,276.99,151.82,61.39,12.62">Triple E -Effective Ensembling of Embeddings and Language Models for NER of Historical German</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,232.65,189.49,69.21,8.74"><forename type="first">Stefan</forename><surname>Schweter</surname></persName>
							<email>stefan.schweter@bsb-muenchen.de</email>
							<affiliation key="aff0">
								<orgName type="department">Digital Library/Munich Digitization Center</orgName>
								<orgName type="institution">Bayerische Staatsbibliothek München</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,329.03,189.49,49.20,8.74"><forename type="first">Luisa</forename><surname>März</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Center for Information and Language Processing (CIS)</orgName>
								<orgName type="institution">LMU Munich</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,142.07,115.96,331.21,12.62;1,151.62,133.89,312.12,12.62;1,276.99,151.82,61.39,12.62">Triple E -Effective Ensembling of Embeddings and Language Models for NER of Historical German</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C0BB8989BE195F5F60A858891839F873</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Named Entity Recognition</term>
					<term>Transformer-based language models</term>
					<term>Embeddings</term>
					<term>Historical texts</term>
					<term>Flair</term>
					<term>FastText</term>
					<term>Byte Pair Encoding</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Named entity recognition (NER) for historical texts is a challenging task compared to NER for contemporary texts. Historical texts come with several peculiarities that differ greatly from modern texts and large labeled corpora for training a neural tagger are hardly available. In this work we tackle NER for historical German with an ensembling approach, combining different labeled and unlabeled resources of historical and contemporary texts as part of the CLEF HIPE 2020 evaluation lab. We stack different word/subword embeddings and transformer-based language models to train a powerful NER tagger for historical German. We conduct experiments with different word embeddings, Flair embeddings and pretrained Bert models. The named entities are classified in literal and in metonymic sense, for which we have developed a separate tagger each. Our experiments show that the usage of Bert is particularly helpful, when trained on a large amount of historical data. Our best ensemble is a combination of FastText embeddings trained on German Wikipedia, Flair embeddings trained on CLEF HIPE data (historical German) and a Bert language model trained on a large corpus of historical German. We release our code and models 3 .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In NER neural networks achieve good accuracy on high resource domains such as modern news text or Twitter ( <ref type="bibr" coords="1,268.69,581.03,10.79,8.74" target="#b1">[2,</ref><ref type="bibr" coords="1,281.14,581.03,7.20,8.74" target="#b3">4]</ref>). But on historical text, NER taggers often perform poorly. This is due to domain shift and to the fact that historical texts contain systematic errors not found in modern text, since historical datasets usually stem from optical character recognition (OCR). OCR is noisy and the Gothic type face (Fraktur) is a low resource font, that is very challenging for OCR. Another problem is that a large amount of data is required when training neural models and only relatively small corpora (e.g. <ref type="bibr" coords="2,376.10,154.86,15.50,8.74" target="#b19">[20]</ref>) exist for historical NER. All of these challenges mean that NER for contemporary texts differs greatly from NER for historical texts and that existing models cannot be used. From a resource orientated and ecological point of view it is reasonable to reuse existing models to save both computing power and emissions. Therefore, we reuse existing models on the one hand and make our newly developed language models publicly available on the other hand.</p><p>In the NLP community there are several approaches and models provided, one of which is Flair <ref type="bibr" coords="2,228.75,250.80,9.96,8.74" target="#b0">[1]</ref>. Flair allows to apply state-of-the-art natural language processing (NLP) models, such as NER, part-of-speech tagging (PoS), word sense disambiguation or classification to various input texts. In this work we built our systems with that framework.</p><p>Transformer-based language models are widely used and Bert <ref type="bibr" coords="2,435.98,298.92,10.52,8.74" target="#b7">[8]</ref> can be considered as a powerful standard resource. There are several recent approaches that use Bert for NER in different languages, such as <ref type="bibr" coords="2,381.30,322.83,15.50,8.74" target="#b24">[25]</ref> or <ref type="bibr" coords="2,413.51,322.83,14.61,8.74" target="#b15">[16]</ref>. The latter conduct experiments with historical German using Bert and unsupervised pretraining on a large corpus of historical German texts together with supervised pretraining on a contemporary German corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Task and Objective</head><p>In this work, we address neural NER tagging on historical German data. With our approach we aim to solve coarse grained NER in the CLEF HIPE shared task <ref type="bibr" coords="2,156.06,435.43,15.50,8.74" target="#b10">[11]</ref> (bundle 4) for historical German as best as possible. The tagset of the provided data contains person, location, organisation, product and time. The organizers arranged two scenarios to be solved: NER for the literal sense of the words and NER for metonymic sense. The example below shows that the tags for the literal (first sentence) and metonymic (second sentence) sense can differ. Hannover can be interpreted as an organization as well as a location depending on its context and the metonymic category addresses this issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Example:</head><p>Unterhandlungen über das Konkordat mit B-loc Hannover schreiten voran. Unterhandlungen über das Konkordat mit B-org Hannover schreiten voran. (Negotiations on the Concordat with Hanover are progressing.) This paper is structured as follows: The next section describes data sets and other resources that are used in the experiments presented. Section 3 outlines our method and section 4 explains details on implementation and the conducted experiments. The outcome of the experiments is discussed in that section as well. Then, section 5 overviews ideas for future work and we conclude the paper with section 6. This section describes the data provided by the shared task organizers as well as additional resources and data that we used for our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">CLEF HIPE Data</head><p>The shared task corpus for German is composed of articles sampled among several Swiss and Luxembourgish historical newspapers on a diachronic basis and is provided by the CLEF-HIPE-2020 organizers. The articles that were chosen for the train, development and test data are journalistic articles only, that had to match certain selection criteria such as length or format. Feuilleton, tabular data, crosswords, weather forecasts, time schedules and obituaries were excluded as well as articles that were fully illegible due to massive ORC noise. The newspaper content stems for the time period from 1798 until 2018 and thus there is different OCR quality present in the data which covers a broad spectrum of text composition. The corpora were manually annotated by native speakers according the HIPE impresso guidelines ( <ref type="bibr" coords="3,270.83,316.38,15.50,8.74" target="#b9">[10,</ref><ref type="bibr" coords="3,288.00,316.38,7.20,8.74" target="#b8">9]</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Additional Data and Resources</head><p>Table <ref type="table" coords="3,162.05,360.96,4.98,8.74" target="#tab_0">1</ref> gives an overview of all resources and shows time period and domain of each data set. The sizes of the training data used for the embeddings/models is shown in Table <ref type="table" coords="3,214.55,384.87,3.87,8.74" target="#tab_1">2</ref>. Our approach includes data from different time periods as well as from various domains to reuse existing resources optimally.</p><p>Embeddings We use different FastText-based word embeddings <ref type="bibr" coords="3,430.44,424.10,15.50,8.74" target="#b18">[19]</ref> trained on Wikipedia<ref type="foot" coords="3,194.18,434.48,3.97,6.12" target="#foot_0">4</ref> , Common Crawl<ref type="foot" coords="3,275.17,434.48,3.97,6.12" target="#foot_1">5</ref> and on historic data (provided by the organizers) as well as Byte Pair Encoding-based embeddings (BPE, <ref type="bibr" coords="3,426.87,448.01,15.50,8.74" target="#b23">[24]</ref>) trained on Wikipedia. We use the FastText embeddings trained on Wikipedia (FastText Wiki ) and Common Crawl (FastText CC ) in a "classic" word embeddings manner, that means we do not use subwords. To include subword information we use German subword embeddings <ref type="bibr" coords="3,267.71,495.83,15.50,8.74" target="#b11">[12]</ref> with a dimension of 300 and a vocab size of 200k (BPEmb). Additionally, we experiment with multilingual subword embeddings <ref type="bibr" coords="3,160.83,519.74,15.50,8.74" target="#b12">[13]</ref> with a dimension size of 300 and a vocab size of 1M (MultiBPEmb).</p><p>We use Flair embeddings <ref type="bibr" coords="3,261.31,531.70,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="3,273.48,531.70,7.75,8.74" target="#b1">2]</ref> provided by the organizers (CLEF-HIPE ) and compared them to other Flair embeddings that were trained on historic data. We use two historic Flair embeddings that were trained by <ref type="bibr" coords="3,407.41,555.61,14.61,8.74" target="#b22">[23]</ref>: embeddings trained on the Hamburger Anzeiger newspaper corpus (HHA) and embeddings trained on the Wiener Zeitung newspaper corpus (WZ ). Both embeddings are available in the Flair framework. In addition we use the data of the recently published REDEWIEDERGABE corpus <ref type="bibr" coords="3,316.26,603.43,10.52,8.74" target="#b5">[6]</ref> that consists of fictional and nonfictional texts. We also experiment with the Flair embeddings provided by <ref type="bibr" coords="3,470.07,615.38,10.52,8.74" target="#b2">[3]</ref> (German Flair). Transformer-based language models For transformer-based language models we conduct experiments with self-trained Bert models, Europeana Bert<ref type="foot" coords="5,476.12,129.37,3.97,6.12" target="#foot_2">6</ref> and large German Bert<ref type="foot" coords="5,241.45,141.33,3.97,6.12" target="#foot_3">7</ref> (German Bert). In preliminary experiments we also used publicly available German Bert models (deepset<ref type="foot" coords="5,376.55,153.28,3.97,6.12" target="#foot_4">8</ref> and DBMDZ <ref type="foot" coords="5,442.71,153.28,3.97,6.12" target="#foot_5">9</ref> ). Since their performance was not convincing we did not include them in our final setup. The Europeana Bert data comes from the Europeana Newspapers collection <ref type="foot" coords="5,151.92,189.30,7.94,6.12" target="#foot_6">10</ref> , which contains historical news articles in 12 languages published between 1618 and 1990. The Europeana Bert model was trained on 51GB of newspapers, extracted from German Europeana. It mainly covers newspaper articles from the 18th to 20th century. German Bert was trained on a huge collection of various historical resources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head><p>To develop an efficient NER tagger for historical texts we experiment with stacking methods described in the following.</p><p>We experiment with different kinds of ensembling/stacking approaches on the development set to figure out the optimal combination of embeddings and language models. Our final system Cisteria uses an ensemble of word embeddings, transformer-based language models and Flair embeddings. To arrive at the best combination of embeddings for Cisteria we conduct experiments where we a) select the best word embeddings, Flair embeddings and transformer-based language models independently and b) combine the best selected word embedding, the best transformer-based language model and the best Flair embeddings and feed those to our network. The network for the classification is a bidirectional LSTM with a conditional random field (CRF) as final output layer as proposed by <ref type="bibr" coords="5,149.17,439.54,14.61,8.74" target="#b13">[14]</ref>. Note that we train separate models for the metonymic and the literal sense span.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Implementation and Experiments</head><p>The following describes the implementation of our approach, overviews the different experiments and presents the results. Our final system for the CLEF HIPE 2020 evaluation lab is referred to as Cisteria.</p><p>To feed the CLEF-HIPE data into our tagger we need several preprocessing steps. Our preprocessing includes sentence splitting (rule based method) and normalizing word hyphenations. The motivation behind normalizing hyphenation is that pretrained language models normally include normalized text and the word hyphenation character in the CLEF-HIPE shared task is a special symbol (¬) and does not occur in training corpora for pretrained language models. As we use contextualized word embeddings, the correct hyphenation is very important to produce high quality embeddings. To get the data ready for evaluation with the officially provided evaluation script, we perform a reverse process and add word hyphenation and sentence boundaries again.</p><p>We use the Flair <ref type="bibr" coords="6,231.19,180.97,10.52,8.74" target="#b0">[1]</ref> library to train our NER tagging models and we make use of Bert embeddings in a feature-based setting. In order to get a representation for an input token, we first compute the mean of the first subword over all layers of the transformer-based architecture and feed the resulting representation into a bidirectional LSTM with a CRF as the final layer, following <ref type="bibr" coords="6,467.31,228.79,9.96,8.74" target="#b2">[3]</ref>. To ensemble different embeddings and language models their representations are concatenated and the resulting vector is processed by the neural model. Cisteria was trained on the official training and development data and does not use any other additional labeled training data.</p><p>For the experiments with transformer-based language models, we fine-tune Bert models using the Hugging Face Transformers library <ref type="bibr" coords="6,396.22,302.72,14.61,8.74" target="#b27">[29]</ref>. For these finetuning experiments, we use a batch size of 16 and train 10 epochs. We perform three runs per transformer-based model and select the best model based on development F1-score. We do not perform extensive hyperparameter search.</p><p>We then use the fine-tuned model in Flair (feature-based approach) for all further experiments. We use a bidirectional LSTM with 256 hidden states and a batch size of 16. The original Bert paper <ref type="bibr" coords="6,343.23,376.66,10.52,8.74" target="#b7">[8]</ref> uses the last four layers of the transformer-based model for a feature-based NER model. Additionally, we reduce the learning rate by a factor of 0.5 with a patience of 3. This factor determines the number of epochs with no improvement after which the learning rate will be reduced and can be seen as early stopping.</p><p>We found that fine-tuning a Bert model for the metonymic sense span was very unstable resulting in zero F1-scores. This is a well known problem for datasets when only a small number of training instances are available and a solution could be to use a different dropout strategy <ref type="bibr" coords="6,373.73,474.50,14.61,8.74" target="#b16">[17]</ref>. For that reason we trained a model using the CLEF-HIPE Flair embeddings. In the prediction phase we only do predictions when an entity is detected for the literal sense span.</p><p>Our final system for the literal sense span uses FastText embeddings trained on Wikipedia (FastText Wiki ) and a self-trained large German Bert model. For the metonymic sense span we train a separate model that uses FastText embeddings trained on Wikipedia and Flair embeddings provided by the organizers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Results</head><p>For the evaluation of NER there are two regimes: strict and fuzzy. The strict regime corresponds to exact boundary matching whereas the fuzzy takes overlapping boundaries into account, a detailed description can be found in <ref type="bibr" coords="6,449.80,656.12,14.61,8.74" target="#b10">[11]</ref>. In addition spans are evaluated w.r.t literal or metonymic sense (see section 1.1). We evaluate our systems using the official evaluation script 11 .</p><p>All our reported results on the development set refer to the F1 score for coarse grained NER in the strict scenario for the literal sense. For the test set we report precision, recall and F1 score for both scenarios in the literal sense as well as in the metonymic sense (see Table <ref type="table" coords="7,321.99,178.77,3.87,8.74" target="#tab_7">8</ref>). According to the overview paper of the shared task <ref type="bibr" coords="7,216.08,190.72,15.50,8.74" target="#b10">[11]</ref> the baseline in the strict evaluation scenario for German Coarse NER in literal sense results in 47.6% F1-score (see <ref type="bibr" coords="7,394.73,202.68,35.15,8.74">Table 7)</ref>.</p><p>Our results of the experiments with different word embeddings show that the FastText Wiki embeddings perform best, see Table <ref type="table" coords="7,380.47,226.59,3.87,8.74" target="#tab_2">3</ref>. With an F1-score of approx. 69% they can overcome the baseline by more than 20 percentage points. Interesting is that the FastText Wiki embeddings are not trained on the biggest amount of data compared to the other word embeddings (see Table <ref type="table" coords="7,432.18,262.46,3.87,8.74" target="#tab_1">2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model F1 FastText Wiki</head><p>69.28 ±0.65 FastText CC 66.38 ±0.51 BPEmb <ref type="bibr" coords="7,273.85,328.86,14.34,7.86" target="#b11">[12]</ref> 67.71 ±0.48 MultiBPEmb <ref type="bibr" coords="7,296.12,339.82,14.34,7.86" target="#b12">[13]</ref> 66.22 ±0.14 Different Flair embeddings lead consistently to better results than using word embeddings. The Flair embeddings provided by the organizers (CLEF-HIPE ) perform best, with an F1-score of 77.04% (see Table <ref type="table" coords="7,393.02,438.94,3.87,8.74" target="#tab_3">4</ref>). The gap between the different Flair embeddings is comparably large and ranges from seven to three percentage points difference. Here the embeddings that were trained on the biggest amount of data perform best and the Redewiedergabe embeddings that were trained on the least amount perform worst.</p><p>Model F1 Hamburger Anzeiger <ref type="bibr" coords="7,310.81,530.69,14.34,7.86" target="#b22">[23]</ref> 74.14 ±0.11 Wiener Zeitung <ref type="bibr" coords="7,290.29,541.65,14.34,7.86" target="#b22">[23]</ref> 75.07 ±0.11 Redewiedergabe <ref type="bibr" coords="7,292.48,552.61,9.73,7.86" target="#b5">[6]</ref> 70.21 ±0.27 German (Flair) <ref type="bibr" coords="7,294.73,563.57,9.73,7.86" target="#b2">[3]</ref> 74.98 ±0.30 CLEF-HIPE 77.04 ±0.12 The usage of Bert enhances the performance once more. The German Bert model performs best and results in 82.11% F-score (see Table <ref type="table" coords="8,409.56,240.56,3.87,8.74" target="#tab_4">5</ref>). Again this is the model that was trained on the biggest amount of data. The cased version of Europeana Bert leads to a similar performance with approx. two percentage points less. Since German is case sensitive it is understandable that the cased models perform better than the uncased ones. Like with the Flair embeddings every setup with Bert outperforms the models of our previous experiments. Finally the combination of German Bert with the FastText Wiki embeddings outperforms all of our other systems on the development set and results in 83.69% (see Table <ref type="table" coords="8,231.94,469.54,3.87,8.74" target="#tab_5">6</ref>). This result is plausible if we compare it to the best F1-scores of <ref type="bibr" coords="8,188.75,481.49,15.50,8.74" target="#b15">[16]</ref> on other historical datasets. For two datasets their performance is around 84%. The addition of the best Flair embeddings decreases the results slightly. If combining the best Flair embeddings with the best FastText embeddings the model performs better than using Flair embeddings only but still worse than the other stacking approaches. The performance of our best system is approx. 40% better than the baseline, which is a large improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Discussion of Results</head><p>We want to relate our final results on the test set to those of the other participating teams. Compared to the baseline our final systems (CISTERIA) could perform very good. If we take a look at the median of all participating teams our system for the literal sense performs approx. 2% points better in the strict scenario and is almost on par with the median in the fuzzy scenario (see Table <ref type="table" coords="8,468.97,644.16,3.87,8.74" target="#tab_6">7</ref>). For both regimes the best system L3i <ref type="bibr" coords="8,298.72,656.12,10.52,8.74" target="#b4">[5]</ref> outperforms ours by slightly more than 10% points. This could be due to the fact that they use powerful transformerbased embeddings for different languages and a hierarchical transformer-based attention model <ref type="bibr" coords="9,207.76,142.90,15.50,8.74" target="#b26">[28]</ref> together with a multi task learning setting approach. Our experiments with Bert embeddings show that the model can benefit from the German Europeana Bert language model a lot and that only a model trained with even more data could outperform it. Therefore it is not surprising that a model trained with more of these powerful Bert embeddings performs even better. The benefit of the combination of models for different languages is at hand and we suppose that our model performances can be enhanced if we integrate multilinguality as well. In the evaluation w.r.t the metonymic sense it turns out that our approach to train a separate model was constructive. In both regimes our system performs clearly above the median and in the fuzzy regime our F1-score is the second best (see Table <ref type="table" coords="9,182.32,530.19,3.87,8.74" target="#tab_7">8</ref>). Again the L3i system can reach the best scores, probably due to the same reasons as mentioned above. Our results support our strategy that we only do predictions for tokens where the literal sense is classified as an entity.</p><p>Regarding the precision our system performs very well and reaches second best performance in all cases, except for the fuzzy evaluation in the literal sense where our system performs best. Unfortunately the recall is relatively low with around 50% for the metonymic sense and 57%/68% for the strict/fuzzy evaluation in the literal sense. Our system has the ability to classify correctly if it identifies a token as a possible entity but has problems with finding the entities as such. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Future Work</head><p>The approach of the winning team suggests to include multilingual language models and/or more data. Since a lot of powerful pretrained language models are available we will integrate some of them in Cisteria.</p><p>Another strategy is to take into account the domain of historical language even more. Since there is a lot of noise in the data due to OCR it greatly differs from modern standard language. Nevertheless there are many modern corpora available on which transformer-based language models can be trained. Our goal is to increase the similarity of those modern corpora to historical data. Therefore we want to recreate some of the phenomena in historical corpora in the modern corpora that we use for training the language models.</p><p>Besides that, manual rule-based sentence segmentation could have drawbacks (e.g. bad segmentation could lead to short sentences). So in future experiments we could use the context before and after the actual training sentence, such as in <ref type="bibr" coords="10,146.58,446.98,14.61,8.74" target="#b17">[18]</ref>. This approach could eliminate potential drawbacks of an automatically sentence segmented training corpus, because shorter sentences are now enhanced with longer contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We proposed a system to solve coarse grained NER for German in the CLEF HIPE shared task. We conducted experiments with ensembling different word and subword embeddings as well as transformer-based language models on the basis of a bidirectional LSTM with a CRF as final layer. To use historical resources at best we trained large language models on historical German data, such as the German Europeana collection. Our best system uses FastText embeddings trained on German Wikipedia data in combination with a large German Bert language model. With a performance of 65.1% F1-score our best system performs slightly better than the median in the strict scenario for the literal sense and with an F1-score of 76.9% on par with the median in the fuzzy scenario. For the metonymic sense our best system performs clearly above the baseline and reaches the second best performance in the fuzzy scenario.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,134.77,159.91,345.82,418.60"><head>Table 1 .</head><label>1</label><figDesc>Overview of time periods and domains of the training data used for the embeddings and language models.</figDesc><table coords="4,159.65,159.91,296.06,418.60"><row><cell cols="2">usage</cell><cell>name</cell><cell></cell><cell cols="2">time period domain</cell></row><row><cell cols="2">train data</cell><cell></cell><cell></cell><cell cols="2">1798 -2018 news</cell></row><row><cell cols="2">FastText</cell><cell cols="2">FastText Wiki</cell><cell>contemp.</cell><cell>various</cell></row><row><cell cols="2">FastText</cell><cell cols="2">FastText CC</cell><cell>contemp.</cell><cell>various</cell></row><row><cell cols="2">BPE</cell><cell>BPEmb</cell><cell></cell><cell cols="2">1798 -2018 news</cell></row><row><cell cols="2">BPE</cell><cell cols="2">MultiBPEmb</cell><cell>contemp.</cell><cell>news</cell></row><row><cell cols="2">Flair</cell><cell>HHA</cell><cell></cell><cell cols="2">1888 -1945 news</cell></row><row><cell cols="2">Flair</cell><cell>WZ</cell><cell></cell><cell cols="2">1703 -1875 news</cell></row><row><cell cols="2">Flair</cell><cell cols="2">Redewiedergabe</cell><cell cols="2">1840 -1920 various</cell></row><row><cell cols="2">Flair</cell><cell cols="2">German Flair</cell><cell>contemp.</cell><cell>various</cell></row><row><cell cols="2">Flair</cell><cell cols="2">CLEF-HIPE</cell><cell cols="2">1798 -2018 news</cell></row><row><cell cols="2">Bert</cell><cell cols="4">Europeana Bert 1618 -1990 news</cell></row><row><cell cols="2">Bert</cell><cell cols="2">German Bert</cell><cell>historical</cell><cell>various</cell></row><row><cell>usage</cell><cell>name</cell><cell></cell><cell>data</cell><cell></cell><cell>tokens</cell><cell>size</cell></row><row><cell>train data</cell><cell></cell><cell></cell><cell cols="2">CLEF HIPE*</cell><cell>0.071</cell><cell>S</cell></row><row><cell>FastText</cell><cell cols="2">FastText Wiki</cell><cell cols="2">Wikipedia</cell><cell>1400</cell><cell>L</cell></row><row><cell>BPE</cell><cell>BPEmb</cell><cell></cell><cell cols="2">Wikipedia</cell><cell>≈ 1400</cell><cell>L</cell></row><row><cell>BPE</cell><cell cols="2">MultiBPEmb</cell><cell cols="2">Wikipedia</cell><cell>&lt; 7000</cell><cell>L</cell></row><row><cell>FastText</cell><cell cols="2">FastText CC</cell><cell cols="2">Common Crawl</cell><cell>65648</cell><cell>XL</cell></row><row><cell>Flair</cell><cell cols="2">Redewiedergabe</cell><cell cols="3">REDEWIEDERGABE 0.489</cell><cell>S</cell></row><row><cell>Flair</cell><cell cols="2">German Flair</cell><cell cols="2">OPUS project</cell><cell>500</cell><cell>M</cell></row><row><cell>Flair</cell><cell>HHA</cell><cell></cell><cell cols="2">Hamburger Anzeiger</cell><cell>742</cell><cell>M</cell></row><row><cell>Flair</cell><cell>WZ</cell><cell></cell><cell cols="2">Wiener Zeitung</cell><cell>802</cell><cell>M</cell></row><row><cell>Flair</cell><cell cols="2">CLEF-HIPE</cell><cell cols="2">CLEF-HIPE*</cell><cell>1722</cell><cell>L</cell></row><row><cell>Bert</cell><cell cols="4">Europeana Bert Europeana</cell><cell>8000</cell><cell>L</cell></row><row><cell>Bert</cell><cell cols="2">German Bert</cell><cell>-</cell><cell></cell><cell>≈ 24000 XL</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,134.77,591.98,345.82,18.85"><head>Table 2 .</head><label>2</label><figDesc>Overview of different training data used. Number of tokens is given in millions.</figDesc><table /><note coords="4,134.77,602.97,214.49,7.86"><p>* indicates that data was provided by the organizers.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,134.77,361.66,345.83,18.85"><head>Table 3 .</head><label>3</label><figDesc>Experiments with different word Embeddings on German development set. Averaged F1-score over 3 runs is reported here. Best result in bold.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,134.77,596.37,345.82,18.85"><head>Table 4 .</head><label>4</label><figDesc>Experiments with different Flair Embeddings on German development set. Averaged F1-score over 3 runs is reported here. Best result in bold.</figDesc><table coords="8,217.03,117.78,181.30,41.64"><row><cell>Model</cell><cell>F1</cell></row><row><cell>Europeana Bert (cased)</cell><cell>80.41 ±0.14</cell></row><row><cell>Europeana Bert (uncased)</cell><cell>79.66 ±0.32</cell></row><row><cell>German Bert (cased, large)</cell><cell>82.11 ±0.50</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,134.77,172.90,345.83,18.85"><head>Table 5 .</head><label>5</label><figDesc>Experiments with different Bert models on German development set. Averaged F1-score over 3 runs is reported here. Best result in bold.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,134.77,334.75,345.82,73.97"><head>Table 6 .</head><label>6</label><figDesc>Experiments with different stacking experiments on German development set. Averaged F1-score over 3 runs is reported here. Best result in bold.</figDesc><table coords="8,163.41,334.75,25.08,7.86"><row><cell>Model</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="9,134.77,271.45,345.82,178.72"><head>Table 7 .</head><label>7</label><figDesc>Results for NERC-Coarse literal with micro precision, recall and F1-score on the test set. Bold font indicates highest, underlined the second highest result.</figDesc><table coords="9,197.14,271.45,221.09,144.77"><row><cell>Team</cell><cell>P</cell><cell>Strict R</cell><cell>F1</cell><cell>P</cell><cell>Fuzzy R</cell><cell>F1</cell></row><row><cell>Cisteria</cell><cell cols="6">0.745 0.578 0.651 0.880 0.683 0.769</cell></row><row><cell cols="7">Ehrmama [27] 0.697 0.659 0.678 0.814 0.765 0.789</cell></row><row><cell>L3i [5]</cell><cell cols="6">0.790 0.805 0.797 0.870 0.886 0.878</cell></row><row><cell>Sbb [15]</cell><cell cols="6">0.499 0.484 0.491 0.730 0.708 0.719</cell></row><row><cell>SinNer [21]</cell><cell cols="6">0.658 0.658 0.658 0.775 0.819 0.796</cell></row><row><cell>UPB [7]</cell><cell cols="6">0.677 0.575 0.621 0.788 0.740 0.763</cell></row><row><cell cols="7">Uva-ilps [22] 0.499 0.556 0.526 0.689 0.768 0.726</cell></row><row><cell>Webis [26]</cell><cell cols="6">0.695 0.337 0.454 0.833 0.405 0.545</cell></row><row><cell>Baseline</cell><cell cols="6">0.643 0.378 0.476 0.790 0.464 0.558</cell></row><row><cell>Median</cell><cell cols="6">0.686 0.576 0.636 0.801 0.752 0.766</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="10,134.77,120.97,345.83,112.96"><head>Table 8 .</head><label>8</label><figDesc>Results for NERC-Coarse metonymic with micro precision, recall and F1score. Bold font indicates highest, underlined the second highest result.</figDesc><table coords="10,197.14,120.97,221.09,79.02"><row><cell>Team</cell><cell>P</cell><cell>Strict R</cell><cell>F1</cell><cell>P</cell><cell>Fuzzy R</cell><cell>F1</cell></row><row><cell>Cisteria</cell><cell cols="6">0.738 0.500 0.596 0.787 0.534 0.636</cell></row><row><cell cols="7">Ehrmama [27] 0.696 0.542 0.610 0.707 0.551 0.619</cell></row><row><cell>L3i [5]</cell><cell cols="6">0.571 0.712 0.634 0.626 0.780 0.694</cell></row><row><cell>Baseline</cell><cell cols="6">0.814 0.297 0.435 0.814 0.297 0.435</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="3,144.73,646.48,240.57,7.47"><p>https://fasttext.cc/docs/en/pretrained-vectors.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1" coords="3,144.73,657.44,217.03,7.47"><p>https://fasttext.cc/docs/en/crawl-vectors.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2" coords="5,144.73,613.61,203.41,7.47"><p>https://github.com/stefan-it/europeana-bert</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_3" coords="5,144.73,623.92,56.36,7.86"><p>Under review.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_4" coords="5,144.73,635.53,213.32,7.47"><p>https://huggingface.co/bert-base-german-cased</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_5" coords="5,144.73,646.48,141.22,7.47"><p>https://github.com/dbmdz/berts</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_6" coords="5,144.73,657.44,165.25,7.47"><p>http://www.europeana-newspapers.eu/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="11,142.96,142.30,337.63,7.86;11,151.52,153.26,329.07,7.86;11,151.52,164.22,329.07,7.86;11,151.52,175.18,329.07,7.86;11,151.52,186.14,329.07,8.11;11,151.52,197.74,38.16,7.47" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,449.24,142.30,31.34,7.86;11,151.52,153.26,211.37,7.86">FLAIR: An Easy-to-Use Framework for State-of-the-Art NLP</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Blythe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Rasul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Schweter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/N19-4010" />
	</analytic>
	<monogr>
		<title level="m" coord="11,385.11,153.26,95.48,7.86;11,151.52,164.22,329.07,7.86;11,151.52,175.18,115.59,7.86">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06">Jun 2019</date>
			<biblScope unit="page" from="54" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,208.00,337.63,7.86;11,151.52,218.96,329.07,7.86;11,151.52,229.92,329.07,7.86;11,151.52,240.87,329.07,7.86;11,151.52,251.83,329.07,8.12;11,151.52,263.44,165.25,7.47" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,319.06,208.00,161.53,7.86;11,151.52,218.96,107.05,7.86">Pooled Contextualized Embeddings for Named Entity Recognition</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Bergmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/N19-1078" />
	</analytic>
	<monogr>
		<title level="m" coord="11,280.82,218.96,199.78,7.86;11,151.52,229.92,329.07,7.86;11,151.52,240.87,76.53,7.86">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06">Jun 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="724" to="728" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="11,142.96,273.69,337.64,7.86;11,151.52,284.65,329.07,7.86;11,151.52,295.61,329.07,7.86;11,151.52,306.57,321.49,8.12" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,299.84,273.69,180.76,7.86;11,151.52,284.65,33.11,7.86">Contextual String Embeddings for Sequence Labeling</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Akbik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Blythe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Vollgraf</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/C18-1139" />
	</analytic>
	<monogr>
		<title level="m" coord="11,205.98,284.65,274.62,7.86;11,151.52,295.61,41.98,7.86">Proceedings of the 27th International Conference on Computational Linguistics</title>
		<meeting>the 27th International Conference on Computational Linguistics<address><addrLine>Santa Fe, New Mexico, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018-08">Aug 2018</date>
			<biblScope unit="page" from="1638" to="1649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,317.47,337.64,7.86;11,151.52,328.43,329.07,7.86;11,151.52,339.39,329.07,7.86;11,151.52,350.35,329.07,7.86;11,151.52,361.31,329.07,8.12;11,151.52,372.91,165.25,7.47" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,408.82,317.47,71.77,7.86;11,151.52,328.43,142.17,7.86">Cloze-driven Pretraining of Self-attention Networks</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Baevski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Edunov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Auli</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D19-1539" />
	</analytic>
	<monogr>
		<title level="m" coord="11,317.91,328.43,162.68,7.86;11,151.52,339.39,329.07,7.86;11,151.52,350.35,329.07,7.86;11,151.52,361.31,150.38,7.86">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). Association for Computational Linguistics</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). Association for Computational Linguistics<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-11">Nov 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,383.17,337.63,7.86;11,151.52,394.13,329.07,7.86;11,151.52,405.09,329.07,7.86;11,151.52,416.05,329.07,7.86;11,151.52,427.00,199.86,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,244.97,394.13,235.63,7.86;11,151.52,405.09,109.04,7.86">Robust Named Entity Recognition and Linking on Historical Multilingual Documents</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Boros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Linhares Pontes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Cabrera-Diego</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hamdi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Sidère</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Doucet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,176.95,416.05,303.64,7.86;11,151.52,427.00,119.03,7.86">CLEF 2020 Working Notes. Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,437.91,337.64,7.86;11,151.52,448.86,329.07,7.86;11,151.52,459.82,329.07,7.86;11,151.52,470.78,329.07,8.12;11,151.52,482.39,14.12,7.47" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,431.40,437.91,49.19,7.86;11,151.52,448.86,75.42,7.86">Corpus RE-DEWIEDERGABE</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Brunner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Engelberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Jannidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">D T</forename><surname>Tu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Weimer</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/2020.lrec-1.100" />
	</analytic>
	<monogr>
		<title level="m" coord="11,249.45,448.86,231.15,7.86;11,151.52,459.82,62.64,7.86">Proceedings of The 12th Language Resources and Evaluation Conference</title>
		<meeting>The 12th Language Resources and Evaluation Conference<address><addrLine>seille, France</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2020-05">Mar-. May 2020</date>
			<biblScope unit="page" from="803" to="812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,492.64,337.64,7.86;11,151.52,503.60,329.07,7.86;11,151.52,514.56,329.07,7.86;11,151.52,525.52,292.81,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,263.68,492.64,216.91,7.86;11,151.52,503.60,190.46,7.86">Multilingual Named Entity Recognition on Historical Texts Using Transfer and Multi-Task Learning</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Craita</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">C</forename><surname>Cercel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,267.47,514.56,213.12,7.86;11,151.52,525.52,211.99,7.86">CLEF 2020 Working Notes. Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névé Ol</surname></persName>
		</editor>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,536.42,337.64,7.86;11,151.52,547.38,329.07,7.86;11,151.52,558.34,329.07,7.86;11,151.52,569.30,329.07,7.86;11,151.52,580.26,329.07,7.86;11,151.52,591.22,287.62,8.12" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,363.52,536.42,117.07,7.86;11,151.52,547.38,228.38,7.86">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/N19-1423" />
	</analytic>
	<monogr>
		<title level="m" coord="11,403.80,547.38,76.79,7.86;11,151.52,558.34,329.07,7.86;11,151.52,569.30,209.93,7.86">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Minneapolis, Minnesota</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-06">Jun 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="11,142.96,602.12,337.64,7.86;11,151.52,613.08,321.35,7.86" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Flückiger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clematide</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.3677171</idno>
		<ptr target="https://doi.org/10.5281/zenodo.3677171" />
		<title level="m" coord="11,397.56,602.12,83.03,7.86;11,151.52,613.08,97.80,7.86">HIPE -Shared Task Participation Guidelines</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,623.98,337.97,7.86;11,151.52,634.94,305.20,7.86" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Flückiger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clematide</surname></persName>
		</author>
		<idno type="DOI">10.5281/zenodo.3604227</idno>
		<ptr target="https://doi.org/10.5281/zenodo.3604227" />
		<title level="m" coord="11,386.71,623.98,93.88,7.86;11,151.52,634.94,90.99,7.86">Impresso Named Entity Annotation Guidelines</title>
		<imprint>
			<date type="published" when="2020-01">Jan 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,645.84,337.98,7.86;11,151.52,656.80,329.07,7.86;12,151.52,119.67,329.07,7.86;12,151.52,130.63,329.07,7.86;12,151.52,141.59,329.07,7.86;12,151.52,152.55,329.07,7.86;12,151.52,163.51,202.68,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,402.56,645.84,78.03,7.86;11,151.52,656.80,310.64,7.86">Overview of CLEF HIPE 2020: Named Entity Recognition and Linking on Historical Newspapers</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romanello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Flückiger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clematide</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,385.32,130.63,95.27,7.86;12,151.52,141.59,329.07,7.86;12,151.52,152.55,205.76,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction. Proceedings of the 11th International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="12,388.20,152.55,92.40,7.86;12,151.52,163.51,81.27,7.86">Lecture Notes in Computer Science (LNCS</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Joho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Lioma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020. 2020</date>
			<biblScope unit="volume">12260</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,175.48,337.98,7.86;12,151.52,186.44,329.07,7.86;12,151.52,197.39,329.07,7.86;12,151.52,208.35,329.07,7.86;12,151.52,219.31,329.07,7.86;12,151.52,230.27,329.07,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,266.88,175.48,213.71,7.86;12,151.52,186.44,104.93,7.86">BPEmb: Tokenization-free Pre-trained Subword Embeddings in 275 Languages</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Heinzerling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,331.73,208.35,148.87,7.86;12,151.52,219.31,329.07,7.86;12,151.52,230.27,163.10,7.86">Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018). European Language Resources Association (ELRA)</title>
		<editor>
			<persName><forename type="first">)</forename><surname>Chair</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">C C</forename><surname>Choukri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Cieri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Declerck</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Goggi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Hasida</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Isahara</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Maegaard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Mariani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Mazo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Moreno</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Odijk</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Piperidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Tokunaga</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename></persName>
		</editor>
		<meeting>the Eleventh International Conference on Language Resources and Evaluation (LREC 2018). European Language Resources Association (ELRA)<address><addrLine>Miyazaki, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018">May 7-12, 2018 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,242.24,337.97,7.86;12,151.52,253.20,329.07,7.86;12,151.52,264.16,329.07,7.86;12,151.52,275.12,329.07,7.86;12,151.52,286.72,193.49,7.47" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,281.15,242.24,199.44,7.86;12,151.52,253.20,259.59,7.86">Sequence Tagging with Contextual and Non-Contextual Subword Representations: A Multilingual Evaluation</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Heinzerling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Strube</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/P19-1027" />
	</analytic>
	<monogr>
		<title level="m" coord="12,432.52,253.20,48.07,7.86;12,151.52,264.16,309.47,7.86">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07">Jul 2019</date>
			<biblScope unit="page" from="273" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,298.04,337.98,7.86;12,151.52,309.00,159.05,7.86" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="12,261.55,298.04,215.01,7.86">Bidirectional LSTM-CRF models for sequence tagging</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.01991</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="12,142.62,320.97,337.98,7.86;12,151.52,331.93,329.07,7.86;12,151.52,342.89,329.07,7.86;12,151.52,353.85,217.78,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="12,269.25,320.97,211.34,7.86;12,151.52,331.93,115.35,7.86">Named Entity Disambiguation and Linking Historic Newspaper OCR with BERT</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Labusch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Neudecker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,190.17,342.89,290.42,7.86;12,151.52,353.85,136.96,7.86">CLEF 2020 Working Notes. Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,365.81,337.98,7.86;12,151.52,376.77,329.07,7.86;12,151.52,387.73,329.07,7.86;12,151.52,398.69,329.07,7.86;12,151.52,409.65,25.60,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="12,329.41,365.81,151.18,7.86;12,151.52,376.77,141.47,7.86">Bert for named entity recognition in contemporary and historic german</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Labusch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Neudecker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zellhöfer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,317.67,376.77,162.92,7.86;12,151.52,387.73,118.94,7.86">Proceedings of the 15th Conference on Natural Language Processing</title>
		<title level="s" coord="12,355.22,387.73,49.18,7.86">Long Papers</title>
		<meeting>the 15th Conference on Natural Language Processing<address><addrLine>KONVENS; Erlangen, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>German Society for Computational Linguistics &amp; Language Technology</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,421.62,337.98,7.86;12,151.52,432.58,329.07,7.86;12,151.52,443.53,280.01,8.12" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="12,269.49,421.62,211.10,7.86;12,151.52,432.58,135.59,7.86">Mixout: Effective Regularization to Finetune Largescale Pretrained Language Models</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kang</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=HkgaETNtDB" />
	</analytic>
	<monogr>
		<title level="m" coord="12,308.31,432.58,172.29,7.86;12,151.52,443.53,48.00,7.86">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,455.50,337.98,7.86;12,151.52,466.46,277.98,7.86" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="12,256.25,455.50,224.34,7.86;12,151.52,466.46,94.23,7.86">Exploring Cross-sentence Contexts for Named Entity Recognition with BERT</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Luoma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Pyysalo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2006.01563</idno>
		<imprint>
			<date type="published" when="2020-06">Jun 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
</biblStruct>

<biblStruct coords="12,142.62,478.43,337.98,7.86;12,151.52,489.39,329.07,7.86;12,151.52,500.35,291.73,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="12,411.85,478.43,68.75,7.86;12,151.52,489.39,175.34,7.86">Advances in Pre-Training Distributed Word Representations</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Puhrsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,349.24,489.39,131.35,7.86;12,151.52,500.35,263.05,7.86">Proceedings of the International Conference on Language Resources and Evaluation (LREC 2018)</title>
		<meeting>the International Conference on Language Resources and Evaluation (LREC 2018)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,512.31,337.98,7.86;12,151.52,523.27,329.07,7.86;12,151.52,534.23,329.07,7.86;12,151.52,545.19,329.07,8.12;12,151.52,556.80,85.23,7.47" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="12,213.62,512.31,266.97,7.86;12,151.52,523.27,24.85,7.86">An Open Corpus for Named Entity Recognition in Historic Newspapers</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Neudecker</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/L16-1689" />
	</analytic>
	<monogr>
		<title level="m" coord="12,199.22,523.27,281.37,7.86;12,151.52,534.23,137.26,7.86">Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)</title>
		<meeting>the Tenth International Conference on Language Resources and Evaluation (LREC&apos;16)<address><addrLine>Portorož, Slovenia</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA)</publisher>
			<date type="published" when="2016-05">May 2016</date>
			<biblScope unit="page" from="4348" to="4352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,568.12,337.98,7.86;12,151.52,579.08,329.07,7.86;12,151.52,590.04,329.07,7.86;12,151.52,600.99,329.07,7.86;12,151.52,611.95,199.86,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="12,368.70,568.12,111.89,7.86;12,151.52,579.08,329.07,7.86;12,151.52,590.04,98.50,7.86">SinNer@Clef-Hipe2020: Sinful adaptation of SotA models for Named Entity Recognition in historical French and German newspapers</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ortiz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pedro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Dupont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Lejeune</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,176.95,600.99,303.64,7.86;12,151.52,611.95,119.03,7.86">CLEF 2020 Working Notes. Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névé Ol</surname></persName>
		</editor>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,623.92,337.98,7.86;12,151.52,634.88,329.07,7.86;12,151.52,645.84,329.07,7.86;12,151.52,656.80,265.17,7.86" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="12,455.89,623.92,24.70,7.86;12,151.52,634.88,164.70,7.86">CLEF HIPE Working Notes: UvA ILPS &amp; REL</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Provatorova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vakulenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Dercksen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Van Hulst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,240.37,645.84,240.22,7.86;12,151.52,656.80,184.34,7.86">CLEF 2020 Working Notes. Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névé Ol</surname></persName>
		</editor>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,119.67,337.98,7.86;13,151.52,130.63,329.07,7.86;13,151.52,141.59,329.07,7.86;13,151.52,152.55,306.28,8.11" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="13,251.96,119.67,228.63,7.86;13,151.52,130.63,29.92,7.86">Towards Robust Named Entity Recognition for Historic German</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Schweter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Baiter</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/W19-4312" />
	</analytic>
	<monogr>
		<title level="m" coord="13,206.37,130.63,274.22,7.86;13,151.52,141.59,94.58,7.86">Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019)</title>
		<meeting>the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019)<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-08">Aug 2019</date>
			<biblScope unit="page" from="96" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,163.51,337.98,7.86;13,151.52,174.47,329.07,7.86;13,151.52,185.43,329.07,7.86;13,151.52,196.39,329.07,7.86;13,151.52,207.99,193.49,7.47" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="13,304.53,163.51,176.06,7.86;13,151.52,174.47,82.93,7.86">Neural Machine Translation of Rare Words with Subword Units</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Birch</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/P16-1162" />
	</analytic>
	<monogr>
		<title level="m" coord="13,259.38,174.47,221.22,7.86;13,151.52,185.43,166.44,7.86">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-08">Aug 2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1715" to="1725" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct coords="13,142.62,218.30,337.98,7.86;13,151.52,229.26,47.99,7.86;13,134.77,240.22,345.83,7.86;13,151.52,251.18,329.07,7.86;13,151.52,262.14,329.07,7.86;13,151.52,273.10,292.81,7.86" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="13,300.18,218.30,180.42,7.86;13,151.52,229.26,47.99,7.86;13,134.77,240.22,7.85,7.86;13,362.51,240.22,118.09,7.86;13,151.52,251.18,193.53,7.86">Enrichement-based Oversampling for Coarse-grained NER in Historical Text</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Souza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Lotufo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tobollik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,267.47,262.14,213.12,7.86;13,151.52,273.10,211.99,7.86">CLEF 2020 Working Notes. Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névé Ol</surname></persName>
		</editor>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Portuguese Named Entity Recognition using BERT-CRF 26</note>
</biblStruct>

<biblStruct coords="13,142.62,284.06,337.98,7.86;13,151.52,295.02,329.07,7.86;13,151.52,305.98,329.07,7.86;13,151.52,316.93,177.67,7.86" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="13,268.35,284.06,212.24,7.86;13,151.52,295.02,73.71,7.86">Transfer Learning for Named Entity Recognition in Historical Corpora</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Todorov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Colavizza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,151.52,305.98,329.07,7.86;13,151.52,316.93,96.85,7.86">CLEF 2020 Working Notes. Working Notes of CLEF 2020 -Conference and Labs of the Evaluation Forum</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<imprint>
			<publisher>CEUR-WS</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,327.89,337.97,7.86;13,151.52,338.83,329.07,7.89;13,151.52,350.46,145.93,7.47" xml:id="b26">
	<monogr>
		<title level="m" type="main" coord="13,230.35,338.85,108.72,7.86">Attention Is All You Need</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<idno>CoRR abs/1706.03762</idno>
		<ptr target="http://arxiv.org/abs/1706.03762" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,360.77,337.98,7.86;13,151.52,371.73,329.07,7.86;13,151.52,382.69,329.07,7.86;13,151.52,393.65,329.07,7.86;13,151.52,404.61,174.95,7.86" xml:id="b27">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shleifer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Von Platen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jernite</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Plu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Le Scao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gugger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Drame</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Lhoest</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Rush</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1910.03771</idno>
		<title level="m" coord="13,177.22,393.65,299.28,7.86">HuggingFace&apos;s Transformers: State-of-the-art Natural Language Processing</title>
		<imprint>
			<date type="published" when="2019-10">Oct 2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
