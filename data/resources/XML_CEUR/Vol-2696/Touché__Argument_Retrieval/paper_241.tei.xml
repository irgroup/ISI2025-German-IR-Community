<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,154.84,115.90,305.69,12.90;1,135.25,135.75,344.86,10.75">Exploring Argument Retrieval with Transformers Notebook for the Touché Lab on Argument Retrieval at CLEF 2020</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,231.02,172.15,72.23,8.64"><forename type="first">Christopher</forename><surname>Akiki</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Leipzig University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,322.62,172.15,61.72,8.64"><forename type="first">Martin</forename><surname>Potthast</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Leipzig University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,154.84,115.90,305.69,12.90;1,135.25,135.75,344.86,10.75">Exploring Argument Retrieval with Transformers Notebook for the Touché Lab on Argument Retrieval at CLEF 2020</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C9E223D1AE3E18606E5812792626A088</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We report on our recent efforts to employ transformer-based models as part of an information retrieval pipeline, using argument retrieval as a benchmark. Transformer models, both causal and bidirectional, are independently used to expand queries using generative approaches as well as to densely embed and retrieve arguments. In particular, we investigate three approaches: (1) query expansion using GPT-2, (2) query expansion using BERT, and orthogonal to these approaches, (3) embedding of documents using Google's BERT-like universal sentence encoder (USE) combined with a subsequent retrieval step based on a nearest-neighbor search in the embedding space. A comparative evaluation of our approaches at the Touché lab on argument retrieval places our query expansion based on GPT-2 first on the leaderboard with a retrieval performance of 0.808 nDCG@5, improving over the task baseline by 6.878%.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Search has become the sine qua non tool of information access, and the gateway to the World Wide Web. The users of web search engines meanwhile expect a high quality of the search results in terms of their relevance to the queries submitted: If relevant documents exist for a given query, they are usually found, and the most relevant ones can be expected to be ranked highest. However, search engines are optimized for ad hoc retrieval tasks, and a key assumption is that a single document suffices to satisfy the information need underlying a query. That assumption falls apart when the topic of interest is inherently subjective and nuanced, such as is the case for contentious issues. Any one document will most likely argue one way or another, so that a user may need to peruse many documents at a time to satisfy a deliberative information need. The current search landscape is, however, not especially attuned to such a nuance, usually preferring to let "the stakeholders compete for what opinion ranks higher" <ref type="bibr" coords="1,401.86,561.56,15.27,8.64" target="#b22">[23]</ref>. The ability to specifically handle arguments rather than the documents that might contain them is an attempt to address that problem using computational argumentation analysis <ref type="bibr" coords="1,446.00,585.47,15.77,8.64" target="#b22">[23,</ref><ref type="bibr" coords="1,464.82,585.47,11.83,8.64" target="#b30">31]</ref>. Such an approach forms the basis of the args.me search engine which relies on a corpus of more than 300,000 arguments mined from online debate portals <ref type="bibr" coords="1,414.62,609.38,10.58,8.64" target="#b0">[1]</ref>. This corpus formed the basis of the Touché shared task on argument retrieval <ref type="bibr" coords="1,394.75,621.34,10.58,8.64" target="#b2">[3]</ref>.</p><p>We leverage transformer models to see how they might enrich argument retrieval at various stages of the information retrieval (IR) pipeline. Attention-based transformer models <ref type="bibr" coords="2,166.07,143.22,16.60,8.64" target="#b29">[30]</ref> have seen a recent surge in popularity as their readiness for massive parallelization and the increasing availability of computational power on GPUs led to such models claiming the state-of-the-art crown on many natural language processing and understanding tasks <ref type="bibr" coords="2,215.96,179.09,10.79,8.64" target="#b6">[7,</ref><ref type="bibr" coords="2,229.16,179.09,11.83,8.64" target="#b24">25]</ref>. We show that competitive performance can be achieved on this task with no preprocessing of the documents or fine-tuning of the models on the task. In what follows, Section 2 presents related work, Section 3 exposes our approach, and Section 4 presents the results of our participation in the shared task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Although the subject of arguments in a retrieval context is by no means a new development (see, e.g., <ref type="bibr" coords="2,210.64,282.70,16.60,8.64" target="#b25">[26]</ref> and <ref type="bibr" coords="2,248.68,282.70,14.94,8.64" target="#b27">[28]</ref>), the field itself is still nascent. Lawrence and Reed <ref type="bibr" coords="2,134.77,294.66,15.27,8.64" target="#b17">[18]</ref>, Potthast et al. <ref type="bibr" coords="2,212.95,294.66,15.27,8.64" target="#b22">[23]</ref>, and Wachsmuth et al. <ref type="bibr" coords="2,322.74,294.66,16.60,8.64" target="#b30">[31]</ref> provide a comprehensive overview of the field, with the last two further putting forth the theoretical considerations that underlie the development of a tool where arguments form the unit of retrieval, using the args.me dataset <ref type="bibr" coords="2,199.76,330.52,11.62,8.64" target="#b0">[1]</ref> to ground the theory in an applied retrieval study. Another salient research direction is spearheaded by IBM's Project Debater and corresponding studies that leverage its numerous datasets (see <ref type="bibr" coords="2,294.29,354.43,16.60,8.64" target="#b28">[29]</ref> for an overview of the project).</p><p>The growing interest of natural language processing (NLP) researchers in information retrieval and argument mining <ref type="bibr" coords="2,273.76,378.34,15.27,8.64" target="#b26">[27]</ref>, as well as the impressive performance and ease of use of transformer-based models <ref type="bibr" coords="2,276.89,390.30,16.60,8.64" target="#b31">[32]</ref> and their propensity to semantic nuance makes a convergence of the two unavoidable. Indeed, researchers in IBM's project debater have recently published two corresponding papers <ref type="bibr" coords="2,340.63,414.21,10.79,8.64" target="#b8">[9,</ref><ref type="bibr" coords="2,354.54,414.21,13.28,8.64" target="#b13">14]</ref> that both use BERT <ref type="bibr" coords="2,454.24,414.21,11.62,8.64" target="#b6">[7]</ref> for argument retrieval and argument quality assessment. Like other efforts in the argument mining direction <ref type="bibr" coords="2,203.15,438.12,10.79,8.64" target="#b5">[6,</ref><ref type="bibr" coords="2,216.31,438.12,11.83,8.64" target="#b10">11]</ref>, these methods, though impressive in their results, do not readily transfer to a domain other than that of the retrieval of arguments because they are usually fine-tuned on a specific document corpus.</p><p>The use of transformers in general, specifically BERT, to the field of document retrieval was until very recently limited to frameworks where initial retrieval is delegated to the Lucene-based Anserini retrieval toolkit <ref type="bibr" coords="2,348.04,497.89,15.77,8.64" target="#b33">[34,</ref><ref type="bibr" coords="2,367.16,497.89,11.83,8.64" target="#b32">33]</ref>, which, while proving a promising approach, did not attempt to instrumentalize transformers at different parts of the IR pipeline. Another approach similarly leverages BERT and Anserini for ad hoc document retrieval, while also coupling the approach with the ability to interface with Python to simplify neural network based research <ref type="bibr" coords="2,334.71,545.71,15.27,8.64" target="#b34">[35]</ref>.</p><p>The semantic prowess of transformers makes them prime candidates for enriching IR pipelines that rely on query expansion <ref type="bibr" coords="2,299.49,569.62,10.58,8.64" target="#b1">[2]</ref>. For a deeper coverage of query expansion we refer the reader to Azad and Deepak's <ref type="bibr" coords="2,309.20,581.58,11.62,8.64" target="#b1">[2]</ref> thorough survey on the topic. In brief, query expansion consists in augmenting a user query to increase its effectiveness and reduce ambiguity. That is achieved through reformulating the query using additional data, and the source of that data coincides with the different sub-approaches of this sub-field of IR. Azad and Deepak <ref type="bibr" coords="2,270.91,629.40,11.62,8.64" target="#b1">[2]</ref> differentiate between two main directions: global analysis and local analysis. The latter relies on user feedback, both direct and implicit, whereas the former consists of approaches that rely on knowledge that can be gleaned and derived from the query itself or its context. These include linguistic, corpus-based, log-based and web-based approaches. Global analysis has proven to be of particular interest for transformer-focused research <ref type="bibr" coords="3,300.37,143.22,10.79,8.64" target="#b7">[8,</ref><ref type="bibr" coords="3,313.88,143.22,12.45,8.64" target="#b21">22,</ref><ref type="bibr" coords="3,329.07,143.22,12.45,8.64" target="#b18">19,</ref><ref type="bibr" coords="3,344.24,143.22,11.83,8.64" target="#b20">21]</ref>. The work of Dibia <ref type="bibr" coords="3,439.94,143.22,11.62,8.64" target="#b7">[8]</ref> in particular aligns nicely with our approach in Section 3.2. Our approaches differ however in the strategies used to determine where and how to inject context. To our knowledge, the query expansion approach we develop in Section 3.1 is the first use of a transformer decoder (GPT-2 in this instance) to generate documents that read as though they might have originated from a corpus of interest, at least plausibly enough for a retrieval system, and thus narrow down the scope of search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Using Transformers for Document Retrieval</head><p>We set out to instrumentalize for the retrieval of documents the ability of different transformers to encode knowledge. The original transformer introduced by Vaswani et al. <ref type="bibr" coords="3,157.42,294.66,16.60,8.64" target="#b29">[30]</ref> uses a standard seq2seq encoder-decoder architecture, whereby the encoder learns a task-specific embedding, and the decoder learns a language model. Subsequent transformer-based models do not necessarily follow that convention. BERT <ref type="bibr" coords="3,447.59,318.57,11.62,8.64" target="#b6">[7]</ref> only uses an encoder, and GPT-2 <ref type="bibr" coords="3,252.75,330.52,16.60,8.64" target="#b24">[25]</ref> only a decoder. It is therefore useful to qualify the rather general "transformer" nomenclature with either "encoder" or "decoder".</p><p>We use transformer decoders (i.e., GPT-2-like models) for query expansion via text hallucination (Section 3.1), i.e., the generation of a text that reads as if it might have come from the corpus, and transformer encoders (i.e., BERT-liked models) for keyword-based query expansion (Section 3.2). Moreover, we consider transformer encoders for document embedding (Section 3.3). Both query expansion approaches make use of an Elasticsearch index where the documents of the args.me corpus were indexed using a language model with Dirichlet priors (DirichletLM) <ref type="bibr" coords="3,371.21,426.16,15.27,8.64" target="#b35">[36]</ref>, which has been shown to be superior to other retrieval models for retrieving arguments from the args.me corpus <ref type="bibr" coords="3,151.88,450.07,15.27,8.64" target="#b22">[23]</ref>. The embedding approach, on the other hand, uses a vector-based similarity index for retrieval.</p><p>Self-supervised pre-training on massive amounts of qualitatively diverse data is what enables transformer models to encode the knowledge that allows them to perform as well as they do on natural language processing (NLP) and natural language understanding (NLU) tasks. Therein also lies their promise for retrieval tasks. We make the conscious decision to only rely on the knowledge encoded into the models by these tasks; that is, we do not rely on any argumentation-specific fine-tuning. That allows us to gauge the performance of transformers for retrieval tasks in general. In particular, our investigation aims at a modular proof-of-concept approach, not to show the superiority of a certain method over others, nor was it our goal to optimize the ensuing pipeline for accuracy on the relevance judgments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Query Expansion with a Transformer Decoder</head><p>A lot of the recent media hype around transformer networks is centered around their ability to generate coherent text. Transformer decoders can be trained as causal language models (CLM), seeing as the representation of a given token can only depend on the tokens preceding it. Indeed, since transformer decoders like GPT-2 simulate language models, it is possible to iteratively generate sentences by sampling from the output distribution at a given time step and feeding that output back into the network at the following time step. By choosing an opening for a text (called prompt), it becomes thus possible to steer GPT-2 and exert some influence over the text it generates. Our approach for query expansion makes use of this capability to generate argumentative expansions of a given query with a positive, negative, and a neutral stance by prompting GPT-2 in turn with the six prompts shown in Table <ref type="table" coords="4,353.02,308.75,3.74,8.64" target="#tab_0">1</ref>. The prompts are purposefully constructed so as to simulate an argumentative dialog that is to be completed by GPT-2.</p><p>The quality of generated sequences, and thus also of our retrieval results, is highly contingent upon the way in which tokens are sampled from the network. It is easy for neural language models to degenerate into incoherent, non-human sounding text when using naive likelihood maximization <ref type="bibr" coords="4,307.50,368.53,15.27,8.64" target="#b15">[16]</ref>. Many sampling methods exist that try to make sure the generated text is less likely to be incoherent, repetitive, or overly generic <ref type="bibr" coords="4,167.03,392.44,15.77,8.64" target="#b11">[12,</ref><ref type="bibr" coords="4,185.75,392.44,12.45,8.64" target="#b12">13,</ref><ref type="bibr" coords="4,201.16,392.44,12.04,8.64" target="#b15">16]</ref>; the following sampling approaches are the most salient ones, ordered from basic to advanced:</p><p>-Pure sampling is the most naive as well as often the worst-performing sampling method. It consists of greedily choosing the most likely token at every time step. This sampling method usually leads to low quality text. -Beam Search is a heuristic that keeps a set number of candidate sequences until they all reach the desired length and keeps the most likely candidate. Search for the output sequence that actually maximizes likelihood is intractable, so that beam search provides a reasonable alternative in practice. -Temperature scaling reshapes the output distribution by skewing it either toward high probability tokens or low probability tokens: the former improves generation quality but hurts diversity <ref type="bibr" coords="4,259.02,531.92,15.27,8.64" target="#b15">[16]</ref>, while the latter regularizes generation by making the model less certain of its top choices. -Top-k sampling is the sampling method that was used for GPT-2 <ref type="bibr" coords="4,413.89,555.83,15.27,8.64" target="#b24">[25]</ref>. It truncates the language model's output distribution to a set of size k of most likely tokens. The sampling then uses relative probability within this truncated set. All other tokens are not considered for generation. -Nucleus sampling is a stochastic decoding method proposed by Holtzman et al. <ref type="bibr" coords="4,151.70,615.60,15.27,8.64" target="#b15">[16]</ref>. Similar to top-k sampling, it also truncates the output distribution, albeit by setting a threshold the cumulative distribution of top tokens must reach before discarding the rest of the tokens.</p><p>For each one of the six prompts in Table <ref type="table" coords="5,318.39,119.31,3.74,8.64" target="#tab_0">1</ref>, we use GPT-2 to generate four possible continuations up to a maximum of 100 tokens. To ensure the four continuations are different from each other, we chose different combinations of the aforementioned sampling strategies. <ref type="foot" coords="5,197.70,153.51,3.49,6.05" target="#foot_0">1</ref> Having framed the prompts as conversational (by virtue of the dashes and formatting), the ensuing generated text often tends to read like an argument. Having generated 24 such texts, <ref type="foot" coords="5,245.06,177.42,3.49,6.05" target="#foot_1">2</ref> we discard the original query and use these hallucinations as 24 queries against the DirichletLM index, which we combine additively to generate the final rankings. We only consider those documents which were returned by at least twelve of the queries simultaneously. <ref type="foot" coords="5,282.56,213.28,3.49,6.05" target="#foot_2">3</ref>For illustration purposes, consider the query "Can alternative energy effectively replace fossil fuels?". Three of the 24 texts that our approach generates are:</p><p>-Yes, because it has proven to be a significant and lasting improvement in fuel efficiency, carbon neutrality. The only other thing that could possibly help this energy is the need for nuclear reactors at low cost which would require more than 20 percent of current generation electricity by 2030 (currently under construction), plus less renewable resources like wind or solar power as well but with sufficient amounts of coal/solar panels if there are enough [sic]</p><p>-No, because there is no evidence for that. There are a few possible alternative energy options available to people who would like to cut down fossil fuels, and I believe those include wind or solar power."The main thing we want in our future climate policies has to be better use of resources instead on these things than if they weren't used at the moment," said Kieferlein. "We need clean air [sic]</p><p>-Not sure. However, many scientists have made the point that alternative sources of power are already producing more carbon emissions than they would otherwise (and it seems like such a small number in our country). There has been some debate about whether this was actually true or if there simply wasn't much coal available at all to replace fossil fuels and other forms thereof as an environmentally sustainable form. . . In fact, recent studies suggest we [sic]</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Query Expansion with a Transformer Encoder</head><p>Unlike transformer decoders, transformer encoders like BERT <ref type="bibr" coords="5,392.73,508.85,11.62,8.64" target="#b6">[7]</ref> cannot be used to auto-regressively generate sentences. Their attention-based architecture is such that any token can see ("attend to") any other token of the sentence. Being able to look ahead into the future of a sequence breaks the causality required by a CLM. As such, these models have to rely on other pre-training tasks to gain linguistic coherence. Global linguistic coherence is achieved through next sentence prediction, where BERT has to predict whether two sentences follow each other in a corpus. Local coherence is achieved through another pre-training task, namely masked language modeling (MLM). During training, tokens in the input are masked at random and the network is tasked with guessing what that word was. Learning to fill in the blank has been shown to imporve the quality of text generation <ref type="bibr" coords="6,252.21,392.29,15.27,8.64" target="#b9">[10]</ref>.</p><p>We leverage this ability of the model to "fill in the blank" to enrich the original query with a set of words that are contextually relevant to the topic at hand. To achieve that, we again augment the original query using the same strategy as outlined in the previous section, this time, however, we leave blanks for BERT to fill out in the form of the [MASK] token (see Table <ref type="table" coords="6,255.61,452.07,3.60,8.64" target="#tab_1">2</ref>). For every [MASK] in every augmented seed text, we ask BERT to return the five most likely words, filtering out stop words, punctuation, and sub-words. This amounts to an average (min=206, max=473) of 340 thematic keywords per query. All keywords are then joined together into a space-separated list of keywords which is what we use to query the DirichletLM index, discarding the original query. For illustration, consider the query "Can Alternative Energy Effectively Replace Fossil Fuels?" and provide the resulting keywords when expanding the query with BERT: diesel, cost, nuclear, consumption, hydrogen, technologies, energy, future, electricity, pregnancy, coal, alternative, migration, emissions, efficiency, economics, technology, growth, wartime, earthquakes, green, environmental, accidents, costs, renewable, winter, development, pollution, new, stress, water, oil, accident, death, health, warming, sustainability, accidental, fires, competition</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Document Embedding with a Transformer Encoder</head><p>Our final approach also employs a transformer encoder in the form of the large variant of Google's universal sentence encoder (USE) <ref type="bibr" coords="6,328.09,656.44,10.58,8.64" target="#b4">[5]</ref>. Though architecturally similar to BERT, the USE model is trained with very different pre-training tasks, which were specifically picked to perform well on downstream NLU tasks with the goal of creating a sentence embedder. A further distinction to BERT is USE's unbounded input length, which lends itself well to the args.me corpus. The following pre-training tasks were considered:</p><p>-Skip-thought is a self-supervised pretraining task, originally devised to use LSTMs to provide high-quality sentence vectors by training on a large amount of contiguous text <ref type="bibr" coords="7,185.31,207.20,15.27,8.64" target="#b16">[17]</ref>. -Natural language response suggestion imparts conversational awareness to the sentence encoder, which fits quite well to the task at hand. The goal of this supervised task is to predict the best short reply among millions of options in response to an email <ref type="bibr" coords="7,176.33,254.27,15.27,8.64" target="#b14">[15]</ref>. -Stanford natural language inference is a labeled dataset <ref type="bibr" coords="7,383.61,265.47,11.62,8.64" target="#b3">[4]</ref> of 570,000 sentence pairs. This can be seen as a supervised variant of BERT's next sentence prediction pre-training task. In this instance however, entailment, contradiction, and irrelevance are explicitly labeled in the data itself, rather than implied by the relative position of two sentences in an unlabeled corpus of contiguous text.</p><p>These pre-training tasks make USE a great candidate for argument retrieval. Using USE, we embed each document in the args.me corpus into a 512-dimensional space. To retrieve arguments given a query, we embed the query using the same model into the same space, and perform exhaustive nearest-neighbor search, <ref type="foot" coords="7,357.19,364.40,3.49,6.05" target="#foot_3">4</ref> considering both L2 distance and inner-product (IP) distance for retrieval. We carried out a small pilot experiment to make sure USE projects the args.me corpus in a semantically meaningful way by running k-means on the embedded corpus, choosing a cluster size of 100. The clusters obtained are both syntactically and semantically coherent in a way that is surprisingly meaningful. Some clusters are thematically coherent, encompassing topics, such as religion, politics, and economics. Others are both syntactically and semantically coherent, where all premises are of the form "X is better than Y" and covering themes such as video game consoles, superheroes, and consumer electronics. Further clusters are only syntactically coherent, where, for instance, all arguments consist of YouTube links or of repeated short idiosyncratic phrases one tends to find on online debate websites (e.g., "I agree.").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>The evaluation of our approaches to argument retrieval was carried out as part of the Touché shared task. In what follows, we briefly recap the experimental setup and overview the performance achieved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Experimental Setup</head><p>The Touché shared task on argument retrieval <ref type="bibr" coords="7,333.96,615.05,11.62,8.64" target="#b2">[3]</ref> uses the TIRA evaluation platform <ref type="bibr" coords="7,157.66,627.00,16.60,8.64" target="#b23">[24]</ref> to judge entries to the competition. On TIRA every task participant is assigned their own virtual machine, and submitting a retrieval model to the shared task corresponds to submitting software to be run on that virtual machine with the relevant inputs provided by TIRA at run time. Those inputs include the args.me corpus and a list of 50 topics (queries) on which the retrieval model is to be judged using crowdsourced relevance judgments. Though participant entries are ranked by nDCG@5 scores on the leaderboard, <ref type="foot" coords="8,184.28,298.61,3.49,6.05" target="#foot_4">5</ref> TIRA also returns nDCG@10, nDCG, and QrelCoverage@10, which we include in Table <ref type="table" coords="8,201.21,312.24,3.74,8.64" target="#tab_2">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results</head><p>The results of all our runs are included in Table <ref type="table" coords="8,323.53,362.05,3.74,8.64" target="#tab_2">3</ref>, where one can clearly see the considerable improvement over the official baseline by our GPT-2 query expansion approach, which comes out on top of the leaderboard. Our BERT query expansion model basically ties with the baseline of 0.756 as it manages to score an nDCG@5 score of 0.755. We speculate that this performance might be partly due to the fact that both the args.me corpus and the datasets on which BERT and GPT-2 are trained consist of user-generated internet data. Both embedding-based runs perform worse than the query expansion approaches and that is to be expected, as the only information signal afforded to those runs originates in the query itself, whereas the other approaches had the benefit of considerable added context through query expansion. Still, judging the embeddings on their own constitutes a useful baseline. A promising approach would combine these two orthogonal approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This work showcases three possible uses of transformer models for the retrieval of relevant arguments from the args.me corpus in particular, and document retrieval from a corpus in general. Impressive results were achieved without hyperparameter tuning or optimization of any sort. A promising future continuation of this work would be an ablation study that judges the effect that the hyperparameters have on retrieval-optimized text generation. Such a continuation would be necessary to judge the quantitative merits of each approach.</p><p>It is also important to note that BERT and GPT-2 are merely the representatives of the transformer family of models. There exists a myriad of models<ref type="foot" coords="9,420.98,129.60,3.49,6.05" target="#foot_5">6</ref> that build on the foundations laid down by the works that introduced them, iterating, improving, and filling gaps those original models did not take into account. It would therefore be important to experiment with other models, perhaps also come up with new pre-training tasks that would make query expansion even more performant.</p><p>Furthermore, our approach leaves out any sort of natural language preprocessing of the corpus or fine-tuning of any of the used models. That some approaches perform as well as they do is a testament to the amount of linguistic and world knowledge encoded in the weights of pre-trained transformers. A future research direction might leverage the args.me and Project Debater corpora to add more argumentative awareness to the transformers and indubitably improve retrieval results.</p><p>Finally, we believe it crucial to sensibly modulate any research direction with the due ethical considerations of such projects. It is unclear whether to include user feedback, as including such signals would incur the risk of calcifying existing biases. While it might be useful to think of a search engine as an educational tool, it might prove dangerous to assume it is the prerogative of an information retrieval technology to monopolize the task of teaching its users how to think by conditioning them to blindly rely on it to populate their existing biases.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,134.77,115.83,345.83,85.86"><head>Table 1 .</head><label>1</label><figDesc>Language model prompts for argumentative query expansion. The dots (. . . ) indicate where the language model takes over and generates text that is used as expanded query.</figDesc><table coords="4,134.94,149.64,345.48,52.05"><row><cell>Positive Prompt</cell><cell>Negative Prompt</cell><cell>Neutral Prompt</cell></row><row><cell>-What do you think? &lt;query&gt;</cell><cell>-What do you think? &lt;query&gt;</cell><cell>-What do you think? &lt;query&gt;</cell></row><row><cell>-Yes because . . .</cell><cell>-No because . . .</cell><cell>-I don't know . . .</cell></row><row><cell>-What do you think? &lt;query&gt;</cell><cell>-What do you think? &lt;query&gt;</cell><cell>-What do you think? &lt;query&gt;</cell></row><row><cell>-The answer is yes . . .</cell><cell>-The answer is no . . .</cell><cell>-Not sure . . .</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,134.77,115.83,345.82,230.32"><head>Table 2 .</head><label>2</label><figDesc>Masked language model prompts for argumentative query expansion. The masks ([MASK]) indicate where the language model takes over and generates alternative words that are used as expanded query.</figDesc><table coords="6,186.53,160.60,242.31,114.42"><row><cell>Stance</cell><cell>Prompt</cell></row><row><cell></cell><cell>-What do you think? &lt;query&gt;</cell></row><row><cell></cell><cell>-Yes, because of [MASK] and the benefits of [MASK].</cell></row><row><cell>Positive</cell><cell>-What do you think? &lt;query&gt; -Absolutely, I think [MASK] is good!</cell></row><row><cell></cell><cell>-What do you think? &lt;query&gt;</cell></row><row><cell></cell><cell>-Yes, [MASK] is associated with [MASK] during [MASK].</cell></row><row><cell></cell><cell>-What do you think? &lt;query&gt;</cell></row><row><cell></cell><cell>-No, because of [MASK] and the risk of [MASK] [MASK].</cell></row><row><cell>Negative</cell><cell></cell></row></table><note coords="6,234.74,263.42,103.20,6.91;6,234.74,272.39,130.97,6.91;6,234.74,285.64,103.20,6.91;6,234.74,294.61,191.45,6.91;6,186.53,321.51,23.90,6.91;6,234.74,308.06,103.20,6.91;6,234.74,317.02,115.15,6.91;6,234.74,330.27,103.20,6.91;6,234.74,339.24,97.02,6.91"><p>-What do you think? &lt;query&gt; -Absolutely not, I think [MASK] is bad! -What do you think? &lt;query&gt; -No, [MASK] is associated with [MASK] during [MASK]. Neutral -What do you think? &lt;query&gt; -What about [MASK] or [MASK]? -What do you think? &lt;query&gt; -Don't forget about [MASK]!</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,134.77,115.83,345.83,112.88"><head>Table 3 .</head><label>3</label><figDesc>Evaluation results of our approaches compared to the two runner-ups of the shared task.</figDesc><table coords="8,134.77,139.39,336.53,89.32"><row><cell>Model</cell><cell>nDCG@5</cell><cell>nDCG@10</cell><cell>nDCG</cell><cell>QrelCoverage@10</cell></row><row><cell>GPT-2</cell><cell>0.808</cell><cell>0.586</cell><cell>0.378</cell><cell>5.70</cell></row><row><cell>Baseline (DirichletLM)</cell><cell>0.756</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>BERT</cell><cell>0.755</cell><cell>0.538</cell><cell>0.337</cell><cell>5.36</cell></row><row><cell>Team Aragorn</cell><cell>0.684</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>USE (L2)</cell><cell>0.598</cell><cell>0.397</cell><cell>0.285</cell><cell>4.16</cell></row><row><cell>Team Zorro</cell><cell>0.573</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>USE (IP)</cell><cell>0.527</cell><cell>0.36</cell><cell>0.275</cell><cell>3.82</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="5,138.25,612.17,342.34,7.77;5,138.25,623.13,262.41,7.77"><p>One with greedy sampling using 10 beams, and three using a temperature of 1.6, a top-k threshhold of 100 tokens, and a nucleus sampling probability threshhold of 0.4.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="5,134.77,632.42,2.99,5.18;5,138.25,634.28,143.21,7.77"><p><ref type="bibr" coords="5,134.77,632.42,2.99,5.18" target="#b1">2</ref> Six prompts with four continuations per</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="5,283.70,634.28,28.15,7.77;5,134.77,643.57,2.99,5.18;5,138.25,645.43,342.34,7.77;5,138.25,656.39,70.72,7.77"><p>prompt.<ref type="bibr" coords="5,134.77,643.57,2.99,5.18" target="#b2">3</ref> This corresponds to an Elasticsearch boolean query of type "should" with the min_should_match parameter set to 12.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="7,138.25,657.08,149.13,7.77"><p>https://github.com/facebookresearch/faiss</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="8,138.25,640.71,190.65,7.77"><p>https://events.webis.de/touche-20/shared-task-1.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="9,138.25,649.81,134.90,7.77"><p>https://github.com/thunlp/PLMpapers</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,154.69,389.95,324.52,7.77;9,154.68,400.91,318.73,7.77;9,154.68,411.87,323.12,7.77;9,154.68,422.83,288.35,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,418.19,389.95,61.02,7.77;9,154.68,400.91,149.08,7.77">Data Acquisition for Argument Search: The args.me corpus</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-30179-8_4</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-30179-8_4" />
	</analytic>
	<monogr>
		<title level="m" coord="9,174.86,411.87,199.08,7.77">German Conference on Artificial Intelligence (KI 2019)</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Benzmüller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Stuckenschmidt</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-09">Sep 2019</date>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="48" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,154.69,433.78,319.78,7.77;9,154.68,444.39,317.27,8.12;9,154.68,455.70,172.71,7.77;9,154.68,466.66,158.01,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,245.31,433.78,225.54,7.77">Query expansion techniques for information retrieval: A survey</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">K</forename><surname>Azad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Deepak</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ipm.2019.05.009</idno>
		<ptr target="http://dx.doi.org/10.1016/j.ipm.2019.05.009" />
	</analytic>
	<monogr>
		<title level="j" coord="9,154.68,444.74,142.20,7.77">Information Processing &amp; Management</title>
		<idno type="ISSN">0306-4573</idno>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1698" to="1735" />
			<date type="published" when="2019-09">Sep 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,154.69,477.62,292.77,7.77;9,154.68,488.58,309.02,7.77;9,154.68,499.54,318.33,7.77;9,154.68,510.50,104.60,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,390.58,488.58,73.12,7.77;9,154.68,499.54,92.30,7.77">Overview of Touché 2020: Argument Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gienapp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,264.90,499.54,208.12,7.77">Working Notes Papers of the CLEF 2020 Evaluation Labs</title>
		<imprint>
			<date type="published" when="2020-09">Sep 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,154.69,521.46,325.90,7.77;9,154.68,532.41,325.91,7.77;9,154.68,543.37,321.07,7.77;9,154.68,554.33,314.26,7.77;9,154.68,565.29,320.40,7.77;9,154.68,576.25,155.51,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,346.72,521.46,133.87,7.77;9,154.68,532.41,93.73,7.77">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d15-1075</idno>
		<ptr target="https://doi.org/10.18653/v1/d15-1075" />
	</analytic>
	<monogr>
		<title level="m" coord="9,186.89,543.37,288.86,7.77;9,154.68,554.33,92.10,7.77">Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015</title>
		<title level="s" coord="9,455.00,554.33,13.94,7.77;9,154.68,565.29,152.68,7.77">The Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Màrquez</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Su</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Pighin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Marton</surname></persName>
		</editor>
		<meeting>the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">September 17-21, 2015. 2015</date>
			<biblScope unit="page" from="632" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,154.69,587.21,272.47,7.77;9,154.68,598.17,313.30,7.77;9,154.68,608.78,311.60,8.12" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="9,433.49,598.17,34.50,7.77;9,154.68,609.13,59.47,7.77">Universal sentence encoder</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Limtiaco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">S</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Guajardo-Cespedes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Strope</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kurzweil</surname></persName>
		</author>
		<idno>CoRR abs/1803.11175</idno>
		<ptr target="http://arxiv.org/abs/1803.11175" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,154.69,620.09,302.31,7.77;9,154.68,631.04,320.86,7.77;10,154.68,119.96,311.27,7.77;10,154.68,130.92,313.52,7.77;10,154.68,141.88,294.29,7.77;10,154.68,152.84,322.39,7.77;10,154.68,163.80,157.50,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,399.21,620.09,57.79,7.77;9,154.68,631.04,180.18,7.77">AMPERSAND: argument mining for persuasive online discussions</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Chakrabarty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hidey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Muresan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hwang</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1291</idno>
		<ptr target="https://doi.org/10.18653/v1/D19-1291" />
	</analytic>
	<monogr>
		<title level="m" coord="10,177.09,119.96,288.86,7.77;10,154.68,130.92,313.52,7.77;10,154.68,141.88,81.15,7.77">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Inui</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Ng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Wan</surname></persName>
		</editor>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">November 3-7, 2019. 2019</date>
			<biblScope unit="page" from="2933" to="2943" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,154.69,173.77,313.23,7.77;10,154.68,184.38,281.42,8.12;10,154.68,195.69,112.61,7.77" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="10,322.48,173.77,145.44,7.77;10,154.68,184.73,144.12,7.77">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno>CoRR abs/1810.04805</idno>
		<ptr target="http://arxiv.org/abs/1810.04805" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,154.69,205.66,320.05,7.77;10,154.68,216.62,112.21,7.77" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dibia</surname></persName>
		</author>
		<title level="m" coord="10,191.38,205.66,283.36,7.77;10,154.68,216.62,86.07,7.77">Neuralqa: A usable library for question answering (contextual query expansion + bert) on large datasets</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,154.69,226.60,325.90,7.77;10,154.68,237.56,304.40,7.77;10,154.68,248.52,298.63,7.77;10,154.68,259.48,294.13,7.77;10,154.68,270.43,296.46,7.77;10,154.68,281.39,306.94,7.77;10,154.68,292.35,172.84,7.77;10,154.68,303.31,194.24,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,377.56,237.56,81.52,7.77;10,154.68,248.52,101.31,7.77">Corpus wide argument mining -A working solution</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ein-Dor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Shnarch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dankin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Halfon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Sznajder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Alzate</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gleize</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Choshen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bilu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Aharonov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Slonim</surname></persName>
		</author>
		<ptr target="https://aaai.org/ojs/index.php/AAAI/article/view/6270" />
	</analytic>
	<monogr>
		<title level="m" coord="10,273.90,248.52,179.41,7.77;10,154.68,259.48,294.13,7.77;10,154.68,270.43,296.46,7.77;10,154.68,281.39,167.81,7.77">The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020">February 7-12, 2020. 2020</date>
			<biblScope unit="page" from="7683" to="7691" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,154.69,313.29,317.71,7.77;10,154.68,324.24,303.82,7.77;10,154.68,335.20,290.29,7.77;10,154.68,346.16,281.34,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,297.99,313.29,174.40,7.77">Maskgan: Better text generation via filling in the</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Fedus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">J</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Dai</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=ByOExmWAb" />
	</analytic>
	<monogr>
		<title level="m" coord="10,202.75,324.24,251.71,7.77">6th International Conference on Learning Representations, ICLR 2018</title>
		<title level="s" coord="10,332.50,335.20,108.64,7.77">Conference Track Proceedings</title>
		<meeting><address><addrLine>Vancouver, BC, Canada; OpenReview</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-05-03">April 30 -May 3, 2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,154.69,356.14,315.02,7.77;10,154.68,367.10,325.43,7.77;10,154.68,378.06,316.42,7.77;10,154.68,389.01,202.09,7.77;10,154.68,399.97,323.74,7.77" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,282.90,356.14,182.86,7.77">TACAM: topic and context aware argument mining</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fromm</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Faerman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Seidl</surname></persName>
		</author>
		<idno type="DOI">10.1145/3350546.3352506</idno>
		<ptr target="https://doi.org/10.1145/3350546.3352506" />
	</analytic>
	<monogr>
		<title level="m" coord="10,154.68,378.06,226.58,7.77">IEEE/WIC/ACM International Conference on Web Intelligence</title>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Barnaghi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Gottlob</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Manolopoulos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tzouramanis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Vakali</surname></persName>
		</editor>
		<meeting><address><addrLine>WI; Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019-10-14">2019. 2019. October 14-17, 2019. 2019</date>
			<biblScope unit="page" from="99" to="106" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,154.69,409.95,294.50,7.77;10,154.68,420.91,299.44,7.77" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="10,195.02,409.95,254.17,7.77;10,154.68,420.91,210.69,7.77">Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow: Concepts, tools, and techniques to build intelligent systems</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Géron</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<publisher>O&apos;Reilly Media</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,154.69,430.88,309.74,7.77;10,154.68,441.84,163.37,7.77" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Courville</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<title level="m" coord="10,347.56,430.88,49.27,7.77">Deep learning</title>
		<imprint>
			<publisher>MIT press Cambridge</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,154.69,451.82,315.82,7.77;10,154.68,462.78,321.42,7.77;10,154.68,473.73,273.29,7.77;10,154.68,484.69,318.03,7.77;10,154.68,495.65,314.17,7.77;10,154.68,506.61,310.16,7.77;10,154.68,517.57,214.41,7.77" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,168.13,462.78,276.12,7.77">A large-scale dataset for argument quality ranking: Construction and analysis</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gretz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Cohen-Karlik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Toledo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lahav</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Aharonov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Slonim</surname></persName>
		</author>
		<ptr target="https://aaai.org/ojs/index.php/AAAI/article/view/6285" />
	</analytic>
	<monogr>
		<title level="m" coord="10,462.16,462.78,13.94,7.77;10,154.68,473.73,273.29,7.77;10,154.68,484.69,318.03,7.77;10,154.68,495.65,314.17,7.77;10,154.68,506.61,16.14,7.77">The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="2020">February 7-12, 2020. 2020</date>
			<biblScope unit="page" from="7805" to="7813" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,154.69,527.55,301.93,7.77;10,154.68,538.50,317.08,7.77;10,154.68,549.11,246.12,8.12" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="10,247.95,538.50,220.46,7.77">Efficient natural language response suggestion for smart reply</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Strope</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Lukács</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Miklos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kurzweil</surname></persName>
		</author>
		<idno>CoRR abs/1705.00652</idno>
		<ptr target="http://arxiv.org/abs/1705.00652" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,154.69,559.44,301.65,7.77;10,154.68,570.40,318.61,7.77;10,154.68,581.36,262.95,7.77;10,154.68,592.32,167.64,7.77" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,346.17,559.44,110.17,7.77;10,154.68,570.40,44.69,7.77">The curious case of neural text degeneration</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Holtzman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Buys</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Forbes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Choi</surname></persName>
		</author>
		<ptr target="https://openreview.net/forum?id=rygGQyrFvH" />
	</analytic>
	<monogr>
		<title level="m" coord="10,217.55,570.40,251.71,7.77">8th International Conference on Learning Representations, ICLR 2020</title>
		<meeting><address><addrLine>Addis Ababa, Ethiopia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">April 26-30, 2020. 2020</date>
		</imprint>
	</monogr>
	<note>OpenReview.net</note>
</biblStruct>

<biblStruct coords="10,154.69,602.29,312.35,7.77;10,154.68,613.25,317.74,7.77;10,154.68,624.21,319.28,7.77;10,154.68,635.17,316.76,7.77;10,154.68,646.13,133.73,7.77;10,154.68,657.08,193.61,7.77" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,154.68,613.25,73.57,7.77">Skip-thought vectors</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kiros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">S</forename><surname>Zemel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Urtasun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fidler</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/5950-skip-thought-vectors" />
	</analytic>
	<monogr>
		<title level="m" coord="10,187.55,624.21,286.41,7.77;10,154.68,635.17,161.08,7.77">Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawrence</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sugiyama</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<meeting><address><addrLine>Montreal, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">December 7-12, 2015. 2015</date>
			<biblScope unit="page" from="3294" to="3302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,154.69,119.61,309.91,8.12;11,154.68,130.92,217.78,7.77;11,154.68,141.88,133.35,7.77" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="11,240.45,119.96,98.98,7.77">Argument mining: A survey</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Reed</surname></persName>
		</author>
		<idno type="DOI">10.1162/coli_a_00364</idno>
		<ptr target="https://doi.org/10.1162/coli_a_00364" />
	</analytic>
	<monogr>
		<title level="j" coord="11,345.29,119.96,95.40,7.77">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="765" to="818" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,154.69,152.84,315.45,7.77;11,154.68,163.80,258.28,7.77" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="11,396.18,152.84,73.96,7.77;11,154.68,163.80,232.13,7.77">Query reformulation using query history for passage retrieval in conversational search</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nogueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,154.69,174.76,303.44,7.77;11,154.68,185.37,128.85,8.12" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="11,253.96,174.76,98.29,7.77">Visualizing data using t-sne</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">V D</forename><surname>Maaten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,357.78,174.76,100.35,7.77;11,154.68,185.71,29.87,7.77">Journal of machine learning research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="2579" to="2605" />
			<date type="published" when="2008-11">Nov. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,154.69,196.67,313.99,7.77;11,154.68,207.63,62.37,7.77" xml:id="b20">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Naseri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">S</forename><surname>Dalton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Yates</surname></persName>
		</author>
		<title level="m" coord="11,312.68,196.67,156.01,7.77;11,154.68,207.63,36.22,7.77">Ceqe: Contextualized embeddings forquery expansion</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,154.69,218.59,325.90,7.77;11,154.68,229.55,243.10,7.77" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="11,263.65,218.59,164.64,7.77">Rethinking query expansion for bert reranking</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Padaki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,446.23,218.59,34.36,7.77;11,154.68,229.55,131.05,7.77">European Conference on Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="297" to="304" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,154.69,240.51,316.14,7.77;11,154.68,251.47,325.91,7.77;11,154.68,262.43,322.07,7.77;11,154.68,273.39,303.33,7.77;11,154.68,284.34,307.88,7.77;11,154.68,295.30,323.74,7.77" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="11,233.09,251.47,172.60,7.77">Argument search: Assessing argument relevance</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gienapp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Euchner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Heilenkötter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Weidmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<idno type="DOI">10.1145/3331184.3331327</idno>
		<ptr target="https://doi.org/10.1145/3331184.3331327" />
	</analytic>
	<monogr>
		<title level="m" coord="11,389.85,262.43,86.91,7.77;11,154.68,273.39,303.33,7.77;11,154.68,284.34,78.70,7.77">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2019</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Piwowarski</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Chevalier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">É</forename><surname>Gaussier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Maarek</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Nie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Scholer</surname></persName>
		</editor>
		<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2019<address><addrLine>Paris, France</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019">July 21-25, 2019. 2019</date>
			<biblScope unit="page" from="1117" to="1120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,154.69,306.26,320.70,7.77;11,154.68,317.22,309.15,7.77;11,154.68,328.18,314.74,7.77;11,154.68,339.14,283.52,7.77;11,154.68,350.10,168.21,7.77" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="11,337.59,306.26,134.37,7.77;11,263.26,317.22,200.58,7.77;11,154.68,328.18,144.92,7.77">Information Retrieval Evaluation in a Changing World -Lessons Learned from 20 Years of CLEF</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-22948-1_5</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-22948-1\_5" />
	</analytic>
	<monogr>
		<title level="s" coord="11,306.68,328.18,116.63,7.77">The Information Retrieval Series</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="123" to="160" />
			<date type="published" when="2019">2019</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>TIRA integrated research architecture</note>
</biblStruct>

<biblStruct coords="11,154.69,361.06,278.30,7.77;11,154.68,372.02,171.96,7.77" xml:id="b24">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<title level="m" coord="11,360.66,361.06,72.33,7.77;11,154.68,372.02,145.81,7.77">Improving language understanding by generative pre-training</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,154.69,382.97,320.58,7.77;11,154.68,393.58,236.84,8.12;11,154.68,404.89,208.17,7.77" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="11,275.41,382.97,195.65,7.77">Laying the foundations for a world wide argument web</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Rahwan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Zablith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Reed</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.artint.2007.04.015</idno>
		<ptr target="https://doi.org/https://doi.org/10.1016/j.artint.2007.04.015" />
	</analytic>
	<monogr>
		<title level="j" coord="11,154.68,393.93,76.95,7.77">Artificial Intelligence</title>
		<idno type="ISSN">0004-3702</idno>
		<imprint>
			<biblScope unit="volume">171</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="897" to="921" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,154.69,415.85,260.85,7.77;11,154.68,426.81,306.53,7.77;11,154.68,437.77,177.68,7.77;11,154.68,448.73,164.67,7.77" xml:id="b26">
	<monogr>
		<idno type="DOI">10.18653/v1/W16-28</idno>
		<ptr target="https://www.aclweb.org/anthology/W16-2800" />
		<title level="m" coord="11,209.46,415.85,206.07,7.77;11,154.68,426.81,62.19,7.77">Proceedings of the Third Workshop on Argument Mining (ArgMining2016)</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Reed</surname></persName>
		</editor>
		<meeting>the Third Workshop on Argument Mining (ArgMining2016)<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-08">Aug 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,154.69,459.69,321.33,7.77;11,154.68,470.65,80.44,7.77" xml:id="b27">
	<monogr>
		<title level="m" type="main" coord="11,215.81,459.69,234.43,7.77">Argumentative zoning: Information extraction from scientific text</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Teufel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Citeseer</publisher>
		</imprint>
	</monogr>
	<note>Ph.D. thesis</note>
</biblStruct>

<biblStruct coords="11,154.69,481.60,324.60,7.77;11,154.68,492.56,307.22,7.77;11,154.68,503.52,324.84,7.77;11,154.68,514.48,307.06,7.77;11,154.68,525.44,322.18,7.77;11,154.68,536.40,318.02,7.77;11,154.68,547.36,298.82,7.77" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="11,250.86,492.56,211.04,7.77;11,154.68,503.52,28.55,7.77">Automatic argument quality assessment -new datasets and methods</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Toledo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gretz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Cohen-Karlik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Venezian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lahav</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jacovi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Aharonov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Slonim</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1564</idno>
		<ptr target="https://doi.org/10.18653/v1/D19-1564" />
	</analytic>
	<monogr>
		<title level="m" coord="11,349.05,503.52,130.48,7.77;11,154.68,514.48,307.06,7.77;11,154.68,525.44,245.98,7.77">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Inui</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Jiang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Ng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Wan</surname></persName>
		</editor>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">November 3-7, 2019. 2019</date>
			<biblScope unit="page" from="5624" to="5634" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,154.69,558.32,312.60,7.77;11,154.68,569.28,301.84,7.77;11,154.68,580.23,316.85,7.77;11,154.68,591.19,325.91,7.77;11,154.68,602.15,320.02,7.77;11,154.68,613.11,209.18,7.77" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="11,209.49,569.28,86.57,7.77">Attention is all you need</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/7181-attention-is-all-you-need" />
	</analytic>
	<monogr>
		<title level="m" coord="11,400.55,580.23,70.99,7.77;11,154.68,591.19,325.91,7.77;11,154.68,602.15,48.27,7.77">Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><surname>Von Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">V N</forename><surname>Vishwanathan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<meeting><address><addrLine>Long Beach, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-12-09">4-9 December 2017. 2017</date>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,154.69,624.07,318.29,7.77;11,154.68,635.03,318.74,7.77;11,154.68,645.99,317.80,7.77;11,154.68,656.95,318.31,7.77;12,154.68,119.96,304.71,7.77;12,154.68,130.92,207.97,7.77;12,154.68,141.88,298.82,7.77" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="11,286.93,635.03,170.08,7.77">Building an argument search engine for the web</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">A</forename><surname>Khatib</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Puschmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dorsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Morari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/w17-5106</idno>
		<ptr target="https://doi.org/10.18653/v1/w17-5106" />
	</analytic>
	<monogr>
		<title level="m" coord="11,304.03,656.95,168.96,7.77;12,154.68,119.96,128.10,7.77">Proceedings of the 4th Workshop on Argument Mining, ArgMining@EMNLP 2017</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Habernal</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><forename type="middle">D</forename><surname>Ashley</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Cardie</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Green</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Litman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Petasis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Reed</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Slonim</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Walker</surname></persName>
		</editor>
		<meeting>the 4th Workshop on Argument Mining, ArgMining@EMNLP 2017<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-09-08">September 8, 2017. 2017</date>
			<biblScope unit="page" from="49" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.69,152.84,315.65,7.77;12,154.68,163.80,311.40,7.77;12,154.68,174.41,323.56,8.12" xml:id="b31">
	<monogr>
		<title level="m" type="main" coord="12,279.68,163.80,186.41,7.77;12,154.68,174.76,71.51,7.77">Huggingface&apos;s transformers: State-of-the-art natural language processing</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Debut</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sanh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chaumond</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Delangue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cistac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rault</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Louf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Funtowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Brew</surname></persName>
		</author>
		<idno>CoRR abs/1910.03771</idno>
		<ptr target="http://arxiv.org/abs/1910.03771" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.69,185.71,287.53,7.77;12,154.68,196.67,325.91,7.77;12,154.68,207.63,301.05,7.77;12,154.68,218.59,325.61,7.77;12,154.68,229.55,314.56,7.77;12,154.68,240.51,295.99,7.77;12,154.68,251.47,135.34,7.77" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="12,401.87,185.71,40.34,7.77;12,154.68,196.67,172.07,7.77">End-to-end open-domain question answering with bertserini</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n19-4013</idno>
		<ptr target="https://doi.org/10.18653/v1/n19-4013" />
	</analytic>
	<monogr>
		<title level="m" coord="12,188.05,207.63,267.68,7.77;12,154.68,218.59,325.61,7.77;12,154.68,229.55,16.14,7.77">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<editor>
			<persName><forename type="first">W</forename><surname>Ammar</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Louis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Mostafazadeh</surname></persName>
		</editor>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">June 2-7, 2019. 2019</date>
			<biblScope unit="page" from="72" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.69,262.43,320.78,7.77;12,154.68,273.04,246.12,8.12" xml:id="b33">
	<monogr>
		<title level="m" type="main" coord="12,260.04,262.43,212.26,7.77">Simple applications of BERT for ad hoc document retrieval</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<idno>CoRR abs/1903.10972</idno>
		<ptr target="http://arxiv.org/abs/1903.10972" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,154.69,284.34,298.87,7.77;12,154.68,295.30,321.90,7.77;12,154.68,306.26,295.85,7.77;12,154.68,317.22,322.18,7.77;12,154.68,328.18,322.50,7.77;12,154.68,339.14,229.74,7.77;12,154.68,350.10,137.33,7.77" xml:id="b34">
	<analytic>
		<title level="a" type="main" coord="12,348.24,284.34,105.32,7.77;12,154.68,295.30,67.08,7.77">Applying BERT to document retrieval with birch</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">A</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-3004</idno>
		<ptr target="https://doi.org/10.18653/v1/D19-3004" />
	</analytic>
	<monogr>
		<title level="m" coord="12,334.90,295.30,141.69,7.77;12,154.68,306.26,295.85,7.77;12,154.68,317.22,245.98,7.77">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Padó</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Huang</surname></persName>
		</editor>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">November 3-7, 2019 -. 2019</date>
			<biblScope unit="page" from="19" to="24" />
		</imprint>
	</monogr>
	<note>System Demonstrations</note>
</biblStruct>

<biblStruct coords="12,154.69,361.06,325.90,7.77;12,154.68,372.02,300.28,7.77;12,154.68,382.97,319.19,7.77;12,154.68,393.93,285.18,7.77;12,154.68,404.89,212.31,7.77;12,154.68,415.85,140.58,7.77" xml:id="b35">
	<analytic>
		<title level="a" type="main" coord="12,231.55,361.06,249.04,7.77;12,154.68,372.02,73.08,7.77">A study of smoothing methods for language models applied to ad hoc information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
		<idno type="DOI">10.1145/383952.384019</idno>
		<ptr target="https://doi.org/10.1145/383952.384019" />
	</analytic>
	<monogr>
		<title level="m" coord="12,245.38,372.02,209.58,7.77;12,154.68,382.97,240.75,7.77;12,450.46,382.97,23.41,7.77;12,154.68,393.93,10.65,7.77">Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="334" to="342" />
		</imprint>
	</monogr>
	<note>SIGIR &apos;01</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
