<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,146.94,115.90,321.48,12.90;1,200.74,133.83,213.87,12.90;1,162.32,153.68,290.71,10.75">Ranking Arguments by Combining Claim Similarity and Argument Quality Dimensions Notebook for Touché: Argument Retrieval at CLEF 2020</title>
				<funder ref="#_KmbFcMW">
					<orgName type="full">Deutsche Forschungsgemeinschaft (DFG)</orgName>
				</funder>
				<funder ref="#_2kBPfjp">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,241.60,190.08,56.73,8.64"><forename type="first">Lorik</forename><surname>Dumani</surname></persName>
							<email>dumani@uni-trier.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Trier University</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,317.69,190.08,56.07,8.64"><forename type="first">Ralf</forename><surname>Schenkel</surname></persName>
							<email>schenkel@uni-trier.de</email>
							<affiliation key="aff0">
								<orgName type="institution">Trier University</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,146.94,115.90,321.48,12.90;1,200.74,133.83,213.87,12.90;1,162.32,153.68,290.71,10.75">Ranking Arguments by Combining Claim Similarity and Argument Quality Dimensions Notebook for Touché: Argument Retrieval at CLEF 2020</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EE2FF82CFA0E155F205E25512281AA57</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe our submissions to the CLEF lab Touché, which addresses argument retrieval from a focused debate collection. Our approach consists of a two-step retrieval.</p><p>Step one finds the most similar claims to a query. Step two ranks the directly tied premises by the count of their convincingness compared to other relevant premises, for which we aggregate the sum of three main argument quality dimensions. The final ranking consists of the product of the two components which are expressed as probabilities.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Argumentation is required not only in political debates, where people try to convince others of certain standpoints, e.g., political views. They are also essential for personal decision making, e.g., which smartphone to buy. Since the emergence of well-equipped computers and the increasingly sophisticated NLP methods, computational argumentation has become a very popular field of research and seeks to help people to find good and strong arguments for their needs. In line with existing work, an argument is defined as a claim supported or attacked by at least one premise <ref type="bibr" coords="1,353.96,450.19,15.27,8.64" target="#b12">[13]</ref>. The claim is usually a controversial standpoint that should not be believed by a reader without further evidence (in form of premises).</p><p>Touché <ref type="bibr" coords="1,181.34,486.05,11.45,8.64" target="#b4">[5,</ref><ref type="bibr" coords="1,192.79,486.05,7.64,8.64" target="#b3">4]</ref> is the first lab on Argument Retrieval. 1 It follows the classical TRECstyle 2 evaluation methodology and features two subtasks:</p><p>1. Argument retrieval from a focused debate collection to support argumentative conversations by providing justifications for the claims. 2. Argument retrieval from a generic Web crawl to answer comparative questions with argumentative results and to support decision making.</p><p>Task 1 aims at supporting users directly and finding arguments, e.g., to strengthen their stance or to form opinions about certain issues by "strong" arguments. Thus, besides general relevance of the argument to the topic, argument quality dimensions (see the work of Wachsmuth et al. <ref type="bibr" coords="2,251.42,155.18,16.60,8.64" target="#b14">[15]</ref> for a survey of work on argument quality) will be also evaluated. From the top-k results of all submissions, pools of answers will be formed that will be assessed by crowd-sourcing; evaluation of the submissions will then be done with nDCG <ref type="bibr" coords="2,183.47,191.04,15.27,8.64" target="#b9">[10]</ref>. The retrieved arguments will be evaluated by the following qualities:</p><p>(1) whether an argumentative text is logically cogent, (2) whether it is rhetorically well-written, and (3) whether it contributes to the users' stance-building process (called utility).</p><p>The Web provides innumerable documents that contain arguments. Especially in online portals controversial topics are discussed. Since basically anyone can participate in the discussion, we can assume that practically all relevant aspects are addressed there. Furthermore, as most of the participants are not experts, the arguments might be written in an understandable language. Hence, the official data basis is the dataset from Ajjour et al. <ref type="bibr" coords="2,184.96,315.90,10.79,8.64" target="#b0">[1,</ref><ref type="bibr" coords="2,195.75,315.90,7.19,8.64" target="#b1">2]</ref>, which consists of controversial discussions from debate portals <ref type="foot" coords="2,459.79,314.23,3.49,6.05" target="#foot_0">3</ref> and ChangeMyView, and on which the argument search engine args.me <ref type="bibr" coords="2,408.47,327.85,16.60,8.64" target="#b13">[14]</ref> also bases its arguments. The lab's participants can choose between the downloadable corpus and args' API. <ref type="foot" coords="2,175.83,350.09,3.49,6.05" target="#foot_1">4</ref> In our implementation we work with the downloadable dataset. Moreover, the lab provides 50 topics on different areas such as "abortion" or "gay marriage", for which the lab participants have to find strong arguments from the provided dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our Approach: Concept and Implementation</head><p>In this section we give a short overview of our approach. First, we introduce the general concept, then we discuss the preprocessing of the provided data as well as another dataset that we use to estimate the convincingness of premises. Finally, we show how we find "strong" arguments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Concept</head><p>We follow the principles developed in <ref type="bibr" coords="2,294.69,520.07,10.79,8.64" target="#b5">[6,</ref><ref type="bibr" coords="2,305.48,520.07,7.19,8.64" target="#b7">8]</ref>, which we summarize here briefly. First the set of claims C = {c 1 , c 2 , . . . } of the collection is clustered such that claims with the same meaning are assigned to the same claim cluster, yielding Γ = {γ 1 , γ 2 , . . .} with γ i , γ j ⊆ C and γ i ∩ γ j = ∅ in an offline operation (see Section 2.2). Note that the claims in args.me are sometimes formulated as questions or topic titles. However, in the following we will only refer to claims. We precluster the claims because often, the same claim appears in different formulations in a large collection, and we want to consider all variants of the same claim at the same time. This is even more important for premises, since premises with the same meaning, but different formulations are often used in many claims, but we want to retrieve that premise only once. We thus cluster the set of premises P = {p 1 , p 2 , . . .} and a set Π = {π 1 , π 2 , . . .} with π i , π j ⊆ P and π i ∩ π j = ∅ of premise clusters is formed such that premises with the same meaning are put into the same premise cluster. Now, given a query claim q, we apply a two-step retrieval approach. In the first step, our approach locates the claims in C that are most similar to q, following the observation that the more similar a claim is to a query, the more relevant are the premises of that claim to the query <ref type="bibr" coords="3,235.82,217.38,10.58,8.64" target="#b6">[7]</ref>. In the second step, we locate the claim clusters containing these claims, collect all premises related to a claim of one of these claim clusters, and finally determine the premise clusters to which these premises belong. For the ranking of premise clusters, we now apply a probabilistic ranking method. Thus, our goal is to compute P (π j |q), that is, the probability that π j is chosen as supporting or attacking premise cluster for q. We can calculate P (π j |q) by iterating over all premises in π j and aggregating their individual probabilities, i.e., P (π j |q) = p∈πj P (p|q), where P (p|q) is the probability that p is chosen as support or attack for q. P (p|q) is defined by combining the two aforementioned steps, i.e., P (p|q) = P (c|q) • P (p|c). Formally, P (c|q) denotes the probability that c is chosen as a similar claim to q. P (p|c) denotes the probability that p is chosen as support (or attack) for c.</p><p>In our previous work <ref type="bibr" coords="3,233.30,352.78,11.62,8.64" target="#b5">[6]</ref> we estimated P (p|c) exclusively via frequencies of premises. For our submissions to Task 1, we use a different approach <ref type="bibr" coords="3,372.58,364.73,11.62,8.64" target="#b7">[8]</ref> that also takes some dimensions of argument quality into account. We describe this approach in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Preprocessing of the Provided Dataset</head><p>Since the provided dataset by Ajjour et al. <ref type="bibr" coords="3,308.87,462.70,11.45,8.64" target="#b0">[1,</ref><ref type="bibr" coords="3,320.32,462.70,7.64,8.64" target="#b1">2]</ref> originally consists of arguments with two components, that is, one claim with exactly one premise, we initially grouped all premises by their textually equal claim. Afterwards this grouping will become important because we calculate the convincingness of a premise in comparison to other premises of the same claim.</p><p>Then the contextualized embeddings of both the claims and the premises were derived by using Sentence-BERT (SBERT) <ref type="bibr" coords="3,306.34,536.86,15.27,8.64" target="#b11">[12]</ref>. <ref type="foot" coords="3,325.43,535.19,3.49,6.05" target="#foot_2">5</ref> For the clustering of claims as well as premises we followed the approach of our prior work <ref type="bibr" coords="3,367.53,548.81,11.62,8.64" target="#b5">[6]</ref> and implemented an agglomerative clustering applying Euclidean distance, the average linkage method, and a dynamic tree cut <ref type="bibr" coords="3,203.66,572.72,15.27,8.64" target="#b10">[11]</ref>. <ref type="foot" coords="3,222.74,571.05,3.49,6.05" target="#foot_3">6</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Including another Dataset to Estimate the Convincingness of Premises</head><p>Wachsmuth et al. <ref type="bibr" coords="4,205.94,138.11,16.60,8.64" target="#b14">[15]</ref> provide a dataset in which three experts assessed 320 arguments with respect to 15 argument quality dimensions. The arguments are distributed over 32 issue-stance pairs, i.e., 16 topics with two polarities and 10 premises each. Among these 15 dimensions there are the three main dimensions:</p><p>(1) logical quality in terms of the cogency or strength of an argument, (2) rhetorical quality in terms of the persuasive effect of an argument or argumentation (called effectiveness), and (3) dialectical quality in terms of the reasonableness of argumentation for resolving issues.</p><p>We considered the mean assessment values for the three main dimensions cogency, reasonableness and effectiveness and integrated the idea of Habernal and Gurevych <ref type="bibr" coords="4,456.47,270.50,11.62,8.64" target="#b8">[9]</ref> by deriving all combinations of (premise 1 , premise 2 ) pairs with premises from the same issue-stance pairs and labels "1" or "2", whereby the labels signal which premise has a higher score with respect to a dimension. Pairs with equal mean value were omitted. Then, for the two premises of each pair as well as the corresponding (issue,stance) pair, we derived their SBERT embeddings, processed them to vectors consisting of the embeddings of the two premises each with the pointwise sum, difference, and product to the embedding of the corresponding (issue,stance) pair, yielding a vector of 6,144 dimension per (premise 1 , premise 2 ) pair. <ref type="foot" coords="4,299.07,364.47,3.49,6.05" target="#foot_4">7</ref> Then, we tested standard classifiers such as gradient boosting, logistic regression, or random forest with 32-fold-cross-validation and found that random forest performs best for cogency and effectiveness. For reasonableness Logistic Regression performed only slightly better. Using these best classifiers per dimension, we were able to precalculate the dimension convincing frequencies (DCFs) of the premises in the datset by Ajjour et al. <ref type="bibr" coords="4,345.54,425.92,10.79,8.64" target="#b0">[1,</ref><ref type="bibr" coords="4,356.33,425.92,7.19,8.64" target="#b1">2]</ref>. Here, the DCF of a premise of a claim is calculated as the count how often the premise was better than the other premises belonging to the same claim in a cross comparison. Now, both claims and premises could be indexed in two separate inverted indexes with the cluster and DCF information. We used Apache Lucene to build the indexes. <ref type="foot" coords="4,470.76,472.07,3.49,6.05" target="#foot_5">8</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Finding Strong Arguments</head><p>For each of the 50 topics which we regard as queries, we started by finding the most similar claims (result claims) using Divergence from Randomness (DFR) <ref type="bibr" coords="4,432.12,533.25,10.58,8.64" target="#b2">[3]</ref>, because our previous work <ref type="bibr" coords="4,211.45,545.21,11.62,8.64" target="#b6">[7]</ref> implies that DFR is well suited for this task. Then all premises belonging to claims that are in the same cluster as the result claims were localized. The set of premises was then expanded with the set of premises in the same premise clusters, yielding the set of result premises.</p><p>Before calculating the premise cluster scores, first the premises were ranked individually. The ranking of these consists of the two components (1) similarity of the query to the claim and (2) the sum of the three different DCFs per premise (see Section 2.3). Both (1) and ( <ref type="formula" coords="5,191.07,131.27,3.87,8.64">2</ref>) were normalized to have values between 0 and 1, allowing to use them like probabilities (P (p|c) in the description above). The cluster scores were determined by aggregating the scores of the individual premises of the same cluster. From each cluster, only one representative was selected; in our implementation this is the longest premise as we followed the intuition that a longer premise is also more specific and therefore may be better suited as a representative.</p><p>As trec eval sorts documents by the score values and not by rank values, it is important to handle tied scores. Furthermore, it is the score (integer or floating point) that is for the TREC evaluation in the ranking. Therefore, the representatives were sorted in descending order by cluster score, then by length to break ties, and alphabetically if also the length was the same. To reflect this in the ranking, of all representatives with the same initial score, the scores were increased by the smallest possible delta in Java (10 -17 ) starting from the premise at the bottom.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Subsequent Adjustions</head><p>We manually reviewed the results of our retrieval at a cutoff value of 30 and found that premises with less than 30 characters were usually completely useless as they are too unspecific or nonsense, so we removed them from the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Conclusion</head><p>In this paper we outlined our contribution (team Don Quixote) to the CLEF lab Touché. First we cluster claims and premises in an offline operation by their meaning. For a given query, we then work with a two-step retrieval process that first finds all similar claims and then, using the clusters, finds the relevant premises. For the ranking, we then calculate (1) the similarity of claim and query, and (2) the frequency with which a premise is more convincing than other relevant premises with respect to the three main argument quality dimensions cogency, reasonableness, and effectiveness. Describing (1) and (2) as probabilities, a ranking can be generated via their product. The code will be made available shortly.</p></div>			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="2,144.73,623.99,335.86,7.77;2,144.73,634.95,220.07,7.77"><p>The arguments were extracted from the following debate portals: debatewise.org, idebate.org, debatepedia.org, and debate.org.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="2,144.73,646.13,335.86,7.77;2,144.73,657.93,249.71,6.31"><p>args' API: https://www.args.me/api-en.html. The downloadable dataset of args: https://zenodo.org/record/3734893#.Xw24QCgzaUk.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="3,144.73,602.08,335.86,7.77;3,144.73,613.03,335.87,7.77;3,144.73,623.99,335.86,7.77;3,144.73,634.95,39.34,7.77"><p>The framework used for this is available on https://github.com/UKPLab/ sentence-transformers. The model we used for calculating the embeddings is "roberta-large-nli-stsb-mean-tokens", yielding embeddings of 1,024 dimensions each.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3" coords="3,139.00,644.26,2.99,5.18;3,144.73,646.13,335.64,7.77;3,144.73,657.08,72.38,7.77"><p><ref type="bibr" coords="3,139.00,644.26,2.99,5.18" target="#b5">6</ref> For the agglomerative clustering we used the scripting language R and the packages STATS and FASTCLUSTER.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4" coords="4,144.73,623.99,335.86,7.77;4,144.73,634.95,335.86,7.77;4,144.73,645.62,278.28,7.86"><p>The input can be determined by the elementwise computed Cartesian product of the embeddings of the following three sets, in compliance with the below order. The difference is positive. {premise1, premise2}, {+, -, * }, {(issue,stance)-pair}.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_5" coords="4,139.00,655.22,147.85,9.02"><p><ref type="bibr" coords="4,139.00,655.22,2.99,5.18" target="#b7">8</ref> https://lucene.apache.org/.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>We participated in Task 1 and in this paper we provide a description of the implementation of our approach. Our submissions to the task were done under the team name <rs type="person">Don Quixote</rs>.</p></div>
<div><head>Acknowledgements</head><p>This work has been funded by the <rs type="funder">Deutsche Forschungsgemeinschaft (DFG)</rs> within the project <rs type="projectName">ReCAP</rs>, Grant Number <rs type="grantNumber">375342983 -2018-2020</rs>, as part of the <rs type="programName">Priority Program "Robust Argumentation Machines (RATIO)</rs>" (<rs type="grantNumber">SPP-1999</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_KmbFcMW">
					<idno type="grant-number">375342983 -2018-2020</idno>
					<orgName type="project" subtype="full">ReCAP</orgName>
					<orgName type="program" subtype="full">Priority Program &quot;Robust Argumentation Machines (RATIO)</orgName>
				</org>
				<org type="funding" xml:id="_2kBPfjp">
					<idno type="grant-number">SPP-1999</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,142.61,613.25,320.06,7.77;5,150.95,624.21,301.64,7.77;5,150.95,635.17,321.53,7.77;5,150.95,646.13,207.57,7.77;5,150.95,657.93,194.17,6.31" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,234.40,624.21,218.19,7.77;5,150.95,635.17,15.11,7.77">Visualization of the topic space of argument search results in args</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Riehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Castiglia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Adejoh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fröhlich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/d18-2011</idno>
		<ptr target="https://doi.org/10.18653/v1/d18-2011" />
	</analytic>
	<monogr>
		<title level="m" coord="5,286.68,635.17,32.63,7.77">EMNLP</title>
		<editor>
			<persName><forename type="first">E</forename><surname>Blanco</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Lu</surname></persName>
		</editor>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="60" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.61,119.96,330.38,7.77;6,150.95,130.92,328.68,7.77;6,150.95,141.88,274.76,7.77;6,150.95,152.84,164.71,7.77;6,150.95,164.64,238.70,6.31" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,414.46,119.96,58.52,7.77;6,150.95,130.92,145.09,7.77">Data acquisition for argument search: The args.me corpus</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-30179-84</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-30179-8\_4" />
	</analytic>
	<monogr>
		<title level="s" coord="6,467.93,130.92,11.70,7.77;6,150.95,141.88,126.47,7.77">KI. Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Benzmüller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Stuckenschmidt</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">11793</biblScope>
			<biblScope unit="page" from="48" to="59" />
			<date type="published" when="2019">2019</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.61,174.21,318.57,7.77;6,150.95,185.17,317.07,7.77;6,150.95,195.78,226.49,8.12" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,267.87,174.21,193.31,7.77;6,150.95,185.17,154.50,7.77">Probabilistic models of information retrieval based on measuring the divergence from randomness</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</author>
		<idno type="DOI">10.1145/582415.582416</idno>
		<ptr target="https://doi.org/10.1145/582415.582416" />
	</analytic>
	<monogr>
		<title level="j" coord="6,311.79,185.17,156.23,7.77">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="357" to="389" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.61,206.54,337.98,7.77;6,150.95,217.50,294.82,7.77;6,150.95,228.46,314.34,7.77;6,150.95,239.42,20.92,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,349.99,217.50,95.78,7.77;6,150.95,228.46,69.64,7.77">Overview of Touché 2020: Argument Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gienapp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,238.50,228.46,208.12,7.77">Working Notes Papers of the CLEF 2020 Evaluation Labs</title>
		<imprint>
			<date type="published" when="2020-09">Sep 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.61,249.83,317.60,7.77;6,150.95,260.79,329.64,7.77;6,150.95,271.75,254.10,7.77;6,150.95,282.71,169.19,7.77;6,150.95,294.51,244.08,6.31" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,243.47,260.79,167.34,7.77">Touché: First shared task on argument retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-45442-567</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-45442-5\_67" />
	</analytic>
	<monogr>
		<title level="s" coord="6,428.34,260.79,52.26,7.77;6,150.95,271.75,96.85,7.77">ECIR. Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">12036</biblScope>
			<biblScope unit="page" from="517" to="523" />
			<date type="published" when="2020">2020</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.61,304.08,322.84,7.77;6,150.95,315.04,305.67,7.77;6,150.95,326.00,183.61,7.77;6,150.95,336.96,169.19,7.77;6,150.95,348.76,244.08,6.31" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,302.54,304.08,162.91,7.77;6,150.95,315.04,165.24,7.77">A framework for argument retrieval -ranking argument clusters by frequency and specificity</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dumani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Neumann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schenkel</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-45439-529</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-45439-5\_29" />
	</analytic>
	<monogr>
		<title level="s" coord="6,333.85,315.04,122.78,7.77;6,150.95,326.00,26.36,7.77">ECIR. Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">12035</biblScope>
			<biblScope unit="page" from="431" to="445" />
			<date type="published" when="2020">2020</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.61,358.33,331.77,7.77;6,150.95,369.29,153.91,7.77;6,150.95,381.09,209.81,6.31" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,246.75,358.33,227.63,7.77;6,150.95,369.29,34.68,7.77">A systematic comparison of methods for finding good premises for claims</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dumani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schenkel</surname></persName>
		</author>
		<idno type="DOI">10.1145/3331184.3331282</idno>
		<ptr target="https://doi.org/10.1145/3331184.3331282" />
	</analytic>
	<monogr>
		<title level="m" coord="6,203.75,369.29,25.65,7.77">SIGIR</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="957" to="960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.61,390.66,336.07,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,246.75,390.66,128.14,7.77">Quality-aware ranking of arguments</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dumani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schenkel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,393.28,390.66,23.41,7.77">CIKM</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>accepted</note>
</biblStruct>

<biblStruct coords="6,142.61,401.07,332.81,7.77;6,150.95,412.03,279.29,7.77;6,150.95,423.83,226.45,6.31" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,247.58,401.07,227.84,7.77;6,150.95,412.03,213.66,7.77">Which argument is more convincing? Analyzing and predicting convincingness of web arguments using bidirectional LSTM</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Habernal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/P16-1150/" />
	</analytic>
	<monogr>
		<title level="m" coord="6,384.29,412.03,17.57,7.77">ACL</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.24,433.40,315.81,7.77;6,150.95,444.01,219.84,8.12;6,150.95,455.32,142.82,7.77;6,150.95,467.12,215.19,6.31" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,252.44,433.40,179.60,7.77">Cumulated gain-based evaluation of IR techniques</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Järvelin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kekäläinen</surname></persName>
		</author>
		<idno type="DOI">10.1145/582415.582418</idno>
		<ptr target="http://doi.acm.org/10.1145/582415.582418" />
	</analytic>
	<monogr>
		<title level="j" coord="6,437.98,433.40,20.07,7.77;6,150.95,444.36,133.92,7.77">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="422" to="446" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.24,476.69,323.15,7.77;6,150.95,487.65,283.78,7.77;6,150.95,499.45,258.23,6.31" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Langfelder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Horvath</surname></persName>
		</author>
		<ptr target="https://horvath.genetics.ucla.edu/html/CoexpressionNetwork/BranchCutting/Supplement.pdf" />
		<title level="m" coord="6,290.83,476.69,174.57,7.77;6,150.95,487.65,43.33,7.77">Dynamic tree cut: In-depth description, tests and applications</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.24,509.02,327.32,7.77;6,150.95,519.98,322.01,7.77;6,150.95,530.94,254.84,7.77" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="6,420.74,509.02,48.82,7.77;6,150.95,519.98,236.53,7.77">Classification and clustering of arguments with contextualized word embeddings</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Schiller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Daxenberger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Stab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/P19-1054/" />
	</analytic>
	<monogr>
		<title level="m" coord="6,406.08,519.98,19.82,7.77">ACL</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="567" to="578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.24,541.35,297.01,7.77;6,150.95,552.31,230.98,7.77;6,150.95,564.11,317.90,6.31" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="6,375.88,541.35,63.37,7.77;6,150.95,552.31,132.92,7.77">Parallel discourse annotations on a corpus of short texts</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Stede</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">D</forename><surname>Afantenos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peldszus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Asher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Perret</surname></persName>
		</author>
		<ptr target="http://www.lrec-conf.org/proceedings/lrec2016/summaries/477.html" />
	</analytic>
	<monogr>
		<title level="m" coord="6,301.49,552.31,22.92,7.77">LREC</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.24,573.68,327.01,7.77;6,150.95,584.64,318.74,7.77;6,150.95,595.60,304.73,7.77;6,150.95,606.56,139.08,7.77;6,150.95,618.36,194.17,6.31" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="6,283.20,584.64,170.08,7.77">Building an argument search engine for the web</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">A</forename><surname>Khatib</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Puschmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dorsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Morari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/w17-5106</idno>
		<ptr target="https://doi.org/10.18653/v1/w17-5106" />
	</analytic>
	<monogr>
		<title level="m" coord="6,150.95,595.60,76.01,7.77">ArgMining@EMNLP</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="49" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.24,627.93,304.86,7.77;6,150.95,638.89,329.64,7.77;6,150.95,649.85,320.13,7.77" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="6,231.81,638.89,244.94,7.77">Computational argumentation quality assessment in natural language</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hirst</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Prabhakaran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bilu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Naderi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Alberdingk Thijm</surname></persName>
		</author>
		<ptr target="https://aclweb.org/anthology/E17-1017/" />
	</analytic>
	<monogr>
		<title level="m" coord="6,163.16,649.85,25.29,7.77">EACL</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="176" to="187" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
