<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,173.85,115.96,267.66,12.62;1,172.91,133.89,269.53,12.62;1,150.30,153.73,314.76,10.52;1,266.32,167.68,82.71,10.52">An Open-Domain Web Search Engine for Answering Comparative Questions Notebook for the Touché Lab on Argument Retrieval at CLEF 2020</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,184.40,203.71,56.79,8.74"><forename type="first">Tinsaye</forename><surname>Abye</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Leipzig University</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,249.50,203.71,62.56,8.74"><forename type="first">Tilmann</forename><surname>Sager</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Leipzig University</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,339.18,203.71,91.77,8.74"><forename type="first">Anna</forename><forename type="middle">Juliane</forename><surname>Triebel</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Leipzig University</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,173.85,115.96,267.66,12.62;1,172.91,133.89,269.53,12.62;1,150.30,153.73,314.76,10.52;1,266.32,167.68,82.71,10.52">An Open-Domain Web Search Engine for Answering Comparative Questions Notebook for the Touché Lab on Argument Retrieval at CLEF 2020</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D4FAE96E8E991E967ECB23C6AE04914A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:07+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present an open-domain web search engine that can help answer comparative questions like "Is X better than Y for Z?" by providing argumentative documents. Building such a system requires multiple steps that each includes non-trivial challenges. State-of-the-art search engines do not perform very well on these tasks, and approaches to solve it are part of current research. We present a system to process the following tasks: Detection of comparative relations in a comparative question, finding claims and arguments relevant to answering comparative questions and scoring the relevance, support and credibility of a website. We follow a rule-based syntactic NLP approach for the comparative relation extraction. To measure the relevance of a document, we combine results from the existing models BERT and CAM. Those results are reused to determine the support through an evidence-based approach, while the credibility consists of a multitude of scores. With this approach, we achieved the best NDCG@5 of all systems participating in task 2 of the Touché Lab on Argument Retrieval at CLEF 2020.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>When searching the web for the answer to a comparative question, popular search engines like Google or DuckDuckGo provide results by referring to question-andanswer 1 or debate 2 websites, where mostly subjective opinions are displayed <ref type="bibr" coords="1,462.33,521.51,14.61,8.74" target="#b25">[26]</ref>. Domain specific comparison systems rely on structured data which makes them inappropriate for answering open domain comparative questions since the data is not structured. Although modern search engines are advanced, answering comparative questions is still challenging <ref type="bibr" coords="1,302.45,569.33,15.50,8.74" target="#b25">[26]</ref> and therefore subject to current research in the field of information retrieval. We participate in CLEF 2020 for Task 2 <ref type="bibr" coords="1,168.73,593.24,9.96,8.74" target="#b3">[4]</ref>, which sets the challenge to retrieve and re-rank documents of the ClueWeb12<ref type="foot" coords="2,184.02,117.42,3.97,6.12" target="#foot_0">3</ref> data set aiming to answer comparative questions that are not categorized in a specific domain with argumentative results <ref type="bibr" coords="2,383.02,130.95,9.96,8.74" target="#b3">[4]</ref>. The results will be assessed on the dimensions relevance, support and credibility. Our prototype is tested on TIRA <ref type="bibr" coords="2,206.91,154.86,14.61,8.74" target="#b19">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>To create an open-domain web search engine for comparative question answering, we build upon results from numerous fields with a connection to information retrieval, like comparison mining, argument mining, comparative opinion mining and evidence mining.</p><p>Comparative Relation Extraction We receive user input as a natural language comparative question. Therefore the problem of detecting the entities and features, i.e. the comparative relation (CR) arises just like in comparative opinion mining. <ref type="bibr" coords="2,188.57,309.94,15.50,8.74" target="#b27">[28]</ref> Comparative relation extraction is used successfully by Xu et al. <ref type="bibr" coords="2,149.55,321.90,15.50,8.74" target="#b29">[30]</ref> by using a dependency graph to detect the CR. Comparative opinion mining from online reviews uses Part-Of-Speech (POS) tags as well as domain specific aspects <ref type="bibr" coords="2,203.61,345.81,14.60,8.74" target="#b10">[11]</ref>. Two techniques based on syntactic analysis were compared by Jindal et al. <ref type="bibr" coords="2,205.81,357.76,14.61,8.74" target="#b14">[15]</ref>. The use of label sequential rules that uses POS tags outperforms class sequential rules using keywords. The use of syntactic dependency trees was proven helpful by Gao et al. <ref type="bibr" coords="2,300.88,381.67,15.50,8.74" target="#b10">[11]</ref> and Xu et al. <ref type="bibr" coords="2,379.19,381.67,14.61,8.74" target="#b29">[30]</ref>. We conduct a syntactic analysis of the queries using POS tags and dependency trees. We follow a syntactic natural language processing (NLP) approach to provide a domainagnostic, rule-based model for extracting the CR from the comparative user query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison and Argument Mining</head><p>The CR then serve as input to comparison and argument mining models that rely on structured data. Hence we close the gap between user queries and structured input needed by comparison and argument mining models with comparative relation extraction. The Comparative Argumentative Machine (CAM) by Schildwächter et al. <ref type="bibr" coords="2,440.90,506.42,15.50,8.74" target="#b25">[26]</ref> is an open-domain information retrieval system capable of retrieving comparative argumentative sentences for two given entities and several features. Argument mining systems detect argumentative sentences including premises, claims or evidence sentences <ref type="bibr" coords="2,219.02,554.25,14.61,8.74" target="#b16">[17]</ref>. Fromm et al. <ref type="bibr" coords="2,301.69,554.25,15.50,8.74" target="#b9">[10]</ref> demonstrate that taking the context of an argument into account significantly boosts the performance of an argument detecting system, whereas most of traditional argumentative unit detecting systems <ref type="bibr" coords="2,159.08,590.11,10.52,8.74" target="#b1">[2,</ref><ref type="bibr" coords="2,171.17,590.11,7.75,8.74" target="#b6">7]</ref> are topic agnostic. The Bidirectional Encoder Representations from Transformers (BERT) model <ref type="bibr" coords="2,261.45,602.07,10.52,8.74" target="#b8">[9]</ref> proposed by Reimers et al. <ref type="bibr" coords="2,391.33,602.07,15.50,8.74" target="#b23">[24]</ref> finds arguments, and is also able to detect, if they support a certain topic. We make use of a combination of these models to find argumentative documents that are relevant to the user query and therefore help answer comparative questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Support and Evidence Mining</head><p>We further increase the quality of candidates presented by CAM and BERT with Support and Evidence Mining. As we aim to find documents that provide arguments for decision-making, the mining of context-dependent, evidence-based arguments is an important task. Braunstain et al. <ref type="bibr" coords="3,159.50,166.81,10.52,8.74" target="#b4">[5]</ref> rank support sentences in community-based question answering forums about movies. Evidence Mining provides many publications of different subtasks like extracting evidence sentences from documents <ref type="bibr" coords="3,390.83,190.72,16.60,8.74" target="#b24">[25]</ref>,detecting claims and retrieving evidence <ref type="bibr" coords="3,239.78,202.68,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="3,251.66,202.68,11.62,8.74" target="#b12">13]</ref>. Since we are interested in a document's support for a query, we extract evidence sentences and analyze their relatedness to claims using methods presented by Rinott et al. <ref type="bibr" coords="3,320.68,226.59,14.61,8.74" target="#b24">[25]</ref>. A higher ranking of documents with a good support and evidence for the claims made, should further increase the usefulness of the search results in order to answer the comparative question asked by the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Comparison Retrieval Model</head><p>In this section, the comparison retrieval model we designed to build an opendomain web search engine for answering comparative questions, as sketched in Figure <ref type="figure" coords="3,166.87,340.22,3.87,8.74" target="#fig_0">1</ref>, is described in detail. The retrieval model consists of four phases to retrieve and rank web search results to answer comparative questions. In phase one (blue), the question is analyzed for its comparative relation and expanded queries are sent to the ChatNoir <ref type="bibr" coords="3,287.33,376.09,10.52,8.74" target="#b2">[3]</ref> search engine. The retrieved documents then go through NLP processing. During the second phase (red) comparison and argument mining are conducted on the pre-processed documents. Through evidence mining, link analysis and diverse other sources, scores that quantify the quality of the documents are collected. In the third phase (yellow), the collected scores are summed up to build the meta-scores of relevance, support and credibility. The final phase four (green) delivers weighted scores and reranked documents.</p><p>This section is structured accordingly to the phases depicted in Figure <ref type="figure" coords="3,472.84,471.73,3.87,8.74" target="#fig_0">1</ref>: subsection 3.1 describes the pre-processing, subsection 3.2 the analysis of the documents and reranking is covered in subsection 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Pre-processing</head><p>In the pre-processing phase, the user query in analyzed, expanded and several queries are sent to the ChatNoir <ref type="bibr" coords="3,281.54,555.47,10.51,8.74" target="#b2">[3]</ref> search engine. A linguistic analysis is performed on the content of the websites returned by ChatNoir.</p><p>Comparative Relation Extraction A comparative relation consists of entities to compare and the features, the entities are compared by. Albeit a CR is easy to detect for a human, it is not trivial to extract it computationally <ref type="bibr" coords="3,442.37,620.25,14.61,8.74" target="#b14">[15]</ref>. Due to the given task, we know that the user query is a comparative question. But we must detect the comparative relation within that question. Using a syntactic NLP approach, we use spacy (model en core web sm, trained on the OntoNotes Web Corpus <ref type="bibr" coords="4,193.43,328.89,15.50,8.74" target="#b28">[29]</ref>) to extract the CR from the user query. It provides us with tokenization, chunking, POS tagging and dependency parsing. Two main types of comparative relations occur in the user query: comparative and superlative questions. As the syntactic structure of a comparison in a question does not differ from the CR in a statement, we use the term "superlative" accordingly to Jindal et al. The term "comparative" matches their "non-equal-grabbable" <ref type="bibr" coords="4,462.33,388.67,14.61,8.74" target="#b14">[15]</ref>. As the direction of the CR and the distinction between "feature" and "relation word" is not relevant in this case, our term "feature" covers them both.</p><p>The CR of superlative questions are detected by the following characteristics that result in high accuracy for the given topics: Superlative questions contain no grammatical or-conjunction but a superlative adjective ("highest") which is the feature. The child of superlative is the entity ("mountain") and the child of a prepositional modifier is another feature ("earth"). For queries with a syntactic pattern like: "What is the highest mountain on earth?", the presented method works perfectly.</p><p>To determine the entities in a comparative question we source the syntactic information from the question's dependency graph. This strategy allows for more than two entities to be detected in one sentence. One entity is the parent of a conjunction and the other entities. First we look for this pattern in chunks, i.e. nominal phrases, of the question. Finding a chunk provides the advantage that it contains descriptive adjectives or compounds. If no chunks could be found, the same rule is applied to the tokens of the question. For queries without a conjunction there is no simple rule to detect them. A feasible strategy was to assume that if there are up to two nouns in the query, that are no attributes, they are the entities to compare. Entities can also be verbs if there are no nonstop-word nouns in the question.</p><p>Features turned out to be more diverse than entities, but most of them are comparative adjectives, superlative adjectives, verbs in base form or children of adjectival complements. If there are direct objects or nominal subjects in the question that were not detected as entities, they are assumed to be features. Finally adjectives, compounds and numeric modifiers are added to all entity and feature tokens, e.g. to be able to compare "green tea" to "black tea".</p><p>The two main reasons for failing the CR-detection are errors of POS tagger <ref type="bibr" coords="5,152.63,178.77,15.50,8.74" target="#b14">[15]</ref> and features detected as entities and vice versa. Since the system is customized for the topics of the task, it will not scale for comparative questions with different syntactic structure, especially more complex ones. In general the achieved results for detecting comparative relations from the user queries can be seen as satisfying.</p><p>Query Expansion To expand the queries that will be send to ChatNoir, <ref type="bibr" coords="5,134.77,267.72,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="5,146.32,267.72,12.73,8.74" target="#b20">21]</ref> we collect synonyms and antonyms of the comparative relation's features. Antonyms are fetched from the WordNet lexical database <ref type="foot" coords="5,392.99,278.10,3.97,6.12" target="#foot_1">4</ref> . Synonyms are retrieved through a Gensim continuous skip-gram model <ref type="bibr" coords="5,371.20,291.63,15.50,8.74" target="#b22">[23]</ref> that was trained on a dump of the English Wikipedia from 2017 <ref type="bibr" coords="5,319.22,303.59,14.61,8.74" target="#b15">[16]</ref>. In some cases the Gensim model also returned antonyms, but as we do not care for the direction of the CR, that is not a problem. From the comparative relation and the expanded features we send four queries to ChatNoir using the index generated from the ClueWeb12 data set. First the original comparative question raised by the user, second the entities combined with 'AND', third the entities and the features and fourth the entities, features and their synonyms and antonyms combined with 'OR'. Multiple expanded queries increase the number of results and therefore the recall reachable through further re-ranking.</p><p>From ChatNoir we receive a list of results consisting of snippets, page titles, URIs, page ranks and spam ranks. We fetch the API again to get the full HTMLdocument for every result. From the HTML-documents the external links and the body content are extracted. We remove any CSS and JavaScript code from the body, as well as header-, footer-and nav-tags by using the Python package BeautifulSoup<ref type="foot" coords="5,196.34,469.38,3.97,6.12" target="#foot_2">5</ref> . The body is then segmented into sentences. Then tokenization, POS tagging, dependency parsing and named entity recognition is performed on the sentences <ref type="bibr" coords="5,195.27,494.87,14.61,8.74" target="#b11">[12]</ref>. Sentences with a minimum length of four tokens are selected for further analysis and reranking of the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Analysis</head><p>Since our interest is finding documents that help answering comparative questions, we aim to detect comparative, argumentative and supportive sentences in the retrieved documents. We analyze them for sentences which compare the entities extracted from the user query, for sentences which contain arguments regarding the decision to be made and for sentences which support such claims. The documents should discuss both entities, may be favoring one of them and ideally justify the decision.</p><p>Comparative Sentences In order to find sentences that compare the entities from the user query, we choose two of the best performing classification models according to Panchenko et al. <ref type="bibr" coords="6,272.71,142.90,14.61,8.74" target="#b18">[19]</ref>: BOW and InferSent <ref type="bibr" coords="6,389.07,142.90,9.96,8.74" target="#b7">[8]</ref>. Both models are based on the gradient boosting library XGBoost <ref type="bibr" coords="6,356.19,154.86,9.96,8.74" target="#b5">[6]</ref>. BOW uses bag-of-words word embeddings and InferSent uses the sentence embeddings method for feature representation <ref type="bibr" coords="6,220.41,178.77,9.96,8.74" target="#b7">[8]</ref>. To assess the models, we crafted a small evaluation data set with 100 sentences, 60 of them being comparative taken from the ClueWeb12 corpus covering 11 different topics. Both classifiers are able to distinguish between three cases: the sentence is comparative in favor of the first entity, in favor of the second entity or contains no comparison. We collect all sentences detected as comparison and discard the non-comparative ones. Both BOW and InferSent have a high precision, while BOW performed slightly better. Although both models reach the same recall at .48, we observed that the true positives they return are partially distinct. The strategy of running both models in combination leads to a significantly higher recall of .66. To achieve that improvement, we first run BOW. On the sentences that were not recognized as comparative in the first step, we run the detection with InferSent.</p><p>Argumentative Sentences We exploit the importance of topic awareness for detecting argumentative sentences by using the fine-tuned BERT <ref type="bibr" coords="6,419.94,351.69,10.52,8.74" target="#b8">[9]</ref> model proposed by Reimers et al. <ref type="bibr" coords="6,244.14,363.65,14.61,8.74" target="#b23">[24]</ref>. For a sentence and a topic, which in our case is one of the entities, the BERT classifier can detect if the sentence is an argument for, argument against or no argument regarding the topic. This enables us to collect arguments that aid the decision-making, because the arguments detected are relevant to the question to be answered. Despite the good performance compared to other models, with BERT we detected systematic errors as well. Comparative sentences were not classified properly. These are according to BERT for or against both entities at the same time, leading us to exclude comparative sentences.</p><p>Support Sentences Next to the number of arguments, a well-balanced argumentation structure is also crucial for satisfying the user's information need. Neither a document with a high number of claims, that are not supported by any argument, nor a document with a high number of arguments, that are not connected to any relevant claims, helps to find well-founded statements. Therefore we want to extract the arguments included in the document that directly support one or several claims. Defining support sentences turned out to be challenging, see section 2. Therefore we used the definition of an Context-Dependent Evidence (CDE) by Rinott et al. <ref type="bibr" coords="6,288.13,584.39,14.61,8.74" target="#b24">[25]</ref>. Their definition of a CDE sentence is very similar to the definition of a support sentence of Braunstain et al. <ref type="bibr" coords="6,452.09,596.34,12.22,8.74" target="#b4">[5]</ref>:"[A Context Dependent Evidence is] a text segment that directly supports a claim in the context of the topic." Nevertheless, we continue using the term support sentence. Rinott et al. also provide important characteristics of a support sentence: semantic relatedness, relative location between claim and support sentence and sentiment-agreement between them. Following the steps of Rinott et al. as a guideline, we implemented a support sentence classifier. Since support sentences are arguments as well, we take the BERT result (see section 3.2) as input for the candidate extraction. Therefore we rank the BERT-classified arguments by their context independent features, e.g. named entity labels like PER or ORG, certain terms like nevertheless, therefore or but, and filter the first 70%, except there might be less than 10 sentences after thresholding. We used a lower threshold because BERT often returns only a few sentences. Taking the CAM-classified sentences as claims regarding to our task to provide arguments for comparisons, we determine semantic and sentiment relatedness between every claim and every candidate in the context-dependent stage. The semantic relatedness is measured by BERT, the sentiment similarity by TextBlob. <ref type="foot" coords="7,346.06,236.97,3.97,6.12" target="#foot_3">6</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Reranking</head><p>In order to compare and finally re-rank the retrieved documents, we define several measures for each document, that are assigned to the scores relevance, support and credibility.</p><p>Relevance As defined by Manning et al. <ref type="bibr" coords="7,321.88,344.84,14.61,8.74" target="#b17">[18]</ref>: "A document is relevant if it is one that the user perceives as containing information of value with respect to their personal information need." Therefore our measures for the relevance are mainly comprised from the comparative sentences and argumentative sentences described in subsection 3.2. We establish a ComparisonCount that results from counting the comparative sentences detected according to section 3.2. CAM is able to classify which entity is described as better or worse than its competitor in the sentence. First we considered introducing a score that provides a wellbalanced measure between the two compared entities. But there is not always an equal amount of arguments for both entities. If one of the entities is not as good as the other, one can not assume to find many arguments for it. Comparative sentences in general take both entities into account giving sufficient reflection on both of them. But only counting the argumentative sentences returned by BERT (ArgumentCount) could favor documents only dealing with one of the entities. To prevent such unbalanced results, we put together a formula that considers both the amount of arguments but also the distribution between the entities:</p><formula xml:id="formula_0" coords="7,149.96,555.08,330.64,22.31">ArgumentRatio = total arguments - |arguments 1 -arguments 2| total arguments + 1<label>(1)</label></formula><p>In Equation <ref type="formula" coords="7,191.36,589.01,4.98,8.74" target="#formula_0">1</ref>arguments n means arguments related to entity n, while total arguments represents the total amount of arguments in the document. The fraction takes their distribution over all entities into account. Further, we divided the term with a threshold, took the hyperbolic tangent to flatten the function and generalizing it for more than two entities. But the repetition of the same, possibly rephrased, argument can spoil the measure. To overcome this issue we measured the similarity between the sentences using BERT for detecting argument similarity. This method was also presented by Reimers et al. <ref type="bibr" coords="8,426.72,142.90,14.61,8.74" target="#b23">[24]</ref>.</p><p>Support A support sentence is defined as "a text segment that directly supports a claim in the context of the topic" <ref type="bibr" coords="8,320.89,190.97,15.50,8.74" target="#b24">[25,</ref><ref type="bibr" coords="8,340.02,190.97,7.01,8.74" target="#b0">1]</ref>. To convert the output of the support analysis into a measure, we defined a good document with respect to the given task: a good document has a high number of support sentences, that directly support claims included in the document. The connection between claim and support sentence is described by their semantic and sentiment similarity.</p><p>To score the argumentation structure of a document, two measures were defined: SemanticRatio and SentimentRatio. SemanticRatio describes the number of support sentences per claim that are semantically similar. Since Braunstain et al. <ref type="bibr" coords="8,161.50,286.61,10.52,8.74" target="#b4">[5,</ref><ref type="bibr" coords="8,175.99,286.61,17.71,8.74">138]</ref> and Rinott et al. <ref type="bibr" coords="8,276.74,286.61,15.50,8.74" target="#b24">[25,</ref><ref type="bibr" coords="8,296.20,286.61,7.75,8.74" target="#b5">6]</ref> point out that especially the sentiment similarity between a claim and a support sentence is an indicator for a coherence, SentimentRatio was added as well. To counterbalance SemanticRatio and SentimentRatio, SupportCount as the number of distinct support sentences was added.</p><p>Credibility Jensen et al. define credibility as the "believability of a source due to message recipients' perceptions of the source's trustworthiness and expertise" <ref type="bibr" coords="8,172.22,394.46,15.50,8.74" target="#b13">[14,</ref><ref type="bibr" coords="8,191.03,394.46,7.01,8.74" target="#b0">1]</ref>. Since Rafalak et al. <ref type="bibr" coords="8,293.04,394.46,15.50,8.74" target="#b21">[22]</ref> claim credibility as very subjective, we added multiple different measures to balance the score. Web Of Trust (WOT) <ref type="foot" coords="8,476.12,404.84,3.97,6.12" target="#foot_4">7</ref>provides user ratings for websites. This measure describes the Bayesian averaged opinion of at least 10 users for a website's host. Additionally, the SpamRank, the likelihood of spam, was added, which is delivered by ChatNoir. We assume that the richer the language used by the author of the document, the more credible is the information. With other words, the more complex a text is written, the more effort was put into writing this text by the author. Therefore we calculate three independent readability scores: Automated Readability Index (ARI), Dale-Chall Readability (DaleChall) and Flesch Reading Ease (Flesch). ARI <ref type="bibr" coords="8,422.02,502.05,15.50,8.74" target="#b26">[27]</ref> describes the understandability of a text. Since ARI, DaleChall and Flesch inspect different aspects of a document, e.g. the usage of different words or the number of syllables per word, all the measures were included to cover a wide range of the understandability and readability of a document. However, the actual scores calculated for the received documents were out of the ranges proposed by the respective authors. This is partly due to the difficulty of extracting clean texts out of HTML documents. To prevent the top results from containing a lot of advertisements or links that lead to block-listed hosts, the external links of a document are checked against a list of block-listed domains. <ref type="foot" coords="8,404.81,608.08,3.97,6.12" target="#foot_5">8</ref> The number of "bad" links is added as the negative measure BlocklistedCount.</p><p>Reranking The measures (as shown in Table <ref type="table" coords="9,341.99,118.99,4.43,8.74" target="#tab_0">1</ref>) are weighted, normalized between 0 and 100, and then combined into the scores relevance, support and credibility. Finally, the three resulting scores are also weighted and then combined into the final score by which the documents are re-ranked as the final result of our search engine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>We now present the results of the evaluation conducted by the CLEF committee to rate all participating systems. The ranked list of retrieved documents was judged by human assessors on the three dimensions document relevance, argumentative support, and trustworthiness and credibility of the web documents and arguments. With the introduced search engine, we reached the best submitted run according to NDCG@5 with a score of 0.580. The combination of different techniques and approaches has proven promising. As they have different strengths and weaknesses, there is a potential to balance each other out. Nevertheless, a processing pipeline consisting of so many steps suggests a detailed evaluation and examination of the propagation of errors through the phases of the model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>We participated in the Touché Lab on Argument Retrieval at CLEF 2020 with a web-scale search engine capable of answering comparative questions resulting in the best submitted run according to NDCG@5. However, each step in the comparison retrieval model could be explored further, refined or be tackled with other methods. Whereas the task at hand requires to build a complete search engine, the extensive study of each part could have been subject to a research project alone. Future work can tie in at various points. From comparative relation extraction, over identifying comparative, argumentative and support sentences, to a learning-to-rank algorithm, the question how a machine learning approach could perform almost imposes itself upon the research community. Widening the capabilities of the system to cope not only with the given set of user queries but with any comparative question in natural language can be seen as a further challenge.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,214.00,292.20,187.36,7.89;4,134.77,115.84,345.84,161.60"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Comparison Retrieval Model Overview</figDesc><graphic coords="4,134.77,115.84,345.84,161.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="9,183.80,174.41,247.76,174.88"><head>Table 1 .</head><label>1</label><figDesc>Assignment of measures to scores and their weights</figDesc><table coords="9,196.15,195.55,223.06,153.74"><row><cell>Scores</cell><cell cols="2">Weights Measures</cell><cell>Weights</cell></row><row><cell>Relevance</cell><cell>.4</cell><cell>ArgumentRatio</cell><cell>.4</cell></row><row><cell></cell><cell></cell><cell>ComparisonCount</cell><cell>.4</cell></row><row><cell></cell><cell></cell><cell>PageRank</cell><cell>.2</cell></row><row><cell>Support</cell><cell>.4</cell><cell>SemanticRatio</cell><cell>.5</cell></row><row><cell></cell><cell></cell><cell>SentimentRatio</cell><cell>.3</cell></row><row><cell></cell><cell></cell><cell>SupportCount</cell><cell>.2</cell></row><row><cell>Credibility</cell><cell>.2</cell><cell>WOT</cell><cell>.4</cell></row><row><cell></cell><cell></cell><cell>SpamRank</cell><cell>.3</cell></row><row><cell></cell><cell></cell><cell>BlocklistedLinks</cell><cell>.2</cell></row><row><cell></cell><cell></cell><cell>ARI</cell><cell>.02</cell></row><row><cell></cell><cell></cell><cell>DaleChall</cell><cell>.04</cell></row><row><cell></cell><cell></cell><cell>Flesch</cell><cell>.04</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="2,144.73,657.44,155.34,7.47"><p>http://lemurproject.org/clueweb12</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="5,144.73,646.48,141.22,7.47"><p>https://wordnet.princeton.edu/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="5,144.73,657.44,216.54,7.47"><p>https://www.crummy.com/software/BeautifulSoup/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3" coords="7,144.73,657.44,178.88,7.47"><p>https://textblob.readthedocs.io/en/dev</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4" coords="8,144.73,646.48,98.85,7.47"><p>https://www.mywot.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_5" coords="8,144.73,657.44,202.42,7.47"><p>https://github.com/hemiipatu/Blocklists.git</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,142.96,289.76,337.63,7.86;10,151.52,300.72,329.07,7.86;10,151.52,311.68,87.28,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,273.75,289.76,206.84,7.86;10,151.52,300.72,160.55,7.86">Real-time claim detection from news articles and retrieval of semantically-similar factchecks</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Bosciani-Gilroy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,332.75,300.72,147.84,7.86;10,151.52,311.68,58.60,7.86">Proceedings of the NewsIR&apos;19 Workshop at SIGIR</title>
		<meeting>the NewsIR&apos;19 Workshop at SIGIR</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,323.41,337.63,7.86;10,151.52,334.37,329.07,7.86;10,151.52,345.33,295.19,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,457.81,323.41,22.78,7.86;10,151.52,334.37,310.72,7.86">What works and what does not: Classifier and feature analysis for argument mining</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Aker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sliwa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Lui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Borad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ziyaei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ghobadi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,151.52,345.33,220.12,7.86">Proceedings of the 4th Workshop on Argument Mining</title>
		<meeting>the 4th Workshop on Argument Mining</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="91" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,357.06,337.63,7.86;10,151.52,368.02,329.07,7.86;10,151.52,378.98,329.07,7.86;10,151.52,389.93,329.07,7.86;10,151.52,400.89,162.00,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,352.14,357.06,128.45,7.86;10,151.52,368.02,161.26,7.86">Elastic ChatNoir: Search Engine for the ClueWeb and the Common Crawl</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bevendorff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,241.27,378.98,239.32,7.86;10,151.52,389.93,136.20,7.86">Advances in Information Retrieval. 40th European Conference on IR Research (ECIR 2018)</title>
		<title level="s" coord="10,295.03,389.93,141.99,7.86">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Pasi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Piwowarski</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018-03">Mar 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,412.62,337.63,7.86;10,151.52,423.58,329.07,7.86;10,151.52,434.54,329.07,7.86;10,151.52,445.50,111.66,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,431.40,423.58,49.18,7.86;10,151.52,434.54,136.39,7.86">Overview of Touché 2020: Argument Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fröbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beloucif</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gienapp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ajjour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,310.34,434.54,170.24,7.86;10,151.52,445.50,65.58,7.86">Working Notes Papers of the CLEF 2020 Evaluation Labs</title>
		<imprint>
			<date type="published" when="2020-09">Sep 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,457.23,337.63,7.86;10,151.52,468.19,329.07,7.86;10,151.52,479.15,329.07,7.86;10,151.52,490.10,329.07,7.86;10,151.52,501.06,52.73,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,419.34,457.23,61.25,7.86;10,151.52,468.19,215.04,7.86">Supporting human answers for advice-seeking questions in cqa sites</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Braunstain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Kurland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Carmel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Szpektor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Shtok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,151.52,490.10,134.96,7.86">Advances in Information Retrieval</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Crestani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Moens</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Mothe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Silvestri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Di Nunzio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Hauff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Silvello</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="129" to="141" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,512.79,337.64,7.86;10,151.52,523.75,329.07,7.86;10,151.52,534.71,166.72,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,254.08,512.79,172.27,7.86">Xgboost: A scalable tree boosting system</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Guestrin</surname></persName>
		</author>
		<idno type="DOI">10.1145/2939672.2939785</idno>
		<ptr target="https://doi.org/10.1145/2939672.2939785" />
	</analytic>
	<monogr>
		<title level="m" coord="10,450.62,512.79,29.97,7.86;10,151.52,523.75,227.74,7.86">Conference: the 22nd ACM SIGKDD International Conference</title>
		<imprint>
			<date type="published" when="2016-08">08 2016</date>
			<biblScope unit="page" from="785" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,546.44,337.64,7.86;10,151.52,557.40,329.07,7.86;10,151.52,568.36,329.07,7.86;10,151.52,579.32,329.07,7.86;10,151.52,590.27,329.07,7.86;10,151.52,601.23,217.56,8.12" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,259.49,557.40,217.46,7.86">TARGER: Neural argument mining at your fingertips</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chernodub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Oliynyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Heidenreich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P19-3031</idno>
		<ptr target="https://www.aclweb.org/anthology/P19-3031" />
	</analytic>
	<monogr>
		<title level="m" coord="10,167.28,568.36,313.31,7.86;10,151.52,579.32,170.01,7.86">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-07">Jul 2019</date>
			<biblScope unit="page" from="195" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,612.96,337.64,7.86;10,151.52,623.92,329.07,7.86;10,151.52,634.88,329.07,7.86;10,151.52,645.84,329.07,7.86;10,151.52,656.80,310.41,8.12" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,402.10,612.96,78.50,7.86;10,151.52,623.92,309.41,7.86">Supervised learning of universal sentence representations from natural language inference data</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Conneau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kiela</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schwenk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Barrault</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/D17-1070" />
	</analytic>
	<monogr>
		<title level="m" coord="10,151.52,634.88,329.07,7.86;10,151.52,645.84,40.95,7.86">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2017 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Copenhagen, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-09">September 2017</date>
			<biblScope unit="page" from="670" to="680" />
		</imprint>
		<respStmt>
			<orgName>Association for Computational Linguistics</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,119.67,337.63,7.86;11,151.52,130.63,329.07,7.86;11,151.52,141.59,329.07,7.86;11,151.52,152.55,329.07,7.86;11,151.52,163.51,329.07,7.86;11,151.52,174.47,329.07,7.86;11,151.52,185.43,329.07,8.12" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,338.64,119.67,141.95,7.86;11,151.52,130.63,184.44,7.86">BERT: pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/n19-1423</idno>
		<ptr target="https://doi.org/10.18653/v1/n19-1423" />
	</analytic>
	<monogr>
		<title level="m" coord="11,190.53,141.59,290.06,7.86;11,151.52,152.55,329.07,7.86;11,151.52,163.51,74.46,7.86">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Burstein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Doran</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Solorio</surname></persName>
		</editor>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019<address><addrLine>Minneapolis, MN, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019">June 2-7, 2019. 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="11,142.62,196.40,337.97,7.86;11,151.52,207.36,329.07,7.86;11,151.52,218.31,329.07,8.12;11,151.52,229.92,70.61,7.47" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,291.93,196.40,188.66,7.86;11,151.52,207.36,11.14,7.86">Tacam: Topic and context aware argument mining</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fromm</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Faerman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Seidl</surname></persName>
		</author>
		<idno type="DOI">10.1145/3350546.3352506</idno>
		<ptr target="http://dx.doi.org/10.1145/3350546.3352506" />
	</analytic>
	<monogr>
		<title level="m" coord="11,169.82,207.36,310.77,7.86">IEEE/WIC/ACM International Conference on Web Intelligence on -WI &apos;19</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,240.24,337.98,7.86;11,151.52,251.20,329.07,7.86;11,151.52,262.13,180.64,7.89" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,301.21,240.24,179.38,7.86;11,151.52,251.20,236.56,7.86">Identifying competitors through comparative relation mining of online reviews in the restaurant industry</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,395.00,251.20,85.59,7.86;11,151.52,262.16,109.62,7.86">International Journal of Hospitality Management</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="19" to="32" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,273.13,337.98,7.86;11,151.52,284.06,322.34,7.89" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,263.27,273.13,217.33,7.86;11,151.52,284.09,45.20,7.86">spacy 2: Natural language understanding with bloom embeddings</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Honnibal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Montani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,204.31,284.09,220.60,7.86">convolutional neural networks and incremental parsing</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,295.06,337.97,7.86;11,151.52,306.02,329.07,7.86;11,151.52,316.98,74.25,7.86" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="11,341.49,295.06,139.10,7.86;11,151.52,306.02,283.85,7.86">Defactonlp: Fact verification using entity recognition, tfidf vector comparison and decomposable attention</title>
		<author>
			<persName coords=""><forename type="first">Janardhan</forename><surname>Reddy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rocha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Esteves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename></persName>
		</author>
		<idno>arXiv-1809</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv</note>
</biblStruct>

<biblStruct coords="11,142.62,327.95,337.98,7.86;11,151.52,338.90,329.07,7.86;11,151.52,349.84,298.51,7.89" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,291.61,327.95,188.98,7.86;11,151.52,338.90,198.19,7.86">Effects of automated and participative decision support in computer-aided credibility assessment</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Lowry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Jenkins</surname></persName>
		</author>
		<idno type="DOI">10.2307/41304610</idno>
		<ptr target="https://doi.org/10.2307/41304610" />
	</analytic>
	<monogr>
		<title level="j" coord="11,357.56,338.90,123.03,7.86;11,151.52,349.86,63.84,7.86">Journal of Management Information Systems</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="201" to="233" />
			<date type="published" when="2011-07">07 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,360.83,337.98,7.86;11,151.52,371.79,44.03,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,230.85,360.83,175.30,7.86">Mining comparative sentences and relations</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Jindal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,427.04,360.83,21.25,7.86">Aaai</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,382.76,337.98,7.86;11,151.52,393.72,329.07,7.86;11,151.52,404.68,329.07,7.86;11,151.52,415.64,93.58,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,339.22,382.76,141.37,7.86;11,151.52,393.72,235.77,7.86">Word vectors, reuse, and replicability: Towards a community repository of large-text resources</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kutuzov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Fares</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Oepen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Velldal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,407.25,393.72,73.34,7.86;11,151.52,404.68,183.47,7.86">Proceedings of the 58th Conference on Simulation and Modelling</title>
		<meeting>the 58th Conference on Simulation and Modelling</meeting>
		<imprint>
			<publisher>Linköping University Electronic Press</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="271" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,426.61,337.97,7.86;11,151.52,437.54,242.73,7.89" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="11,240.20,426.61,88.91,7.86">Argumentation mining</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lippi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Torroni</surname></persName>
		</author>
		<idno type="DOI">10.1145/2850417</idno>
		<ptr target="https://doi.org/10.1145/2850417" />
	</analytic>
	<monogr>
		<title level="j" coord="11,335.48,426.61,145.11,7.86;11,151.52,437.57,26.37,7.86">ACM Transactions on Internet Technology</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="2016">03 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,448.54,337.97,7.86;11,151.52,459.50,297.90,8.12" xml:id="b17">
	<monogr>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
		<ptr target="http://nlp.stanford.edu/IR-book/" />
		<title level="m" coord="11,326.79,448.54,149.92,7.86">Introduction to Information Retrieval</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,470.46,337.98,7.86;11,151.52,481.42,329.07,7.86;11,151.52,492.38,329.07,7.86;11,151.52,503.34,290.74,8.12" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="11,449.36,470.46,31.23,7.86;11,151.52,481.42,117.92,7.86">Categorizing Comparative Sentences</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Franzek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<ptr target="https://www.aclweb.org/anthology/W19-4516" />
	</analytic>
	<monogr>
		<title level="m" coord="11,423.77,481.42,56.82,7.86;11,151.52,492.38,329.07,7.86;11,151.52,503.34,43.24,7.86">6th Workshop on Argument Mining (ArgMining 2019) at ACL. Association for Computational Linguistics</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Stein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wachsmuth</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2019-08">Aug 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,514.31,337.98,7.86;11,151.52,525.27,329.07,7.86;11,151.52,536.23,329.07,7.86;11,151.52,547.19,179.76,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="11,371.31,514.31,109.28,7.86;11,151.52,525.27,48.72,7.86">TIRA Integrated Research Architecture</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wiegmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-22948-1_5</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-22948-15" />
	</analytic>
	<monogr>
		<title level="m" coord="11,343.80,525.27,136.80,7.86;11,151.52,536.23,234.23,7.86">Information Retrieval Evaluation in a Changing World. The Information Retrieval Series</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019-09">Sep 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,558.16,337.97,7.86;11,151.52,569.12,329.07,7.86;11,151.52,580.07,329.07,7.86;11,151.52,591.03,329.07,7.86;11,151.52,601.99,242.48,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="11,199.85,569.12,218.64,7.86">ChatNoir: A Search Engine for the ClueWeb09 Corpus</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Graßegger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tippmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Welsch</surname></persName>
		</author>
		<idno type="DOI">10.1145/2348283.2348429</idno>
		<ptr target="https://doi.org/10.1145/2348283.2348429" />
	</analytic>
	<monogr>
		<title level="m" coord="11,355.82,580.07,124.78,7.86;11,151.52,591.03,287.87,7.86">International ACM Conference on Research and Development in Information Retrieval (SIGIR 2012)</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Hersh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Callan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Maarek</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</editor>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012-08">Aug 2012</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page">1004</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,612.96,337.98,7.86;11,151.52,623.92,329.07,7.86;11,151.52,634.88,329.07,7.86;11,151.52,645.84,329.07,7.86;11,151.52,656.80,166.72,7.86" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="11,350.49,612.96,130.11,7.86;11,151.52,623.92,329.07,7.86;11,151.52,634.88,65.54,7.86">Incredible: is (almost) all web content trustworthy? analysis of psychological factors related to website credibility evaluation</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rafalak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Abramczuk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Wierzbicki</surname></persName>
		</author>
		<idno type="DOI">10.1145/2567948.2578997</idno>
		<ptr target="https://doi.org/10.1145/2567948.2578997" />
	</analytic>
	<monogr>
		<title level="m" coord="11,225.78,634.88,254.81,7.86;11,151.52,645.84,217.02,7.86">Proceedings of the companion publication of the 23rd international conference on World wide web companion</title>
		<meeting>the companion publication of the 23rd international conference on World wide web companion</meeting>
		<imprint>
			<date type="published" when="2014-04">04 2014</date>
			<biblScope unit="page" from="1117" to="1122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,117.41,337.98,10.13;12,151.52,130.63,329.07,7.86;12,151.52,141.59,329.07,8.11;12,151.52,153.20,98.85,7.47" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="12,247.47,119.67,233.12,7.86;12,151.52,130.63,16.61,7.86">Software Framework for Topic Modelling with Large Corpora</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Řehůřek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sojka</surname></persName>
		</author>
		<ptr target="http://is.muni.cz/publication/884893/en" />
	</analytic>
	<monogr>
		<title level="m" coord="12,190.68,130.63,289.90,7.86;12,151.52,141.59,46.28,7.86">Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks</title>
		<meeting>the LREC 2010 Workshop on New Challenges for NLP Frameworks<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<publisher>ELRA</publisher>
			<date type="published" when="2010-05">May 2010</date>
			<biblScope unit="page" from="45" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,163.51,337.98,7.86;12,151.52,174.47,329.07,7.86;12,151.52,185.43,329.07,7.86;12,151.52,196.39,329.07,7.86;12,151.52,207.99,150.63,7.47" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="12,460.06,163.51,20.53,7.86;12,151.52,174.47,324.35,7.86">Classification and Clustering of Arguments with Contextualized Word Embeddings</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Schiller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Beck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Daxenberger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Stab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1906.09821" />
	</analytic>
	<monogr>
		<title level="m" coord="12,167.28,185.43,313.31,7.86;12,151.52,196.39,68.78,7.86">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</title>
		<title level="s" coord="12,268.78,196.39,47.72,7.86">Long Papers</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-07">07 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="567" to="578" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,218.30,337.98,7.86;12,151.52,229.26,329.07,7.86;12,151.52,240.22,76.41,7.86" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="12,459.34,218.30,21.25,7.86;12,151.52,229.26,325.13,7.86">Show me your evidence -an automatic method for context dependent evidence detection</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Rinott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dankin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">A</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Khapra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Aharoni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Slonim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,165.60,240.22,33.65,7.86">EMNLP</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,251.18,337.98,7.86;12,151.52,262.14,329.07,7.86;12,151.52,273.10,329.07,7.86;12,151.52,284.06,329.07,7.86;12,151.52,295.02,270.15,7.86" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="12,216.59,262.14,264.01,7.86">Answering Comparative Questions: Better than Ten-Blue-Links?</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schildwächter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondarenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zenker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Biemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Panchenko</surname></persName>
		</author>
		<idno type="DOI">10.1145/3295750.3298916</idno>
		<ptr target="https://doi.org/10.1145/3295750.3298916" />
	</analytic>
	<monogr>
		<title level="m" coord="12,199.41,284.06,281.18,7.86;12,151.52,295.02,20.48,7.86">Conference on Human Information Interaction and Retrieval (CHIIR 2019)</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Halvey</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Ruthven</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Murdock</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Qvarfordt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Joho</surname></persName>
		</editor>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2019-03">2019. Mar 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,305.98,337.98,7.86;12,151.52,316.91,203.82,7.89" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="12,237.96,305.98,112.90,7.86">Automated readability index</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Senter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,357.06,305.98,123.53,7.86;12,151.52,316.93,89.51,7.86">AMRL-TR. Aerospace Medical Research Laboratories</title>
		<imprint>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="1967-06">6570th. 06 1967</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,327.89,337.98,7.86;12,151.52,338.83,329.07,7.89;12,151.52,349.81,60.92,7.86" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="12,339.47,327.89,141.12,7.86;12,151.52,338.85,16.59,7.86">Comparative opinion mining: a review</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">D</forename><surname>Varathan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,176.11,338.85,275.56,7.86">Journal of the Association for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="811" to="829" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,360.77,337.98,7.86;12,151.52,371.73,154.68,7.86" xml:id="b28">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weischedel</surname></persName>
		</author>
		<title level="m" coord="12,217.21,360.77,263.38,7.86;12,151.52,371.73,68.12,7.86">OntoNotes Release 5.0 LDC2013T19. Web Download. Linguistic Data Consortium</title>
		<meeting><address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,382.69,337.98,7.86;12,151.52,393.62,329.07,7.89" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="12,291.24,382.69,189.36,7.86;12,151.52,393.65,131.19,7.86">Mining comparative opinions from customer reviews for competitive intelligence</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">S</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Song</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,288.95,393.65,101.07,7.86">Decision support systems</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="743" to="754" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
