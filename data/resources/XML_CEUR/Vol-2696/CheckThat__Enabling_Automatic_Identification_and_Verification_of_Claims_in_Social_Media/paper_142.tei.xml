<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,142.37,115.96,330.61,12.62;1,136.31,133.89,342.73,12.62">bigIR at CheckThat! 2020: Multilingual BERT for Ranking Arabic Tweets by Check-worthiness</title>
				<funder ref="#_RfyWV5D">
					<orgName type="full">NPRP</orgName>
				</funder>
				<funder>
					<orgName type="full">Qatar National Research Fund</orgName>
				</funder>
				<funder>
					<orgName type="full">Qatar Foundation)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,226.72,171.56,74.80,8.74"><forename type="first">Maram</forename><surname>Hasanain</surname></persName>
							<email>maram.hasanain@qu.edu.qa</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering Department</orgName>
								<orgName type="institution">Qatar University</orgName>
								<address>
									<settlement>Doha</settlement>
									<country key="QA">Qatar</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,324.22,171.56,64.42,8.74"><forename type="first">Tamer</forename><surname>Elsayed</surname></persName>
							<email>telsayed@qu.edu.qa</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science and Engineering Department</orgName>
								<orgName type="institution">Qatar University</orgName>
								<address>
									<settlement>Doha</settlement>
									<country key="QA">Qatar</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,142.37,115.96,330.61,12.62;1,136.31,133.89,342.73,12.62">bigIR at CheckThat! 2020: Multilingual BERT for Ranking Arabic Tweets by Check-worthiness</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">767C3DE2BE5804AC581162C994677F08</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the third-year participation of our bi-gIR group at Qatar University in CheckThat! lab at CLEF. This year we participated only in Arabic Task 1 that focuses on detecting checkworthy tweets on a given topic. We submitted four runs using both traditional classification models and a pre-trained language model: multilingual BERT (mBERT). Official results showed that our run using mBERT was the best among all our submitted runs. Furthermore, bigIR team was ranked third among all eight teams participated in the lab, with our best run ranked 6th among 28 runs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the huge flood of false information on the Web and social media, verification of all claims that a user face is becoming infeasible. The situation is even more challenging for professional fact-checkers and journalists who usually track multiple topics simultaneously with each having many claims. Twitter poses even more challenges with the tweets being limited in size and very quickly spreading. Moreover, there is a huge volume of tweets that might not even contain any factual claims to begin with. This situation motivated work on prioritization of tweets by their importance of verification for a given topic. Task 1 in the Check-That! lab at CLEF 2020 was designed to support research solving that specific problem <ref type="bibr" coords="1,173.80,496.18,9.96,8.74" target="#b2">[3]</ref>. In the lab, the problem of tweets check-worthiness estimation targeted by Task 1 was defined as follows: "Predict which tweet from a stream of tweets on a topic should be prioritized for fact-checking."</p><p>Although the task was offered for both English and Arabic tweets, the bigIR group at Qatar university decided to participate specifically in the Arabic task, since Arabic is one of the most dominant languages in Twitter <ref type="bibr" coords="1,402.11,555.95,9.96,8.74" target="#b1">[2]</ref>, yet still understudied in the fact-checking domain in general. This is our participation for the third year in a row in Arabic tasks of CheckThat! lab <ref type="bibr" coords="1,371.88,579.86,11.15,8.74" target="#b6">[7,</ref><ref type="bibr" coords="1,383.02,579.86,11.15,8.74" target="#b12">13]</ref>.</p><p>In Arabic Task 1, organizers provided participants with two datasets. The training dataset includes three topics with each having 500 Arabic tweets annotated by check-worthiness. The test dataset includes twelve topics, each with 500 Arabic tweets <ref type="bibr" coords="2,198.04,118.99,9.96,8.74" target="#b7">[8]</ref>. For each test topic, we were asked to return a list of the 500 tweets for the topic ranked by their check-worthiness. We tackled this problem in two ways. In the first, we use traditional learning-based classifiers with handcrafted features. In the second, we fine-tune a multilingual BERT (mBERT) pre-trained model <ref type="bibr" coords="2,215.53,166.81,10.52,8.74" target="#b5">[6]</ref> with a classification layer. The run using mBERT was the best-performing among all of our submitted runs and was ranked 6th among all 28 runs in the lab for this task. These results demonstrate the effectiveness of pre-trained models (and BERT specifically) for the problem of check-worthiness estimation which is consistent with very recent studies on the problem including other submissions to the same task <ref type="bibr" coords="2,290.93,226.59,11.62,8.74" target="#b8">[9,</ref><ref type="bibr" coords="2,302.55,226.59,11.62,8.74" target="#b9">10,</ref><ref type="bibr" coords="2,314.17,226.59,11.62,8.74" target="#b11">12]</ref>.</p><p>We discuss the approach we followed in details in Section 2 and briefly present our results in comparison to top teams in the lab in Section 3. We finally provide some concluding remarks and directions for future work in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head><p>We approach check-worthiness ranking by training different classification models. We choose two main approaches to the problem. We train several common text classification models with hand-crafted features hypothesizing they are good discriminators of claim check-worthiness. In the other approach, we fine-tune a multilingual BERT model <ref type="bibr" coords="2,250.67,371.43,9.96,8.74" target="#b5">[6]</ref>. BERT has shown strong performance in multiple text classification tasks, and very recent applications of BERT in the specific problem at hand showed promising results <ref type="bibr" coords="2,328.44,395.34,11.15,8.74" target="#b8">[9,</ref><ref type="bibr" coords="2,339.58,395.34,11.15,8.74" target="#b9">10]</ref>. Details on both approaches are presented in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Traditional Classification</head><p>We start by developing 13 features hand-crafted for this task. These features were selected and inspired by many existing studies on fact-checking and checkworthiness ranking. The features are categorized as follows:</p><p>-Social features</p><p>• hasURL: whether the tweet has a URL or not. We observe that many non-check-worthy claims have URLs citing official news agencies. -Tweet content and structure. Under this category, we select features designed to capture tweet objectivity, its relevance to the topic, and its structure. We preprocess both the tweet and the topic (represented using its description). We apply the following preprocessing steps: stop words and URLs removal, expansion of hashtags by removing the # symbol and splitting the hashtag by underscores, eliminating special characters (e.g., $), removing diacritics, and finally normalizing the Arabic text to consolidate multiple spellings of the same character into a single unified form of it. The computed features are:</p><formula xml:id="formula_0" coords="2,158.68,545.59,4.98,8.74">•</formula><p>• Jaccard Similarity between the topic and the tweet.</p><p>• Count of entities identified in a tweet using a multilingual named-entity recognition tool <ref type="bibr" coords="3,240.34,251.35,9.96,8.74" target="#b0">[1]</ref>. • Count of polarity words including positive ones (e.g., "Success") and negative words (e.g., "Corruption") identified using a large-scale multilingual sentiment lexicon <ref type="bibr" coords="3,289.97,287.42,9.96,8.74" target="#b4">[5]</ref>. We hypothesize tweets with no factual claims will include more sentiment rather than objective language. • Count of numbers in a tweet.</p><p>• Count of quotes in a tweet.</p><p>• Count of unique tokens.</p><p>• Average of the word embedding vectors representing each token in the tweet. The embeddings were extracted from a word embedding model trained over a very large set of Arabic tweets <ref type="bibr" coords="3,370.69,371.95,14.61,8.74" target="#b10">[11]</ref>. For this feature, the tweet was preprocessed using a preprocessor provided by the model developers.</p><p>As for the classifiers, we use three classical classifiers, namely Logistic Regression, Support Vector Machine (SVM) and Random Forest, with default parameters as provided by scikit-learn Python package. <ref type="foot" coords="3,365.15,439.18,3.97,6.12" target="#foot_0">1</ref> With leave-one-topic-out cross-validation over the training dataset, we apply a stepwise feature selection algorithm in which we greedly add the feature that results in best average performance over the folds. Eventually, we found a combination of only three features achieved the best overall performance for all three classifiers. Performance with these 3 features was superior to that achieved when using all 13 features. The features are word embeddings, isVerified, and count of quoted statements. We use the prediction probability of the positive class (i.e., how probable the tweet is check-worthy) as the ranking score to rank tweets in descending order per topic. We train the models using the three training topics provided by the task organizers <ref type="bibr" coords="3,181.92,560.31,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="3,192.43,560.31,7.01,8.74" target="#b7">8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Multilingual BERT</head><p>We fine-tune a Multilingual BERT (mBERT) model for the task of checkworthiness ranking. In this model, we represent the input as follows:</p><p>[</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CLS] + tweet text + [SEP] + topic text + [SEP]</head><p>where [CLS] is a special classification embedding and [SEP] is a token to indicate a separator between the two sentences. The topic was represented by its title concatenated with description. In order to use mBERT model for check-worthiness ranking, we add on top of it a dense layer, followed by an output Softmax classification layer to predict the probability for the two possible classes (whether the tweet is check-worthy or not). We fine tune the model in full including all layers of mBERT and the classification layer. The probability of the positive class was used as the check-worthiness score by which we rank tweets in descending order per topic. We apply light preprocessing to both the tweet and topic by removing URLs, expanding hashtags by removing the # symbol and splitting the hashtag by underscores, eliminating special characters (e.g., $), and removing diacritics. For the model architecture specifications, we use uncased mBERT model with 12 layers and 768 hidden units. The dense layer on top of mBERT has 256 hidden units and relu activation function. We use binary cross-entropy loss for training, and set the maximum sequence length to 128 with training batch size of 32. The model was trained using the three training topics provided by the organizers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>We submitted four runs for the task, which match exactly the models described in Section 2. Table <ref type="table" coords="4,218.52,375.60,4.98,8.74">1</ref> shows the best run per team for the top three teams in the task in addition to our remaining runs and the two baselines provided by the task organizers. As shown in the table, the run using mBERT achieved the best performance among all our runs measured by precision at rank 30 (P@30), which is the the official measure of the task. In fact, our team is ranked third among all participating eight teams, with a comparable performance to the second-ranked team. We find the mBERT model is our best performing model by far, which is consistent with its robust and effective performance across different ranking and classification tasks. We also observe that although all three traditional classifiers used the same features, SVM and Logistic Regression both showed superior performance over Random Forest.</p><p>We note here that our experiments on the problem are preliminary; further experiments are needed to improve and understand the results. For example, we observe that only 30% of the training data is check-worthy. Oversampling techniques of the positive class might result in better classification performance. Another future experiment is to consider integrating some of the hand-crafted features with the BERT representation in order to represent a claim with more than the content.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and Future Work</head><p>Our work showed that a simple neural model using multilingual BERT had competitive performance that is superior to traditional classifiers that use many hand-crafted features for the task. However, we still need to conduct further Table <ref type="table" coords="5,162.79,115.91,4.13,7.89">1</ref>. Official results for best run for top three teams at Arabic Task 1 at CLEF2020 CheckThat! lab including all our runs. Our best run is boldfaced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run ID</head><p>P@10 P@20 P@30 MAP Accenture-AraBERT 0.7167 0.6875 0.7000 0.6232 TobbEtu-AF 0.7000 0.6625 0.6444 0.5816 bigIR-bert 0.6417 0.6333 0.6417 0.5511 bigIR-svm 0.5667 0.5417 0.5472 0.4564 bigIR-logit regression 0.5750 0.5375 0.5444 0.4525 bigIR-random forest 0.4333 0.4542 0.4361 0.3835 baseline2 0.3500 0.3625 0.3472 0.3149 baseline1 0.3250 0.3333 0.3417 0.3244 experiments with more elaborate parameter optimization and feature selection to make more concrete conclusions. In comparison to other teams in the lab, we observe that the use of a language model pre-trained on Arabic data only can yield better performance and thus, we plan to experiment with such models next. We also hypothesize that including some of the hand-crafted features in the neural model can bring improvements to the performance and we plan to test this hypothesis in future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,168.64,545.59,87.31,8.74;2,158.68,558.04,321.91,8.74;2,168.64,569.99,311.95,8.74;2,168.64,581.95,15.00,8.74;2,158.68,594.39,321.91,8.74;2,168.64,606.35,64.23,8.74;2,158.68,618.79,321.91,8.74;2,168.64,630.74,125.53,8.74;2,158.68,643.19,321.92,8.74;2,168.64,655.14,90.80,8.74"><head></head><label></label><figDesc>Number of hashtags • isVerified: whether the author of the tweet is a verified user or not. Less check-worthy claims were observed from verified accounts in the training set. • Tweet popularity score: The sum of the number of retweets and likes the tweet received. • User social connection score: The sum of the number of followers and friends the tweet author has. • User engagement score: The sum of the number of tweets the user posted and liked in Twitter.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,144.73,657.44,151.13,7.47"><p>https://scikit-learn.org/stable/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was made possible by <rs type="funder">NPRP</rs> grant# <rs type="grantNumber">NPRP11S-1204-170060</rs> from the <rs type="funder">Qatar National Research Fund</rs> (a member of <rs type="funder">Qatar Foundation)</rs>. The statements made herein are solely the responsibility of the authors.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_RfyWV5D">
					<idno type="grant-number">NPRP11S-1204-170060</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,142.96,481.09,337.63,7.86;5,151.52,492.05,329.07,7.86;5,151.52,503.01,329.07,7.86;5,151.52,513.97,101.90,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,363.46,481.09,117.13,7.86;5,151.52,492.05,138.39,7.86">Polyglot-NER: Massive multilingual named entity recognition</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Al-Rfou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Perozzi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,297.83,492.05,182.76,7.86;5,151.52,503.01,113.79,7.86">Proceedings of the 2015 SIAM International Conference on Data Mining</title>
		<meeting>the 2015 SIAM International Conference on Data Mining<address><addrLine>Vancouver, British Columbia, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015-04">April 30 -May 2, 2015. April 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,142.96,525.02,337.64,7.86;5,151.52,535.98,329.07,7.86;5,151.52,546.94,329.07,7.86;5,151.52,557.89,25.60,7.86" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="5,228.10,535.98,252.50,7.86;5,151.52,546.94,329.07,7.86">The growing echo chamber of social media: Measuring temporal and social contagion dynamics for over 150 languages on twitter for 2009-2020</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Alshaabi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">R</forename><surname>Dewhurst</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Minot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">V</forename><surname>Arnold</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M</forename><surname>Danforth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">S</forename><surname>Dodds</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,142.96,568.94,337.64,7.86;5,151.52,579.90,329.07,7.86;5,151.52,590.86,329.07,7.86;5,151.52,601.82,235.22,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,184.33,590.86,296.26,7.86;5,151.52,601.82,101.72,7.86">Overview of CheckThat! 2020: Automatic Identification and Verification of Claims in Social Media</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Hamdan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Sheikh Ali</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,260.88,601.82,24.45,7.86">LNCS</title>
		<imprint>
			<biblScope unit="volume">12260</biblScope>
			<date type="published" when="2020">2020</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,142.96,612.87,337.63,7.86;5,151.52,623.83,243.53,7.86" xml:id="b3">
	<analytic>
		<ptr target="-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="5,394.73,612.87,85.86,7.86;5,151.52,623.83,21.16,7.86">CLEF 2020 Working Notes</title>
		<title level="s" coord="5,179.99,623.83,148.42,7.86">CEUR Workshop Proceedings, CEUR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Névéol</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,142.96,634.88,337.64,7.86;5,151.52,645.84,329.07,7.86;5,151.52,656.80,174.90,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,237.93,634.88,204.12,7.86">Building sentiment lexicons for all major languages</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Skiena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,463.04,634.88,17.56,7.86;5,151.52,645.84,329.07,7.86;5,151.52,656.80,90.85,7.86">Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers)</title>
		<meeting>the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="383" to="389" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,119.67,337.63,7.86;6,151.52,130.63,329.07,7.86;6,151.52,141.59,329.07,7.86;6,151.52,152.55,329.07,7.86;6,151.52,163.51,86.01,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,354.85,119.67,125.74,7.86;6,151.52,130.63,205.07,7.86">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,380.67,130.63,99.92,7.86;6,151.52,141.59,329.07,7.86;6,151.52,152.55,174.01,7.86">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="4171" to="4186" />
		</imprint>
	</monogr>
	<note>Long and Short Papers</note>
</biblStruct>

<biblStruct coords="6,142.96,174.47,337.64,7.86;6,151.52,185.43,329.07,7.86;6,151.52,196.39,149.95,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,287.80,174.47,192.80,7.86;6,151.52,185.43,112.43,7.86">bigIR at CLEF 2019: Automatic Verification of Arabic Claims over the Web</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,286.59,185.43,194.00,7.86;6,151.52,196.39,121.28,7.86">Working Notes of CLEF 2019 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,207.34,337.63,7.86;6,151.52,218.30,329.07,7.86;6,151.52,229.26,329.07,7.86;6,151.52,240.22,33.28,7.86" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="6,329.77,218.30,150.82,7.86;6,151.52,229.26,263.76,7.86">Overview of CheckThat! 2020 Arabic: Automatic identification and verification of claims in social media</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Hamdan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<editor>Cappellato et al.</editor>
		<imprint>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,251.18,337.64,7.86;6,151.52,262.14,329.07,7.86" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Guvenen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.08166</idno>
		<title level="m" coord="6,306.90,251.18,173.69,7.86;6,151.52,262.14,165.37,7.86">Too many claims to fact-check: Prioritizing political claims based on check-worthiness</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="6,142.62,273.10,337.98,7.86;6,151.52,284.06,329.07,7.86;6,151.52,295.02,208.76,7.86" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Meng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Arslan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>Devasier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Obembe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.07725</idno>
		<title level="m" coord="6,441.85,273.10,38.74,7.86;6,151.52,284.06,329.07,7.86;6,151.52,295.02,42.68,7.86">Gradientbased adversarial training on transformer networks for detecting check-worthy factual claims</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="6,142.62,305.98,337.98,7.86;6,151.52,316.91,329.07,7.89;6,151.52,327.89,329.07,8.12;6,151.52,338.85,329.07,8.12;6,151.52,349.81,77.53,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="6,329.17,305.98,151.43,7.86;6,151.52,316.93,139.16,7.86">Aravec: A set of arabic word embedding models for use in arabic nlp</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Soliman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Eissa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">R</forename><surname>El-Beltagy</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.procs.2017.10.117</idno>
		<ptr target="http://www.sciencedirect.com/science/article/pii/S1877050917321749,arabicCompu-tationalLinguistics" />
	</analytic>
	<monogr>
		<title level="j" coord="6,298.87,316.93,113.59,7.86">Procedia Computer Science</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="256" to="265" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.62,360.77,337.98,7.86;6,151.52,371.73,329.07,7.86;6,151.52,382.69,33.28,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="6,312.43,360.77,168.17,7.86;6,151.52,371.73,265.58,7.86">Accenture at CheckThat! 2020: If you say so: Post-hoc fact-checking of claims using transformer-based models</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Novak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,436.82,371.73,43.77,7.86;6,151.52,382.69,20.49,7.86">Cappellato et al</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.62,393.65,337.98,7.86;6,151.52,404.61,329.07,7.86;6,151.52,415.56,167.87,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="6,290.66,393.65,189.93,7.86;6,151.52,404.61,133.38,7.86">bigIR at CLEF 2018: Detection and Verification of Check-Worthy Political Claims</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yasser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,306.22,404.61,174.37,7.86;6,151.52,415.56,139.20,7.86">Working Notes of CLEF 2018 -Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
