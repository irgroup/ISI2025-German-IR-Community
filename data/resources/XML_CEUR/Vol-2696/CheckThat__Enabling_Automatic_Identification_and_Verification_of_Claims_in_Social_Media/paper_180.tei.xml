<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,149.37,115.96,316.61,12.62;1,142.35,133.89,330.66,12.62;1,139.32,151.82,336.71,12.62">SSN NLP at CheckThat! 2020: Tweet Check Worthiness Using Transformers, Convolutional Neural Networks and Support Vector Machines</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,148.82,189.52,123.35,8.74"><forename type="first">Sachin</forename><forename type="middle">Krishan</forename><surname>Thyaharajan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">SSN College Of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,280.38,189.52,85.58,8.74"><forename type="first">Kayalvizhi</forename><surname>Sampath</surname></persName>
							<email>kayalvizhis@ssn.edu.in</email>
							<affiliation key="aff0">
								<orgName type="institution">SSN College Of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,374.47,189.52,87.62,8.74"><forename type="first">Thenmozhi</forename><surname>Durairaj</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">SSN College Of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,241.65,201.48,132.06,8.74"><forename type="first">Rishivardhan</forename><surname>Krishnamoorthy</surname></persName>
							<email>rishivardhan18126@cse.ssn.edu.in</email>
							<affiliation key="aff0">
								<orgName type="institution">SSN College Of Engineering</orgName>
								<address>
									<settlement>Chennai</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,149.37,115.96,316.61,12.62;1,142.35,133.89,330.66,12.62;1,139.32,151.82,336.71,12.62">SSN NLP at CheckThat! 2020: Tweet Check Worthiness Using Transformers, Convolutional Neural Networks and Support Vector Machines</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9DF7AAEF8499A08C7E294FAA14B44DCF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Check Worthiness</term>
					<term>Convolutional Neural Network</term>
					<term>Transformers</term>
					<term>Support Vector Machine</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Social media has become a significant source of information for a large fraction of the population. One such popular social media is twitter. An excessive amount of misinformation spread has become ubiquitous. But it is immensely computationally expensive to verify every claim made in every tweet. In this paper, the authors have explored Machine learning solutions to score a tweet on its worthiness to be factchecked. In this paper, we present approaches using CNN, Transformer models and SVM for CLEF-2020 CheckThat! Check-Worthiness task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The rampant spread of fake news on social media has become an all too familiar plight. Fake news has become indistinguishable from real news. The hazards caused by fake news create confusion and misunderstanding about important social and political issues. According to a study on Twitter, false news travels faster than true news. Research project finds humans, not bots, are primarily responsible for the spread of misleading information <ref type="bibr" coords="1,369.89,521.80,14.61,8.74" target="#b16">[17]</ref>. With important political figures and business tycoons active on Twitter, it has become a rather important stage for global information. It is unrealistic to check every tweet to verify the information it holds due to the exorbitant computational requirement with 500 million tweets posted every day. This puts us in need of an algorithm that can filter or rank tweets based on their check worthiness which is the goal of the CLEF-2020 Check That!'s <ref type="bibr" coords="1,429.99,593.53,10.51,8.74" target="#b2">[3]</ref>[1] Check Worthiness task 1. We use CNN, Transformer models and SVM to score each tweet based on their tweet worthiness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Prevention of fake news collides with freedom of speech, hence detection can be done based on objective facts to curb fake news <ref type="bibr" coords="2,365.47,176.88,9.96,8.74" target="#b6">[7]</ref>. Prevalent state-of-theart fact-checking methods employ the use of feature engineering techniques to extract features from each sentence and thereby its context. ClaimBuster <ref type="bibr" coords="2,442.97,200.79,18.73,8.74" target="#b9">[10]</ref> system arose as the first work to check worthiness. The system extracts sentiment features, TF-IDF word representations, POS tags and named entities. These features were derived from sentence level, thereby no contextual information between sentences was captured. Extending ClaimBuster's work, <ref type="bibr" coords="2,411.42,248.61,10.52,8.74" target="#b8">[9]</ref> incorporated contextual awareness into representation by the inclusion of sentence positioning in a speaker segment, speaker mentioning the opponent, audience reactions and sentence similarity to segments as features. <ref type="bibr" coords="2,324.40,284.47,15.50,8.74" target="#b13">[14]</ref> proposes a deep learning framework for detecting Rumors from Microblogs with Recurrent Neural Networks for learning hidden representations that capture the variation of contextual information of relevant posts over time. In last year's CheckThat! <ref type="bibr" coords="2,253.05,332.29,10.52,8.74" target="#b1">[2]</ref> Team Copenhagen <ref type="bibr" coords="2,354.31,332.29,10.52,8.74" target="#b7">[8]</ref> achieved the best performance. They made use of LSTM RNN that learned dual token embeddings, domain-specific embeddings and syntactic dependencies. Team TheEarthIsFlat <ref type="bibr" coords="2,134.77,368.16,10.52,8.74" target="#b5">[6]</ref> made use of a feed-forward neural network with two hidden layers which takes as input Standard Universal Sentence Encoder (SUSE) embeddings <ref type="bibr" coords="2,436.53,380.11,10.52,8.74" target="#b3">[4]</ref> for the current sentence as well as for the two previous sentences as a context. Our system's approach can be considered to pivot on sentence-level features. We do not include context-aware features into our data due to the low amount of training data and less compute power.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dataset description</head><p>The data for the task was given in two formats: .tsv and .json. The training set has 672 data points, the development set has 150 data points. We have used the .tsv format which is a TAB separated text file. The text encoding is UTF-8. A row of the .tsv file has the following format:</p><formula xml:id="formula_0" coords="2,134.77,591.94,345.83,20.69">topic id &lt; T ab &gt; tweet id &lt; T ab &gt;tweet url &lt; T ab &gt; tweet text &lt; T ab &gt; claim &lt; T ab &gt; check worthiness</formula><p>The column descriptions are as follows:</p><p>topic id unique ID for the topic of the tweet tweet id unique ID for each tweet given by Twitter tweet url URL of the given tweet tweet text text content in the tweet claim It is a binary value of 1 if the tweet contains a claim else 0 check worthiness It is a binary value of 1 if the tweet is worthy to be fact checked else 0 4 Methodology</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Data preparation</head><p>The tweets given were preprocessed initially to remove stop words and punctuation. Then, all the tweets were normalized. The whole data was lemmatized and tokenized using the nltk library[13].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training the models</head><p>The data prepared is given to various models that include Convolutional Neural Network (CNN), Transformers and Support Vector Machine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CNN</head><p>Convolutional neural networks (CNN) are trained on top of pre-trained word vectors for classification tasks <ref type="bibr" coords="3,272.29,398.21,14.61,8.74" target="#b10">[11]</ref>. The training data was vectorized using a Word2Vec vectorizer using a pre-trained Google News word vector model with 3 million 300-dimension English word vectors and then padded with zeros up to the maximum sequence length in the given sentences. The padded sequence was fed to the convolutional neural network made of an input layer, an embedding layer, 5 convolutional layers each followed by max-pooling layers, a dropout layer and 2 dense layers. The convolutional layers each use 200 filters and the layers have kernel sizes of 2,3,4,5 and 6 sequentially with RelU activation. The following dense layer has 128 nodes with RelU activation and the following dense layer has 2 nodes with sigmoid activation. The model was trained and saved for classifying test data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Transformers</head><p>The models used are derivatives of Google's BERT <ref type="bibr" coords="3,363.63,560.48,9.96,8.74" target="#b4">[5]</ref>. BERT stands for Bidirectional Encoder Representations from Transformers. The models used in this paper are RoBERTa <ref type="bibr" coords="3,224.02,584.39,15.50,8.74" target="#b11">[12]</ref> and XLNet <ref type="bibr" coords="3,292.32,584.39,15.50,8.74" target="#b17">[18]</ref> which are derivatives of BERT that give better performance. XLNet is developed to work seamlessly with the Auto Regression objective, including integrating Transformer-XL and the careful design of the two-stream attention mechanism. It manages to overcome the deficiencies of BERT whilst requiring more compute power and memory (GPU/TPU memory). The XLNet model was fine-tuned over the pre-trained XLNet Base Cased language model that comprises 12 Transformer blocks, 12 self-attention heads and 768 hidden dimensions. RoBERTa makes use of a robustly optimized method that improves on BERT by modifying key hyperparameters in BERT. It was fine-tuned over the RoBERTa base language model that comprises 12 Transformer blocks, 12 self-attention heads and 768 hidden dimensions with a total parameter of 215M. For our case of experimentation, both transformer models were trained with hyperparameters as 50 epochs with training batch size set to 128 and the learning rate set to 4e-5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Support Vector Machine</head><p>SVM or Support Vector Machine is a traditional machine learning algorithm. The principle behind the algorithm is it creates a hyperplane which separates the data into classes. The text is vectorized using a count vectorizer. The resulting count matrix is transformed to a normalized TF-IDF representation then classified using SVM <ref type="bibr" coords="4,186.30,283.81,15.50,8.74" target="#b15">[16]</ref> classifiers of scikit-learn <ref type="bibr" coords="4,311.66,283.81,14.61,8.74" target="#b14">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Choosing models</head><p>Amongst these four models experimented, RoBERTa was submitted. It was selected based on the f1 score and because of the proven robustness of transformer models for natural language processing tasks. The performance of our models in the development set is shown in Table <ref type="table" coords="4,304.58,376.32,3.87,8.74" target="#tab_0">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>Table <ref type="table" coords="4,161.98,572.43,4.98,8.74">3</ref> shows the performance of the selected Roberta model on the evaluation data. Table <ref type="table" coords="4,188.98,584.39,4.98,8.74">2</ref> shows the test results of all participants. The main metric used for evaluation is the Mean Average Precision (MAP). The performance of the model is ranked 5th in comparison to the other teams' models. We can see that the Precision @ k value decreases as k increases suggesting the model is reliable with top tweets. The model got a perfect score on the Reciprocal Rank again suggesting the model performs well for the top tweets. We can infer from this that the model gives valid top rankings.</p><p>Team MAP RR R-P P@1 P@3 P@5 P@10 P@20 P@30 Accenture 0.8064 1.0000 0.7167 1.0000 1.0000 1.0000 1.0000 0.9500 0.7400 Team Alex 0.8034 1.0000 0.6500 1.0000 1.0000 1.0000 1.0000 0.9500 0.7400 contr.-1 0.7988 1.0000 0.6500 1.0000 1.0000 1.0000 1.0000 0.9500 0.7400 contr.-2 0.7809 1.0000 0.6667 1.0000 1.0000 1.0000 1.0000 0.8500 0.6800 check square 0.7217 1.0000 0.6667 1.0000 0.6667 0.8000 0.8000 0.8000 0.7000 contr.-1 0.6249 0.5000 0.6000 0.0000 0.6667 0.8000 0.8000 0.6500 0.5800 contr.-2 0.7139 0.5000 0.6833 0.0000 0.6667 0.6000 0.8000 0.8500 0.7000 QMUL-SDS 0.7141 1.0000 0.6333 1.0000 1.0000 1.0000 0.9000 0.8000 0.6400 contr.-1 0.7820 1.0000 0.7000 1.0000 1.0000 1.0000 1.0000 0.8500 0.7000 contr.-2 0.7288 1.0000 0.6333 1.0000 1.0000 1.0000 0.9000 0.8500 0.6800 Tobb Etu 0.7062 1.0000 0.6000 1.0000 1.0000 1.0000 0.9000 0.8000 0.6600 contr.-1 0.5635 0.2000 0.6000 0.0000 0.0000 0.2000 0.3000 0.6000 0.6600 contr.-2 0.7102 1.0000 0.6333 1.0000 1.0000 1.0000 1.0000 0.7500 0.6800 SSN NLP 0.6739 1.0000 0.6000 1.0000 1.0000 0.8000 0.8000 0.8000 0.6200 Factify 0.6561 0.5000 0.6833 0.0000 0.3333 0.6000 0.7000 0.7500 0.7000 contr.-1 0.6963 1.0000 0.6833 1.0000 0.3333 0.6000 0.8000 0.8000 0.7400 BustingMisinformation 0.6172 1.0000 0.5833 1.0000 1.0000 0.8000 0.7000 0.6000 0.6000 nlpir01 0.6069 1.0000 0.5667 1.0000 1.0000 1.0000 0.7000 0.6000 0.5800 contr.-1 0.5546 0.2500 0.5500 0.0000 0.0000 0.4000 0.7000 0.7500 0.5200 contr.-2 0.5193 0.5000 0.4500 0.0000 0.6667 0.4000 0.5000 0.6000 0.4800 ZHAW 0.5052 0.3333 0.5333 0.0000 0.3333 0.4000 0.6000 0.5000 0.5200 contr.-1 0.6648 1.0000 0.6333 1.0000 1.0000 0.8000 0.9000 0.7000 0.6600 UAICS 0.4950 1.0000 0.4667 1.0000 0.3333 0.4000 0.6000 0.6000 0.4600 TheUniversityofSheffield 0.4746 0.2500 0.5333 0.0000 0.0000 0.4000 0.2000 0.3500 0.4800 contr.-1 0.6459 1.0000 0.5833 1.0000 1.0000 1.0000 0.8000 0.6000 0.5800</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2. Test set results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>MAP RR R-P P@1 P@3 P@5 P@10 P@20 P@30 RoBERTa 0.6739 1.0000 0.6000 1.0000 1.0000 0.8000 0.8000 0.8000 0.6200 Table <ref type="table" coords="5,266.56,472.98,4.13,7.89">3</ref>. Performance of test data</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We have presented our submission for Task 1 of CheckThat! @ CLEF-2020 to predict the check-worthiness of tweets. The task was approached with various methods that include transformers, CNN and SVM. Among these models, the Roberta transformer model performed better than other methodologies on the development set. Hence, the output from RoBERTa was submitted for evaluation. From table 2, the results show that our team has a perfect recall score and a good MAP score. The performance can further be improved with some other transformer models such as XLNet, Electra, BERT, etc and inclusion of more data samples for training.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,195.92,376.32,223.52,108.90"><head>Table 1 .</head><label>1</label><figDesc>. Performance of our model in development set</figDesc><table coords="4,275.44,411.03,64.48,53.32"><row><cell>Model</cell><cell>F1</cell></row><row><cell cols="2">RoBERTa 0.730</cell></row><row><cell>XLNet</cell><cell>0.642</cell></row><row><cell>CNN</cell><cell>0.654</cell></row><row><cell>SVM</cell><cell>0.590</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="7">Acknowledgement</head><p>We express our sincere thanks to <rs type="institution">DST-SERB</rs> and <rs type="institution">HPC laboratory</rs> for providing space and materials needed for our work.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="6,142.96,208.85,337.63,7.86;6,151.52,219.81,329.07,7.86;6,151.52,230.77,329.07,7.86;6,151.52,241.73,329.07,7.86;6,151.52,252.69,62.50,7.86" xml:id="b0">
	<analytic>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vrochidis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Joho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Eickhoff</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Névéol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,385.78,219.81,94.81,7.86;6,151.52,230.77,329.07,7.86;6,151.52,241.73,258.98,7.86">Experimental IR Meets Multilinguality, Multimodality, and Interaction Proceedings of the Eleventh International Conference of the CLEF Association (CLEF 2020)</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12260</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,263.53,337.63,7.86;6,151.52,274.49,329.07,7.86;6,151.52,285.45,284.57,7.86" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Atanasova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Karadzhov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mohtarami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<title level="m" coord="6,151.52,274.49,329.07,7.86;6,151.52,285.45,139.57,7.86;6,312.51,285.45,94.91,7.86">Overview of the clef-2019 checkthat! lab: Automatic identification and verification of claims. task 1: Check-worthiness</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>CLEF (Working Notes)</note>
</biblStruct>

<biblStruct coords="6,142.96,296.29,337.64,7.86;6,151.52,307.25,329.07,7.86;6,151.52,318.21,329.07,7.86;6,151.52,329.17,190.89,7.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="6,182.56,318.21,298.03,7.86;6,151.52,329.17,86.54,7.86">Overview of CheckThat! 2020: Automatic identification and verification of claims in social media</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Hamdan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Sheikh Ali</surname></persName>
		</author>
		<editor>Arampatzis et al.</editor>
		<imprint>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,340.02,337.63,7.86;6,151.52,350.97,329.07,7.86;6,151.52,361.93,137.12,7.86" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="6,151.52,361.93,108.44,7.86">Universal sentence encoder</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Yi Kong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Limtiaco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">S</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Guajardo-Cespedes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">H</forename><surname>Sung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Strope</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kurzweil</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,372.78,337.63,7.86;6,151.52,383.74,230.16,7.86" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<title level="m" coord="6,354.85,372.78,125.74,7.86;6,151.52,383.74,201.50,7.86">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,394.58,337.64,7.86;6,151.52,405.54,329.07,7.86;6,151.52,416.50,329.07,7.86;6,151.52,427.46,139.92,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,241.62,394.58,238.97,7.86;6,151.52,405.54,19.21,7.86">TheEarthIsFlat&apos;s submission to CLEF&apos;19 CheckThat! challenge</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Favano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">M L P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,191.83,405.54,288.76,7.86;6,151.52,416.50,260.08,7.86">CLEF 2019 Working Notes. Working Notes of CLEF 2019 -Conference and Labs of the Evaluation Forum. CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>CEUR-WS.org</publisher>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,438.30,337.64,7.86;6,151.52,449.24,329.07,7.89;6,151.52,460.22,175.50,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,273.15,438.30,207.44,7.86;6,151.52,449.26,75.11,7.86">The current state of fake news: challenges and opportunities</title>
		<author>
			<persName coords=""><surname>Figueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Oliveira</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.procs.2017.11.106</idno>
		<ptr target="https://doi.org/10.1016/j.procs.2017.11.106" />
	</analytic>
	<monogr>
		<title level="j" coord="6,238.78,449.26,121.15,7.86">Procedia Computer Science</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="page" from="817" to="825" />
			<date type="published" when="2017">12 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,471.07,337.64,7.86;6,151.52,482.03,329.07,7.86;6,151.52,492.98,329.07,7.86;6,151.52,503.94,329.07,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,259.87,471.07,220.73,7.86;6,151.52,482.03,197.67,7.86">Neural weakly supervised fact check-worthiness detection with contrastive sampling-based ranking loss</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">C S J L C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,369.36,482.03,111.23,7.86;6,151.52,492.98,329.07,7.86;6,151.52,503.94,118.62,7.86">CLEF 2019 Working Notes. Working Notes of CLEF 2019 -Conference and Labs of the Evaluation Forum. CEUR Workshop Proceedings</title>
		<meeting><address><addrLine>Lugano, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>CEUR-WS.org</publisher>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,514.79,337.64,7.86;6,151.52,525.75,329.07,7.86;6,151.52,536.71,166.72,7.86" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="6,344.91,514.79,135.68,7.86;6,151.52,525.75,217.94,7.86">Toward automated fact-checking: Detecting check-worthy factual claims by claimbuster</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Arslan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tremayne</surname></persName>
		</author>
		<idno type="DOI">10.1145/3097983.3098131</idno>
		<ptr target="https://doi.org/10.1145/3097983.3098131" />
		<imprint>
			<date type="published" when="2017-08">08 2017</date>
			<biblScope unit="page" from="1803" to="1812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.61,547.55,337.98,7.86;6,151.52,558.51,329.07,7.86;6,151.52,569.47,329.07,7.86;6,151.52,580.43,329.07,7.86;6,151.52,591.39,329.07,8.12;6,151.52,602.99,32.95,7.47" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,306.55,547.55,174.05,7.86;6,151.52,558.51,80.07,7.86">Detecting check-worthy factual claims in presidential debates</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tremayne</surname></persName>
		</author>
		<idno type="DOI">10.1145/2806416.2806652</idno>
		<ptr target="https://doi.org/10.1145/2806416.2806652" />
	</analytic>
	<monogr>
		<title level="m" coord="6,256.59,558.51,224.00,7.86;6,151.52,569.47,226.74,7.86;6,455.00,569.47,25.59,7.86;6,151.52,580.43,10.75,7.86">Proceedings of the 24th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 24th ACM International on Conference on Information and Knowledge Management<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1835" to="1838" />
		</imprint>
	</monogr>
	<note>CIKM &apos;15</note>
</biblStruct>

<biblStruct coords="6,142.61,613.19,303.31,7.86" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="6,189.66,613.19,227.59,7.86">Convolutional neural networks for sentence classification</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.61,624.04,337.98,7.86;6,151.52,634.99,329.07,7.86;6,151.52,645.95,65.30,7.86;6,134.76,656.80,7.85,7.86" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="6,282.11,634.99,198.48,7.86;6,151.52,645.95,36.62,7.86">Roberta: A robustly optimized bert pretraining approach</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.61,656.80,257.66,7.86" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="6,231.81,656.80,139.80,7.86">Nltk: The natural language toolkit</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.62,119.67,337.98,7.86;7,151.52,130.63,264.78,7.86" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="7,441.81,119.67,38.79,7.86;7,151.52,130.63,223.82,7.86">Detecting rumors from microblogs with recurrent neural networks</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">F</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Cha</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.62,141.59,337.98,7.86;7,151.52,152.55,329.07,7.86;7,151.52,163.51,329.07,7.86;7,151.52,174.44,325.87,7.89" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="7,394.26,163.51,86.33,7.86;7,151.52,174.47,73.64,7.86">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Weiss</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Dubourg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vanderplas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Passos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cournapeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brucher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Perrot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Duchesnay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,232.82,174.47,155.11,7.86">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.62,185.43,337.98,7.86;7,151.52,196.39,329.07,7.86;7,151.52,207.34,329.07,7.86;7,151.52,218.30,281.39,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="7,166.16,196.39,314.43,7.86;7,151.52,207.34,62.36,7.86">Hoax detection system on indonesian news sites based on text classification using svm and sgd</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Prasetijo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">R</forename><surname>Isnanto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Eridani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">A A</forename><surname>Soetrisno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Arfan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sofwan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,233.61,207.34,246.99,7.86;7,151.52,218.30,205.76,7.86">2017 4th International Conference on Information Technology, Computer, and Electrical Engineering (ICITACEE)</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="45" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.62,229.26,337.98,7.86;7,151.52,240.20,329.07,8.14;7,151.52,251.83,207.12,7.47" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="7,280.72,229.26,163.62,7.86">The spread of true and false news online</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vosoughi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Aral</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.aap9559</idno>
		<ptr target="https://science.sciencemag.org/content/359/6380/1146" />
	</analytic>
	<monogr>
		<title level="j" coord="7,451.41,229.26,29.19,7.86">Science</title>
		<imprint>
			<biblScope unit="volume">359</biblScope>
			<biblScope unit="issue">6380</biblScope>
			<biblScope unit="page" from="1146" to="1151" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.62,262.14,337.98,7.86;7,151.52,273.10,296.05,7.86" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="7,455.76,262.14,24.83,7.86;7,151.52,273.10,267.39,7.86">Xlnet: Generalized autoregressive pretraining for language understanding</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Salakhutdinov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
