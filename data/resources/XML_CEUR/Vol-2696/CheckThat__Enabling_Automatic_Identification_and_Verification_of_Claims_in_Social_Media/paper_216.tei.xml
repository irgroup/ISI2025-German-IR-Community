<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,185.59,115.96,244.18,12.62;1,144.52,133.89,326.30,12.62;1,180.99,151.82,253.37,12.62">Check square at CheckThat! 2020: Claim Detection in Social Media via Fusion of Transformer and Syntactic Features</title>
				<funder ref="#_qJAKUV9">
					<orgName type="full">European Union</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,175.01,189.49,76.45,8.74"><forename type="first">Gullal</forename><forename type="middle">S</forename><surname>Cheema</surname></persName>
							<email>gullal.cheema@tib.eu</email>
							<affiliation key="aff0">
								<orgName type="department">TIB Leibniz Information Centre for Science and Technology</orgName>
								<address>
									<settlement>Hannover</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,262.01,189.49,76.69,8.74"><forename type="first">Sherzod</forename><surname>Hakimov</surname></persName>
							<email>sherzod.hakimov@tib.eu</email>
							<affiliation key="aff0">
								<orgName type="department">TIB Leibniz Information Centre for Science and Technology</orgName>
								<address>
									<settlement>Hannover</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,368.63,189.49,60.91,8.74"><forename type="first">Ralph</forename><surname>Ewerth</surname></persName>
							<email>ralph.ewerth@tib.eu</email>
							<affiliation key="aff0">
								<orgName type="department">TIB Leibniz Information Centre for Science and Technology</orgName>
								<address>
									<settlement>Hannover</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">L3S Research Center</orgName>
								<orgName type="institution">Leibniz University Hannover</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,185.59,115.96,244.18,12.62;1,144.52,133.89,326.30,12.62;1,180.99,151.82,253.37,12.62">Check square at CheckThat! 2020: Claim Detection in Social Media via Fusion of Transformer and Syntactic Features</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6AB2197D121DD3537BF9A20C0C3712D0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Check-Worthiness</term>
					<term>Fact-Checking</term>
					<term>Social Media</term>
					<term>Twitter</term>
					<term>COVID-19</term>
					<term>SVM</term>
					<term>BERT</term>
					<term>Retrieval</term>
					<term>Text Classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this digital age of news consumption, a news reader has the ability to react, express and share opinions with others in a highly interactive and fast manner. As a consequence, fake news has made its way into our daily life because of very limited capacity to verify news on the Internet by large companies as well as individuals. In this paper, we focus on solving two problems which are part of the factchecking ecosystem that can help to automate fact-checking of claims in an ever increasing stream of content on social media. For the first problem, claim check-worthiness prediction, we explore the fusion of syntactic features and deep transformer Bidirectional Encoder Representations from Transformers (BERT) embeddings, to classify check-worthiness of a tweet, i.e. whether it includes a claim or not. We conduct a detailed feature analysis and present our best performing models for English and Arabic tweets. For the second problem, claim retrieval, we explore the pre-trained embeddings from a Siamese network transformer model (sentence-transformers) specifically trained for semantic textual similarity, and perform KD-search to retrieve verified claims with respect to a query tweet.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Social media is increasingly becoming the main source of news for so many people. With around 2.5 billion Internet users, 12% receive breaking news from Twitter instead of traditional media according to a 2018 survey report <ref type="bibr" coords="1,462.33,580.00,14.61,8.74" target="#b43">[44]</ref>. Fake news in general can be defined <ref type="bibr" coords="1,304.28,591.96,15.50,8.74" target="#b51">[52]</ref> as fabrication and manipulation of information and facts with the main intention of deceiving the reader. As a result, fake news can have several undesired and negative consequences. For example, recent news around COVID-19 pandemic with non-verified claims, that masks lead to rise in carbon dioxide levels caused an online movement to not wear masks. With ease of access and sharing news on Twitter, any news spreads much faster from the moment an event occurs in any part of the world. Although, the survey report <ref type="bibr" coords="2,196.72,166.81,15.50,8.74" target="#b43">[44]</ref> found that almost 60% of users expect news on social media to be inaccurate, it still leaves millions of people who will spread fake news expecting it to be true.</p><p>Considering the vast amount of news that spreads everyday, there has been a rise in independent fact-checking projects like Snopes, Alt News, Our.News, who investigate the news that spread online and publish the results for public use. Most of these independent projects rely on manual efforts that are time consuming which makes it harder to keep up with rate of news production. Therefore, it has become very important to develop tools that can process news at a rapid rate and provide news consumers with some kind of an authenticity measure that reflects the correctness of claims in the news.</p><p>In this paper, we focus on two sub-problems in CheckThat! 2020 <ref type="bibr" coords="2,438.73,300.44,15.50,8.74" target="#b42">[43]</ref> <ref type="foot" coords="2,454.23,298.86,3.97,6.12" target="#foot_0">3</ref> that are a part of larger fact-checking ecosystem. In the first task, we focus on learning a model that can recognize check-worthy claims on Twitter. We present a solution that works for both English <ref type="bibr" coords="2,294.22,336.30,15.50,8.74" target="#b42">[43]</ref> and Arabic <ref type="bibr" coords="2,363.57,336.30,15.50,8.74" target="#b18">[19]</ref> tweets. Some examples of tweets with claims are classified whether it is a check-worthy or not, shown in Table <ref type="table" coords="2,162.32,360.21,3.87,8.74" target="#tab_0">1</ref>. One can see that the claims which are not check-worthy look like personal opinions and do not pose any threat to a larger audience. We explore the fusion of syntactic features and deep transformer Bidirectional Encoder Representations from Transformers (BERT) embeddings, to classify check-worthiness of a tweet. We use Part-of-speech (POS) tags, named entities, and dependency relations as syntactic features and a combination of hidden layers in BERT to compute tweet embedding. Before learning the model with a Support Vector Machine (SVM) <ref type="bibr" coords="2,208.67,443.90,14.61,8.74" target="#b50">[51]</ref>, we use Principal Component Analysis (PCA) <ref type="bibr" coords="2,434.05,443.90,15.50,8.74" target="#b56">[57]</ref> for dimensionality reduction. In the second task, we focus on learning a model that can accurately retrieve verified claims w.r.t a query claim, where query claim is a tweet and verified claims are snippets from actual documents. The verified claim is true and thus acts as the evidence or support for the query tweet. Some example pairs of tweets and claims can be seen in Table <ref type="table" coords="2,378.43,503.68,3.87,8.74" target="#tab_1">2</ref>, which shows that the pairs share lots of contextual information which makes this task a semantic textual similarity problem. For this reason, we explore the pre-trained embeddings from a Siamese network transformer model (sentence-transformers) specifically trained for semantic textual similarity and perform KD-search to retrieve claims. We share the source code for both tasks publicly with the community. <ref type="foot" coords="2,444.19,561.88,3.97,6.12" target="#foot_1">4</ref>The remainder of the paper is organized as follows. Section 2 briefly discusses about previous works on fake news detection and CheckThat! tasks in particular. Section 3 presents details of our approach for Task-1 and Task-2. Section 4 describes the experimental details and results. Section 5 summarizes our conclusion and future research directions.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Verified Claim</head><p>The U.S. Army is sending text messages informing people they've been selected for the military draft.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Tweet</head><p>El Paso was NEVER one of the MOST dangerous cities in the US. We've had a fence for </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Fake news has been studied from different perspectives in the last five years, like factuality or credibility detection <ref type="bibr" coords="4,277.34,157.60,16.28,8.74" target="#b37">[38,</ref><ref type="bibr" coords="4,293.62,157.60,12.21,8.74" target="#b14">15,</ref><ref type="bibr" coords="4,305.83,157.60,12.21,8.74" target="#b41">42,</ref><ref type="bibr" coords="4,318.04,157.60,12.21,8.74" target="#b20">21,</ref><ref type="bibr" coords="4,330.25,157.60,12.21,8.74" target="#b19">20]</ref>, rumour detection <ref type="bibr" coords="4,425.18,157.60,16.13,8.74" target="#b60">[61,</ref><ref type="bibr" coords="4,441.31,157.60,12.10,8.74" target="#b59">60,</ref><ref type="bibr" coords="4,453.40,157.60,12.10,8.74" target="#b46">47,</ref><ref type="bibr" coords="4,465.50,157.60,12.10,8.74" target="#b58">59]</ref>, propagation in networks <ref type="bibr" coords="4,244.08,169.55,16.13,8.74" target="#b27">[28,</ref><ref type="bibr" coords="4,260.21,169.55,12.10,8.74" target="#b31">32,</ref><ref type="bibr" coords="4,272.31,169.55,12.10,8.74" target="#b44">45,</ref><ref type="bibr" coords="4,284.41,169.55,12.10,8.74" target="#b34">35]</ref>, use of multiple modalities <ref type="bibr" coords="4,420.11,169.55,16.38,8.74" target="#b26">[27,</ref><ref type="bibr" coords="4,436.49,169.55,12.29,8.74" target="#b53">54,</ref><ref type="bibr" coords="4,448.78,169.55,12.29,8.74" target="#b47">48]</ref> and also as an ecosystem of smaller sub-problems like in CheckThat! <ref type="bibr" coords="4,423.48,181.51,15.50,8.74" target="#b32">[33,</ref><ref type="bibr" coords="4,438.98,181.51,11.62,8.74" target="#b10">11,</ref><ref type="bibr" coords="4,450.60,181.51,7.75,8.74" target="#b1">2]</ref>. For social media in particular, Shu et al. <ref type="bibr" coords="4,303.29,193.46,15.50,8.74" target="#b45">[46]</ref> studied and provided a comprehensive review of fake news detection with characterizations from psychology and social science, and existing computational algorithms from data mining perspective. The fact that Twitter has become a source of news for so many people, researchers have extensively used the platform to formulate problems, extract data and test their algorithms. For instance, Zubiaga et. al. <ref type="bibr" coords="4,391.87,253.24,15.50,8.74" target="#b60">[61]</ref> extracted tweets around breaking news and used Conditional Random Fields to exploit context during the sequential learning process for rumour detection. Buntain et. al. <ref type="bibr" coords="4,470.08,277.15,10.52,8.74" target="#b5">[6]</ref> studied three large Twitter datasets and developed models to predict accuracy assessments of fake news by crowd-sourced workers and journalists. While many approaches rely on tweet content for detecting fake news, there has been a rise in methods that exploit user characteristics and metadata to model the problem as fake news propagation. For example, Liu et. al. <ref type="bibr" coords="4,353.83,336.92,15.50,8.74" target="#b27">[28]</ref> modeled the propagation path of each news story as a multivariate time series over users who engaged in spreading the news via tweets. They further classified the fake news using Gated Recurrent Unit (GRU) and Convolutional Neural Networks (CNN) to capture the global and local variations of user characteristics respectively. Monti et. al.</p><p>[32] went a step further and used a hybrid feature set including user characteristics, social network structure and tweet content. They modeled the problem as binary prediction using a Graph CNN resulting in a highly accurate fake news detector.</p><p>Besides fake news detection, a sub task to predict check-worthiness of claims has also been explored recently mostly in political context. For example, Hassan et. al. <ref type="bibr" coords="4,164.18,468.98,16.13,8.74" target="#b20">[21,</ref><ref type="bibr" coords="4,180.31,468.98,12.10,8.74" target="#b21">22]</ref> proposed a system that predicts the check-worthiness of a statement made by presidential candidates using SVM <ref type="bibr" coords="4,350.71,480.93,15.50,8.74" target="#b50">[51]</ref> classifier and combination of lexical and syntactic features. They also compared their results with factchecking organizations like CNN<ref type="foot" coords="4,279.16,503.27,3.97,6.12" target="#foot_2">5</ref> and PolitiFact<ref type="foot" coords="4,350.88,503.27,3.97,6.12" target="#foot_3">6</ref> . Later, in CheckThat! 2018 <ref type="bibr" coords="4,134.77,516.80,14.61,8.74" target="#b32">[33]</ref>, several methods were proposed to improve the check-worthiness of claims in political debates. Best methods used a combination of lexical and syntactic features like Bag of Words (BoW), Parts-of-Speech (POS) tags, named Entities, sentiment, topic modeling, dependency parse trees and word embeddings <ref type="bibr" coords="4,462.32,552.66,14.61,8.74" target="#b30">[31]</ref>. Various classifiers were built using either Recurrent Neural Networks (RNN) <ref type="bibr" coords="4,134.77,576.57,15.50,8.74" target="#b15">[16,</ref><ref type="bibr" coords="4,150.26,576.57,11.62,8.74" target="#b61">62]</ref>, gradient boosting <ref type="bibr" coords="4,252.96,576.57,14.61,8.74" target="#b57">[58]</ref>, k-nearest neighbor <ref type="bibr" coords="4,362.87,576.57,15.50,8.74" target="#b13">[14]</ref> or SVM <ref type="bibr" coords="4,423.72,576.57,14.61,8.74" target="#b61">[62]</ref>. In 2019 edition of CheckThat! <ref type="bibr" coords="4,236.27,588.53,14.61,8.74" target="#b10">[11]</ref>, in addition to using lexical and syntactic features <ref type="bibr" coords="4,134.77,600.48,14.61,8.74" target="#b12">[13]</ref>, top approaches relied on learning richer content embeddings and utilized external data for better performance. For example, Hansen et. al. <ref type="bibr" coords="4,418.76,612.44,15.50,8.74" target="#b16">[17]</ref> used word embeddings and syntactic dependency features as input to an LSTM network, enriched the dataset with additional samples from Claimbuster system <ref type="bibr" coords="5,445.77,118.99,15.50,8.74" target="#b22">[23]</ref> and trained the network with a contrastive ranking loss. Favano et. al. <ref type="bibr" coords="5,430.38,130.95,15.50,8.74" target="#b11">[12]</ref> trained a neural network with Standard Universal Sentence Encoder (SUSE) <ref type="bibr" coords="5,435.52,142.90,10.52,8.74" target="#b7">[8]</ref> embeddings of the current sentence and previous two sentences as context. Another approach by Su et. al. <ref type="bibr" coords="5,232.54,166.81,15.50,8.74" target="#b49">[50]</ref> used co-reference resolution to replace pronouns with named entities to get a feature representation with bag of words, named entity similarity and relatedness. Other than political debates, Jaradat et. al. <ref type="bibr" coords="5,465.09,190.72,15.50,8.74" target="#b24">[25]</ref> proposed an online multilingual check-worthiness system that works for different sources (debates, news articles, interviews) in English and Arabic . They use actual annotated data from reputable fact-checking organizations and use best performing feature representations from previous approaches. For tweets in particular, Majithia et. al. <ref type="bibr" coords="5,254.31,250.50,15.50,8.74" target="#b28">[29]</ref> proposed a system to monitor, search and analyze factual claims in political tweets with Claimbuster <ref type="bibr" coords="5,380.67,262.46,15.50,8.74" target="#b22">[23]</ref> at the backend for check-worthiness. Lastly, Dogan et. al. <ref type="bibr" coords="5,307.78,274.41,15.50,8.74" target="#b9">[10]</ref> also conducted a detailed study on detecting check-worthy tweets in U.S. politics and proposed a real-time system to filter them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Proposed Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task-1: Tweet Check-Worthiness Prediction</head><p>Check-Worthiness prediction is the task of predicting whether a tweet includes a claim that is of interest to a large audience. Our approach is motivated by the successful use of lexical, syntactic and contextual features in the previous editions of CheckThat! check-worthiness task for political debates. Given that this task contains less amount of training data, we approached this problem with the idea of creating a rich feature representation, reducing the dimensions of large feature set with PCA <ref type="bibr" coords="5,266.76,437.65,15.50,8.74" target="#b56">[57]</ref> and then learning the model with a SVM. In doing so, our goal is also to understand which features are the most important for check-worthiness prediction from tweet content. As context is very important for downstream NLP tasks, we experiment with word embeddings (word2vec <ref type="bibr" coords="5,462.33,473.52,14.61,8.74" target="#b30">[31]</ref>, GloVe [37]) and BERT <ref type="bibr" coords="5,234.23,485.47,10.52,8.74" target="#b8">[9]</ref> embeddings to create a sentence representation of each tweet. Our pre-processing and feature extraction is agnostic to the topic of the tweet so that it can be applied to any domain. Next, we provide details about all the features used, their extraction and the encoding process. Our overall approach can be seen in Figure <ref type="figure" coords="5,274.22,533.29,3.87,8.74" target="#fig_1">2</ref>.</p><p>Pre-processing We use two publicly available pre-processing tools for English and Arabic tweets. We use Baziotis et. al.'s <ref type="bibr" coords="5,326.09,572.43,10.52,8.74" target="#b2">[3]</ref> tool for English to apply the following normalization steps: tokenization, lower-casing, removal of punctuation, spell correction, normalize hashtags, all-caps, censored, elongated and repeated words, and terms like URL, email, phone, user mentions. We use Stanford Stanza <ref type="bibr" coords="5,134.77,620.25,15.50,8.74" target="#b38">[39]</ref> toolkit to pre-process Arabic tweets by applying the following normalization steps: tokenization, multi-word token expansion and lemmatization.</p><p>In the case of extracting word embeddings from a transformer network, we use the raw text as the networks have their own tokenization process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Syntactic Features</head><p>We use the following syntactic features for English and Arabic tasks: Parts-of-Speech (POS) tags, named entities (NE) and dependency parse tree relations. We use the pre-processed text and run off-the-shelf tools to extract syntactic information of tweets and then convert each group of information to feature sets. For English we used spaCy <ref type="bibr" coords="6,335.99,166.81,18.84,8.74" target="#b23">[24]</ref> and Stanford Stanza <ref type="bibr" coords="6,450.05,166.81,15.50,8.74" target="#b38">[39]</ref> for Arabic tweets to extract the following syntactic features. In all the features, we experiment with keeping and removing stop-words to evaluate their affect.</p><p>Part-of-Speech: For both English and Arabic, we extract 16 POS tags in total and through our empirical evaluation we find that the following eight tags to be the most useful when used as features: NOUN, VERB, PROPN, ADJ, ADV, NUM, ADP, PRON. For Arabic, the additional four tags are useful features: DET, INTJ, AUX, PART. We used the chosen set of POS tags for respective language to encode the syntactic information of tweets.</p><p>Named Entities: We identified the following named entity types to be the most important features through our evaluation: (GPE, PERSON, ORG, NORP, LOC, DATE, CARDINAL, TIME, ORDINAL, FAC, MONEY) for English and (LOC, PER, ORG, MISC) for Arabic. We also found that while developing feature combinations named entities do not add much value to overall accuracy, and hence our primary and contrastive submissions do not include them.</p><p>Syntactic Dependencies: these features are constructed using dependency relation between tokens in a given tweet. We use the dependency relation between two nodes in the parsed tree if the the child and parent nodes' POS tags are one of the following ADJ, ADV, NOUN, PROPN, VERB or NUM. All dependency relations that match the defined constraint are converted into the triplet relation such as (child node-POS, dependency-relation, parent-POS ) and pairs such as (child node-POS, dependency-relation) where the relation is not part of a feature representation. This process is shown in Figure <ref type="figure" coords="6,348.17,431.53,3.87,8.74" target="#fig_0">1</ref>. We found that the features based on pairs of child and parent node perform better than the triplet feature. The dimension of the feature vector for English and Arabic is 133 and 134 respectively.</p><p>For encoding a feature, we get a histogram vector which contains the number of type of tag, named entity or syntactic relation pair. The process of feature encoding is shown in Figure <ref type="figure" coords="6,261.66,503.83,3.87,8.74" target="#fig_0">1</ref>. Finally, we normalize each type of feature with maximum value in the vector.</p><p>Average Word Embeddings One simple way to get a contextual representation of a sentence is to average the word embeddings of each token in a given sentence. For this purpose, we experiment with three types of word embeddings pre-trained on three different sources for English: GloVe embeddings [37] trained on Twitter and Wikipedia, word2vec embeddings <ref type="bibr" coords="6,353.72,596.34,15.50,8.74" target="#b30">[31]</ref> trained on Google News, and FastText <ref type="bibr" coords="6,196.09,608.30,15.50,8.74" target="#b29">[30]</ref> embeddings trained on multiple sources. In addition, we also experiment with removing stop-words from the average word representation, as stop-words can dominate in the average and result in less meaningful sentence representation. For Arabic, we use word2vec embeddings that are trained on Arabic tweets and Arabic Wikipedia <ref type="bibr" coords="6,297.32,656.12,14.61,8.74" target="#b48">[49]</ref>. Transformer Features Another way to extract contextual features is to use BERT <ref type="bibr" coords="7,166.00,415.69,10.52,8.74" target="#b8">[9]</ref> embeddings that are trained using the context of the word in a sentence. BERT is usually trained on a very large text corpus which makes them very useful for off-the-shelf feature extraction and fine-tuning for downstream tasks in NLP. To get one embedding per tweet, we follow the observations made in <ref type="bibr" coords="7,147.03,463.51,10.52,8.74" target="#b8">[9]</ref> that, different layers of BERT capture different kinds of information, so an appropriate pooling strategy should be applied depending on the task. The paper also suggests that the last four hidden layers of the network are good for transfer learning tasks and thus we experiment with 4 different combinations, i.e. concatenate last 4 hidden layers, average of last 4 hidden layers, last hidden layer and 2 nd last hidden layer. We normalize the final embedding so that l2 norm of the vector is 1. We also experimented with BERT's pooled sentence embedding that is encoded in the CLS (class) tag, which performed significantly poorer than the pooling strategies we employed. For Arabic, we only experimented with a sentence-transformer <ref type="bibr" coords="7,293.59,571.11,15.50,8.74" target="#b39">[40]</ref> that is trained on multilingual training corpus and outputs a sentence embedding for each tweet/sentence.</p><p>Sentence Representation: To get the overall representation of the tweet, we concatenate all the syntactic features together with either average word embedding or BERT-based transformer features and then apply PCA for dimensionality reduction. SVM classifier is trained on the feature vectors of tweets to output a binary decision (check worthy or not). The overall process is shown in Figure <ref type="figure" coords="7,166.20,656.12,3.87,8.74" target="#fig_1">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Task-2: Claim Retrieval</head><p>Claim Retrieval is the task of retrieving the most similar already verified claim to the query claim. For this task, it is important that the feature representation captures the meaning and context of words and phrases so that query matches the correct verified claim. Therefore, we relied on a triplet-network setting, where the network could be trained with triplets consisting of an anchor sample a, positive sample p and a negative sample n. We use triplet loss to fine-tune a pre-trained sentence embedding network, such that the distance between a and p is smaller than the distance between a and n using the following loss function.</p><formula xml:id="formula_0" coords="8,209.52,563.55,271.08,30.20">Loss = N n=1 [||S a i -S p i || 2 2 -||S a i -S n i || 2 2 + m] +<label>(1)</label></formula><p>where S a i , S p i and S n i are triplet sentence embeddings and m is the margin (set to 1), N is the number of samples in the batch.</p><p>As each verified claim is a tuple consisting of text and title, we create two triplets for every true tweet-claim pair, i.e., (anchor tweet, true claim text, negative claim text) and (anchor tweet, true claim title, negative claim title). This increases the number of positive samples for training as there are only 800 samples and one true claim for every tweet. To get negative claims, we select 3 claims with highest cosine similarity that are not the true claims for the anchor tweet using the pre-trained sentence-transformer embeddings. For pre-processing, we use Baziotis et. al.'s <ref type="bibr" coords="9,228.38,166.81,10.52,8.74" target="#b2">[3]</ref> tool for processing the tweets to remove URL, email, phone, user mentions, as the claim text or title do not contain any such information.</p><p>As retrieval is a search task, we used KD-Tree search to find the most similar already verified claim that has the minimum Euclidean distance to the query claim. The sentence embeddings extracted from the network are used to build a KD-Tree and for each query claim, top 1000 verified claims are extracted from the tree for evaluation. For building the KD-Tree, we average the sentence embeddings of claim text and claim title, as it performs better than just using either claim or title. In our ablation study, we directly compute the cosine similarity between each query tweet and all the verified claims, and pick the top 1000 (highest cosine similarity) verified claims for evaluation. We conduct the second evaluation because building a KD-Tree can affect the retrieval accuracy.</p><p>Sentence Transformers for Textual Similarity As a backbone network to extract sentence embeddings and fine-tuning with triplet loss, we use the recently proposed Sentence-BERT <ref type="bibr" coords="9,247.41,361.37,10.52,8.74" target="#b8">[9]</ref> that learns the embeddings in a Siamese (pairs) and triplet network settings. We experiment with the pre-trained Siamese Network models trained on SNLI (Stanford Natural Language Inference) <ref type="bibr" coords="9,421.97,385.28,10.52,8.74" target="#b4">[5]</ref> and STSb (Semantic Textual Similarity benchmark) <ref type="bibr" coords="9,319.77,397.24,10.52,8.74" target="#b6">[7]</ref> datasets that have been shown to perform very well for semantic textual similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Task-1: Tweet Check-Worthiness Prediction</head><p>Dataset and Training Details English dataset consists of training, development (dev) and test splits with 672, 150 and 140 tweets respectively on the topic of COVID-19. We perform grid search using development set to find the best parameters. Arabic dataset consists of training and test splits with 1500 tweets on 3 topics and 6000 tweets on 12 topics respectively with 500 tweets on each topic. For validation purpose, we keep 10% (150 samples) from the training data as development set. The official ranking of submitted system for this task is based on Mean Average Precision (MAP) and Precision@30 (P@30) for English and Arabic datasets, respectively.</p><p>To train the SVM models for both English and Arabic, we perform grid search over PCA energy (%) conservation, regularization parameter C and RBF kernel's gamma. Parameters range for PCA varies from 100% (original features) to 95% with decrements of 1, and both C and gamma vary between -3 to 3 on a log-scale with 30 steps. For faster training on a large grid search, we use ThunderSVM <ref type="bibr" coords="9,198.31,644.16,15.50,8.74" target="#b54">[55]</ref> which takes advantage of a GPU or a multi-core system to speed up SVM training.</p><p>Results Our submissions used the best models that we obtained from the grid search and are briefly discussed below.</p><p>English: We made 3 submissions in total. Our primary (Run-1) and 2 nd contrastive (Run-3) submission uses sentence embeddings computed from BERTlarge word embeddings as discussed in the proposed work section. In addition, both submissions use POS tag and dependency relation features. Interestingly, we found that the best performing sentence embeddings did not include stopwords. The primary submission (Run-1) uses an ensemble of predictions from three models trained on concatenated last 4 hidden layers, average of last 4 hidden layers and 2nd last hidden layer. The 2 nd contrastive submission (Run-3) uses predictions from the model trained on the best performing sentence embedding computed from concatenating last 4 hidden layers. Our 1 st contrastive submission (Run-2) uses an ensemble of predictions from three models trained with GloVe[37] on Twitter with 25, 50 and 100-dimensional embeddings but with the same POS tag and dependency relation features. We use majority voting to get the final prediction and mean of decision values to get the final decision value. We found that removing the stop-words to compute average of word embeddings actually degraded the performance and hence included them in the average.</p><p>We also add some additional results to see the effect of stop-words, POS tags, named entities, dependency relations and ensemble predictions in Table <ref type="table" coords="10,472.84,347.42,3.87,8.74" target="#tab_3">3</ref>. The effect of stop-words can be clearly seen in alternative runs of Run-1 and Run-3, where the MAP clearly drops by 1-2 points. Similarly, the negative effect of removing POS tag and dependency relation features can be seen in rest of the alternative runs. Lastly, adding named entity features to the original submissions also decreases the precision by 1-2 points. This might be because the tweets have very few named entities and are not useful to distinguish between check-worthy and not check-worthy claims. For comparison with other teams in the challenge, we show top 3 results at the bottom of the table for reference. Team Accenture <ref type="bibr" coords="10,134.77,455.02,15.50,8.74" target="#b55">[56]</ref> fine-tuned a RoBERTa model with an extra mean pooling and a dropout layer to prevent overfitting. Team Alex <ref type="bibr" coords="10,312.09,466.97,15.50,8.74" target="#b33">[34]</ref> experimented with different tweet pre-processing techniques and various transformer models together with logistic regression and SVM. Their main submission used logistic regression trained on 5-fold predictions from RoBERTa concatenated with tweet metadata. Team QMUL-SDS <ref type="bibr" coords="10,191.90,514.79,10.52,8.74" target="#b0">[1]</ref> fine-tuned a BERT model pre-trained specifically on COVID twitter data.</p><p>Arabic There are a total of four submissions that we made in this task. Our best performing submission (Run-1) uses 100-dimensional word2vec Arabic embeddings trained on a Twitter corpus <ref type="bibr" coords="10,314.07,563.25,15.50,8.74" target="#b48">[49]</ref> in combination with POS tag features. Our second and third submissions are redundant in terms of feature use, so we only mention the second one (Run-2) here. In addition features used in first submission, it uses dependency relation features and 300-dimensional Twitter embeddings instead of 100-dimensional. Our last submission (Run-3) uses only pre-trained multilingual sentence-transformer 7 [41] that is trained on 10 languages including Arabic. In the first three submissions, we removed the stop- words from all the features as keeping them resulted in a poorer performance.</p><p>Precision@K and Average Precision (AP) results on the test set are shown in the same order in Table <ref type="table" coords="11,223.99,461.62,3.87,8.74">4</ref>. Official metric for ranking is P@30. For comparison with other teams in the challenge,we show top 3 results at the bottom of the table for reference. Team Accenture <ref type="bibr" coords="11,252.37,485.53,15.50,8.74" target="#b55">[56]</ref> experimented with and fine-tuned three different pre-trained Arabic BERT models and used external data to increase the positive instances. Team TOBB-ETU <ref type="bibr" coords="11,262.74,509.44,15.50,8.74" target="#b25">[26]</ref> used logistic regression and experimented with Arabic BERT and word embeddings together to classify tweets. Team UB ET <ref type="bibr" coords="11,134.77,533.35,15.50,8.74" target="#b17">[18]</ref> used a multilingual BERT for ranking tweets by check-worthiness. To fine-tune the sentence-transformer network with the triplet loss, we use a batch size of eight and train the network for two epochs. The official ranking of this is based on Mean Average Precision@5 (MAP@5). All tweets and verified claims are in English.</p><p>Table <ref type="table" coords="12,161.95,127.36,3.87,8.74">4</ref>: Task-1 Check-Worthiness Arabic Results, P@K (Precision@K) and AP (Average Precision), *Primary Submission Run ID P@5 P@10 P@15 P@20 P@25 P@30 AP Our primary (Run-1) and 2 nd contrastive (Run-3) submission uses BERTbase and BERT-large pre-trained on SNLI dataset with sentence embedding pooled from the CLS and MAX tokens respectively. We fine-tune these two networks with the triplet loss. On the contrary, our 1 st contrastive submission (Run-2) uses multilingual DistilBERT model <ref type="bibr" coords="12,338.37,359.60,15.50,8.74" target="#b40">[41]</ref> trained on 10 languages including English. This model is directly used to test the pre-trained embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>Results Interestingly, pre-trained embeddings extracted from multilingual Dis-tilBERT without any fine-tuning turn out to be better for semantic similarity than fine-tuned monolingual BERT models. Having said that, the fine-tuned monolingual BERT models do perform better than extracted pre-trained embeddings and the difference can be seen in Run-1-2 and Run-3-2 in Table <ref type="table" coords="12,456.07,476.79,3.87,8.74" target="#tab_5">5</ref>. We also try to fine-tune the multilingual model which drastically decreases the retrieval performance. The decrease can be attributed to the pre-training process <ref type="bibr" coords="12,134.77,512.66,15.50,8.74" target="#b40">[41]</ref> in which the model was trained in a teacher-student knowledge distillation learning framework and on multiple languages. As stated in the proposed work section, we conduct a second evaluation to retrieve the claims with highest similarity without KD-Search and the results are significantly better as shown in Table <ref type="table" coords="12,162.36,560.48,3.87,8.74" target="#tab_5">5</ref>. For comparison with other teams in the challenge, we have shown top 3 primary submissions at the bottom of the table for reference. Team Buster.AI <ref type="bibr" coords="12,134.77,584.39,10.52,8.74" target="#b3">[4]</ref> investigated sentence similarity using transformer models, and experimented with multimodality and data augmentation. Team UNIPI-NLE <ref type="bibr" coords="12,417.46,596.34,15.50,8.74" target="#b35">[36]</ref> fine-tuned a sentence-BERT in two steps, first to predict the cosine similarity of positive and negative pairs, followed by a binary classification of whether a tweet-claim pair is a correct match or not. Team UB ET <ref type="bibr" coords="12,335.74,632.21,15.50,8.74" target="#b52">[53]</ref> experimented with three different models to rank the verified claims and their main submission used a DPH Divergence from Randomness (DFR) term weighting model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>In this paper, we have presented our solutions for two tasks in CLEF Check-That! 2020. In the first task, we used syntactic, contextual features and SVM for predicting the check-worthiness of tweets in Arabic and English. For syntactic features, we evaluated Parts-of-Speech tags, named entities and syntactic dependency relations, and used the best feature sets for both languages. In the case of contextual features, we evaluated different word embeddings, BERT models and sentence-transformers to capture the semantics of each tweet or sentence.</p><p>For future work, we would like to evaluate the possibility of using relevant metadata and other modalities like images and videos present in tweets for claim's check-worthiness. In the second task, we evaluated monolingual and multilingual sentence-transformers to retrieve verified claims for the query tweet. We found that off-the-shelf multilingual sentence-transformer is very well suited for semantic textual similarity task than other monolingual BERT models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="7,134.77,358.57,345.83,8.74;7,134.77,370.53,268.47,8.74;7,134.77,115.83,345.84,231.21"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Syntactic feature extraction and encoding process. Feature vectors are based on the number of times it is seen in the given sentence.</figDesc><graphic coords="7,134.77,115.83,345.84,231.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="8,177.39,385.62,260.58,8.74;8,134.77,115.84,345.80,258.26"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Proposed Approach for Check-Worthiness Prediction</figDesc><graphic coords="8,134.77,115.84,345.80,258.26" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="11,134.77,563.82,144.98,8.77;11,134.77,584.36,345.82,8.77;11,134.77,596.34,345.83,8.74;11,134.77,608.30,345.83,8.74"><head>4. 2</head><label>2</label><figDesc>Task-2: Claim Retrieval Dataset and Training Details The dataset in this task has 1,003 tweets for training and 200 tweets for testing. These tweets are to be matched against a set 10,373 verified claims. From the training set, 197 tweets are kept for validation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,157.02,127.36,301.17,235.79"><head>Table 1 :</head><label>1</label><figDesc>Sample tweets for Task-1 Check-Worthiness Prediction</figDesc><table coords="3,157.02,144.65,301.17,174.27"><row><cell>Tweet</cell><cell cols="2">Claim Check-Worthy</cell></row><row><cell>Dear @VP Pence: What are you hiding from the</cell><cell></cell><cell></cell></row><row><cell>American people? Why won't you let the people see and hear what experts are saying about the</cell><cell>0</cell><cell>0</cell></row><row><cell>#CoronaOutbreak?</cell><cell></cell><cell></cell></row><row><cell>Greeting my good friends from the #US the</cell><cell></cell><cell></cell></row><row><cell>#Taiwan way. Remember: to better prevent the spread of #COVID19, say no to a handshake &amp;</cell><cell>0</cell><cell>0</cell></row><row><cell>yes to this friendly gesture. Check it out:</cell><cell></cell><cell></cell></row><row><cell>Corona got these flights cheap as hell I gotta job interview in Greece Monday</cell><cell>1</cell><cell>0</cell></row><row><cell>My mum has a PhD on Corona Virus from WhatsApp University</cell><cell>1</cell><cell>0</cell></row><row><cell>This is why the beaches haven't closed in</cell><cell></cell><cell></cell></row><row><cell>Florida, and why they've had minimal COVID-19</cell><cell>1</cell><cell>1</cell></row><row><cell>prevention. Absolute dysfunction. &lt;link&gt;</cell><cell></cell><cell></cell></row></table><note coords="3,157.02,322.41,173.97,7.86;3,157.02,333.37,174.12,7.86;3,157.02,344.33,172.28,7.86;3,157.02,355.29,29.44,7.86;3,372.26,338.90,4.61,7.86;3,422.43,338.90,4.61,7.86"><p>COVID-19 cases in the Philippines jumped from 24 to 35 in less than 12 hours. This is seriously ALARMING. Stay safe everyone! &lt;link&gt; 1 1</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,137.52,388.77,340.31,47.10"><head>Table 2 :</head><label>2</label><figDesc>Sample pairs of tweets and verified claims for Task-2 Claim Retrieval</figDesc><table /><note coords="3,170.76,417.07,28.61,7.89;3,221.38,406.09,242.45,7.86;3,221.38,417.05,238.48,7.86;3,221.38,428.01,137.82,7.86"><p><p>Tweet</p>A number of fraudulent text messages informing individuals they have been selected for a military draft have circulated throughout the country this week.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="11,134.77,127.36,345.83,280.67"><head>Table 3 :</head><label>3</label><figDesc>Task-1 Check-Worthiness English Results, MAP (Mean Average Precision), DRel (dependency relations), NE (named entities), *Primary Submission</figDesc><table coords="11,139.75,160.44,336.72,247.59"><row><cell>Run</cell><cell cols="7">Stopwords Ensemble POS DRel NE Embedding MAP</cell></row><row><cell>Run-1  *</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>BERT</cell><cell>0.7217</cell></row><row><cell>Run-2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>GloVe</cell><cell>0.6249</cell></row><row><cell>Run-3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>BERT</cell><cell>0.7139</cell></row><row><cell>Run-1-1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>BERT</cell><cell>0.7102</cell></row><row><cell>Run-1-2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>BERT</cell><cell>0.6965</cell></row><row><cell>Run-1-3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>BERT</cell><cell>0.7094</cell></row><row><cell>Run-1-4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>BERT</cell><cell>0.7100</cell></row><row><cell>Run-3-1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>BERT</cell><cell>0.6889</cell></row><row><cell>Run-3-2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>BERT</cell><cell>0.7074</cell></row><row><cell>Run-3-3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>BERT</cell><cell>0.6981</cell></row><row><cell>Run-3-4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>BERT</cell><cell>0.6940</cell></row><row><cell>[56]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.8064</cell></row><row><cell>[34]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.8034</cell></row><row><cell>[1]</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.7141</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="13,134.77,127.36,345.82,230.16"><head>Table 5 :</head><label>5</label><figDesc>Task-2 Claim Retrieval Results, MAP (Mean Average Precision), *Primary Submission</figDesc><table coords="13,142.59,160.44,330.19,197.08"><row><cell>Run</cell><cell cols="6">Fine-tuned KD-Search MAP@1 MAP@3 MAP@5 MAP@10</cell></row><row><cell>Run-1  *</cell><cell></cell><cell></cell><cell>0.6520</cell><cell>0.6900</cell><cell>0.6950</cell><cell>0.7000</cell></row><row><cell>Run-2</cell><cell></cell><cell></cell><cell>0.8280</cell><cell>0.8680</cell><cell>0.8730</cell><cell>0.8740</cell></row><row><cell>Run-3</cell><cell></cell><cell></cell><cell>0.7180</cell><cell>0.7460</cell><cell>0.7540</cell><cell>0.7600</cell></row><row><cell>Run-1-1</cell><cell></cell><cell></cell><cell>0.703</cell><cell>0.743</cell><cell>0.756</cell><cell>0.760</cell></row><row><cell>Run-1-2</cell><cell></cell><cell></cell><cell>0.527</cell><cell>0.584</cell><cell>0.589</cell><cell>0.594</cell></row><row><cell>Run-2-1</cell><cell></cell><cell></cell><cell>0.858</cell><cell>0.892</cell><cell>0.894</cell><cell>0.896</cell></row><row><cell>Run-3-1</cell><cell></cell><cell></cell><cell>0.718</cell><cell>0.764</cell><cell>0.770</cell><cell>0.772</cell></row><row><cell>Run-3-2</cell><cell></cell><cell></cell><cell>0.532</cell><cell>0.569</cell><cell>0.576</cell><cell>0.585</cell></row><row><cell>[4]</cell><cell>-</cell><cell>-</cell><cell>0.8970</cell><cell>0.9260</cell><cell>0.9290</cell><cell>0.9290</cell></row><row><cell>[36]</cell><cell>-</cell><cell>-</cell><cell>0.8770</cell><cell>0.9070</cell><cell>0.9120</cell><cell>0.9130</cell></row><row><cell>[53]</cell><cell>-</cell><cell>-</cell><cell>0.8180</cell><cell>0.8620</cell><cell>0.8640</cell><cell>0.8660</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="2,144.73,646.48,231.15,7.47"><p>https://sites.google.com/view/clef2020-checkthat/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="2,144.73,657.44,226.45,7.47"><p>https://github.com/cleopatra-itn/claim_detection</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="4,144.73,646.48,84.73,7.47"><p>http://www.cnn.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3" coords="4,144.73,657.44,127.10,7.47"><p>https://www.politifact.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4" coords="10,144.73,657.44,221.74,7.47"><p>https://github.com/UKPLab/sentence-transformers</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This project has received funding from the <rs type="funder">European Union</rs>'s <rs type="programName">Horizon 2020 research and innovation programme</rs> under the <rs type="grantName">Marie Sk lodowska-Curie</rs> grant agreement no <rs type="grantNumber">812997</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_qJAKUV9">
					<idno type="grant-number">812997</idno>
					<orgName type="grant-name">Marie Sk lodowska-Curie</orgName>
					<orgName type="program" subtype="full">Horizon 2020 research and innovation programme</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="14,142.96,142.37,337.63,7.86;14,151.52,153.33,329.07,7.86;14,151.52,164.29,177.22,7.86" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="14,431.96,142.37,48.63,7.86;14,151.52,153.33,329.07,7.86;14,151.52,164.29,177.22,7.86">QMUL-SDS at CheckThat! 2020: Determining COVID-19 tweet check-worthiness using an enhanced CT-BERT with numeric expressions</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Alkhalifa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Yoong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kochkina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zubiaga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Liakata</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,175.21,337.64,7.86;14,151.52,186.17,329.07,7.86;14,151.52,197.12,329.07,7.86;14,151.52,208.08,88.42,7.86" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="14,182.56,197.12,298.03,7.86;14,151.52,208.08,88.42,7.86">Overview of CheckThat! 2020: Automatic identification and verification of claims in social media</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Hamdan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Sheikh Ali</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,219.00,337.64,7.86;14,151.52,229.96,329.07,7.86;14,151.52,240.92,329.07,7.86;14,151.52,251.88,329.07,7.86;14,151.52,262.84,57.64,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="14,316.55,219.00,164.05,7.86;14,151.52,229.96,290.60,7.86">Datastories at semeval-2017 task 4: Deep lstm with attention for message-level and topic-based sentiment analysis</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Baziotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Pelekis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Doulkeridis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,463.03,229.96,17.56,7.86;14,151.52,240.92,283.95,7.86">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
		<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>SemEval; Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-08">2017. August 2017</date>
			<biblScope unit="page" from="747" to="754" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,273.75,337.63,7.86;14,151.52,284.71,276.42,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="14,399.76,273.75,80.83,7.86;14,151.52,284.71,22.53,7.86">Buster.AI at Check-That!</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bouziane</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Perrin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cluzeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mardas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sadeq</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,201.18,284.71,222.84,7.86">Insights and recommendations to improve fact-checking</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,295.63,337.63,7.86;14,151.52,306.59,306.32,7.86" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="14,365.91,295.63,114.68,7.86;14,151.52,306.59,140.38,7.86">A large annotated corpus for learning natural language inference</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">R</forename><surname>Bowman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Angeli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Potts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1508.05326</idno>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="14,142.96,317.50,337.63,7.86;14,151.52,328.46,329.07,7.86;14,151.52,339.42,104.56,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="14,257.44,317.50,223.15,7.86;14,151.52,328.46,28.29,7.86">Automatically identifying fake news in popular twitter threads</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buntain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Golbeck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,201.93,328.46,274.17,7.86">2017 IEEE International Conference on Smart Cloud (SmartCloud)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="208" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,350.33,337.63,7.86;14,151.52,361.29,329.07,7.86;14,151.52,372.25,159.05,7.86" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Diab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Lopez-Gazpio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Specia</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1708.00055</idno>
		<title level="m" coord="14,405.43,350.33,75.16,7.86;14,151.52,361.29,325.09,7.86">Semeval-2017 task 1: Semantic textual similarity-multilingual and cross-lingual focused evaluation</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="14,142.96,383.17,337.63,7.86;14,151.52,394.13,329.07,7.86;14,151.52,405.09,133.43,7.86" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">Y</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Limtiaco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">S</forename><surname>John</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Guajardo-Cespedes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1803.11175</idno>
		<title level="m" coord="14,346.27,394.13,105.27,7.86">Universal sentence encoder</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="14,142.96,416.00,337.63,7.86;14,151.52,426.96,329.07,7.86;14,151.52,437.92,25.60,7.86" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="14,346.99,416.00,133.60,7.86;14,151.52,426.96,189.89,7.86">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="14,142.62,448.84,337.97,7.86;14,151.52,459.80,173.46,7.86" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Dogan</surname></persName>
		</author>
		<title level="m" coord="14,228.11,448.84,252.48,7.86;14,151.52,459.80,88.89,7.86">Detecting Real-time Check-worthy Factual Claims in Tweets Related to US Politics</title>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct coords="14,142.62,470.71,337.98,7.86;14,151.52,481.67,329.07,7.86;14,151.52,492.63,329.07,7.86;14,151.52,503.59,329.07,7.86;14,151.52,514.55,25.60,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="14,295.36,481.67,185.23,7.86;14,151.52,492.63,181.45,7.86">Overview of the clef-2019 checkthat! lab: automatic identification and verification of claims</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Atanasova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,354.28,492.63,126.31,7.86;14,151.52,503.59,235.77,7.86">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="301" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,525.46,337.97,7.86;14,151.52,536.42,250.24,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="14,347.75,525.46,132.84,7.86;14,151.52,536.42,105.59,7.86">Theearthisflat&apos;s submission to clef&apos;19checkthat! challenge</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Favano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Carman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">L</forename><surname>Lanzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,278.18,536.42,94.91,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,547.34,337.98,7.86;14,151.52,558.30,166.45,7.86" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gasior</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Przybyla</surname></persName>
		</author>
		<title level="m" coord="14,255.56,547.34,225.04,7.86;14,151.52,558.30,137.78,7.86">The ipipan team participation in the check-worthiness task of the clef2019 checkthat! lab</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,569.21,337.98,7.86;14,151.52,580.17,304.11,7.86" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ghanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M Y</forename><surname>Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<title level="m" coord="14,375.82,569.21,104.78,7.86;14,151.52,580.17,243.71,7.86">Upv-inaoe-autoritas-check that: Preliminary approach for checking worthiness of claims</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
		<respStmt>
			<orgName>CLEF</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,591.09,337.98,7.86;14,151.52,602.05,329.07,7.86;14,151.52,613.01,292.34,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="14,308.73,591.09,171.86,7.86;14,151.52,602.05,35.49,7.86">Leveraging emotional signals for credibility detection</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Giachanou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,209.36,602.05,271.23,7.86;14,151.52,613.01,208.59,7.86">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="877" to="880" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,623.92,337.98,7.86;14,151.52,634.88,329.07,7.86;14,151.52,645.84,329.07,7.86;14,151.52,656.80,123.58,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="14,362.42,623.92,118.17,7.86;14,151.52,634.88,329.07,7.86;14,151.52,645.84,310.67,7.86">The copenhagen team participation in the check-worthiness task of the competition of automatic identification and verification of claims in political debates of the clef-2018 checkthat! lab</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Simonsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,151.52,656.80,94.91,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,119.67,337.97,7.86;15,151.52,130.63,329.07,7.86;15,151.52,141.59,95.81,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="15,360.85,119.67,119.74,7.86;15,151.52,130.63,285.34,7.86">Neural weakly supervised fact check-worthiness detection with contrastive sampling-based ranking loss</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Simonsen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,455.89,130.63,24.70,7.86;15,151.52,141.59,67.14,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,152.56,337.98,7.86;15,151.52,163.52,153.54,7.86" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="15,258.87,152.56,221.73,7.86;15,151.52,163.52,153.54,7.86">bigIR at CheckThat! 2020: Multilingual BERT for ranking Arabic tweets by check-worthiness</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,174.49,337.98,7.86;15,151.52,185.44,329.07,7.86;15,151.52,196.40,265.84,7.86" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="15,329.77,185.44,150.82,7.86;15,151.52,196.40,265.84,7.86">Overview of CheckThat! 2020 Arabic: Automatic identification and verification of claims in social media</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Hamdan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,207.37,337.98,7.86;15,151.52,218.33,329.07,7.86;15,151.52,229.29,329.07,7.86;15,151.52,240.25,103.93,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="15,344.91,207.37,135.68,7.86;15,151.52,218.33,213.22,7.86">Toward automated fact-checking: Detecting check-worthy factual claims by claimbuster</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Arslan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tremayne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,385.64,218.33,94.95,7.86;15,151.52,229.29,329.07,7.86;15,151.52,240.25,11.14,7.86">Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1803" to="1812" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,251.22,337.98,7.86;15,151.52,262.17,329.07,7.86;15,151.52,273.13,255.00,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="15,292.86,251.22,187.74,7.86;15,151.52,262.17,62.31,7.86">Detecting check-worthy factual claims in presidential debates</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tremayne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,236.21,262.17,244.38,7.86;15,151.52,273.13,161.05,7.86">Proceedings of the 24th acm international on conference on information and knowledge management</title>
		<meeting>the 24th acm international on conference on information and knowledge management</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1835" to="1838" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,284.10,337.97,7.86;15,151.52,295.06,329.07,7.86;15,151.52,306.02,139.87,7.86" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="15,335.70,284.10,144.89,7.86;15,151.52,295.06,223.60,7.86">Comparing automated factual claim detection against judgments of journalism organizations</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tremayne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Arslan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,396.07,295.06,84.52,7.86;15,151.52,306.02,73.51,7.86">Computation+ Journalism Symposium</title>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,316.99,337.97,7.86;15,151.52,327.94,329.07,7.86;15,151.52,338.88,329.07,7.89;15,151.52,349.86,25.60,7.86" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="15,345.25,327.94,135.34,7.86;15,151.52,338.90,96.58,7.86">Claimbuster: the first-ever end-toend fact-checking system</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Arslan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Caraballo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Gawsane</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joseph</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">K</forename><surname>Nayak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,254.53,338.90,150.79,7.86">Proceedings of the VLDB Endowment</title>
		<meeting>the VLDB Endowment</meeting>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1945" to="1948" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,360.83,337.97,7.86;15,151.52,371.79,329.07,7.86;15,151.52,382.75,25.60,7.86" xml:id="b23">
	<monogr>
		<title level="m" type="main" coord="15,262.25,360.83,218.34,7.86;15,151.52,371.79,278.77,7.86">spaCy 2: Natural language understanding with bloom embeddings, convolutional neural networks and incremental parsing</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Honnibal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Montani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct coords="15,142.62,393.72,337.98,7.86;15,151.52,404.67,329.07,7.86;15,151.52,415.63,97.80,7.86" xml:id="b24">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Jaradat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gencheva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1804.07587</idno>
		<title level="m" coord="15,453.46,393.72,27.13,7.86;15,151.52,404.67,257.04,7.86">Claimrank: Detecting check-worthy claims in arabic and english</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="15,142.62,426.60,337.98,7.86;15,151.52,437.56,163.83,7.86" xml:id="b25">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Kartal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<title level="m" coord="15,249.61,426.60,109.52,7.86;15,385.13,426.60,95.46,7.86;15,151.52,437.56,163.83,7.86">Prioritizing English and Arabic claims based on check-worthiness</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>TOBB ETU at CheckThat!</note>
</biblStruct>

<biblStruct coords="15,142.62,448.53,337.98,7.86;15,151.52,459.49,329.07,7.86;15,151.52,470.44,70.14,7.86" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="15,358.07,448.53,122.52,7.86;15,151.52,459.49,147.14,7.86">Mvae: Multimodal variational autoencoder for fake news detection</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Khattar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">S</forename><surname>Goud</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,321.51,459.49,138.07,7.86">The World Wide Web Conference</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2915" to="2921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,481.41,337.97,7.86;15,151.52,492.37,329.07,7.86;15,151.52,503.33,231.46,7.86" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="15,239.07,481.41,241.51,7.86;15,151.52,492.37,278.22,7.86">Early detection of fake news on social media through propagation path classification with recurrent and convolutional networks</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">F B</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,451.39,492.37,29.20,7.86;15,151.52,503.33,202.80,7.86">Thirty-Second AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,514.30,337.98,7.86;15,151.52,525.26,329.07,7.86;15,151.52,536.22,329.07,7.86;15,151.52,547.17,304.41,7.86" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="15,151.52,525.26,329.07,7.86;15,151.52,536.22,67.57,7.86">Claimportal: Integrated monitoring, searching, checking, and analytics of factual claims on twitter</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Majithia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Arslan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lubal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Caraballo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,240.34,536.22,240.25,7.86;15,151.52,547.17,220.14,7.86">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="153" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,558.14,337.97,7.86;15,151.52,569.10,329.07,7.86" xml:id="b29">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Puhrsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1712.09405</idno>
		<title level="m" coord="15,412.81,558.14,67.78,7.86;15,151.52,569.10,163.70,7.86">Advances in pretraining distributed word representations</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="15,142.62,580.07,337.97,7.86;15,151.52,591.03,329.07,7.86;15,151.52,601.99,217.12,7.86" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="15,407.41,580.07,73.17,7.86;15,151.52,591.03,232.55,7.86">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,404.48,591.03,76.12,7.86;15,151.52,601.99,123.83,7.86">Advances in neural information processing systems</title>
		<imprint>
			<biblScope unit="page" from="3111" to="3119" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.62,612.95,337.97,7.86;15,151.52,623.91,329.07,7.86;15,151.52,634.87,97.80,7.86" xml:id="b31">
	<monogr>
		<title level="m" type="main" coord="15,462.03,612.95,18.55,7.86;15,151.52,623.91,260.45,7.86">Fake news detection on social media using geometric deep learning</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Monti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Frasca</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Eynard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mannion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Bronstein</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.06673</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="15,142.62,645.84,337.98,7.86;15,151.52,656.80,329.07,7.86;16,151.52,119.67,329.07,7.86;16,151.52,130.63,329.07,7.86;16,151.52,141.59,164.06,7.86" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="15,378.81,656.80,101.78,7.86;16,151.52,119.67,310.62,7.86">Overview of the clef-2018 checkthat! lab on automatic identification and verification of political claims</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Màrquez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Zaghouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Atanasova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kyuchukov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,151.52,130.63,329.07,7.86;16,151.52,141.59,40.25,7.86">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="372" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,152.56,337.98,7.86;16,151.52,163.52,253.68,7.86" xml:id="b33">
	<monogr>
		<title level="m" type="main" coord="16,376.78,152.56,103.81,7.86;16,151.52,163.52,253.68,7.86">Team Alex at CheckThat! 2020: Identifying check-worthy tweets with transformer models</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Koychev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,174.48,337.98,7.86;16,151.52,185.42,167.03,7.89" xml:id="b34">
	<analytic>
		<title level="a" type="main" coord="16,228.16,174.48,224.59,7.86">Fake news propagation and detection: A sequential model</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Papanastasiou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,459.35,174.48,21.25,7.86;16,151.52,185.44,65.80,7.86">Management Science</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1826" to="1846" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,196.41,337.98,7.86;16,151.52,207.37,329.07,7.86;16,151.52,218.33,95.46,7.86;16,134.77,229.30,11.78,7.86" xml:id="b35">
	<monogr>
		<title level="m" type="main" coord="16,368.87,196.41,111.73,7.86;16,151.52,207.37,329.07,7.86;16,151.52,218.33,95.46,7.86;16,134.77,229.30,7.85,7.86">UNIPI-NLE at CheckThat! 2020: Approaching fact checking from a sentence similarity perspective through the lens of transformers 37</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Passaro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bondielli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lenci</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Marcelloni</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="16,151.52,229.30,329.07,7.86;16,151.52,240.25,329.07,7.86;16,151.52,251.21,215.28,7.86" xml:id="b36">
	<analytic>
		<title level="a" type="main" coord="16,329.82,229.30,150.77,7.86;16,151.52,240.25,35.30,7.86">Glove: Global vectors for word representation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pennington</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,207.71,240.25,272.88,7.86;16,151.52,251.21,120.77,7.86">Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)</title>
		<meeting>the 2014 conference on empirical methods in natural language processing (EMNLP)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="1532" to="1543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,262.18,337.98,7.86;16,151.52,273.14,329.07,7.86;16,151.52,284.10,292.12,7.86" xml:id="b37">
	<analytic>
		<title level="a" type="main" coord="16,362.59,262.18,118.00,7.86;16,151.52,273.14,88.38,7.86">Credibility assessment of textual claims on the web</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Popat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mukherjee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Strötgen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,261.05,273.14,219.54,7.86;16,151.52,284.10,198.10,7.86">Proceedings of the 25th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 25th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="2173" to="2178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,295.06,337.98,7.86;16,151.52,306.02,329.07,7.86;16,151.52,316.98,329.07,7.86;16,151.52,327.94,92.15,7.86" xml:id="b38">
	<analytic>
		<title level="a" type="main" coord="16,377.72,295.06,102.87,7.86;16,151.52,306.02,227.80,7.86">Stanza: A Python natural language processing toolkit for many human languages</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bolton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,403.39,306.02,77.21,7.86;16,151.52,316.98,329.07,7.86;16,151.52,327.94,63.48,7.86">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</title>
		<meeting>the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations</meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,338.91,337.97,7.86;16,151.52,349.87,200.34,7.86" xml:id="b39">
	<monogr>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1908.10084</idno>
		<title level="m" coord="16,257.91,338.91,222.68,7.86;16,151.52,349.87,33.97,7.86">Sentence-bert: Sentence embeddings using siamese bertnetworks</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="16,142.62,360.83,337.98,7.86;16,151.52,371.79,329.07,8.12;16,151.52,383.40,122.39,7.47" xml:id="b40">
	<monogr>
		<title level="m" type="main" coord="16,260.21,360.83,220.39,7.86;16,151.52,371.79,113.57,7.86">Making monolingual sentence embeddings multilingual using knowledge distillation</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.09813(042020</idno>
		<ptr target="http://arxiv.org/abs/2004.09813" />
		<imprint/>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="16,142.62,393.72,337.98,7.86;16,151.52,404.68,329.07,7.86;16,151.52,415.64,173.10,7.86" xml:id="b41">
	<analytic>
		<title level="a" type="main" coord="16,346.25,393.72,134.35,7.86;16,151.52,404.68,240.96,7.86">Claimeval: Integrated and flexible framework for claim evaluation using credibility of sources</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Samadi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Talukdar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Veloso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Blum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,415.57,404.68,65.02,7.86;16,151.52,415.64,144.44,7.86">Thirtieth AAAI Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,426.60,337.97,7.86;16,151.52,437.56,329.07,7.86;16,151.52,448.52,329.07,7.86;16,151.52,459.48,49.46,7.86" xml:id="b42">
	<monogr>
		<title level="m" type="main" coord="16,442.93,437.56,37.66,7.86;16,151.52,448.52,329.07,7.86;16,151.52,459.48,49.46,7.86">Overview of CheckThat! 2020 English: Automatic identification and verification of claims in social media</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shaar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Babulkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hasanain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Suwaileh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Haouari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Da San Martino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,470.45,337.98,7.86;16,151.52,481.41,329.07,7.86;16,151.52,492.37,116.85,7.86" xml:id="b43">
	<monogr>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Shearer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Eva Matsa</surname></persName>
		</author>
		<ptr target="https://www.journalism.org/2018/09/10/news-use-across-social-media-platforms-2018/" />
		<title level="m" coord="16,288.03,470.45,192.57,7.86;16,151.52,481.41,61.17,7.86">How Social Media Has Changed How We Consume News</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,503.33,337.97,7.86;16,151.52,514.29,329.07,7.86;16,151.52,525.25,323.22,7.86" xml:id="b44">
	<analytic>
		<title level="a" type="main" coord="16,292.24,503.33,188.34,7.86;16,151.52,514.29,90.41,7.86">Studying fake news via network analysis: detection and mitigation</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">R</forename><surname>Bernard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,264.82,514.29,215.78,7.86;16,151.52,525.25,208.68,7.86">Emerging Research Challenges and Opportunities in Computational Social Network Analysis and Mining</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="43" to="65" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,536.22,337.98,7.86;16,151.52,547.15,329.07,7.89;16,151.52,558.14,25.60,7.86" xml:id="b45">
	<analytic>
		<title level="a" type="main" coord="16,335.24,536.22,145.35,7.86;16,151.52,547.18,106.94,7.86">Fake news detection on social media: A data mining perspective</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sliva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,266.02,547.18,159.43,7.86">ACM SIGKDD explorations newsletter</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="22" to="36" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,569.10,337.97,7.86;16,151.52,580.04,323.41,7.89" xml:id="b46">
	<analytic>
		<title level="a" type="main" coord="16,390.82,569.10,89.77,7.86;16,151.52,580.06,101.37,7.86">Twitter rumour detection in the health domain</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sicilia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">L</forename><surname>Giudice</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Pei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pechenizkiy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Soda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,260.58,580.06,138.03,7.86">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="page" from="33" to="40" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,591.03,337.98,7.86;16,151.52,601.99,329.07,7.86;16,151.52,612.95,288.01,7.86" xml:id="b47">
	<analytic>
		<title level="a" type="main" coord="16,433.27,591.03,47.33,7.86;16,151.52,601.99,187.40,7.86">Spotfake: A multi-modal framework for fake news detection</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">R</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Chakraborty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kumaraguru</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Satoh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,359.40,601.99,121.19,7.86;16,151.52,612.95,184.55,7.86">2019 IEEE Fifth International Conference on Multimedia Big Data (BigMM)</title>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="39" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,623.91,337.97,7.86;16,151.52,634.85,314.47,7.89" xml:id="b48">
	<analytic>
		<title level="a" type="main" coord="16,321.99,623.91,158.60,7.86;16,151.52,634.87,110.99,7.86">Aravec: A set of arabic word embedding models for use in arabic nlp</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Soliman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Eissa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">R</forename><surname>El-Beltagy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,269.43,634.87,111.02,7.86">Procedia Computer Science</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="page" from="256" to="265" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,645.84,337.98,7.86;16,151.52,656.80,184.24,7.86" xml:id="b49">
	<monogr>
		<title level="m" type="main" coord="16,285.93,645.84,194.67,7.86;16,151.52,656.80,155.57,7.86">Entity detection for check-worthiness prediction: Glasgow terrier at clef checkthat! 2019</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,119.67,337.98,7.86;17,151.52,130.61,186.26,7.89" xml:id="b50">
	<analytic>
		<title level="a" type="main" coord="17,280.09,119.67,197.17,7.86">Least squares support vector machine classifiers</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Suykens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Vandewalle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,151.52,130.63,99.55,7.86">Neural processing letters</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="293" to="300" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,141.59,337.97,7.86;17,151.52,152.52,206.76,7.89" xml:id="b51">
	<analytic>
		<title level="a" type="main" coord="17,304.47,141.59,176.12,7.86;17,151.52,152.55,40.41,7.86">Defining &quot;fake news&quot; a typology of scholarly definitions</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">C</forename><surname>Tandoc</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">W</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,198.67,152.55,72.90,7.86">Digital journalism</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="137" to="153" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,163.51,337.97,7.86;17,151.52,174.47,309.88,7.86" xml:id="b52">
	<monogr>
		<title level="m" type="main" coord="17,410.90,163.51,69.69,7.86;17,151.52,174.47,22.53,7.86;17,201.18,174.47,260.22,7.86">Exploring ad hoc retrieval approaches in verified claims retrieval</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Thuma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">P</forename><surname>Motlogelwa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Leburu-Dingalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mudongo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>UB ET at Check-That!</note>
</biblStruct>

<biblStruct coords="17,142.62,185.43,337.98,7.86;17,151.52,196.39,329.07,7.86;17,151.52,207.35,329.07,7.86;17,151.52,218.30,110.07,7.86" xml:id="b53">
	<analytic>
		<title level="a" type="main" coord="17,431.00,185.43,49.60,7.86;17,151.52,196.39,259.30,7.86">Eann: Event adversarial neural networks for multi-modal fake news detection</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Xun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Jha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,432.52,196.39,48.07,7.86;17,151.52,207.35,329.07,7.86;17,151.52,218.30,25.89,7.86">Proceedings of the 24th acm sigkdd international conference on knowledge discovery &amp; data mining</title>
		<meeting>the 24th acm sigkdd international conference on knowledge discovery &amp; data mining</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="849" to="857" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,229.26,337.97,7.86;17,151.52,240.20,309.50,7.89" xml:id="b54">
	<analytic>
		<title level="a" type="main" coord="17,326.12,229.26,154.47,7.86;17,151.52,240.22,65.86,7.86">ThunderSVM: A fast SVM library on GPUs and CPUs</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,225.67,240.22,155.11,7.86">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="797" to="801" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,251.18,337.98,7.86;17,151.52,262.14,273.70,7.86" xml:id="b55">
	<monogr>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Novak</surname></persName>
		</author>
		<title level="m" coord="17,312.43,251.18,168.17,7.86;17,151.52,262.14,273.70,7.86">Accenture at CheckThat! 2020: If you say so: Post-hoc fact-checking of claims using transformer-based models</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,273.10,337.98,7.86;17,151.52,284.03,222.33,7.89" xml:id="b56">
	<analytic>
		<title level="a" type="main" coord="17,297.96,273.10,117.91,7.86">Principal component analysis</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Wold</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Esbensen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Geladi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,423.17,273.10,57.42,7.86;17,151.52,284.06,137.16,7.86">Chemometrics and intelligent laboratory systems</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="37" to="52" />
			<date type="published" when="1987">1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,295.02,337.97,7.86;17,151.52,305.98,259.84,7.86" xml:id="b57">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yasser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kutlu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Elsayed</surname></persName>
		</author>
		<title level="m" coord="17,293.83,295.02,186.76,7.86;17,151.52,305.98,115.15,7.86;17,287.77,305.98,94.92,7.86">bigir at clef 2018: Detection and verification of check-worthy political claims</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note>CLEF (Working Notes)</note>
</biblStruct>

<biblStruct coords="17,142.62,316.93,337.98,7.86;17,151.52,327.89,329.07,7.86;17,151.52,338.85,154.13,7.86" xml:id="b58">
	<analytic>
		<title level="a" type="main" coord="17,273.05,316.93,207.54,7.86;17,151.52,327.89,101.36,7.86">Enquiring minds: Early detection of rumors in social media from enquiry posts</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Resnick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Mei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,273.69,327.89,206.90,7.86;17,151.52,338.85,60.50,7.86">Proceedings of the 24th international conference on world wide web</title>
		<meeting>the 24th international conference on world wide web</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1395" to="1405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,349.81,337.97,7.86;17,151.52,360.77,329.07,7.86;17,151.52,371.70,75.12,7.89" xml:id="b59">
	<analytic>
		<title level="a" type="main" coord="17,422.63,349.81,57.96,7.86;17,151.52,360.77,184.79,7.86">Detection and resolution of rumours in social media: A survey</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zubiaga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Aker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Bontcheva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Liakata</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Procter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="17,342.73,360.77,137.87,7.86">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,382.69,337.97,7.86;17,151.52,393.65,329.07,7.86;17,151.52,404.61,62.50,7.86" xml:id="b60">
	<analytic>
		<title level="a" type="main" coord="17,314.50,382.69,166.08,7.86;17,151.52,393.65,59.30,7.86">Exploiting context for rumour detection in social media</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zubiaga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Liakata</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Procter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,233.37,393.65,188.48,7.86">International Conference on Social Informatics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="109" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,415.56,337.97,7.86;17,151.52,426.52,329.07,7.86" xml:id="b61">
	<analytic>
		<title level="a" type="main" coord="17,296.30,415.56,184.29,7.86;17,151.52,426.52,185.97,7.86">A hybrid recognition system for check-worthy claims using heuristics and supervised learning</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zuo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Karakas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Banerjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,357.91,426.52,94.32,7.86">CLEF (Working Notes)</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
