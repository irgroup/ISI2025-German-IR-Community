<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,323.26,115.96,132.11,12.62;1,161.84,133.89,291.67,12.62;1,278.37,151.82,58.63,12.62">Lightweight neural document ranking with zero-shot snippet retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,143.99,189.49,64.48,8.74"><forename type="first">Tiago</forename><surname>Almeida</surname></persName>
							<email>tiagomeloalmeida@ua.pt</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">University of Aveiro</orgName>
								<orgName type="institution" key="instit2">IEETA</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">DETI/IEETA</orgName>
								<orgName type="institution">University of Aveiro</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,323.26,115.96,132.11,12.62;1,161.84,133.89,291.67,12.62;1,278.37,151.82,58.63,12.62">Lightweight neural document ranking with zero-shot snippet retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C97EF179AA77B5FE6E6FADE907C8774D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the participation of the University of Aveiro Biomedical Informatics and Techologies (BIT) group in the eighth edition of the BioASQ challenge for the document and snippet retrieval tasks. Our system follows a two-stage retrieval pipeline, where a group of candidate documents is retrieved based on BM25 and reranked by a lightweight interaction-based model that uses the context of exact matches to refine the ranking. Additionally, we also show a zero-shot setup for snippet retrieval based on the architecture of our interaction based model. Our system achieved competitive results scoring at the top or close to the top for all the batches, with MAP values ranging from 33.98% to 48.42% in the document retrieval task, although being less effective on snippet retrieval.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Last year (2019), PubMed indexed almost one and a half million articles, which is equivalent to almost three new articles indexed every minute. 3 As a consequence, it is continually more time consuming for a biomedical expert to successfully search this unprecedented amount of available information. So, given the current artificial intelligence (AI) revolution, it is clear that such systems can be exploited to aid with this searching task and ultimately help researchers to rapidly find consistent information about their research topic.</p><p>The BioASQ <ref type="bibr" coords="1,209.03,534.13,15.50,8.74" target="#b24">[25]</ref> challenge provides annual competitions on document classification, retrieval and question-answering applied to the biomedical domain. These competitions are notable for continuously pushing the development of intelligent systems capable of tackling the previously enunciated problem.</p><p>This paper describes the participation of the Biomedical Informatics and Techologies (BIT) group in the eighth edition of the BioASQ challenge, specifically in the document and snippet retrieval tasks of BioASQ 8b Phase A. More precisely, the objective is to retrieve, from the PubMed/MEDLINE collection, the most relevant articles and documents snippets for a given biomedical question written in English.</p><p>Our approach is an evolution of a previous work <ref type="bibr" coords="2,369.53,155.10,10.52,8.74" target="#b0">[1]</ref> that develops and applies a two-stage retrieval system to the biomedical searching problem. More concretely, it uses the Elasticsearch engine with BM25 weighing scheme to reduce the search space and then applies a neural ranking model in this smaller space to produce a final ranking order. In this work, we focus on improving the neural ranking model by simplifying the previous architecture and by adopting some modifications based on new assumptions. Furthermore, one of the enhancements enables us to directly extract the importance that the model assigns to each document passage without the need of training the model on this specific task, which makes it a zero-shot learner. In other words, the neural ranking model is only trained to predict the relevance of an entire document for a given question.</p><p>The final neural ranking model, presented here, has only 620 trainable parameters, making it an extremely lightweight approach when compared to transformer based models which are the current state-of the-art for NLP related tasks.</p><p>Our submissions achieved the top and close to the top positions for every document retrieval batch and also showed interesting results for all of the snippet retrieval batches. These are insightful results, that show the potential of our lightweight neural ranking model and demonstrate a potential zeroshot learning setup that can be easily extended to a snippet retrieval task. The full network configuration is publicly available at https://github.com/ bioinformatics-ua/BioASQ_CLEF, together with code for replicating the results presented in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>In classical IR methods, a ranking function is parameterized by a set of handcrafted features to score the relevance of a query-document pair. Nowadays, recent works on the application of deep learning methods to IR, and questionanswering in particular, have shown very good results. In this new perspective, commonly referred to as neural IR, the ranking function is approximated by a neural network that learns its parameters from large data collections. In the literature, neural models are usually subdivided into two categories based on their architecture. In one category, the models learn a semantic representation of the texts and use a similarity measure to score each query-document pair. Examples in this representation-based category include the Deep Structured Semantic Model (DSSM) <ref type="bibr" coords="2,220.49,596.34,10.52,8.74" target="#b6">[7]</ref> and the Convolutional Latent Semantic Model (CLSM) <ref type="bibr" coords="2,134.77,608.30,14.61,8.74" target="#b22">[23]</ref>. On the other hand, in interaction-based approaches, query and document matching signals are captured and then fed to a neural network that produces a ranking score based on the extracted matching patterns over these signals. Examples include the Deep Relevance Matching Model (DRMM) <ref type="bibr" coords="2,403.85,644.16,10.52,8.74" target="#b5">[6]</ref> and DeepRank <ref type="bibr" coords="2,134.77,656.12,14.61,8.74" target="#b16">[17]</ref>.</p><p>Since 2018, transformer-based architectures, like GPT <ref type="bibr" coords="3,395.09,118.99,15.50,8.74" target="#b19">[20]</ref> and BERT <ref type="bibr" coords="3,467.31,118.99,9.96,8.74" target="#b4">[5]</ref>, have been revolutionizing the NLP field, showing outstanding performance in the majority of tasks. These are large models that explore transfer learning techniques by leveraging the knowledge learned on enormous text collection. Following this trend, some promising works show positive results when applying this type of models for the ad-hoc retrieval task <ref type="bibr" coords="3,348.88,178.77,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="3,361.06,178.77,7.75,8.74" target="#b3">4,</ref><ref type="bibr" coords="3,370.48,178.77,11.62,8.74" target="#b11">12]</ref>. However, despite the indisputable performance presented by these architectures, it is also undeniable that the dimension of such models is a major drawback, that makes it almost impossible for some institutions to deploy or even use these models given their demanding computational costs.</p><p>Endorsed by the annual BioASQ competition, biomedical IR became a challenge with a wide range of different solutions, either based on traditional IR, neural IR, or a combination of both. For example, the system proposed by the USTB PRIR team <ref type="bibr" coords="3,218.89,276.47,10.52,8.74" target="#b8">[9]</ref> uses query enrichment strategies, Sequential Dependence Models (SDM) and pseudo-relevance feedback to obtain a list of relevant documents. This traditional approach scored in the top positions between the third and fifth edition, which highlights early challenges of applying neural models to this task. The system proposed by the AUEB team <ref type="bibr" coords="3,371.22,324.29,10.52,8.74">[2]</ref> was the first to show some evidence that deep neural models are capable of outscoring the traditional models by scoring at the top positions in the sixth and seventh editions. Their system uses a variation of DRMM <ref type="bibr" coords="3,285.83,360.15,15.50,8.74" target="#b13">[14]</ref> or BERT <ref type="bibr" coords="3,347.15,360.15,10.52,8.74" target="#b4">[5]</ref> to rerank the top 100 documents recovered using the BM25 scheme <ref type="bibr" coords="3,315.64,372.11,14.61,8.74" target="#b21">[22]</ref>. The importance of the reranking step is evidenced by comparing the results to another work that submitted the top documents directly retrieved based on BM25 <ref type="bibr" coords="3,351.23,396.02,14.61,8.74" target="#b12">[13]</ref>.</p><p>3 Base architecture Fig. <ref type="figure" coords="3,225.69,630.30,4.13,7.89">1</ref>. Overview of our two-stage retrieval system</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Phase-I</head><p>The main objective of this phase is to reduce the enormous searching space by only selecting the most top-N potential relevant documents for a given question. Given the large dimension of the article collection (approximately 30 million scientific articles), it is important to consider an efficient solution capable of handling this growing collection. With this in mind, we decided to rely on ElasticSearch (ES) with the BM25 weighting scheme described in Equation <ref type="formula" coords="4,472.84,197.67,3.87,8.74" target="#formula_1">1</ref>. As mentioned before, only the exact matching signals are considered during this retrieval phase.</p><formula xml:id="formula_0" coords="4,172.31,242.01,266.77,55.49">IDF (q i ) = ln(1 + C -f (q i ) + 0.5 f (q i ) + 0.5 ), weight(q i , D) = IDF (q i ) × f (q i , D) × (k 1 + 1) f (q i , D) + k 1 (1 -b + b × |D| avg l (D) )</formula><p>.</p><p>(</p><formula xml:id="formula_1" coords="4,472.10,264.96,8.49,8.74">)<label>1</label></formula><p>Equation 1 presents the weighting scheme of each query term q i with respect to a document D, where C corresponds to the total number of documents in the collection, f (q i ) represents the number of documents that contain the term q i , f (q i , D) represents the frequency of term q i in document D, |D| corresponds to the total number of terms in document D, i.e., its length, avg t (D) represents the average length of the documents in the collection, and k 1 , b are hyperparameters that should be finetuned for the collection.</p><p>At last, given the weight of each query term with respect to a document, weight(q i , D), the final query-document score is computed by taking a summation of each query term weight, as shown in Equation <ref type="formula" coords="4,371.96,411.13,3.87,8.74">2</ref>. score(Q, D) = qi∈Q weight(q i , D).</p><p>(2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Phase-II</head><p>The second phase has the objective of reranking the previously retrieved top-N documents by taking into consideration additional matching signals to produce the final ranking order. The rationale here is that the previous step only considers the exact matching signals, i.e., only the words that appear both on the query and the document are taken into account and weighted to produce the phase-I ranking. So a more powerful neural solution may be able to learn how to better explore the context where these exact matches occur. More precisely, our model is inspired by the DeepRank <ref type="bibr" coords="4,390.98,576.22,15.50,8.74" target="#b16">[17]</ref> architecture and represents a direct enhancement of our previous work <ref type="bibr" coords="4,381.58,588.17,9.96,8.74" target="#b0">[1]</ref>, with the following major differences:</p><p>• Passages no longer follow the query-centric assumption and now correspond directly to entire document sentences; • The detection network and the measure network were simplified and now form the interaction network;</p><p>• The passage position input was dropped;</p><p>• The contributions of each passage to the final document score are now assumed to be independent, replacing the self-attention proposed in <ref type="bibr" coords="5,441.95,142.84,9.96,8.74" target="#b0">[1]</ref>; • The pooling step now receives more operators, namely average and average over k-max; • Calculation of the passage relevance score was simplified.</p><p>The intuition behind this model is to make a thorough evaluation of the document passages where the exact matches occur, by taking into consideration their context. More precisely, this model explores the interactions presented in the entire passage of each exact match and makes a more refined judgment of the passage relevance based on that.</p><p>The updated architecture is depicted in Figure <ref type="figure" coords="5,353.76,259.98,4.98,8.74" target="#fig_0">2</ref> and described here in detail in order to keep this paper self-contained. First, let us define a query as a sequence of terms q = {u 0 , u 1 , ..., u Q }, where u i is the i-th term of the query and Q the size of the query; a document passage as p = {v 0 , v 1 , ..., v T }, where v k is the k-th term of the passage and T the size of the passage; and a document as sequence of passages D = {p 0 , p 1 , ..., p N }. From the architecture presented in Figure <ref type="figure" coords="5,333.58,493.29,4.98,8.74" target="#fig_0">2</ref> it is observable that a document is first split into individual sentences, i.e., a sequence of passages. In this step, we rely on the nltk.PunktSentenceTokenizer<ref type="foot" coords="5,326.06,515.62,3.97,6.12" target="#foot_0">4</ref> , that implements an unsupervised algorithm for sentence splitting and shows good results on majority of European languages. Then, passages are grouped with each query-term occurring in the passage, and the resulting structure is fed to the interaction network together with the full query to calculate relevance scores for each passage. The final document score is produced in the aggregation network taking into consideration each passage score and the relative importance of each query term.</p><p>In more detail, the Grouping by q-term block associates each passage with each query term that appears in the passage. Formally, this step produces a set of document passages aggregated by each query term as D(u i ) = {p i0 , p i1 , ..., p iP }, where p ij corresponds to the j-th passage with respect to the query term u i . This aggregated flow facilitates considering the weight of each query term in downstream calculations in a straightforward way, as proposed in DRMM <ref type="bibr" coords="6,459.80,130.95,9.96,8.74" target="#b5">[6]</ref>.</p><p>The Interaction network was designed to independently evaluate each query-passage interaction, producing a final relevance score per sentence. In detail, it receives as input the query q and the aggregated set of passages D(u i ) and creates for each query-passage pair a similarity tensor (interaction matrix) S ∈ [-1, 1]</p><p>Q×T , where each entry S ij corresponds to the cosine similarity between the embeddings of the i-th query term and j-th passage term,</p><formula xml:id="formula_2" coords="6,134.77,215.54,69.69,16.25">S ij = ui T • vj ui × vj .</formula><p>Next, an x by y convolution followed by a concatenation of the global max, average and average k-max pooling operation are applied to each similarity tensor, to capture multiple local relevance signals from each feature map, as described in Equation <ref type="formula" coords="6,270.64,257.42,3.87,8.74" target="#formula_3">3</ref>,</p><formula xml:id="formula_3" coords="6,209.32,283.67,271.27,92.81">h m i,j = x s=0 y t=0 w m s,t × S i+s,j+t + b m , h m max = max(h m ), m = 1, ..., M , h m avg = avg(h m ), m = 1, ..., M , h m avg-kmax = avg(k-max(h m )), m = 1, ..., M , h = {h max ; h avg ; h avg-kmax }.<label>(3)</label></formula><p>Here, w and b are trainable parameters, the symbol ';' represents the concatenation operator, M corresponds to the total number of filters and the vector h</p><formula xml:id="formula_4" coords="6,134.77,423.93,22.51,6.12">3M ×1</formula><p>encodes the local relevance between each query-passage, extracted by these pooling operations. At this point, the aggregated set of passages D(u i ) is now represented by their respective vectors h, i.e., D(u i ) = { h p0 , h p1 , ..., h p P }.</p><p>The final step of the interaction network is to convert these passage representations h to a final relevance score, for which we employed a fully connected layer with sigmoid activation, Equation <ref type="formula" coords="6,310.16,483.10,3.87,8.74" target="#formula_5">4</ref>,</p><formula xml:id="formula_5" coords="6,240.04,514.26,236.31,17.07">r ui P ×3M = σ( h ui P ×3M • w 3M ×1 + b 1×1 ). (<label>4</label></formula><formula xml:id="formula_6" coords="6,476.35,514.26,4.24,8.74">)</formula><p>The aim here is to derive a relevance score, relevant (1) or irrelevant (0), directly from the information that was extracted by the pooling operators. So, after this stage the aggregated set of passages D(u i ) is represented by this relevance score, i.e., D(u i ) = {r p0 , r p1 , ..., r p P } = r ui .</p><p>The aggregation network, as already mentioned, takes into consideration the importance of each query term by using a gating mechanism, similar to DRMM <ref type="bibr" coords="6,170.56,620.25,9.96,8.74" target="#b5">[6]</ref>, over the aggregated set of passages, as described in Equation <ref type="formula" coords="6,448.66,620.25,3.87,8.74" target="#formula_7">5</ref>. That is, each passage score is weighted by the importance of its associated query term, following the intuition that in a query different terms carry different importance with respect to the final information goal.</p><formula xml:id="formula_7" coords="7,265.24,128.36,215.35,68.75">c ui = w 1×E • x ui E×1 , a ui = e cu i u k ∈Q e cu k , s ui P ×1 = a ui 1×1 × r ui P ×1 ,<label>(5)</label></formula><p>Here, w is a trainable parameter and x ui corresponds to the embedding vector of the u i query term. Then the distribution of the query term importance, a, is computed as a softmax and applied to the respective passages scores, r ui .</p><p>To produce the final document score, a scorable vector s is created by performing a summation alongside the query-term dimension of s ui . Note that in this step we could have explored other ways to produce this final vector, however, this approach seems to empirically work. Finally, this scorable vector s is fed to a Multi-Layer Percepreton (MLP) to produce the final ranking score, as summarized in Equation <ref type="formula" coords="7,244.85,299.61,3.87,8.74">6</ref>.</p><formula xml:id="formula_8" coords="7,255.79,323.52,224.80,20.06">score = M LP ( ui∈Q s ui ) (6)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Snippet Retrieval</head><p>As initially stated in <ref type="bibr" coords="7,229.62,381.15,9.96,8.74" target="#b0">[1]</ref>, this architecture has an interesting property that enables us to directly infer the relevance of each passage according to the model perspective, i.e., the passages scores that most contribute to the final document score. We can therefore derive a final score for each passage as the score given by the interaction network weighted by the query term importance, which was already computed and corresponds to the vector s ui .</p><p>It is important to note that extracting the most relevant passages per document is not the same as producing a ranked list of passage relevance as intended in the BioASQ competition, which implies comparing passages between different documents. In our case, however, passage scores are not directly comparable since they are obtained with respect to their document, which involves different distributions. So, similarly to [2], we assume that passages from documents with higher document scores are more relevant than passages from documents with a lower score, which seems intuitive. We therefore obtain the list of passages by collecting, from the top ranked documents, all passages with a score above a set threshold. However, a better approach could be explored in the future by producing scores that take into consideration the passage itself and the score of the respective document.</p><p>Furthermore, it is noteworthy to reinforce that this strategy works in an unsupervised manner, in the sense that the model does not take into consideration the gold-standard of the passage relevance, but instead produces this relevance based on what is important to increase the final score of a relevant document, according to the document gold-standard. From another perspective, we can argue that the model is pretrained on the document gold-standard and then applied to the snippet retrieval task, making this a zero-shot learning setup since it was never trained on the passage gold-standard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Joint Training</head><p>Moved by the interesting results, especially in terms of snippet performance, reported in the previous BioASQ challenge <ref type="bibr" coords="8,318.69,192.43,14.61,8.74" target="#b17">[18]</ref>, we also tried to implement a joint training methodology that explores both document and snippet gold-standards, instead of only training with the document gold-standard. More precisely, we compute the binary cross entropy loss over the passage relevance from Equation <ref type="formula" coords="8,134.77,240.25,3.87,8.74" target="#formula_5">4</ref>. Then we added the average cross entropy loss of each passage to the document pairwise loss and trained the model over this combination of the two losses. Note that the architecture for document score and snippet retrieval remained the same, since our main idea at this point was to exploit the snippet gold-standard to, through supervision, enforce the model to distinguish relevant from nonrelevant passages. Furthermore, as will be addressed in the following sections and discussed in Section 5, this idea empirically failed to improve the model performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Submission and Results</head><p>In the section, we start by detailing the data collection and some pre-processing steps that are common to our official submissions for the 5 batches. Then we independently show our results for each batch since we continuously refined our base solution by better finetuning the hyperparameters and changing small aspects of the architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Collection and Pre-processing</head><p>In this edition of the BioASQ challenge, the document collection was the 2019 PubMed/MEDLINE annual baseline consisting of almost 30 million articles. However, only roughly 66% of the articles had title and abstract, so following previous observations [2], we decided to discard the remaining 34%, which were rarely relevant according to the gold-standard. At this point, our collection had approximately 20 million documents that were indexed (title and abstract) with Elasticsearch using the english text analyzer, which automatically performs tokenization, stemming and stopword filtering.</p><p>We adopted a custom tokenizer that uses simple regular expressions to exclude none alphanumeric characters except the hyphen, since many words in the biomedical domain contain a hyphen, like chemical substances. This way we keep these words intact, which enhances the detection of important exact matches. We also trained 200-dimensional word embeddings using the GenSim <ref type="bibr" coords="8,435.12,620.25,15.50,8.74" target="#b20">[21]</ref> implementation of word2vec <ref type="bibr" coords="8,237.52,632.21,14.60,8.74" target="#b14">[15]</ref>, with the 20 million documents (title and abstract) following the described tokenization, which produced a vocabulary of approximately 4 million tokens. We used the default configuration of the word2vec algorithm and fixed the embeddings matrix during the training of the neural ranking model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Training Details and Hyperparameters</head><p>For training our neural ranking model, we used the gold-standard data from the 1-7 editions of BioASQ, with the exception of one test batch of the seventh edition that we used for validation. Contrarily to our previous work <ref type="bibr" coords="9,451.03,199.09,9.96,8.74" target="#b0">[1]</ref>, we adopted the pairwise cross-entropy loss, as suggested by Hui et al. <ref type="bibr" coords="9,421.48,211.05,10.52,8.74" target="#b7">[8]</ref> and shown in Equation <ref type="formula" coords="9,189.42,223.00,3.87,8.74">7</ref>.</p><formula xml:id="formula_9" coords="9,200.79,250.56,89.91,10.81">L(q, d + , d -) = -log(</formula><p>e (score(q,d + )) e (score(q,d + )) + e (score(q,d -)) ) <ref type="bibr" coords="9,467.86,252.64,12.73,8.74" target="#b6">(7)</ref> Since the BioASQ data only provides a list of relevant (positive) documents per query, we sampled the negative documents as the documents that were retrieved by the ES but did not appear in the gold-standard. Another important note is that only the top 10 documents per submission are analyzed by experts in terms of relevance, which may produce an incomplete gold-standard, i.e., positive documents may not be judged since they were not retrieved by participating systems and hence are taken as negative documents during training. To exacerbate the problem, the gold-standard was built as a concatenation of the judged relevance of documents from different years, which implies a different snapshot of the document collection. To alleviate this problem, we restrict the ES search by year so that only the available documents at that time are available to the model training.</p><p>We gave a major emphasis to training/validation in order to gain a better intuition of the model behavior and what configuration should be followed in each batch. The neural ranking model was trained using the Adam <ref type="bibr" coords="9,419.06,440.29,15.50,8.74" target="#b9">[10]</ref> optimizer, alongside with modern techniques like learning rate finder and cyclical learning rates <ref type="bibr" coords="9,160.78,464.20,14.61,8.74" target="#b23">[24]</ref>. The finetuning of this model was a rolling process that took the duration of the 5 batches. More concretely, we searched the kernel size for the convolution, the total number of filters, the pooling operation, the activation functions, and other minor details that ended up not influencing the overall performance. To summarize, Table <ref type="table" coords="9,289.57,512.02,4.98,8.74" target="#tab_0">1</ref> shows the model configuration that seems to be the strongest producing a model with only 620 trainable parameters.</p><p>The model was implemented in TensorFlow <ref type="foot" coords="9,349.36,534.35,3.97,6.12" target="#foot_1">5</ref> and is available at https: //github.com/bioinformatics-ua/BioASQ_CLEF. The entire training process was conducted with the help of an in-house toolbox that implements pairwise training in TensorFlow. <ref type="foot" coords="9,240.45,570.22,3.97,6.12" target="#foot_2">6</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">BioASQ Evaluation</head><p>The BioASQ evaluation is divided in two stages. In the first stage, the submissions are evaluation against a gold-standard annotated by biomedical experts. In a second stage, the biomedical experts will manually annotate the relevance of the retrieved documents from each submission. At the time of writing, only the results for the first stage are available, corresponding to the results presented in this paper. In terms of numerical evaluation, the organizers automatically compute five measures (Mean Precision, Recall, F-Measure (F1), MAP and GMAP) over each submission given the current gold-standard. According to the challenge evaluation guidelines <ref type="bibr" coords="10,256.99,332.36,14.61,8.74" target="#b18">[19]</ref>, the overall system rankings are based on the MAP measure.</p><p>Our group submitted five runs for each of the batches, which can be identified by the prefix "bioinfo" on the official results <ref type="foot" coords="10,348.49,366.65,3.97,6.12" target="#foot_3">7</ref> . In the following sections we present a summary table of the results, comparing our five submissions to the top competitor in each batch, i.e., with the top performing system excluding our systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Submission and Results for Batch 1</head><p>For the first batch, the BioASQ organizers received a total of 21 submissions from 8 teams 8 . For this run, our main idea was to validate the performance of our phase-I retrieval mechanism and to test if our phase-II reranking model was indeed boosting the original ranking order. As a summary, we submitted one run with the results coming from phase-I, i.e., the BM25 ranking order that was finetuned on the validation set, while the remaining runs were produced by reranking the phase-I results with our neural ranking model:</p><p>• bioinfo-0: A finetuned BM25 run produced by the ElastisSearch; • bioinfo-1 to 4: Neural reranking of the Top-250 documents produced by the finetunned BM25.</p><p>At the time of this submission, our ranking model was still in an initial phase of development, which means that it did not completely follow the architecture presented in Section 3.2. More concretely, the model only used the max-pooling operator and a simple linear combination was used for producing the final document score, instead of an MLP. Table <ref type="table" coords="11,178.48,269.10,4.98,8.74" target="#tab_1">2</ref> reflects the first stage of the BioASQ evaluation for our submissions. In terms of document retrieval, the "bioinfo-3" submission achieved the top score in terms of MAP, which means it was the best performing system in this batch. Additionally, the "bioinfo-2" submission was the second-best performing system and achieved the best result in terms of recall and GMAP. For the snippet retrieval, our best performing system achieved fifth place and also showed interesting results in terms of recall and F-measure when compared to the top-performing system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Submission and Results for Batch 2</head><p>The second batch received a total of 26 submissions from 9 teams. Our system was built directly on the validation performed for the gold-standard of the previous test batch and the validation set. More precisely, we tested the addition of more pooling operators (average and average over k-max) and the addition of the MLP for scoring, which empirically proved to be beneficial. Additionally, we also decided to pursue a joint training approach described in Section 3.4 and the following list presents a summary of each submitted system:</p><p>• bioinfo-0: Neural reranking model with joint training (snippets and documents); • bioinfo-1,3 and 4: Neural reranking described in Section 3.2; • bioinfo-2: Neural reranking using max and average pooling operator.</p><p>Table <ref type="table" coords="11,177.96,584.39,4.98,8.74" target="#tab_2">3</ref> shows the performance of the submitted systems, overall only the system that was trained in joint fashion achieved a poor performance. For document retrieval, our top-performing system was the "bioinfo-3", which achieved third place in the overall ranking and also the best score in terms of GMAP. For the snippet retrieval, our best performing system achieved the fourth place on the overall ranking and similarly to the previous batch showed interesting results in terms of recall and F-measures when compared to other systems. Contrarily to the previous sections, we now present the results for the third, fourth and fifth batches in the same section, since the submissions for the different batches all follow the same description:</p><p>• bioinfo-0: Ensemble of multiple Neural reranking models;</p><p>• bioinfo-1 to 4: Neural reranking described in Section 3.2.</p><p>The organizers received a total of 28 submissions from 9 teams for the third batch, 26 submissions from 11 teams for the fourth batch, and 25 submissions from 9 teams for the last batch. Given that the proposed joint training seemed to deteriorate the overall performance we decided to keep the focus on the current solution and leave as future work a reformulation of the joint training idea. So, we replaced the joint training submission with a submission that used a naive ensemble of multiple neural reranking models that were trained during validation. Note that for the ensemble run we did not produce a ranked list of snippets since the proposed snippet algorithm does not support multiple relevance values, from different sources, per passage.</p><p>Table <ref type="table" coords="12,176.46,481.89,4.98,8.74" target="#tab_3">4</ref> presents a summary of the results obtained for the last three batches. Focusing now on the document retrieval task, "bioinfo-3" was our best performing system in the third batch achieving a fourth place in the overall ranking and, additionally, "bioinfo-0" was the best system in terms of recall and GMAP. Similarly, "bioinfo-3" was our best performing system in the fourth batch, with a fourth place, and "bioinfo-0" achieved the best result in terms of recall. For the fifth batch, "bioinfo-4" achieved the overall best performance, ranking first place in both MAP and recall. We also achieved the top score in terms of GMAP with the "bioinfo-1" submission. In terms of snippet retrieval, the best ranking was a fifth place on the third and fifth batches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>In this section we discuss the previously presented results, analyzing first the overall performance on the document retrieval task followed by the results on Addressing the results presented in Tables 2, 3 and 4, we consider that our system had an extremely competitive permanence, being in the top position for the first and fifth batch and close to the top in the remaining batches. Additionally, we note that at least one of our submissions achieved the best performance in at least one metric for all the batches. Furthermore, if we look at the GMAP metric it is observable that our systems achieved the best results in all but the fourth batch.</p><p>With respect to the neural reranking performance comparative to the phase-I ranking, we can see in Table <ref type="table" coords="13,259.53,571.96,4.98,8.74" target="#tab_1">2</ref> that every neural submission was able to improve the original BM25 ranking order, what is in accord with our speculation and validation results. So, these results also seem to be according to our proposed idea of better exploring the context where the exact match occurs to produce a more refined judgment that contributes to the final score.</p><p>As previously said, after the first batch and based on some validation tests we decided to change the model by adding more pooling operations and the MLP. However, at a first glance, according to the results on the second, third, and fourth batches, it seems that these changes were not beneficial, since the system was not able to achieve the top performance, similarly to the first batch. However, we argue that this discrepancy can also be a consequence of some improvement of the competitors systems after the first batch. Additionally, we experiment the updated architecture on the first batch and were able to easily achieve a MAP score of over 35%, surpassing the previous best.</p><p>Finally, the only metric for which our system does not seem to be able to achieve competitive results is F-measure. However, as noted previously <ref type="bibr" coords="14,453.32,203.18,14.61,8.74" target="#b17">[18]</ref>, a system that outputs confidence scores instead of ranking scores seems to be able to achieve higher performance in terms of this metric. A possible explanation relies on the BioASQ data and more properly on the questions that have only a few true positive documents 9 in the collection. In this case, a system based on confidence scores can easily create a ranked list with fewer than 10 documents (the maximum considered per question), since it selects the relevant documents based on a threshold value over the confidence scores. So, for this type of questions, a system based on confidence is more likely to achieve higher values of Precision and Recall (resulting in a higher F1 measure) when compared to a ranking system that will obtain a higher Recall but lower Precision since it always outputs the top 10 documents.</p><p>In terms of snippet retrieval, the submitted system did not present competitive results when compared to the top submissions, being the best performance a fourth place in the second batch. However, given that our method does not use the snippet gold-standard for training and follows a naive ranking approach, we consider these results encouraging, especially in terms of recall and F-measure, and with the potential to be better explored in future work.</p><p>Concerning the joint training approach, we considered that it has empirically failed. More precisely, it seems that our intuition to improve the passage relevance with supervision may be more challenging to achieve. One problem is the notion of passage relevance since most of the time a relevant snippet in the gold-standard encompasses multiple sentences, which the model will see and score as independent. So, this supervision may be forcing the model to boost the relevance score of sentences that in isolation carry week matching signals, ending up hindering the overall matching signal extraction. Another problem lies on the naive implementation of the snippet retrieval algorithm. Another idea is to directly use the snippet gold-standard to produce ranking scores, more similar to the winning approach in <ref type="bibr" coords="14,256.29,538.92,14.61,8.74" target="#b17">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>In this paper, we propose a two-stage retrieval pipeline to address the biomedical retrieval problem. Our system first uses BM25 to selected a pool of potential relevant candidates that are then reranked by a neural ranking model. Contrarily to the NLP trend, we focused on building a lightweight interaction based model, which yields a final model with only 620 trainable parameters. The proposed architecture can also be used to produce relevance scores for each document passage according to the model perspective of relevance. This property enables us to perform passage retrieval in a zero-shot learning setup.</p><p>The proposed pipeline was evaluated on the eighth edition of BioASQ, were it achieved competitive results for the document retrieval task, being on and close to the top in all batches. In the snippet retrieval task, it showed interesting results given that they were produced by a naive algorithm in a zero-shot learning setup.</p><p>As future work, there are minor questions still open especially on the aggregation network configuration. Additionally, an interesting route is to compare the current architecture with a direct, but parameter-greedy, extension that uses a state-of-the-art transformer based model, such as BERT, which are well suited to our objective of better evaluating the passage context. This may be achieved by replacing the word2vec embeddings by the context-aware embeddings produced by these models or by completely replacing the interaction network.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,134.77,450.96,345.83,7.89;5,134.77,461.95,18.68,7.86;5,169.35,351.60,276.65,84.59"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Overview of the neural ranking model with a tensor representation of the data flow.</figDesc><graphic coords="5,169.35,351.60,276.65,84.59" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="10,134.77,115.91,345.83,119.55"><head>Table 1 .</head><label>1</label><figDesc>List of the hyperparameters and their respective values. In some cases, the range of tested values is listed, with the best one highlighted in bold.</figDesc><table coords="10,137.53,147.16,340.29,88.30"><row><cell>Hyperparameter</cell><cell>Value</cell></row><row><cell>BM25 k1 and b</cell><cell>k1∈[0.1, ..., 0.4, ..., 1.25] and b∈[0.2, ..., 0.4, ..., 0.7].</cell></row><row><cell>ES top-N</cell><cell>250, 500, 1000</cell></row><row><cell>Number maximum of query tokens, Q</cell><cell>30</cell></row><row><cell>Number maximum of passage tokens, T</cell><cell>30</cell></row><row><cell>Maximum of passage aggregated to each q-term, P</cell><cell>5</cell></row><row><cell>Kernel size</cell><cell>3 by 3, multiples (2 by 2, 3 by 3) following [8]</cell></row><row><cell>Filters</cell><cell>16, 20 , 32</cell></row><row><cell>Pooling operations</cell><cell>{max}, {max and avg}, {max, avg and avg over k-max}</cell></row><row><cell>Activation function</cell><cell>leakyReLU, selu [11], mish [16]</cell></row><row><cell>Embedding size</cell><cell>200</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="11,134.77,115.91,345.83,123.01"><head>Table 2 .</head><label>2</label><figDesc>Summary of the results for the first batch of the BioASQ challenge. Our five submission are presented at the top of the table, starting with the prefix "bioinfo". Additional, we highlight, in bold, the best recorded values per each metric.</figDesc><table coords="11,137.80,158.48,339.76,80.44"><row><cell>System</cell><cell cols="8">Rank Recall F1 MAP GMAP Rank Recall F1 MAP GMAP</cell></row><row><cell></cell><cell></cell><cell>Document Retrieval</cell><cell></cell><cell></cell><cell cols="3">Snippet Retrieval</cell><cell></cell></row><row><cell>bioinfo-0</cell><cell>8</cell><cell>44.62 16.27 30.67</cell><cell>0.63</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>bioinfo-1</cell><cell>6</cell><cell>44.84 16.92 32.23</cell><cell>1.03</cell><cell>7</cell><cell cols="3">17.77 13.86 26.32</cell><cell>0.05</cell></row><row><cell>bioinfo-2</cell><cell>2</cell><cell cols="2">48.64 17.59 33.83 1.20</cell><cell>5</cell><cell cols="3">17.15 15.00 29.53</cell><cell>0.06</cell></row><row><cell>bioinfo-3</cell><cell>1</cell><cell cols="2">48.20 17.48 33.98 1.20</cell><cell>8</cell><cell cols="3">18.23 15.91 24.06</cell><cell>0.05</cell></row><row><cell>bioinfo-4</cell><cell>4</cell><cell>47.79 17.47 33.59</cell><cell>1.03</cell><cell>6</cell><cell cols="3">17.91 15.01 26.53</cell><cell>0.07</cell></row><row><cell cols="2">Top competitior 3</cell><cell>44.00 16.86 33.59</cell><cell>0.88</cell><cell>1</cell><cell cols="4">24.67 17.52 85.75 0.17</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="12,134.77,115.91,345.82,157.76"><head>Table 3 .</head><label>3</label><figDesc>Summary of the results for the second batch of the BioASQ challenge. Our five submission are presented at the top of the table, starting with the prefix "bioinfo". Additional, we highlight, in bold, the best recorded values per each metric.</figDesc><table coords="12,134.77,158.47,342.80,115.20"><row><cell>System</cell><cell cols="6">Rank Recall F1 MAP GMAP Rank Recall F1 MAP GMAP</cell></row><row><cell></cell><cell></cell><cell>Document Retrieval</cell><cell></cell><cell></cell><cell>Snippet Retrieval</cell><cell></cell></row><row><cell>bioinfo-0</cell><cell>8</cell><cell>43.41 18.30 29.10</cell><cell>1.17</cell><cell>13</cell><cell>16.17 11.75 18.84</cell><cell>0.09</cell></row><row><cell>bioinfo-1</cell><cell>4</cell><cell>47.55 19.94 31.49</cell><cell>1.86</cell><cell>5</cell><cell>21.03 14.61 27.21</cell><cell>0.16</cell></row><row><cell>bioinfo-2</cell><cell>7</cell><cell>46.48 19.14 30.84</cell><cell>1.52</cell><cell>6</cell><cell>20.18 14.08 26.37</cell><cell>0.11</cell></row><row><cell>bioinfo-3</cell><cell>3</cell><cell cols="2">48.80 20.27 31.68 2.23</cell><cell>7</cell><cell>20.04 14.08 26.37</cell><cell>0.11</cell></row><row><cell>bioinfo-4</cell><cell>5</cell><cell>47.87 20.02 31.20</cell><cell>1.61</cell><cell>4</cell><cell>20.09 14.13 27.67</cell><cell>0.16</cell></row><row><cell cols="2">Top competitior 1</cell><cell cols="2">45.01 23.00 33.04 1.85</cell><cell>1</cell><cell cols="2">25.31 17.73 68.21 0.15</cell></row><row><cell cols="6">4.6 Submission and Results for Batch 3, 4 and 5</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="13,134.77,115.91,345.83,356.24"><head>Table 4 .</head><label>4</label><figDesc>Summary of the results for the third, fourth and fifth batches of the BioASQ challenge. Our submissions are presented at the top of each batch, starting with the prefix "bioinfo". Additional, we highlight, in bold, the best recorded values per each metric.</figDesc><table coords="13,134.77,167.68,345.82,304.47"><row><cell>System</cell><cell cols="8">Rank Recall F1 MAP GMAP Rank Recall F1 MAP GMAP</cell></row><row><cell></cell><cell></cell><cell cols="2">Batch 3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Document Retrieval</cell><cell></cell><cell></cell><cell cols="3">Snippet Retrieval</cell><cell></cell></row><row><cell>bioinfo-0</cell><cell>7</cell><cell cols="2">54.15 18.73 43.50 2.07</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>bioinfo-1</cell><cell>11</cell><cell>52.43 18.11 42.68</cell><cell>1.55</cell><cell>7</cell><cell cols="3">27.01 16.70 39.10</cell><cell>0.37</cell></row><row><cell>bioinfo-2</cell><cell>8</cell><cell>53.20 18.08 43.03</cell><cell>1.86</cell><cell>6</cell><cell cols="3">28.25 17.29 40.85</cell><cell>0.36</cell></row><row><cell>bioinfo-3</cell><cell>4</cell><cell>53.65 18.20 43.69</cell><cell>2.04</cell><cell>5</cell><cell cols="3">29.63 17.34 41.37</cell><cell>0.37</cell></row><row><cell>bioinfo-4</cell><cell>10</cell><cell>54.08 18.83 42.84</cell><cell>2.02</cell><cell>8</cell><cell cols="3">26.79 16.61 37.76</cell><cell>0.32</cell></row><row><cell cols="2">Top competitior 1</cell><cell cols="2">53.77 19.32 45.10 1.87</cell><cell>1</cell><cell cols="4">35.58 21.40 100.39 0.56</cell></row><row><cell></cell><cell></cell><cell cols="2">Batch 4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Document Retrieval</cell><cell></cell><cell></cell><cell cols="3">Snippet Retrieval</cell><cell></cell></row><row><cell>bioinfo-0</cell><cell>7</cell><cell>55.60 19.95 39.77</cell><cell>1.92</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>bioinfo-1</cell><cell>8</cell><cell>55.28 19.30 39.71</cell><cell>2.01</cell><cell>10</cell><cell cols="3">25.29 16.62 34.55</cell><cell>0.13</cell></row><row><cell>bioinfo-2</cell><cell>6</cell><cell>55.53 19.77 40.06</cell><cell>2.10</cell><cell>7</cell><cell cols="3">25.84 17.23 36.59</cell><cell>0.15</cell></row><row><cell>bioinfo-3</cell><cell>4</cell><cell>53.92 19.38 40.24</cell><cell>1.31</cell><cell>9</cell><cell cols="3">26.55 17.42 35.00</cell><cell>0.15</cell></row><row><cell>bioinfo-4</cell><cell>10</cell><cell>54.44 19.75 38.69</cell><cell>1.54</cell><cell>12</cell><cell cols="3">25.29 16.62 34.55</cell><cell>0.13</cell></row><row><cell cols="2">Top competitior 1</cell><cell cols="2">54.46 19.67 41.63 2.04</cell><cell>1</cell><cell cols="4">33.03 21.51 102.44 0.55</cell></row><row><cell></cell><cell></cell><cell cols="2">Batch 5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Document Retrieval</cell><cell></cell><cell></cell><cell cols="3">Snippet Retrieval</cell><cell></cell></row><row><cell>bioinfo-0</cell><cell>4</cell><cell>62.08 19.95 47.47</cell><cell>3.20</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>bioinfo-1</cell><cell>3</cell><cell cols="2">62.21 19.97 47.80 3.49</cell><cell>8</cell><cell cols="3">31.94 19.46 42.97</cell><cell>0.24</cell></row><row><cell>bioinfo-2</cell><cell>7</cell><cell>59.98 19.09 46.45</cell><cell>2.40</cell><cell>10</cell><cell cols="3">31.94 19.47 42.06</cell><cell>0.24</cell></row><row><cell>bioinfo-3</cell><cell>5</cell><cell>61.54 19.67 46.65</cell><cell>2.88</cell><cell>9</cell><cell cols="3">32.05 19.35 42.70</cell><cell>0.23</cell></row><row><cell>bioinfo-4</cell><cell>1</cell><cell cols="2">62.63 19.78 48.42 3.30</cell><cell>5</cell><cell cols="3">32.14 19.60 43.79</cell><cell>0.29</cell></row><row><cell cols="2">Top competitior 2</cell><cell>60.50 39.63 48.25</cell><cell>2.54</cell><cell>1</cell><cell cols="4">35.36 24.91 112.67 0.38</cell></row><row><cell cols="9">snippet retrieval. We complement this discussion with our considerations on</cell></row><row><cell cols="4">what was successful and what has failed.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="5,144.73,656.80,305.41,7.86"><p>https://kite.com/python/docs/nltk.tokenize.punkt.PunktSentenceTokenizer</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1" coords="9,144.73,646.48,127.10,7.47"><p>https://www.tensorflow.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2" coords="9,144.73,656.80,300.22,8.12"><p>The toolbox is open-sourced here: https://github.com/T-Almeida/mmnrm</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_3" coords="10,144.73,646.48,254.69,7.47"><p>http://participants-area.bioasq.org/results/8b/phaseA/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="15,142.96,358.54,337.63,7.86;15,151.52,369.50,329.07,7.86;15,151.52,380.45,329.07,7.86;15,151.52,391.41,329.07,7.86;15,151.52,402.37,4.61,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="15,250.04,358.54,230.55,7.86;15,151.52,369.50,28.51,7.86">Calling attention to passages for biomedical question answering</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Matos</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-030-45442-5</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-45442-5" />
	</analytic>
	<monogr>
		<title level="m" coord="15,253.11,380.45,139.77,7.86">Advances in Information Retrieval</title>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Jose</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Yilmaz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Magalhães</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Castells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Silva</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Martins</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="69" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.96,413.73,337.64,7.86;15,151.52,424.69,329.07,8.12;15,151.52,436.29,47.07,7.47" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">I</forename><surname>Brokos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Liosis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Pappas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1809.06366" />
		<title level="m" coord="15,443.21,413.73,37.38,7.86;15,151.52,424.69,179.55,7.86">AUEB at BioASQ 6: Document and Snippet Retrieval</title>
		<imprint>
			<date type="published" when="2018-09">sep 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.96,447.00,337.63,7.86;15,151.52,457.96,329.07,7.86;15,151.52,468.92,329.07,7.86;15,151.52,479.88,329.07,7.86;15,151.52,490.83,166.72,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="15,232.09,447.00,248.49,7.86;15,151.52,457.96,62.74,7.86">Deeper text understanding for ir with contextual neural language modeling</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<idno type="DOI">10.1145/3331184.3331303</idno>
		<ptr target="https://doi.org/10.1145/3331184.3331303" />
	</analytic>
	<monogr>
		<title level="m" coord="15,239.40,457.96,241.20,7.86;15,151.52,468.92,259.10,7.86;15,469.07,468.92,11.52,7.86;15,151.52,479.88,27.15,7.86">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="985" to="988" />
		</imprint>
	</monogr>
	<note>SI-GIR&apos;19</note>
</biblStruct>

<biblStruct coords="15,142.96,502.19,337.64,7.86;15,151.52,513.15,329.07,7.86;15,151.52,524.11,329.07,7.86;15,151.52,535.06,166.72,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="15,248.65,502.19,231.95,7.86;15,151.52,513.15,23.54,7.86">Context-aware document term weighting for ad-hoc search</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Dai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
		<idno type="DOI">10.1145/3366423.3380258</idno>
		<ptr target="https://doi.org/10.1145/3366423.3380258" />
	</analytic>
	<monogr>
		<title level="m" coord="15,201.17,513.15,178.34,7.86;15,452.18,513.15,28.41,7.86;15,151.52,524.11,10.75,7.86">Proceedings of The Web Conference 2020</title>
		<meeting>The Web Conference 2020<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1897" to="1907" />
		</imprint>
	</monogr>
	<note>WWW &apos;20</note>
</biblStruct>

<biblStruct coords="15,142.96,546.42,337.63,7.86;15,151.52,557.38,230.16,7.86" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<title level="m" coord="15,354.85,546.42,125.74,7.86;15,151.52,557.38,201.50,7.86">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.96,568.73,337.63,7.86;15,151.52,579.69,329.07,7.86;15,151.52,590.65,329.07,7.86;15,151.52,601.61,166.72,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="15,354.43,568.73,126.15,7.86;15,151.52,579.69,117.96,7.86">A deep relevance matching model for ad-hoc retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Ai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<idno type="DOI">10.1145/2983323.2983769</idno>
		<ptr target="https://doi.org/10.1145/2983323.2983769" />
	</analytic>
	<monogr>
		<title level="m" coord="15,280.93,579.69,199.65,7.86;15,151.52,590.65,269.99,7.86">Proceedings of the 25th ACM International on Conference on Information and Knowledge Management</title>
		<meeting>the 25th ACM International on Conference on Information and Knowledge Management</meeting>
		<imprint>
			<date type="published" when="2016-10">Oct 2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,142.96,612.96,337.64,7.86;15,151.52,623.92,329.07,7.86;15,151.52,634.88,329.07,7.86;15,151.52,645.84,329.07,7.86;15,151.52,656.80,219.96,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="15,397.14,612.96,83.46,7.86;15,151.52,623.92,248.87,7.86">Learning deep structured semantic models for web search using clickthrough data</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Acero</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Heck</surname></persName>
		</author>
		<idno type="DOI">10.1145/2505515.2505665</idno>
		<ptr target="https://doi.org/10.1145/2505515.2505665" />
	</analytic>
	<monogr>
		<title level="m" coord="15,421.89,623.92,58.70,7.86;15,151.52,634.88,329.07,7.86;15,151.52,645.84,120.27,7.86">Proceedings of the 22nd ACM international conference on Conference on information &amp; knowledge management -CIKM &apos;13</title>
		<meeting>the 22nd ACM international conference on Conference on information &amp; knowledge management -CIKM &apos;13<address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2333" to="2338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.96,119.67,337.64,7.86;16,151.52,130.63,329.07,7.86;16,151.52,141.59,166.72,7.86" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="16,387.02,119.67,93.57,7.86;16,151.52,130.63,205.30,7.86">Co-pacrr: A contextaware neural ir model for ad-hoc retrieval</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Berberich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>De Melo</surname></persName>
		</author>
		<idno type="DOI">10.1145/3159652.3159689</idno>
		<ptr target="https://doi.org/10.1145/3159652.3159689" />
		<imprint>
			<date type="published" when="2018-02">02 2018</date>
			<biblScope unit="page" from="279" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.96,151.83,337.63,7.86;16,151.52,162.79,329.07,7.86;16,151.52,173.75,110.50,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="16,387.95,151.83,92.64,7.86;16,151.52,162.79,329.07,7.86;16,151.52,173.75,27.96,7.86">A multi-strategy query processing approach for biomedical question answering: Ustb prir at bioasq 2017 task 5b</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">X</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">W</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><forename type="middle">C</forename><surname>Yin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,200.72,173.75,32.64,7.86">BioNLP</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,183.98,337.98,7.86;16,151.52,194.94,329.07,7.86;16,151.52,205.90,329.07,7.86;16,151.52,216.86,172.45,8.12" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="16,244.82,183.98,182.98,7.86">Adam: A method for stochastic optimization</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1412.6980" />
	</analytic>
	<monogr>
		<title level="m" coord="16,240.03,194.94,240.56,7.86;16,151.52,205.90,42.85,7.86">3rd International Conference on Learning Representations, ICLR 2015</title>
		<title level="s" coord="16,358.32,205.90,122.27,7.86">Conference Track Proceedings</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</editor>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2015">May 7-9, 2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,227.10,337.97,7.86;16,151.52,238.06,76.62,7.86" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="16,387.64,227.10,92.95,7.86;16,151.52,238.06,35.66,7.86">Self-normalizing neural networks</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Klambauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Unterthiner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mayr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hochreiter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">06</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,248.29,337.97,7.86;16,151.52,259.25,329.07,7.86;16,151.52,270.21,329.07,7.86;16,151.52,281.17,329.07,7.86;16,151.52,292.13,166.72,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="16,363.17,248.29,117.42,7.86;16,151.52,259.25,107.49,7.86">Cedr: Contextualized embeddings for document ranking</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Macavaney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goharian</surname></persName>
		</author>
		<idno type="DOI">10.1145/3331184.3331317</idno>
		<ptr target="https://doi.org/10.1145/3331184.3331317" />
	</analytic>
	<monogr>
		<title level="m" coord="16,278.88,259.25,201.72,7.86;16,151.52,270.21,267.66,7.86;16,151.52,281.17,35.66,7.86">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1101" to="1104" />
		</imprint>
	</monogr>
	<note>SIGIR&apos;19</note>
</biblStruct>

<biblStruct coords="16,142.62,302.37,337.98,7.86;16,151.52,313.33,214.84,7.86" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="16,306.70,302.37,173.90,7.86;16,151.52,313.33,9.73,7.86">Mindlab neural network approach at bioasq 6b</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mateus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/W18-5305</idno>
		<ptr target="https://doi.org/10.18653/v1/W18-5305" />
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,323.56,337.98,7.86;16,151.52,334.52,329.07,8.11;16,151.52,346.13,47.07,7.47" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">I</forename><surname>Brokos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1809.01682" />
		<title level="m" coord="16,360.49,323.56,120.11,7.86;16,151.52,334.52,179.00,7.86">Deep Relevance Ranking Using Enhanced Document-Query Interactions</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,355.72,337.98,7.86;16,151.52,366.68,329.07,7.86;16,151.52,377.64,329.07,7.86;16,151.52,388.60,307.11,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="16,387.82,355.72,92.78,7.86;16,151.52,366.68,213.28,7.86">Distributed representations of words and phrases and their compositionality</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,385.64,366.68,94.95,7.86;16,151.52,377.64,284.42,7.86;16,209.37,388.60,31.47,7.86">Proceedings of the 26th International Conference on Neural Information Processing Systems</title>
		<meeting>the 26th International Conference on Neural Information Processing Systems<address><addrLine>Red Hook, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates Inc</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
	<note>NIPS&apos;13</note>
</biblStruct>

<biblStruct coords="16,142.62,398.83,337.98,7.86" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="16,193.45,398.83,259.37,7.86">Mish: A self regularized non-monotonic neural activation function</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Misra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,409.07,337.98,7.86;16,151.52,420.03,329.07,7.86;16,151.52,430.99,194.36,7.86" xml:id="b16">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Cheng</surname></persName>
		</author>
		<idno type="DOI">10.1145/3132847.3132914</idno>
		<ptr target="https://doi.org/10.1145/3132847.3132914" />
		<title level="m" coord="16,376.82,409.07,103.77,7.86;16,151.52,420.03,305.89,7.86">Deeprank. Proceedings of the 2017 ACM on Conference on Information and Knowledge Management</title>
		<imprint>
			<date type="published" when="2017-11">Nov 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,441.23,337.98,7.86;16,151.52,452.19,329.07,7.86;16,151.52,463.14,329.07,7.86;16,151.52,474.10,101.04,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="16,407.79,441.23,72.80,7.86;16,151.52,452.19,124.59,7.86">Aueb at bioasq 7: Document and snippet retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Pappas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">I</forename><surname>Brokos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Androutsopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,418.25,452.19,62.34,7.86;16,151.52,463.14,175.73,7.86">Machine Learning and Knowledge Discovery in Databases</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Cellier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Driessens</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="607" to="623" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,484.34,337.98,7.86;16,151.52,495.30,329.07,8.12;16,151.52,506.90,23.54,7.47" xml:id="b18">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Prodromos</forename><surname>Malakasiotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">A D</forename><surname>Ioannis Pavlopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nentidis</surname></persName>
		</author>
		<ptr target="http://participants-area.bioasq.org/Tasks/b/eval_meas_2020/" />
		<title level="m" coord="16,415.68,484.34,64.91,7.86;16,151.52,495.30,65.82,7.86">Evaluation measures for task b</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,516.50,337.97,7.86;16,151.52,527.46,183.44,7.86" xml:id="b19">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Radford</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Narasimhan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Salimans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<title level="m" coord="16,384.93,516.50,95.65,7.86;16,151.52,527.46,154.76,7.86">Improving language understanding by generative pre-training</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,535.43,337.98,10.13;16,151.52,548.65,329.07,7.86;16,151.52,559.61,329.07,8.12;16,151.52,571.22,98.85,7.47" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="16,247.47,537.69,233.12,7.86;16,151.52,548.65,16.61,7.86">Software Framework for Topic Modelling with Large Corpora</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Řehůřek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sojka</surname></persName>
		</author>
		<ptr target="http://is.muni.cz/publication/884893/en" />
	</analytic>
	<monogr>
		<title level="m" coord="16,190.68,548.65,289.90,7.86;16,151.52,559.61,46.28,7.86">Proceedings of the LREC 2010 Workshop on New Challenges for NLP Frameworks</title>
		<meeting>the LREC 2010 Workshop on New Challenges for NLP Frameworks<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<publisher>ELRA</publisher>
			<date type="published" when="2010-05">May 2010</date>
			<biblScope unit="page" from="45" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,580.81,337.97,7.86;16,151.52,591.74,329.07,7.89;16,151.52,602.72,145.73,7.86" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="16,300.59,580.81,180.00,7.86;16,151.52,591.77,80.05,7.86">The probabilistic relevance framework: Bm25 and beyond</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
		<idno type="DOI">10.1561/1500000019</idno>
		<ptr target="https://doi.org/10.1561/1500000019" />
	</analytic>
	<monogr>
		<title level="j" coord="16,243.46,591.77,111.87,7.86">Found. Trends Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="333" to="389" />
			<date type="published" when="2009-04">Apr 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,142.62,612.96,337.98,7.86;16,151.52,623.92,329.07,7.86;16,151.52,634.88,329.07,7.86;16,151.52,645.84,329.07,7.86;16,151.52,656.80,197.94,7.86" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="16,352.74,612.96,127.85,7.86;16,151.52,623.92,233.44,7.86">A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Mesnil</surname></persName>
		</author>
		<idno type="DOI">10.1145/2661829.2661935</idno>
		<ptr target="https://doi.org/10.1145/2661829.2661935" />
	</analytic>
	<monogr>
		<title level="m" coord="16,406.07,623.92,74.53,7.86;16,151.52,634.88,329.07,7.86;16,151.52,645.84,101.97,7.86">Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management -CIKM &apos;14</title>
		<meeting>the 23rd ACM International Conference on Conference on Information and Knowledge Management -CIKM &apos;14<address><addrLine>New York, New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="101" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,119.67,296.48,7.86" xml:id="b23">
	<monogr>
		<title level="m" type="main" coord="17,204.63,119.67,205.80,7.86">Cyclical learning rates for training neural networks</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">N</forename><surname>Smith</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,142.62,130.63,337.98,7.86;17,151.52,141.59,329.07,7.86;17,151.52,152.55,329.07,7.86;17,151.52,163.51,329.07,7.86;17,151.52,174.47,329.07,7.86;17,151.52,185.40,329.07,7.89;17,151.52,196.39,26.11,7.86" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="17,404.81,163.51,75.78,7.86;17,151.52,174.47,329.07,7.86;17,151.52,185.43,14.75,7.86">An overview of the bioasq large-scale biomedical semantic indexing and question answering competition</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Tsatsaronis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Balikas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Malakasiotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Partalas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zschunke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Alvers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Weißenborn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Krithara</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Petridis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Polychronopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Almirantis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pavlopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Baskiotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gallinari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Artieres</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C</forename><surname>Ngonga Ngomo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Heino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Barrio-Alvers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Paliouras</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12859-015-0564-6</idno>
		<ptr target="https://doi.org/10.1186/s12859-015-0564-6" />
	</analytic>
	<monogr>
		<title level="j" coord="17,172.43,185.43,82.67,7.86">BMC Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">04</biblScope>
			<biblScope unit="page">138</biblScope>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
