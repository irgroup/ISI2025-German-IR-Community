<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,227.59,116.56,160.18,13.46;1,173.53,136.37,268.30,11.21">Three is Better than One Ensembling Math Information Retrieval Systems</title>
				<funder>
					<orgName type="full">Brno Ph</orgName>
				</funder>
				<funder>
					<orgName type="full">South Moravian Centre for International Mobility</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,175.78,177.48,52.42,9.58"><forename type="first">Vít</forename><surname>Novotný</surname></persName>
						</author>
						<author>
							<persName coords="1,235.92,177.48,42.14,9.58"><forename type="first">Petr</forename><surname>Sojka</surname></persName>
							<email>sojka@fi.muni.cz</email>
						</author>
						<author>
							<persName coords="1,284.89,177.48,66.94,9.58"><forename type="first">Michal</forename><surname>Štefánik</surname></persName>
						</author>
						<author>
							<persName coords="1,377.93,177.48,61.65,9.58"><forename type="first">Dávid</forename><surname>Lupták</surname></persName>
							<email>dluptak@mail.muni.cz</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">Math Information Retrieval Research Group</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">mir.fi.muni.cz</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Faculty of Informatics</orgName>
								<orgName type="institution">Masaryk University Botanická</orgName>
								<address>
									<addrLine>68a</addrLine>
									<postCode>602 00</postCode>
									<settlement>Brno</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,227.59,116.56,160.18,13.46;1,173.53,136.37,268.30,11.21">Three is Better than One Ensembling Math Information Retrieval Systems</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C4BC7DAC604DF5BFD7D68859AADAE19C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Math information retrieval</term>
					<term>question answering</term>
					<term>math representations</term>
					<term>word embeddings</term>
					<term>ensembling</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We report on the systems that the Math Information Retrieval group at Masaryk University (MIRMU) prepared for tasks 1 (find answers) and 2 (formula search) of the ARQMath lab at the CLEF conference. We prototyped three primary MIR systems, proposed several math representations to tackle the lab tasks, and evaluated the proposed systems and representations. We developed a novel algorithm for ensembling information retrieval systems that outperformed all our systems on task 1 and placed ninth out of the 23 competing submissions. Out-of-competition ensembles of all non-baseline primary submissions in the competition made available by the participants placed first on task 1 and third on task 2. Our prototypes will help to understand the challenging problems of answer and formula retrieval in the STEM domain and bring the possibility of accurate math information retrieval one step closer.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="22" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="23" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="24" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="25" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="26" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="27" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="28" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="29" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="30" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Math Information Retrieval (MIR) group at Masaryk University (MIRMU) is interested in challenges of MIR already for more than a decade. The challenges are numerous:</p><p>3. How to pick the canonical representation of formulae in context for formulae retrieval? 4. How to integrate the inference into the information retrieval or question answering system?</p><p>In the ARQMath competition, we tackled both task 1 (find answers) and task 2 (formula search). We researched and evaluated several ways of tackling the challenges <ref type="bibr" coords="2,199.67,196.62,16.60,9.58" target="#b40">[41]</ref> to push the boundaries of knowledge in MIR.</p><p>We prototyped and submitted results for three primary systems, MIaS, SCM, and COMPUBERT, and a secondary system, Formula2Vec. <ref type="foot" coords="2,389.93,218.54,3.79,7.28" target="#foot_0">1</ref> Our main objective was to gain insight into the problems above and we submitted five result lists for both tasks. We think that the key in solving the challenges lies in the accurate representation of meaning of texts and formulae in context-thus we opted to prototype systems that primarily tackle the math representation problem.</p><p>We preprocessed the data and represented both given data and other STEM corpora as arXiv to learn the joint representations of text and math. We have compared several math formulae representations and used unsupervised approaches for representation learning. Finally, we ensembled our primary submissions into a committee of MIR systems that was able to achieve better result on task 1 than any of the ensembled method alone.</p><p>In this report we report in detail about our achievements: Section 2 describes in detail the resources we used and our math representations. Section 3 reports about using our venerable old MIaS system for ARQMath tasks. In sections 4 and 5, systems based on the embeddings of shallow multilayer perceptrons are evaluated. To push the envelope and catch up with the recent trends in the NLP, we experiment with using the Transformer architecture to produce math representations with our COMPUBERT system in Section 6. The description of our ensembling algorithm can be found in Section 7. Our results, insights we got, and future directions are thoroughly discussed in sections 8 and 9.</p><p>"Don't ask the world to change. . . you change first." Anthony de Mello</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>In this section, we will describe the math representations ingested by our information retrieval systems, the corpora used for training the models that power our systems, and the relevance judgements we used for parameter optimization, model selection, and performance estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Math Representations</head><p>Our math information retrieval systems ingest math formulae in a variety of formats: L A T E X, Presentation MathML, Content MathML, Symbol Layout Tree (SLT), Operator Tree (OPT), prefix, and infix. Figure <ref type="figure" coords="3,358.66,119.02,4.98,9.58" target="#fig_0">1</ref> shows how the individual math representations are derived from L A T E X. L A T E X As the most direct math representation, we used L A T E X, which is the standard authoring format for math. Although L A T E X is easy to type, it encodes mostly just the presentation aspects of a math formula, not its content. L A T E X is also a Turing-complete language and therefore impossible to statically parse in the general case. As a result, each formula is represented as a single token in the L A T E X representation. L A T E X is useful as a baseline math representation and as a basis for deriving more fine-grained math representations described in the following sections. Although having each formula represented as a single token may not seem useful, two of our four systems (the SCM and COMPUBERT) model subwords, which allows them to extract symbols out of the formulae.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>LaTeX</head><p>To give an example, the formula x!!y<ref type="foot" coords="3,330.30,522.02,3.79,7.28" target="#foot_2">2</ref> = 0 would be represented as a single token $x!! -y^2 = 0$ in L A T E X.</p><p>MathML Using L A T E XML v0.8.4 2 <ref type="bibr" coords="3,282.28,565.37,16.60,9.58" target="#b42">[43]</ref> and MathML Canonicalizer, <ref type="foot" coords="3,424.98,563.38,3.79,7.28" target="#foot_3">3</ref>  <ref type="bibr" coords="3,431.81,565.37,11.62,9.58" target="#b7">[8]</ref> we converted math formulae from L A T E X to MathML 3.0, <ref type="bibr" coords="3,351.88,577.33,11.62,9.58" target="#b0">[1]</ref> which contains two markups: Presentation MathML (PMML) and Content MathML (CMML).</p><p>Like L A T E X, PMML encodes mostly just the presentation aspects of a math formula. Unlike L A T E X, PMML is tokenized to individual math symbols. Unlike L A T E X and like PMML, CMML is tokenized. Unlike PMML, CMML is independent &lt;mrow&gt; &lt;mi&gt;x&lt;/mi&gt; &lt;mo&gt;!!&lt;/mo&gt; &lt;msup&gt; &lt;mi&gt;y&lt;/mi&gt; &lt;mn&gt;2&lt;/mn&gt; &lt;/msup&gt; &lt;mo&gt;=&lt;/mo&gt; &lt;mn&gt;0&lt;/mn&gt; &lt;/mrow&gt; &lt;apply&gt; &lt;eq/&gt; &lt;apply&gt; &lt;minus/&gt; &lt;apply&gt; &lt;csymbol cd="latexml"&gt;double-factorial&lt;/csymbol&gt; &lt;ci&gt;x&lt;/ci&gt; &lt;/apply&gt; &lt;apply&gt; &lt;csymbol cd="ambiguous"&gt;superscript&lt;/csymbol&gt; &lt;ci&gt;y&lt;/ci&gt; &lt;cn type="integer"&gt;2&lt;/cn&gt; &lt;/apply&gt; &lt;/apply&gt; &lt;cn type="integer"&gt;0&lt;/cn&gt; &lt;/apply&gt; Fig. <ref type="figure" coords="4,151.46,312.02,3.36,8.41">2</ref>. The PMML (left) and CMML (right) representations of the math formula x!!y 2 = 0. Notice how the double factorial operator is recognized and how the numerical constants (&lt;cn&gt;) are differentiated from variable names (&lt;ci&gt;) in CMML. <ref type="figure" coords="4,151.46,449.21,3.36,8.41">3</ref>. The SLT representation of the math formula x!!y 2 = 0, where V! prefixes variable names, N! prefixes numerical constants, n stands for next, and a stands for above.</p><formula xml:id="formula_0" coords="4,134.77,380.61,332.15,77.01">V!x !! n - n V!y n N!2 a = n N!0 n Fig.</formula><formula xml:id="formula_1" coords="4,166.62,502.77,280.62,83.39">U!eq O!minus 0 N!0 1 O!double-factorial 0 O!SUP 1 V!x 0 V!y 0 N!2 1</formula><p>Fig. <ref type="figure" coords="4,151.46,610.11,3.36,8.41">4</ref>. The OPT representation of the math formula x!!y 2 = 0, where U! prefixes commutative operators, O! prefixes non-commutative operators, V! prefixes variable names, N! prefixes numerical constants, 0 stands for the first operand, and 1 stands for the second operand.</p><p>of the presentation aspects of a formula and encodes visually distinct but semantically equivalent formulae the same.</p><p>To give an example, the formula x!!y 2 = 0 would be represented as the PMML and CMML documents in Figure <ref type="figure" coords="5,306.88,154.89,3.74,9.58">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>M-Terms</head><p>Using MIaSMath, <ref type="foot" coords="5,261.32,181.78,3.79,7.28" target="#foot_4">4</ref> we converted math formulae from MathML to mathematical tokens (M-Terms) by ordering, tokenization, and unification. <ref type="bibr" coords="5,463.99,195.73,16.60,9.58" target="#b41">[42]</ref> Although M-Terms can be extracted from both PMML and CMML, the CMML representation has produced the best results in previous MIR competitions. <ref type="bibr" coords="5,463.99,219.64,16.60,9.58" target="#b29">[30]</ref> To give an example, the formula x!!y 2 = 0 would be represented as the following comma-separated bag of tokens in MathML:</p><formula xml:id="formula_2" coords="5,134.89,241.56,345.70,37.98">x!! -y 2 = 0, x!! -y 2 , 0, =, x!!, y 2 , -, x, !!, y, 2, id 1 !! -id 2 2 = 0, id 1 !! -id 2 2 , id 1 !!, id 2 2 , id 1 , id 2 , x!! - y const = const, x!! -y const , y const , id 1 !! -id 2 const = const, id 1 !! -id 2 const , id 2 const .</formula><p>Symbol Layout Tree and Operator Tree Using our fork of Tangent-CFT<ref type="foot" coords="5,456.76,295.66,3.79,7.28" target="#foot_5">5</ref>  <ref type="bibr" coords="5,463.99,297.65,16.60,9.58" target="#b18">[19]</ref> that recognizes all math operators in our corpora (see Section 2.2), we converted math formulae from PMML and CMML to the Symbol Layout Tree (SLT) and Operator Tree (OPT) math representations, respectively. SLT corresponds to PMML with positional relations between math symbols. In our systems, we tokenize SLT into paths in depth-first-search order. A path in the SLT is represented as a 4-tuple (initial node of the path, terminal node of the path, spatial relations between symbols on the path, spatial relations between symbols on the path from the SLT root to the initial node).</p><p>OPT corresponds to CMML with additional information about the types of math symbols. In our systems, we tokenize OPT into paths in depth-first-search order. A path in the OPT is represented as a 4-tuple (initial node of the path, terminal node of the path, edge numbers on the path, edge numbers on the path from the SLT root to the initial node).</p><p>To give an example, the formula x!!y 2 = 0 would be represented as the SLT tree in Figure <ref type="figure" coords="5,213.32,476.98,4.98,9.58">3</ref> and the OPT tree in Figure <ref type="figure" coords="5,337.62,476.98,3.74,9.58">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prefix and Infix</head><p>To linearize the OPT, we converted math formulae from OPT into the prefix and infix notations. The prefix notation corresponds to the list of visited nodes in the OPT in depth-first-search order, i.e. the topological sorting of the OPT. By parenthesizing operands and by recognizing infix operators, we also produce the infix notation.</p><p>Like L A T E X, the prefix and infix notations are easy to type. Unlike L A T E X, the prefix and infix notations are tokenized into math symbols and independent on the presentation aspects of a formula. In TF-IDF-based systems, the prefix and infix notations are virtually equivalent.</p><p>To give an example, the formula x!!y 2 = 0 would be represented as the following space-separated list of tokens in the prefix notation: U!eq O!minus O!double-factorial V!x O!SUP V!y N!2 N!0 and as the following space-separated list of tokens in the infix notation: ( ( O!double-factorial ( V!x ) O!minus O!SUP ( V!y , N!2 ) ) U!eq N!0 ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Corpora</head><p>For training our models, we used the arXMLiv and Math StackExchange corpus. Our data preprocessing code is available online. <ref type="foot" coords="6,367.05,209.81,3.79,7.28" target="#foot_6">6</ref>ArXMLiv The arXMLiv 08.2019 corpus <ref type="bibr" coords="6,312.50,245.23,11.62,9.58" target="#b8">[9]</ref> contains 1,374,539 articles from the arXiv.org open-access archive converted from L A T E X to HTML5 and MathML. The corpus is split into four subsets: no_problem (150,701 articles), warning_1 (500,000 articles), warning_2 (328,127 articles), and error (395,711 articles), according to the severity of errors encountered when converting L A T E X to HTML5. For training our models, we only used the no_problem, warning_1, and warn-ing_2 subsets of the corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Math StackExchange</head><p>The Math StackExchange corpus V1.2 provided by the organizers of the ARQMath 2020 competition contains 2,466,080 posts (questions and answers) from the Math StackExchange question answering website in HTML5 and L A T E X. In our conversion from L A T E X to MathML, we successfully converted 28,320,920 math formulae from L A T E X to 26,705,527 math formulae in CMML (94.3% success rate) and to 27,232,230 math formulae in PMML (96.16% success rate).</p><p>Posts in the Math StackExchange corpus are layered and contain not only the body text, but also the title, tags, comments, up-and downvotes, view count, authorship information, etc. Each of our systems used different parts of the corpus, which will be specified in detail in the corresponding sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Competition Tasks</head><p>In the ARQMath 2020 competition, we competed in tasks 1 and 2.</p><p>Task 1: Find Answers Given a posted question as a query, task 1 is to search all answer posts in the Math StackExchange corpus and return relevant answers. There exist 1.4 million answers in Math StackExchange.</p><p>For task 1, we submitted three primary submissions, which correspond to the three primary systems that we developed (MIaS, SCM, and COMPUBERT), and two alternative submissions, which correspond to the Formula2Vec secondary system and an ensemble of the three primary submissions.</p><p>Task 2: Formula Search Given a formula from a question as a query, search all question and answer posts in the Math StackExchange corpus for relevant formulae. There exist 28.3 million math formulae in Math StackExchange.</p><p>For task 2, we submitted two primary submissions, which corresponded to the two systems designed with task 2 in mind (SCM and Formula2Vec), and three alternative submissions, which correspond to different configurations of SCM and Formula2Vec, and an ensemble of the two primary submissions.</p><p>Both SCM and Formula2Vec were straightforwardly adapted from task 1 to task 2 by changing the indexing unit from an answer to a formula. Neither search engine takes the textual context of the indexed formulae into account.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Relevance Judgements</head><p>In our experiments, we used two sets of relevance judgements, automatic for parameter estimation and model selection, and human-annotated for performance estimation.</p><p>Automatic Since there were no relevance judgements for task 1 available during the development of our systems, we produced our own from the Math StackExchange corpus. <ref type="foot" coords="7,236.82,353.04,3.79,7.28" target="#foot_7">7</ref> The judgements served as a proxy for task 1 during parameter estimation and model selection in our systems.</p><p>Each question in the Math StackExchange corpus is a topic, and its judged documents are all its answers with max(0, the number of upvotes minus the number of downvotes) as the gain. Answers to different questions are not judged.</p><p>Out of all 797,652 questions in the Math StackExchange corpus with answers, we used 628,442 (78.79%) for training, 85,840 (10.76%) for parameter optimization, and 83,370 (10.45%) for model selection, i.e. for deciding which systems will get submitted to the competition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Human-Annotated</head><p>After the submission of our systems, official human-annotated task 1 and 2 relevance judgements produced by eight annotators with fair agreement (κ = 0.34) <ref type="bibr" coords="7,228.18,504.84,16.60,9.58" target="#b12">[13]</ref> were released. <ref type="foot" coords="7,308.98,502.84,3.79,7.28" target="#foot_8">8</ref>  <ref type="bibr" coords="7,315.18,504.84,15.77,9.58" target="#b47">[47,</ref><ref type="bibr" coords="7,332.88,504.84,49.50,9.58">Section 4.4]</ref> We used the relevance judgements for performance estimation of system configurations that we did not submit to the competition.</p><p>Task 1 For each of 77 questions excluded from the Math StackExchange corpus, the judged documents are on average 460 answers from Math StackExchange that were evaluated by human annotators with a range from 0 (not relevant) to 3 (highly relevant) as the gain.</p><p>The relevance judgements are highly imbalanced in favor of non-relevant answers: Out of all 39,124 judgements, there exist as many as 35,051 judgements (89.59%) with gain 0, 2,269 judgements (5.8%) with gain 1, 1,071 judgements (2.74%) with gain 2, and only 733 (1.85%) judgements with gain 3. The small number of relevant answers impedes the usefulness of the human-annotated relevance judgements for training supervised models for use in future systems.</p><p>Out of all 39,124 judgements, we used 31,541 (80.62%) for training out-ofcompetition system configurations, 3,560 (9.10%) for parameter optimization, and 4,023 (10.28%) for performance estimation. <ref type="foot" coords="8,341.57,176.81,3.79,7.28" target="#foot_9">9</ref>Task 2 For each of 45 math formulae from questions excluded from the Math StackExchange corpus, the judged documents are on average 256 formulae from questions and answers in Math StackExchange that were evaluated by human annotators with a range from 0 (not relevant) to 3 (highly relevant) as the gain.</p><p>The relevance judgements are slightly imbalanced in favor of non-relevant formulae: Out of all 12,116 judgements, there exist 7,891 judgements (65.13%) with gain 0, 718 judgements with gain 1 (5.93%), 553 judgements (4.56%) with gain 2, and 2,954 judgements (24.38%) with gain 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Evaluation Measures</head><p>To measure information retrieval accuracy for parameter optimization, model selection, and performance estimation, we used the Normalized discounted cumulative gain prime (nDCG') and Spearman's ρ.</p><p>Normalized Discounted Cumulative Gain Prime The nDCG' <ref type="bibr" coords="8,410.60,388.80,16.60,9.58" target="#b31">[32]</ref> is an evaluation measure specifically designed for information retrieval with incomplete relevance judgements. nDCG' is defined as follows:</p><formula xml:id="formula_3" coords="8,140.39,434.41,340.20,30.01">nDCG' = avg t∈T DCG' t IDCG t , IDCG = |REL t | ∑ i=1 gain t (REL t,i ) log 2 (i + 1) , DCG' = |RES' t | ∑ i=1 gain t (RES' t,i ) log 2 (i + 1) ,<label>(1)</label></formula><p>where T are the topics for a task, REL t is a list of relevant documents for topic t in the descending order of their gain up to position 1,000, RES t is a list of results produced for topic t our system up to position 1,000, RES' t = REL t ∩ RES t , and gain t (R) is the gain of result R for topic t as specified by relevance judgements.</p><p>To see if two nDCG' values are significantly different, we construct two 95% Student's t <ref type="bibr" coords="8,184.19,534.30,16.60,9.58" target="#b43">[44]</ref> confidence intervals from the values of ( DCG t/IDCGt ) t∈T . If the intervals do not overlap, we say that the higher nDCG' value is significantly better.</p><p>Spearman's ρ Spearman's ρ is a general non-parametric measure of rank correlation. Spearman's ρ between random variables X and Y corresponds to Pearson's r between the rank values rg X and rg Y of the random variables:</p><formula xml:id="formula_4" coords="8,140.11,621.03,336.60,26.52">ρ = cov(rg X , rg Y ) σ rg X • σ rg Y and cov(rg X , rg Y ) = E (rg X -E[rg X ])•(rg Y -E[rg Y ]) . (<label>2</label></formula><formula xml:id="formula_5" coords="8,476.72,628.45,3.87,9.58">)</formula><p>Unlike nDCG', Spearman's ρ can not handle incomplete relevance judgements. Therefore, we only used Spearman's ρ to evaluate our systems with automatic relevance judgements, which are always complete for all answers of a question. Throughout the paper, we refer to both nDCG' and Spearman's ρ as measurements of our systems' accuracy. This should not be confused with the binary classification accuracy measure, which is computed as the proportion of correct predictions to all predictions and which we do not use.</p><p>"When you get rid of your fear of failure, your tensions about succeeding. . . you can be yourself. Relaxed. You'll no longer be driving with your brakes on." Anthony de Mello</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Math Indexer and Searcher</head><p>In 2011, we have developed and open-sourced the Math Indexer and Searcher (MIaS) system <ref type="bibr" coords="9,201.79,295.77,16.60,9.58" target="#b39">[40]</ref> based on Apache Lucene: <ref type="bibr" coords="9,339.75,295.77,11.62,9.58" target="#b1">[2]</ref> a high-performance full-text search engine library. We have deployed MIaS in the European Digital Mathematical Library 10 , making it historically the first MIR system deployed in a digital mathematical library. <ref type="bibr" coords="9,261.20,331.63,16.60,9.58" target="#b46">[46]</ref> The architecture of MIaS is shown in Figure <ref type="figure" coords="9,473.11,331.63,3.74,9.58" target="#fig_2">5</ref>.</p><p>In this section, we will describe MIaS and its results on task 1 of the ARQMath 2020 competition. Our experimental code is available online.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Configuration</head><p>We represented answers from the Math StackExchange corpus as the text and math in their body text and comments, as produced by the HtmlGenerator. generate_answer method of the code provided by the ARQMath 2020 organizers. <ref type="foot" coords="10,150.19,172.37,7.57,7.28" target="#foot_10">12</ref> We represented math in answers using M-Terms extracted from CMML with structural unification disabled, since experimental results have shown that the it is not suitable for general use. <ref type="bibr" coords="10,293.69,198.27,15.77,9.58" target="#b27">[28,</ref><ref type="bibr" coords="10,311.12,198.27,13.28,9.58" target="#b30">31]</ref> Since the TF-IDF scoring function of MIaS [40, Section 3.1] is best suited for short and precise queries due to a lack of logarithmic TF factoring, [38, <ref type="bibr" coords="10,438.55,222.18,42.04,9.58">Section 2]</ref> we represented topics as the text and math in their title, ignoring the body text and tags. Like in the indexing of answers, we represented math in topics using M-Terms extracted from CMML. To improve the recall of MIaS, we use the Leave Rightmost Out (LRO) querying strategy <ref type="bibr" coords="10,317.53,270.00,15.77,9.58" target="#b29">[30,</ref><ref type="bibr" coords="10,334.95,270.00,12.45,9.58" target="#b15">16,</ref><ref type="bibr" coords="10,349.07,270.00,13.28,9.58" target="#b27">28]</ref> that expands the original query and produces a set of subqueries by leaving out text keywords and math subformulae. After expansion, we submit the subqueries to MIaS and interleave the partial results into a final result list.</p><p>We submitted the described configuration of MIaS as a primary submission.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>In this section, we will discuss the accuracy of the MIaS using nDCG' on the official human-annotated relevance judgements for task 1, and the speed of MIaS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Accuracy</head><p>In the described configuration, the MIaS system achieved the nDCG' 0.155 on task 1, which is far from the best competing system, but close to the Tangent-S system that served as a baseline. [47, Table <ref type="table" coords="10,370.21,432.02,10.70,9.58" target="#tab_0">A1</ref>] Speed For task 1, the average run time of MIaS over all topics was 1.24 seconds, with the minimum of 0.1 seconds for topic A.55, and the maximum of 7.27 seconds for topic A.80. MIaS ran on a machine with 2 TiB free disk space, eight Intel Xeon™ X7560 2.26 GHz processors with a total of 32 CPU cores, 252 GiB RAM and no GPUs.</p><p>"You have to understand, my dears, that the shortest distance between truth and a human being is a story." Anthony de Mello</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Soft Cosine Measure</head><p>Since the seminal work of Mikolov et al., <ref type="bibr" coords="10,317.57,600.65,16.60,9.58" target="#b20">[21]</ref> unsupervised word embeddings have become the preferred word representations for many natural language processing tasks. Document similarity measures extracted from TF-IDF and unsupervised word embeddings, such as the Soft Cosine Measure (SCM), <ref type="bibr" coords="10,447.78,636.51,16.60,9.58" target="#b35">[36]</ref> are fast <ref type="bibr" coords="11,153.49,119.02,16.60,9.58" target="#b21">[22]</ref> and achieve strong performance on semantic text similarity, <ref type="bibr" coords="11,441.49,119.02,11.62,9.58" target="#b5">[6]</ref> information retrieval, <ref type="bibr" coords="11,210.85,130.98,16.60,9.58" target="#b9">[10]</ref> entrance exam question answering, <ref type="bibr" coords="11,389.42,130.98,16.60,9.58" target="#b35">[36]</ref> and text classification <ref type="bibr" coords="11,164.05,142.93,16.60,9.58" target="#b22">[23]</ref> tasks, among others.</p><p>In this section, we will describe the Soft Cosine Measure (SCM) system, which combines TF-IDF with unsupervised word embeddings to produce interpretable representations of math documents and math formulae that enable fast and interpretable information retrieval. We will also report the results of the SCM on tasks 1 and 2 of the ARQMath 2020 competition. Our experimental code is available online. <ref type="foot" coords="11,239.73,212.67,7.57,7.28" target="#foot_11">13</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Orthogonalized Joint Word Embeddings</head><p>In mathematical discourse, math formulae are often more important than words for understanding. <ref type="bibr" coords="11,222.27,276.40,16.60,9.58" target="#b13">[14]</ref> Using a single representation for both text and math makes it possible to exploit zettabytes of text for training high-quality unsupervised word embeddings that can capture the relations between text with math.</p><p>Drawing inspiration from the existing work about unsupervised word embeddings for math, <ref type="bibr" coords="11,223.19,324.22,15.77,9.58" target="#b11">[12,</ref><ref type="bibr" coords="11,240.62,324.22,13.28,9.58" target="#b18">19]</ref> we produce unsupervised joint word embeddings for text and math tokens by training a fastText skipgram model <ref type="bibr" coords="11,416.59,336.18,11.62,9.58" target="#b2">[3]</ref> on text and math in a corpus. For the Math StackExchange corpus, we use the body text of posts. For the arXMLiv corpus, we use the full texts. We experiment with different representations of math: L A T E X, SLT, OPT, prefix, and infix.</p><p>Unlike the embeddings produced by Krstowski and Blei <ref type="bibr" coords="11,414.85,384.00,16.60,9.58" target="#b11">[12]</ref> and Mansouri et al., <ref type="bibr" coords="11,190.11,395.95,16.60,9.58" target="#b18">[19]</ref> our fastText embeddings are share weights between tokens that have subwords in common. This speeds up training convergence <ref type="bibr" coords="11,449.01,407.91,11.62,9.58" target="#b2">[3]</ref> and enables inference of embeddings for text and math tokens not seen during training. To differentiate the token type (text or math) of subwords, we use a crude heuristic that lower-cases text tokens and upper-cases math tokens.</p><p>Following the work of Novotný et al., <ref type="bibr" coords="11,317.23,455.73,15.77,9.58" target="#b22">[23,</ref><ref type="bibr" coords="11,335.39,455.73,38.14,9.58">Section 4</ref>.2] we orthogonalize the word embeddings in order to improve retrieval accuracy and speed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Document Similarity Measure</head><p>The TF-IDF vector space model (VSM) <ref type="bibr" coords="11,304.68,517.46,16.60,9.58" target="#b32">[33]</ref> is a distributional semantics model that is fundamental to information retrieval. The VSM represents documents as coordinate vectors relative to an orthogonal basis, where the similarity between documents or formulae in tasks 1 or 2, respectively, is the cosine similarity between their coordinate vectors.</p><p>Although the VSM is fast and interpretable, it is highly susceptible to polysemy, since distinct text and math terms correspond to mutually orthogonal basis vectors. Therefore, documents that use different terminology will always be regarded as dissimilar.</p><p>To better model the polysemy, we use the TF-IDF soft vector space model (soft VSM). <ref type="bibr" coords="11,185.75,637.02,15.77,9.58" target="#b35">[36,</ref><ref type="bibr" coords="11,203.19,637.02,13.28,9.58" target="#b21">22]</ref> Unlike the VSM, the soft VSM assumes that documents are Fig. <ref type="figure" coords="12,151.46,229.58,3.36,8.41">6</ref>. The representation of two documents, "Hi, world" and "Hello, world" in the TF-IDF vector space model (VSM, left) and in the TF-IDF soft vector space model (soft VSM, right). In the VSM, different terms correspond to orthogonal axes, making the document representations distant despite their semantic equivalence. In the soft VSM, different terms correspond to non-orthogonal axes, where the angle between the axes is proportional to the similarity of terms in a word embedding space (middle).</p><p>represented in a non-orthogonal basis, i.e. similar text and math terms correspond to basis vectors that make acute angles, see Figure <ref type="figure" coords="12,387.19,330.77,3.74,9.58">6</ref>.</p><p>Following the work of Novotný et al., <ref type="bibr" coords="12,320.26,342.73,15.77,9.58" target="#b22">[23,</ref><ref type="bibr" coords="12,338.85,342.73,50.40,9.58">Section 3.2]</ref> we use the orthogonalized joint word embeddings as the source of similarity between terms. We use the implementation of fastText and the soft VSM in Gensim. <ref type="foot" coords="12,412.86,364.65,7.57,7.28" target="#foot_12">14</ref>  <ref type="bibr" coords="12,423.42,366.64,16.60,9.58" target="#b24">[25]</ref> For task 1, we represent answers from the Math StackExchange corpus as the text and math in their body text. For math, we experiment with different representations: L A T E X, SLT, OPT, prefix, and infix. For task 2, we represent formulae from questions and answers in the Math StackExchange corpus as the math in the optimal representation selected for task 1. For both tasks 1 and 2, we represent topics as the text and math in their title, body text, and tags.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Parameter Optimization</head><p>To select the optimal parameters for the SCM on task 1, we used the nDCG' on our relevance judgements (see sections 2.4 and 2.5) as the objective. Since we lacked relevance judgements for task 2, we used the optimal model for task 1 in both tasks.</p><p>Initialization To produce the word embeddings, we reproduced the experimental setup of Bojanowski et al.: [3, Section 4] hash table bucket size 2 • 10 6 , 300 vector dimensions, negative sampling loss with five negative samples, initial learning rate 0.05 with a linear decay to zero, sampling threshold 10 -4 , a window size of five, a minimum of five occurences of a term, and character n-grams with n in {3, . . . , 6}. We did not model phrases 15 [20, Section 4] and trained on the text and the no_problem subset of arXMLiv in the prefix notation for five epochs.</p><p>To produce the orthogonalized word embeddings and the term similarity matrix, we used the optimal parameters suggested by Novotný et al.: [23, Table 2] symmetric (Sym = ) and strictly diagonally dominant (Dom = ) term similarity matrix with a maximum of C = 100 non-zero elements in a row/column, and term similarity with threshold t = -1 and exponent o = 4.</p><p>For the TF-IDF soft VSM, we used the dtn.dtn SMART weighting scheme.</p><p>Tree Search To optimize the parameters, we performed tree search: assuming the parameters were mutually independent, we varied only one of the parameters at each step of the search, and we selected the best value of the parameter using the nDCG' on our relevance judgements. In each step, we used the optimal values for parameters from previous steps and the default values (see Section 4.3) for parameters from future steps. For each step, we report the best parameter value together with the corresponding nDCG' score italic. None of the differences in nDCG' were statistically significant.</p><p>In the first step, we selected the optimal representation of math from removing math tokens (0.7600), L A T E X (0.7602), OPT (0.7606), SLT (0.7607), and prefix/infix (0.7612). We were delighted to learn that whereas removing math tokens and just using L A T E X representation produced the worst results, the novel prefix and infix notations led to improvements in the accuracy.</p><p>In the second step, we selected the optimal maximum length of phrases from one (0.7612), two (0.7613), three (0.7614), four (0.7612), five (0.7610), and concatenating all consequent math tokens into a single math token (0.7603). The optimal value of three reproduces the result of Mikolov et al. <ref type="bibr" coords="13,420.24,424.96,15.77,9.58" target="#b19">[20,</ref><ref type="bibr" coords="13,438.25,424.96,42.34,9.58">Section 4]</ref> who suggest using 2-4 iterations of bigram merging when modeling phrases. Notice also the similar accuracy received when concatenating all math tokens in prefix/infix notation (0.7603) and when using L A T E X (0.7602).</p><p>In the third step, we optimized the hash bucket size from 1 • 10 6 (0.7612), 2 • 10 6 (0.7614), 4 • 10 6 (0.7612), 8 • 10 6 (0.7611). Despite our worries, the default bucket size of 2 • 10 6 appears to be sufficient to store character n-grams for both text and math tokens.</p><p>In the fourth step, we performed an exhaustive grid search of the Sym ∈ {, }, Dom ∈ {, }, and C ∈ {0, 50, 100, 200, 400, 800, 1600} parameters, see Table <ref type="table" coords="13,160.85,544.76,3.74,9.58" target="#tab_0">1</ref>. To break the tie, we selected the default parameters: Sym = , Dom = , and C = 100 (0.7614).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Evaluation</head><p>We trained the tiny, small, medium, and large models, and used them to produce the competition submissions.</p><p>Tiny model For the task 2 alternative submission, we used the model produced via parameter selection. Small model For the task 1 and 2 primary submissions, we trained fastText for ten epochs on both the Math StackExchange corpus and the no_problem subset of arXMLiv, and we used character n-grams with n in {4, 5} shown to be optimal for English by Bojanowski et al. <ref type="bibr" coords="14,316.29,332.93,10.79,9.58" target="#b2">[3,</ref><ref type="bibr" coords="14,330.06,332.93,34.63,9.58">Table 4]</ref> We also used the dtb.nnn SMART weighting scheme with slope s = 0.2 for the TF-IDF soft VSM instead of dtn.dtn, as suggested by Singhal, [39, Table <ref type="table" coords="14,343.18,356.84,4.15,9.58" target="#tab_0">1</ref>] and we replaced cosine normalization in the soft VSM document similarity function with a normalization function that maintains the 2 norm of a document vector during a change of basis, 16 which we theorize is a better fit for the pivoted normalization <ref type="bibr" coords="14,452.03,392.71,16.60,9.58" target="#b36">[37]</ref> in the dtb.nnn SMART weighting scheme.</p><p>Medium and large models After the submission deadline, we trained fastText for two epochs on both the Math StackExchange corpus and the no_problem and warning_1 subsets of arXMLiv (medium), and for ten epochs on both the Math StackExchange corpus and the no_problem, warning_1, and warning_2 subsets of arXMLiv (large). The medium and large models were not submitted to the competition and only serve for comparison.</p><p>For task 1, the results are the closest 1,000 answers in the soft VSM. For task 2, the results are the closest 1,000 formulae in the soft VSM that did not originate from a comment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Results</head><p>In this section, we will discuss the accuracy of the SCM using nDCG' on the official human-annotated relevance judgements for tasks 1 and 2, and the speed of the SCM.</p><p>Accuracy For task 1, only the small model was submitted out of the tiny (0.178), small (0.224), medium (0.237), and large (0.231). We conjecture that the poorer performance of the large model was due to training on the warning_2 subset of arXMLiv, which contains highly malformed L A T E X documents.</p><p>For task 2, both the tiny and small models were submitted out of the tiny (0.119), small (0.059), medium (0.078), and large (0.075). We conjecture that the poorer performance of all models larger than tiny was either due to the change from cosine normalization to pivoted normalization, or due to the reduced range of modeled character n-gram sizes.</p><p>Speed For task 1, the average run time of the small, medium, and large models over all topics was 58.46 seconds with the minimum of 30.52 seconds for topic A.88 and the maximum of 502.84 seconds for topic A.35. For task 2, the average run time of the small, medium, and large models over all topics was 108.86 seconds with the minimum of 54.81 seconds for topic B.88 and the maximum of 2720.14 seconds for topic B. <ref type="bibr" coords="15,257.22,304.00,8.41,9.58" target="#b24">25</ref>. For the tiny model, the speed may be different due to the different normalization in the soft VSM document similarity function.</p><p>The SCM ran on a machine with 2 TiB of free disk space, eight Intel Xeon™ X7560 2.26 GHz processors with a total of 32 CPU cores, 252 GiB RAM and no GPUs. For the SCM, all documents were stored in the RAM, and queries were processed using matrix multiplication on one CPU core without any index. In a production system, the SCM can be reduced to the run time of a TF-IDF-based system, <ref type="bibr" coords="15,170.55,387.69,15.77,9.58" target="#b26">[27,</ref><ref type="bibr" coords="15,187.99,387.69,12.45,9.58" target="#b28">29,</ref><ref type="bibr" coords="15,202.09,387.69,13.28,9.58" target="#b21">22]</ref> see the performance of MIaS in Section 3.2.</p><p>"Thought can organize the world so well that you are no longer able to see it." Anthony de Mello</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Formula2Vec</head><p>Many machine learning algorithms require the input to be represented as a fixed-length feature vector. Architecturally similar to the fastText model used in Section 4 by the SCM, the Doc2Vec DBOW model <ref type="bibr" coords="15,365.49,491.65,16.60,9.58" target="#b14">[15]</ref> is a staple in the area of text classification. The shallow multilayer perceptron can be trained on large volumes of text and infers embeddings for unseen retrieval units.</p><p>In this section, we will describe the Formula2Vec system that uses Doc2Vec to infer document and formula embeddings for tasks 1 and 2, respectively. We will also report the results of Formula2Vec on tasks 1 and 2 of the ARQMath 2020 competition. Our experimental code is available online. 17</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Document Similarity Measure</head><p>In Formula2Vec, documents and formulae are represented by document and formula embeddings produced by traning the Doc2Vec DBOW model <ref type="bibr" coords="15,449.22,624.49,16.60,9.58" target="#b14">[15]</ref> on text and math in a corpus. For the Math StackExchange corpus, we use the body text of posts. For the arXMLiv corpus, we use the full texts. To differentiate the token type (text and math) of n-grams extracted by fastText, we lower-case all text tokens and upper-case all math tokens.</p><p>For task 1, we represent answers from the Math StackExchange corpus as the text and math in their body text. For task 2, we represent formulae from questions and answers in the Math StackExchange corpus as the math. For both tasks 1 and 2, we represent topics as the text and math in their title, body text, and tags.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Parameter Optimization</head><p>Due to the architectural similarities between the SCM and Doc2Vec, we reused the results of the parameter optimization of the SCM, see Section 4.3: 300 vector dimensions and a minimum of five occurences of a term. We modeled phrases with a maximum length of two, and trained on the no_problem subset of arXM-Liv in the prefix notation for five epochs.</p><p>The remaining parameters were taken from the searchisko information retrieval system:<ref type="foot" coords="16,200.29,320.01,7.57,7.28" target="#foot_13">18</ref> 300 vector dimensions, negative sampling loss with twelve negative samples, initial learning rate 0.1 with a linear decay to zero, and a window size of eight.</p><p>We use the implementation of Doc2Vec in Gensim. 19 [25]</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Evaluation</head><p>We trained the tiny, small, medium, and large models, and used them to produce the competition submissions.</p><p>Tiny model For the task 2 alternative submission, we used the model produced via parameter selection.</p><p>Small model For the task 1 alternative submission and the task 2 primary submission, we trained Doc2Vec for ten epochs on both the Math StackExchange corpus and the no_problem subset of arXMLiv.</p><p>Medium and large models After the submission deadline, we trained Doc2Vec for two epochs on both the Math StackExchange corpus and the no_problem and warning_1 subsets of arXMLiv (medium), and for ten epochs on both the Math StackExchange corpus and the no_problem, warning_1, and warning_2 subsets of arXMLiv (large). The medium and large models were not submitted to the competition and only serve for comparison.</p><p>For task 1, the results are the closest 1,000 answers in the soft VSM. For task 2, the results are the closest 1,000 formulae in the soft VSM that did not originate from a comment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Results</head><p>In this section, we will discuss the accuracy of Formula2Vec using nDCG' on the official human-annotated relevance judgements for tasks 1 and 2, and the speed of Formula2Vec.</p><p>Accuracy For task 1, only the small model was submitted out of the tiny (0.101), small (0.050), medium (0.054), and large (0.074). We conjecture that the poorer performance of all models larger than tiny was due to training on the arXMLiv corpus, which contains scientific articles that are significantly longer and lexically different compared to the short-form questions and answers in the Math StackExchange corpus.</p><p>For task 2, both the tiny and small models were submitted out of the tiny (0.077), small (0.108), medium (0.063), and large (0.078). We conjecture that the poorer performance of the tiny and medium models is due to the small number of epochs (five and two, respectively) used for their training. In the Gensim implementation of Doc2Vec, the same number of epochs is also used to infer embeddings of unseen retrieval units. By contrast, both the small and large models used ten epochs for both training and inference. We conjecture that the poorer performance of the large model was due to training on the warning_2 subset of arXMLiv, which contains highly malformed L A T E X documents. Speed For task 1, the average run time of the large model over all topics was 3.23 seconds with the minimum of 3.14 seconds for topic A.11 and the maximum of 7.87 seconds for topic A.1. For task 2, the average run time of the large model over all topics was 164.5 seconds with the minimum of 61.61 seconds for topic B.26 and the maximum of 5448.65 seconds for topic B.20. For the other models, the speed may be different due to the different number of epochs used for inference.</p><p>Like the SCM, Formula2Vec ran on a machine with 2 TiB free disk space, eight Intel Xeon™ X7560 2.26 GHz processors with a total of 32 CPU cores, 252 GiB RAM and no GPUs. Like for the SCM, all documents were stored in the RAM, and queries were processed using matrix multiplication on one CPU core without any index. In a production system, Formula2Vec can be reduced to the run time of a TF-IDF-based system, <ref type="bibr" coords="17,296.69,530.91,16.60,9.58" target="#b26">[27]</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">COMPUBERT</head><p>Our COMPUBERT system aims to utilize the expressive power of pre-trained Transformer models <ref type="bibr" coords="17,227.07,656.15,16.60,9.58" target="#b44">[45]</ref> and the results of applying the Transformer architec- A irrelevant : Ask elsewhere ... Gurevych: <ref type="bibr" coords="18,179.02,294.70,14.94,8.63" target="#b25">[26]</ref> Informally, the system combines the Wordpiece embeddings <ref type="bibr" coords="18,441.99,294.70,10.45,8.63" target="#b6">[7]</ref> to create static representations of questions, that are similar to the representations of relevant answers, while dissimilar to the representations of irrelevant answers.</p><p>ture to complex math-related tasks, such as computing derivatives and firstorder differential equations by representing math formulae in the prefix notation. <ref type="bibr" coords="18,157.13,375.84,16.60,9.58" target="#b16">[17]</ref> In this section, we will describe COMPUBERT and its results on task 1 of the ARQMath 2020 competition. Our experimental code is available online. <ref type="foot" coords="18,446.04,398.17,7.57,7.28" target="#foot_14">20</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Matching Questions with Answers</head><p>In addition to math representation, we have to contend with additional challenges characteristic to information retrieval but alien to Transformers: While the original Transformer architecture <ref type="bibr" coords="18,300.79,477.99,16.60,9.58" target="#b44">[45]</ref> builds upon the Wordpiece text segmentation <ref type="bibr" coords="18,182.68,489.95,16.60,9.58" target="#b34">[35]</ref> that optimizes the representation of subwords (not unlike fast-Text in the SCM), we also need to uniformly represent long spans of text.</p><p>We address this challenge with an approach introduced by Reimers and Gurevych <ref type="bibr" coords="18,182.03,526.22,16.60,9.58" target="#b25">[26]</ref> and shown in Figure <ref type="figure" coords="18,300.97,526.22,3.74,9.58" target="#fig_3">7</ref>. The underlying idea of their Sentence Transformers is to adjust the pre-trained language model so that it reflects the pairwise similarity of pieces of text, where this similarity is known.</p><p>This approach has shown to reach state-of-the-art results on several document classification tasks, where it minimizes the pairwise distance of documents of the same class and maximizes the distance between documents in different classes.</p><p>Similarly, in order to get a unified representation of spans of texts representing both questions and answers, the Transformer architecture is extended with an additional pooling layer. The training of the system mimics the Siamese net-work architecture <ref type="bibr" coords="19,216.39,119.02,16.60,9.58" target="#b33">[34]</ref> with a Triplet objective to minimize the cosine distance of the similar blocks of text, as shown in Figure <ref type="figure" coords="19,344.56,130.98,3.74,9.58" target="#fig_3">7</ref>.</p><p>COMPUBERT uses the Triplet objective as a proxy to the objective of task 1: to minimize the cosine distance of questions to their high-ranking answers, while maximizing the distance to their low-ranking answers. Specifically, we use the following objective:</p><formula xml:id="formula_6" coords="19,188.49,203.58,292.10,30.00">minimize |Qs| ∑ i=1 |A i | ∑ j=1 1 -cos(q i , a ij ) -dist exp (q i , a ij ) ,<label>(3)</label></formula><p>where the expected distance dist exp of an answer a ij to the question q i is the number of upvotes given to a ij , standardized with respect to all answers to q i . Using a similar objective, we can fine-tune an arbitrary embedding model to respect either inherent ranking provided by a feedback of the users, or an explicit relevance ranking provided by relevance judgements.</p><p>Adapting the embeddings of the Transformer architecture to Information Retrieval is an active field of research. <ref type="bibr" coords="19,314.91,321.44,15.77,9.58" target="#b23">[24,</ref><ref type="bibr" coords="19,332.33,321.44,12.45,9.58" target="#b17">18,</ref><ref type="bibr" coords="19,346.45,321.44,8.30,9.58" target="#b4">5]</ref> However, COMPUBERT is, to our knowledge, the first application of pairwise, multimodal (joint text and math) embedding optimization applied in Information Retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Model Training</head><p>We represent topics and questions and answers from the Math StackExchange corpus as the text and math in their body text. For math, we experiment with different representations: L A T E X, prefix, and infix.</p><p>In order to train the system to minimize the distance of relevant answers to a question, we used the Math StackExchange corpus (see Section 2.2) and our relevance judgements (see Section 2.4) with the nDCG' and Spearman's ρ as our objectives (see Section 2.5). We represent math in each question and answer using either L A T E X, the prefix notation, or the infix notation (see Section 2.1). Finally, we iterate over the data set 3-4 times until we reach the convergence with respect to our objectives.</p><p>We performed 35 experiments with different configurations of COMPUBERT, and we submitted the configuration of COMPUBERT with the highest nDCG' as a primary submission. See Table <ref type="table" coords="19,279.31,549.47,4.98,9.58">2</ref> for the nDCG' of selected COMPUBERT configurations. See Figure <ref type="figure" coords="19,235.89,561.43,4.98,9.58">8</ref> for the learning curves of the submitted COMPUBERT configuration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Results</head><p>In this section, we will discuss the accuracy of COMPUBERT using nDCG' on the official human-annotated relevance judgements for task 1, and the speed of COMPUBERT. Accuracy We expected the nDCG' and Spearman's ρ to reflect the same objective and we've observed that to be the case for the most cases: Out of 18 configurations with both the nDCG' and Spearman's ρ measured, the ranking based on Spearman's ρ diverged from the nDCG' only for some three systems. However, the automatic and human-annotated relevance judgements for task 1 have proven to be divergent. The best configuration, reaching 0.78 nDCG' on our relevance judgements, reached only 0.009 nDCG' on the human-annotated relevance judgements for task 1, which is not significantly better than zero.</p><p>After the competition, we experimented with additional configurations:</p><p>1. We trained on the human-annotated relevance judgements, using weighted sampling to correct class imbalance (see Section 2.4). 2. We replaced the standardization of dist exp with linear scaling to [0; 1]. 3. We replaced the Triplet objective with the objective of a related Transformer model that produces embeddings for questions and answers. [11, Section 4.a] 4. We assigned questions and answers different token types.</p><p>None of the configurations achieved significantly better nDCG' than zero on the human-annotated relevance judgements for task 1. Speed The submitted system was trained in 4 iterations over 1.4 million pairs of question-answer bodies with math represented in L A T E X. Each iteration took 6 hours and 30 minutes to finish, using NVIDIA GTX 2080 Ti, with 11 GiB of VRAM. We were able to fit batches of 25 question-answer pairs in-memory in a training step and hence we adjusted weights based on such amount of data.</p><p>Table <ref type="table" coords="21,160.61,116.30,3.36,8.41">2</ref>. The nDCG' on our relevance judgements for selected COMPUBERT configurations. The bert-base-cased configurations were pre-trained as described by Devlin et al. <ref type="bibr" coords="21,146.08,138.14,10.45,8.63" target="#b6">[7]</ref> and the bert-base-wikipedia-sections-mean-tokens and bert-base-nli-mean-tokens configurations were pretrained using similar objective to ours, as described by Reimers and Gurevych. In the explicit token_type configuration, we assigned a distinct mask for math tokens on input, often used to distinguish between different input languages. <ref type="bibr" coords="21,465.53,171.02,3.48,8.63">[</ref> We fine-tuned the pre-trained Bert-base-cased snapshot of the Bert-base architecture. <ref type="bibr" coords="21,182.87,360.61,11.62,9.58" target="#b6">[7]</ref> Following the example of Reimers and Gurevych, <ref type="bibr" coords="21,416.28,360.61,16.60,9.58" target="#b25">[26]</ref> we choose the top-layer representation to be a 768-float vector.</p><p>The trained system was able to index all 1.4 million answers by inferring the static embeddings of their content, preprocessed in the same manner. Indexing using the same GPU takes roughly four times less than training: 1 hour and 44 minutes. Once all the answers are indexed, the system consumes 27 GiB of RAM to keep the embeddings in-memory. This can be further optimized using vector databases, if needed.</p><p>Retrieval for a single topic requires an inference of topic embedding and the retrieval of a ranked list of answers, based on the similarity of the embeddings. We use exact nearest neighbor search and compute the cosine similarity between the topic embedding and each of the indexed answers. Single embedding inference takes 0.004 seconds on GPU and an exact-search retrieval of requested 1,000 ranked questions -just as all ranked answers -takes 3.426 seconds on average, 3.667 seconds maximum and 3.198 seconds minimum.</p><p>"There are two ways to wash dishes: One is to wash them in order to make them clean; the other is to wash them in order to wash them." Anthony de Mello</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Ensemble</head><p>Different information retrieval systems can agree on a small portion of the most relevant documents, but each individual system will miss the great majority of relevant documents. With ensembling, we can combine the strenghts of different information retrieval systems to produce more accurate results.</p><p>In this section, we describe a parameter-free algorithm for ensembling an arbitrary number of result lists into a single result list. The algorithm is agnostic to the scoring functions used by the different systems and only uses the ranks of results. Our experimental code is available online. <ref type="foot" coords="22,365.85,152.90,7.57,7.28" target="#foot_15">21</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Algorithm</head><p>Definition 1 (Frequency f ). Let T be a topic. Let R be a result for T that appears in exactly f result lists. The frequency of R is f . Definition 2 (Median Inverse Rank M -1 ). Let T be a topic. Let R be a result for T that appears in any of the N result lists. Let M be the median of rank 1 , rank 2 , . . . , rank N , where rank i , 0 ≤ rank i ≤ 1000 is the zero-based rank of R in the i-th result list if R appears in the i-th result list, and 1000 otherwise. The median inverse rank M -1 of R is (1000 -M)/1000. Definition 3 (Striped Inverse Rank S -1 ). Let T be a topic. Let R be the k-th result for T (according to some criterion). Let S = rank i , where i ≡ k (mod f ) and rank i , 0 ≤ rank i ≤ 1000 is the zero-based rank of R in the i-th result list of the f result lists in which R appears. The striped inverse rank S -1 of R is (1000 -S)/1000.</p><p>For each topic T, we combine the result lists of the systems, and we lexicographically order them using the four-tuple (M -1 , f , S -1 , result name). The top 1,000 ordered results are the ensembled result list for topic T.</p><p>The rationale of the algorithm is the following: If multiple results with the same M -1 exist, then f is used to break the ties. If ties still exist, the tied results are interleaved using S -1 to ensure fairness. The remaining ties are broken arbitrarily using the result name.</p><p>In our implementation, we only reported M -1 as the score in the ensembled result lists. Since the trec_eval software <ref type="foot" coords="22,305.92,462.29,7.57,7.28" target="#foot_16">22</ref> used for evaluation disregards the reported ranks of results and infers them from the reported scores instead, the ensembled result lists were effectively reordered using the two-tuple (M -1 , result name) during evaluation. This flaw in trec_eval has only a limited effect on the nDCG', since the four-tuple (M -1 , f , S -1 , result name) has already decided which 1,000 results would appear in the result list. See also the discussion of tie-breaking in information retrieval by Cabanac et al. <ref type="bibr" coords="22,373.04,536.01,11.62,9.58" target="#b3">[4]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Evaluation</head><p>For task 1, we ensembled our three primary submissions: MIaS (0.155, see Section 3), the small model of the SCM (0.224, see Section 4), and COMPUBERT (0.009, see Section 6). To assess the capabilities of our ensembling algorithm, we also ensembled all non-baseline primary submissions submitted to task 1 by the ARQMath participants: alpha05 (0.278), PSU2 (0.228), SCM (0.224), MIaS (0.155), COMPUBERT (0.009), zbMATH (0.101), and DPLR2 (0.051). <ref type="bibr" coords="23,421.22,130.98,15.77,9.58" target="#b47">[47,</ref><ref type="bibr" coords="23,439.10,130.98,41.49,9.58">Table A1]</ref> For task 2, we also ensembled our two primary submissions: the small model of the SCM (0.059, see Section 4), and the small model of Formula2Vec (0.108, see Section 6). To assess the capabilities of our ensembling algorithm, we also ensembled all non-baseline primary submissions submitted to task 2 by the ARQMath participants: TangentCFTED (0.420), Formula2Vec (0.108), and SCM (0.059). [47, Table <ref type="table" coords="23,216.40,202.71,10.69,9.58">A2</ref>] The primary submission of formulaembedding (0.026) was not included in the ensemble, since it was not shared by the participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Results</head><p>In this section, we will discuss the tie-breaking performance of ensembling, and the accuracy of ensembling using nDCG' on the official human-annotated relevance judgements for task 1. Since the ensembling was applied on the result lists as a post-processing step, speed can not be meaningfully reported.</p><p>Breaking Ties Table <ref type="table" coords="23,231.83,323.64,4.98,9.58" target="#tab_4">3</ref> shows how successful our algorithm was in breaking ties. 59.29% of results in task 1 and 47.56% of results in task 2 only had their ties broken using their names. A fairer tie-breaking strategy would have been to combine and lexicographically order the results R using the four-tuple (M -1 , f , S -1 , index of R's originating result list), so that tied results from different input result list are interleaved. Accuracy For task 1, the ensemble of our three primary submissions achieved the highest accuracy of all our systems (0.238). The ensemble of all non-baseline primary submissions <ref type="foot" coords="23,228.94,552.35,7.57,7.28" target="#foot_17">23</ref> received the highest accuracy in the competition (0.419), significantly better than the alpha05noReRank alternative submission of the MathDowsers team (0.345). [47, Table <ref type="table" coords="23,301.75,578.25,10.70,9.58" target="#tab_0">A1</ref>] For task 2, the ensemble of our two primary submissions achieved a slightly lower accuracy (0.100) than Formula2Vec (0.108). The ensemble of all non-baseline primary submissions <ref type="foot" coords="23,247.03,612.12,7.57,7.28" target="#foot_18">24</ref> received the third highest accuracy results in the competition (0.327).</p><p>There was no difference in nDCG' for either task when using the fairer tiebreaking strategy described in the previous section. This is because of the arbitrary reordering of results by trec_eval discussed in Section 7.1: the fairer tiebreaking did not alter the top 1,000 results present in the ensembled result lists.</p><p>Figure <ref type="figure" coords="24,180.48,167.39,4.98,9.58" target="#fig_5">9</ref> shows the percentage of judged results at different ranks for all our submissions <ref type="foot" coords="24,189.01,177.35,7.57,7.28" target="#foot_19">25</ref> and offers an alternative interpretation of the surprisingly high accuracy of the ensemble: Due to the pooling of submitted results before annotation, [47, Figure <ref type="figure" coords="24,215.95,203.25,4.15,9.58">2</ref>] the ensembled result lists have significantly more judged results than any other submission. Since there is no penalty to the nDCG' for adding non-relevant results (i.e. gain(RES' i ) = 0) at the end of a result list (see Section 2.5), having more judged results is beneficial even if few are relevant. However, the high mean relevance of the first ten results (see Figure <ref type="figure" coords="24,432.29,251.07,8.85,9.58" target="#fig_0">10</ref>) and the best P@10 among our systems [47, Tables <ref type="table" coords="24,322.16,263.03,12.73,9.58" target="#tab_0">A1</ref> and<ref type="table" coords="24,358.23,263.03,10.70,9.58">A2</ref>] indicate that this is not the main cause of the high accuracy of the ensemble.</p><p>"Meaning is only found when you go beyond meaning." Anthony de Mello</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Results</head><p>In this section, we will describe the accuracy and the speed of all our systems on tasks 1 and 2.    <ref type="figure" coords="25,151.46,643.12,7.47,8.41" target="#fig_0">10</ref>. The mean relevance (gain) for all our task 1 (above) and 2 (below) submissions. For task 1, the ensemble has the highest mean relevance at ten, except for ranks 1 and 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Accuracy</head><p>Table <ref type="table" coords="26,161.84,136.35,4.98,9.58" target="#tab_5">4</ref> shows the nDCG' of all our systems on both tasks. The primary and alternative rows only show the results of our submissions, whereas the best row also include the results of our out-of-competition system configurations.</p><p>On task 1, the best configuration of the SCM is significantly better than MIaS, Formula2Vec, and COMPUBERT. On both tasks, the best configuration of the ensemble is significantly better than the ensembled systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Speed</head><p>Table <ref type="table" coords="26,161.31,240.74,4.98,9.58" target="#tab_6">5</ref> shows the run times of all our systems on task 1 and 2 topics. In task 1, MIaS was the fastest, closely followed by Formula2Vec and COMPUBERT. In task 2, SCM was faster than Formula2Vec, which is likely due to the larger number of indexing units and the fact that SCM uses sparse matrix multiplication, which becomes significantly faster than dense matrix multiplication as the matrices grow large.</p><p>"Wisdom tends to grow in proportion to one's awareness of one's ignorance." Anthony de Mello</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion and Future Work</head><p>In our work, we have introduced three significantly different MIR systems. The methods based on the vector space model (SCM and MIaS) have shown useful transferability to other tasks as well as interpretability, as it contains the solid ground in relying on concrete term matching.</p><p>While COMPUBERT has demonstrated an outstanding ability to learn a specific task of guessing the number of votes of an answer based on its textual and mathematical content, we've also observed an unexpected sensitivity to the training objective, where COMPUBERT was able to significantly outperform others on our relevance judgements but finished last on task 1 of the ARQMath 2020 competition. The possible reasons include overfitting, underfitting, and divergent objectives.</p><p>Thanks to the ARQMath competition, we will be able to identify such failures and further fine-tune our systems to better regard the provided humanannotated relevance judgements, that as we believe, better reflect the quality of a MIR system, than our artificial relevance judgements that we had to rely on when developing our systems.</p><p>Our most surprising finding is that three is better than one: In terms of accuracy, ensembling the results of our primary submissions outperformed all our three primary systems on task 1 of the ARQMath 2020 competition. Ensembling all non-baseline primary submissions for task 1 received the best score in the competition at a statistically significant margin.</p><p>Question answering in a complex domain such as STEM is a very challenging task. Looking at it from diverse viewpoints is a good thing and so is compounding and merging diverse approaches and their results! Ensembling worked for the ARQMath tasks, and it may work for other complex tasks in general.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,156.06,341.62,303.24,8.63"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Dependencies between math representations ingested by our systems.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="9,400.83,353.55,7.57,7.28"><head>11</head><label>11</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="9,153.41,654.30,308.55,8.63"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Top-level architecture of our Math Indexer and Searcher (MIaS) system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="18,134.77,283.74,345.82,8.63;18,134.77,294.70,345.83,8.63;18,134.77,305.66,345.83,8.63;18,134.77,316.62,276.79,8.63"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. COMPUBERT model and Triplet objective, introduced by Reimers andGurevych:<ref type="bibr" coords="18,179.02,294.70,14.94,8.63" target="#b25">[26]</ref> Informally, the system combines the Wordpiece embeddings<ref type="bibr" coords="18,441.99,294.70,10.45,8.63" target="#b6">[7]</ref> to create static representations of questions, that are similar to the representations of relevant answers, while dissimilar to the representations of irrelevant answers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="20,134.77,303.57,345.82,8.63;20,134.77,314.53,345.83,8.63;20,134.77,325.49,321.61,8.63"><head>Epoch 0 Fig. 8 .</head><label>08</label><figDesc>Fig. 8. Spearman's ρ and the corresponding loss (averaged over 20 batches) of training the submitted COMPUBERT configuration. Based on the monitoring, we chose to use the model weights from after epoch 4, before the performance started to degrade.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="25,134.77,354.56,345.82,8.63;25,134.77,365.52,345.83,8.63;25,134.77,376.48,345.82,8.63;25,134.77,387.43,345.82,8.63"><head>Fig. 9 .</head><label>9</label><figDesc>Fig.9. The percentage of judged results at different ranks for all our task 1 (above) and 2 (below) submissions. Whereas other alternative submissions only have the first 20 and ten results judged for tasks 1 and 2, respectively, due to the pooling of submissions, the ensemble has significantly more judged results, which may put it at an unfair advantage.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="25,134.77,643.05,345.83,8.63;25,134.77,654.00,345.82,8.63"><head></head><label></label><figDesc>Fig.10. The mean relevance (gain) for all our task 1 (above) and 2 (below) submissions. For task 1, the ensemble has the highest mean relevance at ten, except for ranks 1 and 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="14,114.10,116.47,390.56,148.90"><head>Table 1 .</head><label>1</label><figDesc>The results of a grid search of the Sym ∈ {, }, Dom ∈ {, }, and C ∈ {0, 50, 100, 200, 400, 800, 1600} parameters using the nDCG' on our relevance judgements as the objective. Optimal parameter values are bold. However, only the values that are italic were available before the competition due to time constraints.</figDesc><table coords="14,114.10,174.50,390.56,90.86"><row><cell>Sym Dom C nDCG'</cell><cell>Sym Dom C nDCG'</cell><cell>Sym Dom C nDCG'</cell><cell>Sym Dom C nDCG'</cell></row><row><cell>0 0.7613</cell><cell>0 0.7613</cell><cell>0 0.7613</cell><cell>0 0.7613</cell></row><row><cell>50 0.7614</cell><cell>50 0.7613</cell><cell>50 0.7613</cell><cell>50 0.7612</cell></row><row><cell>100 0.7614</cell><cell>100 0.7613</cell><cell>100 0.7610</cell><cell>100 0.7610</cell></row><row><cell>200 0.7614</cell><cell>200 0.7613</cell><cell>200 0.7611</cell><cell>200 0.7610</cell></row><row><cell>400 0.7612</cell><cell>400 0.7613</cell><cell>400 0.7613</cell><cell>400 0.7609</cell></row><row><cell>800 0.7614</cell><cell>800 0.7613</cell><cell>800 0.7609</cell><cell>800 0.7609</cell></row><row><cell>1600 0.7612</cell><cell>1600 0.7613</cell><cell>1600 0.8104</cell><cell>1600 0.7609</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="17,134.77,530.91,345.83,71.85"><head></head><label></label><figDesc>see the performance of MIaS in Section 3.2. "If what you seek is Truth, there is one thing you must have above all else." "I know. An overwhelming passion for it." "No. An unremitting readiness to admit you may be wrong." Anthony de Mello</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="18,135.76,118.82,230.48,148.06"><head></head><label></label><figDesc>Can anyone explain ...</figDesc><table coords="18,144.64,118.82,221.61,148.06"><row><cell cols="3">Sentence Transformer</cell><cell></cell><cell></cell></row><row><cell>[wordpiece embedding]</cell><cell>[wordpiece embedding] (Mean) Pooling model</cell><cell>[wordpiece embedding]</cell><cell>[Q embedding]</cell><cell>[A rel embedding]</cell></row><row><cell></cell><cell>BERT_Base</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">A relevant : Consider c 2 = a 2 +b 2 ...</cell></row></table><note coords="18,135.76,258.09,9.06,7.74"><p>Q:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="23,134.77,412.37,345.83,72.35"><head>Table 3 .</head><label>3</label><figDesc>Percentages of ties in the submitted ensembled result lists when ordering the result lists by just a first few ordering criteria.</figDesc><table coords="23,220.34,446.65,174.68,38.07"><row><cell>(M -1 ,</cell><cell>f ,</cell><cell>S -1 , result name)</cell></row><row><cell cols="3">Task 1 92.76% 92.75% 59.29% 0.00%</cell></row><row><cell cols="3">Task 2 48.33% 47.72% 47.56% 0.00%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="24,134.77,444.05,345.83,104.78"><head>Table 4 .</head><label>4</label><figDesc>The nDCG' for the primary and secondary submissions of all our systems on tasks 1 (left) and 2 (right) as well as the best nDCG' among the submitted and out-ofcompetition system configurations. Best and second best systems in a row are bold and italic, respectively.</figDesc><table coords="24,161.28,501.92,292.80,46.91"><row><cell></cell><cell cols="2">MIaS SCM F2Vec CBRT Ens.</cell><cell></cell><cell>SCM F2Vec Ens.</cell></row><row><cell>Best</cell><cell cols="2">0.155 0.237 0.101 0.009 0.419</cell><cell>Best</cell><cell>0.119 0.108 0.327</cell></row><row><cell>Primary</cell><cell>0.155 0.224</cell><cell>0.009</cell><cell>Primary</cell><cell>0.059 0.108</cell></row><row><cell>Alternative</cell><cell>0.050</cell><cell>0.238</cell><cell cols="2">Alternative 0.119 0.077 0.100</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="24,134.77,565.68,345.82,93.82"><head>Table 5 .</head><label>5</label><figDesc>The average, minimum, and maximum run time in seconds for all our systems to produce results for a task 1 (left) and 2 (right) topic. Best and second best results in a row are bold and italic, respectively.</figDesc><table coords="24,178.06,612.59,259.23,46.91"><row><cell></cell><cell>MIaS SCM F2Vec CBRT</cell><cell></cell><cell>SCM F2Vec</cell></row><row><cell cols="2">Minimum 0.1 30.52 3.14 3.2</cell><cell cols="2">Minimum 54.81 61.61</cell></row><row><cell>Average</cell><cell>1.24 58.64 3.23 3.43</cell><cell>Average</cell><cell>108.86 164.5</cell></row><row><cell cols="2">Maximum 7.27 502.84 7.87 3.67</cell><cell cols="2">Maximum 2720.14 5448.65</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,634.91,335.86,8.63;2,144.95,645.87,278.06,8.63"><p>Formula2Vec is considered secondary, because it is a direct application of the Doc2Vec DBOW model<ref type="bibr" coords="2,199.09,645.87,14.94,8.63" target="#b14">[15]</ref> without any adaptation to the tasks of the ARQMath</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2020" xml:id="foot_1" coords="2,445.60,645.87,35.00,8.63;2,144.73,656.82,334.38,8.63"><p>competition. It serves as a baseline for the architecturally-similar primary system of the SCM.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2" coords="3,144.73,646.07,136.48,7.47"><p>https://dlmf.nist.gov/LaTeXML</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3" coords="3,144.73,657.44,165.22,7.47"><p>https://github.com/MIR-MU/MathMLCan</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4" coords="5,144.73,646.07,160.51,7.47"><p>https://github.com/MIR-MU/MIaSMath</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_5" coords="5,144.73,657.44,169.92,7.47"><p>https://github.com/MIR-MU/TangentCFT</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_6" coords="6,144.73,657.44,246.22,7.47"><p>https://github.com/MIR-MU/ARQMath-data-preprocessing</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_7" coords="7,144.73,645.45,307.22,8.63"><p>https://github.com/MIR-MU/ARQMath-eval, files votes-qrels-*.V1.0.tsv</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_8" coords="7,144.73,656.82,287.90,8.63"><p>https://github.com/MIR-MU/ARQMath-eval, files qrel_task{1,2}.tsv</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_9" coords="8,144.73,656.82,278.48,8.63"><p>https://github.com/MIR-MU/ARQMath-eval, files qrel_task1-*.tsv</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_10" coords="10,144.73,656.82,296.72,8.63"><p>https://github.com/ARQMath/ARQMathCode, file generate_html_file.py</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_11" coords="11,144.73,656.82,335.86,8.63"><p>https://github.com/MIR-MU/SCM-at-ARQMath, file json_to_fasttext_and_scm.py</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_12" coords="12,144.73,634.49,262.14,8.63;12,144.73,646.07,268.25,7.47"><p>https://radimrehurek.com/gensim/models/fasttext.html and https://radimrehurek.com/gensim/similarities/termsim.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="18" xml:id="foot_13" coords="16,144.73,645.45,292.01,8.63"><p>https://github.com/searchisko/searchisko, file Doc2Vec_wrapper.py</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="20" xml:id="foot_14" coords="18,144.73,657.44,165.22,7.47"><p>https://github.com/MIR-MU/CompuBERT</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="21" xml:id="foot_15" coords="22,144.73,645.45,284.10,8.63"><p>https://github.com/MIR-MU/SCM-at-ARQMath, file combine_serps.py</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="22" xml:id="foot_16" coords="22,144.73,657.44,178.84,7.47"><p>https://github.com/usnistgov/trec_eval</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="23" xml:id="foot_17" coords="23,144.73,645.45,294.01,8.63"><p>https://github.com/MIR-MU/SCM-at-ARQMath, file ensemble-task1.tsv</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="24" xml:id="foot_18" coords="23,144.73,656.82,294.01,8.63"><p>https://github.com/MIR-MU/SCM-at-ARQMath, file ensemble-task2.tsv</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="25" xml:id="foot_19" coords="24,144.73,400.18,182.07,7.47;24,144.73,410.52,218.93,8.63"><p>https://github.com/MIR-MU/ARQMath-eval, file mean-relevance-and-percentages-judged.ipynb</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements First author's work was graciously funded by the <rs type="funder">South Moravian Centre for International Mobility</rs> as a part of the <rs type="funder">Brno Ph</rs>.D. Talent project. We also thank the three anonymous reviewers for their insightful comments. Last but not least, we extend our gratitude to the ARQMath 2020 organizers for their great professionalism and patience.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="27,142.61,225.70,337.98,8.63;27,150.95,236.66,329.64,8.63;27,150.95,247.62,329.64,8.63;27,150.95,258.58,329.64,8.63;27,150.95,270.16,174.13,7.47" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="27,150.95,258.58,128.77,8.63">Mathematical markup language</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ausbrooks</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Buswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Carlisle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Chavchanidze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dalmas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Devitt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Diaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dooley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ion</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kohlhase</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lazrek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Libbrecht</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Miner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Rowley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sargent</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Soiffer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sutor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Watt</surname></persName>
		</author>
		<ptr target="https://www.w3.org/TR/MathML3/Overview.html" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>MathML) version 3.0 2nd edition</note>
</biblStruct>

<biblStruct coords="27,142.61,280.84,337.98,8.63;27,150.95,291.79,237.05,8.63" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="27,352.87,280.84,66.37,8.63">Apache Lucene 4</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Białecki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Muir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Ingersoll</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Imagination</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="27,437.08,280.84,43.51,8.63;27,150.95,291.79,186.28,8.63">SIGIR 2012 workshop on open source information retrieval</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="27,142.61,303.09,337.98,8.63;27,150.95,314.05,329.64,8.63;27,150.95,325.01,57.53,8.63" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="27,346.35,303.09,134.24,8.63;27,150.95,314.05,68.97,8.63">Enriching word vectors with subword information</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="27,226.40,314.05,245.13,8.63">Transactions of the Association for Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="135" to="146" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="27,142.61,336.31,337.98,8.63;27,150.95,347.27,329.64,8.63;27,150.95,358.23,329.64,8.63;27,150.95,369.18,96.30,8.63" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="27,384.85,336.31,95.74,8.63;27,150.95,347.27,258.47,8.63">Tie-breaking bias: effect of an uncontrolled parameter on information retrieval evaluation</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Cabanac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hubert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Boughanem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Chrisment</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="27,429.15,347.27,51.44,8.63;27,150.95,358.23,309.68,8.63">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="112" to="123" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="27,142.61,380.48,337.98,8.63;27,150.95,391.44,328.04,8.63" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">X</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2002.03932</idno>
		<title level="m" coord="27,391.28,380.48,89.31,8.63;27,150.95,391.44,155.93,8.63">Pre-training Tasks for Embedding-based Large-scale Retrieval</title>
		<imprint>
			<date type="published" when="2020-02">Feb 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
</biblStruct>

<biblStruct coords="27,142.61,402.74,337.98,8.63;27,150.95,413.70,329.64,8.63;27,150.95,424.66,329.64,8.63;27,150.95,435.61,23.90,8.63" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="27,250.80,402.74,229.79,8.63;27,150.95,413.70,237.07,8.63">Simbow at semeval-2017 task 3: Soft-cosine semantic similarity between questions for community question answering</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Charlet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Damnati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="27,407.40,413.70,73.19,8.63;27,150.95,424.66,213.03,8.63">Proceedings of the 11th International Workshop on Semantic Evaluation</title>
		<meeting>the 11th International Workshop on Semantic Evaluation<address><addrLine>SemEval</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2017. 2017</date>
			<biblScope unit="page" from="315" to="319" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="27,142.61,446.91,337.98,8.63;27,150.95,457.87,329.64,8.63;27,150.95,468.83,23.90,8.63" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="27,345.15,446.91,135.44,8.63;27,150.95,457.87,193.11,8.63">Bert: Pre-training of deep bidirectional transformers for language understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="27,142.61,480.13,337.98,8.63;27,150.95,491.09,329.64,8.63;27,150.95,502.05,329.64,8.63;27,150.95,513.00,329.64,8.63;27,150.95,523.96,329.63,8.63;27,150.95,535.54,47.56,7.47" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="27,338.94,480.13,141.65,8.63;27,150.95,491.09,70.41,8.63">Normalization of digital mathematics library content</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Formánek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Líška</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sojka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename></persName>
		</author>
		<ptr target="http://ceur-ws.org/Vol-921/wip-05.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="27,463.49,491.09,17.11,8.63;27,150.95,502.05,329.64,8.63;27,150.95,513.00,236.97,8.63;27,162.31,523.96,119.11,8.63">24th OpenMath Workshop, 7th Workshop on Mathematical User Interfaces (MathUI), and Intelligent Computer Mathematics Work in Progress</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Davenport</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Jeuring</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Lange</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Libbrecht</surname></persName>
		</editor>
		<meeting><address><addrLine>Aachen</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="91" to="103" />
		</imprint>
	</monogr>
	<note>CEUR Workshop Proceedings</note>
</biblStruct>

<biblStruct coords="27,142.61,546.22,337.98,8.63;27,150.95,557.18,329.64,8.63;27,150.95,568.14,218.06,8.63" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ginev</surname></persName>
		</author>
		<idno>arXiv.org</idno>
		<ptr target="https://sigmathling.kwarc.info/resources/arxmliv-dataset-082019/,SIG-MathLing-SpecialInterest" />
		<title level="m" coord="27,196.64,546.22,212.63,8.63">arXMLiv:08.2019 dataset, an HTML5 conversion of</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
		<respStmt>
			<orgName>Group on Math Linguistics</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="27,142.24,579.44,338.35,8.63;27,150.95,590.39,329.64,8.63;27,150.95,601.35,329.64,8.63;27,150.95,612.93,180.83,7.47" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="27,250.98,590.39,229.61,8.63;27,150.95,601.35,114.53,8.63">Implementation of an Information Retrieval System Using the Soft Cosine Measure</title>
		<author>
			<persName coords=""><forename type="first">González</forename><surname>Barbosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Frausto-Solis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Villanueva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Valdés</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Florencia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Mata</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-47054-2_50</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-47054-2_50" />
		<imprint>
			<date type="published" when="2017-12">Dec 2017</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">667</biblScope>
			<biblScope unit="page" from="757" to="766" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="27,142.24,623.61,338.35,8.63;27,150.95,635.19,306.40,7.47;27,150.95,646.15,183.54,7.47" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Jernite</surname></persName>
		</author>
		<ptr target="https://github.com/huggingface/notebooks/blob/master/longform-qa/Long_Form_Question_Answering_with_ELI5_and_Wikipedia.ipynb" />
		<title level="m" coord="27,197.93,623.61,135.10,8.63">Explain Anything Like I&apos;m Five</title>
		<imprint>
			<date type="published" when="2020-06">June 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="27,142.24,656.82,303.48,8.63" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Krstovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<title level="m" coord="27,250.66,656.82,85.97,8.63">Equation Embeddings</title>
		<imprint>
			<date type="published" when="2018-03">Mar 2018</date>
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct coords="28,142.24,119.70,338.35,8.63;28,150.95,130.66,138.41,8.63" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="28,252.88,119.70,227.71,8.63;28,150.95,130.66,15.69,8.63">The measurement of observer agreement for categorical data</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Landis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">G</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="28,172.81,130.66,41.53,8.63">biometrics</title>
		<imprint>
			<biblScope unit="page" from="159" to="174" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="28,142.24,141.63,338.35,8.63;28,150.95,152.59,329.64,8.63;28,150.95,163.55,329.64,8.63;28,150.95,174.51,194.58,8.63" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="28,296.21,141.63,184.38,8.63;28,150.95,152.59,151.60,8.63">The abject failure of keyword IR for mathematics search: Berkeley at NTCIR-10 math</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">R</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="28,322.96,152.59,157.64,8.63;28,150.95,163.55,259.48,8.63">Proceedings of the 10th NTCIR Conference on Evaluation of Information Access Technologies, NTCIR-10</title>
		<meeting>the 10th NTCIR Conference on Evaluation of Information Access Technologies, NTCIR-10<address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">June 18-21, 2013 (2013</date>
		</imprint>
		<respStmt>
			<orgName>National Center of Sciences</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="28,142.24,185.47,338.35,8.63;28,150.95,196.43,226.52,8.63" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="28,233.26,185.47,217.71,8.63">Distributed representations of sentences and documents</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">V</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<idno>CoRR abs/1405.4053</idno>
		<ptr target="http://arxiv.org/abs/1405.4053" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="28,142.24,207.40,338.35,8.63;28,150.95,218.36,329.64,8.63;28,150.95,229.32,329.64,8.63;28,150.95,240.28,329.64,8.63;28,150.95,251.24,211.93,8.63" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="28,284.83,207.40,195.76,8.63;28,150.95,218.36,262.27,8.63">Combining text and formula queries in math information retrieval: Evaluation of query results merging strategies</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Líška</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sojka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename></persName>
		</author>
		<idno type="DOI">10.1145/2810355.2810359</idno>
		<ptr target="https://doi.org/10.1145/2810355.2810359" />
	</analytic>
	<monogr>
		<title level="m" coord="28,432.24,218.36,48.36,8.63;28,150.95,229.32,325.31,8.63;28,184.02,240.28,54.94,8.63">Proceedings of the First International Workshop on Novel Web Search Interfaces and Systems</title>
		<meeting>the First International Workshop on Novel Web Search Interfaces and Systems<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="7" to="9" />
		</imprint>
	</monogr>
	<note>NWSearch &apos;15</note>
</biblStruct>

<biblStruct coords="28,142.24,262.21,338.35,8.63;28,150.95,273.16,329.64,8.63;28,150.95,284.12,151.57,8.63" xml:id="b16">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">Y</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.02762</idno>
		<title level="m" coord="28,420.36,262.21,60.23,8.63;28,150.95,273.16,325.47,8.63">Understanding and improving transformer from a multi-particle dynamic system point of view</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="28,142.24,295.09,338.35,8.63;28,150.95,306.05,306.21,8.63" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="28,356.01,295.09,124.58,8.63;28,150.95,306.05,132.43,8.63">Sparse, Dense, and Attentional Representations for Text Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Luan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Eisenstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.00181</idno>
		<imprint>
			<date type="published" when="2020-04">Apr 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
</biblStruct>

<biblStruct coords="28,142.24,317.02,338.35,8.63;28,150.95,327.98,329.64,8.63;28,150.95,338.94,328.53,8.63" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="28,427.22,317.02,53.37,8.63;28,150.95,327.98,195.04,8.63">Tangent-CFT: An Embedding Model for Mathematical Formulas</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mansouri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Rohatgi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">L</forename><surname>Giles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zanibbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="28,364.66,327.98,115.94,8.63;28,150.95,338.94,258.66,8.63">Proceedings of the 2019 ACM SIGIR international conference on theory of Information Retrieval</title>
		<meeting>the 2019 ACM SIGIR international conference on theory of Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="28,142.24,349.91,338.35,8.63;28,150.95,360.87,329.64,8.63;28,150.95,371.82,329.64,8.63;28,150.95,382.78,150.60,8.63" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="28,392.41,349.91,88.18,8.63;28,150.95,360.87,223.49,8.63">Distributed Representations of Words and Phrases and their Compositionality</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="28,351.73,371.82,128.87,8.63;28,150.95,382.78,77.06,8.63">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Burges</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Bottou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Welling</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Z</forename><surname>Ghahramani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Weinberger</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="3111" to="3119" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="28,142.24,393.75,338.35,8.63;28,150.95,404.71,240.94,8.63" xml:id="b20">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1301.3781</idno>
		<title level="m" coord="28,325.96,393.75,154.63,8.63;28,150.95,404.71,87.44,8.63">Efficient Estimation of Word Representations in Vector Space</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="28,142.24,415.68,338.35,8.63;28,150.95,426.64,329.64,8.63;28,150.95,437.60,329.64,8.63;28,150.95,448.56,215.52,8.63" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="28,204.16,415.68,196.65,8.63">Implementation notes for the soft cosine measure</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Novotný</surname></persName>
		</author>
		<idno type="DOI">10.1145/3269206.3269317</idno>
		<ptr target="https://doi.org/10.1145/3269206.3269317" />
	</analytic>
	<monogr>
		<title level="m" coord="28,421.49,415.68,59.10,8.63;28,150.95,426.64,329.64,8.63;28,150.95,437.60,68.65,8.63">Proceedings of the 27th ACM International Conference on Information and Knowledge Management (CIKM &apos;18)</title>
		<meeting>the 27th ACM International Conference on Information and Knowledge Management (CIKM &apos;18)<address><addrLine>Torino, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1639" to="1642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="28,142.24,459.53,338.35,8.63;28,150.95,470.48,329.63,8.63;28,150.95,482.06,65.89,7.47" xml:id="b22">
	<monogr>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Novotný</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">F</forename><surname>Ayetiran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Štefánik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sojka</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/2003.05019" />
		<title level="m" coord="28,362.12,459.53,118.47,8.63;28,150.95,470.48,214.16,8.63">Text classification with word embedding regularization and soft similarity measure</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="28,142.24,492.41,338.35,8.63;28,150.95,503.37,329.64,8.63;28,150.95,514.33,169.78,8.63" xml:id="b23">
	<monogr>
		<title level="m" type="main" coord="28,165.78,503.37,310.34,8.63">Transformer Based Language Models for Similar Text Retrieval and Ranking</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Qadrud-Din</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bah Rabiou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Soni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gajek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Pack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rangaraj</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2005.04588</idno>
		<imprint>
			<date type="published" when="2020-05">May 2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv e-prints</note>
</biblStruct>

<biblStruct coords="28,142.24,523.30,338.36,10.63;28,150.95,536.26,329.64,8.63;28,150.95,547.22,321.46,8.63" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="28,236.62,525.30,239.56,8.63">Software Framework for Topic Modelling with Large Corpora</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Řeh Ůřek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sojka</surname></persName>
		</author>
		<idno type="DOI">10.13140/2.1.2393.1847</idno>
		<ptr target="https://doi.org/10.13140/2.1.2393.1847" />
	</analytic>
	<monogr>
		<title level="m" coord="28,163.57,536.26,297.13,8.63">Proceedings of LREC 2010 workshop New Challenges for NLP Frameworks</title>
		<meeting>LREC 2010 workshop New Challenges for NLP Frameworks<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<publisher>ELRA</publisher>
			<date type="published" when="2010-05">May 2010</date>
			<biblScope unit="page" from="45" to="50" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="28,142.24,558.18,338.35,8.63;28,150.95,569.14,329.64,8.63;28,150.95,580.10,329.64,8.63;28,150.95,591.06,329.64,8.63;28,150.95,602.02,329.64,8.63;28,150.95,612.98,329.64,8.63;28,150.95,624.56,38.14,7.47" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="28,263.36,558.18,217.23,8.63;28,150.95,569.14,59.87,8.63">Sentence-BERT: Sentence embeddings using Siamese BERT-networks</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Reimers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/D19-1410</idno>
		<ptr target="https://www.aclweb.org/anthology/D19-1410" />
	</analytic>
	<monogr>
		<title level="m" coord="28,237.14,569.14,243.46,8.63;28,150.95,580.10,329.64,8.63;28,150.95,591.06,255.19,8.63">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</title>
		<meeting>the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)<address><addrLine>Hong Kong, China</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2019-11">Nov 2019</date>
			<biblScope unit="page" from="3982" to="3992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="28,142.24,632.91,338.35,10.62;28,150.95,645.87,329.64,8.63;28,150.95,656.82,329.64,8.63;29,150.95,119.70,329.64,8.63;29,150.95,130.66,160.18,8.63" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="28,450.98,634.91,29.61,8.63;28,150.95,645.87,290.23,8.63">Semantic vector encoding and similarity search using fulltext search engines</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rygl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pomikálek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Řeh Ůřek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Novotný</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sojka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename></persName>
		</author>
		<idno type="DOI">10.18653/v1/W17-2611</idno>
		<ptr target="https://doi.org/10.18653/v1/W17-2611" />
	</analytic>
	<monogr>
		<title level="m" coord="28,463.92,645.87,16.68,8.63;28,150.95,656.82,288.12,8.63">Proceedings of the 2nd Workshop on Representation Learning for NLP</title>
		<meeting>the 2nd Workshop on Representation Learning for NLP<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2017-08">Aug 2017</date>
			<biblScope unit="page" from="81" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.24,140.90,338.35,8.63;29,150.95,151.86,329.63,8.63;29,150.95,163.43,28.24,7.47" xml:id="b27">
	<monogr>
		<title level="m" type="main" coord="29,209.43,140.90,209.13,8.63">Maths Information Retrieval for Digital Libraries</title>
		<author>
			<persName coords=""><forename type="first">M</forename></persName>
		</author>
		<ptr target="https://is.muni.cz/th/pxz4q/" />
		<imprint>
			<date type="published" when="2018">2018</date>
			<pubPlace>Brno</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Masaryk University, Faculty of Informatics</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct coords="29,142.24,171.05,338.35,10.63;29,150.95,184.01,329.64,8.63;29,150.95,194.97,194.76,8.63" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="29,414.46,173.05,66.13,8.63;29,150.95,184.01,243.94,8.63">Flexible Similarity Search of Semantic Vectors Using Fulltext Search Engines</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Novotný</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sojka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pomikálek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Řeh Ůřek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="29,415.80,184.01,64.79,8.63;29,150.95,194.97,89.49,8.63">HybridSemStats Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">1923</biblScope>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.24,205.21,338.35,8.63;29,150.95,216.17,329.64,8.63;29,150.95,227.13,329.64,8.63;29,150.95,238.08,148.92,8.63" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="29,282.91,205.21,197.68,8.63;29,150.95,216.17,175.03,8.63">Math Indexer and Searcher under the Hood: History and Development of a Winning Strategy</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sojka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Líška</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="29,450.68,216.17,29.91,8.63;29,150.95,227.13,310.05,8.63">Proc. of the 11th NTCIR Conference on Evaluation of Information Access Technologies</title>
		<editor>
			<persName><forename type="first">H</forename><surname>Joho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Kishida</surname></persName>
		</editor>
		<meeting>of the 11th NTCIR Conference on Evaluation of Information Access Technologies<address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<publisher>NII</publisher>
			<date type="published" when="2014-12">Dec 2014</date>
			<biblScope unit="page" from="127" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.24,248.32,338.35,8.63;29,150.95,259.28,329.64,8.63;29,150.95,270.24,329.64,8.63;29,150.95,281.20,329.64,8.63;29,150.95,292.16,270.03,8.63" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="29,283.06,248.32,197.53,8.63;29,150.95,259.28,195.91,8.63">Math indexer and searcher under the hood: Finetuning query expansion and unification strategies</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sojka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Líška</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="29,252.88,270.24,227.72,8.63;29,150.95,281.20,139.87,8.63">Proceedings of the 12th NTCIR Conference on Evaluation of Information Access Technologies</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Kando</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Kishida</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">P</forename><surname>Kato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Yamamoto</surname></persName>
		</editor>
		<meeting>the 12th NTCIR Conference on Evaluation of Information Access Technologies<address><addrLine>Chiyoda-ku, Tokyo; Japan; Tokyo</addrLine></address></meeting>
		<imprint>
			<publisher>Hitotsubashi</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="101" to="8430" />
		</imprint>
		<respStmt>
			<orgName>National Institute of Informatics</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.24,302.40,338.35,8.63;29,150.95,313.35,308.30,8.63" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="29,234.15,302.40,246.44,8.63;29,150.95,313.35,132.42,8.63">On information retrieval metrics designed for evaluation with incomplete relevance assessments</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sakai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="29,289.82,313.35,85.76,8.63">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="447" to="470" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.24,323.59,338.35,8.63;29,150.95,334.55,229.28,8.63" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="29,244.97,323.59,217.91,8.63">Term-weighting approaches in automatic text retrieval</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="29,469.36,323.59,11.23,8.63;29,150.95,334.55,156.06,8.63">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="513" to="523" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.24,344.79,338.35,8.63;29,150.95,355.75,329.64,8.63;29,150.95,366.71,329.64,8.63;29,150.95,377.66,179.89,8.63" xml:id="b33">
	<analytic>
		<title level="a" type="main" coord="29,352.46,344.79,128.13,8.63;29,150.95,355.75,183.22,8.63">FaceNet: A unified embedding for face recognition and clustering</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Schroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kalenichenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Philbin</surname></persName>
		</author>
		<idno type="DOI">10.1109/CVPR.2015.7298682</idno>
		<ptr target="https://doi.org/10.1109/CVPR.2015.7298682" />
	</analytic>
	<monogr>
		<title level="m" coord="29,364.33,355.75,116.27,8.63;29,150.95,366.71,228.50,8.63">2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="815" to="823" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.24,387.90,338.35,8.63;29,150.95,398.86,329.64,8.63;29,150.95,409.82,329.64,8.63;29,150.95,420.78,329.64,8.63;29,150.95,431.74,329.63,8.63;29,150.95,443.32,85.21,7.47" xml:id="b34">
	<analytic>
		<title level="a" type="main" coord="29,320.60,387.90,159.99,8.63;29,150.95,398.86,120.03,8.63">Neural Machine Translation of Rare Words with Subword Units</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sennrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Haddow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Birch</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/P16-1162</idno>
		<ptr target="https://www.aclweb.org/anthology/P16-1162" />
	</analytic>
	<monogr>
		<title level="m" coord="29,298.77,398.86,181.83,8.63;29,150.95,409.82,212.09,8.63">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 54th Annual Meeting of the Association for Computational Linguistics<address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2016-08">Aug 2016</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1715" to="1725" />
		</imprint>
	</monogr>
	<note>Long Papers</note>
</biblStruct>

<biblStruct coords="29,142.24,452.93,338.35,8.63;29,150.95,463.89,329.64,8.63;29,150.95,474.85,81.43,8.63" xml:id="b35">
	<analytic>
		<title level="a" type="main" coord="29,374.87,452.93,105.72,8.63;29,150.95,463.89,224.94,8.63">Soft similarity and soft cosine measure: Similarity of features in vector space model</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Sidorov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Gómez-Adorno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Pinto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="29,382.65,463.89,97.95,8.63">Computación y Sistemas</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="491" to="504" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.24,485.09,338.35,8.63;29,150.95,496.05,290.98,8.63" xml:id="b36">
	<analytic>
		<title level="a" type="main" coord="29,299.78,485.09,162.14,8.63">Pivoted document length normalization</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="29,150.95,496.05,72.31,8.63">ACM SIGIR forum</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="176" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.24,506.29,338.35,8.63;29,150.95,517.24,329.64,8.63" xml:id="b37">
	<analytic>
		<title level="a" type="main" coord="29,377.66,506.29,65.52,8.63">AT&amp;T at TREC-7</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hindle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="29,463.91,506.29,16.68,8.63;29,150.95,517.24,232.97,8.63">Proceedings of the seventh Text REtrieval Conference (TREC-7)</title>
		<meeting>the seventh Text REtrieval Conference (TREC-7)</meeting>
		<imprint>
			<date type="published" when="1999-07">July 1999</date>
			<biblScope unit="page" from="239" to="252" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.24,527.48,338.35,8.63;29,150.95,538.44,93.05,8.63" xml:id="b38">
	<analytic>
		<title level="a" type="main" coord="29,224.09,527.48,187.89,8.63">Modern information retrieval: A brief overview</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="29,418.98,527.48,61.61,8.63;29,150.95,538.44,18.35,8.63">IEEE Data Eng. Bull</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="35" to="43" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.24,548.68,338.35,8.63;29,150.95,559.64,329.64,8.63;29,150.95,570.60,329.63,8.63;29,150.95,582.17,108.24,7.47" xml:id="b39">
	<analytic>
		<title level="a" type="main" coord="29,230.25,548.68,132.30,8.63">The Art of Mathematics Retrieval</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sojka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Líška</surname></persName>
		</author>
		<idno type="DOI">10.1145/2034691.2034703</idno>
		<ptr target="http://doi.acm.org/10.1145/2034691.2034703" />
	</analytic>
	<monogr>
		<title level="m" coord="29,382.15,548.68,98.44,8.63;29,150.95,559.64,156.05,8.63">Proceedings of the ACM Conference on Document Engineering</title>
		<meeting>the ACM Conference on Document Engineering<address><addrLine>Mountain View, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association of Computing Machinery</publisher>
			<date type="published" when="2011-09">2011. Sep 2011</date>
			<biblScope unit="page" from="57" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.24,591.79,338.35,8.63;29,150.95,602.75,329.64,8.63;29,150.95,613.71,329.63,8.63;29,150.95,625.29,136.98,7.47" xml:id="b40">
	<analytic>
		<title level="a" type="main" coord="29,398.95,591.79,81.64,8.63;29,150.95,602.75,76.61,8.63">Quo Vadis, Math Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sojka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Novotný</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">F</forename><surname>Ayetiran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lupták</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Štefánik</surname></persName>
		</author>
		<ptr target="https://nlp.fi.muni.cz/raslan/2019/paper11-sojka.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="29,247.64,602.75,232.96,8.63;29,150.95,613.71,68.19,8.63">Proceedings of Recent Advances in Slavonic Natural Language Processing</title>
		<meeting>Recent Advances in Slavonic Natural Language Processing<address><addrLine>RASLAN</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="117" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="29,142.24,634.91,338.35,8.63;29,150.95,645.87,329.64,8.63;29,150.95,656.82,329.64,8.63;30,150.95,119.70,329.64,8.63;30,150.95,130.66,166.86,8.63" xml:id="b41">
	<analytic>
		<title level="a" type="main" coord="29,318.96,634.91,161.63,8.63;29,150.95,645.87,117.57,8.63">MIaS: Math-Aware Retrieval in Digital Mathematical Libraries</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sojka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Novotný</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename></persName>
		</author>
		<idno type="DOI">10.1145/3269206.3269233</idno>
		<ptr target="https://doi.org/10.1145/3269206.3269233" />
	</analytic>
	<monogr>
		<title level="m" coord="29,299.49,645.87,181.10,8.63;29,150.95,656.82,326.30,8.63">Proceedings of the 27th ACM International Conference on Information and Knowledge Management (CIKM &apos;18)</title>
		<meeting>the 27th ACM International Conference on Information and Knowledge Management (CIKM &apos;18)<address><addrLine>Torino, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1923" to="1926" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,142.24,141.62,338.35,8.63;30,150.95,152.58,329.64,8.63;30,150.95,163.54,57.53,8.63" xml:id="b42">
	<analytic>
		<title level="a" type="main" coord="30,405.07,141.62,75.52,8.63;30,150.95,152.58,166.82,8.63">Transforming large collections of scientific publications to xml</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Stamerjohanns</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kohlhase</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ginev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="30,324.63,152.58,136.27,8.63">Mathematics in Computer Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="299" to="307" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,142.24,174.50,273.23,8.63" xml:id="b43">
	<analytic>
		<title level="a" type="main" coord="30,150.96,174.50,147.96,8.63">Student: The probable error of a mean</title>
	</analytic>
	<monogr>
		<title level="j" coord="30,305.99,174.50,43.74,8.63">Biometrika</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="25" />
			<date type="published" when="1908">1908</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,142.24,185.45,338.35,8.63;30,150.95,196.41,329.64,8.63;30,150.95,207.37,329.64,8.63;30,150.95,218.33,204.52,8.63" xml:id="b44">
	<analytic>
		<title level="a" type="main" coord="30,230.01,196.41,99.74,8.63">Attention is All you Need</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vaswani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shazeer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Parmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Uszkoreit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">N</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">U</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Polosukhin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="30,400.81,207.37,79.78,8.63;30,150.95,218.33,128.60,8.63">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Guyon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><forename type="middle">V</forename><surname>Luxburg</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Wallach</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Fergus</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Vishwanathan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Garnett</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="5998" to="6008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,358.52,218.33,122.08,8.63;30,150.95,229.91,294.28,7.47" xml:id="b45">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Curran Associates</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Inc</surname></persName>
		</author>
		<ptr target="http://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf" />
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="30,142.24,240.25,338.35,8.63;30,150.95,251.21,329.64,8.63;30,150.95,262.17,329.64,8.63;30,150.95,273.74,244.73,7.47" xml:id="b46">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Wojciechowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Nowi Ński</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sojka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Líška</surname></persName>
		</author>
		<ptr target="https://project.eudml.eu/sites/default/files/D5_3_v1.2.pdf" />
		<title level="m" coord="30,379.48,240.25,101.11,8.63;30,150.95,251.21,329.64,8.63;30,150.95,262.17,242.89,8.63">The EuDML Search and Browsing Service -Final (Feb 2013), deliverable D5.3 of EU CIP-ICT-PSP project 250503 EuDML: The European Digital Mathematics Library</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="30,142.24,284.08,338.35,8.63;30,150.95,295.04,241.18,8.63" xml:id="b47">
	<monogr>
		<title level="m" type="main" coord="30,362.69,284.08,117.90,8.63;30,150.95,295.04,215.03,8.63">Overview of ARQMath 2020: CLEF Lab on Answer Retrieval for Questions on Math</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zanibbi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mansouri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
