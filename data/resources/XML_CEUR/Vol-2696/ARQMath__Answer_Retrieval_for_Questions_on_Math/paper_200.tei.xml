<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,138.18,153.17,317.92,12.82;1,216.27,171.17,162.50,12.82">ARQMath Lab: An Incubator for Semantic Formula Search in zbMATH Open?</title>
				<funder>
					<orgName type="full">German Research Foundation</orgName>
				</funder>
				<funder ref="#_g8ah8Mq">
					<orgName type="full">DFG</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,188.48,210.26,63.15,8.78"><forename type="first">Philipp</forename><surname>Scharpf</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Konstanz</orgName>
								<address>
									<settlement>Konstanz</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,259.83,210.26,67.23,8.78"><forename type="first">Moritz</forename><surname>Schubotz</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Wuppertal</orgName>
								<address>
									<settlement>Wuppertal</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">FIZ Karlsruhe</orgName>
								<address>
									<settlement>Karlsruhe</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,340.17,210.26,82.79,8.78"><forename type="first">Andr√©</forename><surname>Greiner-Petter</surname></persName>
							<email>andre.greiner-petter@zbmath.org</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Wuppertal</orgName>
								<address>
									<settlement>Wuppertal</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,202.75,222.29,69.16,8.78"><forename type="first">Malte</forename><surname>Ostendorff</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Konstanz</orgName>
								<address>
									<settlement>Konstanz</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,280.10,222.29,53.76,8.78"><forename type="first">Olaf</forename><surname>Teschke</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">FIZ Karlsruhe</orgName>
								<address>
									<settlement>Karlsruhe</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,359.63,222.29,39.33,8.78"><forename type="first">Bela</forename><surname>Gipp</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Wuppertal</orgName>
								<address>
									<settlement>Wuppertal</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,138.18,153.17,317.92,12.82;1,216.27,171.17,162.50,12.82">ARQMath Lab: An Incubator for Semantic Formula Search in zbMATH Open?</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4338231CC0B96EBA510C51ECFF0F8AB2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Information Retrieval</term>
					<term>Mathematical Information Retrieval</term>
					<term>Question Answering</term>
					<term>Semantic Search</term>
					<term>Machine Learning</term>
					<term>Mathematical Objects of Interest</term>
					<term>ARQMath Lab 1</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The zbMATH database contains more than 4 million bibliographic entries. We aim to provide easy access to these entries. Therefore, we maintain different index structures, including a formula index. To optimize the findability of the entries in our database, we continuously investigate new approaches to satisfy the information needs of our users. We believe that the findings from the ARQMath evaluation will generate new insights into which index structures are most suitable to satisfy mathematical information needs. Search engines, recommender systems, plagiarism checking software, and many other added-value services acting on databases such as the arXiv and zbMATH need to combine natural and formula language. One initial approach to address this challenge is to enrich the mostly unstructured document data via Entity Linking. The ARQMath Task at CLEF 2020 aims to tackle the problem of linking newly posted questions from Math Stack Exchange (MSE) to existing ones that were already answered by the community. To deeply understand MSE information needs, answer-, and formula types, we performed manual runs for tasks 1 and 2. Furthermore, we explored several formula retrieval methods: For task 2, such as fuzzy string search, k-nearest neighbors, and our recently introduced approach to retrieve Mathematical Objects of Interest (MOI) with textual search queries. The task results show that neither our automated methods nor our manual runs archived good scores in the competition. However, the perceived quality of the hits returned by the MOI search particularly motivates us to conduct further research about MOI.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="22" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="23" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="24" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="25" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="26" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
		<surface n="27" ulx="0.0" uly="0.0" lrx="595.5" lry="842.25"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>In 2013 the first prototype of formula -search in zbMATH was announced <ref type="bibr" coords="1,431.02,667.42,10.29,8.77" target="#b0">[1]</ref>, which became an integral part of the zbMATH interface by now. At the beginning of 2021, zbMATH will transform its business model from a subscription-based service to a publicly funded open service. In this context, we evaluate novel approaches to include mathematical formulae as first-class citizens in our mathematical information retrieval infrastructure. Despite the standard search that targets abstract, review, and publication meta-data, zbMATH also traces incoming links from the Question Answering platform MathOverflow and provides backlinks from scientific articles to MathOverflow links, mentioning the publication <ref type="bibr" coords="2,242.55,223.04,10.29,8.78" target="#b0">[1]</ref>. We hypothesize that federating information from zbMATH and MathOverflow will enhance the zbMATH search experience significantly. The ARQMath Lab at CLEF 2020 aims to tackle the problem of linking newly posted questions from Math Stack Exchange to existing ones that we re already answered by the community <ref type="bibr" coords="2,231.27,271.06,10.29,8.77" target="#b1">[2]</ref>. Using question postings from a test collection (extracted by the ARQMath organizers from an MSE Internet Archive Snapshot<ref type="foot" coords="2,410.00,282.14,3.38,6.08" target="#foot_0">1</ref> until 2018) as queries, the goal is to retrieve relevant answer posts, containing both text and at least one formula . The test collection created for the task is intended to be used by researchers as a benchmark for mathematical retrieval tasks that involve both natural and mathematical language. The ARQMath Lab consists of two separate subtasks. Task 1 -Answer poses the challenge to retrieve relevant community answer post given a question from Math Stack Exchange (MSE). Task 2 -Formulas poses the challenge to retrieve relevant formulas from question and answer posts. Specifically, the aim of Task 1 is to be able to find old answers to new questions to speed up the community answer process. The aim of Task 2 is to find a ranked list of relevant formulae in old questions and answers to match to a query formula from the new question. This task design seems to a good fit for our research interest, since the information needs are related. Moreover, MathOverflow and math.stackexchange use the same data -format, which enables us to reuse software developed during this competition and to transform it into production software later on. On the other hand, the mathematical level of questions on Math Stack Exchange is less sophisticated and thus not all relevant rankings might be suitable for our use-case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">ARQMath Lab</head><p>The ARQMath lab was motivated by the fact that Mansouri et al. discovered "that 20% of the mathematical queries in general-purpose search engines were expressed as wellformed questions" <ref type="bibr" coords="2,200.50,560.81,10.26,8.77" target="#b1">[2]</ref>, <ref type="bibr" coords="2,216.99,560.81,10.30,8.77" target="#b2">[3]</ref>. Furthermore, with the increasing public interest in Community Question Answering sites such as MSE <ref type="foot" coords="2,301.13,571.89,3.38,6.08" target="#foot_1">2</ref> and MathOverflow 3 , it will be beneficial to develop computational methods to support human answerers. Particularly, the "timeto-answer" should be shortened by linking to related answers already provided on the platform, which can potentially lead to the answer more quickly. This will be of great help since most of the time the question is urgent and relatedsometimes even directly exactexisting answers are available. However, the task is challenging because both questions and answers can be a combination of natural and mathematical language, involving words and formulae. ARQMath lab at CLEF 2020 will be the first in a threeyear sequence through which the organizers "aim to push the state of the art in evaluation design for math-aware IR" <ref type="bibr" coords="3,257.57,187.01,10.27,8.78" target="#b1">[2]</ref>. The task starts with the domain of mathematics involving formula language. The goal is to later extend the task to other domains (e.g., chemistry or biology), which employ other types of special notation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Math Stack Exchange</head><p>Stack Exchange is an online platform with a host of Q&amp;A forums <ref type="bibr" coords="3,395.75,260.56,10.27,8.77" target="#b3">[4]</ref>. The Stack Exchange network consists of 177 Q&amp;A communities including Stack Overflow, which claims to be "the largest, most trusted online community for developers to learn and share their knowledge" 2 . The different topic sites include Q&amp;A on com puter issues, math, physics, photography, etc. Users can rank questions and answers by voting them up or down according to their quality assessment. Stack Exchange provides its content publicly available in XML format under the Creative Commons license <ref type="bibr" coords="3,415.27,332.64,10.27,8.77" target="#b3">[4]</ref>. The Math Stack Exchange collection for the ARQ lab tasks comprises Q&amp;A postings extracted from data dumps from the Internet Archive<ref type="foot" coords="3,304.13,355.69,3.38,6.08" target="#foot_3">4</ref> . Currently, over 1 million questions are included <ref type="bibr" coords="3,161.45,368.67,10.29,8.77" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Mathematical Question Answering</head><p>Already in 1974, Smith <ref type="bibr" coords="3,220.77,445.96,11.49,8.77" target="#b4">[5]</ref> describes a project investigating the understanding of natural language by computers. He develops a theoretical model of natural language processing (NLP) and algorithmically implements his theory. Specifically, he chooses the domain of elementary mathematics to construct a Q&amp;A system for unrestrict ed natural language input. However, for some time later, there was little interest and progress in the field of mathematical question answering. In 2012, Nguyen et al. <ref type="bibr" coords="3,396.50,506.04,11.49,8.78" target="#b5">[6]</ref> present a mathaware search engine for a math question answering system . Their system handles both textual keywords as well as mathematical expressions. The math feature extraction is designed to encode the semantics of math expressions via a Finite State Machine model. They tested their approach against three classical information retrieval strategies on math documents crawled from Math Overflow, claiming to outperform them by more than 9%. In 2017, Bhattacharya et al. <ref type="bibr" coords="3,280.85,578.09,11.49,8.77" target="#b6">[7]</ref> publish a survey of question answering for math and science problems. They explore the current achievements towards the goal of making computers smart enough to pass math and science tests. They conclude claiming that "the smartest AI could not pass high school". In 2018, Gunawan et al. <ref type="bibr" coords="3,441.55,614.11,11.49,8.77" target="#b7">[8]</ref> present an Indonesian question answering system for solving arithmetic word problems using pattern matching. Their approach is integrated into a physical humanoid robot.</p><p>For auditive communication with the robot, the user's Indonesian question must be translated into English text. They employ NLP using the NLTK toolkit <ref type="foot" coords="4,416.02,150.01,3.38,6.08" target="#foot_4">5</ref> , specifically co-referencing, question parsing, and preprocessing. They conclude claiming that the Q&amp;A system achieves an accuracy between 80% and 100%. However, they state that the response time is rather slow with average about more than one minute. Also in 2018, Schubotz et a l. <ref type="bibr" coords="4,187.73,199.01,11.49,8.78" target="#b8">[9]</ref> present MathQA <ref type="foot" coords="4,270.33,198.06,3.38,6.08" target="#foot_5">6</ref> , an open-source math-aware question answering system based on Ask Platypus<ref type="foot" coords="4,248.55,210.06,3.38,6.08" target="#foot_6">7</ref> . The system returns as a single mathematical formula for a natural language question in English or Hindi. The formulae are fetched from the open knowledge-base Wikidata <ref type="foot" coords="4,251.55,234.09,3.38,6.08" target="#foot_7">8</ref> . With numeric values for constants loaded from Wikidata, the user can do computations using the retrieved formula. It is claimed that the system outperforms a popular computational mathematical k nowledge-engine by 13%.</p><p>In 2019, Hopkins et al. <ref type="bibr" coords="4,217.77,271.06,16.72,8.77" target="#b9">[10]</ref> report on the SemEva l 2019 task on math question answering. The derived a question set from Math SAT practice exams, including 2778 training questions and 1082 test questions. According to their study, the top system correctly answered 45% of the test questions, with a random guessing baseline at 17%. Beyond the domain of math Q&amp;A, Pineau <ref type="bibr" coords="4,263.58,319.12,16.72,8.77" target="#b10">[11]</ref> and Abdi et al. <ref type="bibr" coords="4,345.42,319.12,16.72,8.77" target="#b11">[12]</ref> present first approaches to answer questions on physics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Mathematical Document Subject Class Classification</head><p>For open-domain question redirection, it is beneficial to classify a given mathematical question by its domain, e.g. geometry, calculus, set theory, physics, etc. There have been several approaches to perform categorization or subject class classification for mathematical documents. In 2017, Suzuki and Fujii <ref type="bibr" coords="4,334.15,416.69,16.72,8.77" target="#b12">[13]</ref> test classification methods on collections built from MathOverflow <ref type="foot" coords="4,276.35,427.76,3.38,6.08" target="#foot_8">9</ref> and the arXiv<ref type="foot" coords="4,338.67,427.76,7.13,6.08" target="#foot_9">10</ref> paper preprint repository. The user tags include both keywords for math concepts and categories form the Mathematical Subject Classification (MSC) 2010 <ref type="foot" coords="4,292.85,451.79,7.13,6.08" target="#foot_10">11</ref> top and second-level subjects. In 2020, Scharpf et al. <ref type="bibr" coords="4,183.23,464.74,11.49,8.77" target="#b8">[9]</ref> investigate how combining encodings of natural and mathematical language affect the classification and clustering of documents with ma thematical content. They employ sets of documents, sections, and abstracts from the arXiv 10, labeled by their subject class (mathematics, computer science, physics, etc.) to compare different encodings of text and formulae and evaluate the performance and runtimes of selected classification and clustering algorithms. Also in 2020, Schubotz et al. <ref type="bibr" coords="4,438.55,524.79,16.72,8.77" target="#b13">[14]</ref> explore whether it is feasible to automatically assign a coarse-grained prima ry classification using the MSC scheme using multi-class classification algorithms. They claim to achieve a precision of 81% for the autom atic article classification. We conclude that for math Q&amp;A systems, the classification needs to be performed at the sentence level.</p><p>If MSE questions contain several sentences, the problem could potentially also be framed as an abstract classification problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Connecting Natural and Mathematical Language</head><p>For mathematical question answering, mathematical information needs to be connected to natural language queries. Yang &amp; Ko <ref type="bibr" coords="5,291.35,182.49,16.72,8.78" target="#b14">[15]</ref> present a search engine for formulae in MathML<ref type="foot" coords="5,162.20,193.56,7.13,6.08" target="#foot_11">12</ref> using a plain word query. Mansouri et al. <ref type="bibr" coords="5,346.18,194.51,11.49,8.78" target="#b2">[3]</ref> investiga te how queries for mathematical concepts are performed in search engines. They conclude "that math search sessions are typically longer and less successful than general search sessions". For non-mathematical queries, search engines like Google <ref type="foot" coords="5,356.70,229.59,7.13,6.08" target="#foot_12">13</ref> or DuckDuckGo <ref type="foot" coords="5,434.02,229.59,7.13,6.08" target="#foot_13">14</ref> already provide entity cards with a short encyclopedic description of the searched concept <ref type="bibr" coords="5,452.80,242.56,15.17,8.78" target="#b15">[16]</ref>.</p><p>For mathematical concepts, however, there is an urgent need to connect a natural language query to a formula representing the keyword. Dmello <ref type="bibr" coords="5,370.20,266.56,16.72,8.77" target="#b15">[16]</ref> proposes integrating entity cards into the math-aware search interface MathSeer <ref type="foot" coords="5,366.45,277.64,7.13,6.08" target="#foot_14">15</ref> . Scharpf et al. <ref type="bibr" coords="5,435.55,278.59,16.72,8.77" target="#b16">[17]</ref> propose a Formula Concept Retrieval challenge for Formula Concept Discovery (FCD) and Formula Concept Recognition (FCR) tasks. They present first machine learning based approaches for retrieving formula concepts from the NTCIR 11/12 arXiv dataset <ref type="foot" coords="5,144.17,325.67,7.13,6.08" target="#foot_15">16</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Semantic Annotations</head><p>To connect mathematical formulae and symbols to natural language keywords, semantic annotations are an effective means. So far there are only a few annotation systems available for mathematical documents. Dumitru et al. <ref type="bibr" coords="5,340.17,400.94,16.72,8.77" target="#b17">[18]</ref> present a browser-based annotation tool ("KAT system") for linguistic/semantic annotations in structured (XHTML5) documents. Scharpf et al. <ref type="bibr" coords="5,280.85,424.96,16.72,8.77" target="#b18">[19]</ref> present "AnnoMathTeX", a recommender system for formula and identifier annotation of Wikipedia articles using Wikidata<ref type="foot" coords="5,463.33,436.01,7.13,6.08" target="#foot_16">17</ref> QID item tags. The annotations can be integrated into the MathML markup using MathML Wikidata Content Dictionaries<ref type="foot" coords="5,285.35,460.04,7.13,6.08" target="#foot_17">18</ref>  <ref type="bibr" coords="5,295.88,460.99,15.15,8.77" target="#b19">[20]</ref>, <ref type="bibr" coords="5,317.65,460.99,15.15,8.77" target="#b20">[21]</ref>, <ref type="bibr" coords="5,339.43,460.99,15.17,8.77" target="#b21">[22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Summary of Our Approach</head><p>We tackle the ARQMath lab tasks (Task 1answer retrieval, Task 2formula retrieval) using manual run selection benchmarking. Therefore, we create, populate, and employ a Wiki <ref type="foot" coords="5,182.47,541.12,7.13,6.08" target="#foot_18">19</ref> with pages for normal (Task 1) and formula (Task 2) topics. The main objective of our experiments was to explore methods to enable automatic answer assignment recommendations to question postings on Mathematics Stack Exchange (MSE). We tested the following approaches or methods: 1) manual run annotation using Google and MSE search, 2) formula TF-IDF or Doc2vec 20 encodings <ref type="bibr" coords="6,414.50,150.96,16.72,8.78" target="#b22">[23]</ref> using the Python libraries Scikit-learn 21 <ref type="bibr" coords="6,250.05,162.99,16.72,8.78" target="#b23">[24]</ref> and Gensim 22 <ref type="bibr" coords="6,329.65,162.99,15.17,8.78" target="#b24">[25]</ref>, 3) fuzzy string comparison or matching using rapidfuzz 23 , 4) k-nearest neighbors algorithm, and 5) discovering of Mathematical Objects of Interest (MOI) with textual search queries <ref type="bibr" coords="6,397.25,187.01,15.15,8.78" target="#b25">[26]</ref>.</p><p>As result, we obtained a relevant MSE answer(s) ID for each query in the sample of Task 1, and a ranked list of most relevant formulae for each query in the sample of Task 2 (if available). Finally, we analyzed our results using a manual consistency and quality check.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Workflow of Our Approach</head><p>The workflow of our approa ch is illustrated in Fig. <ref type="figure" coords="6,335.67,292.09,3.84,8.78">1</ref>. It can be logically divided into three stages: 1) the creation of a Wiki with pages for normal and formula topics, 2) methods to tackle Task 1, and 3) methods to tackle Task 2.</p><p>Fig. <ref type="figure" coords="6,143.43,553.08,3.38,8.10">1</ref>. Workflow of our approach to retrieve answer and formula candidates for Tasks 1 and 2.</p><p>In the following, we describe the stages with their subtasks in more detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Setup Wiki Framework</head><p>The initial preparation step for our approach to tackle Task 1 and 2 was to create, populate, and employ a MediaWiki environment connected to a mathoid <ref type="bibr" coords="6,413.75,620.12,16.72,8.77" target="#b26">[27]</ref> rendering 20 Also known as "Paragraph Vectors", as introduced in <ref type="bibr" coords="6,330.40,653.68,3.45,8.10">[</ref> Task 2</p><p>‚Ä¢Ma nual run selection of the most s uitable formula(e) ‚Ä¢La TeX s tring as "defining formula" property a s subproperty of "relevant a ns wers" on Wikidata item for formula topics service with pages for normal and formula topics. For each query, there is a Wikibase item with the following properties: 'math-stackexchange-category' (P10), 'topic-id' (P12), 'post-type' (P9), 'math stackexcange post id' (P5), and 'relevant answers' (P14).</p><p>Having set up the Wiki, we manually retrieved the question URLs using Google and MSE search and inserted them as values for the 'math stackexchange post id' on the respective question pages. Unfortunately by doing so some post 2019 new post-ids were entered because we did not check the date carefully enough. The 'math-stackexchangecategory' values were automatically retrieved from the question tags. The 'topic-id' (e.g., A.50) was transferred from the task dataset, the 'post-type' set to "Question".</p><p>Unfortunately, as we discovered later, the use of Google and MSE search led to results outside the task dataset. This means that the answer that was accepted as the best answer by the questioner was often not included in the task da taset. However, our aim was to establish the "correct" answer as semantic reference in our MediaWiki.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Populate Topic Answers (Task 1)</head><p>The first part in our experimental pipeline was a manual run selection of the most suitable answer from the MSE question posting page (preferably the one selected by the questioner, if available). Subsequently, we inserted links to the answers, i.e., math.stackexchange.com/a/xxx to the 'relevant answers' property of the query item normal topics page.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Populate Formula Answers (Task 2)</head><p>The second part in our experimental pipeline was a manual run selection of the most suitable formula per question or answer. The chosen formula was considered to answer the given question as concise as possible. Thus, we did interpret Task 2 as having to find formula answers to the question and only not similar formulae. We inserted the extracted LaTeX string to the 'defining formula ' property, as a subproperty of 'relevant answers' on the Wikidata item for formula topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Preparing Data for Experiments and Submission</head><p>After having populated our Wiki database, we used a SPARQL query (Fig. <ref type="figure" coords="7,431.02,565.34,4.26,8.78" target="#fig_0">2</ref>) to have an overview of its content. The query fetches all Wikidata question items, displaying their 'topic-id' (e.g. A.1 or B.1), 'post-id' (e.g., 3063081), and the formula LaTeX string. With the list of normal and formula topic insertions, we performed a quality check, correcting wrong or missing values. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">Discovering Mathematical Objects of Interest</head><p>The previously developed MOI search engine <ref type="bibr" coords="8,319.90,399.44,16.72,8.77" target="#b25">[26]</ref> allows us to search meaningful mathematical expressions by a given textual search query. This workflow can be used to solve Task 2, but it requires some substantial updates. Essentially, Task 2 requests relevant formula IDs for a given input formula ID. Each formula ID is mapped to the corresponding post ID. Hence, we can take the entire post of a formula ID as the input for our MOI search engine. However, there are two main problems with the existing approach: (i) the MOI search engine was developed and tested only to search for k eywords, thus, entering entire posts at once may harm the accuracy, and (ii) every retrieved MOI is by design a subexpression and, thus, has probably no designated formula ID. To overcome these issues, we need to understand the current system. The MOI search system retrieves MOIs in two steps. The first step retrieves relevant documents from an elasticsearch <ref type="foot" coords="8,215.52,530.59,7.13,6.08" target="#foot_19">24</ref> instance for the input query. Hence, we first indexed all ARQMath posts in elasticsearch. To index the content of each post appropriately, we set up the standard English stemmer, stopword filtering, HTML strippin g (filters out HTML tags but preserves the content of each tag), and enable ASCII folding (converts alphabetic, numeric, and symbolic characters to their ASCII equivalence, e.g., '√°' is replaced by 'a'). For the search query, we used the standard match query system but boosted every mathematical expression in the input. This tells elasticsearch to focus more on the math expressions in a search query, rather than the actual text. With this setup, we overcome the mentioned issue (i) and can search for relevan t posts by entering an entire content of a post. In the second step of the MOI search engine, the engine disassembles all formulae in the retrieved documents and calculates the mBM25 score <ref type="bibr" coords="9,124.65,162.99,16.72,8.78" target="#b25">[26]</ref> for each of these subexpressions (MOI) where mBM25 ( ùë°, ùê∑ ) is a modified version of the BM25 relevance score <ref type="bibr" coords="9,414.50,227.54,16.72,8.78" target="#b27">[28]</ref> with ùê∑ as the entire ARQMath corpus, IDF ( ùë° ) is the inverse document frequency of the term ùë°, TF ( ùë°, ùëë ) the term frequency of the term ùë° in the document ùëë ‚àà ùê∑, ITF ( ùë°, ùëë ) the inverse term frequency (calculated the same way as IDF ( ùë° ) but on the document level for the document ùëë), AVG DL the average document length of ùê∑ and AVG C the average complexity of ùê∑ (see <ref type="bibr" coords="9,193.75,287.59,16.72,8.77" target="#b25">[26]</ref> for a more detailed description). The top-scored expressions will be returned. The mBM25 score requires the global term and document frequencies of every subexpression. Hence, we first calculated these global values for every subexpression of every formula in the ARQMath dataset. Table <ref type="table" coords="9,359.70,323.62,4.88,8.78" target="#tab_1">1</ref> shows the statistics of this MOI database in comparison to the previously generated databases for arXiv and zbMATH. A document in ARQMath is a post from MSE. The dataset only includes MathML representations. The complexity of a formula is the maximum depth of the Presentation Ma thML representation of the formula. As Table <ref type="table" coords="9,376.98,371.66,4.88,8.78" target="#tab_1">1</ref> shows, the ARQMath database can be interpreted as a hybrid between the full research papers in arXiv and relatively short review discussions in zbMATH (mainly contain ing reviews of mathematical articles). Considering that every formula in the ARQMath dataset has its own ID and the system needs to preserve the ID during computation, we need to attach the ID to every generated MOI. However, this would result in a massive overload. For exam ple, the single identifier ùë• appears 7.6 million times in ARQMath and thus will have millions of different formula IDs. The entire ARQMath dataset has 16.8 million unique MOIs. Handle this number of different IDs is impractical. Hence, we choose a different approach to get the formula IDs for every MOI. Since the search engine retrieves the relevant documents first, we only need to consider formula IDs that exist in these retrieved documents. To achieve this, we attached the formula IDs to every post in the elasticsearch database ra ther than to the MOIs itself. A single document in elasticsearch now contains the post ID, the textual content, and a list of MOIs with local term frequencies (how often the MOI appears in the corresponding post) and formula IDs. Note that most MOI still has multiple formula IDs, since a subexpression may appear multiple times in a single post, but the number of different IDs reduced drastically. Since the IDs are now attached to each post but are not used in the search query, the performance of retrieving relevant documents from elasticsearch stays the same. With this approach, we may calculate multiple but different mBM25 scores for a single formula ID, since a single unique formula ID can be attached to multiple MOIs. To calcula te the final score for a formula ID, we calculated the average of all mBM25 scores for a formula ID. For example, consider we would retrieve the document with the ID 2759760. This post contains the formula ID 25466124 ùëí ùë• 6 , which would be disassembled into its subexpressions ùëí, ùë• 6 , and ùë•. Hence, we would calculate three mBM25 scores for ùëí/ùë• 6 . The average of these scores would be the score for the formula ID.</p><formula xml:id="formula_0" coords="9,193.00,180.81,4.19,9.75">s</formula><p>We used this updated MOI search engine to retrieve results for Task 2. Note t hat the approach might be a bit unorthodox, since the MOI search engine takes the entire post of the given formula ID rather than the formula ID alone. We interpreted Task 2 to retrieve answer formulae for a given question formula, rather than retrieving v isually or semantically similar formulae. Based on this interpretation, it makes sense to use the entire post of a formula ID to search for relevant answers. In other words, we interpreted Task 2 as an extension and math specific version of Task 1. In summary, the key steps of the MOI search engine to solve Task 2 were the following:</p><p>1. Take the entire post of the given formula ID.</p><p>2. Search for posts similar to the retrieved post in step 1.</p><p>3. Extract all MOI from all retrieved posts in step 2. 4. Calculate mBM25 scores for all MOIs of step 3. 5. Group the MOIs by their associated formula IDs (every formula ID has now multiple mBM25 scores). 6. Average the mBM25 scores for each formula ID.</p><p>For Task 2, we retrieved 107,476 MOIs. We used the provided annotation dataset to evaluate the retrieved results. For a better comparison, we calculated the nDCG p ‚Ä≤ (nDCG-prime) score, as the task organizers did <ref type="bibr" coords="11,325.15,174.99,15.17,8.78" target="#b28">[29]</ref>. Note the nDCG p ‚Ä≤ removes unjudged documents before calculating the score. Since these were post-experiment calculations, there is not much correlation between the retrieved MOI documents and the judged formula IDs. We found 179 formula IDs that were retrieved by our MOI engine and contained a judgment by the annotators of the ARQMath task. Based on these 179 judges, we retrieved an nDCG p ‚Ä≤ value of 0.374, which is in the midrange compared to the other competitors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">Data Integration of Query and Pool Formulae</head><p>We tested two other approaches for Task 2: Formula pool retrieval via k -nearest neighbors and fuzzy string matching. For both methods, we first needed to integrate the pool of formulae (the task dataset) with our query set, consisting of the formulae, which we 'manually' chose from the candidate answers to be a formula answer to the question asked.</p><p>Fig. <ref type="figure" coords="11,142.68,478.02,3.38,8.10">3</ref>. Workflow for Task 2 -formula answer candidate retrieval. Manually selected 'query' formulae must be integrated with the task dataset pool before testing k-nearest neighbors or fuzzy string formula candidate retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data integration query &amp; pool K-nearest neighbors retrieval</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fuzzy string candidates retrieval</head><p>Fig. <ref type="figure" coords="12,141.18,363.17,3.38,8.10">4</ref>. Workflow of the data integration (DI) and formula candidate retrieval via k-nearest neighbors (kNN) and (fuzzy) string similarity matching for Task 2.</p><p>In our integrated formula dictionary, each query formula has the following properties: -order 'ord', e.g., ' In our integrated formula dictionary, each pool formula has the following properties:</p><p>formula ID 'id', e.g., '1', -'post_id', e.g., '9', -'thread_id', e.g. '5', -'type', e.g., 'comment', -MathML string 'formula', e.g., '"&lt;?xml version=""1.0"" encoding=""UTF -8""?&gt;&lt;math xmlns=""http://www.w3.org/1998/Math/MathML"" alttext=""\\pi"" display=""block""&gt; &lt;ci&gt;ùúã&lt;/ci&gt;&lt;/math&gt;"', -identifiers list retrieved from MathML 'identifiers', e.g., ['c'], -operators list retrieved from MathML 'operators', e.g., [‚àÇ], and -LaTeX formula string retrieved from MathML 'LaTeX', e.g., '\\pi'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DI</head><p>‚Ä¢Loa d TSV files for query a nd pool formulae ‚Ä¢Retri eve formula symbols (identifiers, operators) from mathml-tags ('ci ','mi','co','mo'), together with formula LaTeX s tring ‚Ä¢Integrate all formulae with IDs a nd s ave dictionary to a Python Pi ckle file kNN ‚Ä¢Encode formula La TeX s trings via TF-IDF and Doc2Vec</p><p>‚Ä¢Retri eve distances a nd k-nearest formula ca ndidates via kNN algorithm fuzzy ‚Ä¢Ca l culate pairwise fuzzy string partial ratios (matching percentage)</p><p>‚Ä¢Ra nk all percentages for each formula to identify cl osest candidates</p><p>The properties are retrieved from the task dataset tsv files. For the identifiers and operators list, the symbols are retrieved from the MathML string. For the query formulae, the search tags are '&lt;mi&gt;' and '&lt;mo&gt;', and for the pool formulae, '&lt;ci&gt;' and '&lt;co&gt;' for identifiers and operators respectively. The formula LaTeX string is retrieved from the 'alttext' attribute of the '&lt;math&gt;' tag. Finally, the formula dictionary is serialized to a pickle file. It is utilized in the following steps (formula encoding, kNN and fuzzy string similarity retrieval).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">Formula LaTeX String Encoding via TF-IDF and Doc2Vec</head><p>Having retrieved the LaTeX formula from the MathML string, it is encoded by jointly feeding its identifier and operator tokens (utf -8) into the TfidfVectorizer from the Python package Scikit-learn <ref type="bibr" coords="13,232.02,296.59,16.72,8.77" target="#b23">[24]</ref> and the Doc2Vec encoder from Gensim <ref type="bibr" coords="13,419.03,296.59,15.17,8.77" target="#b24">[25]</ref>. For the TfidfVectorizer, an ngram range of (1,1) is used. The Doc2Vec distributed bag of words (PV-DBOW) model is trained for 10 iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">Formula Pool Retrieval via K-Nearest-Neighbors</head><p>The two different formula encodings vector spaces are subsequently fed into a Nearest-Neighbors algorithm from Scikit-learn. In Table <ref type="table" coords="13,325.90,382.91,3.84,8.78" target="#tab_5">3</ref>, some illustrative examples of the top 3 results are displayed. In all cases, the retrieved formulae are structurally similar, sometimes equivalent, sometimes even "visually" identical. Having generated the formula encodings, the kNN method is very fast compared to classical text matching. The vector computations can be carried out faster than text processing. sum^{k}_{m=0}bi-nom{k}{m}=2^{k} (280771) 3: sum_{k=0}^{n}binom{n}{k}k= 2^{n}sum_{k=1}^{n}frac{2^{k-1}}{2^{k}}=‚Ä¶ Formula 1 and 2 are identical and almost equivalent to the query, formula 3 starts the summation index at k=1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.9">Formula Pool Retrieval via Fuzzy String Search</head><p>Apart from the NearestNeighbors prediction using TF-IDF and Doc2Vec encoded La-TeX formula strings, we also tested a fuzzy string matching to retrieve similar formulae. For each 'manually' selected query formula, we calculated the fuzzy partial ratio similarity with all pool formulae and ranked them with descending overlap. The top 10 of the candidates were then submitted. Compared to the kNN approach, the fuzzy string search has the advantage of not requiring an encoding index. Thus new formula instances can easily be added without requiring to retrain the vector encodings of the whole corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Classification of Question and Answer Types</head><p>To assess the relative relevance of the specific question, answer, and formula types, we carried out a human multi-label classification for each set respectively. Our approach was inductive, meaning that we did not specify the cla sses upfront but observed them examining the questions, answers, and formulae as they occurred.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Example Questions and Answers</head><p>To illustrate our classification operation mode, we will first give some examples.</p><p>In question A.1, the user asks to find the value of a parameter contained within a function, given an interval constraint. We classified this question with the label "calculate / compute / find value". Our manually selected answer 25 for A.1 was labeled "numeric value / fraction", and "inequality".</p><p>In question A.50, the user asks whether a series containing a fraction of powers and a trigonometric function converges or diverges. We classified this question with the labels "power / exponential / logarithmic", "trigonometry", and "sequence / summation".</p><p>Our manually selected formula for B.50, ùëÜ ùúÄ ‚â§ -ùëìùëüùëéùëê { ùëôùëúùëî ( ùê∂ ‚Ä≤</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3</head><p>) + ( 1 + ùúà ) ùëôùëúùëî ùúÄ} {ùê∂ ‚Ä≤ ùúÄ { ùúà } }, was labeled "inequality" and "powers / exponentials / logarithms".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Question Types</head><p>We labeled the question types as shown in Table <ref type="table" coords="14,324.40,593.09,3.84,8.78" target="#tab_6">4</ref>. The occurrence statistics of the individual question types is shown in Fig. <ref type="figure" coords="15,431.77,524.04,3.86,8.78" target="#fig_2">5</ref>. Apparently, the major part of the questions involved "sets" of numbers. This is partly ca used by the set symbols for natural numbers ‚Ñï or rational numbers ‚Ñö appearing frequently in definitions that are included in the question. The second-highest ranked label is "function". This is not surprising considering that functions are a heavily used n otion or concept in mathematics. To obtain this label, it was sufficient that a function identifier appears in the question. The third highest ranked label is "solve equationsalgebraic or differential". In many cases, provided enough information, the question can be answered by using a computer a lgebra system (QAS) connected to the question answering engine. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Question Subject Classes</head><p>Classifying the question subject classes, we see that almost all questions are pure mathematics, except A 33 is from the math-stackexchange-category physics. Employing subject class classifications can help to redirect questions and reducing the answer space. Open-domain QA systems can then be modularized into distinct closed domain parts that handle different QA types differently. For example, a geometry question such as "What is the surface area of a sphere?" can be parsed and a nswered differently than an algebraic question such as "How to solve ùë• + 1 = 2?". While the former could be passed to a database containing properties of geometric objects, the latter could be passed to a computer algebra system. On the other hand, physics questions often rely heavily on the semantics of identifier names. As an example, the question "What is the relationship between mass and energy?" should yield formulae such as ùê∏ = ùëö ùëê 2 or ùê∏ = ¬Ω ùëö ùë£ 2 . Without having annotated identifier names contained within the formulae, the question cannot be answered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Answer Types</head><p>We labeled our manually retrieved answer types as shown in Table <ref type="table" coords="16,397.25,563.82,3.84,8.78" target="#tab_7">5</ref>. The occurrence statistics of the individua l answer types is shown in Fig. <ref type="figure" coords="17,420.52,396.44,3.85,8.78">6</ref>. As for the question types, "set" is still the most frequent label. However, "function" is here only ranked fourth. The label "algorithmic transformation" is ranked second. Some of the transformations can be done using computer algebra systems. Apparently, the answer and question categories differ. This means, for example, that given a short question, the potentially longer answer (proof or other) can involve more categories.</p><p>Fig. <ref type="figure" coords="17,162.20,631.90,3.38,8.10">6</ref>. Answer type distribution of the 'manually' retrieved MSE answer candidates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Formula Types</head><p>We labeled the formula types as shown in Table <ref type="table" coords="17,322.15,680.92,3.84,8.78">6</ref>. Discussion of Challenges Table <ref type="table" coords="19,151.68,383.67,4.88,8.78" target="#tab_8">7</ref> shows the results of our submission in the ARQMath lab. For Task 1, the reported nDCG' score for our manual run is outstandingly low. Hence, we tried to investigate the reasons for this low score. We identified one critical issue in our m anual run.</p><p>We have linked the posts from the ARQMath dataset with the real posts in MSE, which makes it easier to crawl for relevant answers manually. However, this approach leads to the problem that some of our reported answers do not exist in the ARQMath dataset. Nonetheless, the nDCG' removes non-judged documents prior to evaluation. Hence, a relatively high number of answers that do not exist in the dataset should not harm our score dramatically. We can report an nDCG' score of 0.504 for our submitted run. This is significantly higher than the reported score by the ARQMath result paper <ref type="bibr" coords="19,435.55,491.76,15.15,8.77" target="#b28">[29]</ref>. We calculated the nDCG' score as formulated in <ref type="bibr" coords="19,305.63,503.77,16.72,8.77" target="#b29">[30]</ref> and <ref type="bibr" coords="19,342.42,503.77,16.72,8.77" target="#b30">[31]</ref> </p><formula xml:id="formula_1" coords="19,262.83,511.20,70.32,27.75">nDCG p ‚Ä≤ = DCG p ‚Ä≤ IDCG p ‚Ä≤ ,</formula><p>where</p><formula xml:id="formula_2" coords="19,242.55,550.22,110.67,72.81">DCG p ‚Ä≤ = ‚àë 2 rel i -1 log 2 ( ùëñ + 1 ) p ùëñ =1 IDCG p ‚Ä≤ = ‚àë 2 rel i -1 log 2 (ùëñ + 1) |REL p | ùëñ=1</formula><p>and rel i is the given relevance score for the element, and REL p is the list of relevant documents ordered by their relevance up to position ùëù. In other words, the nDCG p ‚Ä≤ score is the DCG p ‚Ä≤ score divided by the DCG p ‚Ä≤ score for the ideal order of relevant hits. The nDCG p ‚Ä≤ is calculated for every query in the test set. The overall sco re is therefore calculated as the mean value of nDCG p ‚Ä≤ over all queries.</p><p>We identified two possible issues that could explain the mismatch between our calculated score and the reported one. The nDCG p ‚Ä≤ score is calculated for a fixed number ùëù of retrieved top hits. If ùëù is larger than the number of retrieved documents, it would reduce the score. We assume that most contestants reported a list of relevant hits for each query. Since we performed a manual run, we only reported the actual answer. This means, for our reported answers it only makes sense to set ùëù = 1.</p><p>Moreover, we did not report valid answers for some queries (in case the answer ID did not exist in the dataset, we had no valid answer in total for that particular query). If these queries were considered when calculating the mean nDCG p ‚Ä≤ over all queries, it would also explain a significantly lower score. The nDCG p ‚Ä≤ is designed to not taking unjudged documents into account. Similarly, it makes sense to ignore queries with no returned answers when calculating the overall nDCG p ‚Ä≤ over all queries. Following these rules, we calculated an nDCG p ‚Ä≤ of 0.504 for our manual run. Table <ref type="table" coords="20,393.48,322.12,10.13,8.78" target="#tab_1">10</ref> in the Appendix shows the results for our DCG 1 ‚Ä≤ und IDCG 1 ‚Ä≤ scores for all queries of Task 1, for which we retrieved answers in our manual run and were ranked by the ARQMath reviewers. The final average score for nDCG 1 ‚Ä≤ is 0.504.</p><p>In addition to the problematic score calculation, we found incomprehensible relevanc e scores on multiple occasions. A possible reason for this is the subjectiveness of relevance. While we found the reported answers highly relevant, the annotators provided a relevance score of 0. Table <ref type="table" coords="20,241.80,419.71,4.88,8.78" target="#tab_9">8</ref> summarizes the identified problematic annotations. In five out of nine of these cases, our reported answers were marked as correct by the questioner at MSE (last column in Table <ref type="table" coords="20,304.13,443.71,4.25,8.78" target="#tab_9">8</ref>) but annotated as non-relevant by the ARQMath annotator. This seems to indicate that the relevance scores for ARQMath tasks 1 and 2 are very subjective, even though the reported Kappa coefficient for interannotator agreement was reasonably high with around 0.34. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Linking Text and Formulae</head><p>In the process of manual annotation and answer retrieval, we noticed several cha llenges for IR systems. First, the question and answer features are obviously very heterogeneous data types (text and formulae). It remains to be explored how to combine both in a suitable way. Recent studies <ref type="bibr" coords="21,241.05,279.34,16.72,8.77" target="#b31">[32]</ref> investigated the impact of different encoding combinations on the classification accuracy and cluster purity on the NTCIR-11/12 arXiv dataset <ref type="bibr" coords="21,156.20,303.37,15.17,8.77" target="#b32">[33]</ref>. They called out for a "formula encoding challenge" to exploit the formula information for machine learning tasks. A successful encoding should, e.g., improve the text classification accuracy. The aim is motivated by the observation that there is little correla tion between text and formula similarity, at least using the cosine measure on tf-idf and doc2vec encodings. We need to somehow connect text and math, such that there is a synergy between their semantics. In the case of the mathematical question answering task, this could be achieved by transforming the mathematical formu la elements to textual entities. Consider for example the ARQ Task question A.29. The question asks for a recipe to divide complex numbers by infinity (title: "Dividing Complex Numbers by Infinity"). For this question, we manually retrieved the formula ùëé+ùëèùëñ ‚àû = 0 from the answer that was selected by the questioner on MSE. One way to connect the question to possible answer formulae would be to annotate both textual elements. Table <ref type="table" coords="21,124.65,452.74,4.88,8.78">9</ref> shows how linking to items of the semantic knowledge-base Wikidata 8 <ref type="bibr" coords="21,417.52,452.74,15.13,8.77" target="#b19">[20]</ref>, <ref type="bibr" coords="21,438.50,452.74,16.72,8.77" target="#b20">[21]</ref> can provide a connection via the joint QIDs Q1226939, Q11567, and Q205. A joint semantic vector representation of both the title text and the formula could then be a concatenation of the Wikidata item embeddings, as proposed in <ref type="bibr" coords="21,351.42,488.76,15.17,8.77" target="#b33">[34]</ref>.</p><p>Table <ref type="table" coords="21,149.43,511.80,3.39,8.10">9</ref>. Possible semantic annotations of the question A.29 "Dividing Complex Numbers by Infinity" to link text and formulae using Wikidata 8 QIDs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Question text annotation</head><p>Formula answer annotation "Dividing": "division" (Q1226939) ùëé+ùëèùëñ ‚àû : "division" (Q1226939) "Adding": "addition" (Q32043) ùëé + ùëèùëñ: "addition" (Q32043) N/A ùëé + ùëèùëñ: "complex number" (Q11567) N/A ùëé: "real number" (Q12916) N/A ùëèùëñ: "complex number" (Q9165172) "Infinity": "infinity" (Q205) ‚àû: "infinity" (Q205)</p><p>This example illustrates how linking Formula Concepts <ref type="bibr" coords="21,351.42,635.89,15.13,8.77" target="#b15">[16]</ref>, <ref type="bibr" coords="21,373.89,635.89,16.72,8.77" target="#b16">[17]</ref> can be very beneficial for mathematical question answering (on MSE, arXiv, Wikipedia , etc.). However, this requires the semantic annotation of textual and formula elements, which can be done, e.g., using the "AnnoMathTeX" <ref type="foot" coords="22,281.60,150.01,7.13,6.08" target="#foot_20">26</ref> system <ref type="bibr" coords="22,322.15,150.96,16.72,8.78" target="#b18">[19]</ref> hosted by Wikimedia. In the future, we should be able to automatically link text and formula entities to Wikidata items and Wikipedia articles. It remains a challenging problem for mathematical formula entity linking to exhaustively and unambiguously identify the important semantic parts of a formula. In the future, annotation guidelines should be developed to tackle this problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Formula Search and Retrieval</head><p>For Task 2, we used the MOI search engine to retrieve relevant mathematical expressions from the dataset. Since the MOI engine does not handle entire mathematical expressions by itself but disassemble formulae into their subexpressions, the concept of linking retrieved MOIs back to a formula ID was challenging. Furthermore, the approach we used to calculate the form ula ID of an MOI has some drawbacks. First, the MOI engine retrieves relevant documents from elasticsearch with a textual search query. In the second step, the MOIs are scored based on the retrieved documents. Thus, the retrieved MOIs (and the corresponding formula IDs) are as good as the retrieved documents in the first task. When the retrieved documents are not relevant, none of the retrieved MOIs can be relevant. Hence, the search results are quite sensitive to the settings that were used to retrieve relevant documents. Nonetheless, the approach performed reasonably well compared to the results of other competitors with a n nDCG p ‚Ä≤ score of 0.374.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Outlook and Future Work</head><p>We are excited to employ our approaches and the approaches of other task participants to retrieve relevant formulae on zbMATH datasets. However, as discussed before, we are uncertain if the computed performance numbers are a suitable indicat or to predict the usefulness of the approaches to zbMATH users. We will, therefore, consider suggesting a mathematical literature retrieval task in the future. However, as a prerequisite, we see the need to research math specific deterministic evaluation m etrics that eliminate task-specific human annotators in the loop. In contrast, we believe that obj ective verifiable or almost provable semantic enhancement techniques can significantly benefit from a human review. While relevant (to an information need) is not yet a well-established term among working mathematicians, definitions, equivalences, examples, substitutions, theorems and proves are well established. While formal mathematics is not (yet) able to automatically map mathematical named entities to formal concepts, working mathematicians are generally able to create such a mapping with a very high interreviewer agreement. Therefore, we aim to explore how employing our "AnnoMath-TeX" formula annotation recommender system <ref type="bibr" coords="22,322.15,631.39,16.72,8.77" target="#b18">[19]</ref> on MSE questions and answers can promote answer retrieval.</p><p>To summarize the marginal results from our contribution, the kNN method can be employed as a fast search engine, provided formulae are indexed as vector encodings. The fuzzy string search is slower but has the advantage that no index is needed. As for MOI, the retrieved results are less strictly tied to existing expressions since it considers all subexpressions in an entire dataset. This helps to extract meaningful expressions rather than exact matches.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="8,124.65,317.38,345.77,8.10;8,124.65,327.78,345.42,8.19;8,124.65,339.06,346.13,8.19;8,124.65,350.31,126.15,8.18;8,124.70,147.40,345.90,160.85"><head>Fig. 2 .</head><label>2</label><figDesc>Fig.2. SPARQL query to retrieve our manually inserted data containing topic answer links (Task 1 -Answer) and formula LaTeX strings (Task 2 -Formulas). The query properties are 'mathstackexchange-category' (P10), 'topic-id' (P12), 'post-type' (P9), 'math stackexcange post id' (P5), and 'relevant answers' (P14).</figDesc><graphic coords="8,124.70,147.40,345.90,160.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="9,197.50,179.31,33.89,11.25;9,252.30,171.06,130.22,11.25;9,239.55,192.08,17.45,9.75;9,234.30,199.50,28.77,9.75;9,265.08,190.58,93.62,11.25;9,361.20,186.08,23.99,9.75;9,385.22,190.67,9.26,6.75;9,361.20,195.83,30.74,11.25;9,391.97,201.92,3.38,6.75;9,396.50,191.33,4.82,9.75;9,401.00,180.81,2.00,9.75;9,237.30,209.33,89.53,11.25;9,310.88,219.20,14.60,6.75;9,329.65,209.33,28.30,11.25"><head></head><label></label><figDesc>( ùë°, ùëë ) ‚âî ( ùëò + 1 ) IDF ( ùë° ) ITF ( ùë°, ùëë ) TF ( ùë°, ùëë ) max ùë° ‚Ä≤ ‚ààùëë | ùëê(ùë°) TF ( ùë° ‚Ä≤ , ùëë ) + ùëò (1 -ùëè + ùëèAVG DL | ùëë | AVG c ) , mBM25 ( ùë°, ùê∑ ) ‚âî max ùëë ‚ààùê∑ s ( ùë°, ùëë ) ,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="16,172.73,320.38,250.04,8.10;16,124.70,147.40,345.77,163.00"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Question type distribution of the ARQTask question selection.</figDesc><graphic coords="16,124.70,147.40,345.77,163.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="17,124.80,476.70,345.63,145.20"><head></head><label></label><figDesc></figDesc><graphic coords="17,124.80,476.70,345.63,145.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="19,124.70,147.40,345.85,163.04"><head></head><label></label><figDesc></figDesc><graphic coords="19,124.70,147.40,345.85,163.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="9,124.65,431.47,345.67,135.86"><head>Table 1 .</head><label>1</label><figDesc>The MOI database statistics of ARQMath compared to the existing databases for arXiv and zbMATH. The document length is the number of subexpressions.</figDesc><table coords="9,147.18,459.49,318.53,107.84"><row><cell></cell><cell>arXiv</cell><cell>zbMATH</cell><cell>ARQMath</cell></row><row><cell>Documents</cell><cell>841,008</cell><cell>1,349,297</cell><cell>2,058,866</cell></row><row><cell>Formulae</cell><cell>294,151,288</cell><cell>11,747,860</cell><cell>26,074,621</cell></row><row><cell>Subexpressions</cell><cell>2,508,620,512</cell><cell>61,355,307</cell><cell>143,317,218</cell></row><row><cell>Unique Subexpressions</cell><cell>350,206,974</cell><cell>8,450,496</cell><cell>16,897,129</cell></row><row><cell>Avg. Doc. Length</cell><cell>2,982.87</cell><cell>45.47</cell><cell>69.69</cell></row><row><cell>Avg. Complexity</cell><cell>5.01</cell><cell>4.89</cell><cell>5.00</cell></row><row><cell>Max. Complexity</cell><cell>218</cell><cell>26</cell><cell>188</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,124.65,588.59,345.22,20.79"><head>Table 2</head><label>2</label><figDesc>lists the machine specification for the MOI retrieval and runtime for example query B.1.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,130.65,624.40,307.11,62.72"><head>Table 2 .</head><label>2</label><figDesc>Machine hardware specification and example runtime for query B.1.</figDesc><table coords="9,130.65,640.67,305.69,46.46"><row><cell>Machine</cell><cell>Intel(R) Core(TM) i7-6700HQ CPU @ 2.60GHz -4 Cores / 8 Threads</cell></row><row><cell>RAM</cell><cell>32GB 2133 MHz</cell></row><row><cell>Disk</cell><cell>1TB SSD</cell></row><row><cell cols="2">Required Diskspace 7.8 GB (Posts) + 3 GB (MOIs) = 10.8 GB</cell></row><row><cell>Runtime</cell><cell>6.0 s / query (average over all queries)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="13,130.65,454.75,335.86,210.61"><head>Table 3 .</head><label>3</label><figDesc>Illustrative short examples of top 3 kNN results.</figDesc><table coords="13,130.65,471.02,335.86,194.34"><row><cell>Query (Task 2 ID)</cell><cell cols="2">Results (Task 2 Formula ID)</cell><cell></cell><cell>Comment</cell></row><row><cell>ùëê &lt; 25/64 (B.1)</cell><cell cols="2">1: k &lt; 6.64‚Ä¶ (77098),</cell><cell></cell><cell>Similar but wrong number,</cell></row><row><cell></cell><cell cols="2">2: 1/64 (144990),</cell><cell></cell><cell>No inequation,</cell></row><row><cell></cell><cell cols="2">3: 7/64 (95528)</cell><cell></cell><cell>"</cell></row><row><cell>5^{2}equiv</cell><cell cols="3">1: (a-b)^{n}equiv 0 (text{mod} n)</cell><cell>Structurally similar but contain-</cell></row><row><cell>1({text{mod}}(B.8)</cell><cell cols="2">(54185),</cell><cell></cell><cell>ing variables instead of constants</cell></row><row><cell></cell><cell cols="3">2: a^{p-1}equiv 1 (text{mod} p)</cell><cell></cell></row><row><cell></cell><cell cols="2">(94320),</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">3: 2^{p-1}equiv 1 (text{mod} p)</cell><cell></cell></row><row><cell></cell><cell cols="2">(198801)</cell><cell></cell><cell></cell></row><row><cell>{{frac{a+bi}{infty</cell><cell cols="2">1: a+bi (272260),</cell><cell></cell><cell>The complex number a+bi is de-</cell></row><row><cell>}}=0} (B.29)</cell><cell cols="2">2: z=a+bi (218917)</cell><cell></cell><cell>tected and retrieved, infty missing</cell></row><row><cell></cell><cell cols="2">3: a+bi (272255)</cell><cell></cell><cell></cell></row><row><cell>{p_{1}dots p_{n}+1}</cell><cell cols="2">1: p_{1}dots p_{k}+1 (2203),</cell><cell></cell><cell>Formula 1 equivalent, using index</cell></row><row><cell>(B.52)</cell><cell>2:</cell><cell>p_{1}+p_{2}+dots</cell><cell>p{n}=1</cell><cell>k instead of n, Formula 2 equiva-</cell></row><row><cell></cell><cell cols="2">(76726),</cell><cell></cell><cell>lent, with additional information</cell></row><row><cell></cell><cell cols="3">3: p_{1}=p_{2}=dots=p_{6} (76715)</cell><cell>(=1)</cell></row><row><cell>{sum_{k=0}^{n}k{bi-</cell><cell>1:</cell><cell cols="2">sum^{k}_{m=0}bi-</cell><cell></cell></row><row><cell>nom{n}{k}}=n2^{n-</cell><cell cols="2">nom{k}{m}=2^{k} (280774),</cell><cell></cell><cell></cell></row><row><cell>1}=2^{n-1+log_{2}n}}</cell><cell>2:</cell><cell></cell><cell></cell><cell></cell></row><row><cell>(B.86)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="14,124.65,616.87,345.42,77.93"><head>Table 4 .</head><label>4</label><figDesc>Question type labels for Task 1.</figDesc><table coords="14,124.65,633.17,345.42,61.64"><row><cell cols="2">Label</cell><cell>Questions</cell></row><row><cell>25</cell><cell cols="2">https://math.stackexchange.com/questions/3062860/finding-value-of-c-such-that-the-range-</cell></row><row><cell></cell><cell cols="2">of-the-rational-function-fx-frac/3063081#3063081</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="16,130.65,587.60,264.37,98.77"><head>Table 5 .</head><label>5</label><figDesc>Answer type labels for Task 1.</figDesc><table coords="16,130.65,603.89,264.37,82.49"><row><cell>Label</cell><cell>Answers for Questions</cell></row><row><cell>Value / fraction</cell><cell>A 1</cell></row><row><cell>Probability</cell><cell>A 5, 85</cell></row><row><cell>Binomial</cell><cell>A 7, 41, 49, 51, 69, 86</cell></row><row><cell>Pow / exp / log</cell><cell>A 7, 16, 18, 35, 39, 41, 43, 44, 47, 48, 51, 65, 73, 75, 85, 98</cell></row><row><cell>Interval</cell><cell>A 3, 10, 46, 74, 82, 91</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="20,130.65,515.55,312.18,38.28"><head>Table 7 .</head><label>7</label><figDesc>Results of the zbMATH participation submission at the ARQMath Lab.</figDesc><table coords="20,130.65,533.04,301.45,20.79"><row><cell>RUN</cell><cell>DATA</cell><cell>nDCG'</cell><cell>MAP'</cell><cell>P@10</cell></row><row><cell>zbMATH</cell><cell>Text &amp; Math</cell><cell>0.101</cell><cell>0.053</cell><cell>0.030</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="20,124.65,580.85,345.68,105.79"><head>Table 8 .</head><label>8</label><figDesc>Topic and Post IDs that are marked as non-relevant by the ARQMath task reviewers<ref type="bibr" coords="20,124.65,591.59,16.72,8.77" target="#b28">[29]</ref> but annotated as correct / helpful by the questioner in the Math Stack Exchange forum.</figDesc><table coords="20,130.65,609.15,330.71,77.50"><row><cell>Topic ID</cell><cell>Post ID</cell><cell>Relevance</cell><cell>MSE Marked as Correct</cell></row><row><cell>A.17</cell><cell>5322</cell><cell>0</cell><cell>Yes</cell></row><row><cell>A.21</cell><cell>65456</cell><cell>0</cell><cell>Yes</cell></row><row><cell>A.35</cell><cell>170589</cell><cell>0</cell><cell>No</cell></row><row><cell>A.42</cell><cell>331468</cell><cell>0</cell><cell>No</cell></row><row><cell>A.50</cell><cell>110019</cell><cell>0</cell><cell>No</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,129.90,664.93,155.48,8.10"><p>https://archive.org/download/stackexchange</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,129.90,675.42,112.01,8.10"><p>https://math.stackexchange.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,129.90,686.70,86.50,8.10"><p>https://mathoverflow.net</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="3,129.90,686.70,63.75,8.10"><p>https://archive.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="4,129.90,620.63,74.21,8.10"><p>https://www.nltk.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="4,129.90,631.90,92.99,8.10"><p>http://mathqa.wmflabs.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="4,129.90,642.40,68.00,8.10"><p>https://askplatyp.us</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7" coords="4,129.90,653.68,90.71,8.10"><p>https://www.wikidata.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8" coords="4,129.90,664.93,86.60,8.10"><p>https://mathoverflow.net</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_9" coords="4,132.93,675.42,56.24,8.10"><p>https://arxiv.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_10" coords="4,132.93,686.70,66.74,8.10"><p>http://msc2010.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12" xml:id="foot_11" coords="5,132.93,609.38,124.44,8.10"><p>https://www.w3.org/TR/MathML3</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13" xml:id="foot_12" coords="5,132.93,620.63,87.98,8.10"><p>https://www.google.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_13" coords="5,132.93,631.90,85.00,8.10"><p>https://duckduckgo.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15" xml:id="foot_14" coords="5,132.93,642.40,134.34,8.10"><p>https://www.cs.rit.edu/~dprl/mathseer</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16" xml:id="foot_15" coords="5,132.93,653.68,86.28,8.10"><p>http://ntcir-math.nii.ac.jp</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="17" xml:id="foot_16" coords="5,132.93,664.93,90.71,8.10"><p>https://www.wikidata.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="18" xml:id="foot_17" coords="5,132.93,675.42,95.22,8.10"><p>https://www.openmath.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="19" xml:id="foot_18" coords="5,132.93,686.70,137.50,8.10"><p>https://arq20.formulasearchengine.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="24" xml:id="foot_19" coords="8,132.93,686.70,78.72,8.10"><p>https://www.elastic.co</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="26" xml:id="foot_20" coords="22,132.93,686.70,92.24,8.10"><p>annomathtex.wmflabs.org</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was supported by the <rs type="funder">German Research Foundation</rs> (<rs type="funder">DFG</rs> grant <rs type="grantNumber">GI -1259-1</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_g8ah8Mq">
					<idno type="grant-number">GI -1259-1</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The occurrence statistics of the individual formula types is shown in Fig. <ref type="figure" coords="18,421.28,529.29,3.84,8.78">7</ref>. Algebraic transformations and functions are still ranked high. All in all, the most frequent question, answer, and formula types involve sets, sequences, sums, powers, exponentials, logarithms, trigonometry functions, inequalities, and algebraic transformations, or equation solving. In the future, one could explore whether the question classification label is enha ncing answer retrieval.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="23,144.17,325.01,327.42,8.87;23,144.17,337.14,115.56,8.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="23,253.78,325.01,141.00,8.86">Full text formula search in zbMATH</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>M√ºller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Teschke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="23,409.25,325.11,62.34,8.77;23,144.17,337.14,22.68,8.78">Eur. Math. Soc. Newsl</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<biblScope unit="page">51</biblScope>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,144.17,349.04,326.67,8.87;23,144.17,361.07,326.02,8.87;23,144.17,373.17,326.20,8.77;23,144.17,385.16,326.80,8.77;23,144.17,397.19,54.24,8.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="23,353.86,349.04,116.98,8.87;23,144.17,361.07,205.54,8.86">Finding Old Answers to New Math Questions: The ARQMath Lab at CLEF 2020</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mansouri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zanibbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="23,371.70,361.17,98.49,8.77;23,144.17,373.17,36.00,8.78">Advances in Information Retrieval</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Jose</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Yilmaz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Magalh√£es</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Castells</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Silva</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Martins</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer International Publishin g</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">12036</biblScope>
			<biblScope unit="page" from="564" to="571" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,144.17,409.09,326.81,8.86;23,144.17,421.11,326.74,8.87;23,144.17,433.21,31.74,8.77;23,191.49,433.21,111.10,8.77;23,318.17,433.21,153.02,8.77;23,144.17,445.21,113.95,8.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="23,325.95,409.09,145.03,8.86;23,144.17,421.11,69.51,8.86">Characterizing Searches for Mathematical Concepts</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mansouri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zanibbi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<idno type="DOI">10.1109/JCDL.2019.00019</idno>
	</analytic>
	<monogr>
		<title level="m" coord="23,238.05,421.21,232.86,8.77;23,144.17,433.21,27.20,8.77">2019 ACM/IEEE Joint Conference on Digital Libraries (JCDL)</title>
		<meeting><address><addrLine>Champaign, IL, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-06">Jun. 2019</date>
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,144.17,457.14,326.18,8.86;23,144.17,469.14,326.85,8.87;23,144.17,481.27,326.85,8.77;23,144.17,493.26,308.35,8.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="23,264.26,457.14,206.08,8.86;23,144.17,469.14,286.28,8.86">Insights for Curriculum Development: Identifying Emerging Data Science Topics through Analysis of Q&amp;A Communities</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Karbasian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Johri</surname></persName>
		</author>
		<idno type="DOI">10.1145/3328778.3366817</idno>
	</analytic>
	<monogr>
		<title level="m" coord="23,452.80,469.24,18.22,8.77;23,144.17,481.27,322.47,8.77">Proceedings of the 51st ACM Technical Symposium on Computer Science Education</title>
		<meeting>the 51st ACM Technical Symposium on Computer Science Education<address><addrLine>Portland OR USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-02">Feb. 2020</date>
			<biblScope unit="page" from="192" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,144.17,505.16,327.06,8.86;23,144.17,517.29,23.38,8.77;23,189.13,517.29,40.18,8.77;23,252.10,517.29,16.66,8.77;23,290.34,517.29,12.91,8.77;23,325.58,517.29,23.38,8.77;23,371.29,517.29,34.66,8.77;23,429.03,517.29,41.65,8.77;23,144.17,529.29,139.45,8.77" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="23,204.64,505.16,238.30,8.86">A Question-Answering System for Elementary Mathematics</title>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">W</forename><surname>Smith</surname></persName>
		</author>
		<ptr target="https://eric.ed.gov/?id=ED093703" />
		<imprint>
			<date type="published" when="1974-04">Apr. 1974. Jun. 22, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,144.17,541.22,326.00,8.87;23,144.17,553.21,327.10,8.87;23,144.17,565.23,327.43,8.88;23,144.17,577.34,210.56,8.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="23,317.71,541.22,152.47,8.87;23,144.17,553.21,107.18,8.86">A math-aware search engine for math question answering system</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">T</forename><surname>Nguyen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">C</forename><surname>Hui</surname></persName>
		</author>
		<idno type="DOI">10.1145/2396761.2396854</idno>
	</analytic>
	<monogr>
		<title level="m" coord="23,274.85,553.31,196.42,8.77;23,144.17,565.23,262.01,8.88">Proceedings of the 21st ACM international conference on Information and knowledge management -CIKM &apos;12</title>
		<meeting>the 21st ACM international conference on Information and knowledge management -CIKM &apos;12<address><addrLine>Maui, Hawaii, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page">724</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,144.17,589.24,326.26,8.87;23,144.17,601.27,327.23,8.87;23,144.17,613.37,239.08,8.77" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="23,221.84,589.24,248.59,8.87;23,144.17,601.27,12.94,8.86">A Survey of Question Answering for Math and Science Problem</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bhattacharya</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1705.04530" />
		<imprint>
			<date type="published" when="2017-05">May 2017. Jun. 08, 2020</date>
			<publisher>CoRR)</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Computing Research Repository</note>
</biblStruct>

<biblStruct coords="23,144.17,625.29,326.78,8.87;23,144.17,637.39,325.51,8.77;23,144.17,649.29,326.89,8.87;23,144.17,661.41,119.21,8.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="23,369.62,625.29,101.33,8.87;23,144.17,637.39,325.51,8.77;23,144.17,649.29,22.87,8.86">Indonesian Question Answering System for Solving Arithmetic Word Problems on Intelligent Humanoid Robot</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">A S</forename><surname>Gunawan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">R</forename><surname>Mulyono</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Budiharto</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.procs.2018.08.213</idno>
	</analytic>
	<monogr>
		<title level="j" coord="23,182.47,649.39,121.32,8.77">Procedia Computer Science</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="page" from="719" to="726" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,144.17,673.32,327.55,8.87;23,144.17,685.34,326.19,8.87;24,144.17,150.96,326.83,8.78;24,144.17,162.99,118.07,8.78" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="23,448.39,673.32,23.33,8.86;23,144.17,685.34,265.94,8.87">Introducing MathQA --A Math-Aware Question Answering System</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schubotz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Scharpf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Dudhat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Nagar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hamborg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Gip</surname></persName>
		</author>
		<idno type="DOI">10.1108/IDD-06-2018-0022</idno>
	</analytic>
	<monogr>
		<title level="j" coord="23,423.53,685.44,46.83,8.78;24,144.17,150.96,102.69,8.78">Information Discovery and Delivery</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="214" to="224" />
			<date type="published" when="2018-11">Nov. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,144.17,174.99,327.57,8.78;24,144.17,186.91,326.85,8.87;24,144.17,199.01,327.56,8.78;24,144.17,211.01,286.98,8.78" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="24,230.17,186.91,199.66,8.86">SemEval-2019 Task 10: Math Question Answering</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hopkins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">Le</forename><surname>Bras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Petrescu-Prahova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Stanovsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hajishirzi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Koncel-Kedziorski</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/S19-2153</idno>
	</analytic>
	<monogr>
		<title level="m" coord="24,452.80,187.01,18.22,8.78;24,144.17,199.01,283.35,8.78">Proceedings of the 13th International Workshop on Semantic Evaluation</title>
		<meeting>the 13th International Workshop on Semantic Evaluation<address><addrLine>Minneapolis, Minnesota, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="893" to="899" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,144.17,222.94,326.02,8.87;24,144.17,235.04,326.43,8.78;24,144.17,247.06,214.38,8.78" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="24,203.97,222.94,257.26,8.87">Math-Aware Search Engines: Physics Applications and Overview</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">C</forename><surname>Pineau</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1609.03457" />
		<imprint>
			<date type="published" when="2016-09">Sep. 2016. Jun. 21, 2020</date>
			<publisher>CoRR</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Computing Research Repository</note>
</biblStruct>

<biblStruct coords="24,144.17,258.96,327.03,8.87;24,144.17,270.96,326.78,8.87;24,144.17,283.09,162.40,8.77" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="24,285.20,258.96,186.00,8.87;24,144.17,270.96,121.38,8.86">QAPD: an ontology-based question answering system in the physics domain</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Abdi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Idris</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Ahmad</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00500-016-2328-2</idno>
	</analytic>
	<monogr>
		<title level="j" coord="24,277.85,271.06,49.27,8.77">Soft Comput</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="213" to="230" />
			<date type="published" when="2018-01">Jan. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,144.17,294.99,325.30,8.86;24,144.17,307.02,327.43,8.87;24,144.17,319.12,327.00,8.77;24,144.17,331.14,123.69,8.77" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="24,241.80,294.99,227.67,8.86;24,144.17,307.02,105.30,8.86">Mathematical Document Categorization with Structure of Mathematical Expressions</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Fujii</surname></persName>
		</author>
		<idno type="DOI">10.1109/JCDL.2017.7991566</idno>
	</analytic>
	<monogr>
		<title level="m" coord="24,271.07,307.12,200.53,8.77;24,144.17,319.12,66.22,8.77">2017 ACM/IEEE Joint Conference on Digital Libraries (JCDL)</title>
		<meeting><address><addrLine>Toronto, ON, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-06">Jun. 2017</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,144.17,343.14,326.02,8.77;24,144.17,355.04,327.51,8.87;24,144.17,367.06,327.27,8.87;24,144.17,379.17,239.08,8.77" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="24,149.55,355.04,322.13,8.87;24,144.17,367.06,14.88,8.86">AutoMSC: Automatic Assignment of Mathematics Subject Classification Labels</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schubotz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Scharpf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Teschke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">K</forename><surname>Uhnemund</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Breitinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Gipp</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/2005.12099" />
	</analytic>
	<monogr>
		<title level="m" coord="24,169.70,367.16,174.13,8.77">Proceedings of the CICM Conference 2020</title>
		<meeting>the CICM Conference 2020</meeting>
		<imprint>
			<date type="published" when="2020-05">May 2020. Jun. 21, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,144.17,391.09,326.06,8.86;24,144.17,403.09,320.99,8.87" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="24,229.77,391.09,240.46,8.86;24,144.17,403.09,13.39,8.86">Mathematical Formula Search using Natural Language Queries</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ko</surname></persName>
		</author>
		<idno type="DOI">10.4316/AECE.2014.04015</idno>
	</analytic>
	<monogr>
		<title level="j" coord="24,168.20,403.19,21.79,8.78">AECE</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="99" to="104" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,144.17,415.09,326.12,8.86;24,144.17,427.11,327.59,8.87;24,144.17,439.21,27.88,8.77" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="24,195.79,415.09,274.50,8.86;24,144.17,427.11,89.21,8.86">Representing Mathematical Concepts Associated With Formulas Using Math Entity Cards</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dmello</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">167</biblScope>
		</imprint>
		<respStmt>
			<orgName>Rochester Institute of Technology (RIT) Scholar Works</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="24,144.17,451.14,325.93,8.87;24,144.17,463.14,325.89,8.87;24,144.17,475.24,165.34,8.77" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="24,362.26,451.14,107.84,8.86;24,144.17,463.14,109.66,8.86">Towards Formula Concept Discovery and Recognition</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Scharpf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schubotz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">S</forename><surname>Cohl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Gipp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="24,266.57,463.24,203.49,8.77;24,144.17,475.24,120.37,8.77">Proceedings of the 4th BIRNDL Workshop at the 42nd ACM SIGIR Conference</title>
		<meeting>the 4th BIRNDL Workshop at the 42nd ACM SIGIR Conference</meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,144.17,487.26,325.34,8.77;24,144.17,499.17,327.55,8.87;24,144.17,511.29,163.10,8.78" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="24,149.00,499.17,273.90,8.86">System Description: KAT an Annotation Tool for STEM Documents</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Dumitru</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ginev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kohlhase</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Merticariu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mirea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wiesing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="24,434.78,499.27,36.94,8.77;24,144.17,511.29,118.89,8.78">Proceedings of the CICM Conference</title>
		<meeting>the CICM Conference</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,144.17,523.29,326.02,8.77;24,144.17,535.21,325.66,8.87;24,144.17,547.21,326.89,8.87;24,144.17,559.32,20.47,8.77;24,180.97,559.32,138.78,8.77;24,335.33,559.32,51.12,8.77;24,402.03,559.32,69.16,8.77;24,144.17,571.34,112.46,8.77" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="24,149.47,535.21,320.36,8.87;24,144.17,547.31,42.24,8.78">AnnoMathTeX -a formula identifier annotation recommender system for STEM documents</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Scharpf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Mackerracher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schubotz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Beel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Breitinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Gipp</surname></persName>
		</author>
		<idno type="DOI">10.1145/3298689.3347042</idno>
	</analytic>
	<monogr>
		<title level="m" coord="24,208.00,547.31,263.06,8.77;24,144.17,559.32,16.37,8.78">Proceedings of the 13th ACM Conference on Recommender Systems</title>
		<meeting>the 13th ACM Conference on Recommender Systems<address><addrLine>Copenhagen Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019-09">Sep. 2019</date>
			<biblScope unit="page" from="532" to="533" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,144.17,583.24,325.44,8.86;24,144.17,595.37,326.60,8.77;24,144.17,607.36,181.86,8.77" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="24,308.10,583.24,161.51,8.86;24,144.17,595.37,132.87,8.77">Representing Mathematical Formulae in Content MathML using Wikidata</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Scharpf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schubotz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Gipp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="24,288.35,595.37,182.42,8.77;24,144.17,607.36,131.62,8.77">Proceedings of the 3th BIRNDL Workshop at the 41st ACM SIGIR Conference</title>
		<meeting>the 3th BIRNDL Workshop at the 41st ACM SIGIR Conference</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">14</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,144.17,619.27,326.85,8.87;24,144.17,631.39,181.87,8.77" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="24,205.54,619.27,235.97,8.86">Generating OpenMath Content Dictionaries from Wikidata</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schubotz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="24,452.80,619.37,18.22,8.77;24,144.17,631.39,136.86,8.77">Proceedings of the CICM Conference</title>
		<meeting>the CICM Conference</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,144.17,643.39,326.45,8.77;24,144.17,655.32,326.07,8.86;24,144.17,667.32,326.53,8.87;25,144.17,150.96,327.46,8.78;25,144.17,162.99,170.17,8.78" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="24,148.93,655.32,321.31,8.86;24,144.17,667.32,140.06,8.86">Improving the Representation and Conversion of Mathematical Formulae by Considering their Textual Context</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schubotz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Greiner-Petter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Scha Rpf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Meuschke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">S</forename><surname>Cohl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Gipp</surname></persName>
		</author>
		<idno type="DOI">10.1145/3197026.3197058</idno>
	</analytic>
	<monogr>
		<title level="m" coord="24,307.88,667.42,162.82,8.77;25,144.17,150.96,155.36,8.78">Proceedings of the 18th ACM/IEEE on Joint Conference on Digital Libraries</title>
		<meeting>the 18th ACM/IEEE on Joint Conference on Digital Libraries<address><addrLine>Fort Worth Texas USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-05">May 2018</date>
			<biblScope unit="page" from="233" to="242" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,144.17,174.89,325.96,8.86;25,144.17,186.91,229.16,8.87" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="25,250.77,174.89,219.36,8.86;25,144.17,186.91,22.36,8.86">Distributed Representations of Sentences and Documents</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="25,177.23,187.01,151.10,8.78">Proceedings of the ICML Conference</title>
		<meeting>the ICML Conference</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,144.17,198.91,326.59,8.87;25,144.17,211.01,124.04,8.78" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="25,237.30,198.91,175.89,8.86">Scikit-learn: Machine Learning in Python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="25,427.27,199.01,43.49,8.78;25,144.17,211.01,96.69,8.78">MACHINE LEARNING IN PYTHON</title>
		<imprint>
			<biblScope unit="page">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,144.17,222.94,326.59,8.87;25,144.17,235.04,147.08,8.78" xml:id="b24">
	<monogr>
		<title level="m" type="main" coord="25,252.30,223.04,218.46,8.78;25,144.17,235.04,33.03,8.78">Software Framework for Topic Modelling with Large Corpora</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>≈òeh≈Ø≈ôek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sojka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
		<respStmt>
			<orgName>University of Malta</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="25,144.17,246.96,326.24,8.87;25,144.17,258.96,327.80,8.87;25,144.17,271.06,276.03,8.77" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="25,245.39,246.96,225.02,8.87;25,144.17,259.06,107.02,8.77">Discovering Mathematical Objects of Interest-A Study of Mathematical Notations</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Greiner-Petter</surname></persName>
		</author>
		<idno type="DOI">10.1145/3366423.3380218</idno>
	</analytic>
	<monogr>
		<title level="m" coord="25,271.07,259.06,168.89,8.77">Proceedings of The Web Conference 2020</title>
		<meeting>The Web Conference 2020<address><addrLine>Taipei Taiwan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020-04">Apr. 2020</date>
			<biblScope unit="page" from="1445" to="1456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,144.17,282.99,325.45,8.86;25,144.17,294.99,326.26,8.87;25,144.17,307.12,326.80,8.77;25,144.17,319.12,161.39,8.77" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="25,259.74,282.99,209.89,8.86;25,144.17,294.99,99.75,8.86">Mathoid: Robust, Scalable, Fast and Accessible Math Rendering for Wikipedia</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schubotz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Wicke</surname></persName>
		</author>
		<idno>doi: 10/ggv8pz</idno>
	</analytic>
	<monogr>
		<title level="m" coord="25,268.08,295.09,202.35,8.77;25,144.17,307.12,96.60,8.77">Intelligent Computer Mathematics -International Conference, CICM 2014</title>
		<meeting><address><addrLine>Coimbra, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014">July 7-11, 2014. 2014</date>
			<biblScope unit="volume">8543</biblScope>
			<biblScope unit="page" from="224" to="235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,144.17,331.04,325.44,8.86;25,144.17,343.04,326.88,8.87;25,144.17,355.14,89.99,8.77" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="25,277.99,331.04,191.62,8.86;25,144.17,343.04,46.28,8.86">The Probabilistic Relevance Framework: BM25 and Beyond</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
		<idno type="DOI">10.1561/1500000019</idno>
	</analytic>
	<monogr>
		<title level="j" coord="25,202.00,343.14,94.87,8.77">Found. Trends Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="333" to="389" />
			<date type="published" when="2009-04">Apr. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,144.17,367.06,326.22,8.86;25,144.17,379.07,278.00,8.86" xml:id="b28">
	<monogr>
		<title level="m" type="main" coord="25,375.17,367.06,95.23,8.86;25,144.17,379.07,244.01,8.86">Overview of ARQMath 2020: CLEF Lab on Answer Retrieval for Questions on Math</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zanibbi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Mansouri</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,144.17,391.09,327.27,8.87;25,144.17,403.09,326.86,8.87;25,144.17,415.19,101.98,8.77" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="25,281.74,391.09,189.70,8.87;25,144.17,403.09,24.59,8.86">Cumulated gain-based evaluation of IR techniques</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>J√§rvelin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kek√§l√§inen</surname></persName>
		</author>
		<idno type="DOI">10.1145/582415.582418</idno>
	</analytic>
	<monogr>
		<title level="j" coord="25,181.73,403.19,91.99,8.77">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="422" to="446" />
			<date type="published" when="2002-10">Oct. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,144.17,427.11,326.31,8.87;25,144.17,439.21,326.55,8.77;25,144.17,451.24,175.46,8.77" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="25,217.03,427.11,157.79,8.86">Learning to rank using gradient descent</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Burges</surname></persName>
		</author>
		<idno type="DOI">10.1145/1102351.1102363</idno>
	</analytic>
	<monogr>
		<title level="m" coord="25,395.75,427.21,74.73,8.77;25,144.17,439.21,208.48,8.77">Proceedings of the 22nd international conference on Machine learning</title>
		<meeting>the 22nd international conference on Machine learning<address><addrLine>Bonn, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-08">Aug. 2005</date>
			<biblScope unit="page" from="89" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,144.17,463.24,326.01,8.77;25,144.17,475.14,326.84,8.86;25,144.17,487.16,326.28,8.87;25,144.17,499.27,275.99,8.77" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="25,148.14,475.14,322.87,8.86;25,144.17,487.16,236.11,8.87">Classification and Clustering of arXiv Documents, Sections, and Abstracts, Comparing Encodings of Natural and Mathematical Language</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Scharpf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schubotz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Youssef</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Hamborg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Meuschke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Gipp</surname></persName>
		</author>
		<idno type="DOI">10.1145/3383583.3398529</idno>
	</analytic>
	<monogr>
		<title level="m" coord="25,393.48,487.26,76.97,8.77;25,144.17,499.27,93.83,8.77">Proceedings of the JCDL Conference 2020</title>
		<meeting>the JCDL Conference 2020</meeting>
		<imprint>
			<date type="published" when="2020-05">May 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,144.17,511.19,326.20,8.86;25,144.17,523.29,327.07,8.77;25,144.17,535.31,103.76,8.77" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="25,322.51,511.19,138.89,8.86">NTCIR-12 MathIR Task Overview</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zanibbi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Aizawa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kohlhase</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="25,144.17,523.29,327.07,8.77;25,144.17,535.31,54.69,8.78">Proceedings of the 12th NTCIR Conference on Evaluation of Information Access Technologies</title>
		<meeting>the 12th NTCIR Conference on Evaluation of Information Access Technologies</meeting>
		<imprint>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,144.17,547.21,326.87,8.87;25,144.17,559.32,326.49,8.77;25,144.17,571.34,214.80,8.77" xml:id="b33">
	<analytic>
		<title level="a" type="main" coord="25,213.40,547.21,248.51,8.87">PyTorch-BigGraph: A Large-scale Graph Embedding System</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lerer</surname></persName>
		</author>
		<ptr target="http://arxiv.org/abs/1903.12287" />
	</analytic>
	<monogr>
		<title level="m" coord="25,144.17,559.32,176.38,8.77">Proceedings of the MLSys Conference 2019</title>
		<meeting>the MLSys Conference 2019</meeting>
		<imprint>
			<date type="published" when="2019-04">Apr. 2019. Jul. 16, 2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
