<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,208.56,116.95,198.25,12.62;1,151.06,134.89,313.24,12.62;1,192.01,152.82,231.34,12.62">Inter-Sentence Features and Thresholded Minimum Error Rate Training: NAIST at CLEF 2013 QA4MRE</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,204.99,190.72,57.51,8.74"><forename type="first">Philip</forename><surname>Arthur</surname></persName>
							<email>philip-a@is.naist.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">Nara Institute of Science and Technology</orgName>
								<address>
									<addrLine>8916-5, Takayama-cho, Ikoma-shi</addrLine>
									<postCode>630-0192</postCode>
									<settlement>Nara</settlement>
									<country key="JP">JAPAN</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,270.50,190.72,67.54,8.74"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
							<email>neubig@is.naist.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">Nara Institute of Science and Technology</orgName>
								<address>
									<addrLine>8916-5, Takayama-cho, Ikoma-shi</addrLine>
									<postCode>630-0192</postCode>
									<settlement>Nara</settlement>
									<country key="JP">JAPAN</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,346.14,190.72,60.03,8.74"><forename type="first">Sakriani</forename><surname>Sakti</surname></persName>
							<email>ssakti@is.naist.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">Nara Institute of Science and Technology</orgName>
								<address>
									<addrLine>8916-5, Takayama-cho, Ikoma-shi</addrLine>
									<postCode>630-0192</postCode>
									<settlement>Nara</settlement>
									<country key="JP">JAPAN</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,226.14,202.68,55.90,8.74"><forename type="first">Tomoki</forename><surname>Toda</surname></persName>
							<email>tomoki@is.naist.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">Nara Institute of Science and Technology</orgName>
								<address>
									<addrLine>8916-5, Takayama-cho, Ikoma-shi</addrLine>
									<postCode>630-0192</postCode>
									<settlement>Nara</settlement>
									<country key="JP">JAPAN</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,309.71,202.68,79.51,8.74"><forename type="first">Satoshi</forename><surname>Nakamura</surname></persName>
							<email>s-nakamura@is.naist.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">Nara Institute of Science and Technology</orgName>
								<address>
									<addrLine>8916-5, Takayama-cho, Ikoma-shi</addrLine>
									<postCode>630-0192</postCode>
									<settlement>Nara</settlement>
									<country key="JP">JAPAN</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,208.56,116.95,198.25,12.62;1,151.06,134.89,313.24,12.62;1,192.01,152.82,231.34,12.62">Inter-Sentence Features and Thresholded Minimum Error Rate Training: NAIST at CLEF 2013 QA4MRE</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3903755E815A13972130092478D1A411</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>discriminative learning</term>
					<term>minimum error rate training</term>
					<term>linear feature model</term>
					<term>question answering</term>
					<term>machine reading</term>
					<term>inter-sentence features</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the Nara Institute of Science and Technology's system for the main task of CLEF 2013 QA4MRE. The core of the system is a log linear scoring model that couples both intra and intersentence features. Each of the features receives an input of a candidate answer, question, and document, and uses these to assign a score according to some criterion. We use minimum error rate training (MERT) to train the weights of the model and also propose a novel method for MERT with the addition of a threshold that defines the certainty with which we must answer questions. The system received a score of 28% c@1 on main questions and 33% c@1 when considering auxiliary questions on the CLEF 2013 evaluation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>While years of research on Question Answering (QA) have greatly improved the state-of-the-art, we know that this problem is far from solved. Question answering campaigns such as CLEF <ref type="bibr" coords="1,296.67,525.61,10.52,8.74" target="#b8">[9]</ref> and TREC <ref type="bibr" coords="1,362.97,525.61,10.52,8.74" target="#b2">[3]</ref> have resulted in a large number of distinct proposals about how to build robust systems that can provide correct answers in the general domain. One of the features of QA that is widely accepted is that "two heads are better than one" <ref type="bibr" coords="1,361.26,561.47,9.96,8.74" target="#b1">[2]</ref>. By combining different information sources, we gain the ability to cover up the disadvantages of one system with another information source, which results in more effective QA on the whole. One way to combine multiple systems is to weight each system's score with some value and choose the maximum value from a linear combination <ref type="bibr" coords="1,462.32,609.29,14.61,8.74" target="#b11">[12]</ref>. Another important aspect of QA is that it is sometimes good not to answer the question <ref type="bibr" coords="1,174.95,633.20,9.96,8.74" target="#b7">[8]</ref>. Many systems currently return No Answer (NoA) if they are not confident because a wrong answer is often worse than no answer <ref type="bibr" coords="1,414.50,645.16,9.96,8.74" target="#b0">[1]</ref>. Our system for the CLEF QA4MRE this year is based on these two principles, devising a number of features that provide useful information to identify the correct answer, and combining them together with a learning framework that is also able to learn when not to answer questions.</p><p>We introduce several new features that span multiple sentences in addition to more traditional features such as cosine similarity. These features are combined in a framework that learns both how and when to answer questions in a single weighted linear model. In particular, we find how to answer questions by learning appropriate weigths for each feature, with final score of an answer being their weighted linear combination. We define when not to answer by not returning candidates for which scores are less than a set threshold t from other candidates. Finally, we propose a method to intelligently weight the features and threshold using minimum error rate training.</p><p>As results for the 2013 evaluation, our best run in main task scored 28% for only main questions and 33% when auxiliary questions are also included. Our QA system has a modular pipeline architecture, making it easy to modify some modules without changing other parts of the system. The system is divided into three major modules: preprocessing, scoring, and answer selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Description</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Architecture</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Preprocessing</head><p>As the raw input is full of noise that can drastically reduce the ability to generate appropriate hypotheses, preprocessing is necessary to process the text into machine-readable format. First, the tokenization step splits the sentence into a list of tokens. Second, the named entity recognition step uses the Stanford named entity annotator<ref type="foot" coords="3,205.61,142.33,3.97,6.12" target="#foot_0">1</ref> to recognize the existence of named entities. We use the Stanford 4 tag set, which consists of PERSON, LOCATION, ORGANIZATION, and MISC. Third, the anaphora resolution module is based on the "last introduced named entity" constraint <ref type="bibr" coords="3,249.72,179.77,9.96,8.74" target="#b4">[5]</ref>. Next, the lowercasing step alters all tokens into lowercase form and the stop word deletion step deletes all words that appear in a stop word list. <ref type="foot" coords="3,220.23,202.10,3.97,6.12" target="#foot_1">2</ref> Finally, stemming uses the Porter stemmer to reduce all conjugated forms of some words into their stem.</p><p>In addition, we made a few refinements to choose which named entity best replaces the Referring Expression (RE). This module focuses on RE that represent humans according to the following rules:</p><p>-"They" and "we" are replaced by the most recent ORGANIZATION named entity. -"I" is replaced by the first PERSON entity that occurs in the passage, which is generally the speaker. -"You" is replaced "theaudience." -"He" and "she" are replaced by the most recent PERSON named entity.</p><p>-"It" may refer to either LOCATION, ORGANIZATION, or MISC.</p><p>-The remaining pronouns are simply left unaltered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Scoring</head><p>The scoring criterion is based on linear combination of several weighted features, <ref type="bibr" coords="3,134.77,423.42,15.50,8.74" target="#b11">[12]</ref> s(a j,k | q j , D) = n i=1 w i * φ i (a j,k , q j , D),</p><p>where s is a function specifying the score of candidate a j,k given question q j and document D. φ i (a j,k , q j , D) is a feature function, w i is its corresponding weight, and D is a sequence of sentences. We describe the features in more detail in section 3.2, and the weight training algorithm in section 4</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Answer Selection</head><p>The answer selection module chooses which, if any, question to answer. Let a j,k be a candidate answer for a given q j and D, and let s k be the score from evaluation s(a j,k | q, D). If a j,k1 is the answer with the highest score among all candidates for q j , we define the certainty of the answer to be</p><formula xml:id="formula_1" coords="3,208.40,619.35,272.19,14.66">c j,k1 = min k2 =k1 (s(a j,k1 | q j , D) -s(a j,k2 | q j , D))<label>(2)</label></formula><p>If our certainty exceeds a threshold t, we provide the answer a j,k1 and if it does not, the system returns no answer.</p><p>As the main test data for this year evaluation contains a "none of the above" candidate answer for every question, we choose to answer 20% of the questions with this answer. This heuristic strategy is applied because our system is currently incapable to provide an analysis toward this type of negation and we do not have any gold-standard training data from previous years on which to perform training. Intuitively, we choose 20% questions with lowest score from Equation ( <ref type="formula" coords="4,182.04,215.71,4.24,8.74" target="#formula_0">1</ref>) to be assigned with the candidate answer "none of the above".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Sentence-Matching Criterion</head><p>Our system uses a bags-of-n-grams vector space model for sentence matching. For example, if we have the sentence "We are scientists", we will have bags-ofwords as follow: 1-gram = {"We", "are", "scientists"}, 2-gram = {"We are", "are scientists"}, 3-gram = {"We are scientists"}. The model that we used is a model consisting of bags-of-words for all n-grams and is defined as follows:</p><formula xml:id="formula_2" coords="4,226.97,362.47,161.42,8.74">model = 1-gram ∪ 2-gram ∪ 3-gram.</formula><p>In preliminary experiments, we found n = 3 achieved higher precision than n = 1, 2, 4, 5, and that it was necessary to take the union of higher and lower order n-grams.</p><p>To measure similarity between vectors, we used TF/IDF <ref type="bibr" coords="4,392.65,420.56,15.50,8.74" target="#b10">[11]</ref> weighted cosinesimilarity <ref type="bibr" coords="4,178.27,432.52,10.52,8.74" target="#b4">[5]</ref> as the weight of term i . Most of our features are based on the cosine similarity measure, which is commonly used in many IR systems</p><formula xml:id="formula_3" coords="4,229.56,465.23,251.03,22.31">tf-idf(i, v) = tf(i, v) × log |v| n(i, v) ,<label>(3)</label></formula><p>where tf(i, v) is the occurrence frequency of term i in passage v, |v| is the total number of sentences in D, and n(i, v) is the number of sentences in v in which term i occurs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Features</head><p>Following from (3), the equation for cosine similarity between question q and sentence d j is</p><formula xml:id="formula_4" coords="4,187.39,605.47,288.96,29.23">sim(q, d j ) = p i=1 (tf-idf(i, q) × tf-idf(i, d j )) p i=1 tf-idf(i, q) 2 × p i=1 tf-idf(i, d j ) 2 . (<label>4</label></formula><formula xml:id="formula_5" coords="4,476.35,615.32,4.24,8.74">)</formula><p>Each feature gives a score to each pair of {q, D} and {a k }. We use three intrasentence features that are widely known in previous work:</p><p>1. Greatest Cosine (GC) finds the most related sentence to q and a k . If this value is high, we have more certainty in the candidate answer. This feature concatenates the question and answer and finds the greatest cosine similarity value for a sentence in the document.Let p be a query where q and a k are concatenated together.</p><p>GC ← max j (sim(p, d j )).</p><p>2. Greatest Matching (GM) does not adopt cosine matching, but simply counts the maximum number of words that match both the a k and q in a single sentence. This feature simply counts the greatest number of words overlapping between one sentence in the background text and the concatenated question and answer. GM ← max</p><formula xml:id="formula_6" coords="5,295.93,278.01,83.08,14.43">j (|(q ∪ a k ) ∩ d j |).</formula><p>3. Cosine Matching (CosM) distinguishes whether the question and candidate answers occur in the same sentences in D or not. Here l is some threshold, which we set to 0.1 after preliminary tests.</p><formula xml:id="formula_7" coords="5,151.70,348.00,345.41,9.65">CosM ← |D 1 ∩D 2 | where D 1 = {d j | sim(q, d j ) &gt; l} ∧ D 2 = {d j | sim(a k , d j ) &gt; l}</formula><p>We also propose new inter-sentence features that help capture answers that span multiple sentences in a simple manner:</p><p>1. Closest Matching (ClM) aims to find candidate answers that are not in the same sentence as q but close in proximity. We represent this using the distance from representative sentence r, which is defined as the sentence most similar to the question, and all answer candidate sentences. Let index(d j ) be a function that indicates the location of d j in the passage, r = argmax j (sim(q, d j )) and D = {d j | sim(a k , d j ) &gt; l}.</p><formula xml:id="formula_8" coords="5,138.97,491.13,283.75,57.17">ClM =    min dj ∈D (|index(r) -index(d j )|) if D = ∅ 0 otherwise 2.</formula><p>Closest Sentence (ClS) is quite similar to ClM, but instead of finding a representative sentence r, it counts the distance from all sentences that exceed the threshold t. 3. Unmatched (UM) is a binary feature active when ClM or ClS find no answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Weight Learning</head><p>This section describes a unified minimum error rate training <ref type="bibr" coords="5,407.50,633.20,10.52,8.74" target="#b6">[7]</ref> framework to learn how and when to answer questions by adjusting w and its scaling with respect to threshold t.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">QA Evaluation Measures</head><p>Before learning, we must formally define how good any particular values of w are. One definition of the "goodness" of w is the accuracy, or percentage of questions answered correctly</p><formula xml:id="formula_9" coords="6,258.50,178.10,217.85,22.31">a(w, t, Q) = c(w, t, Q) |Q| (<label>5</label></formula><formula xml:id="formula_10" coords="6,476.35,184.84,4.24,8.74">)</formula><p>where c(w, t, Q) is the number of questions in Q answered correctly given w and t. However, while this measure is intuitive, it also cannot distinguish between unanswered and incorrectly answered questions. As a remedy to this, <ref type="bibr" coords="6,433.77,233.12,10.52,8.74" target="#b7">[8]</ref> propose "c@1," which gives partial credit to unanswered questions, in proportion to the accuracy</p><formula xml:id="formula_11" coords="6,204.43,267.44,271.92,22.31">c@1(w, t, Q) = c(w, t, Q) + n(w, t, Q)a(w, t, Q) |Q| (<label>6</label></formula><formula xml:id="formula_12" coords="6,476.35,274.18,4.24,8.74">)</formula><p>where n(w, t, Q) is the number of no-answers. Next, we want to find a value of w that allows our system to score well on these evaluation measures. To do so, we first adopt the minimum error rate training (MERT) framework of <ref type="bibr" coords="6,279.70,586.83,9.96,8.74" target="#b6">[7]</ref>, which can learn weights w for arbitrary evaluation measures that do not consider a threshold (t = 0).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Minimum Error Rate Training</head><p>The basic idea of MERT is to efficiently find weights that minimize some measure of error of the system. For example, we could define our error as one minus the accuracy of the system, and find weights that minimize this value ŵ = argmin w 1 -a(w, 0, Q)</p><p>As exactly solving Equation ( <ref type="formula" coords="7,279.90,119.99,4.24,8.74" target="#formula_13">7</ref>) is computationally difficult, <ref type="bibr" coords="7,415.25,119.99,10.52,8.74" target="#b6">[7]</ref> proposes an approximate algorithm using the coordinate ascent method of <ref type="bibr" coords="7,419.07,131.95,14.61,8.74" target="#b9">[10]</ref>. <ref type="foot" coords="7,437.33,130.37,3.97,6.12" target="#foot_2">3</ref> We will give a conceptual overview of the procedure here, and readers may refer to <ref type="bibr" coords="7,470.07,143.90,10.52,8.74" target="#b5">[6]</ref> or the supplementary code for a more complete algorithmic explanation. The basic idea of this method is that we iterate through each single element w i ∈ w, and find the value of w i that minimizes error, given that all other elements of w (represented as w\w i ) are kept constant:</p><formula xml:id="formula_14" coords="7,251.57,212.50,229.02,16.07">ŵi = argmin wi 1 -a(w, 0, Q)<label>(8)</label></formula><p>This process continues until no w i can be modified to decrease the error rate.</p><p>Figure <ref type="figure" coords="7,181.24,251.11,4.98,8.74" target="#fig_1">2</ref> shows this procedure on two questions with answers and their corresponding features in Figure <ref type="figure" coords="7,267.09,263.06,20.20,8.74" target="#fig_1">2 (a)</ref>. First note that for answer a j,k to question q j , Equation ( <ref type="formula" coords="7,197.68,275.02,4.24,8.74" target="#formula_0">1</ref>) can be decomposed into the part affected by w i and the part affected by w\w i :</p><formula xml:id="formula_15" coords="7,195.15,309.75,285.44,20.14">s(q j , a j,k ) = w i φ i (q j , a j,k , D) + h =i w h φ h (q j , a j,k , D)<label>(9)</label></formula><p>Figure <ref type="figure" coords="7,182.43,341.38,4.98,8.74" target="#fig_1">2</ref> (b) plots Equation ( <ref type="formula" coords="7,284.17,341.38,4.24,8.74" target="#formula_15">9</ref>) as a linear equation over w i in the form y = cx+d where c = φ i (q j , a j,k , D), x = w i and d is equal to the right hand sum. These plots demonstrate for which values of w i each answer a j,k will be assigned a particular score, with the highest line being the one chosen by the system. For q 1 , the chosen answer will be a 1,1 for w i &lt; -2, to a 1,2 for -2 &lt; w i &lt; 2, and to a 1,3 for 2 &lt; w i as indicated by the range where the answer's corresponding line is greater than the others.</p><p>Next, we take the information of answers chosen in Figure <ref type="figure" coords="7,397.63,425.06,4.98,8.74" target="#fig_1">2</ref> (b) and, given the information about what answers are correct, convert this into a graph as Figure <ref type="figure" coords="7,134.77,448.97,4.98,8.74" target="#fig_1">2</ref> (c) where the value is one for regions covered by the correct answer and zero otherwise. The ranges for each question are then combined into a single graph indicating the total number of correct answers for each value of w i (Figure <ref type="figure" coords="7,453.19,472.89,19.43,8.74" target="#fig_1">2 (d)</ref>). Finally, given the statistics in Figure <ref type="figure" coords="7,299.74,484.84,20.55,8.74" target="#fig_1">2 (d)</ref>, we can calculate the error function used in Equation ( <ref type="formula" coords="7,219.15,496.80,4.24,8.74" target="#formula_14">8</ref>) and choose a point in the center of the region with the minimal error as shown in Figure <ref type="figure" coords="7,283.46,508.75,4.98,8.74" target="#fig_1">2</ref> (e).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Thresholded MERT</head><p>While the previous procedure can minimize errors that are merely concerned with the highest scoring answer, when considering a threshold t we also need to keep track of whether the best answer exceeds the second best answer by more than t. We present a modification to the standard MERT procedure that allows us to learn weights in the face of a threshold, which we will refer to as thresholded minimum error rate training (TMERT).   This encodes the information that if a particular answer line for a j,k1 is less than or equal to the threshold line for a j,k2 , a j,k1 has failed to exceed a j,k2 by t, and thus no answer should be returned. To find the response that will be provided by the system for any region in Figure <ref type="figure" coords="8,365.25,386.11,4.98,8.74" target="#fig_3">3</ref> (b), we examine not the line with the highest score, but the line with the second highest score. For each range where the second highest line is an answer line for a j,k1 , we know the first highest line is the corresponding threshold line for a j,k1 , so a j,k1 has exceeded all other answers by at least t and thus will be returned as the answer by the system. For each range where the second highest line is a threshold line, we can tell that the margin between the first and second answers is less than t, and thus the system will return no answer.</p><p>During the aggregation of statistics in Figure <ref type="figure" coords="8,355.01,488.12,4.98,8.74" target="#fig_3">3</ref> (c), we collect information not only on regions where the answer was correct, but also on regions where the question was unanswered. Given these statistics, we can calculate accuracy for measures that reward non-response such as c@1 and choose a value of w i that minimizes the error accordingly.</p><p>We can also indirectly optimize threshold t itself in this framework. To do so, we note that the overall scale of the weights w is inversely proportional to the threshold t; having large weights is equivalent to having a small threshold, and vice-versa. Thus, any t &gt; 0 will have the same effect on our thresholded learning algorithm, so we simply set t = 1. 5 5 Evaluation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Experimental Setup</head><p>For this year's QA4MRE, our system used only the English test set document and did not reference the background collection.</p><p>The main task consists of 284 questions, classified into 4 main topics ("AIDS", "Climate Change", "Music and Society" and "Alzheimer") and main task questions and documents that in standard and relatively simple language. There are 16 test documents (4 for each topic) and approximately 15-20 questions with 5 candidate answers for each test document. The system is required to choose answer from these multiple choices and only 1 correct candidate answer is available for each question. The system can leave the question answered if it lacks confidence. While the main task is quite similar to the past years, this year each question contains "none of the above" as a candidate answer.</p><p>To train the parameters of our model, we use both test set documents from past CLEF 2011 and 2012 QA4MRE campaigns <ref type="bibr" coords="9,347.45,312.95,9.96,8.74" target="#b8">[9]</ref>. As they provide 120 + 160 question with correct answers, we use this as our primary training data. We train the weights of the features using the described TMERT training algorithm. After training, the system achieved 112 correct answers, 15 answers with no candidate, and 153 wrong answers, yielding a c@1 score of 42% on the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Main Task Results</head><p>We submit a total of 2 runs for the main task separating the results from different strategies. Run1 uses the strategy of choosing some answers as "none of the above" as mentioned in Section 2.4 while Run2 does not. First, we show the results as measured by c@1 in Table <ref type="table" coords="9,400.61,572.96,3.87,8.74" target="#tab_0">1</ref>. Our strategy in Run1 resulted in a gain in system performance for an additional 3-4% over Run2, for evaluation in both main and +Aux questions. It indicates that the strategy is able to slightly raise accuracy for our system. The gains are relatively stable among the topics, with the topic "Alzheimer" receiving the most benefit. Overall, the system's best topic is "Alzheimer" and worst topic is "AIDS". The accuracies for the topic "Music and society" and "Climate change" are relatively similar. However as we did not use any form of knowledge except reading the document itself, we cannot provide further analysis on why our system is good or bad at certain topic.</p><p>The results in Table <ref type="table" coords="10,239.08,145.44,4.98,8.74" target="#tab_0">1</ref> also indicates that the system is relatively weak at the main questions. In particular taking a look at the sample question r id=5 and q id=6: Of all Cramer's works, the one that has had the greatest enduring value is his celebrated set of 84 studies for the piano, published in two sets of 42 each in 1804 and 1810 as "Studio per il pianoforte". This collection has long been considered a cornerstone of pianistic technique and is the only work of Cramer's that is generally known today. Question: Why is the "Studio per il pianoforte" well known even today?</p><p>1. because there are 84 studies 2. because the studies are structurally simple 3. because it teaches piano technique very effectively 4. because it shows the influence of Scarlatti 5. none of the above</p><p>The system return the answer of "1" because there are many matching keywords of the candidate answer and question in the same sentence and our anaphora resolution module failed to match the word "This" as "Studio per il pianoforte". However, our inter-sentence features are also able to answer some questions that need an inter-sentence analysis (taken from r id=7, q id=9):</p><p>The major Hollywood studios of the so-called Golden Age (c1935-55) were MGM, Paramount, RKO, Warner Brothers and 20th Century-Fox. Each housed a permanent music department, with contracted composers, arrangers, orchestrators, librarians and music editors, as well as a resident orchestra, all working under a senior music director. Question: What sort of music was written for Hollywood films in the Golden Age?</p><p>1. music for orchestra with strong melodies 2. music for singer and piano 3. music for youth audiences 4. music with four-track stereo sound 5. none of the above This question was successfully answered with the help of the ClM features, which finds a distance of one between the question and candidate answer. The question matched the first sentence because the term "Golden Age" and "Hollywood" appeared in it and the next sentence matched candidate answer 1 because term "orchestra" appeared in it. So the system returned "1" as its final answer.</p><p>For the evaluation measure <ref type="bibr" coords="10,274.98,621.25,11.62,8.74" target="#b6">(7)</ref>, the function c, and n are respectively the number of correct answers and no answers for paticular test set. Run1 achieved 88 correct answers, 182 wrong answers, and 14 unanswered, resulting a c@1 score of 32.51%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>As part of our participation in QA4MRE@CLEF 2013, we have developed QAsystem that is simple but able to answer certain types of questions. In particular it achieved higher accuracy for simpler types of questions in the main task, but lacks in terms of answering more complex question types that need more sophisticated processing. For future work, we believe that it is necessary to use external knowledge such as background knowledge so the system can provide further analysis in classifying questions and determining certain type of strategies to answer the questions. Luckily our described framerwork for a linear combination of experts and the proposed MERT training metric are conducive to adding additional components to capture this information. Further work will be focussed on integrating external knowledge derived from sources such as Wikipedia and the background collections by adding more features.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,251.06,533.45,113.23,7.89;2,134.77,372.05,375.00,146.63"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. System Architecture</figDesc><graphic coords="2,134.77,372.05,375.00,146.63" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,134.77,508.07,345.82,7.89;6,134.77,519.06,345.83,7.86;6,134.77,530.02,152.86,7.86;6,134.77,359.42,382.68,138.09"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Optimization of w3: (a) training examples and initial w, (b) slopes of each example, (c) whether qj is correct for ranges of w3, (d) total number of correct answers, (e) the accuracy and new value of w3.</figDesc><graphic coords="6,134.77,359.42,382.68,138.09" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,363.02,614.95,3.97,6.12"><head>4</head><label>4</label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="8,200.69,267.91,213.97,7.89;8,134.77,117.83,382.68,139.52"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Minimum error rate training with thresholds.</figDesc><graphic coords="8,134.77,117.83,382.68,139.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="8,149.71,314.38,330.88,8.74;8,134.77,326.33,345.83,8.74;8,134.77,338.29,345.83,8.74;8,134.77,350.24,345.82,8.74;8,134.77,362.20,345.82,9.65;8,134.77,374.16,345.82,9.65;8,134.77,386.11,345.83,8.74;8,134.77,398.07,345.82,8.74;8,134.77,410.02,345.82,9.65;8,134.77,421.98,345.83,9.65;8,134.77,433.93,345.83,8.74;8,134.77,445.89,345.83,8.74;8,134.77,457.84,345.83,8.74;8,134.77,469.80,145.82,8.74"><head>Figure 3</head><label>3</label><figDesc>Figure3demonstrates our proposed algorithm, emphasizing parallels and differences to traditional MERT. The first difference is that for each answer line y = cx + d in Figure2(b), we add an additional threshold line y = cx + d + t raised by t. This encodes the information that if a particular answer line for a j,k1 is less than or equal to the threshold line for a j,k2 , a j,k1 has failed to exceed a j,k2 by t, and thus no answer should be returned. To find the response that will be provided by the system for any region in Figure3(b), we examine not the line with the highest score, but the line with the second highest score. For each range where the second highest line is an answer line for a j,k1 , we know the first highest line is the corresponding threshold line for a j,k1 , so a j,k1 has exceeded all other answers by at least t and thus will be returned as the answer by the system. For each range where the second highest line is a threshold line, we can tell that the margin between the first and second answers is less than t, and thus the system will return no answer.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="9,213.27,457.40,188.81,90.99"><head>Table 1 .</head><label>1</label><figDesc>Result of Participation in Main Task</figDesc><table coords="9,219.62,457.40,173.04,74.42"><row><cell>Topic</cell><cell>Run1 Main +Aux Main +Aux Run2</cell></row><row><cell>Alzheimer</cell><cell>0.36 0.36 0.29 0.29</cell></row><row><cell cols="2">Music and society 0.28 0.37 0.29 0.39</cell></row><row><cell cols="2">Climate Change 0.29 0.32 0.24 0.28</cell></row><row><cell>AIDS</cell><cell>0.19 0.25 0.15 0.23</cell></row><row><cell>Average C@1</cell><cell>0.28 0.33 0.24 0.30</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,144.73,646.84,203.96,7.86"><p>http://nlp.stanford.edu/software/CRF-NER.shtml</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,144.73,657.79,224.42,7.86"><p>http://www.lextek.com/manuals/onix/stopwords2.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="7,144.73,635.88,335.86,7.86;7,144.73,646.84,283.64,7.86"><p><ref type="bibr" coords="7,144.73,635.88,9.73,7.86" target="#b3">[4]</ref> present a method to improve the efficiency of exact MERT, but it is still significantly less efficient and more complicated than approximate solutions.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="7,137.50,656.03,3.65,5.24;7,144.73,657.79,315.00,8.12"><p><ref type="bibr" coords="7,137.50,656.03,3.65,5.24" target="#b3">4</ref> Our implementations is available open source at http://phontron.com/tmert</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="8,144.73,646.81,335.87,7.89;8,144.73,655.43,281.00,10.23"><p>It is also possible to more efficiently adjust the scale of w by taking an additional TMERT optimization step for a scaling factor λ, then scale w ← λw.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="11,142.96,330.88,337.63,7.86;11,151.52,341.84,237.94,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,284.32,330.88,196.27,7.86;11,151.52,341.84,27.04,7.86">An Analysis of the AskMSR Question-Answering System</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Brill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Banko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,211.73,341.84,91.82,7.86">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="257" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,352.80,337.64,7.86;11,151.52,363.76,294.35,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,383.34,352.80,97.26,7.86;11,151.52,363.76,133.22,7.86">In Question Answering, Two Heads Are Better Than One</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chu-Carroll</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Czuba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Prager</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ittycheriah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,318.14,363.76,51.36,7.86">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="24" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,374.72,337.63,7.86;11,151.52,385.68,109.84,7.86" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="11,282.51,374.72,198.08,7.86;11,151.52,385.68,33.72,7.86">Overview of the TREC 2006 Question Answering Track 99</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">T</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kelly</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>TREC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,396.64,337.63,7.86;11,151.52,407.59,153.00,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,241.97,396.64,200.22,7.86">Optimal Search for Minimum Error Rate Training</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Galley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Quirk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,463.04,396.64,17.55,7.86;11,151.52,407.59,76.44,7.86">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="38" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,418.55,337.64,7.86;11,151.52,429.51,155.69,7.86" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="11,262.70,418.55,131.87,7.86">Speech and Language Processing</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Jurafsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Martin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Pearson Education</publisher>
			<pubPlace>Upper Saddle River, NJ</pubPlace>
		</imprint>
	</monogr>
	<note>2 edn.</note>
</biblStruct>

<biblStruct coords="11,142.96,440.47,337.64,7.86;11,151.52,451.43,134.67,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,196.85,440.47,118.66,7.86">Section 9.3: Parameter tuning</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,336.39,440.47,124.48,7.86">Statistical Machine Translation</title>
		<imprint>
			<publisher>Cambridge Press</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="263" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,462.39,337.64,7.86;11,151.52,473.35,94.64,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,194.35,462.39,248.12,7.86">Minimum error rate training in statistical machine translation</title>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">J</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,463.04,462.39,17.56,7.86;11,151.52,473.35,65.97,7.86">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,484.31,337.63,7.86;11,151.52,495.27,329.07,7.86;11,151.52,506.22,104.59,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,250.93,484.31,171.78,7.86">A Simple Measure to Assess Non-response</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rodrigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,445.37,484.31,35.22,7.86;11,151.52,495.27,45.36,7.86">Proceedings of ACL</title>
		<meeting>ACL<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011-06">June 2011</date>
			<biblScope unit="page" from="1415" to="1424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,514.92,337.64,10.13;11,151.52,528.14,329.07,7.86;11,151.52,539.10,329.07,7.86;11,151.52,550.06,173.75,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,209.92,528.14,270.68,7.86;11,151.52,539.10,103.17,7.86">Overview of QA4MRE at CLEF 2011: Question Answering for Machine Reading Evaluation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Forner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Á</forename><surname>Rodrigo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">F E</forename><surname>Sutcliffe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Forascu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Sporleder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,455.89,539.10,24.70,7.86;11,151.52,550.06,140.35,7.86">CLEF (Notebook Papers/Labs/Workshop</title>
		<editor>
			<persName><forename type="first">V</forename><surname>Petras</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Clough</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,561.02,337.98,7.86;11,151.52,571.98,329.07,7.86;11,151.52,582.94,25.60,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,200.43,561.02,280.16,7.86;11,151.52,571.98,164.96,7.86">An efficient method for finding the minimum of a function of several variables without calculating derivatives</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Powell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,324.75,571.98,95.67,7.86">The Computer Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="155" to="162" />
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,593.90,337.97,7.86;11,151.52,604.85,248.33,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,247.52,593.90,215.99,7.86">Term-weighting approaches in automatic text retrieval</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,151.52,604.85,163.52,7.86">Information Processing and Management</title>
		<imprint>
			<biblScope unit="page" from="513" to="523" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,615.81,337.98,7.86;11,151.52,626.77,200.84,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,190.71,615.81,224.10,7.86">Natural Language Question Answering in Open Domains</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Tufis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,421.90,615.81,58.70,7.86;11,151.52,626.77,110.23,7.86">The Computer Science Journal of Moldova</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="146" to="164" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
