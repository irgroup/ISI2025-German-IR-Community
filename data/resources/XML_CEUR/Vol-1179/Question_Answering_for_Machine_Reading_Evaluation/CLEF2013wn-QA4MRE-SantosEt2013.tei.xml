<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,187.22,115.96,240.92,12.62;1,253.69,133.89,107.98,12.62">An Approach to the Main Task of QA4MRE-2013</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,203.76,171.56,61.47,8.74"><forename type="first">Marília</forename><surname>Santos</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Informática</orgName>
								<orgName type="institution">ECT Universidade de Évora</orgName>
								<address>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,273.03,171.56,43.97,8.74"><forename type="first">José</forename><surname>Saias</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Informática</orgName>
								<orgName type="institution">ECT Universidade de Évora</orgName>
								<address>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,339.70,171.56,71.89,8.74"><forename type="first">Paulo</forename><surname>Quaresma</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Informática</orgName>
								<orgName type="institution">ECT Universidade de Évora</orgName>
								<address>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,187.22,115.96,240.92,12.62;1,253.69,133.89,107.98,12.62">An Approach to the Main Task of QA4MRE-2013</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">548365061892C2141642FC44220BB0ED</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>MRE</term>
					<term>QA</term>
					<term>NLP</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This article describes the participation of a group from the University of Évora in the CLEF2013 QA4MRE main task. Our system has a superficial text analysis based approach. The methodology starts with the preprocessing of background collection documents, whose texts are lemmatized and then indexed. Named entities and numerical expressions are sought in questions and their candidate answers. Then the lemmatizer is applied and stop words are removed. Answer patterns are formed for each question+answer pair, with a search query for document retrieval. Original search terms are expanded with synonyms and hyperonyms. Finally, the texts retrieved for each candidate response are segmented and scored for answer selection. Considering only the main questions, the system best result was obtained in the third run, having answered to 206 questions, with 0.24 c@1 and 51 correct answers. When evaluating main and auxiliary questions, the final run continued to have our better results, being answered 245 questions, with 64 right answers and 0.26 for c@1. The use of hypernyms proved to be an improvement factor in the third run, which results had a 12% increase of correct answers and a 0.02 gain in c@1.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This article describes the participation of a group from the University of Évora in the Question Answering for Machine Reading Evaluation (QA4MRE) challenge of the 2013 edition of Cross Language Evaluation Forum (CLEF)<ref type="foot" coords="1,428.39,540.09,3.97,6.12" target="#foot_0">1</ref> . Although some authors of this paper have previous work in other QA4MRE editions <ref type="bibr" coords="1,459.56,553.62,10.52,8.74" target="#b2">[4,</ref><ref type="bibr" coords="1,470.08,553.62,7.01,8.74" target="#b3">5]</ref>, this work is based on a new system for the QA4MRE Main Task, associated with the first author's master's thesis work, and focused on the English language. The objective of this task is the automatic understanding of one or more texts, and the subsequent identification of the answer for several questions about information that is stated or implied in those texts. While answering the questions, systems must process single documents, and Background Collections (BC) with documents that can be used as auxiliary information sources <ref type="bibr" coords="1,403.01,637.31,9.96,8.74" target="#b0">[2]</ref>. This year's QA4MRE Main Task was composed by 4 topics, namely "Aids", "Climate Change", "Music and Society" and "Alzheimer", and all of them having a background collection of documents. Each topic had 4 reading tests with 15 to 20 questions each, and each question had 5 choice answers <ref type="bibr" coords="2,426.05,154.86,9.96,8.74">[1]</ref>. The test was composed by 240 main questions and 44 auxiliary questions. The latter are duplicates of the main questions, but without the previously required inference, allowing to test the ability of systems to use inference and its impact in the question treatment. Next section presents our system arquitecture. Section 3 describes the methodology we used to process the questions, answers and the background information. The evaluation of the obtained results is detailed in section 4, while the last two sections are devoted to an analysis of those results, some conclusions and a balance of our participation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Architecture</head><p>The system architecture is shown in Figure <ref type="figure" coords="2,323.74,333.96,4.98,8.74" target="#fig_0">1</ref> and has the following components:</p><p>• XML Parser -Extracts texts, questions and answers from the input and stores them on the system;</p><p>• Indexing Component -Documents from BC pass through the lemmatizer (Candc tools/ C&amp;C Boxer<ref type="foot" coords="2,249.56,380.21,3.97,6.12" target="#foot_1">2</ref> ) and then they are indexed with Lucene<ref type="foot" coords="2,435.73,380.21,3.97,6.12" target="#foot_2">3</ref> ;</p><p>• Consult Index Component -Responsible for processing question and answers and perform document retrieval. With keywords from question and answers, this component uses Lucene to search for relevant documents in BC. The analysis and search query creation is based on:</p><p>-Lemmatizer -Question and answers's words are parsed to the corresponding lemma form; -Named Entity Recognition (NER) -Through regular expression, the system tries identify entity names or mentions; -WordNet module from Natural Language Toolkit<ref type="foot" coords="2,374.31,498.03,3.97,6.12" target="#foot_3">4</ref> : the system uses synonyms, derivationally related forms and hypernyms; -Numerical expressions -Through regular expression, the system tries identify numerical expressions; -Remove stop words.</p><p>• Filter Component -Responsible for select relevant text segments, assigning a score to each segment and to each candidate answer. This component applies a set of criteria to choose the most plausible answer. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>The system is based on a simple approach without a deep linguistic processing. In this edition of QA4MRE, our system generated 3 runs, having minor differences in configuration, as explained below. The processing performed on the BC texts, the reading tests and questions, comprises the following steps:</p><p>1. Indexing Component (this component is used only once) (a) Lemmatization is applied to the text of all documents in BC; (b) BC documents are indexed, considering the lemmatizer outcome; 2. XML Parser (a) The information from the input is extracted and stored on the system; 3. Consult Index Component -Each question is processed with the following steps and as illustrated in the examples: (a) Entities and numerical expressions from question and candidate answers are stored in the system. -If the filter returns no relevant documents, then the system selects the answer "5 -None of the above"; -The system returns Unanswer when there is more than one maximum, or in cases where there is a small difference between the maximum and another answer's score; -If none of above applies, the system returns the answer with maximum score.</p><p>The difference between the runs is reflected in the number of answers given, and in system's accuracy. This difference can be observed in the following examples:</p><p>Example 1: How can Alzheimer's patients regain the sense of smell? Unanswered in the first and the second run; Answered correctly in the third run.</p><p>Example 2: How can apolipoprotein E help people with Alzheimer's? Answered wrongly in the first and the second run; Answered correctly in the third run.</p><p>Example 3: What is U.S. AIDS policy dominated by? Unanswered in the second run; Answered correctly in the first and the third run.</p><p>Examples 1 and 2 are cases where the use of hypernyms causes a small improvement on Component Filter. Example 3 shows the importance of applying the methodology step 4.c when the information is not dispersed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>In QA4MRE, the evaluation of all runs submitted is based on the c@1 measure, discussed in <ref type="bibr" coords="6,189.73,266.54,9.96,8.74" target="#b1">[3]</ref>:</p><formula xml:id="formula_0" coords="6,246.98,285.91,121.39,22.31">c@1 = 1 n (n R + n U n R n ) (1)</formula><p>Equation ( <ref type="formula" coords="6,196.61,321.08,3.87,8.74">1</ref>): n R -number of correctly answered questions; n U -number of unanswered questions; n -total number of questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evaluation on the main questions</head><p>In the first approach the system answered to 188 of 240 questions, of which only 45 were correct, resulting in 0.23 c@1. In the second run, 185 questions were answered, with 0.18 c@1. And in the last run we answered to 206 questions, with 0.24 c@1 and 51 correct answers. Table <ref type="table" coords="6,336.92,450.69,4.98,8.74" target="#tab_1">1</ref> shows the detail of the system result assessment, by topic and by run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation on all questions</head><p>For the first run, the system answered to 224 out of 284 questions. From those, 57 were correctly answered, and the c@1 was 0.24. In the second, 219 questions were answared. The c@1 was 0.19. In the final run, our system answered to 245 questions, finding 64 right answers and obtaining 0.26 for c@1. Table <ref type="table" coords="6,446.35,556.39,4.98,8.74" target="#tab_2">2</ref> shows these results with greater detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>One of the main causes of this system failure is the lack of an entities disambiguation module, because entities are, quite often, referred by different expressions.</p><p>Other identified causes are: 1. Yes/no questions; 2. Answers supported by adverbs of frequency (rarely, always, never, sometimes, ...); 3. Words with high frequency have a negative impact in our system due to way the scoring algorithm works. This is specially noticed when it causes the selection of non relevant documents and incorrect answers and, in this way, it invalidates the possibility of answering "5 -None of the above". These failures were observed essencially for the Aids topic.</p><p>We have also observed that using a second analysis in the Filter Component (step 4.c in the methodology section) is only effective when the information about the correct answer is not disperse over several documents. However, the use of this approach allowed the improvement of 5-8% relatively to the base option (run 2), with the exception of the topic "Music and Society", where there was no impact. The use of hyperonyms didn't cause any improvement in the Aids topic but in the "Alzheimer" and "Climate Change" topics it allowed an improvement of 10% relatively to the base option and in the "Music and Society" topic an improvement of 5%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We described the experience in QA4MRE challenge, using a simple system, with a superficial text analysis based approach. This system clearly needs further developments, aiming to improve the analysis of the questions and answers. Namely, we intend to work on the disambiguation of entities, establishment of relations between acronyms and entities, and trying to handle the failure causes described in the previous sections. One of the critical aspects is to change the way our system evaluates answer patterns composed by words with high frequency; we need to add a new component to improve the answer selection process and, namely, to take into account the question and answer types. We have also detected that the incorporation of an anaphora resolution module would allow the system to answer more questions and to improve its performance.</p><p>On a more abstract level, we intend to assess the strengths of the system used by Évora's team last year and combine strategies with some new ideas tested in this year's work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,251.06,333.47,113.23,7.89;3,170.28,115.84,274.80,192.90"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. System Architecture</figDesc><graphic coords="3,170.28,115.84,274.80,192.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,168.64,537.42,311.96,116.04"><head></head><label></label><figDesc>If the answer has a numerical expression which does not exist on the document, it is discarted;-If the answer or the question has entities and if the document does not contain 30% of them, it is discarted; (b) When a document is valid:-Each Answer Pattern that validates the current document receives a score with the sum of:• Number of entities in the text;• Number of numerical expressions in the text;• Number of times that each keyword, from current Answer Pattern, occurs in the text; -The document score is the sum of each of its Answer Patterns score; (c) Thereafter, a second analysis is performed, only on the top 5 resulting documents from the filter; (This step is used only in the first and in the</figDesc><table coords="3,168.64,537.42,311.96,116.04"><row><cell>(b) Question and candidate answers pass through the lemmatizer; ((clinic OR clinical) OR (test OR trial OR attempt)) OR</cell></row><row><cell>How can Alzheimer's patient regain the sense of smell? ((care OR treatment OR treat) OR (bexarotene)) OR</cell></row><row><cell>1 through chemotherapy ((lie) OR (sun))</cell></row><row><cell>2 through clinical trial</cell></row><row><cell>3 through treatment with bexarotene 4. Filter Component -For each question:</cell></row><row><cell>4 by lie in the sun (a) Each document is validated for each Answer Pattern:</cell></row><row><cell>5 None of the above -If it doesn't contain 50% keywords from question and 50% keywords</cell></row><row><cell>from answer, it is discarted;</cell></row><row><cell>(c) Stop words are removed from question and candidate answers; Alzheimer's patient regain sense smell 1 chemotherapy 2 clinical trial 3 treatment bexarotene 4 lie sun 5 none -Alzheimer's synonyms: Alzheimer's disease | hypernyms: dementia -third runs) -patient -Documents are split into text segments; hypernyms: case -Current Answer Pattern's score is incremented if 80% of Answer -regain Pattern's words are present in the current text segment and the synonyms: recover | related forms: recoverer | hypernyms: get distance between them is less or equal to 5; -sense hypernyms: awareness (d) Answer Selection:</cell></row><row><cell>-smell</cell></row><row><cell>hypernyms: sensation</cell></row><row><cell>-chemotherapy</cell></row><row><cell>related forms: chemotherapeutical | hypernyms: therapy</cell></row><row><cell>-clinical</cell></row><row><cell>related forms: clinic</cell></row><row><cell>-trial</cell></row><row><cell>The filter uses them to score answers and text synonyms: test | hypernyms: attempt</cell></row><row><cell>segments; -treatment</cell></row><row><cell>How can Alzheimer's patients regain the sense of smell? related forms: treat | hypernyms: care</cell></row><row><cell>1 through chemotherapy</cell></row><row><cell>2 through clinical trials (e) Document retrieval, using Lucene to get relevant documents, using the</cell></row><row><cell>3 through treatment with bexarotene generated Answer Patterns to querying over the indexed BC;</cell></row><row><cell>4 by lying in the sun Query:</cell></row><row><cell>5 None of the above ((Alzheimer's OR dementia OR Alzheimer's_disease) OR (case</cell></row><row><cell>OR patient) OR (regain OR recoverer OR recover OR get) OR</cell></row><row><cell>Entities: Alzheimer's patients (awareness OR sense) OR (smell OR sensation)) OR</cell></row><row><cell>((chemotherapy OR chemotherapeutical OR therapy)) OR</cell></row></table><note coords="4,150.37,309.79,330.22,8.74;4,168.64,321.74,311.95,8.74;4,168.64,333.70,311.95,8.74;4,168.64,345.65,251.53,8.74"><p>(d) For each pair (question, candidate answer) try to form an Answer Pattern. The Answer Pattern is compound by: keywords from question; keywords from answer; synonyms, derivationally related forms and hypernyms (used only on the third run) from each keyword;</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,179.06,115.91,257.24,218.55"><head>Table 1 .</head><label>1</label><figDesc>Results of the main questions</figDesc><table coords="7,359.13,136.29,45.46,7.89"><row><cell>Answered</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,179.06,115.91,257.24,218.55"><head>Table 2 .</head><label>2</label><figDesc>Results of the main + auxiliary questions</figDesc><table coords="8,359.13,136.29,45.46,7.89"><row><cell>Answered</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,656.80,80.91,7.86"><p>http://clef2013.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,144.73,623.92,213.69,7.86"><p>http://svn.ask.it.usyd.edu.au/trac/candc/wiki/boxer</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,144.73,634.88,335.86,7.86;2,144.73,645.84,103.96,7.86"><p>ApacheLucene is an open source information retrieval software library. http://lucene.apache.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="2,144.73,656.80,60.43,7.86"><p>http://nltk.org</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,138.35,577.78,300.68,8.12" xml:id="b0">
	<monogr>
		<ptr target="http://celct.fbk.eu/QA4MRE" />
		<title level="m" coord="8,146.91,577.78,162.60,7.86">Track Guidelines</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>QA4MRE@CLEF</note>
</biblStruct>

<biblStruct coords="8,138.35,589.89,342.25,7.86;8,146.91,600.85,333.67,7.86;8,146.91,611.81,333.68,7.86;8,146.91,622.77,135.39,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,245.64,589.89,164.71,7.86">A simple measure to assess non-response</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rodrigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,432.51,589.89,48.08,7.86;8,146.91,600.85,333.67,7.86;8,146.91,611.81,113.88,7.86;8,379.69,611.81,32.91,7.86">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1415" to="1424" />
		</imprint>
	</monogr>
	<note>HLT &apos;11</note>
</biblStruct>

<biblStruct coords="8,138.35,634.88,342.24,7.86;8,146.91,645.84,333.68,7.86;8,146.91,656.80,287.39,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,246.92,634.88,233.67,7.86;8,146.91,645.84,63.40,7.86">The di@ue&apos;s participation in qa4mre: from qa to multiple choice challenge</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Saias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Quaresma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,410.69,645.84,69.90,7.86;8,146.91,656.80,131.42,7.86">CLEF 2011 Labs and Workshop: Notebook Papers</title>
		<editor>
			<persName><forename type="first">V</forename><surname>Petras</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Clough</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.35,119.67,342.24,7.86;9,146.91,130.63,333.68,7.86;9,146.91,141.59,285.41,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,250.96,119.67,229.63,7.86;9,146.91,130.63,132.73,7.86">Di@ue in clef2012: question answering approach to the multiple choice qa4mre challenge</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Saias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Quaresma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,301.67,130.63,178.92,7.86;9,146.91,141.59,156.06,7.86">Proceedings of CLEF 2012 Evaluation Labs and Workshop -Working Notes Papers</title>
		<meeting>CLEF 2012 Evaluation Labs and Workshop -Working Notes Papers<address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-09">September 2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
