<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,139.16,116.95,337.03,12.62">NAIST at the CLEF 2013 QA4MRE Pilot Task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,204.99,154.69,57.51,8.74"><forename type="first">Philip</forename><surname>Arthur</surname></persName>
							<email>philip-a@is.naist.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">Nara Institute of Science and Technology</orgName>
								<address>
									<addrLine>8916-5, Takayama-cho, Ikoma-shi</addrLine>
									<postCode>630-0192</postCode>
									<settlement>Nara</settlement>
									<country key="JP">JAPAN</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,270.50,154.69,67.54,8.74"><forename type="first">Graham</forename><surname>Neubig</surname></persName>
							<email>neubig@is.naist.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">Nara Institute of Science and Technology</orgName>
								<address>
									<addrLine>8916-5, Takayama-cho, Ikoma-shi</addrLine>
									<postCode>630-0192</postCode>
									<settlement>Nara</settlement>
									<country key="JP">JAPAN</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,346.14,154.69,60.03,8.74"><forename type="first">Sakriani</forename><surname>Sakti</surname></persName>
							<email>ssakti@is.naist.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">Nara Institute of Science and Technology</orgName>
								<address>
									<addrLine>8916-5, Takayama-cho, Ikoma-shi</addrLine>
									<postCode>630-0192</postCode>
									<settlement>Nara</settlement>
									<country key="JP">JAPAN</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,226.14,166.65,55.90,8.74"><forename type="first">Tomoki</forename><surname>Toda</surname></persName>
							<email>tomoki@is.naist.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">Nara Institute of Science and Technology</orgName>
								<address>
									<addrLine>8916-5, Takayama-cho, Ikoma-shi</addrLine>
									<postCode>630-0192</postCode>
									<settlement>Nara</settlement>
									<country key="JP">JAPAN</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,309.71,166.65,79.51,8.74"><forename type="first">Satoshi</forename><surname>Nakamura</surname></persName>
							<email>s-nakamura@is.naist.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">Nara Institute of Science and Technology</orgName>
								<address>
									<addrLine>8916-5, Takayama-cho, Ikoma-shi</addrLine>
									<postCode>630-0192</postCode>
									<settlement>Nara</settlement>
									<country key="JP">JAPAN</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,139.16,116.95,337.03,12.62">NAIST at the CLEF 2013 QA4MRE Pilot Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9561FF6F714AD81FC5A227613911E150</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>discriminative learning</term>
					<term>minimum error rate training</term>
					<term>linear feature model</term>
					<term>question answering</term>
					<term>machine reading</term>
					<term>inter-sentence features</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the Nara Institute of Science and Technology's system for the entrance exam pilot task of CLEF 2013 QA4MRE. The core of the system is a similar to the system for the main task of CLEF 2013 QA4MRE. We use minimum error rate training (MERT) to train the weights of the model and also propose a novel method for MERT with the addition of a threshold that defines the certainty with which we must answer questions. The system received a score of 22% c@1.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>While years of research on Question Answering (QA) have greatly improved the state-of-the-art, we know that this problem is far from solved. Question answering campaigns such as CLEF <ref type="bibr" coords="1,296.67,453.73,10.52,8.74" target="#b6">[7]</ref> and TREC <ref type="bibr" coords="1,362.97,453.73,10.52,8.74" target="#b3">[4]</ref> have resulted in a large number of distinct proposals about how to build robust systems that can provide correct answers in the general domain.</p><p>One of the features of QA that is widely accepted is that "two heads are better than one" <ref type="bibr" coords="1,213.34,501.63,9.96,8.74" target="#b2">[3]</ref>. By combining different information sources, we gain the ability to cover up the disadvantages of one system with another information source, which results in more effective QA on the whole. One way to combine multiple systems is to weight each system's score with some value and choose the maximum value from a linear combination <ref type="bibr" coords="1,339.56,549.45,9.96,8.74" target="#b7">[8]</ref>. Another important aspect of QA is that it is sometimes good not to answer the question <ref type="bibr" coords="1,401.64,561.40,9.96,8.74" target="#b5">[6]</ref>. Many systems currently return No Answer (NoA) if they are not confident because a wrong answer is often worse than no answer <ref type="bibr" coords="1,305.21,585.31,9.96,8.74" target="#b1">[2]</ref>. Our system for the CLEF Question Answering for Machine Reading Evaluation (QA4MRE) this year is based on these two principles, devising a number of features that provide useful information to identify the correct answer, and combining them together with a learning framework that is also able to learn when not to answer questions.</p><p>We introduce several new features that span multiple sentences in addition to more traditional features such as cosine similarity. These features are combined in a framework that learns both how and when to answer questions in a single weighted linear model. In particular, we find how to answer questions by learning appropriate weigths for each feature, with final score of an answer being their weighted linear combination. We define when not to answer by not returning candidates for which scores are less than a set threshold t from other candidates. Finally, we propose a method to intelligently weight the features and threshold using minimum error rate training.</p><p>As results, our system received a score of 22% on the Entrance Exam pilot task according to the c@1 evaluation metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Description</head><p>The core of our system relies on a log linear scoring model that is fully described in <ref type="bibr" coords="2,147.18,290.32,9.96,8.74" target="#b0">[1]</ref>. Before we score the answer, our system use several basic preprocessing methods such as tokenization, named entity recognition, anaphora resolution, lowercasing, stop word deletion, and stemming to process the text before hand. Our model is based on bags-of-n-grams vector space model that takes the union from higher and lower order of n-grams. We weight the features of the model based on tf-idf term weighting and also use this criterion to measure the similarity between vectors. Next, we score each candidate answer for each question with features that are based on traditional intra-sentence features and some proposed inter-sentence features multiplied by their trained weight. The candidate answer with the best score that exceeds a defined threshold will be chosen as system's answer, or the system will return no answer if the score is below the threshold.</p><p>To train the model, we used a new training method based on minimum error rate training (MERT, <ref type="bibr" coords="2,232.92,434.41,10.79,8.74" target="#b4">[5]</ref>) for question answering. The training method takes a set of questions, candidate answers and their particular features score and train it accordingly. Furthermore, we define a threshold t, and the system will only answer if the highest scoring candidate exceeds the second candidate by more than the threshold. This MERT plus its threshold is a new training method called TMERT that is described in <ref type="bibr" coords="2,290.43,494.18,9.96,8.74" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Evaluation Measures</head><p>To evaluate the system's performance, we used "c@1," which is used for the QA4MRE evaluation metric <ref type="bibr" coords="2,260.43,591.32,9.96,8.74" target="#b5">[6]</ref>,</p><formula xml:id="formula_0" coords="2,255.45,612.45,225.14,22.31">c@1 = 1 n ca + ca * ca n<label>(1)</label></formula><p>where "ca", "na", and "n" correspond to "correct answer", "no answer", and number of questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experimental Setup</head><p>The system used only the English test set document and did not reference the background collection. The "Entrance Exams" task aims to evaluate systems under the same conditions under which humans are evaluated for entering university. This new task consists of 9 test sets containing 10 questions with 4 candidate answers each. To train the parameters of the model, we use both test set documents from past CLEF 2011 and 2012 QA4MRE campaigns <ref type="bibr" coords="3,449.44,198.51,10.52,8.74" target="#b6">[7]</ref> and receive a c@1 score of 42% on the training data <ref type="bibr" coords="3,345.51,210.46,9.96,8.74" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Entrance Exam Task Results</head><p>Reading First we show the result in Table <ref type="table" coords="3,301.90,394.94,3.87,8.74" target="#tab_0">1</ref>. For the Japanese entrance exam pilot task, we only submitted 1 run which achieved 10 correct answers, 35 wrong answers and 1 unanswered question resulting a c@1 score of 22.22%, which is lower than a random baseline (25%). We take a look at the results carefully and spot some mistakes the system made. This sample question is taken from the r id=1 and q id=1. When I was a child, our dining room had two kinds of chairs -two large ones with arm rests and four small ones without. The larger ones stood at the ends of the table, the small ones on the sides. Mom and Dad sat in the big chairs, except when one of us was away; then Mom would sit in one of the smaller chairs. I always remained in the same place, at my father's right. He always sat at the end, at the "head" of the table. Question: Where did the author's mother sit when one of her children was away?</p><p>1. She didn't change her chair. 2. She moved her own chair next to Dad's. 3. She moved to an empty chair on the side. 4. She sat opposite to Dad.</p><p>The system return 4 as its answer because the keyword "sat" occurs in it. Normally, to answer this question, we need deep comprehension of the reading document. While all of the sentences are constructively the scene, we know that the answer must be 2 or 3 because candidate answers number 1 and 4 are contradicting the evidence. Further, because there is not enough evidence to answer candidate answer number 2, the most probable answer is candidate answer number 3. However, our system is incapable of constructing this kind of proof. Currently, our features are only based on statistical analysis of keywords that occured in the passage, question, and candidate answer so this type of logical inferences can't be solved. This problem shows that our system needs further refinement in terms of processing, inference, and more knowledge to answer these type of questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>As part of our participation in QA4MRE Pilot Task@CLEF 2013, we have developed QA-system that is simple but lacks in terms of answering more complex question types found in the pilot task. For future work, we believe that it is necessary to use external knowledge such as background knowledge so the system can provide further analysis in classifying questions and determining certain type of strategies to answer the questions. Further work will be focussed on integrating external knowledge derived from sources such as Wikipedia and the background collections by adding more features.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,194.56,262.61,244.02,123.47"><head>Table 1 .</head><label>1</label><figDesc>Result of Participation in Pilot Task</figDesc><table coords="3,194.56,262.61,244.02,106.89"><row><cell></cell><cell cols="4">ID Correct Answer Wrong Answer No Answer c@1 Score</cell></row><row><cell>1</cell><cell>1</cell><cell>4</cell><cell>0</cell><cell>20%</cell></row><row><cell>2</cell><cell>0</cell><cell>5</cell><cell>1</cell><cell>0%</cell></row><row><cell>3</cell><cell>2</cell><cell>3</cell><cell>0</cell><cell>40%</cell></row><row><cell>4</cell><cell>1</cell><cell>4</cell><cell>0</cell><cell>20%</cell></row><row><cell>5</cell><cell>0</cell><cell>5</cell><cell>0</cell><cell>0%</cell></row><row><cell>6</cell><cell>1</cell><cell>4</cell><cell>0</cell><cell>20%</cell></row><row><cell>7</cell><cell>1</cell><cell>4</cell><cell>0</cell><cell>20%</cell></row><row><cell>8</cell><cell>3</cell><cell>2</cell><cell>0</cell><cell>60%</cell></row><row><cell>9</cell><cell>1</cell><cell>4</cell><cell>0</cell><cell>20%</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,138.35,410.58,342.24,7.86;4,146.91,421.54,333.68,7.86;4,146.91,432.50,67.45,7.86" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="4,385.62,410.58,94.97,7.86;4,146.91,421.54,327.33,7.86">Inter Sentence Features and Thresholded Minimum Error Rate Training: NAIST at CLEF 2013 QAMRE</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Arthur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Neubig</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sakti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Toda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Nakamura</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>CLEF</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,138.35,443.46,342.24,7.86;4,146.91,454.42,237.94,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,282.24,443.46,198.35,7.86;4,146.91,454.42,27.04,7.86">An Analysis of the AskMSR Question-Answering System</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Brill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Banko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,207.12,454.42,91.82,7.86">Proceedings of EMNLP</title>
		<meeting>EMNLP</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="257" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,138.35,465.38,342.24,7.86;4,146.91,476.34,273.62,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,366.22,465.38,114.38,7.86;4,146.91,476.34,112.48,7.86">In Question Answering, Two Heads Are Better Than One</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chu-Carroll</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Czuba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Prager</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ittycheriah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,292.80,476.34,51.36,7.86">HLT-NAACL</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="24" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,138.35,487.30,342.24,7.86;4,146.91,498.25,109.84,7.86" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="4,280.20,487.30,200.38,7.86;4,146.91,498.25,33.72,7.86">Overview of the TREC 2006 Question Answering Track 99</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">T</forename><surname>Dang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kelly</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>TREC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,138.35,509.21,342.24,7.86;4,146.91,520.17,94.64,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,190.59,509.21,251.05,7.86">Minimum error rate training in statistical machine translation</title>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">J</forename><surname>Och</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,463.04,509.21,17.55,7.86;4,146.91,520.17,65.98,7.86">Proceedings of ACL</title>
		<meeting>ACL</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,138.35,531.13,342.24,7.86;4,146.91,542.09,333.68,7.86;4,146.91,553.05,104.59,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,248.00,531.13,173.87,7.86">A Simple Measure to Assess Non-response</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rodrigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,445.37,531.13,35.22,7.86;4,146.91,542.09,46.39,7.86">Proceedings of ACL</title>
		<meeting>ACL<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011-06">June 2011</date>
			<biblScope unit="page" from="1415" to="1424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,138.35,561.74,342.24,10.13;4,146.91,574.97,333.68,7.86;4,146.91,585.93,333.68,7.86;4,146.91,596.88,173.75,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,206.15,574.97,274.45,7.86;4,146.91,585.93,104.01,7.86">Overview of QA4MRE at CLEF 2011: Question Answering for Machine Reading Evaluation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Forner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Á</forename><surname>Rodrigo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">F E</forename><surname>Sutcliffe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Forascu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Sporleder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,455.89,585.93,24.70,7.86;4,146.91,596.88,140.35,7.86">CLEF (Notebook Papers/Labs/Workshop</title>
		<editor>
			<persName><forename type="first">V</forename><surname>Petras</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Clough</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,138.35,607.84,342.24,7.86;4,146.91,618.80,200.84,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,187.02,607.84,226.87,7.86">Natural Language Question Answering in Open Domains</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Tufis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,421.43,607.84,59.16,7.86;4,146.91,618.80,110.23,7.86">The Computer Science Journal of Moldova</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="146" to="164" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
