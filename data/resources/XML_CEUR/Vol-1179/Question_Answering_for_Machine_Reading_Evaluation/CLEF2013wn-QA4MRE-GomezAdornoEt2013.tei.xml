<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,151.61,116.95,312.12,12.62;1,173.21,134.89,268.95,12.62;1,257.16,152.82,101.05,12.62">Two Approaches for QA4MRE: Information Retrieval and Graph-based knowledge representation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,191.41,190.52,96.13,8.74"><forename type="first">Helena</forename><surname>Gómez-Adorno</surname></persName>
							<email>helena.gomez@cs.buap.mx</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution" key="instit1">Benemérita</orgName>
								<orgName type="institution" key="instit2">Universidad Autónoma de Puebla Av</orgName>
								<address>
									<addrLine>San Claudio y 14 Sur</addrLine>
									<postBox>.P. 72570</postBox>
									<settlement>Puebla</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,296.11,190.52,51.23,8.74"><forename type="first">David</forename><surname>Pinto</surname></persName>
							<email>dpinto@cs.buap.mx</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution" key="instit1">Benemérita</orgName>
								<orgName type="institution" key="instit2">Universidad Autónoma de Puebla Av</orgName>
								<address>
									<addrLine>San Claudio y 14 Sur</addrLine>
									<postBox>.P. 72570</postBox>
									<settlement>Puebla</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,355.07,190.52,68.89,8.74"><forename type="first">Darnes</forename><surname>Vilariño</surname></persName>
							<email>darnes@cs.buap.mx</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution" key="instit1">Benemérita</orgName>
								<orgName type="institution" key="instit2">Universidad Autónoma de Puebla Av</orgName>
								<address>
									<addrLine>San Claudio y 14 Sur</addrLine>
									<postBox>.P. 72570</postBox>
									<settlement>Puebla</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,151.61,116.95,312.12,12.62;1,173.21,134.89,268.95,12.62;1,257.16,152.82,101.05,12.62">Two Approaches for QA4MRE: Information Retrieval and Graph-based knowledge representation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A548FDF95CD0FD92FDF34A74F52D225C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Question answering system</term>
					<term>reading comprehension</term>
					<term>information retrieval</term>
					<term>graph-based representation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we present our approaches for tackling the QA4MRE 2013 main task. We have built two different methodologies, one based on information retrieval and the other one based on graph representations of the text, additionally we have built a third hybrid methodology combining both of the previous one. The first methodology uses the Lucene information retrieval engine for carrying out information extraction employing additional automated linguistic processing such as stemming, anaphora resolution and part-of-speech tagging. This approach validates the answers based on a textual entailment assessment, lexical and semantic similarity measures. In the second methodology the documents along with its hypotheses are parsed to produce a lexical, morphological and syntactic graph representation. Thereafter, we traverse different paths on the document and the hypothesis in order to find features in those graphs by counting text components (word lemmas, PoS tags, grammatical tags). As a result of this procedure, we obtain two feature vectors for each traversed path. Finally, a cosine based similarity is calculated over the feature vectors in order to select the correct hypothesis.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper we present the experiments carried out as part of the participation in the main task of QA4MRE@CLEF 2013. The QA4MRE task is associated with the ability of a system to understand the main ideas established in a given text. The task consists of reading a document and identifying answers for a set of questions about the information that is expressed or implied in the text. The questions are written in the form of multiple choices; each question has 5 different options, and only one option is the correct answer. The detection of the correct answer is specifically designed to require various types of inference, and the consideration of prior knowledge acquired from a collection of reference documents <ref type="bibr" coords="2,184.65,131.95,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="2,196.83,131.95,7.01,8.74" target="#b1">2]</ref>. Answering a question about a given text in an automatic way to evaluate the understanding of that text, is a very difficult task that oftenly has been tackled in the literature through some Natural Language Processing (NLP) techniques, such as Question Answering (QA). Information retrieval and QA are related, however, QA assumes that given a query, the result must be the correct answer of that question, instead of a number of references to documents that contain the answer.</p><p>The main idea behind QA4MRE task is to answer questions based on a single document. This approach is different from that of traditional QA systems, in which they have a very large corpus for searching the requested information, which implies in some cases a very different system architecture.</p><p>Since the first edition of this task in 2011, and later in the 2012, it has provided a single evaluation platform for the experimentation with new techniques and methodologies towards giving a solution to this problem. In this sense we can take the systems presented in this conference as state-of-the-art work for this research field.</p><p>The rest of the paper is organized as follows. Section 2 describes the Developed Approaches. Section 3 presents the evaluation results in the collection of documents of the QA4MRE task at CLEF 2013. Finally, Section 4 presents the conclusions obtained, so that it outlines some future work directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Developed Approaches</head><p>We have developed two different methodologies for tacking the problem for two languages, English and Spanish. The first one based on Information Retrieval techniques, and the other one is based on text representations by means of graphs. Both of them include a general Document Processing module. In the following sections each of the methodologies are discussed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Document Processing</head><p>This module is executed for both data sets, English and Spanish. An XML parser receives as input a corpus structured in XML format which contains all the documents, along with their respective questions and multiple choice answers, as is shown in Figure <ref type="figure" coords="2,208.52,561.48,3.87,8.74" target="#fig_0">1</ref>. The XML parser extracts the documents, questions and associated answers. It stores the questions and answers identifying them according to the document to which they belong, in order to be used in the following processes. Later, the queries associated to each document are analyzed, applying a Part-Of-Speech (POS) tagger in order to identify the "question keywords" (what, where, when, who, etc.), and the result is passed to the hypothesis generation module. Thereafter, hypothesis generation module receives the set of questions with their multiple choice answers, previously processed. We construct what we means hypothesis as the concatenation of the question with each of the possible answers. This hypothesis is intended to become the input to the Information Retrieval (IR) module, i.e., the query, as well as to the graph generation module. In order to generate the hypothesis, first the "question keyword" is identified and subsequently replaced by each of the five possible answers, thereby obtaining five hypotheses for each question. For example, given the question: Who is the founder of the SING campaign?. And a posible answer: Annie Lennox. The obtained hypothesis is: Annie Lennox is the founder of the SING campaign. Afterwards, we perform anaphora resolution for the English documents associated with the questions using the JavaRAP<ref type="foot" coords="3,344.38,424.78,3.97,6.12" target="#foot_0">1</ref> system. It has been observed that applying anaphora resolution in QA systems improves the results obtained, in terms of precision <ref type="bibr" coords="3,227.08,450.27,9.96,8.74" target="#b2">[3]</ref>.</p><p>The output of this module is the set of hypotheses along with its reference documents. These sets are the input for the two approaches previously mentioned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Information Retrieval Approach</head><p>The Information Retrieval approach consists of the following two submodules: Information Retrieval (IR) and Answer Validation. Both submodules are illustrated in the Figure <ref type="figure" coords="3,224.90,562.48,3.87,8.74">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Information Retrieval module</head><p>The IR module was built using the Lucene<ref type="foot" coords="3,331.25,613.10,3.97,6.12" target="#foot_1">2</ref> IR library. It is responsible for indexing the document collection, and for the further passage retrieval, given a query. Each hypothesis obtained in the hypothesis generation module is processed in order to identify the query keywords, removing stop words (using the stop word list of python NLTK<ref type="foot" coords="4,222.01,297.67,3.97,6.12" target="#foot_2">3</ref> ). Every processed hypothesis is sent to the IR module. The IR module returns a relevant passage for each hypothesis. This passage is used as a support text to decide whether or not the hypothesis can be the right answer. For each hypothesis the first passage returned is taken (only one), which is considered the most important one. This process generates a pair "Hypothesis + Passage (H-P )", along with a lexical similarity score calculated by lucene.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Answer validation module</head><p>The answer validation module aims to assign a score based on the textual entailment judgment to the pair H-P generated in the Information Retrieval module. In addition to the Textual Entailment process a semantic similarity measure is calculated over the H-P pair.</p><p>It has been proven that the textual entailment judgment may improve the performance of the hypothesis validation, given a support text, which in this case is the retrieved passage <ref type="bibr" coords="4,241.76,460.36,7.75,8.74" target="#b3">[4]</ref><ref type="bibr" coords="4,249.51,460.36,3.87,8.74" target="#b4">[5]</ref><ref type="bibr" coords="4,253.38,460.36,7.75,8.74" target="#b5">[6]</ref>. The aim of this module is to obtain the textual entailment judgment over all the H -P pairs that it receives as input. In order to determine whether or not the passage P implies an hypothesis H, we implemented an approach based in an research work <ref type="bibr" coords="4,336.85,496.22,13.54,8.74" target="#b6">[7]</ref> presented in the Crosslingual Textual Entailment task of the SEMEVAL-2012 <ref type="foot" coords="4,343.90,506.60,3.97,6.12" target="#foot_3">4</ref> . In this work the set provided in that conference is used as a training data. The textual entailment judgment is performed over the hypotheses-passages set as test data.</p><p>For this particular problem all the previously developed models were tested, determining that the best performance is obtained when the following 29 features are used: the number of n-grams of words (n = 1, • • • , 4) and characters (n = 1, • • • , 5), which share each pair of sentences and the number n-grams of words (n = 1, • • • , 4) and characters (n = 1, • • • , 5) that are in the hypothesis and not in the support text and viceversa. In addition, the length of both sentences are included to the feature set, since it has been proven to help to obtain the textual entailment judgment. Given that this problem can be seen as a classification one, after several experiments, it was decided to use a 4-layer neural network, using the WEKA<ref type="foot" coords="5,210.23,130.37,3.97,6.12" target="#foot_4">5</ref> data mining tool.</p><p>The SemanticSimilarity measure used in this work <ref type="bibr" coords="5,375.28,145.17,10.52,8.74" target="#b7">[8]</ref> gives a weight to each word of the sentence in terms of the degree of specificity of the word. For example the words catastrophe and disaster gain more weight than words could and should. The similarity inter-words for both sentences is integrated into this measure. The three similarity word-to-word measures proposed are Knowledgebased Measures, based on the Wordnet taxonomy (path, lin and wup)).</p><p>The similarity between the pair H y P is given by the equation 1</p><formula xml:id="formula_0" coords="5,148.99,234.30,331.60,42.51">sim(H, P ) = 1 2 ( ∑ w ϵ {H} (maxSim(w, P ) * idf (w)) ∑ w ϵ {H} idf (w) + ∑ w ϵ {P } (maxSim(w, H) * idf (w)) ∑ w ϵ {P } idf (w) ) (1)</formula><p>For the Answer Selection process, we have developed a method based on the following rules:</p><p>1. Check the entailment judgment between the hypothesis and the recovered passage. If the judgment is "no entailment", in the five hypotheses then this algorithm discards this answer, in other case, the lexical similarity score obtained by Lucene is used. 2. For each question, the answer obtaining the highest sum of scores is selected</p><p>as the correct answer. 3. Finally, we check the Lucene score, and if the score is lower than 0.1 and higher than 0.0 we answer the question with the option "5) None of the above"; if the score is equal to 0.0 the question is not answered.</p><p>The reason for discarding the hypothesis with "no entailment" judgment is that even thought the IR module returned a passage for the hypothesis, this one does not share sufficient information to support the selection of that hypothesis as the correct answer to the question. The use of the lexical similarity score obtained by lucene allows the system to determine which answer is more similar with its support text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Graph-based Knowledge Extraction Approach</head><p>For many problems in natural language processing, a graph structure is an intuitive, natural and direct way to represent the data.There exist several research works that have employed graphs for text representation in order to solve some particular problem <ref type="bibr" coords="5,219.81,609.58,9.96,8.74" target="#b8">[9]</ref>. The Graph-based Knowledge Extraction Approach consists of the following two submodules: Graph Generation and Answer Validation. Both submodules are illustrated in the Figure <ref type="figure" coords="5,338.15,633.49,3.87,8.74">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph Generation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Syntactic</head><p>Level Tagger</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Morphological Level Tagger</head><p>Lexical Level Graph Generation module This module receives the set of hypotheses along with its associated documents from the Document Processing module. Text documents along with its hypotheses are parsed to produce their graph-based representation. For the graph-based representation we took into account the different linguistic levels (lexical, syntactic, morphologic and semantic) in order to capture the majority of the features presented in the text. By including those linguistic analysis we attempt to represent how different text components (words, phrases, clauses, sentences, etc) are related.</p><formula xml:id="formula_1" coords="6,288.94,174.36,7.48,42.81">-------- -------- -------- -------- -------- -------- -------- --------</formula><p>The process of the graph generation is described by the following submodules:</p><p>The Syntactic Level Parser is the base for the Graph-based representation.</p><p>At the syntactic level we deal with rules and principles that govern the structure of a given text. Different syntactic-based parsers exist in literature, however, for the purposes of this work, we use the Stanford Dependency Parser 6 for the English language set, and Freeling 7 for the Spanish language set. In this type of parsing, we may take advantage of the grammatical relation obtained between two components of the sentence. The Morphologic Level Parser deals with the identification of the morpheme's structure of a given language and others linguistic units, such as word's roots, affixes, Part-Of-Speech(POS) tags. With the aim of introducing these morphological components to the proposed representation, we have used the Stanford Log linear Part-Of-Speech Tagger 8 (English) and Freeling (Spanish) in order to obtain the POS tags. Furthermore, the Lancaster stemmer algorithm was used in order to obtain truncated words. The Lexical Level At this level we deal with words, one of the most basic text units, describing their meaning in relation to the physical world or to abstract concepts, without reference to any sentence in which they may occur.</p><p>As a result of this process, each document is represented as a tree rooted in a ROOT -0 node, and branches to sub-trees that represent all the sentences in the document. The nodes of the tree represent the word lemmas of the sentences along with its part-of-speech tag. The branches represent the dependency tag between the two connecting nodes, and a frequency label established as the number of occurrences of the pair (initial node, final node) in the graph plus the frequency of the dependency tag of the same pair of nodes. In the same way the hypotheses are represented as a tree with the same characteristics as well.</p><p>In Figure <ref type="figure" coords="7,193.28,250.02,4.98,8.74" target="#fig_1">4</ref> we show the graph-based representation for the hypothesis "Annie Lennox is the founder of the SING campaign", whereas, Figure <ref type="figure" coords="7,445.60,261.98,4.98,8.74">5</ref> shows the graph-based representation for the first sentences of the reference document associated to the given question. In the Features Extractor module, the process start by fixing the root node of the hypothesis graph as the initial node, whereas the final nodes selected correspond to the rest nodes of the hypothesis graph. We have used the DijkstraAlgorithm <ref type="bibr" coords="7,134.76,501.61,15.50,8.74" target="#b9">[10]</ref> for finding the minimum path between the initial and each final node. Thereafter, we count the occurrences of all the multi-level linguistic features considered in the text representation such as part-of-speech tags and dependencies tags found in the path. The same procedure is performed with the document graph, using as initial and final node the pair of words identified in the hypothesis. As a result of this procedure, we obtain two set of feature vectors: one for the answer hypothesis, and another one for the reference document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Answer Validation module</head><p>The answer validation module receives the set of vectorial features ( -→ f t,i ) for each text. Thus, the reference document d will now be represented by m feature vectors (d</p><formula xml:id="formula_2" coords="7,328.26,625.82,106.58,15.57">* = { --→ f d,1 , --→ f d,2 , ..., --→ f d,m }),</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>as well as the answer hypothesis h (h</head><formula xml:id="formula_3" coords="7,258.33,639.24,106.60,15.58">* = { --→ f h,1 , --→ f h,2 , ..., --→ f h,m })</formula><p>, being m, the number of different paths that may be traversed in both graphs, using the ROOT-0 vertex as the initial node and each one of the words appearing in the hypothesis as the final node.</p><p>Since each path of the answer hypothesis contains exactly the same number and types of components than the reference document, it is possible to calculate the degree of similarity among each path traversed. For the purposes of this study case, we have used the cosine similarity measure, which is calculated as shown in Eq. 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>cosine(d, h) = cosine(d</head><formula xml:id="formula_4" coords="8,308.61,427.34,171.98,32.57">* , h * ) = m ∑ i=1 -→ f h,i • -→ f d,i ∥ -→ f h,i • -→ f d,i ∥<label>(2)</label></formula><p>After obtaining all the similarity scores for the five hypothesis of one question, the hypothesis achieving the highest score is selected as the correct answer. For the experiments carried out with this methodology we have decided to answer every question. The only case in which the question is not answered is when the similarity score is 0.0, but this case only occurred in the Spanish language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental results</head><p>This section describes the data sets used for evaluating the methodologies proposed in this paper. Additionally, the results obtained in the experiments carried out are reported and discussed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Corpus Description -QA4MRE task 2013</head><p>The features of the test dataset are detailed in Table <ref type="table" coords="8,368.84,633.21,3.87,8.74" target="#tab_2">1</ref>.</p><p>It is worth to mention that this year The data set was composed of a total of 284 questions of which: The difference between main and auxiliary questions resides in the presence of a inference. In fact an auxiliary question is just a duplicate of a main question minus the inference. The idea is that the simpler versions (auxiliary) could be added to a main questions: if a system gets the difficult version wrong and the easy version right, it could be that it could not perform the required inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Obtained Results</head><p>The main measure used in this evaluation campaign is c@1, which is defined as shown in equation 3. This measure is defined in the QA4MRE task at CLEF 2011 with the purpose of allowing the systems to decide whether or not to answer a given question. The aim of this procedure is to reduce the amount of incorrect answers, maintaining the number of correct ones.</p><formula xml:id="formula_5" coords="9,258.33,473.32,222.26,22.31">c@1 = 1 n (n R + n U n R n )<label>(3)</label></formula><p>where: n R : number of correctly answered questions. n U : number of unanswered questions. n: total number of questions.</p><p>We have sent seven runs for the English language data set and three runs for the Spanish language data set. Table <ref type="table" coords="9,294.49,573.25,4.98,8.74" target="#tab_3">2</ref> present the obtained results of all runs for both languages on the main questions set. The column N oA indicates the number of answered questions, the column N oU shows the number of unanswered questions, the column P cD represents the percentage of correctly discarded answers and finally the c@1 measure.</p><p>In particular, the runs: buap1301enen, buap1309enen were executed using the IR Approach. The difference relies in the addition of the semantic similarity measure to the buap1309enen run and all questions are answered in this run.</p><p>The inclusion of the semantic similarity measure allows to overcome the results of the buap1301enen run, but, it could achieve a better performance if we would included the "no answer" rules.</p><p>The runs: buap1302enen and buap1310enen were executed using the Graphbased Approach, with the difference of the algorithm for obtaining the shortest path between an initial and a final node. The buap1302enen run uses the Dijkstra Algorithm, while the buap1310enen uses All shortest path Algorithm, both implemented in the N etworkx 9 tool of Python. This methodology attempts to find the similarity between the hypothesis and the complete document, without the use of IR or NLP techniques. The purpose of using this methodology was to test a framework for this particular task, but it is still a basic approach which can be improve including others pre processing techniques such as question analysis, and inferences mechanisms, and add more elements to the graph, like named entity recognition, semantic relations (synonyms, hyponyms and hyperonyms).</p><p>The runs: buap1303enen and buap1304enen are executed using a hybrid approach. It means, we mix the IR approach with the Graph-based approach. With the IR system we recovered 5 passages for each hypothesis, which we use instead if the reference document in order to find the similarity measure using the Graph-based Approach. The rest of the methodology is maintained the same. The run buap1304enen include the validation for detecting if none of the candidate answer is correct. Finally, the run buap1305enen is a voting system between buap1301enen, buap1302enen and buap1304enen. If two of the three candidates respond the same answer for a given question, that answer is selected. In other case, the question is not respond. For the Spanish language, we have sent one run buap1306eses using the Graph-based Approach and the other two runs buap1307eses and buap1308eses 9 http://networkx.github.io/ using the hybrid Approach, similar to the English language runs. The best performance was obtained by the Graph-based Approach in contrary with the English results.</p><p>Table <ref type="table" coords="11,177.98,156.93,4.98,8.74" target="#tab_4">3</ref> present the obtained results of all runs for both languages on the auxiliary + main questions set. In this table we can observe that the results are higher than the other one. This means that our system is not able to perform the inference needed to solve the more difficult questions. The results behavior is similar to the results of the main questions data set. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and Future Work</head><p>We have developed two different methodologies plus a third hybrid one, as a part of our participation of the QA4MRE task 2013. The first one was built using a basic IR Approach, the second one was built by means of graph-based representations and feature extraction, finally the third hybrid approach is a combination of the two firsts approaches.</p><p>In particular we have sent ten different runs. Our best performance for the English language data set was obtained with the IR Approach, while the hybrid approach was a little bit lower. In the case of the Spanish language the Graphbased approach brings the bests results.</p><p>We consider that, even though, the Graph methodology did not achieve the bests results for the English language, it is an interesting framework to represent documents and it could be improve by adding particular characteristics of this task, such as, question analysis, question expansion (by synonym, hyponym,etc), and some improve mechanisms to allow us to detect whether to answer or not a given question.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,222.10,370.18,171.16,7.89"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Document Processing Architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,134.76,409.78,345.82,7.89;7,134.76,420.77,84.54,7.86"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Graph-based representation of the hypothesis "Annie Lennox is the founder of the SING campaign"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="8,180.30,297.43,254.76,7.89"><head>9 Fig. 5 .</head><label>95</label><figDesc>Fig. 5. Graph-based representation for one reference document</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,221.78,117.18,165.86,122.64"><head>Information Retrieval Information Retrieval Hypothesis + Retrieved Passage + IR score Answer Selection Final Answer Answer Validation Textual Entailment Hypotheses Documents Semantic Similarity Fig. 2. Information Retrieval Approach</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,140.99,116.91,289.46,177.26"><head>Table 1 .</head><label>1</label><figDesc>Features of the test dataset</figDesc><table coords="9,140.99,138.23,289.46,155.94"><row><cell>Features</cell><cell>2013</cell></row><row><cell>1. Topics</cell><cell>4</cell></row><row><cell>2. Topic details</cell><cell>Climate Change,</cell></row><row><cell></cell><cell>Music &amp; Society,</cell></row><row><cell></cell><cell>Alzheimer and AIDS</cell></row><row><cell>2. Reading tests (documents)</cell><cell>4</cell></row><row><cell>3. Questions per document</cell><cell>15/20</cell></row><row><cell>4. Multiple-choice answers per question</cell><cell>5</cell></row><row><cell>5. Total of questions</cell><cell>240/320</cell></row><row><cell>6. Total of answers</cell><cell>1200/1600</cell></row><row><cell>-240 are main questions</cell><cell></cell></row><row><cell>-44 are auxiliary questions</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="10,186.01,429.43,243.33,164.85"><head>Table 2 .</head><label>2</label><figDesc>Table of results Evaluation on the main questions.</figDesc><table coords="10,216.17,452.49,183.01,141.79"><row><cell>Description</cell><cell cols="4">NoA NoU PcD c@1</cell></row><row><cell cols="3">English Data Set</cell><cell></cell></row><row><cell cols="2">buap1301enen 221</cell><cell>19</cell><cell cols="2">0.84 0.27</cell></row><row><cell cols="2">buap1309enen 240</cell><cell>0</cell><cell cols="2">0.00 0.28</cell></row><row><cell cols="2">buap1302enen 240</cell><cell>0</cell><cell cols="2">0.00 0.20</cell></row><row><cell cols="2">buap1310enen 240</cell><cell>0</cell><cell cols="2">0.00 0.19</cell></row><row><cell cols="2">buap1303enen 240</cell><cell>0</cell><cell cols="2">0.00 0.24</cell></row><row><cell cols="2">buap1304enen 240</cell><cell>0</cell><cell cols="2">0.00 0.25</cell></row><row><cell cols="2">buap1305enen 198</cell><cell>42</cell><cell>0.7</cell><cell>0.24</cell></row><row><cell cols="3">Spanish Data Set</cell><cell></cell></row><row><cell cols="2">buap1306eses 233</cell><cell>7</cell><cell cols="2">0.86 0.27</cell></row><row><cell cols="2">buap1307eses 238</cell><cell>2</cell><cell cols="2">1.00 0.24</cell></row><row><cell cols="2">buap1308eses 238</cell><cell>2</cell><cell cols="2">1.00 0.23</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="11,159.64,238.87,296.06,165.35"><head>Table 3 .</head><label>3</label><figDesc>Table of results Evaluation on all questions (main + auxiliary).</figDesc><table coords="11,214.69,262.43,185.96,141.79"><row><cell>Description</cell><cell cols="3">NoA NoU PcD. c@1</cell></row><row><cell></cell><cell cols="2">English Data Set</cell></row><row><cell cols="2">buap1301enen 264</cell><cell>20</cell><cell>0.80 0.33</cell></row><row><cell cols="2">buap1309enen 284</cell><cell>0</cell><cell>0.00 0.31</cell></row><row><cell cols="2">buap1302enen 284</cell><cell>0</cell><cell>0.00 0.24</cell></row><row><cell cols="2">buap1310enen 284</cell><cell>0</cell><cell>0.00 0.24</cell></row><row><cell cols="2">buap1303enen 284</cell><cell>0</cell><cell>0.00 0.31</cell></row><row><cell cols="2">buap1304enen 284</cell><cell>0</cell><cell>0.00 0.32</cell></row><row><cell cols="2">buap1305enen 240</cell><cell>44</cell><cell>0.70 0.32</cell></row><row><cell></cell><cell cols="2">Spanish Data Set</cell></row><row><cell cols="2">buap1306eses 274</cell><cell>10</cell><cell>0.90 0.30</cell></row><row><cell cols="2">buap1307eses 282</cell><cell>2</cell><cell>1.00 0.28</cell></row><row><cell cols="2">buap1308enen 282</cell><cell>2</cell><cell>1.00 0.28</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,144.73,646.84,244.23,7.86"><p>http://wing.comp.nus.edu.sg/ qiu/NLPTools/JavaRAP.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,144.73,657.80,124.97,7.86"><p>http://lucene.apache.org/core/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,144.73,646.84,65.04,7.86"><p>http://nltk.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,144.73,657.80,190.89,7.86"><p>http://www.cs.york.ac.uk/semeval-2012/task8/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="5,144.73,657.80,159.01,7.86"><p>http://www.cs.waikato.ac.nz/ml/weka/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="6,144.73,635.88,200.73,7.86"><p>http://nlp.stanford.edu/software/lex-parser.shtml</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="6,144.73,646.84,125.76,7.86"><p>http://nlp.lsi.upc.edu/freeling/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7" coords="6,144.73,657.80,186.58,7.86"><p>http://nlp.stanford.edu/software/tagger.shtml</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="12,142.95,141.32,337.63,10.13;12,151.52,154.55,329.07,7.86;12,151.52,165.51,298.81,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,212.66,154.55,267.94,7.86;12,151.52,165.51,72.59,7.86">Overview of qa4mre at clef 2011: Question answering for machine reading evaluation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Forner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Á</forename><surname>Rodrigo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">F E</forename><surname>Sutcliffe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Forascu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Sporleder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,246.24,165.51,166.14,7.86">CLEF (Notebook Papers/Labs/Workshop</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.95,174.20,337.63,10.13;12,151.52,187.42,329.05,7.86;12,151.52,198.38,329.07,7.86;12,151.52,209.34,126.24,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,318.12,187.42,162.46,7.86;12,151.52,198.38,196.97,7.86">Overview of qa4mre at clef 2012: Question answering for machine reading evaluation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Forner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Á</forename><surname>Rodrigo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">F E</forename><surname>Sutcliffe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Sporleder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Forascu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Benajiba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Osenova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,380.50,198.38,100.09,7.86;12,151.52,209.34,88.29,7.86">CLEF (Online Working Notes/Labs/Workshop</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.95,220.30,337.63,7.86;12,151.52,231.26,329.06,7.86;12,151.52,242.22,262.34,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,274.98,220.30,205.60,7.86;12,151.52,231.26,108.42,7.86">Importance of pronominal anaphora resolution in question answering systems</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Vicedo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ferrandez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,292.84,231.26,187.74,7.86;12,151.52,242.22,193.31,7.86">Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics (ACL</title>
		<meeting>the 38th Annual Meeting of the Association for Computational Linguistics (ACL</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="555" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.95,253.18,337.62,7.86;12,151.52,264.14,329.07,7.86;12,151.52,275.10,264.48,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,151.52,264.14,329.07,7.86;12,151.52,275.10,38.41,7.86">A hybrid question answering system based on information retrieval and answer validation</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pakray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">C</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bandyopadhyay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">F</forename><surname>Gelbukh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,211.92,275.10,166.14,7.86">CLEF (Notebook Papers/Labs/Workshop</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.95,286.05,337.62,7.86;12,151.52,297.01,329.07,7.86;12,151.52,307.97,126.24,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,174.81,297.01,192.24,7.86">Question answering system for qa4mre@clef 2012</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pakray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bandyopadhyay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">F</forename><surname>Gelbukh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,387.18,297.01,93.42,7.86;12,151.52,307.97,88.29,7.86">CLEF (Online Working Notes/Labs/Workshop</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.95,318.93,337.63,7.86;12,151.52,329.89,281.76,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,292.66,318.93,187.92,7.86;12,151.52,329.89,35.26,7.86">An entailment-based approach to the qa4mre challenge</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Harrison</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,208.85,329.89,186.48,7.86">CLEF (Online Working Notes/Labs/Workshop</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.95,340.85,337.63,7.86;12,151.52,351.81,329.06,7.86;12,151.52,362.77,326.23,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,391.21,340.85,89.37,7.86;12,151.52,351.81,213.02,7.86">Buap: Lexical and semantic similarity for cross-lingual textual entailment</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Vilariño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tovar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>León</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Castillo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,388.48,351.81,92.10,7.86;12,151.52,362.77,192.90,7.86">Proceedings of the 6th International Workshop on Semantic Evaluation</title>
		<meeting>the 6th International Workshop on Semantic Evaluation<address><addrLine>Montréal, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.95,373.73,337.63,7.86;12,151.52,384.68,284.12,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,335.34,373.73,145.24,7.86;12,151.52,384.68,143.58,7.86">Corpus-based and knowledge-based measures of text semantic similarity</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Corley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Strapparava</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,316.87,384.68,51.20,7.86">IN AAAI &apos;06</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="775" to="780" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.95,395.64,337.63,7.86;12,151.52,406.60,177.91,7.86" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="12,251.12,395.64,229.46,7.86;12,151.52,406.60,32.08,7.86">Graph-based natural language processing and information retrieval</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Radev</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,417.56,337.98,7.86;12,151.52,428.49,132.53,7.89" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,219.50,417.56,204.54,7.86">A note on two problems in connexion with graphs</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">W</forename><surname>Dijkstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,433.91,417.56,46.68,7.86;12,151.52,428.52,48.38,7.86">Numerische mathematik</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="269" to="271" />
			<date type="published" when="1959">1959</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
