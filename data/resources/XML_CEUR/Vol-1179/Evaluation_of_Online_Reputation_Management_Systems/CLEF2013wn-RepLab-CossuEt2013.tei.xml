<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,241.19,116.95,28.60,12.62">LIA</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,151.78,154.70,79.42,8.74;1,231.20,153.12,1.36,6.12"><forename type="first">Jean-Valère</forename><surname>Cossu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">LIA</orgName>
								<orgName type="institution" key="instit2">Université d&apos;Avignon et des Pays de Vaucluse</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">LSIS</orgName>
								<orgName type="institution" key="instit2">Aix-Marseille University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,241.87,154.70,68.64,8.74;1,310.50,153.12,1.36,6.12"><forename type="first">Benjamin</forename><surname>Bigot</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">LIA</orgName>
								<orgName type="institution" key="instit2">Université d&apos;Avignon et des Pays de Vaucluse</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">LSIS</orgName>
								<orgName type="institution" key="instit2">Aix-Marseille University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,321.17,154.70,78.32,8.74;1,399.49,153.12,1.46,6.12"><forename type="first">Ludovic</forename><surname>Bonnefoy</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">LIA</orgName>
								<orgName type="institution" key="instit2">Université d&apos;Avignon et des Pays de Vaucluse</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">LSIS</orgName>
								<orgName type="institution" key="instit2">Aix-Marseille University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,420.68,154.70,42.90,8.74;1,159.52,166.65,36.00,8.74;1,195.52,165.08,1.36,6.12"><forename type="first">Mohamed</forename><surname>Morchid</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">LIA</orgName>
								<orgName type="institution" key="instit2">Université d&apos;Avignon et des Pays de Vaucluse</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">LSIS</orgName>
								<orgName type="institution" key="instit2">Aix-Marseille University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,206.19,166.65,51.70,8.74;1,257.89,165.08,1.36,6.12"><forename type="first">Xavier</forename><surname>Bost</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">LIA</orgName>
								<orgName type="institution" key="instit2">Université d&apos;Avignon et des Pays de Vaucluse</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">LSIS</orgName>
								<orgName type="institution" key="instit2">Aix-Marseille University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,268.55,166.65,64.06,8.74;1,332.61,165.08,1.36,6.12"><forename type="first">Grégory</forename><surname>Senay</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">LIA</orgName>
								<orgName type="institution" key="instit2">Université d&apos;Avignon et des Pays de Vaucluse</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">LSIS</orgName>
								<orgName type="institution" key="instit2">Aix-Marseille University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,343.27,166.65,68.14,8.74;1,411.41,165.08,1.36,6.12"><forename type="first">Richard</forename><surname>Dufour</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">LIA</orgName>
								<orgName type="institution" key="instit2">Université d&apos;Avignon et des Pays de Vaucluse</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">LSIS</orgName>
								<orgName type="institution" key="instit2">Aix-Marseille University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,422.07,166.65,33.77,8.74;1,172.65,178.61,33.93,8.74;1,206.58,177.03,1.36,6.12"><forename type="first">Vincent</forename><surname>Bouvier</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">LIA</orgName>
								<orgName type="institution" key="instit2">Université d&apos;Avignon et des Pays de Vaucluse</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">LSIS</orgName>
								<orgName type="institution" key="instit2">Aix-Marseille University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,225.41,178.61,123.70,8.74;1,349.11,177.03,1.36,6.12"><forename type="first">Juan-Manuel</forename><surname>Torres-Moreno</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">LIA</orgName>
								<orgName type="institution" key="instit2">Université d&apos;Avignon et des Pays de Vaucluse</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">LSIS</orgName>
								<orgName type="institution" key="instit2">Aix-Marseille University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,379.16,178.61,58.97,8.74;1,438.13,177.03,1.36,6.12"><forename type="first">Marc</forename><surname>El-Bèze</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">LIA</orgName>
								<orgName type="institution" key="instit2">Université d&apos;Avignon et des Pays de Vaucluse</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">LSIS</orgName>
								<orgName type="institution" key="instit2">Aix-Marseille University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,241.19,116.95,28.60,12.62">LIA</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D745CDE3D925C7853540A3DF7C352C0B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present the participation of the Computer Science Laboratory of Avignon (LIA) to RepLab 2013 edition. RepLab is an evaluation campaign for Online Reputation Management Systems. LIA has produced a important number of experiments for every tasks of the campaign: filtering, topic priority detection, Polarity for Reputation and topic detection. Our approaches rely on a large variety of machine learning methods. We have chosen to mainly exploit tweet contents. In several of our experiments we have also added selected metadata. A fewer number of our proposals have integrated external information by using provided links to Wikipedia and users homepage.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>RepLab addresses the challenging problem of online Reputation analysis, i.e. mining and understanding opinions about companies and individuals by extracting information conveyed in tweets. In this context, LIA's participants have proposed several methods to automatically annotate tweets.</p><p>The rest of this article is structured as follows. In section 2, we briefly discuss about datasets and RepLab tasks. In section 3, we present the LIA's submitted systems. Then in section 4, performances are reported before concluding and discussing some future works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data and Tasks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data</head><p>The corpus is a multilingual collection of tweets referring to a set of 61 entities. These entities are spread into four domains: automotive, banking, universities and music/artists. These tweets cover a period going from the 1 st of June 2012 to the 31 st of December 2012. Entities' canonical names have been used as queries http://lia.univ-avignon.fr/ to extract tweets from a larger database. For each entity, at least 2,200 tweets have been collected. The 700 first tweets have been taken to compose the training set, and the other ones are for the test set. Consequently, tweets concerning each of the four tasks are not homogeneously distributed in the datasets. We have selected 8,000 tweets from the training collection to build a development set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Filtering</head><p>The Filtering task consists in identifying, in a stream of tweets, those which are referring or not to a given entity and label these tweets as related or unrelated. For instance in the tweets written in English, systems have to distinguish if a tweet containing the word "U2" correctly refers to the famous music band or not. The lack of context is one of the main issue while processing tweets. These messages count only 140 characters and in many cases the text content is not sufficient to correctly classify a tweet as related or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Polarity for Reputation</head><p>The goal of the task Polarity for Reputation is to find if a tweet contains a positive, negative or neutral statement concerning the reputation of a company. This task is significantly different from a standard sentiment analysis since the objective is to find a polarity about a reputation, without considering if tweet contents are opinionated or not. For example, sentiments known as negative do not always imply a negative polarity for reputation characterization in tweets. We observed that the tweet "We'll miss you R.I.P. Whitney" has been associated with a negative label (the writer is sad because of someone's death), but this is undoubtedly a positive tweet about the reputation of Whitney Houston. Finally, polarity's definition may be really different depending on the considered entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Topic Priority Detection</head><p>In the Topic Priority Detection task, we look for the priority level (alert, mildly important, unimportant) of a topic. Priority classes have been defined as follow:</p><p>1. alert : the topic deserves immediate attention of reputation managers; 2. mildly relevant : the topic contributes to the reputation of the entity but does not require immediate attention; 3. unimportant : the topic can be neglected from a reputation management perspective;</p><p>It seems possible to detect priority levels without processing any new clustering task. Indeed, negative messages typically concern an information requiring a high priority reaction. Negative tweets may therefore be highly correlated with the higher priority level. Again many factors play a role on the understanding of the proposed priority level.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Topic Detection</head><p>Systems used for Topic Detection are asked, in a first time, to find out the main subject of a message and then to cluster related tweets. The objective is therefore to bring together tweets referring to the same subject with regards to a given entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approaches</head><p>In this section we propose descriptions of the LIA's systems used in this edition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">TF-IDF-Gini approach with a SVM classification</head><p>We proposed a supervised classification method based on the Term Frequency-Inverse Document Frequency (TF-IDF) method using the Gini purity criteria coupled with a Support Vector Machines (SVM) classification. The system is composed of two main steps. The first one creates a vector representation of words using a term frequency Okapi/BM25 vector <ref type="bibr" coords="3,366.02,331.32,10.51,8.74" target="#b10">[9]</ref> with the TF-IDF-Gini method <ref type="bibr" coords="3,170.32,343.27,14.61,8.74" target="#b11">[10]</ref>. The second part uses the extracted vectors to learn SVM classifiers. TF-IDF <ref type="bibr" coords="3,188.55,355.31,10.52,8.74" target="#b10">[9]</ref> has been widely used for extracting discriminative words from text. Several works have also reported improvements by using TF-IDF in association with the Gini purity criteria <ref type="bibr" coords="3,309.88,379.22,14.61,8.74" target="#b11">[10]</ref>. SVMs are a set of discriminative supervised machine learning techniques aiming at determining a separation hyperplane <ref type="bibr" coords="3,175.47,403.13,10.52,8.74" target="#b2">[1]</ref> that maximizes the structural margin between training samples.</p><p>Only tweet textual content is used with this approach. Classifiers have been trained with vectorial representation of words in order to automatically assign the most relevant class (for priority and polarity tasks) to a tweet. These tasks require a multi-class SVM classifier. We have chosen the one-against-one strategy and a linear kernel. This method have reported a better accuracy than the oneagainst-rest method [5].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Boosting classification approach</head><p>For the classification tasks, we propose to combine various features extracted from the tweets using a supervised machine learning meta-algorithm: the Boosting <ref type="bibr" coords="3,151.17,549.52,9.96,8.74" target="#b7">[6]</ref>. We chose to use the popular AdaBoost algorithm which is a variation of the classical boosting approach. AdaBoost is a multiclass large-margin classifier based on a boosting method of weak classifiers. The weak classifiers are given as input. They can be the occurrence or the absence of a specific word or n-gram (useful for linguistic features) or a numerical value. At the end of the training process, a list of selected rules is obtained as well as their weights. With this set of rules, a score for each class is computed on each data to classify. The classification tool used is IcsiBoost <ref type="bibr" coords="3,269.09,633.20,9.96,8.74" target="#b9">[8]</ref>, an open source tool based on the AdaBoost algorithm such as the Boostexter software <ref type="bibr" coords="3,321.40,645.16,9.96,8.74" target="#b8">[7]</ref>. IcsiBoost presents the advantage to provide a confidence score between 0 (low confidence) and 1 (very confident) for each instance to classify. This classification process proposes a categorization of the tweets according to its polarity and its priority. It takes into consideration information contained in the tweets: 1. user id; 2. tweet's textual content (bags of 3-grams max.); 3. language; 4. entity id; 5. category; 6. query string (bags of 3-grams max.); Note that the tweet textual content has been normalized with some particular manual rules which mainly consist in separating punctuation from words (ex: "price!" becomes "price !""). We chose to not remove the punctuation from the tweet content because we assume that this information may be useful for polarity and priority classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Cosine distance with TF-IDF and Gini purity criteria</head><p>We proposed a supervised classification method based on a cosine distance computed over vectors built using discriminant features like Term Frequency-Inverse Document Frequency (TF-IDF) <ref type="bibr" coords="4,274.96,367.01,15.50,8.74" target="#b13">[12]</ref> using the Gini purity criteria <ref type="bibr" coords="4,420.74,367.01,14.61,8.74" target="#b14">[13]</ref>. This system consists in two steps. First the text is cleaned by removing hypertext links and punctuation marks and we generate a list of n-grams by using the Gini purity criteria. During this step stoplists (from Oracle.com)<ref type="foot" coords="4,400.78,401.30,3.97,6.12" target="#foot_0">1</ref> for both English and Spanish have been used. In the second step we creates terms (words or n-grams) models for each class by using term frequency with the TF-IDF and Gini criterion. Models also contain specific tags when the second step has not been unable to properly produce feature from a training tweet. A cosine distance measures the similarity of a given tweet by comparing its bag of words to the whole bag built for each class and ranks tweets according to this measure. This classification process takes into account (depending on the task) one or several metadata among: 1. user id; 2. entity id; 3. language;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Continuous Context Models</head><p>Continuous Context Models (CCM) tend to capture and model the positional and lexical dependencies existing between a given word and its context. In this method, the presence in tweets of anchor words is required in order to build context vectors used in CCM. For every given entity of the data set, we consider a predefined set of words including hashtags, "@'s usernames" and other specific terms. These words have been chosen on the training set in order to cover a large number of context examples for each entity.</p><p>According to the procedure formerly presented in <ref type="bibr" coords="5,376.10,143.90,14.61,8.74" target="#b12">[11]</ref>, for one occurrence of a given entity in a tweet, we build one vector. This vector is filled with the relative positions of words in the entity's neighbourhood with reference to the entity's position in the tweet. Vectors are then taken together in order to build a context-to-entity matrix on which we apply a dimension reduction using a Singular Value Decomposition for matrix sparseness reduction. The matrix is then used to train a 2-class SVM classifier <ref type="bibr" coords="5,322.18,215.63,10.52,8.74" target="#b2">[1]</ref> with a linear kernel.</p><p>Continuous Context Models have been used for the filtering task and for polarity and priority classification. For the filtering task, the two classes are respectively composed of vectors extracted from unrelated and related tweets. For the polarity and priority classifications, the strategy is different. For these 3-class problems we have built three classifiers. For example for the polarity classification we have built a positive-versus-not-positive model (no-positive corresponds to negative plus neutral tweets), negative-versus-not-negative and neutral-versusnot-neutral. The same procedure has been used for priority classification. Decision rules for the final class attribution has been learnt on the training data set. We only use tweet text content in this experiments. A normalization consisting in turning upper-case characters to lower-case and removing punctuation marks have been done.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">k-Nearest-Neighbour with discriminant features</head><p>This method can be considered as a very improved version of the baseline. The system tries to match each tweet in the test set with the N most similar tweets in the training set. Tweet similarity is computed using Jaccard measure on the bag-of-words discriminant representation of the tweets. The representation being built from TF-IDF Term Frequency-Inverse Document Frequency <ref type="bibr" coords="5,420.96,454.31,15.50,8.74" target="#b13">[12]</ref> combined with the Gini purity criteria <ref type="bibr" coords="5,266.30,466.26,14.61,8.74" target="#b14">[13]</ref>. The process also takes into account tokens created from the metadata (author, entity-id). A stoplist for both English and Spanish has been used. It contains tool-words and ID from entities which obtained a score equal to 0 with official measures on the development set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Adaptation of the LIA's system used in KBA 2012</head><p>In collaboration with the LSIS, we participated last year to the Knowledge Base Acceleration (KBA) task in TREC 2012 <ref type="bibr" coords="5,321.86,561.47,14.61,8.74" target="#b17">[16]</ref>. The KBA task is very similar to the RepLab filtering and priority sub-tasks: filtering a time-ordered corpus for documents that are highly relevant to a predefined list of 29 entities from Wikipedia and assigning them a degree of priority among central (alert), relevant (mildly important), neutral (related but unimportant) and garbage (unrelated). Even if the definitions are similar, the type of documents studied are different: blogs, forum posts, news and web pages vs. tweets.</p><p>For the KBA task we developed a state-of-the-art approach, which captures intrinsic characteristics of highly relevant documents by mean of three types of features: document centric features, entity's profile features, and time features <ref type="bibr" coords="6,160.46,396.73,14.61,8.74" target="#b18">[17]</ref>. This set of features is computed for each candidate document and, using a classification approach, used to determine if it is related or not to a given entity. A Random Forest classifier have been used in these experiments. One important point of this approach over most KBA 2012 systems is that only one classifier has been trained for all the entities and it has been proven to remains competitive without training data associated to a specific tested entity.</p><p>We want to measure the performances of this approach on another kind of documents and with a minimum of adaption. Features peculiar to the KBA corpus have been removed and no additional features have been built to match the specific features of the RepLab corpus. Feature set is listed in Table <ref type="table" coords="6,451.63,505.72,3.87,8.74" target="#tab_0">1</ref>.</p><p>Filtering task: we have submitted 3 runs for the filtering task:</p><p>-Run 4: Tweets are cleaned : stop-words are deleted as well as @ before a user name and hashtag are split. A classifier is trained on all positive and negative examples for the all set of entities; -Run 5: Similar to Run 4 but a new set of features is computed on web pages pointed by the URLs in the tweet. If the tweet do not contain an URL the value of the corresponding each feature are set to "missing"; -Run 6: Similar to Run 5 but one classifier is trained by type of entities (automotive, universities, banking and music/artists).</p><p>Priority task one run has been submitted for the priority task . It is similar to Run 5 presented above. Two steps are used to associate a priority level to a document: at first documents are tested with a classifier trained on unimportant vs. mildly important/alert examples; then documents which that have not been associated to the unimportant class go through a second classifier trained to separate mildly important documents to alert ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Ultrastemming + n-grams</head><p>For the filtering task, we proposed a supervised classification method based on word n-grams in <ref type="bibr" coords="7,212.03,239.26,15.50,8.74" target="#b15">[14]</ref> and n-ultra stemming in <ref type="bibr" coords="7,344.73,239.26,14.61,8.74" target="#b16">[15]</ref>. Tweets in English and/or Spanish are present in the RepLab corpus. In order to avoid the language detection or the specific strategies to process each language, we use the common information of each words, i.e. their ultra stem. For example, Information and Información share the common 5-ultra stem "Infor". n-ultra stemming is a method of words normalization to further reduce the space of documents representation. We propose to truncate each word to its five initial letters. The algorithm is very simple: we computed 5-ultra stems of i tweets in learning corpus. Then two simple probabilistic language models (LM X ) of n-grams (n = 1, 2, 3) for each class (X=related/unrelated) have been created. We classify each tweet j of the testing set by computing the argmax(x) value over each LM X . The results show that 5-stemming preserves the content information of each tweet, regardless their language, in order to filter the tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8">Maximum a Posteriori Feature Selection</head><p>LIA's topic detection system at first relies on the identification of headwords (HW) characteristic of one topic. HW are words, bigrams, distance bigrams and tweet author selected using a Maximum A Posteriori probability (MAP) estimator. For one theme, we compile one ordered list of HW, ranked considering a purity criterion. An initial choice of features for theme hypothesization is a set HW k for each T k of discriminative theme headwords. In order to have a fair characterization of themes with discriminative word vocabularies, all headword vocabularies have been formed with the same size |HW k |. Vocabularies of different themes may share some headwords.</p><p>In order to attribute a topic to a tweet, we compute the topic contribution of a tweet Y d in each topics T . This topic contribution HW (T k |Y d ) is a sum of contributions of the tweet in the topic coded by the features selected for it. The topic is attributed to the topic with maximum HW contributions. Systems proposed by the LIA for the topic detection vary by the number of features selected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.9">Merging algorithms</head><p>LIA's methods presented above rely on very different approaches and we except that combining systems outputs by the use of merging algorithms to improve the performances of any system taken alone. To this purpose, we have applied merging methods at every tasks except for topic detection. We have used a linear combination of scores, as well as ELECTRE and PROMETHEE algorithms. Seven of our systems have been combined for polarity detection and filtering tasks and six for priority classification.</p><p>Linear combination of outputs scores: We dispose of N systems. For one tweet T of the set set, one system propose an entity label L k with k = 1 . . . 61 and a corresponding output score s j (T i , L k ). We first normalize to 1 the sum of scores provided by a system over the whole test set. The output entity label L is chosen according to</p><formula xml:id="formula_0" coords="8,200.82,263.27,279.77,33.53">γ(T i , L) = k = 1 . . . 61arg max   N j=1 s j (T i , L k )   ,<label>(1)</label></formula><p>ELECTRE method: the objective of this method <ref type="bibr" coords="8,373.05,317.87,15.50,8.74" target="#b19">[18]</ref> is to chose the best system from the entire set of systems. This methods first consists in ranking entity labels comparing to each others by considering how an entity dominates another one. In a second time the method evaluates the rate of systems where this dominance between entity labels appears.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PROMETHEE method:</head><p>The Preference Ranking Organisation METHod for Enrichment Evaluations <ref type="bibr" coords="8,241.96,406.66,15.50,8.74" target="#b19">[18]</ref> is a multi-criteria analysis method. It compare several alternative of actions taken by pair and measure the capacity of an entity label to dominates the others candidates and its capacity of being be dominated by the other ones. It finally creates a ranking of several alternatives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Submissions and results</head><p>Eleven methods compose the LIA's set of submissions. For reading convenience these methods are summed up in Table <ref type="table" coords="8,307.98,508.54,4.98,8.74">2</ref> and refer to a method number used in results table presented above. We now compare our result with regards to the baseline and also to the median score computed over the scores obtained by all the RepLab particpant for a given task.</p><p>Filtering task: most of our runs, ranked according to F-measure in Table <ref type="table" coords="8,457.00,573.43,3.87,8.74">3</ref>, are situated between the median and the baseline. Two systems (nb 1 and nb 4 with a F-measure scores of respectively 0.3819 and 0.3412) have reached performances greater than the baseline. The confidence interval (0.002) shows that in terms of accuracy many systems are equivalent despite of what can be seen according to F-measure. Merging strategies (methods 6, 7 and 8) have not been able to produce good selection rules since their performances remains lower than our best runs taken alone, a selection of best candidates before the merging would  <ref type="table" coords="9,174.50,436.66,4.13,7.89">3</ref>. Submitted runs to Filtering Task ordered according to the F-Measure.</p><p>have been better. Moreover, the differences between entity label distributions of data in training and test sets may introduce some noise during the learning process. We have observed better performances by using a development set where entity label populations are more equally distributed in training and test set.</p><p>Polarity task: performances ranked according to the Pearson correlation are reported in Table <ref type="table" coords="9,215.40,573.43,3.87,8.74" target="#tab_2">4</ref>. One important aspect of polarity systems consists of predicting the average polarity of an entity with respect to other entities. To cover this aspect, correlation is computed between the average polarity of entities versus the reference. This is therefore not necessary to capture the polarity of all tweets to correctly estimate the average polarity. In this task, most of our proposal performances are between the median and the baseline scores. One method (number 1) is over the baseline and reaches a correlation value equal to 0.8799. Here again, systems are very close according to accuracy while it can be re-ally different with the others criterion. For some systems results are far from what was seen on the development set, theses differences come from the label distributions between the data set and rules learned from the training process. Priority Detection task: performances ranked according to F-measure are reported in Table <ref type="table" coords="10,214.05,407.78,3.87,8.74" target="#tab_3">5</ref>. Most of our runs are situated between the median and the baseline values. Method number 1 based on k-NN classification method has obtained a F-measure equal to 0.3351 comparing to 0.2965 reached by the baseline system. Several of our proposal have reached accuracy scores over the baseline but here again merging strategies did not provide better results than the best system. Topic Detection task: one system has been submitted for this task. Performances of runs produced around this method are reported and ranked in terms of F-measure in Table <ref type="table" coords="11,235.11,288.76,3.87,8.74">6</ref>. We can see that all our proposal are greater that the median and the baseline scores with a F-measure equal to 0.2463 for our best system.</p><p>As reported in Table <ref type="table" coords="11,245.25,327.70,4.98,8.74">7</ref> runs 1 &amp; 2 yield a better classification for the class "other topics". and runs 3 and 4 do not consider "other topics" labels. Nevertheless performances are better even if runs 3 &amp; 4 consider a lower number of tweets. In a complementary experiment realized after the campaign we have added a rule consisting in removing this "other topic" tweets from runs 1 &amp; 2. This rules improves the performances and F-measure reaches now 0.2972 (R=0.4648, S=0.2307) for run 1 and 0.2928 (R=0.2763, S=0.3296) for run 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run 1 679</head><p>Run 2 648 419 "other topics" 335 "other topics" 40 "mention of a product" 53 "u2 favourite songs" 36 "u2 favourite songs" 46 "jokes" 30 "second hand selling / buying" 39 "u2 fans" 25 "4square" 37 "4square" 21 "secondhand cars" 36 "second hand selling / buying" 19 "nowplaying"</p><p>35 "mention of a product" Run 3 264 Run 4 193 75 "u2 fans" 36 "nowplaying" 32 "nowplaying" 36 "u2 favourite songs" 31 "u2 favourite songs" 25 "4square" 21 "4square" 24 "u2 fans" 13 "secondhand cars"</p><p>19 "mention of a product" 8 "praise for volvo" 17 "secondhand cars" 7 "mtv" 8 "lyrics" Table <ref type="table" coords="11,215.25,636.10,4.13,7.89">7</ref>. Number of tweet topic well classified in each runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and perspectives</head><p>In this paper we have presented the systems as well as the performances reached by the Computer Science Laboratory of Avignon (LIA) to RepLab 2013. We have presented a large variety of approaches and observed logically a large variety of system performances. We have also proposed several combinations of systems by using different merging strategies in order to benefit from the diversity of information considered by our runs. Our results are globally good and are mostly situated between the median and the baseline, but could still be improved by considering a subset of systems instead of handling system outputs with an equal weight. In other words, new merging strategies will have to be explored. However we did not paid enough attention to label distribution while building this development set. This lead us to introduce some noise in our models and to produce "over-training" rules. Using cross-validation strategies with chopping development would avoid these problems.</p><p>In a future work, we will propose some clustering strategies applied to labels co-occurrence and we will as well considered as a more important feature the users' influence sphere. Indeed, several tweet writer whose tweets are followed a large number of persons should be consider in a different manner than a user never read. Exploring how sentiment in web streams are affected by society and political events and their effects on topic and polarity trends, is also a very challenging question. Many situations may conduct to "swinging opinion states" for instance during a political campaign or depending of press coverage of an event.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,134.77,129.34,348.85,216.83"><head>Table 1 .</head><label>1</label><figDesc>Document centric features, Entity related features and Time features. TFs are normalized by the size of the document if applicable.</figDesc><table coords="6,136.16,129.34,347.46,194.96"><row><cell>T F (e, d)</cell><cell>Term frequency of the entity e in d</cell></row><row><cell>T F 10% (e, d)</cell><cell>Term frequency of e for each 10% part of d</cell></row><row><cell>T F 20% (e, d)</cell><cell>Term frequency of e for each 20% part of d</cell></row><row><cell>C(sent, e, d)</cell><cell>Count of sentences mentioning e</cell></row><row><cell>entropy(d)</cell><cell>Entropy of document d</cell></row><row><cell>length(d)</cell><cell>Count of words in d</cell></row><row><cell>SIM1g(d, sd)</cell><cell>Cosine similarity between d and the entity's Wikipedia article,</cell></row><row><cell></cell><cell>based on unigrams</cell></row><row><cell>SIM2g(d, sd)</cell><cell>Cosine similarity with bigrams</cell></row><row><cell>T F (re, d)</cell><cell>Term frequency of related entities in d</cell></row><row><cell>T F (reL, d)</cell><cell>Term frequency of related entities</cell></row><row><cell></cell><cell>(embedded in links) in d</cell></row><row><cell cols="2">T F (e, d).IDF (e, 1h) Term frequency in d and inverse document frequency for an hour</cell></row><row><cell>DF (e, 1day)</cell><cell>Number of documents with e this day</cell></row><row><cell>DF (e, 7d)</cell><cell>Number of documents with e in 7 days</cell></row><row><cell>V ar(DF (e, 7d))</cell><cell>Variance of the DF in 7 days</cell></row><row><cell>T F (e, 7d)</cell><cell>Term frequency of e in 7 days</cell></row><row><cell>T F (e, title, 7d)</cell><cell>TF of e in titles in 7 days</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="10,144.73,180.62,325.89,139.72"><head>Table 4 .</head><label>4</label><figDesc>Submitted runs to Polarity Task ordered with Pearson correlation.</figDesc><table coords="10,144.73,180.62,325.89,128.81"><row><cell cols="6">Run Id # Method ACCURACY RELIABILITY SENSITIVITY Correlation</cell></row><row><cell>Run 5</cell><cell>1</cell><cell>.6441</cell><cell>.4470</cell><cell>.2681</cell><cell>.8799</cell></row><row><cell>Baseline</cell><cell></cell><cell>.5840</cell><cell>.3151</cell><cell>.2900</cell><cell>.8654</cell></row><row><cell>Run 7</cell><cell>6</cell><cell>.6477</cell><cell>.4978</cell><cell>.1518</cell><cell>.8237</cell></row><row><cell>Run 8</cell><cell>7</cell><cell>.6467</cell><cell>.5125</cell><cell>.1393</cell><cell>.8203</cell></row><row><cell>Run 9</cell><cell>8</cell><cell>.6449</cell><cell>.5200</cell><cell>.1293</cell><cell>.8109</cell></row><row><cell>Run 1</cell><cell>9</cell><cell>.6152</cell><cell>.4779</cell><cell>.0824</cell><cell>.7778</cell></row><row><cell>Run 10</cell><cell>5</cell><cell>.5334</cell><cell>.5009</cell><cell>.0708</cell><cell>.7752</cell></row><row><cell>Run 2</cell><cell>10</cell><cell>.5942</cell><cell>.3410</cell><cell>.0802</cell><cell>.7698</cell></row><row><cell>Run 4</cell><cell>3</cell><cell>.5720</cell><cell>.5509</cell><cell>.0461</cell><cell>.7265</cell></row><row><cell>Median</cell><cell></cell><cell>.5777</cell><cell>.4319</cell><cell>.2192</cell><cell>.7053</cell></row><row><cell>Run 3</cell><cell>2</cell><cell>.5989</cell><cell>.3678</cell><cell>.2709</cell><cell>.6353</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="10,141.17,504.27,333.01,139.72"><head>Table 5 .</head><label>5</label><figDesc>Submitted runs to Priority Task ordered according to the F-Measure.</figDesc><table coords="10,141.17,504.27,333.01,128.81"><row><cell cols="6">Run Id #Method ACCURACY RELIABILITY SENSITIVITY F-MEASURE</cell></row><row><cell>Run 5</cell><cell>1</cell><cell>.6275</cell><cell>.3873</cell><cell>.3155</cell><cell>.3351</cell></row><row><cell>Baseline</cell><cell></cell><cell>.6007</cell><cell>.3049</cell><cell>.3029</cell><cell>.2965</cell></row><row><cell>Run 6</cell><cell>4</cell><cell>.5858</cell><cell>.3156</cell><cell>.2761</cell><cell>.2820</cell></row><row><cell>Run 1</cell><cell>9</cell><cell>.6405</cell><cell>.3760</cell><cell>.2364</cell><cell>.2680</cell></row><row><cell>Run 4</cell><cell>2</cell><cell>.6167</cell><cell>.3168</cell><cell>.2552</cell><cell>.2657</cell></row><row><cell>Run 8</cell><cell>7</cell><cell>.6514</cell><cell>.4129</cell><cell>.2210</cell><cell>.2530</cell></row><row><cell>Run 7</cell><cell>6</cell><cell>.6470</cell><cell>.4349</cell><cell>.2181</cell><cell>.2513</cell></row><row><cell>Run 9</cell><cell>8</cell><cell>.6527</cell><cell>.4143</cell><cell>.2167</cell><cell>.2510</cell></row><row><cell>Median</cell><cell></cell><cell>.5734</cell><cell>.3639</cell><cell>.2069</cell><cell>.2496</cell></row><row><cell>Run 2</cell><cell>10</cell><cell>.5758</cell><cell>.3094</cell><cell>.1089</cell><cell>.1457</cell></row><row><cell>Run 3</cell><cell>3</cell><cell>.5424</cell><cell>.2421</cell><cell>.1284</cell><cell>.1367</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,144.73,657.79,91.72,7.86"><p>http://docs.oracle.com</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="11,169.37,118.78,47.70,7.86" xml:id="b0">
	<monogr>
		<title level="m" coord="11,169.37,118.78,47.70,7.86">Run Id #</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="11,220.14,118.78,225.85,7.86;11,169.37,130.13,24.71,7.86;11,225.77,130.13,9.22,7.86;11,277.23,130.13,20.99,7.86;11,342.26,130.11,24.17,7.89;11,406.01,130.11,24.17,7.89;11,169.37,141.09,24.71,7.86;11,225.77,141.09,9.22,7.86;11,277.23,141.09,20.99,7.86;11,343.85,141.09,20.99,7.86;11,407.60,141.09,20.99,7.86;11,169.37,152.05,24.71,7.86;11,225.77,152.05,9.22,7.86;11,275.64,152.03,24.17,7.89;11,343.85,152.05,20.99,7.86;11,407.60,152.05,20.99,7.86;11,169.37,163.01,24.71,7.86;11,225.77,163.01,9.22,7.86;11,277.23,163.01,20.99,7.86;11,343.85,163.01,20.99,7.86;11,407.60,163.01,20.99,7.86;11,169.37,173.97,29.43,7.86;11,276.30,173.97,21.64,7.86;11,342.93,173.97,21.64,7.86;11,406.66,173.97,21.64,7.86;11,169.37,184.93,33.76,7.86;11,276.31,184.93,21.64,7.86;11,342.92,184.93,21.64,7.86;11,406.67,184.93,21.64,7.86;11,134.77,195.81,25.36,7.89" xml:id="b1">
	<analytic>
		<title/>
		<idno>Run 3 11 .2187 .3468 .2463 Run 2 11 .2342 .2730 .2435 Run 1 11 .3841 .1724 .2280 Run 4 11 .2538 .2222 .2267 Median .3659 .2180 .1954 Baseline .1525 .2173 .1735 Table</idno>
	</analytic>
	<monogr>
		<title level="j" coord="11,220.14,118.78,225.85,7.86">Method RELIABILITY SENSITIVITY F-MEASURE</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,457.46,337.64,7.86;12,151.52,468.42,170.90,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,201.25,457.46,212.13,7.86">Pattern recognition using generalized portrait method</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,432.21,457.46,48.38,7.86;12,151.52,468.42,80.75,7.86">Automation and Remote Control</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="774" to="780" />
			<date type="published" when="1963">1963</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,479.82,337.64,7.86;12,151.52,490.78,329.07,7.86;12,151.52,501.73,18.43,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,320.94,479.82,159.65,7.86;12,151.52,490.78,37.82,7.86">A training algorithm for optimal margin classifiers</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">E</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">M</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,204.88,490.78,223.39,7.86">5th annual workshop on Computational Learning Theory</title>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="144" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,513.13,337.64,7.86;12,151.52,524.09,329.07,7.86;12,151.52,535.05,107.76,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,205.01,513.13,275.59,7.86;12,151.52,524.09,23.57,7.86">Transductive inference for text classification using support vector machines</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,194.81,524.09,170.02,7.86">international Machine learning conference</title>
		<imprint>
			<publisher>Morgan Kaufmann Publishers, Inc</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="200" to="209" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,546.45,337.63,7.86;12,151.52,557.41,329.07,7.86;12,151.52,568.37,57.89,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,151.52,557.41,209.09,7.86">Predicting time series with support vector machines</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Smola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rätsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kohlmorgen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,380.06,557.41,40.04,7.86">ICANN&apos;97</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="999" to="1004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,579.76,337.64,7.86;12,151.52,590.72,276.17,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,292.64,579.76,187.95,7.86;12,151.52,590.72,14.66,7.86">Recent advances of large-scale linear classification</title>
		<author>
			<persName coords=""><forename type="first">G-X</forename><surname>Yuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C-H And</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,183.66,590.72,101.24,7.86">proceedinngs of the IEEE</title>
		<meeting>eedinngs of the IEEE</meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="page" from="2584" to="2603" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,602.12,337.64,7.86;12,151.52,613.08,246.63,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,221.04,602.12,243.44,7.86">The Boosting Approach to Machine Learning: An Overview</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,151.52,613.08,218.84,7.86">Workshop on Non-linear Estimation and Classification</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,624.48,337.64,7.86;12,151.52,635.44,221.96,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,297.08,624.48,183.51,7.86;12,151.52,635.44,56.51,7.86">BoosTexter: A boosting-based system for text Categorization</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yoram</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,225.89,635.44,70.68,7.86">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="135" to="168" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,646.84,337.63,7.86;12,151.52,657.79,272.19,7.86" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Favre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hakkani-Tür</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Cuendet</surname></persName>
		</author>
		<ptr target="http://code.google.com/p/icsiboost,2007" />
		<title level="m" coord="12,354.43,646.84,126.16,7.86;12,151.52,657.79,97.55,7.86">Icsiboost: an opensource implementation of BoosTexter</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,120.67,337.64,7.86;13,151.52,131.63,329.07,7.86;13,151.52,142.59,77.10,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="13,205.95,120.67,274.65,7.86;13,151.52,131.63,29.66,7.86">Understanding inverse document frequency: on theoretical arguments for IDF</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,201.22,131.63,105.15,7.86">Journal of Documentation</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="503" to="520" />
			<date type="published" when="2004">2004</date>
			<publisher>Emerald Group Publishing Limited</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,153.55,337.97,7.86;13,151.52,164.51,241.94,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="13,293.32,153.55,187.27,7.86;13,151.52,164.51,42.35,7.86">An Improved Algorithm of Bayesian Text Categorization</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Shang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,211.54,164.51,76.94,7.86">Journal of Software</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1837" to="1843" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,175.46,337.98,7.86;13,151.52,186.42,329.07,7.86;13,151.52,197.38,78.45,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="13,425.24,175.46,55.35,7.86;13,151.52,186.42,251.18,7.86">Person Name Recognition in ASR outputs using Continuous Context Models</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Bigot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Senay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Linarès</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Fredouille</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Dufour</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,421.62,186.42,58.97,7.86;13,151.52,197.38,52.21,7.86">Proceedings of ICASSP&apos;2013</title>
		<meeting>ICASSP&apos;2013</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,208.34,337.98,7.86;13,151.52,219.30,266.76,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="13,259.24,208.34,217.80,7.86">Term weighting approaches in automatic text retrieval</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,162.28,219.30,165.90,7.86">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="513" to="523" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,230.26,337.97,7.86;13,151.52,241.22,329.07,7.86;13,151.52,252.18,106.11,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="13,397.66,230.26,82.93,7.86;13,151.52,241.22,113.32,7.86">Opinion detection as a topic classification problem</title>
		<author>
			<persName coords=""><forename type="first">J.-M</forename><surname>Torres-Moreno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>El-Beze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bellot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Bechet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,281.90,241.22,108.41,7.86">Textual Information Access</title>
		<imprint>
			<publisher>ISTE Ltd John Wiley and Son</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note>Chapter 9</note>
</biblStruct>

<biblStruct coords="13,142.62,263.14,337.97,7.86;13,151.52,274.09,207.43,7.86" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="13,282.41,263.14,198.18,7.86;13,151.52,274.09,26.53,7.86">Foundations of Statistical Natural Language Processing</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
		<imprint>
			<publisher>The MIT Press</publisher>
			<pubPlace>Cambridge, Massachusetts</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,285.05,337.98,7.86;13,151.52,296.01,290.94,7.86" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="13,244.63,285.05,235.96,7.86;13,151.52,296.01,201.23,7.86">Beyond Stemming and Lemmatization: Ultra-stemming to Improve Automatic Text Summarization in C oRR</title>
		<author>
			<persName coords=""><forename type="first">J.-M</forename><surname>Torres-Moreno</surname></persName>
		</author>
		<idno>, abs/1209.3126</idno>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,306.97,337.98,7.86;13,151.52,317.93,329.07,7.86;13,151.52,328.89,283.25,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="13,200.93,317.93,279.66,7.86">Building an Entity-Centric stream filtering test collection for TREC</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kleiman-Weiner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Niu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Re</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,186.72,328.89,218.84,7.86">Proceedings of the Text REtrieval Conference (TREC)</title>
		<meeting>the Text REtrieval Conference (TREC)</meeting>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,339.85,337.97,7.86;13,151.52,350.81,193.39,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="13,314.81,339.85,165.78,7.86;13,151.52,350.81,125.40,7.86">A Weakly-Supervised Detection of Entity Central Documents in a Stream</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bonnefoy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bouvier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bellot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,295.06,350.81,23.62,7.86">SIGIR</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,361.77,337.97,7.86;13,151.52,372.73,165.87,7.86" xml:id="b19">
	<monogr>
		<title level="m" type="main" coord="13,312.82,361.77,167.77,7.86;13,151.52,372.73,72.05,7.86">Multiple Criteria Decision Analysis: State of the Art Surveys</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Figueira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Greco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ehrgott</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Springer Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
