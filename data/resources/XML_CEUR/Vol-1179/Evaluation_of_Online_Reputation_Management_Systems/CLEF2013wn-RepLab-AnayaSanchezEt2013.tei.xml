<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,145.20,116.95,324.95,12.62;1,177.31,134.89,260.74,12.62">UNED-READERS: Filtering Relevant Tweets using Probabilistic Signature Models</title>
				<funder ref="#_6ZzutQQ">
					<orgName type="full">Spanish Ministry of Science and Innovation</orgName>
				</funder>
				<funder ref="#_2aSmGy3">
					<orgName type="full">Spanish Government (MINECO)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,168.51,172.56,93.39,8.74"><forename type="first">Henry</forename><surname>Anaya-Sánchez</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">IR &amp; NLP Group</orgName>
								<orgName type="institution">UNED</orgName>
								<address>
									<addrLine>Juan del Rosal 16</addrLine>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,270.09,172.56,64.19,8.74"><forename type="first">Anselmo</forename><surname>Peñas</surname></persName>
							<email>anselmo@lsi.uned.es</email>
							<affiliation key="aff0">
								<orgName type="laboratory">IR &amp; NLP Group</orgName>
								<orgName type="institution">UNED</orgName>
								<address>
									<addrLine>Juan del Rosal 16</addrLine>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,361.67,172.56,85.18,8.74"><forename type="first">Bernardo</forename><surname>Cabaleiro</surname></persName>
							<email>bcabaleiro@lsi.uned.es</email>
							<affiliation key="aff0">
								<orgName type="laboratory">IR &amp; NLP Group</orgName>
								<orgName type="institution">UNED</orgName>
								<address>
									<addrLine>Juan del Rosal 16</addrLine>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,145.20,116.95,324.95,12.62;1,177.31,134.89,260.74,12.62">UNED-READERS: Filtering Relevant Tweets using Probabilistic Signature Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">ED81F5CF15144A565DC7B71DF8BB086C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the (usupervised) knowledge-based approach to filter relevant tweets for a given entity that is followed by the UNED-READERS system at RepLab 2013. The approach relies on a new way of contextualizing entity names from relative large and broad collections of texts using probabilistic signature models (i.e., discrete probability distributions of words lexically related to the knowledge or topic underlying set of entities in background text collections). The contextualization is intended to recover relevant information about the entity (specifically, lexically related words) from background knowledge. Results obtained in the filtering task are presented.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In the last few years, Twitter has become an increasingly popular platform for users to communicate with each other by sharing their latest updates in the form of short messages called tweets. <ref type="foot" coords="1,274.47,445.19,3.97,6.12" target="#foot_0">1</ref> Because tweets are compact and fast, Twitter has become widely used to spread and share many kinds of information, such as breaking news, personal updates, spontaneous ideas, or opinions about brands, services, celebrities, etc. <ref type="bibr" coords="1,242.08,482.63,9.96,8.74" target="#b5">[6]</ref>.</p><p>This phenomenon has attracted the attention of information analysts, who see in tweet datasets a valuable input source to carry out a plethora of studies. The large and ever increasing volume of available tweets obliges to make use of automatic methods and tools to interpret and analyze them. Nevertheless, tweets are particularly challenging for being interpreted and analized automatically, since they are shorts piece of texts (i.e., 140 characters) usually posted using a nonstandard language with similarities to SMS style <ref type="bibr" coords="1,366.12,566.32,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="1,378.30,566.32,7.01,8.74" target="#b3">4]</ref>.</p><p>Currently, a major problem concerning the analysis of tweets is that of deciding whether a given tweet containing the name of an entity is actually refering or not to the entity. This is because entity names are often ambiguous. For instance, a tweet containing the word "Ford" might refer to the motor company, but also might be about the Ford Models (the modeling agency), Tom Ford (the film director), etc. <ref type="bibr" coords="1,217.29,638.05,9.96,8.74" target="#b4">[5]</ref>.</p><p>In this paper, we address the above problem by proposing a methodology to contextualize entity names with probabilistic models from relative large and broad text collections, so that a model of these entities can be applied to decide whether a tweet contains or not a reference to a given entity. By "contextualize" we refer to the process of recovering relevant information about the entity (specifically, lexically related words) from background knowledge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Contextualizing Entities with Probabilistic Signature Models</head><p>Given a collection of text documents C = {d 1 , . . . , d N } with vocabulary V = {w 1 , . . . , w M }, we propose to contextualize a set of entity names q = {w i1 , . . . , w in } in the same domain (e.g., automotive, education, music/artists) according to C (∀j ∈ {1, . . . , n}, we assume that w ij ∈ V) by means of a probabilistic signature model; that is, a discrete probability distribution of words lexically related to the knowledge or topic underlying the set of entities in the collection.</p><p>To define such a probabilistic signature model for the text element q (hereafter referred to as the signature model for q), we rely on a posterior probability distribution of words {p(w|q)} w∈V that is defined from the following equation:</p><formula xml:id="formula_0" coords="2,261.61,366.66,218.98,8.74">p(w|q) = p(q|w) p(w)<label>(1)</label></formula><p>where p(w) represents a prior for word w in C, and p(q|w) is a conditional probability estimated from a statistical (stochastic) mapping between words τ = {p(</p><formula xml:id="formula_1" coords="2,150.91,410.66,253.88,14.11">w i |w j )} 1≤i≤M,1≤j≤M (∀j ∈ {1, . . . , M }, M i=1 p(w i |w j ) = 1</formula><p>) that is based on word co-occurrences from local contexts in C, as in <ref type="bibr" coords="2,359.49,425.59,9.96,8.74" target="#b1">[2]</ref>.</p><p>The aim is to base the signature model on the likelihood with which words in the vocabulary V are mapped to (or entail) words in q.</p><p>Nevertheless, as the posterior {p(w|q)} w∈V can actually assign high probability values to either meaningless words (such as prepositions, conjunctions, common verbs, etc.) or words with a relative high prior or frequency in C (for example, ambiguous words with different interpretations in the collection), we propose to learn the signature model that contextualizes q from a refined version of the posterior distribution of words {p(w|q)} w∈V , namely, {p q (w)} w∈V , that is obtained by minimizing the following cross entropy value:</p><formula xml:id="formula_2" coords="2,204.61,556.38,271.74,20.06">H q = - w∈V p(w|q) log (1 -λ) p q (w) + λ p(w) (<label>2</label></formula><formula xml:id="formula_3" coords="2,476.35,556.38,4.24,8.74">)</formula><p>where λ is a mixture weight that accounts for the proportion of "background noise" in {p(w|q)} w∈V and {p(w)} w∈V is a background probability distribution of words (e.g., the distribution of words in C).</p><p>Let z represents the topic underlying q in the context of C. Then, we define the signature model of q as the discrete distribution:</p><formula xml:id="formula_4" coords="2,276.39,657.11,204.20,10.59">s q (w) ∝ p q (w)<label>(3)</label></formula><p>where w ranges over the set of words V q (V q ⊆ V) such that a word w is in V q if both:</p><p>(i) w is among the set of words with the higher probablity values under p q , and (ii) the probability value of including w in z (i.e., p(z|w ) = (1 -λ) p q (w )/((1λ) p q (w )+λ p(w ))) is greater than a threshold (for example, the probability of including w in complement of z that can be defined as p(z|w ) = 1p(z|w )).</p><p>To estimate the refined that minimize H s,q , we rely on an Expectation Maximization procedure that starting from initial values for {p q (w)} w∈V , namely {p (0) q (w)} w , it iteratively approximates the values of {p s (w)} w for each w ∈ V until convergence by means of the following updates in the kth iteration:</p><formula xml:id="formula_5" coords="3,249.75,273.14,230.84,24.72">p (k) q (w) = p(w|q)Z w w p(w |q)Z w<label>(4)</label></formula><p>where Z w is:</p><formula xml:id="formula_6" coords="3,233.07,321.46,247.53,28.51">Z w = (1 -λ) p (k-1) q (w) (1 -λ) p (k-1) q (w) + λ p(w)<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">RepLab 201Results</head><p>From the above formulation of signature models, we devise an (unsupervised) knowledge-based system for filtering tweets as it was asked by the Replab 2013 filtering task <ref type="bibr" coords="3,193.24,413.55,9.96,8.74" target="#b0">[1]</ref>. The RepLab dataset comprises about 105, 000 tweets in the test set, each one containing the canonical name of at least one entity in a selected set of 61 entities from four domains: automotive, banking, universities and music/artists. The source languages of the tweets in this dataset include English and Spanish.</p><p>The idea underlying our system is to consider -as positive evidence-the overlapping between the vocabularies of the tweets and the vocabulary of the topic signature models obtained for the four different sets of entity names that comprise each domain of entities in Replab 2013 (i.e., automotive, banking, universities and music/artists).</p><p>The signature models were obtained by contextualizing each set of entity names according to webtext (a collection of about 1, 700, 000 text documents in English).</p><p>We have submitted the following four runs:</p><p>(1) The system considers only tweets in English, and regards that the input tweet is related to the given entity if it contains at least 2 words in the signature obtained for the corresponding set of domain entities. (2) The system considers only tweets in English, and regards that the input tweet is related to the given entity if it contains at least one word in the signature obtained for the corresponding set of domain entities after removing from the tweet the name of the entity.</p><p>(3) The system considers tweets in any language and regards that the input tweet is related to the given entity if it contains at least 2 words in the signature obtained for the corresponding set of domain entities. (4) The system considers only tweets in any language and regards that the input tweet is related to the given entity if it contains at least one word in the signature obtained for the corresponding set of domain entities after removing from the tweet the name of the entity.</p><p>Since signature models wer obtained from a collection of texts in English, the aim of runs 3 and 4 is to measure the quality of signatures build from an English corpus to filter tweets in Spanish.</p><p>We present the obtained results in terms of the following measures: Precision, Recall, F1(Precision,Recall), Reliability, Sensitivity and F1(Reliability,Sensitivity). The last three of these measures were considered as the official mesaures of Re-pLab 2013 <ref type="bibr" coords="4,183.61,285.25,9.96,8.74" target="#b0">[1]</ref>.</p><p>Tables <ref type="table" coords="4,182.12,297.58,4.98,8.74" target="#tab_0">1</ref> and<ref type="table" coords="4,211.97,297.58,4.98,8.74" target="#tab_1">2</ref> sumarize the results obtained by our four runs. As it can be appreciated, our run relative good values of Precision, Recall and F1 if we take into account that our signature models are base only in English texts. The fact that recall values are lower than those of precision can be explained since the proposed contextualization is base on a completely different collection of documents and in this way the learned models focus on modeling domain aspects rather than typical aspects observed in tweets such as irony and sarcasm-based aspects related to entities.</p><p>It is worth mentioning that our runs are completely unsupervised, and do not use the training data provided to this task at all.</p><p>Results obtained by runs 1 and 2 can not be compared to those ones obtained by runs 3 and 4 because they are applied to different input data. Interestingly, when regarding the official RepLab 2013 measure of Reliability, which is a precision-based measure, it can be seen that the results obtained by runs 3 and 4 are smaller than those obtained by runs 1 and 2 even when the values of Precision of runs 1 to 4 are similar. Besides, these values of Reliability are smaller than those of Sensitivity, which is a recall-based measure, while Recall values are always smaller than Precision values. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,134.77,462.58,345.83,106.17"><head>Table 1 .</head><label>1</label><figDesc>Overall values of Precision, Recall and F1(Precision,Recall) obtained by the different runs of our system.</figDesc><table coords="4,154.37,494.34,306.61,74.41"><row><cell>Run id.</cell><cell>Precision</cell><cell>Recall</cell><cell>F1(Precision,Recall)</cell></row><row><cell>1</cell><cell>0.8946</cell><cell>0.5627</cell><cell>0.6909</cell></row><row><cell>2</cell><cell>0.9112</cell><cell>0.5195</cell><cell>0.6618</cell></row><row><cell>3</cell><cell>0.8915</cell><cell>0.7039</cell><cell>0.7866</cell></row><row><cell>4</cell><cell>0.9038</cell><cell>0.6438</cell><cell>0.7520</cell></row><row><cell>1(vs. test in Eng.)</cell><cell>0.8946</cell><cell>0.7249</cell><cell>0.8009</cell></row><row><cell>2(vs. test in Eng.)</cell><cell>0.9112</cell><cell>0.6693</cell><cell>0.7717</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,134.77,117.41,345.83,213.94"><head>Table 2 .</head><label>2</label><figDesc>Averaged values of Reliability, Sentitivity and F1(Reliability,Sensitivity) obtained by the different runs of our system.In this paper, we have described the UNED-READERS system that participated in the filtering task at RepLab 2013. This knowledge-based system relies on a new way of contextualizing entity names from relative large and broad collections of texts using probabilistic signature models. The learned contexts can be shown useful to model domain vocabulary if we consider the obtained values of Precision and Recall. The submitted system is completely unsupervised. It does not use the training set provided by the competition.</figDesc><table coords="5,134.77,149.16,326.59,87.97"><row><cell>Run id.</cell><cell>Reliability</cell><cell>Sensitivity</cell><cell>F1(Reliability,Sensitivity)</cell></row><row><cell>1</cell><cell>0.3734</cell><cell>0.3162</cell><cell>0.2677</cell></row><row><cell>2</cell><cell>0.3824</cell><cell>0.3305</cell><cell>0.2838</cell></row><row><cell>3</cell><cell>0.1894</cell><cell>0.4191</cell><cell>0.2071</cell></row><row><cell>4</cell><cell>0.1955</cell><cell>0.4339</cell><cell>0.2211</cell></row><row><cell cols="2">4 Conclusions</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,658.44,103.56,7.47"><p>http://www.twitter.com</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. This work has been partially supported by the <rs type="funder">Spanish Ministry of Science and Innovation</rs>, through the project <rs type="projectName">Holopedia</rs> (<rs type="grantNumber">TIN2010-21128-C02</rs>), and by the <rs type="funder">Spanish Government (MINECO)</rs> in the framework of <rs type="programName">CHIST-ERA program</rs> (<rs type="projectName">READERS project</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_6ZzutQQ">
					<idno type="grant-number">TIN2010-21128-C02</idno>
					<orgName type="project" subtype="full">Holopedia</orgName>
				</org>
				<org type="funded-project" xml:id="_2aSmGy3">
					<orgName type="project" subtype="full">READERS project</orgName>
					<orgName type="program" subtype="full">CHIST-ERA program</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,138.35,440.46,342.24,7.86;5,146.91,451.42,333.67,7.86;5,146.91,462.38,333.67,7.86;5,146.91,473.34,333.68,7.86;5,146.91,484.30,87.97,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,442.93,451.42,37.65,7.86;5,146.91,462.38,253.30,7.86">Overview of replab 2013: Evaluating online reputation monitoring systems</title>
		<author>
			<persName coords=""><forename type="first">Enrique</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jorge</forename><surname>Carrillo De Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Irina</forename><surname>Chugur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adolfo</forename><surname>Corujo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tamara</forename><surname>Martín</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Edgar</forename><surname>Meij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Damiano</forename><surname>Spina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,418.26,462.38,62.33,7.86;5,146.91,473.34,210.69,7.86">Fourth International Conference of the CLEF initiative, CLEF 2013</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Springer LNCS</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,495.00,342.25,7.86;5,146.91,505.96,333.68,7.86;5,146.91,516.92,232.03,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,454.60,495.00,26.00,7.86;5,146.91,505.96,333.68,7.86;5,146.91,516.92,28.07,7.86">A language model approach for retrieving product features and opinions from customer reviews</title>
		<author>
			<persName coords=""><forename type="first">Lisette</forename><surname>García-Moya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henry</forename><surname>Anaya-Sánchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rafael</forename><surname>Berlanga-Llavori</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,183.08,516.92,99.81,7.86">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">PrePrints</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,527.62,342.24,7.86;5,146.91,538.57,333.68,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,288.63,527.62,174.70,7.86">Syntactic normalization of twitter messages</title>
		<author>
			<persName coords=""><forename type="first">Max</forename><surname>Kaufmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jugal</forename><surname>Kalita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,146.91,538.57,230.42,7.86">International Conference on Natural Language Processing</title>
		<meeting><address><addrLine>Kharagpur, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,549.27,342.24,7.86;5,146.91,560.23,333.68,7.86;5,146.91,571.19,333.68,7.86;5,146.91,582.15,20.99,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,437.33,549.27,43.26,7.86;5,146.91,560.23,241.48,7.86">Tokenizing micro-blogging messages using a text classification approach</title>
		<author>
			<persName coords=""><forename type="first">Gustavo</forename><surname>Laboreiro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luís</forename><surname>Sarmento</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jorge</forename><surname>Teixeira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eugénio</forename><surname>Oliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,408.52,560.23,72.07,7.86;5,146.91,571.19,248.07,7.86">Proceedings of the fourth workshop on Analytics for noisy unstructured text data</title>
		<meeting>the fourth workshop on Analytics for noisy unstructured text data</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="81" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,592.85,342.24,7.86;5,146.91,603.81,333.68,7.86;5,146.91,614.77,79.86,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,370.23,592.85,110.36,7.86;5,146.91,603.81,183.77,7.86">Discovering filter keywords for company name disambiguation in twitter</title>
		<author>
			<persName coords=""><forename type="first">Damiano</forename><surname>Spina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Enrique</forename><surname>Amigó</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,341.44,603.81,135.15,7.86">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="4986" to="5003" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,625.47,342.24,7.86;5,146.91,636.43,333.68,7.86;5,146.91,647.39,267.83,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,221.56,636.43,242.12,7.86">Comparing twitter and traditional media using topic models</title>
		<author>
			<persName coords=""><forename type="first">Jing</forename><surname>Wayne Xin Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianshu</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jing</forename><surname>Weng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ee-Peng</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hongfei</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaoming</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,146.91,647.39,137.44,7.86">Advances in Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="338" to="349" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
