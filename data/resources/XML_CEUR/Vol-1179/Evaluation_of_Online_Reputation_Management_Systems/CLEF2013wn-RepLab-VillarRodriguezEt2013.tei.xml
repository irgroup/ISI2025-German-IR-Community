<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,127.50,152.87,355.80,12.58">Using Linked Open Data sources for Entity Disambiguation</title>
				<funder ref="#_dQywAAY">
					<orgName type="full">HOLOPEDIA</orgName>
				</funder>
				<funder>
					<orgName type="full">Fundación Centros Tecnológicos Iñaki Goenaga (País Vasco)</orgName>
				</funder>
				<funder ref="#_SatbdPZ">
					<orgName type="full">Regional Government of Madrid under Research Network MA2VIRMR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,123.66,191.41,82.19,7.18"><forename type="first">Esther</forename><surname>Villar Rodríguez</surname></persName>
						</author>
						<author>
							<persName coords="1,141.36,203.23,46.85,7.18"><forename type="first">Optima</forename><surname>Unit</surname></persName>
						</author>
						<author>
							<persName coords="1,221.16,191.41,71.10,7.18"><forename type="first">Ana</forename><forename type="middle">I Torre</forename><surname>Bastida</surname></persName>
						</author>
						<author>
							<persName coords="1,317.82,191.41,39.75,7.18;1,323.94,200.59,27.54,7.18"><forename type="first">Ana</forename><forename type="middle">García</forename><surname>Serrano</surname></persName>
						</author>
						<author>
							<persName coords="1,378.78,191.41,92.83,7.18"><forename type="first">Marta</forename><surname>González Rodríguez</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">OPTIMA Unit</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">ETSI Informática UNED</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">OPTIMA Unit</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,127.50,152.87,355.80,12.58">Using Linked Open Data sources for Entity Disambiguation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">308461DBF6DB01646659C7D115CBCE11</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Within the framework of RepLab 2013, the filtering task try to discover if one tweet is related to one certain entity or not. Our work tries to take advantages of the Web of Data in order to create a context for every entity, extracted from the available Linked Data Sources. The context in Natural Language Processing (NLP) is the outstanding issue able to distinguish the contained semantics in a message by analyzing the frame in which the words are embedded.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Reputation management is used by companies (or individuals) to monitor the public opinions aiming at maintaining a good brand image. The first step is to establish the correct relation between the opinion (text) and the entity with some grade of confidence. This is the objective of the filtering task in RepLab, an initiative promoted by the EU project Limosine focused on the ability to process and understand which the strengths and weaknesses of one entity are, based on users opinions (http://www.limosine-project.eu/events/replab2013). Nowadays there is a large amount of available information on the web, such as web pages, social media data (tweets, facebook and others) or blogs. All of them mention different entities, such as locations, characters, organizations ... The problem appears when a name refers to an entity that have several meanings, for example the song "Munich" of the music group "Editors" and the German city of the same name.</p><p>For this filtering task, our system uses an approach based on the semantic context of an entity. The goal of this work is to create a description of an entity that will help to achieve a, enough complex, semantic context to execute a successful disambiguation. The data sources from where entity descriptions are extracted make up the Web of Data, specifically the Linked Open Data Cloud.</p><p>In this respect, our research has been developed in the frame of Linked Open Data paradigm that is a recommended best practice for exposing, sharing, and connecting pieces of data, information, and knowledge on the Semantic Web using URIs and RDF. Due to activities like this, the volume of data in RDF format is continuously growing, building the known "Web of Data", which today is the largest free available knowledge base. Its size, open access, semantic character and continued growth led us to choose it as our information provider for context generation during the filtering task. This process is carried out using different semantic technologies: such as the SPARQL query language, the ontology definition languages, like RDF, RDFS or OWL and RDF repositories (SPARQL endpoints).</p><p>The main contribution of this paper is the definition of a system that achieves high precision/sensitivity in the tasks of filtering by entities, using semantic technologies to extract context information from the Linked Open Data Sources, as are going to be presented in the following.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Proposed Approach</head><p>In this section, we introduce our approach for filtering entities on tweets. Our procedure uses the semantic context of the analyzed entities, and compares it versus the terms contained in the tweet. First of all the tweets are preprocessed, extracting the terms involved on them. These terms are the input for a second phase, where equivalent available forms for the concepts are obtained by the Stylus<ref type="foot" coords="2,270.24,349.21,3.24,5.83" target="#foot_0">1</ref> tool. When all the possible forms of a term are calculated, the last step consists on generating a semantic context by querying different data sources (modeled by a set of ontologies) that the Linked Open Data Cloud provides to us.</p><p>The section is divided into four parts. First we introduce the motivation to use a semantic context for entities filtering, later we explain the preprocessing phase of the system. In the third subsection we include a description of the generation of the context and finally we resume our filtering algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Motivation</head><p>The main reasons to utilize a semantic context for discovering the relatedness of tweets with the different entities processed are the next two ones:</p><p> Powerful modeling and rendering capabilities offered by ontologies. The ontologies allow us to capture the concepts and properties of a particular domain. It is possible to draw a conceptual structure as detailed and complete as necessary. Furthermore, the process of describing ontologies is simple and straightforward, generating an independent and autonomous model.  The amount of free available semantically represented data (RDF, RDFS, and OWL) into the linked Open Data Cloud. Nowadays the amount of information available in RDF format is huge. The Linked Data paradigm has promoted the Web of Data, formed by the Linked Datasets. This makes possible that any user can obtain information about heterogeneous domains. Consulting these datasets through technologies such as SPARQL or RDF Dumps, the user can get semantic information about concepts or entities using modeling ontologies of different repositories.</p><p>To illustrate the benefits which can give us a semantic context, there is an example here: In the field of reputation analysis of music groups, we consider the following tweet and the studied entity is the group U2:</p><p>"Enjoy a lot in the last concert of the singer Bono"</p><p>At first there is nothing in the tweet that can help us to relate it in a syntactically manner with "U2". But using the semantic context generated for this group of music, we know that among the members of the group, their vocalist is Paul David Hewson, better known by its artistic name "Bono".</p><p>The semantic context allows us to build relationships that lead to U2 from Bono and in this way we deduce that a tweet talking about Bono entity, it also does indirectly about the U2 entity and therefore the tweet and the second entity are related.</p><p>For the extraction of the necessary information for the generation of context, we have considered the data sources and ontologies shown in the The table shows datasets of the four domains used in the task of filtering: music, university, banks and automobile.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Preprocessing of tweets</head><p>This task is in charge of extracting the terms contained in the tweet. Before that the terms are compared with the entities, they need to be pre-processed to remove the typical characteristics of the tweets (#) which can affect the precision. This preprocessing has three main tasks (fig 1 <ref type="figure" coords="3,318.35,577.80,7.40,9.02">):</ref> 1. Removing URL. URLs in this approach are eliminated, because they do not provide value for the comparison in a the semantic context. In future work, we will try to replace the URLs by entities that represent them, and we could even consider the various relationships / links inside the web page that are identified by the URL under study. 2. Removing mentions. For our task, the mentions are not interesting at this moment, because the relationship between them and the content of the tweet is irrelevant.</p><p>3. Tr su be</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Co</head><p>The cont between t The in 1.  This task is performed by consulting different datasets through their corresponding SPARQL endpoint, using SPARQL query language and following the ontologies of each dataset, that depends on the type of entity. An example of a SPARQL query type is described in figure <ref type="figure" coords="5,267.69,198.48,3.74,9.02" target="#fig_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Filtering Algorithm</head><p>In this section, the final version of the complete algorithm is provided. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head><p>The corpus of RepLab 2013 uses Twitter data in English and Spanish. The corpus consists of a collection of tweets (at least 2,200 for each entity) potentially associated to 61 entities from four domains: automotive, banking, universities and music/artists. As result measures, reliability and sensitivity are used <ref type="bibr" coords="5,359.23,637.74,10.64,9.02" target="#b7">[8]</ref>. For a better and deep understanding, the outcomes for this typical binary classification problem (true positives, false positives, true negatives and false negatives) are showed:</p><p>Table <ref type="table" coords="6,306.43,150.27,3.38,8.10" target="#tab_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Predicat ed Class</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Actual Class</head><p> Reliability (also called precision) measures the fraction of retrieved instances which belong to positive class. Reliability = TP / Predicted P = 0,327229 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Related work</head><p>The disambiguation task has become essential when trying to mining the web in the search of opinions. Brands or individuals such as Apple or Bush usually lead to confusions due to their ambiguity and need to be disambiguated as a related or unrelated reference. In many approaches Wikipedia has been used to tackle this challenge by co-reference resolution methods (measuring context similarity through vectors or another kind of metric) <ref type="bibr" coords="6,272.11,521.82,10.88,9.02" target="#b0">[1,</ref><ref type="bibr" coords="6,287.20,521.82,7.22,9.02" target="#b1">2]</ref>. Research has been used to focus on the appearance of a pair of named entities in both texts to come to a conclusion about their interrelation. The problem with Twitter is the shortness of its messages which makes more difficult the comparison (overall considering the usual lack of two coappearing entities). Some works are carried out by mapping name entities to Wikipedia articles and overlapping the context surrounding the entity in the text (the string which is wanted to be disambiguated) <ref type="bibr" coords="6,218.93,605.82,10.64,9.02" target="#b2">[3]</ref>. The systems return the entity which best matches the context.</p><p>This approach, instead, tries to take advantage of Linked Open Data Cloud. A huge open data base where to ask and recover data in a straight way. This avoids scanning unstructured pages and obtaining wrong or disconnected information. Other paper that has been used as corpus, the data extracted from Linked Open Data sources is presented by Hogan et al. <ref type="bibr" coords="6,229.15,677.82,10.61,9.02" target="#b3">[4]</ref>.</p><p>In Natural Language Processing, the Recognizing named entities (NER) is a extensively research field. Typically, the approaches used Wikipedia for explicit disambiguation <ref type="bibr" coords="7,153.27,174.30,10.64,9.02" target="#b4">[5]</ref>, but there are also some examples of how semantics can be used for this task <ref type="bibr" coords="7,144.36,186.30,10.84,9.02" target="#b5">[6,</ref><ref type="bibr" coords="7,158.75,186.30,7.22,9.02" target="#b6">7]</ref>. Both works are based on defining a similarity measure based on the semantic relatedness.</p><p>Hoffart et al. <ref type="bibr" coords="7,190.48,210.30,11.68,9.02" target="#b5">[6]</ref> ] is the most closed approach to our work, because the knowledge base used on their works are Linked Data sources, like DBpedia and YAGO and in our research we also use DBpedia (among others). The main difference is that on our approach we generate a context on which we place the entities in study. Afterwords we check if the text has any relationship with the generated context, instead of using a measure of semantic relatedness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>The results reveal a high value for sensitivity which comes along with a low value for false negatives. This indicates that the system does not usually get wrong classifications and if it concludes that one example is related to one entity it is almost sure that it is correct. The reliability, however, is quite poor due to the fact that the context is very enclosed and thus there are a lot of not found examples (false negative rate). This leads us to think that the context should be widely enriched and this could enlarge the well classified group. So to filter with better precision, the context should contain not only semantic information from Linked Data sources, but also domain concepts such as verbs, idioms or any kind of expressions prone to be good indicators. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Result: TRUE</head><p>These clues could be extracted and treated by means of PLN and IR (Information Retrieval) algorithms. The first ones to preprocess the words (including stemming and disambiguation treatment) and the former in order to find a similarity-based structure for the data so the filtering can be carried out by measuring the distance between the query (actually the relationship related/unrelated) and the tweet according to the clues. Commonly, a data mining process would need to learn from training examples or on the other hand to use some statistical method as the tf-idf scheme or LSI (Latent Semantic Indexing) able to categorize and clustering the concepts most associated to a certain subject For context generation, we will also analyze more refined techniques in the same research line:</p><p>o Improving the semantic context, using a larger number of Linked Datasets, and refining the questions to be sent. In order to improve the questions we plan to delve deeper into the ontologies and thereby expand the scope of the context. o Using other disambiguation techniques that can be combined with our approach, as the information extraction from web pages, cited in the text, the study of hash tags and mentions or using other non-semantic corpuses.</p><p>The combination of all these techniques would allow creating a huge semanticpragmatic context with the valuable distinct feature of not being static, but an increasing and open context fed by Linked Data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,246.60,271.95,23.79,8.10"><head></head><label></label><figDesc>Fig. 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,231.30,577.41,38.52,8.10"><head>Fig. 2 </head><label>2</label><figDesc>Fig. 2. Pro</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,261.96,194.31,27.53,8.10;6,389.51,194.31,35.54,8.10;6,191.10,207.81,27.55,8.10;6,261.96,207.99,43.69,8.10;6,389.53,207.99,38.69,8.10;6,191.10,219.81,35.42,8.10;6,261.96,219.99,44.16,8.10;6,389.52,219.99,44.66,8.10;6,124.68,249.43,345.92,12.26;6,136.02,264.72,158.05,9.02;6,211.32,284.76,155.77,9.02"><head></head><label></label><figDesc>Sensitivity (also called the true positive rate) measures the proportion of actual positives which are correctly classified. Sensitivity = TP / Actual P = 0,944078</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,124.68,459.85,100.79,5.74;7,124.68,467.83,153.59,5.74;7,124.68,475.81,259.19,5.74"><head></head><label></label><figDesc>Entity: Led Zeppeling Tweet: Listening to Led Zeppelin Context: [music, band, concert, instrument,… listen,…]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,124.68,306.30,328.53,130.52"><head>table 1 :</head><label>1</label><figDesc></figDesc><table coords="3,124.68,330.42,328.53,106.40"><row><cell>Dataset Name</cell><cell>Domain</cell><cell></cell><cell>Sparql Endpoint</cell></row><row><cell>DBPEDIA</cell><cell cols="2">General domain.</cell><cell>http://dbpedia.org/sparql</cell></row><row><cell>MusicBranz</cell><cell>Music domain</cell><cell></cell><cell>http://dbtune.org/musicbrainz/sparql</cell></row><row><cell>EventMedia</cell><cell>Media domain</cell><cell></cell><cell>http://eventmedia.eurecom.fr/sparql</cell></row><row><cell cols="3">ZBW Economics Economic domain</cell><cell>http://zbw.eu/beta/sparql/</cell></row><row><cell>Swetodblp</cell><cell cols="2">University bibliog-</cell><cell>http://datahub.io/dataset/sweto-dblp</cell></row><row><cell></cell><cell>raphy domain</cell><cell></cell><cell></cell></row><row><cell>DBLP</cell><cell>University</cell><cell>biblio-</cell><cell>http://dblp.rkbexplorer.com/sparql/</cell></row><row><cell></cell><cell>graphy domain</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,139.92,451.59,315.54,19.08"><head>Table 1 .</head><label>1</label><figDesc>Available datasets and ontologies into Linked Open Data cloud for the studied domains</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,124.68,360.75,298.12,51.50"><head>Table 2 .</head><label>2</label><figDesc>Filtering Results</figDesc><table coords="6,124.68,378.75,298.12,33.50"><row><cell>Run</cell><cell>Reliability</cell><cell>Sensitivity</cell><cell>F(R,S)</cell></row><row><cell>BEST_APPROACH</cell><cell>0,7288</cell><cell>0,4507</cell><cell>0,4885</cell></row><row><cell>UNEDTECNALIA_filtering_1</cell><cell>0,2760</cell><cell>0.2862</cell><cell>0.1799</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,129.96,686.19,124.95,8.10"><p>http://www.daedalus.es/productos/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. This work has been partially supported by the <rs type="funder">Regional Government of Madrid under Research Network MA2VIRMR</rs> (<rs type="grantNumber">S2009/TIC-1542</rs>), and by <rs type="funder">HOLOPEDIA</rs> (<rs type="grantNumber">TIN 2010-21128-C02</rs>). Special thanks to Daedalus for the free licencing to the utilization of Stilus Core. Hereby the authors would like to thank <rs type="funder">Fundación Centros Tecnológicos Iñaki Goenaga (País Vasco)</rs> for the awarded doctoral grant to the first author.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_SatbdPZ">
					<idno type="grant-number">S2009/TIC-1542</idno>
				</org>
				<org type="funding" xml:id="_dQywAAY">
					<idno type="grant-number">TIN 2010-21128-C02</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,132.68,392.07,337.98,8.10;8,141.72,403.05,131.75,8.10" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="8,249.59,392.07,221.07,8.10;8,141.72,403.05,128.04,8.10">Is Hillary Rodham Clinton the President? In ACL Workshop on Coreference and its Applications</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ravin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Kazi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.68,414.09,337.98,8.10;8,141.72,425.07,116.25,8.10" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,312.30,414.09,144.94,8.10">Disambiguation of proper names in text</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Wacholder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ravin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,141.72,425.07,76.56,8.10">Proceedings of ANLP</title>
		<meeting>ANLP</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="202" to="208" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.68,436.05,337.91,8.10;8,141.72,447.09,328.90,8.10;8,141.72,458.07,64.76,8.10" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,397.48,436.05,73.11,8.10;8,141.72,447.09,164.62,8.10">Using encyclopedic knowledge for named entity disambiguation</title>
		<author>
			<persName coords=""><forename type="first">Pasca</forename><forename type="middle">;</forename><surname>Bunescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Razvan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marius</forename><surname>Bunescu</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Pasca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,325.68,447.09,144.94,8.10;8,141.72,458.07,38.76,8.10">EACL. The Association for Computer Linguistics</title>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.68,469.05,337.95,8.10;8,141.72,480.09,328.86,8.10;8,141.72,491.07,206.02,8.10" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,225.86,469.05,244.76,8.10;8,141.72,480.09,172.22,8.10">Scalable and distributed methods for entity matching, consolidation and disambiguation over linked data corpora</title>
		<author>
			<persName coords=""><forename type="first">Aidan</forename><surname>Hogan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,322.50,480.09,148.08,8.10;8,141.72,491.07,110.46,8.10">Web Semantics: Science, Services and Agents on the World Wide Web</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="76" to="110" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.68,502.05,337.88,8.10;8,141.72,513.09,328.91,8.10;8,141.72,524.07,179.96,8.10" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,245.82,502.05,224.73,8.10;8,141.72,513.09,52.48,8.10">Named entity disambiguation by leveraging wikipedia semantic knowledge</title>
		<author>
			<persName coords=""><forename type="first">Xianpei</forename><forename type="middle">;</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,220.26,513.09,250.37,8.10;8,141.72,524.07,84.62,8.10">Proceedings of the 18th ACM conference on Information and knowledge management</title>
		<meeting>the 18th ACM conference on Information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="215" to="224" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.68,535.05,337.97,8.10;8,141.72,546.09,328.87,8.10;8,141.72,557.07,193.06,8.10" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,245.85,535.05,173.51,8.10">Robust disambiguation of named entities in text</title>
		<author>
			<persName coords=""><forename type="first">Johannes</forename><surname>Hoffart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,425.04,535.05,45.61,8.10;8,141.72,546.09,290.49,8.10">En Proceedings of the Conference on Empirical Methods in Natural Language Processing</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="782" to="792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.68,568.05,337.88,8.10;8,141.72,579.09,328.94,8.10;8,141.72,590.07,328.88,8.10;8,141.72,601.05,23.22,8.10" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,245.76,568.05,224.79,8.10;8,141.72,579.09,103.96,8.10">Structural semantic relatedness: a knowledge-based method to named entity disambiguation</title>
		<author>
			<persName coords=""><forename type="first">Xianpei</forename><forename type="middle">;</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jun</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,265.02,579.09,205.64,8.10;8,141.72,590.07,127.71,8.10">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="50" to="59" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.68,612.09,337.90,8.10;8,141.72,623.07,219.47,8.10" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,355.54,612.09,115.04,8.10;8,141.72,623.07,121.11,8.10">A General Evaluation Measure for Document Organization Tasks</title>
		<author>
			<persName coords=""><forename type="first">Enrique</forename><surname>Amigo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gonzalo</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julio</forename><surname>Verdejo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Felisa</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,268.99,623.07,69.68,8.10">Proceedings SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
