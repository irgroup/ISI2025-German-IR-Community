<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,142.71,116.90,329.94,12.68;1,225.76,134.83,163.84,12.68">Filtering and Polarity Detection for Reputation Management on Tweets</title>
				<funder ref="#_KXKJSXM">
					<orgName type="full">European Social Fund</orgName>
				</funder>
				<funder>
					<orgName type="full">European Union</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,231.25,172.50,64.49,8.80"><forename type="first">Viktor</forename><surname>Hangya</surname></persName>
							<email>hangyav@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">University of Szeged</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,318.43,172.50,65.68,8.80"><forename type="first">Richárd</forename><surname>Farkas</surname></persName>
							<email>rfarkas@inf.u-szeged.hu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Informatics</orgName>
								<orgName type="institution">University of Szeged</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,142.71,116.90,329.94,12.68;1,225.76,134.83,163.84,12.68">Filtering and Polarity Detection for Reputation Management on Tweets</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9C4B1C968CE77BA3DE63467AA3150974</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Reputation management</term>
					<term>Sentiment analysis</term>
					<term>Twitter</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we introduce our contribution to the RepLab 2013 -An evaluation campaign for Online Reputation Management Systems challenge. We participated in the filtering and polarity detection subtasks. The task of filtering is to determine whether a tweet is related to an entity. Then we classify tweets into positive, negative or neutral classes from the entity point of view. To solve these problems we employed supervised machine learning techniques. We applied several Twitter specific text preprocessing and features engineering methods. Besides supervised methods, we experimented with incorporating clustering information as well. Our system was ranked 2nd in the filtering task and 1st in the polarity detection task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In the past few years, the popularity of social media has increased. People post messages on a variety of topics for example products, political issues, etc. Thus a big amount of user generated data is created day-by-day. The manual processing of this data is impossible, therefore automatic procedures are needed. Many studies have been made in the area <ref type="bibr" coords="1,291.47,489.68,10.51,8.80" target="#b5">[6,</ref><ref type="bibr" coords="1,303.63,489.68,11.62,8.80" target="#b12">13]</ref>, for example predicting the results of elections <ref type="bibr" coords="1,175.21,501.64,14.61,8.80" target="#b13">[14]</ref>, monitoring brands <ref type="bibr" coords="1,280.46,501.64,10.51,8.80" target="#b8">[9]</ref> or predicting stock price changes <ref type="bibr" coords="1,440.57,501.64,14.61,8.80" target="#b14">[15]</ref>.</p><p>In this paper we introduce our contribution for the RepLab 2013 An evaluation campaign for Online Reputation Management Systems challenge <ref type="bibr" coords="1,440.78,525.55,9.96,8.80" target="#b2">[3]</ref>. Here, the end-user application is monitoring the reputation of several entities, like companies, organizations, celebrities, etc. from Twitter messages. The organizers defined four tasks, namely filtering, polarity classification, topic detection and assigning priority, from which we take part in the first two ones. In the case of the filtering task the goal was to determine which tweets are related to a given entity and which are not, for instance, distinguishing between tweets that contain the word "Stanford" referring to the University of Stanford or to Stanford as a place. This step is necessary as we can ignore the unrelated tweets, so this step could be considered as a preprocessing step. The task of polarity detection is to decide whether a given tweet carries positive, negative or neutral message towards the entity in question.</p><p>The data provided by the organizers of the challenge consists of English and Spanish messages. The data was crawled from 61 entities each from automotive, banking, universities or music/artists domains. The data was collected using the entities canonical names as queries. Besides the train and test databases a set of background tweets were also provided which could be used while preparing our system.</p><p>We created a similar system for the filtering and polarity detection tasks. It is an n-gram based supervised model as it has been shown that it works well on short messages like tweets <ref type="bibr" coords="2,264.24,215.68,10.51,8.80" target="#b0">[1,</ref><ref type="bibr" coords="2,276.41,215.68,7.75,8.80" target="#b4">5,</ref><ref type="bibr" coords="2,285.81,215.68,12.73,8.80" target="#b9">10,</ref><ref type="bibr" coords="2,300.20,215.68,11.62,8.80" target="#b10">11]</ref>. We reduced the size of the dictionary by normalizing the messages. Furthermore we examined novel methods which increased the precision of our classifiers for example specially weighting our features and using the results of topic modeling technologies. In case of the filtering task the official evaluation metric was an F measure calculated from the reliability and sensitivity values <ref type="bibr" coords="2,257.10,275.46,9.96,8.80" target="#b1">[2]</ref>. Besides the organizers provided the accuracy of the participated systems as well. Our system achieved 0.438 F measure in this task which is the second best result from all off the participated systems, and achieved 0.928 accuracy which is the best. In the polarity detection task, the official measure was the accuracy. We achieved an accuracy of 0.685, the highest value among the participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head><p>We employed a unigram model along with tweet-specific normalization techniques. We investigated novel features as well, which increased the accuracy of our classifier. For implementation we used the MALLET toolkit, which is a Java-based package for natural language processing <ref type="bibr" coords="2,362.03,428.01,14.61,8.80" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Normalization</head><p>One reason for the unusually big dictionary size of the standard unigram model is that it contains one word in many forms, for example in upper and lower case, in a misspelled form, with character repetition, etc. On the other hand, it contains various special annotations which are typical for blogging, such as Twitter-specific annotations, URL's, smiles, etc. Keeping these in mind we made the following normalization steps:</p><p>• First, in order to get rid of the multiple forms of a single word we converted them into lower case form then we stemmed them. For this purpose we used the Porter Stemming Algorithm. • We replaced the @ Twitter-specific tag and every URL with the [USER] and</p><p>[URL] notations, respectively. Besides, in case of a hash tag we deleted the hash mark from it, for example we converted #funny to funny. This way we do not distinguish Twitter specific tag from other words. • Smileys in messages play an important role in polarity classification. For this reason we grouped them into positive and negative smiley classes. We considered :), :-),: ), :D, =), ;), ; ), (: and :(, :-(, : (, ):, ) : smileys as positive and negative, respectively. • Since numbers do not contain information regarding a message polarity, we converted them as well to the [NUMBER] form. In addition, we replaced the question and exclamation marks with the [QUESTION_MARK] and [EX-CLAMATION_MARK] notations. After this we removed the unnecessary characters '"#$%&amp;()*+,./:;&lt;=&gt;\^{}~, with the exception that we removed the ' character only if a word started or ended with it. • In the case of words which contained character repetitions -more precisely those which contained the same character at least three times in a row -, we reduced the length of this sequence to three. For instance, in the case of the word yeeeeahhhhhhh we got the form yeeeahhh. This way we unified these character repetitions, but we did not loose this extra information.</p><p>Before the normalization step, the dictionary contained approximately 113, 000 words. After the above introduced steps we managed to reduce the size of the dictionary to 38, 000 words. It is important to mention that we handle English and Spanish tweets the same way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Features</head><p>After normalizing Twitter messages, we investigated feature space for a supervised classifier. In many cases, phrases are important because they can catch aspects of messages that simple unigrams can't. For example "don't like" if we handle the two words separately we lose the knowledge that the negation word refers to the word "like". From this reason we examined the effects of bigrams and trigrams and we realized that bigrams can improve the accuracy of our classifier. However trigrams did not improve our result significantly so we used only bigrams besides unigrams. Furthermore, we added a new feature as well which is the number of negation words in a message.</p><p>We searched for special features which characterize the polarity of the tweets. One such feature is the polarity of each word in a message. To determine the polarity of a word, we used the SentiWordNet sentiment lexicon <ref type="bibr" coords="3,436.17,512.42,9.96,8.80" target="#b3">[4]</ref>. In this lexicon, a positive, negative and an objective real value belong to each word, which describes the polarity of the given word. We created three new features for each tweet which are the sum of the positive, negative and objective values divided by the number of words in a message.</p><p>For handling acronyms, we used an acronym lexicon which can be found on the www.internetslang.com website. For each acronym we separately summed up the positive and negative values of each word in the description of the acronym and we normalized them by the number of words in the description. Then for each tweet we added two new features which are the sums of the positive and negative values of the acronyms in the message divided by the number of acronyms.</p><p>Our intuition was that people like to use character repetitions in their words for expressing their happiness or sadness. Besides normalizing these tokens (see Section 2.1), we created a new feature as well, which represents the number of this kind of words in a tweet.</p><p>Beyond character repetitions people like to write words or a part of the text in upper case in order to call the reader's attention. Because of this we created another feature which is the number of upper case words in the given text.</p><p>Since the task is to filter tweets related to given entity and to classify them by their sentiments, we found it important to sign whether the message contains the mention of the entity or not (e.g. the username can also contains the name of the entity). For this purpose we created a binary feature which indicates this aspect.</p><p>Furthermore it could be helpful to take into consideration the distance between the token in question and the mention of the target entity. The closer a token is to an entity the more the possibility that the given token is related to the entity. For example consider following message where the first sentence does not refer to BMW at all: I do agree that money can't buy happiness. But somehow, it's more comfortable to sit and cry in a BMW than on a bicycle! For this reason we weighted each word in the message by its distance from the mention of given entities:</p><formula xml:id="formula_0" coords="4,292.98,377.95,187.61,23.74">1 e 1 n |i-j| (1)</formula><p>where n is the length of the message, i and j are the position of the actual word and the mention of the entity in the message. Besides this, because different properties could be positive or negative to different entities we created a new feature which is the name of the entity, this way the classifier could handle entities differently.</p><p>Beyond the above supervised steps we experimented with leveraging unlabeled data as well. We used Latent Dirichlet Allocation (LDA) <ref type="bibr" coords="4,411.75,479.54,10.51,8.80" target="#b6">[7]</ref> for detecting topics on the train, test and background tweets provided by the RepLab 2013 organizers. The goal of topic modeling is to discover abstract topics that occur in a collection of documents. As a result of LDA, we get the topic distribution for each tweet and the topic for each word. We used the topic distributions over each tweet as features. Each word belongs to a topic, so for a given message we calculated the number of each topic by its content and used it as a feature as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>In this section we report the results of the several systems which we experimented with and their parametrization and the official results of the RepLab 2013 challenge. The training data which was provided by the organizers consists of 36, 940 English and 8, 731 Spanish tweets. From this 15, 123 tweets are from automotive, 7, 774 from banking, 6, 964 from universities and 15, 814 from music/artists domains. The test data consists of 79, 981 English and 25, 118 Spanish tweets which are distributed over the four domains similarly like the train data.</p><p>In our system we used Maximum Entropy classifier because we earlier showed that it works well in document classification <ref type="bibr" coords="5,330.57,167.75,9.96,8.80" target="#b7">[8]</ref>.</p><p>Below we will show the effects of the methods which was introduced in section 2. On figures 1 and 2 the accuracy of our system for both filtering and polarity detection tasks can be seen while adding more and more features to it. Our baseline system is named naive which uses simple unigram features without any normalization steps or extra features. In the norm version of our system we used all of the normalization steps which we introduced earlier. It can be seen that this step increased the accuracy for both tasks with a relatively large value. The next step was to use the bigrams as features besides unigrams and normalization in the N-gram system. This step increased the accuracy as well. The next system which we named features uses several abstract features too, which are the polarity of words and acronyms, the presence of character repetitions and upper case words and the number of negation words. These features increased our results marginally. In the so called weighting system we applied the distance based weighting for each word in the message and in the entities system we used the presence or absence of the given entity's name in the messages. These steps further increased our accuracy. In the last two systems we used the results of LDA topic modeling with 50 topics. In the topic50 we used the topic distributions over the messages as features and in the topic50-num we used the number of topics feature as well. These methods slightly improved our classifier only for the polarity task. In total, the introduced methods and features improved our results by 3-4 percents compared to our baseline.</p><p>In table <ref type="table" coords="5,187.26,430.92,4.98,8.80" target="#tab_0">1</ref> we show the effects of LDA with different number of topics. Here we used a system that uses all of the above introduced methods and features. It can be seen that LDA increased our results in both tasks, mainly the F measures. The best topic number was 50 and 100 for the filtering and polarity detection tasks, respectively. The RepLab 2013 participants were allowed to send up to ten different runs per subtask. In case of the filtering task we achieved our best result with the following system. We used all of the above mentioned methods and features, we detected 50 topics with LDA on the train and test data. Furthermore we run our classifier separately on the four domains (automotive, banking, university, music/artists). This way we reached 0.438 F measure comparing to the best system which reached 0.488 and the baseline provided by the organizers was 0.325. With this system we reached 0.928 accuracy which turns out to be the highest value. In case of the polarity detection task our best system was parametrized as follows. Like before, we used all the technologies which we developed, we detected only 20 topics on the train and test data. Unlike the filtering task, here we run our classifier on the four domains at the same time. We achieved 0.685 accuracy which is the highest among all of the participated systems, the given baseline was 0.584. We achieved our highest F measure with a different system which similar to the previous but it did not use the polarity of the words and the acronyms. This way we reached 0.381 F measure, whilst the given baseline was 0.297.</p><p>From this analysis we can conclude that the normalization of the messages yielded a considerable increase in the accuracy of our classifier. We discussed above that this also significantly reduced the size of the dictionary. The features and other methods increased the precision as well. During our experiments we realized that in some cases LDA did not detect topics well which can cause the low improvements in accuracy by LDA features. For example consider the following topic which contains these words "the to for a in of and year a". In future it would be worth trying to improve the performance of topic modeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions and Future Work</head><p>Recently, sentiment analysis on Twitter messages has gained a lot of attention due to the huge amount of Twitter users and their tweets. A commercial extension of classical binary sentiment analysis is reputation management systems. In this paper, we examined several methods for filtering relevant tweet by a given entity and for classifying them by their sentiments for reputation management. We proposed special features which characterize the polarity and other aspects of tweets and we concluded that due to the informality (slang, spelling mistakes, etc.) of the messages it is crucial to normalize them properly. Our system achieved outstanding ranks in both filtering and polarity tasks of the RepLab 2013 challenge.</p><p>In the future, we plan to investigate the utility of relations between Twitter users and between their tweets. Furthermore we would like to examine several domain adaption methods in such way that we use messages for training from other sources than Twitter.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,229.90,349.89,155.56,7.93"><head>Fig. 1 .Fig. 2 .</head><label>12</label><figDesc>Fig. 1. Filtering accuracy on test data</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,185.09,510.37,245.19,72.93"><head>Table 1 .</head><label>1</label><figDesc>Results with different number of topics</figDesc><table coords="5,185.09,531.15,245.19,52.15"><row><cell cols="5">topic number filtering acc. filtering F polarity acc. polarity F</cell></row><row><cell>0</cell><cell>0.919</cell><cell>0.380</cell><cell>0.680</cell><cell>0.368</cell></row><row><cell>20</cell><cell>0.920</cell><cell>0.387</cell><cell>0.680</cell><cell>0.370</cell></row><row><cell>50</cell><cell>0.919</cell><cell>0.391</cell><cell>0.682</cell><cell>0.375</cell></row><row><cell>100</cell><cell>0.920</cell><cell>0.388</cell><cell>0.683</cell><cell>0.379</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was supported in part by the <rs type="funder">European Union</rs> and the <rs type="funder">European Social Fund</rs> through project <rs type="projectName">FuturICT</rs>.hu (grant no.: <rs type="grantNumber">TÁMOP-4.2.2.C-11/1/KONV-2012-0013</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_KXKJSXM">
					<idno type="grant-number">TÁMOP-4.2.2.C-11/1/KONV-2012-0013</idno>
					<orgName type="project" subtype="full">FuturICT</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.95,143.53,337.64,7.92;8,151.52,154.49,329.07,7.92;8,151.52,165.45,127.45,7.92" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,403.75,143.53,76.85,7.92;8,151.52,154.49,62.49,7.92">Sentiment Analysis of Twitter Data</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Vovsha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Rambow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Passonneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,238.74,154.49,241.85,7.92;8,151.52,165.45,46.44,7.92">Proceedings of the Workshop on Language in Social Media (LSM 2011)</title>
		<meeting>the Workshop on Language in Social Media (LSM 2011)</meeting>
		<imprint>
			<date type="published" when="2011-06">June 2011</date>
			<biblScope unit="page" from="30" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.95,176.41,337.64,7.92;8,151.52,187.37,329.08,7.92;8,151.52,198.33,122.07,7.92" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,380.10,176.41,100.49,7.92;8,151.52,187.37,198.50,7.92">Overview of replab 2012: Evaluating online reputation management systems</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Corujo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Meij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,370.01,187.37,110.58,7.92;8,151.52,198.33,89.14,7.92">CLEF 2012 Labs and Workshop Notebook Papers</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.95,209.28,337.64,7.92;8,151.52,220.24,329.07,7.92;8,151.52,231.20,329.07,7.92;8,151.52,242.16,26.11,7.92" xml:id="b2">
	<analytic>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigãş</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carrillo De Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Chugur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Corujo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Martãŋn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Meij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,321.98,220.24,158.61,7.92;8,151.52,231.20,113.98,7.92">Fourth International Conference of the CLEF initiative</title>
		<title level="s" coord="8,340.54,231.20,112.32,7.92">Proceedings. Springer LNCS</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint/>
	</monogr>
	<note>CLEF 2013</note>
</biblStruct>

<biblStruct coords="8,142.95,253.12,337.63,7.92;8,151.52,264.08,329.07,7.92;8,151.52,275.04,329.08,7.92;8,151.52,286.00,329.08,7.92;8,151.52,296.96,329.07,7.92;8,151.52,307.91,82.27,7.92" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,317.62,253.12,162.97,7.92;8,151.52,264.08,210.76,7.92">SentiWordNet 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Baccianella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Esuli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,151.52,286.00,329.08,7.92;8,151.52,296.96,87.78,7.92">Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC&apos;10)</title>
		<editor>
			<persName><forename type="first">)</forename><surname>Chair</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><forename type="middle">C C</forename><surname>Choukri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Maegaard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Mariani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Odijk</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Piperidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Rosner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Tapias</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename></persName>
		</editor>
		<meeting>the Seventh International Conference on Language Resources and Evaluation (LREC&apos;10)<address><addrLine>Valletta, Malta</addrLine></address></meeting>
		<imprint>
			<publisher>European Language Resources Association (ELRA)</publisher>
			<date type="published" when="2010-05">May 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.95,318.87,337.64,7.92;8,151.52,329.83,263.51,7.92" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,246.63,318.87,233.96,7.92;8,151.52,329.83,43.55,7.92">Robust Sentiment Detection on Twitter from Biased and Noisy Data</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Barbosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,280.61,329.83,47.61,7.92">Coling 2010</title>
		<imprint>
			<date type="published" when="2010-08">August 2010</date>
			<biblScope unit="page" from="36" to="44" />
		</imprint>
	</monogr>
	<note>Poster volume</note>
</biblStruct>

<biblStruct coords="8,142.95,340.79,337.64,7.92;8,151.52,351.75,25.59,7.92" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="8,237.23,340.79,238.89,7.92">Sentiment Knowledge Discovery in Twitter Streaming Data</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bifet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.95,362.71,337.63,7.92;8,151.52,373.66,184.19,7.93" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,305.58,362.71,105.55,7.92">Latent dirichlet allocation</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,421.92,362.71,58.67,7.92;8,151.52,373.67,107.23,7.92">the Journal of machine Learning research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.95,384.63,337.64,7.92;8,151.52,395.59,329.08,7.92;8,151.52,406.55,329.08,7.92;8,151.52,417.50,329.07,7.92;8,151.52,428.46,155.45,7.92" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,312.35,384.63,168.24,7.92;8,151.52,395.59,34.27,7.92">Szte-nlp: Sentiment detection on twitter messages</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Hangya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Berend</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Farkas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,209.80,395.59,270.80,7.92;8,151.52,406.55,29.28,7.92;8,230.81,406.55,249.79,7.92;8,151.52,417.50,121.22,7.92">Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013)</title>
		<meeting>the Seventh International Workshop on Semantic Evaluation (SemEval 2013)<address><addrLine>Atlanta, Georgia, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2013-06">June 2013</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="549" to="553" />
		</imprint>
	</monogr>
	<note>Second Joint Conference on Lexical and Computational Semantics (*SEM)</note>
</biblStruct>

<biblStruct coords="8,142.95,439.42,337.64,7.92;8,151.52,450.38,329.07,7.92;8,151.52,461.34,166.66,7.92" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,373.96,439.42,106.63,7.92;8,151.52,450.38,105.91,7.92">Twitter Power: Tweets as Electronic Word of Mouth</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">J</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Sobel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chowdury</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,283.33,450.38,197.26,7.92;8,151.52,461.34,89.40,7.92">Journal of the American society for information science and technology</title>
		<imprint>
			<biblScope unit="page" from="2169" to="2188" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,472.30,337.98,7.92;8,151.52,483.26,329.08,7.92;8,151.52,494.22,195.37,7.92" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,334.93,472.30,145.66,7.92;8,151.52,483.26,52.17,7.92">Target-dependent Twitter Sentiment Classification</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,226.21,483.26,254.38,7.92;8,151.52,494.22,105.44,7.92">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2011-06">June 2011</date>
			<biblScope unit="page" from="151" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,505.18,337.97,7.92;8,151.52,516.13,226.42,7.92" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,188.13,505.18,146.99,7.92">Sentiment Analysis and Subjectivity</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,172.56,516.13,171.61,7.92">Handbook of Natural Language Processing</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Indurkhya</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Damerau</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,527.09,84.15,7.92;8,249.16,527.09,231.43,7.92;8,151.52,538.05,137.08,7.92" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="8,249.16,527.09,227.78,7.92">Mallet: A machine learning for language toolkit</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">K</forename><surname>Mccallum</surname></persName>
		</author>
		<ptr target="http://mallet.cs.umass.edu" />
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,549.01,337.98,7.92;8,151.52,559.97,329.07,7.92;8,151.52,570.93,326.92,7.92" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,428.75,549.01,51.84,7.92;8,151.52,559.97,258.32,7.92">From Tweets to Polls: Linking Text Sentiment to Public Opinion Time Series</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>O'connor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Balasubramanyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">R</forename><surname>Routledge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,432.53,559.97,48.07,7.92;8,151.52,570.93,272.96,7.92">Proceedings of the International AAAI Conference on Weblogs and Social Media</title>
		<meeting>the International AAAI Conference on Weblogs and Social Media</meeting>
		<imprint>
			<date type="published" when="2010-05">May 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,581.89,337.98,7.92;8,151.52,592.85,329.07,7.92;8,151.52,603.81,251.17,7.92" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,249.12,581.89,231.48,7.92;8,151.52,592.85,28.46,7.92">Predicting the 2011 Dutch Senate Election Results with Twitter</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">T K</forename><surname>Sang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,203.67,592.85,276.92,7.92;8,151.52,603.81,168.77,7.92">Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the 13th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2012-04">April 2012</date>
			<biblScope unit="page" from="53" to="60" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,614.76,337.98,7.92;8,151.52,625.72,329.07,7.92;8,151.52,636.68,153.27,7.92" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,323.12,614.76,157.48,7.92;8,151.52,625.72,173.25,7.92">An experiment in integrating sentiment features for tech stock prediction in twitter</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">T</forename><surname>Vu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><forename type="middle">T</forename><surname>Ha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Collier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,346.97,625.72,133.61,7.92;8,151.52,636.68,105.44,7.92">24th International Conference on Computational Linguistics</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page">23</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
