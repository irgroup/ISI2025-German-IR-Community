<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,148.85,116.90,317.65,12.90;1,266.63,134.83,82.10,12.90">POPSTAR at RepLab 2013: Polarity for Reputation Classification</title>
				<funder ref="#_z8MMjQ4">
					<orgName type="full">FCT (Portuguese research funding agency</orgName>
				</funder>
				<funder ref="#_bjZVwgj #_9RRyJmv">
					<orgName type="full">FCT</orgName>
				</funder>
				<funder ref="#_84xWGys">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,244.03,172.87,60.60,8.64"><forename type="first">João</forename><surname>Filgueiras</surname></persName>
							<email>jfilgueiras@inesc-id.pt</email>
							<affiliation key="aff0">
								<orgName type="department">INESC-ID</orgName>
								<orgName type="institution">Technical University of Lisbon</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,324.00,172.87,47.33,8.64"><forename type="first">Silvio</forename><surname>Amir</surname></persName>
							<email>samir@inesc-id.pt</email>
							<affiliation key="aff0">
								<orgName type="department">INESC-ID</orgName>
								<orgName type="institution">Technical University of Lisbon</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,148.85,116.90,317.65,12.90;1,266.63,134.83,82.10,12.90">POPSTAR at RepLab 2013: Polarity for Reputation Classification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E2DB36C40BD8FC375B779A7D882711B8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our participation in the Polarity for Reputation classification task of RepLab 2013. Our system leveraged on a set of components previously developed for a Twitter message polarity classifier. Following a supervised approach, a Logistic Regression classifier is trained from annotated data. A refined language model is used to represent tweets in terms of a vocabulary consisting only of the most informative terms with word features weighted using a measure from the Information Retrieval field. To help reduce the sparseness of the feature vector, the model is enriched with another, more compact, representation of the words. Finally, we extract features to capture the use of informal and affective language. Our approach ranked in the top three for all the metrics, showing that the strategies for Twitter Sentiment Analysis are useful for the task of Polarity for Reputation classification.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Twitter has become a vast repository of user-generated content over the years. A current research trend is to use this repository, and others like it, as a source of indicators of public opinion on a number of topics. Some popular examples are the prediction of elections or the prediction of box-office revenues for movies.</p><p>The RepLab Polarity for Reputation Classification task aims to use tweets as an indicator of the reputation of entities, such as companies, brands or artists. To accomplish this goal the reputation analysis problem is divided into four tasks: filtering, polarity, clustering and priority. The filtering step removes tweets that are not related to an entity. The polarity step rates the impact of the tweet on the reputation of the entity as positive, negative or neutral. The clustering step, aims to cluster tweets pertaining to an entity into topics and finally, the priority step assigns a level of importance to each topic. Re-pLab participants were given an annotated dataset and asked to implement one or more components of this system.</p><p>It is clear that reputation analysis and sentiment analysis are different tasks. Objective facts can still have a negative impact on the reputation of an entity, and tweets expressing negative sentiment may still be positive for a reputation or vice-versa. However, from a technical perspective, how different are the underlying problems? And to what extent are the techniques suitable for one task effective on the other? Motivated by these questions we participated in RepLab 2013 using an effective classifier we had developed for a Twitter message polarity classifier. This classifier was tailored to participate in the task proposed in the Sentiment Analysis in Twitter track of SemEval 2013, a workshop focused on the evaluation of semantic analysis systems <ref type="bibr" coords="2,401.78,120.31,78.80,8.64" target="#b2">(Nakov et al., 2013)</ref> and achieved state-of-the-art results.</p><p>The remainder of the document is organized as follow: next, the annotated dataset is presented, in Section 2 we describe our approach in detail, Section 3 shows the results of the experiments and we briefly conclude in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Dataset</head><p>The RepLab 2013 organization provided an annotated dataset that contained a total of 33,191 tweets annotated for polarity. Of these, 7,073 were written in Spanish and 26,118 in English. The content of webpages linked by URLs in each tweet was also provided. The tweet distribution across classes is shown in Table <ref type="table" coords="2,354.61,259.24,3.74,8.64" target="#tab_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Overview</head><p>Following a supervised approach, we used the annotated data to train a Logistic Regression classifier. Each tweet was modelled as a feature vector consisting of a bag-ofwords vocabulary representation. However, the lexical variation introduced by typos, abbreviations, slang and unconventional spelling found in Twitter data, leads to very large vocabularies. The resulting sparse vector representations with few non-zero values hamper the learning process. To overcome this problem, words with high entropy (not discriminative of any of the classes) were discarded and Brown Clusters <ref type="bibr" coords="2,450.40,524.44,30.19,8.64;2,134.77,536.40,49.40,8.64" target="#b1">(Brown et al., 1992)</ref> were used as a complementary representation of the tweet to enrich the feature vector.</p><p>We used sentiment lexicons to extract features based on the prior polarity of words, taking the presence of negation particles into consideration. Some microblog oriented features were included to capture particular aspects of this type of text (e.g. presence of emoticons). Finally, the title of the web pages referred in the messages was included to provide additional context.</p><p>To deal with the fact that there were two different languages, we chose to train a separate classifier for each language. The Spanish classifier was a simplified version of the English classifier, without Brown clusters and lexicons features.</p><p>Each major component of our system is described in detail in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Preprocess</head><p>In order to cope with the noisy content and reduce the vocabulary size, the following preprocess steps were taken: stop words were discarded, user mentions (@username) were replaced with a fixed tag &lt;USER&gt; and URLs with the tag &lt;URL&gt;. Then, messages were normalized by converting to lower-case and reducing character repetitions to at most 3 characters (e.g. "helloooooo!" would be normalized to "hellooo!"). Finally, words were stemmed using the Snowball Stemmer implementation of NLTK<ref type="foot" coords="3,442.87,200.11,3.49,6.05" target="#foot_0">1</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Document Representation</head><p>Negation The presence of a negation word can have great impact in the meaning of a sentence, e.g., the expressions "very good" and "not very good" convey opposite sentiments. Therefore, following the work of <ref type="bibr" coords="3,317.97,279.03,70.04,8.64" target="#b5">Pang et al. (2002)</ref>, negation was directly integrated in the words representation. All the words between a negation word and the first punctuation mark, were suffixed with the NEG tag. The list of negation words was compiled manually.</p><p>Weighting Schemes for Word Features Typical schemes proposed for weighting word features in text classification tasks are binary weighting, term frequency and tf.idf. However, <ref type="bibr" coords="3,174.66,370.46,120.00,8.64" target="#b4">Paltoglou and Thelwall (2010)</ref> showed that advanced weighting schemes used in Information Retrieval can enhance sentiment classification accuracy. As these measures capture the relative importance of a term in two classes (positives and negatives in this case), they provide more informative word weights for the task at hand. We found experimentally that delta-tf.idf weight function yields the best results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Brown Clusters</head><p>The Brown algorithm is a hierarchical clustering algorithm that clusters words to maximize the mutual information of bi-grams. The hierarchical nature of the clustering allows words to be represented at several levels in the hierarchy, which can compensate for poor clusters of a small number of words. Brown clusters are created by applying the Brown algorithm to a large corpora, capturing relations between bi-grams to form a denser representation of a vocabulary. Using these clusters we also represented documents in terms of a more compact vocabulary, where each word was mapped to its corresponding cluster. Plugging these clusters as extra-features into the document model, can alleviate the problems of feature vector sparseness and unseen words.</p><p>Word Entropy Previous work has shown that in order to improve classification performance when using bag-of-words, words with high entropy, i.e., that do not contribute strongly to any of the classes should be discarded <ref type="bibr" coords="3,339.01,613.10,103.01,8.64" target="#b3">(Pak and Paroubek, 2010)</ref>. The entropy of the probability distribution of a word appearing in the different classes was computed using the <ref type="bibr" coords="3,215.29,637.01,113.12,8.64" target="#b6">Shannon and Weaver (1948)</ref> definition.</p><p>A high entropy value indicates that a word appears evenly in all the classes, whereas low entropy values mean that a word is more frequent in one of the classes, hence, being more discriminative of a given sentiment. After computing the entropy values for each term, a threshold τ was defined and words with entropy above τ were discarded, reducing vocabulary size.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Features</head><p>The document representation model was enriched with features that take into account the presence of words with prior polarity, such as "happy" (positive) or "sad" (negative) in a document. In the spirit of previous approaches, features that aim at capturing the creative and informal use of language in tweets, were also extracted. In summary, the following features were employed:</p><p>-Sentiment Lexicons: number of words with positive\negative prior polarity and a score obtained by summing both. Negation was taken into account by detecting the presence of a negation token in a window of two words. Bing Liu's Opinion Lexicon<ref type="foot" coords="4,184.20,311.93,3.49,6.05" target="#foot_1">2</ref> was employed for this feature.</p><p>-Heavy Punctuation: number of sequences of exclamation marks, question marks and combinations of both.</p><p>-Upper-case Words: number of words all in upper case.</p><p>-Emoticons: number of positive and negative emoticons. The polarity of emoticons was assessed with custom regular expressions and a list of polar emoticons used in SentiStrength.</p><p>-Emphasized Words: number of words emphasized with more than 2 character repetitions, e.g., "awesoooome".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Context</head><p>As mentioned in Section 1.1 the training and test datasets also contained the contents of web pages linked on tweets. To take advantage of this extra information we employed a simplistic strategy. We extracted the title HTML tag of these pages and appended it to text of the tweet associated with it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>To test the impact of each feature and determine the best settings for this problem, we used a 70%-30% split to evaluate different versions of the classifier. Table <ref type="table" coords="4,444.39,578.64,4.98,8.64" target="#tab_1">2</ref> reports our results for the English classifier. The baseline used only a binary bag-of-words and Brown clusters representation of each tweet without any vocabulary reduction. We then added the traditional features mentioned in Section 2.4. The binary weighting scheme was changed afterwards for a Delta-tf.idf, followed by a vocabulary reduction using entropy, and finally the addition of the HTML title tags.  Finally, Table <ref type="table" coords="5,209.57,406.52,4.98,8.64" target="#tab_4">4</ref> shows our results in the final evaluation by the organization of RepLab 2013, using a test dataset. Each participant could submit up to ten different runs, and we opted to submit different variations of the vocabulary reduction and the use of the context HTML title tags. Several vocabulary sizes were tested experimentally and the best were submitted. The reported metrics of reliability and sensitivity, related to precision and recall of the positive and negative classes, are described by <ref type="bibr" coords="5,431.92,466.30,48.67,8.64;5,134.77,478.25,24.90,8.64" target="#b0">Amigo et al. (2012)</ref>. Our submissions ranked third in the accuracy metric, first in Pearson correlation and second in the F-measure of sensitivity and reliability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>Although the problems of evaluating the polarity of sentiment and analyzing polarity for the reputation of an entity expressed in a tweet are different we found that the same principles and techniques can be used.</p><p>Our classifier achieved good results even in a different language, such as Spanish, without any language-specific features. The experiments and evaluation show that the proposed approach is robust and indicate that the underlying problems of reputation analysis are not very different from free domain sentiment analysis.</p><p>We also note that the use of context, even in such a simplistic way as the one we used, improves the overall results. It becomes clear that more sophisticated approaches should be explored in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,215.30,291.41,184.75,51.66"><head>Table 1 .</head><label>1</label><figDesc>Tweet distribution across polarity classes.</figDesc><table coords="2,215.30,291.41,184.75,30.84"><row><cell cols="2">Language Positive</cell><cell>Negative</cell><cell>Neutral</cell></row><row><cell>English</cell><cell cols="3">15545 59.5% 3429 13.1% 7144 27.4%</cell></row><row><cell cols="4">Spanish 3195 45.2% 2143 30.3% 1735 24.5%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,190.79,118.72,233.78,85.73"><head>Table 2 .</head><label>2</label><figDesc>Experimental results for the English classifier iterations.</figDesc><table coords="5,226.40,118.72,162.56,64.91"><row><cell>Classifier</cell><cell cols="2">Accuracy Polar F1</cell></row><row><cell>Baseline</cell><cell>71.7%</cell><cell>69.5%</cell></row><row><cell>+ Features</cell><cell>72.4%</cell><cell>71.0%</cell></row><row><cell>+ Delta TF.IDF</cell><cell>72.8%</cell><cell>71.0%</cell></row><row><cell cols="2">+ Vocabulary Reduction 73.5%</cell><cell>71.5%</cell></row><row><cell>+ HTML Title</cell><cell>73.7%</cell><cell>72.0%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,134.77,247.64,345.82,95.02"><head>Table 3</head><label>3</label><figDesc>shows a simplified table for the Spanish classifier. In this case the baseline was simply a binary bag-of-words. As mentioned previously, the full classifier employed every strategy in the English classifier except Brown clusters and lexicons.</figDesc><table coords="5,245.56,311.83,124.24,30.84"><row><cell>Classifier</cell><cell cols="2">Accuracy Polar F1</cell></row><row><cell>Baseline</cell><cell>71.6%</cell><cell>74.5%</cell></row><row><cell cols="2">Full classifier 72.3%</cell><cell>75.5%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,208.35,355.37,198.67,8.12"><head>Table 3 .</head><label>3</label><figDesc>Experimental results for the Spanish classifier.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,137.53,518.14,340.29,85.73"><head>Table 4 .</head><label>4</label><figDesc>Submitted runs.</figDesc><table coords="5,137.53,518.14,340.29,64.91"><row><cell cols="7">Run English Vocab. Spanish Vocab. Title Accuracy Pearson Corr. Reliability Sensitivity</cell></row><row><cell>1</cell><cell>80%</cell><cell>30%</cell><cell>No 63.2%</cell><cell>0.883</cell><cell>42.6%</cell><cell>33.6%</cell></row><row><cell>2</cell><cell>98%</cell><cell>80%</cell><cell>No 63.3%</cell><cell>0.881</cell><cell>42.0%</cell><cell>32.8%</cell></row><row><cell>3</cell><cell>80%</cell><cell>80%</cell><cell>No 63.6%</cell><cell>0.883</cell><cell>43.0%</cell><cell>33.4%</cell></row><row><cell>4</cell><cell>80%</cell><cell>30%</cell><cell>Yes 63.6%</cell><cell>0.889</cell><cell>43.0%</cell><cell>34.0%</cell></row><row><cell>5</cell><cell>80%</cell><cell>80%</cell><cell>Yes 63.9%</cell><cell>0.888</cell><cell>43.3%</cell><cell>33.9%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,144.73,658.92,86.08,6.31"><p>http://nltk.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,144.73,658.92,296.39,8.03"><p>http://www.cs.uic.edu/ ˜liub/FBS/sentiment-analysis.html</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was partially supported by <rs type="funder">FCT (Portuguese research funding agency</rs>) under project grants <rs type="grantNumber">UTA-Est/MAI/0006/2009</rs> (<rs type="projectName">REACTION</rs>) and <rs type="grantNumber">PTDC/CPJ-CPO/116888/2010</rs> (<rs type="projectName">POPSTAR</rs>). <rs type="funder">FCT</rs> also supported scholarship <rs type="grantNumber">SFRH/BD/89020/2012</rs>. This research was also funded by <rs type="funder">FCT</rs> under contract <rs type="grantNumber">Pest-OE/EEI/LA0021/2013</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_z8MMjQ4">
					<idno type="grant-number">UTA-Est/MAI/0006/2009</idno>
					<orgName type="project" subtype="full">REACTION</orgName>
				</org>
				<org type="funded-project" xml:id="_bjZVwgj">
					<idno type="grant-number">PTDC/CPJ-CPO/116888/2010</idno>
					<orgName type="project" subtype="full">POPSTAR</orgName>
				</org>
				<org type="funding" xml:id="_9RRyJmv">
					<idno type="grant-number">SFRH/BD/89020/2012</idno>
				</org>
				<org type="funding" xml:id="_84xWGys">
					<idno type="grant-number">Pest-OE/EEI/LA0021/2013</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,134.77,172.11,345.82,8.64;7,144.73,184.07,335.87,8.64;7,144.73,196.03,58.93,8.64" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="7,338.15,172.11,142.44,8.64;7,144.73,184.07,214.79,8.64">Reliability and sensitivity: Generic evaluation measures for document organization tasks</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Verdejo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
		<respStmt>
			<orgName>UNED</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="7,134.77,207.98,345.82,8.64;7,144.73,219.76,335.87,8.82" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,455.68,207.98,24.91,8.64;7,144.73,219.94,160.24,8.64">Classbased n-gram models of natural language</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">F</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">V</forename><surname>Desouza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L</forename><surname>Mercer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">J D</forename><surname>Pietra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,311.70,219.76,101.59,8.59">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="467" to="479" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,134.77,231.89,345.82,8.64;7,144.73,243.67,335.86,8.82;7,144.73,255.62,269.04,8.82" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,144.73,243.85,201.79,8.64">Semeval-2013 task 2: Sentiment analysis in twitter</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Nakov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Rosenthal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Kozareva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wilson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,365.28,243.67,115.31,8.59;7,144.73,255.62,172.87,8.59">Proceedings of the 7th International Workshop on Semantic Evaluation</title>
		<meeting>the 7th International Workshop on Semantic Evaluation<address><addrLine>SemEval</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,134.77,267.76,345.82,8.64;7,144.73,279.53,198.23,8.82" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,266.90,267.76,213.69,8.64;7,144.73,279.71,26.34,8.64">Twitter as a corpus for sentiment analysis and opinion mining</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Paroubek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,179.04,279.53,83.56,8.59">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1320" to="1326" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,134.77,291.67,345.82,8.64;7,144.73,303.44,335.87,8.82;7,144.73,315.40,335.86,8.82;7,144.73,327.53,89.12,8.64" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,304.67,291.67,175.92,8.64;7,144.73,303.62,124.34,8.64">A study of information retrieval weighting schemes for sentiment analysis</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Paltoglou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Thelwall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,290.11,303.44,190.48,8.59;7,144.73,315.40,167.92,8.59">Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 48th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1386" to="1395" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,134.77,339.49,345.82,8.64;7,144.73,351.26,335.86,8.82;7,144.73,363.22,335.86,8.82;7,144.73,375.35,145.02,8.64" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,331.76,339.49,148.83,8.64;7,144.73,351.44,140.06,8.64">Thumbs up?: sentiment classification using machine learning techniques</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vaithyanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,308.31,351.26,172.28,8.59;7,144.73,363.22,207.11,8.59">Proceedings of the ACL-02 conference on Empirical methods in natural language processing</title>
		<meeting>the ACL-02 conference on Empirical methods in natural language processing</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="79" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,134.77,387.31,329.00,8.64" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="7,294.70,387.31,164.46,8.64">A mathematical theory of communication</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Weaver</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1948">1948</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
