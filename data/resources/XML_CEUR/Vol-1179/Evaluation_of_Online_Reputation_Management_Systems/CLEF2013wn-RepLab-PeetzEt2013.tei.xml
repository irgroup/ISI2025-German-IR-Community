<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,167.55,115.96,280.27,12.62;1,145.34,133.89,324.67,12.62;1,276.14,151.82,56.86,12.62">Towards an Active Learning System for Company Name Disambiguation in Microblog Streams</title>
				<funder ref="#_3yr2g3M">
					<orgName type="full">Netherlands eScience Center</orgName>
				</funder>
				<funder ref="#_RnRG87m">
					<orgName type="full">Spanish Ministry of Science and Innovation</orgName>
				</funder>
				<funder ref="#_rQEQ6rA">
					<orgName type="full">Royal Dutch Academy of Sciences (KNAW)</orgName>
				</funder>
				<funder ref="#_vDEdjYn">
					<orgName type="full">Spanish Ministry of Education</orgName>
				</funder>
				<funder ref="#_s3kuQ8m">
					<orgName type="full">Netherlands Organisation for Scientific Research (NWO)</orgName>
				</funder>
				<funder>
					<orgName type="full">Regional Government of Madrid</orgName>
				</funder>
				<funder ref="#_GDxQuHJ">
					<orgName type="full">Center for Creation, Content and Technology</orgName>
					<orgName type="abbreviated">CCCT</orgName>
				</funder>
				<funder ref="#_m3BkpJC #_YKe3qr6 #_hZmPmc5 #_eDFjwWW #_3a7gsxT #_JUPr8CY #_YTpuGrf">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_ZUpvYQn">
					<orgName type="full">ESF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,140.64,189.57,95.12,8.74"><forename type="first">Maria-Hendrike</forename><surname>Peetz</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">ISLA</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,246.31,189.57,66.84,8.74"><forename type="first">Damiano</forename><surname>Spina</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">UNED NLP &amp; IR Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,323.71,189.57,59.99,8.74"><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">UNED NLP &amp; IR Group</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,394.25,189.57,75.99,8.74"><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
							<email>derijke@uva.nl</email>
							<affiliation key="aff0">
								<orgName type="laboratory">ISLA</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,181.49,202.24,36.81,8.30"><forename type="first">H</forename><surname>Peetz</surname></persName>
						</author>
						<title level="a" type="main" coord="1,167.55,115.96,280.27,12.62;1,145.34,133.89,324.67,12.62;1,276.14,151.82,56.86,12.62">Towards an Active Learning System for Company Name Disambiguation in Microblog Streams</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DCC6928C55642CE619F31EDD6AC2F098</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe the collaborative participation of UvA &amp; UNED at RepLab 2013. We propose an active learning approach for the filtering subtask, using features based on the detected semantics in the tweet (using Entity Linking with Wikipedia), as well as tweetinherent features such as hashtags and usernames. The tweets manually inspected during the active learning process is at most 1% of the test data. While our baseline does not perform well, we can see that active learning does improve the results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With increasing volumes of social media data, social media monitoring and analysis is a vital part of the marketing strategy of businesses. Manual, and increasingly also automatic, extraction of topics, reputation, and trends around a brand allows analysts to understand and manage a brand's reputation. Twitter, in particular, has been used as such a proxy.</p><p>Efficient manual and automatic extraction requires filtering and disambiguation of tweets. Currently, for manual analysis, many non-relevant tweets have to be discarded. This has an impact on the costs of the analysis. For automatic analysis, non-relevant tweets might distort the results and decrease reliability.</p><p>Automatic reliable named-entity disambiguation on social media is therefore an active field of research. Typically, filtering systems are static (once trained, the model does not change) and fully automatic (there is no interaction with the analysts). However, both language and topics around an entity may change over time and the disambiguation performance is therefore likely to decay. Additionally, assuming the improvement in performance are worth it, the time to annotate a handful of tweets a day can easily be spent by analysts. We therefore propose an active learning approach to company name disambiguation. In particular, we analyze whether the annotation of a small number of tweets (at most 1% of the test data) per company improves significantly the results.</p><p>The paper is organized as follows. We continue with an introduction of the proposed approach in Section 2. We proceed with an explanation of the runs in the experimental setup (Section 3) and analyse the results in Section 4. We conclude in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Proposed Approach</head><p>Our proposed approach is based on active learning, a semi-automatic machine learning process that interacts with the user for updating the classification model. It selects those instances that may maximize the classification performance with minimal effort. Figure <ref type="figure" coords="2,286.02,373.96,4.98,8.74" target="#fig_0">1</ref> illustrates the pipeline of the system. First, the instances are represented as feature vectors. Second, the instances from the training dataset are used for building the initial classification model. Third, the test instances are automatically classified using the initial model. Fourth, the system guesses the candidate to be prompted to the user. This step is performed by uncertainty sampling: the instance with least certain as to be correctly classified is selected. Fifth, the user manually inspects the instance and labels it. The labeled instance is then considered to update the model. The active learning process is repeated until a termination condition is satisfied (e.g., the number n of iterations performed). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Feature representation</head><p>We tested two feature representations:</p><p>Bag of Entities + Twitter metadata (BoE). First, an entity linking system is used to identify relevant Wikipedia articles to a given tweet. The COM-MONNESS probability <ref type="bibr" coords="3,239.10,191.76,9.96,8.74" target="#b4">[5]</ref>, based on the intra-Wikipedia hyperlinks, is used to select the most probable entity for each of the longest n-grams that were linked to Wikipedia articles from corpora related to the specific language. Spanish Wikipedia articles are finally translated to the corresponding English Wikipedia article by following the interlingual links, using the Wikimedia API. <ref type="foot" coords="3,439.83,238.00,3.97,6.12" target="#foot_0">3</ref> Besides the entities linked to the tweet, special Twitter metadata-hashtags, usernames and author of the tweet-is also considered as features.</p><p>BoE + Bag of Words (BoE+BoW). This second feature representation simply adds the tokenized text of the tweet to the features in BoE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Features are then weighted by two different weighting functions: 4</head><p>Presence Each term is weighted with binary occurrence in the tweet: 1 if present, 0 otherwise.</p><p>Pseudo-document TF.IDF As in <ref type="bibr" coords="3,303.24,399.05,14.61,8.74" target="#b9">[10]</ref>, we consider a pseudo-document D built from all the tweets given for an entity in the RepLab 2013 training/test dataset and a background corpus C containing all the D i in the RepLab 2013 collection. Then, the weight w given to the term t is</p><formula xml:id="formula_0" coords="3,239.81,454.02,134.54,22.31">w(t, D, C) = tf (t, D) • log N df (t)</formula><p>where tf (t, D) denotes the term frequency of term t in pseudo-document D and df (t) denotes the total number of pseudo-documents D i ∈ C in which the term t occurs at least once.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Learning model</head><p>We use Naïve Bayes<ref type="foot" coords="3,221.91,559.10,3.97,6.12" target="#foot_2">5</ref> (NB) as a classifier and build an initial model. Our active learning approach can be split into the selection of candidates for active annotations, annotation of the candidates and updating the model. Therefore, one iteration of our learning model follows the following three steps:</p><p>-Select the best candidate x from the test set T ; -Annotate the candidate x; -Update the model. The annotations are selected from the test set. The test set depends on the experimental setup: in the cross-validation scenario, we could use the available annotations, while in the actual testing scenario, we annotated the candidates manually.</p><p>Candidate Selection. Following <ref type="bibr" coords="4,289.69,217.83,10.52,8.74" target="#b7">[8]</ref> the candidate selection can be based on uncertainty sampling, margin sampling (in particular for support vector machines <ref type="bibr" coords="4,165.91,241.74,15.50,8.74" target="#b10">[11]</ref>) or entropy sampling. Selecting candidates close to the margin is motivated by selecting candidates where the classification is less confident. Extending this motivation to NB, we choose to look at the probabilities P (C 1 |F ) and P (C 2 |F x )) that a candidate x feature vector F x generates the classes C 1 and C 2 . The candidate x to be annotated from the test set T is:</p><formula xml:id="formula_1" coords="4,224.14,311.74,252.20,14.58">x = arg min i∈T |P (C 1 | F x ) -P (C 2 | F x )|. (<label>1</label></formula><formula xml:id="formula_2" coords="4,476.35,311.74,4.24,8.74">)</formula><p>This candidate x is then being annotated and used to update the model.</p><p>Model updating Due to the speed of the training of the model, we decided to retrain NB with every new instance. We assigned all newly annotated instances a higher weight than the instances in the original training set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Setup</head><p>In the following we describe how we used the training set to select the best feature groups. Based on this, we describe the runs we submitted. Unlike previous company name disambiguation datasets, such as the WePS-3 ORM dataset <ref type="bibr" coords="4,449.59,473.33,11.62,8.74" target="#b0">[1,</ref><ref type="bibr" coords="4,461.22,473.33,11.62,8.74" target="#b11">12,</ref><ref type="bibr" coords="4,472.84,473.33,7.75,8.74" target="#b8">9]</ref> and the RepLab 2012 dataset <ref type="bibr" coords="4,269.45,485.29,9.96,8.74" target="#b1">[2]</ref>, the RepLab 2013 collection shares the same set of entities in training and test datasets. As reputation seems to be entityspecific <ref type="bibr" coords="4,169.41,509.20,9.96,8.74" target="#b6">[7]</ref>, we build models per entity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Training and parameter selection</head><p>Section 2.1 lists two feature representations: bag of entities (BoE) and BoE + bag of words (BoE+BoW). The BoW representation was generated by tokenizing the text of the tweet using a Twitter-specific tokenizer <ref type="bibr" coords="4,360.32,584.25,10.52,8.74" target="#b5">[6]</ref> and removing stopwords (using both Spanish and English stopword lists). Additionally, the feature values could be presence or TF.IDF. We used 10 fold cross-validation (10CV) and iterative time-based splitting (ITS) <ref type="bibr" coords="4,162.84,632.21,10.52,8.74" target="#b3">[4]</ref> to evaluate the performance of the features. ITS ensures that classification of past tweets cannot be learnt from future tweets. Thus, we sort the tweets according to their time stamps and train the classifier on the first K tweets and evaluate on the next K tweets. We then train on the first 2K tweets and evaluate on the next K tweets, etc. The total accuracy is the mean accuracy over all splits. We set K = 10. For both 10CV and ITS we used accuracy as our evaluation metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Submitted runs</head><p>The research questions that motivate our selection of submitted runs are:</p><p>RQ1 Does annotating a small number (15) of tweets from the test set improve the results? RQ2 Do language-dependent models perform better?</p><p>We submitted four runs based the research questions, and two additional runs based on our observation that the data is imbalanced. We submitted two baseline runs without applying active learning: UvA UNED filtering 1 and UvA UNEDfiltering 2. The first run is language-dependent, i.e., it uses a different NB model per language. The second run is language-independent, i.e., it uses a combined NB model for both languages. In order to answer RQ1, we submitted the two active learning runs UvA UNED filtering 3 and UvA UNED filtering 4. The initial models are based on UvA UNED filtering 1 and UvA UNED filtering 2, respectively. For the language-dependent case, we annotated 10 tweets per entity from the test set for English and 5 tweets per entity for Spanish. In the language-independent case, per entity, we annotated candidate 15 tweets from the test set. The runs UvA UNED filtering 5 and UvA UNED filtering 6 are UvA UNED filtering 3 and UvA UNED filtering 4, but when for an entity the training set related ratio 6 was &lt; 0.1 or &gt; 0.9, we used a winner-takes-all strategy. The winner-takes-all strategy classifies all the tweets as related or unrelated depending on which class is dominant in the training set.</p><p>Table <ref type="table" coords="5,176.77,470.28,4.98,8.74" target="#tab_0">1</ref> provides an overview over the runs. The official results are evaluated based on accuracy, reliability (R), sensitivity (S) and F(R,S), the F 1 -measure of R and S <ref type="bibr" coords="5,173.65,494.19,9.96,8.74" target="#b2">[3]</ref>. In the following we analyze the results on the training set in Section 4.1. We then elaborate on the official results in Section 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Preliminary experiments</head><p>Table <ref type="table" coords="6,163.12,222.88,4.98,8.74" target="#tab_1">2</ref> shows the accuracy for the two representation methods BoW+BoE and BoE. It shows results for coding the presence of the feature or the TF.IDF value. We can see that using the TF.IDF coding of the features works better than the Presence encoding. Additionally, we can see that using the BoE alone works better than the combination of both, BoE+BoW.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Submitted runs</head><p>Table <ref type="table" coords="7,161.86,138.80,4.98,8.74" target="#tab_4">4</ref> shows the results of our official runs with respect to accuracy, reliability (R), sensitivity (S), and F(R,S), the F 1 Measure of Reliability and Sensitivity. We can see that our baselines as well as the best performing system performs worse than a simple baseline. The provided baseline selects the class of an instance based on the class of the closest (using Jaccard similarity) instance in the training set.</p><p>We can, however, see some interesting improvements. For a start, active learning helps. We can see that the use of 1% annotation improves the results for all four metrics. Secondly, building a language-independent model performs better than building two language-dependent models per entity. Finally, we can see that the class imbalance also holds in the test set, as assigning the majority class for strongly skewed data performs much better than using active learning alone. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We have presented an active learning approach to company name disambiguation in tweets. For this classification task, we found that active learning does indeed improve the results in terms of accuracy, reliability, and sensitivity. Since our initial models perform significantly lower than an instance-based learning baseline (probably due to bugs in the implementation), future work will include the analysis of the impact of active learning on stronger baselines.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,192.23,655.03,230.89,7.89"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Overview of the proposed active learning process.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,137.50,527.35,307.93,140.22"><head>Table 1 .</head><label>1</label><figDesc>Overview over the runs submitted to RepLab 2013.</figDesc><table coords="5,137.50,551.34,307.93,116.23"><row><cell></cell><cell></cell><cell></cell><cell>language</cell></row><row><cell></cell><cell></cell><cell cols="2">dependent</cell><cell>independent</cell></row><row><cell cols="2">initial models</cell><cell cols="2">UvA UNED filtering 1 UvA UNED filtering 2</cell></row><row><cell cols="4">active learning (AL) UvA UNED filtering 3 UvA UNED filtering 4</cell></row><row><cell cols="4">AL + winner-takes-all UvA UNED filtering 5 UvA UNED filtering 6</cell></row><row><cell>6 related ratio =</cell><cell cols="2">|related| |related|+|unrelated|</cell><cell>.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,134.77,304.62,345.82,91.90"><head>Table 2 .</head><label>2</label><figDesc>Accuracy for the different representation methods tested on the initial model, not split by language.</figDesc><table coords="6,242.94,339.57,129.48,56.95"><row><cell>Representation</cell><cell>10CV ITS</cell></row><row><cell cols="2">BoE+BoW -Presence 0.42 0.46</cell></row><row><cell>BoE+BoW -TF.IDF</cell><cell>0.68 0.72</cell></row><row><cell>BoE -Presence</cell><cell>0.66 0.70</cell></row><row><cell>BoE -TF.IDF</cell><cell>0.76 0.79</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,134.77,428.65,345.83,80.47"><head>Table 3</head><label>3</label><figDesc>shows the accuracy for the two representation methods BoW+BoE and BoE for models built on split languages. It shows results for coding the presence of the feature or the TF.IDF value. Again, we can see that only using the BoE representation performs better in both test settings, 10CV and ITS. Additionally, we can see that here that TF.IDF outperforms performs better than Presence. We therefore choose to use the BoE representation coded with TF.IDF for our submitted runs.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,134.77,532.37,345.82,102.86"><head>Table 3 .</head><label>3</label><figDesc>Accuracy for the different represenation methods tested on the initial model, split by language.</figDesc><table coords="6,215.86,567.31,183.64,67.91"><row><cell></cell><cell>English</cell><cell>Spanish</cell></row><row><cell cols="3">Representation method 10CV ITS 10CV ITS</cell></row><row><cell cols="3">BoE + BoW -Presence 0.60 0.60 0.65 0.46</cell></row><row><cell>BoE + BoW -TF.IDF</cell><cell cols="2">0.71 0.72 0.71 0.52</cell></row><row><cell>BoE -Presence</cell><cell cols="2">0.67 0.69 0.74 0.54</cell></row><row><cell>BoE -TF.IDF</cell><cell cols="2">0.78 0.78 0.78 0.57</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,200.04,301.74,215.28,112.07"><head>Table 4 .</head><label>4</label><figDesc>Results of the official runs. UvA UNED filtering 1 0.2785 0.1635 0.1258 0.0730 UvA UNED filtering 2 0.2847 0.2050 0.1441 0.0928 UvA UNED filtering 3 0.5657 0.2040 0.2369 0.1449 UvA UNED filtering 4 0.6360 0.2386 0.2782 0.1857 UvA UNED filtering 5 0.7745 0.6486 0.1833 0.1737 UvA UNED filtering 6 0.8155 0.6780 0.2187 0.2083</figDesc><table coords="7,200.04,323.98,215.28,24.08"><row><cell>run id</cell><cell>accuracy R</cell><cell>S F(R,S)</cell></row><row><cell>baseline</cell><cell cols="2">0.8714 0.4902 0.3200 0.3255</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="3,144.73,635.53,207.12,7.47"><p>http://www.mediawiki.org/wiki/API:Properties</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="3,144.73,645.84,293.28,7.86"><p>Each linked entity, hashtag, named user and author is treated as a term.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="3,144.73,657.44,70.61,7.47"><p>http://nltk.org</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>This research was partially supported by the <rs type="funder">Spanish Ministry of Education</rs> (<rs type="grantName">FPU</rs> grant nr <rs type="grantNumber">AP2009-0507</rs>), the <rs type="funder">Spanish Ministry of Science and Innovation</rs> (<rs type="projectName">Holopedia</rs> Project, <rs type="grantNumber">TIN2010-21128-C02</rs>), the <rs type="funder">Regional Government of Madrid</rs> and the <rs type="funder">ESF</rs> under <rs type="projectName">MA2VICMR</rs> (<rs type="grantNumber">S2009/TIC-1542</rs>) the <rs type="programName">European Community's Seventh Framework Programme</rs> (<rs type="grantNumber">FP7/2007-2013</rs>) under grant agreements nr <rs type="grantNumber">258191</rs> (<rs type="programName">PROMISE Network of Excellence</rs>) and <rs type="grantNumber">288024</rs> (<rs type="projectName">LiMoSINe</rs> project), the <rs type="funder">Netherlands Organisation for Scientific Research (NWO)</rs> under project nrs <rs type="grantNumber">640.004.802</rs>, <rs type="grantNumber">727.011.005</rs>, <rs type="grantNumber">612.001.116</rs>, <rs type="grantNumber">HOR-11-10</rs>, the <rs type="funder">Center for Creation, Content and Technology (CCCT)</rs>, the <rs type="projectName">BILAND</rs> project funded by the <rs type="programName">CLARIN-nl program</rs>, the <rs type="programName">Dutch national program COMMIT</rs>, the <rs type="programName">ESF Research Network Program</rs> <rs type="projectName">ELIAS</rs>, the <rs type="projectName">Elite Network Shifts</rs> project funded by the <rs type="funder">Royal Dutch Academy of Sciences (KNAW)</rs>, the <rs type="funder">Netherlands eScience Center</rs> under project number <rs type="grantNumber">027.012.105</rs>, and the <rs type="programName">Yahoo! Faculty Research and Engagement Program</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_vDEdjYn">
					<idno type="grant-number">AP2009-0507</idno>
					<orgName type="grant-name">FPU</orgName>
				</org>
				<org type="funded-project" xml:id="_RnRG87m">
					<idno type="grant-number">TIN2010-21128-C02</idno>
					<orgName type="project" subtype="full">Holopedia</orgName>
				</org>
				<org type="funded-project" xml:id="_ZUpvYQn">
					<idno type="grant-number">S2009/TIC-1542</idno>
					<orgName type="project" subtype="full">MA2VICMR</orgName>
					<orgName type="program" subtype="full">European Community&apos;s Seventh Framework Programme</orgName>
				</org>
				<org type="funding" xml:id="_m3BkpJC">
					<idno type="grant-number">FP7/2007-2013</idno>
				</org>
				<org type="funding" xml:id="_YKe3qr6">
					<idno type="grant-number">258191</idno>
					<orgName type="program" subtype="full">PROMISE Network of Excellence</orgName>
				</org>
				<org type="funded-project" xml:id="_s3kuQ8m">
					<idno type="grant-number">288024</idno>
					<orgName type="project" subtype="full">LiMoSINe</orgName>
				</org>
				<org type="funding" xml:id="_hZmPmc5">
					<idno type="grant-number">640.004.802</idno>
				</org>
				<org type="funding" xml:id="_eDFjwWW">
					<idno type="grant-number">727.011.005</idno>
				</org>
				<org type="funding" xml:id="_3a7gsxT">
					<idno type="grant-number">612.001.116</idno>
				</org>
				<org type="funded-project" xml:id="_GDxQuHJ">
					<idno type="grant-number">HOR-11-10</idno>
					<orgName type="project" subtype="full">BILAND</orgName>
					<orgName type="program" subtype="full">CLARIN-nl program</orgName>
				</org>
				<org type="funding" xml:id="_JUPr8CY">
					<orgName type="program" subtype="full">Dutch national program COMMIT</orgName>
				</org>
				<org type="funded-project" xml:id="_YTpuGrf">
					<orgName type="project" subtype="full">ELIAS</orgName>
					<orgName type="program" subtype="full">ESF Research Network Program</orgName>
				</org>
				<org type="funded-project" xml:id="_rQEQ6rA">
					<orgName type="project" subtype="full">Elite Network Shifts</orgName>
				</org>
				<org type="funding" xml:id="_3yr2g3M">
					<idno type="grant-number">027.012.105</idno>
					<orgName type="program" subtype="full">Yahoo! Faculty Research and Engagement Program</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,142.96,602.03,337.64,7.86;7,151.52,612.99,329.07,7.86;7,151.52,623.95,206.58,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,415.45,602.03,65.14,7.86;7,151.52,612.99,282.85,7.86">WePS-3 Evaluation Campaign: Overview of the Online Reputation Management Task</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Artiles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Corujo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,455.90,612.99,24.70,7.86;7,151.52,623.95,177.90,7.86">CLEF 2010 Labs and Workshops Notebook Papers</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,634.88,337.63,7.86;7,151.52,645.84,329.07,7.86;7,151.52,656.80,159.24,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,396.82,634.88,83.78,7.86;7,151.52,645.84,236.87,7.86">Overview of RepLab 2012: Evaluating Online Reputation Management Systems</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Corujo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Meij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,411.06,645.84,69.52,7.86;7,151.52,656.80,130.57,7.86">CLEF 2012 Labs and Workshop Notebook Papers</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,119.67,337.63,7.86;8,151.52,130.63,221.30,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,298.57,119.67,182.02,7.86;8,151.52,130.63,76.30,7.86">A General Evaluation Measure for Document Organization Tasks</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Verdejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,249.17,130.63,98.43,7.86">Proceedings SIGIR 2013</title>
		<meeting>SIGIR 2013</meeting>
		<imprint>
			<date>Jul.</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,141.59,337.64,7.86;8,151.52,152.55,329.07,7.86;8,151.52,163.51,261.33,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,329.90,141.59,150.69,7.86;8,151.52,152.55,294.19,7.86">Others: Automatic Categorization of Email into Folders: Benchmark Experiments on Enron and SRI Corpora</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Bekkerman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,453.68,152.55,26.91,7.86;8,151.52,163.51,143.51,7.86">Center for Intelligent Information Retrieval</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report IR</note>
</biblStruct>

<biblStruct coords="8,142.96,174.47,337.63,7.86;8,151.52,185.43,329.07,7.86;8,151.52,196.39,56.31,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,313.14,174.47,149.10,7.86">Adding semantics to microblog posts</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Meij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Weerkamp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,151.52,185.43,329.07,7.86;8,151.52,196.39,27.65,7.86">Proceedings of the fifth ACM international conference on Web search and data mining</title>
		<meeting>the fifth ACM international conference on Web search and data mining</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,207.34,337.64,7.86;8,151.52,218.30,269.10,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,307.52,207.34,173.07,7.86;8,151.52,218.30,105.77,7.86">Tweetmotif: Exploratory search and topic summarization for Twitter</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>O'connor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Krieger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ahn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,264.53,218.30,94.66,7.86">Proceedings of ICWSM</title>
		<meeting>ICWSM</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="2" to="3" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,229.26,337.63,7.86;8,151.52,240.22,329.07,7.86;8,151.52,251.18,123.69,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,331.53,229.26,127.70,7.86">From sentiment to reputation</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">H</forename><surname>Peetz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Schuth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,379.30,240.22,101.29,7.86;8,151.52,251.18,90.26,7.86">CLEF (Online Working Notes/Labs/Workshop</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Karlgren</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Womser-Hacker</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,262.14,337.63,7.86;8,151.52,273.10,187.09,7.86" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="8,198.12,262.14,127.87,7.86">Active learning literature survey</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Settles</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>University of Wisconsin-Madison</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Computer Sciences Technical Report 1648</note>
</biblStruct>

<biblStruct coords="8,142.96,284.06,337.63,7.86;8,151.52,295.02,329.07,7.86;8,151.52,305.98,25.60,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,293.81,284.06,186.78,7.86;8,151.52,295.02,105.16,7.86">Discovering filter keywords for company name disambiguation in Twitter</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigó</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,264.39,295.02,139.47,7.86">Expert Systems with Applications</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4986" to="5003" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,316.93,337.98,7.86;8,151.52,327.89,269.72,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,437.07,316.93,43.52,7.86;8,151.52,327.89,131.24,7.86">Identifying entity aspects in microblog posts</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Meij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Oghina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Bui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Breuss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,303.80,327.89,23.62,7.86">SIGIR</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1089" to="1090" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,338.85,337.97,7.86;8,151.52,349.81,244.28,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,237.11,338.85,243.48,7.86;8,151.52,349.81,68.99,7.86">Support vector machine active learning with applications to text classification</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,227.14,349.81,83.91,7.86">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="45" to="66" />
			<date type="published" when="2002-03">Mar 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,360.77,337.97,7.86;8,151.52,371.73,185.07,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,252.18,360.77,160.34,7.86">The University of Amsterdam at WePS3</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tsagkias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,434.56,360.77,46.03,7.86;8,151.52,371.73,156.39,7.86">CLEF 2010 Labs and Workshops Notebook Papers</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
