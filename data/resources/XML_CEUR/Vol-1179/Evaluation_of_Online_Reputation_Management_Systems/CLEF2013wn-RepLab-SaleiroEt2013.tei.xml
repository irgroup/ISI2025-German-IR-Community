<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,147.01,115.96,321.45,12.62;1,232.03,133.89,151.34,12.62">POPSTAR at RepLab 2013: Name ambiguity resolution on Twitter</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,140.32,171.83,56.80,8.74"><forename type="first">Pedro</forename><surname>Saleiro</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">DEI-FEUP</orgName>
								<orgName type="department" key="dep2">Labs Sapo UP</orgName>
								<orgName type="institution">INESC TEC University of Porto</orgName>
								<address>
									<addrLine>Rua Dr. Roberto Frias, s/n</addrLine>
									<postCode>4200-465</postCode>
									<settlement>Porto</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,204.45,171.83,34.76,8.74"><forename type="first">Luís</forename><surname>Rei</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">DEI-FEUP</orgName>
								<orgName type="department" key="dep2">Labs Sapo UP</orgName>
								<orgName type="institution">INESC TEC University of Porto</orgName>
								<address>
									<addrLine>Rua Dr. Roberto Frias, s/n</addrLine>
									<postCode>4200-465</postCode>
									<settlement>Porto</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,246.85,171.83,63.12,8.74"><forename type="first">Arian</forename><surname>Pasquali</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">DEI-FEUP</orgName>
								<orgName type="department" key="dep2">Labs Sapo UP</orgName>
								<orgName type="institution">INESC TEC University of Porto</orgName>
								<address>
									<addrLine>Rua Dr. Roberto Frias, s/n</addrLine>
									<postCode>4200-465</postCode>
									<settlement>Porto</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,317.67,171.83,57.24,8.74"><forename type="first">Carlos</forename><surname>Soares</surname></persName>
							<email>csoares@fe.up.pt</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">DEI-FEUP</orgName>
								<orgName type="department" key="dep2">Labs Sapo UP</orgName>
								<orgName type="institution">INESC TEC University of Porto</orgName>
								<address>
									<addrLine>Rua Dr. Roberto Frias, s/n</addrLine>
									<postCode>4200-465</postCode>
									<settlement>Porto</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,382.60,171.83,60.22,8.74"><forename type="first">Jorge</forename><surname>Teixeira</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">DEI-FEUP</orgName>
								<orgName type="department" key="dep2">Labs Sapo UP</orgName>
								<orgName type="institution">INESC TEC University of Porto</orgName>
								<address>
									<addrLine>Rua Dr. Roberto Frias, s/n</addrLine>
									<postCode>4200-465</postCode>
									<settlement>Porto</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,450.32,171.83,24.79,8.74;1,183.44,183.79,22.03,8.74"><forename type="first">Fábio</forename><surname>Pinto</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">DEI-FEUP</orgName>
								<orgName type="department" key="dep2">Labs Sapo UP</orgName>
								<orgName type="institution">INESC TEC University of Porto</orgName>
								<address>
									<addrLine>Rua Dr. Roberto Frias, s/n</addrLine>
									<postCode>4200-465</postCode>
									<settlement>Porto</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,213.20,183.79,81.91,8.74"><forename type="first">Mohammad</forename><surname>Nozari</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">DEI-FEUP</orgName>
								<orgName type="department" key="dep2">Labs Sapo UP</orgName>
								<orgName type="institution">INESC TEC University of Porto</orgName>
								<address>
									<addrLine>Rua Dr. Roberto Frias, s/n</addrLine>
									<postCode>4200-465</postCode>
									<settlement>Porto</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,302.90,183.79,61.98,8.74"><forename type="first">Catarina</forename><surname>Félix</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">DEI-FEUP</orgName>
								<orgName type="department" key="dep2">Labs Sapo UP</orgName>
								<orgName type="institution">INESC TEC University of Porto</orgName>
								<address>
									<addrLine>Rua Dr. Roberto Frias, s/n</addrLine>
									<postCode>4200-465</postCode>
									<settlement>Porto</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,372.27,183.79,59.72,8.74"><forename type="first">Pedro</forename><surname>Strecht</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">DEI-FEUP</orgName>
								<orgName type="department" key="dep2">Labs Sapo UP</orgName>
								<orgName type="institution">INESC TEC University of Porto</orgName>
								<address>
									<addrLine>Rua Dr. Roberto Frias, s/n</addrLine>
									<postCode>4200-465</postCode>
									<settlement>Porto</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,147.01,115.96,321.45,12.62;1,232.03,133.89,151.34,12.62">POPSTAR at RepLab 2013: Name ambiguity resolution on Twitter</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5EF1707926F852E1CAD2D1C4EDD61A5E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Online Reputation Management, Word Sense Disambiguation</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Filtering tweets relevant to a given entity is an important task for online reputation management systems. This contributes to a reliable analysis of opinions and trends regarding a given entity. In this paper we describe our participation at the Filtering Task of RepLab 2013. The goal of the competition is to classify a tweet as relevant or not relevant to a given entity. To address this task we studied a large set of features that can be generated to describe the relationship between an entity and a tweet. We explored different learning algorithms as well as, different types of features: text, keyword similarity scores between entities metadata and tweets, Freebase entity graph and Wikipedia. The test set of the competition comprises more than 90000 tweets of 61 entities of four distinct categories: automotive, banking, universities and music. Results show that our approach is able to achieve a Reliability of 0.72 and a Sensitivity of 0.45 on the test set, corresponding to an F-measure of 0.48 and an Accuracy of 0.908.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The relationship between people and public entities has changed with the rise of social media. Online users of social networks, blogs and micro-blogs are able to directly express and spread opinions about public entities, such as politicians, artists, companies or products. Online Reputation Management aims to automatically process online information about public entities. Some of the common tasks within Online Reputation Management consist in collecting, processing and aggregating social network messages to extract opinion trends about such entities .</p><p>Twitter, one of the most used online social networks, provides a search system that allows users to query for tweets containing a set of keywords. Online Reputation Management systems often use Twitter as a source of information when monitoring a given entity. However, search results are not necessarily relevant to that entity because keywords can be ambiguous. For instance, a tweet containing the word "columbia" can be related with several entities, such as a federal state, a city or a university. Furthermore, tweets are short which results in a reduced context for entity disambiguation. When monitoring the reputation of a given entity on Twitter, it is first necessary to guarantee that all tweets are relevant to that entity. Consequently, other processing tasks, such as sentiment analysis will benefit from filtering out noise in the data stream.</p><p>In this work, we tackle the aforementioned problem by applying a supervised learning approach. We studied a large set of features that can be generated to describe the relationship between an entity and a tweet and different learning algorithms. Concerning features, we used meta-data, tweet postings represented with TF-IDF, similarity between tweets and Wikipedia, Freebase entities disambiguation, feature selection of terms based on frequency and transformation of content representation using SVD. The algorithms tested include Naive Bayes, SVM, Random Forests, Decision trees and Neural networks.</p><p>The resulting classifier participated in the Filtering task of RepLab 2013 <ref type="bibr" coords="2,467.36,314.14,9.97,8.74" target="#b0">[1]</ref>. The corpus used for the competition consisted of a collection of tweets both in English and Spanish, possibly relevant to 61 entities from four domains: automotive, banking, universities and music.</p><p>The reminder of this paper consists in the overview of the Filtering task followed by the explanation of our methodology in Section 3. Experimental setup and results are described in Section 4 and 5, respectively, followed by the conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Task Overview</head><p>RepLab 2013 <ref type="bibr" coords="2,193.71,474.86,10.52,8.74" target="#b0">[1]</ref> focus on monitoring the online reputation of entities on Twitter. The Filtering task consists in determining which tweets are relevant to each entity. The corpus consists of a collection of tweets obtained by querying the Twitter Search API with 61 entity names during the period from the June 2012 until the December 2012. The corpus contain tweets both in English and Spanish. The balance between both languages varies for each entity. Tweets were manually annotated as "Related" or "Unrelated" to the respective target entity.</p><p>The data provided to participants consists in tweets and a list of 61 entities. For each tweet in the corpus we have the target entity id, the language of the tweet, the timestamp and the tweet id. The content of each URL in the tweets is also provided. Due to Twitter's terms of service, the participants were responsible to download the tweets using the respective id. The data related with entities contain the query used to collect the tweets (e.g. "BMW"), the official name of the entity (e.g. "Bayerische Motoren Werke AG"), the category of the entity (e.g. "automotive"), the content of its homepage and both Wikipedia articles in English and Spanish.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>The task we are tackling consists in building a relevance classifier: given an entity e i and a tweet t j we want to classify t j as Related or Unrelated to e i . We use a supervised learning approach to address this problem. In this section, we describe our approach which comprises pre-processing of raw tweets and selecting the most appropriate feature representation of the relationship between entities and tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Pre-processing</head><p>Contrary to other type of online texts (e.g. news or blog posts) tweets contain informal and non-standard language containing emoticons, spelling errors, wrong letter casing, unusual punctuation and abbreviations. Therefore, we apply some pre-processing techniques for text normalization. We use a tokenizer <ref type="bibr" coords="3,445.26,285.41,10.52,8.74" target="#b1">[2]</ref> optimized for segmenting words in tweets. After tokenization we apply the following procedure:</p><p>1. extract user mentions and URLs. 2. convert hashtags to words by removing the hash symbol. 3. remove all punctuation. 4. convert text to lower case. 5. remove accents and convert non-ASCII characters to their ASCII equivalent. 6. remove stopwords based on the list of stopwords for English and Spanish of NLTK.</p><p>We apply the same normalization process to metadata about the entities, namely query and entity name.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Features</head><p>We are interested in exploring the best combination of features to optimize relevance classification. We investigate several types of features: TF-IDF of n-grams, keyword similarities between tweets and entities as well as external resources projections.</p><p>RepLab metadata: we use entity's category, query and the language of tweets as features. TF-IDF: we calculate TF-IDF of uni-grams, bi-grams and tri-grams using the normalized text of tweets. Text probability : we encapsulate text in a single feature to avoid high dimensionality issues when adding other features. We use the TF-IDF of unigrams, bi-grams and tri-grams for training a text classifier which calculates the probability of a tweet being related to the expected entity. We use the output probabilities of the classifier as a feature by applying a scheme of cross folds to train and classify within the training set. Regarding the test set, we use all tweets of the training set as training of the text classifier.</p><p>Keyword similarity: we calculate similarity scores between Replab metada and the tweets, by calculating the ratio of the number of common terms in the tweet and the terms of query and entity name. We also calculate similarities at character level in order to include possible spelling errors in the tweet. We apply the same procedure for user mentions and hashtags. Web similarity: we calculate the similarity between the tweet text and the normalized content of the entity's homepage and normalized Wikipedia articles. The similarity value is the number of common terms multiplied by logarithm of the number of terms in tweet. Freebase: For each keyword of the entity's query present in the tweet we create two bi-grams, containing the keyword and the previous/subsequent word. We submit these bi-grams to the Freebase Search API and compare the list of retrieved entities with the id of the target entity on Freebase. We calculate a Freebase score by using the inverse position of the target entity in the list of results retrieved. If the target entity is the first result, the score is 1, if it is the second, the score is 0.5, and so on. If the target entity is not in the results list, the score is zero. The feature corresponds to the maximum score of the extracted bi-grams of each tweet. Category classifier: We create a sentence category classifier using the Wikipedia articles of each entity. We annotate each sentence of the Wikipedia articles with the category of the corresponding entity. We calculate TF-IDF for unigrams, bi-grams and tri-grams and train a multi-class classifier (SVM). We classify each tweet using this classifier. We use as feature the probability of the tweet being relevant to its target class. Twitter metadata: We use URL domains, hashtags and user mentions as features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Set-up</head><p>The dataset provided by the RepLab 2013 organization is divided in training, test and background. The test dataset is not labeled and it is used to create submissions for the competition. We discarded the background tweets which were also not labeled. The text and metadata of tweets was collected using a script provided by the organization. The training set consists in a total of 45671 tweets from which we were able to download 43582. Approximately 75% of tweets in the training set are labeled as "Related" as depicted in Table <ref type="table" coords="4,417.42,548.13,3.88,8.74" target="#tab_0">1</ref>.</p><p>We split the training dataset into a development set and a validation set, containing 80% and 20% of the original, respectively. We adopted a randomly stratified split approach per entity, i.e., we group tweets of each entity and randomly split them preserving the balance of "Related"/"Unrelated" tweets. The submission dataset consists of 90356 tweets from which we were able to download 88934. We used the development set for trying new features and test algorithms. We divided the development set in 10 folds generated with the randomly stratified approach. The validation set remained untouched until near the submission deadline. At this time, we used the validation set to validate the results obtained in the development set. The purpose of this validation step is to evaluate how well our classifier generalizes from its training data to the validation data and thus estimate how well it will generalize to the test set. It allows us to spot overfitting. After validation, our submissions were trained using all of the data in the training dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>We tried to create different submissions using different algorithms, features and we also tried to create entity specific models as explained in Table <ref type="table" coords="5,436.93,337.84,3.88,8.74" target="#tab_1">2</ref>. We applied selection of features based on frequency and transformation of content representation using SVD. The algorithms tested include Naive Bayes, SVM, Random Forests, Decision trees and Neural networks. The evaluation measures used are accuracy and the official metric of the competition, F-measure which is the harmonic mean of Reliability and Sensitivity <ref type="bibr" coords="5,359.91,397.62,9.97,8.74" target="#b2">[3]</ref>. We submitted a total of 10 submissions to the RepLab competition though, we only present the top 4 submissions regarding the F-measure. Table <ref type="table" coords="5,176.06,596.35,4.98,8.74" target="#tab_2">3</ref> shows the results of our top submissions and the official baseline of the competition. This baseline classifies each tweet with the label of the most similar tweet of target entity in the training set using Jaccard similarity coefficient. The baseline results were obtained using 99.5% of the test set.</p><p>Based on the results achieved we are able to conclude that the models of our classifier are able to generalize successfully. Results obtained in the validation set are similar to those obtained in the test set. During development, solutions based on one model per entity were consistently outperformed by solutions based on global models. We also noticed during development that language specific models did not exhibit improvements in global accuracy, therefore we opted to use language as a feature. Results show that the best submission uses the Random Forests classifier with 500 estimators for training a global model and it does not contain the TF-IDF feature. Though, the Text Probabilities feature encapsulates text by using a specific model trained just with TF-IDF of n-grams of tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this paper we have described the POPSTAR participation at the Filtering task of RepLab 2013. The main goal of this task was to classify tweets as relevant or not to a given target entity. We have explored several types of features, namely similarity between keywords, TF-IDF of n-grams and we have also explored external resources such as Freebase and Wikipedia. Results show that it is possible to achieve an Accuracy over 0.90 and an F-measure of 0.48 in a test set containing more than 90000 tweets of 61 entities.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,229.92,117.79,155.52,64.19"><head>Table 1 .</head><label>1</label><figDesc>Dataset description.</figDesc><table coords="5,229.92,117.79,155.52,53.28"><row><cell>Dataset</cell><cell cols="3">Related Unrelated Total</cell></row><row><cell>Training</cell><cell cols="2">33193 10389</cell><cell>43582</cell></row><row><cell cols="3">Development 26534 8307</cell><cell>34841</cell></row><row><cell>Validation</cell><cell>6659</cell><cell>2082</cell><cell>8741</cell></row><row><cell>Test</cell><cell>-</cell><cell>-</cell><cell>90356</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,141.32,453.65,326.65,108.08"><head>Table 2 .</head><label>2</label><figDesc>Submissions description.</figDesc><table coords="5,141.32,453.65,326.65,97.17"><row><cell>Submission</cell><cell>Algorithm</cell><cell>Features</cell><cell>No. of models</cell></row><row><cell>popstar filtering 2</cell><cell>Random Forests</cell><cell>No TF-IDF and no Twitter metadata</cell><cell>1, global</cell></row><row><cell>popstar filtering 3</cell><cell>Logistic Regression</cell><cell>Both TF-IDF and Twitter metadata</cell><cell>1, global</cell></row><row><cell>popstar filtering 7</cell><cell>SVM</cell><cell>No TF-IDF and no Twitter metadata</cell><cell>1, global</cell></row><row><cell>popstar filtering 8</cell><cell>Random Forests</cell><cell>No TF-IDF and no Twitter metadata</cell><cell>61, 1 per entity</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,150.89,117.79,313.11,86.76"><head>Table 3 .</head><label>3</label><figDesc>Official results for each submission plus our validation set accuracy.</figDesc><table coords="6,150.89,117.79,312.99,75.80"><row><cell>Submission</cell><cell>Accuracy (Val. Set)</cell><cell cols="4">Accuracy Reliability Sensitivity F-measure</cell></row><row><cell>popstar filtering 2</cell><cell>0.945</cell><cell>0.908</cell><cell>0.729</cell><cell>0.451</cell><cell>0.488</cell></row><row><cell>popstar filtering 3</cell><cell>0.947</cell><cell>0.907</cell><cell>0.765</cell><cell>0.440</cell><cell>0.480</cell></row><row><cell>popstar filtering 7</cell><cell>0.944</cell><cell>0.906</cell><cell>0.759</cell><cell>0.428</cell><cell>0.470</cell></row><row><cell>popstar filtering 8</cell><cell>0.948</cell><cell>0.902</cell><cell>0.589</cell><cell>0.444</cell><cell>0.448</cell></row><row><cell>Official Baseline</cell><cell>-</cell><cell>0.8714</cell><cell>0.4902</cell><cell>0.3199</cell><cell>0.3255</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,138.34,518.99,342.15,7.86;6,146.91,529.95,333.57,7.86;6,146.91,540.91,333.68,7.86;6,146.91,551.87,333.65,7.86;6,146.91,562.83,20.99,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,306.45,529.95,174.03,7.86;6,146.91,540.91,123.18,7.86">Overview of replab 2013 evaluating online reputation monitoring systems</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carrillo De Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Chugur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Corujo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Meij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,293.67,540.91,186.92,7.86;6,146.91,551.87,89.34,7.86">Fourth International Conference of the CLEF initiative, CLEF 2013</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Springer LNCS</publisher>
			<date type="published" when="2013-09">September 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.34,573.79,342.12,7.86;6,146.91,584.75,333.69,7.86;6,146.91,595.71,333.68,7.86;6,146.91,606.66,92.91,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,374.95,573.79,105.51,7.86;6,146.91,584.75,175.48,7.86">Tokenizing micro-blogging messages using a text classification approach</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Laboreiro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Sarmento</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Teixeira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Oliveira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,343.62,584.75,136.98,7.86;6,146.91,595.71,227.84,7.86">Proceedings of the fourth workshop on Analytics for noisy unstructured text data, AND 10</title>
		<meeting>the fourth workshop on Analytics for noisy unstructured text data, AND 10<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="81" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.34,617.62,342.18,7.86;6,146.91,628.58,216.15,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,308.22,617.62,172.30,7.86;6,146.91,628.58,72.38,7.86">A general evaluation measure for document organization tasks</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Verdejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,240.98,628.58,95.67,7.86">Proceedings SIGIR 2013</title>
		<meeting>SIGIR 2013</meeting>
		<imprint>
			<date>July</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
