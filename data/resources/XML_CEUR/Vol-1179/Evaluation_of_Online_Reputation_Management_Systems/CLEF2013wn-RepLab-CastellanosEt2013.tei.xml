<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,144.62,152.67,305.72,12.64;1,178.94,170.67,237.29,12.64">Modelling Techniques for Twitter Contents: A step beyond classification based approaches</title>
				<funder ref="#_FwjtsJf">
					<orgName type="full">Regional Government of Madrid under Research Network MA2VIRMR</orgName>
				</funder>
				<funder ref="#_r4sPvQ5">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,180.86,210.18,71.37,8.96"><forename type="first">Angel</forename><surname>Castellanos</surname></persName>
							<email>acastellanos@lsi.uned.es</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing and Information Retrieval Group</orgName>
								<orgName type="institution">UNED Juan del Rosal</orgName>
								<address>
									<addrLine>16 (Ciudad Universitaria)</addrLine>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,258.81,210.18,55.81,8.96"><forename type="first">Juan</forename><surname>Cigarrán</surname></persName>
							<email>juanci@lsi.uned.es</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing and Information Retrieval Group</orgName>
								<orgName type="institution">UNED Juan del Rosal</orgName>
								<address>
									<addrLine>16 (Ciudad Universitaria)</addrLine>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,334.10,210.18,80.12,8.96"><forename type="first">Ana</forename><surname>García-Serrano</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing and Information Retrieval Group</orgName>
								<orgName type="institution">UNED Juan del Rosal</orgName>
								<address>
									<addrLine>16 (Ciudad Universitaria)</addrLine>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,144.62,152.67,305.72,12.64;1,178.94,170.67,237.29,12.64">Modelling Techniques for Twitter Contents: A step beyond classification based approaches</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D854EB5E5787DD9F4BBFF06FCF96E378</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Formal Concept Analysis</term>
					<term>Stability</term>
					<term>Kullback Leibler Divergence</term>
					<term>Content Modelling</term>
					<term>ORM</term>
					<term>POS Tagging</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we present our first participation at RepLab Campaign. Our work is focused in two contributions. The first one is the use of an IR method to address Polarity and Filtering tasks. These two tasks can be seen as the same problem: to find the most relevant class to annotate a given tweet. For that, we applied a classical IR approach, using the tweet content as query against an index with the models of the classes used to annotate tweets. To model these classes we propose the use of the Kullback Leibler Divergence (KLD), in order to extract their most representative terminology. Different data and ways to model these data (through KLD) are also proposed. The second contribution is related to the Topic Detection task. Instead a clustering based technique; we propose the application of Formal Concept Analysis (FCA) to represent the contents in a lattice structure. To extract topics from the lattice, we applied a FCA concept: stability. According to the results, our IR based approach has been proven as very satisfactory for the Polarity task, while for the Filtering task, it seems to be less suitable. On the other hand FCA modelling has been demonstrated as a promising methodology for Topic Detection, achieving high successful results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper we summarize our participation in the 2013 edition of the RepLab Campaign <ref type="bibr" coords="1,152.18,572.30,10.68,8.96" target="#b0">[1]</ref>. RepLab Campaign is focused on the Online Reputation Management (ORM) task; that is, the reputation monitoring of entities and persons on the Web, and more concretely in Twitter. Our participation focuses on three of the RepLab Tasks: in the filtering and polarity tasks and, by other hand, in the topic detection task. The first two tasks (filtering and polarity) are usually addressed through classification approaches: a data set is used to train classification systems and learns a set of classes (related/unrelated, positive/neutral/negative) allowing the classification of new contents. More sophisticated approaches, based on probabilistic techniques, have been also recently proposed to address filtering and polarity tasks; one of them, maybe the most widely used, is Topic Modelling.</p><p>Both tasks (filtering and polarity) can be seen technically as the same task: given a tweet to annotate, find the most similar class. For that, instead of the common state of the art approaches, we propose the application of an IR based annotation that, given a tweet to annotate, uses its content as query against an index containing the content models of the classes to annotate the tweet. To generate these content models, we apply a divergence based technique (Kullback Leibler Divergence) to find the most representative terminology of each class. We have previously applied this technique for content modelling, outperforming other content modelling techniques <ref type="bibr" coords="2,420.37,234.21,11.00,8.96" target="#b2">[3]</ref>, and also for content modelling for polarity and sentiment detection <ref type="bibr" coords="2,358.72,246.21,10.89,8.96" target="#b3">[4]</ref>.</p><p>The other task in which we have participated this year is the topic detection task. As in the previous tasks, classification approaches has been commonly used to address the detection of topics. However, this approach poses a problem: often new topics unseen in the training data appear along the time, making useless to detect them the learnt classes. To solve that, unsupervised techniques based on clustering have been proposed. But, even these techniques have many problems with the issue of topics diversity.</p><p>Given this problems, we propose a Formal Concept Analysis (FCA) based approach. FCA allows the modelling of the contents (tweets) according to their attributes (terminology) in a lattice structure. FCA also allows the adaptation for detecting new topics while take advantage of knowledge provided by the training data. Once the content was modelled through FCA, clusters/topics should be selected; however, the number of concepts (possible topics) generated by FCA is potentially quite high. In order to select proper cluster/topics, we applied the concept of stability, coming from FCA field.</p><p>The rest of the paper is organized as follows: In section 2 we present the IR based approach applied for the Polarity and Filtering tasks, in section 3 we expose the novel application of FCA for the Topic Detection task, in section 4 we present the results of each task and, finally, in section 5 we present our conclusions and the feasible future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">IR-based approach for Polarity and Filtering Tasks</head><p>As we said before, filtering and polarity tasks can be as a classification problem. In filtering task, tweets have to be classified in RELATED and UNRELATED, while in polarity task they have to be classified in POSITIVE, NEGATIVE and NEUTRAL. So, we proposed the same approach for both tasks. Instead of common approaches, based on classification, we propose an IR-based approach. If we considered the contents of the tweets to be classified and the contents of the classes (gathered from the tweets in the training set annotated with them), these tasks can be seen as an IR task, using the tweet content as query against an index containing the class contents. Then, the classification will be dependent on the results of these queries. The work done for both tasks includes:</p><p> Annotation. A well-known problem in the use of tweets is the scarcity of information. To limit the impact of this problem, tweet contents have been processed in order to identify some features (hashtags, named entities, adjectives), which have been added to the information used to model the class.  Modelling. To represent each of the classes with their representative terminology, the contents of the tweets annotated with them in the training set have been modelled. The modelling technique is based on the comparison of class contents with the content of the rest of the class/es, by applying the Kullback-Leibler Divergence as weighting function <ref type="bibr" coords="3,226.14,222.42,10.77,8.96" target="#b7">[8]</ref>. The application of a divergence-based technique intends to identify the terminology that better differentiate one class from the rest. The different models generated for each class (see sections below) have been indexed taking into account the relevance of each term in the model, according KLD formulation.  IR-based Classification. To classify tweets, their contents have been used as query against the indexed models. Each tweet will be classified into the class with the highest relevance according the results returned by the query.</p><p>Specific details of these steps for each task, and the executed runs for each of them are presented in the sections below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Filtering</head><p>This task is focused on classify a set of tweets as related/unrelated to an entity. Our approach is based on modelling the related and unrelated content to identify the more representative terminology for every class in the collection. For that, we have experimented with different data sources: a) Wikipedia entity pages; b) Content of the set of tweets related to the entity and c) Content of the external webs which appear in the related tweets. Furthermore, we annotated Twitter data with some features, helpful to represent the entities: a) Named Entities (this annotation has been carried out through Stilus Core<ref type="foot" coords="3,169.94,470.48,3.24,5.83" target="#foot_0">1</ref> tool) and b) Hashtags, given that they are usually used to identify a specific topic in Twitter.</p><p>Our modelling is based on the comparison between terms of a specific content with terms present in the rest of the contents of the collection. In this context, it results in comparing the related (unrelated) terms of an entity with the related (unrelated) terms of the rest of the entities. Modelling the entities in this way, we will be able to say that a tweet is related to an entity if, using the tweet content as query, the IR system returns the entity model. It could be also interesting to identify the more representative terms of the related contents of an entity according to their unrelated contents. So, for each entity we have also modelled their related and unrelated content following this approach, denoted from here as Related vs. Unrelated (RvsU) modelling.</p><p>As our modelling is based on compare entities, since there are 4 domains in the collection (university, automotive, music and banking) some domain-specific words could be identified as entity-specific words (e.g. car and wheel can be set as representative of the automotive entities). To cope with this, we proposed a domain-specific modelling (in contrast with the "generic modelling"): each entity is modelled by comparing it only with the entities of its domain.</p><p>Besides of modelling experimentation, we have experimented with different IRbased methods. Firstly, given some tweet contents, we query against an index containing the related models of each entity: is the tweet related to a given entity? Nevertheless, looking at detail the collection there are much more tweets related than unrelated (about the 75% of the tweets). Taking that into account we propose an inverse approach by querying against the unrelated models: is not this tweet related with the entity? The idea is to consider all the tweets as related, except those for which we have solid evidences to the contrary.</p><p>Even so, some tweets are undoubtedly related with the entity, thus there is no need to check if the tweet is not related. This situation is addressed by querying against the Wikipedia models: since Wikipedia contents are very accurate, if a tweet is related to these contents, it will be related to the entity with a high probability.</p><p>Taking into account all of these considerations we have conducted the following experiments, summarized in Table <ref type="table" coords="4,265.61,330.21,3.90,8.96" target="#tab_0">1</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Polarity</head><p>This task is focused on identify the polarity of a tweet for the reputation of an entity.</p><p>We have followed the same approach as in the filtering task, modelling polarity values (POSITIVE, NEGATIVE and NEUTRAL) of each entity with its contents related, in the training set. In the same way that in the filtering task, we have experimented with different types of information, modelling techniques and classification approaches. To model each polarity we have used one single source: the content of the related tweets. From this source we have gathered: a) Tweet Contents and b) Adjectives identified in these tweet contents, using Stilus Core 2 . We have also applied generic and specific modelling, as in the filtering task, and what we have called most similar modelling. With this technique, given a tweet to be annotated, it searches for the most similar tweet in the training set and it uses its polarity as annotation. If there is not similar tweet, the first approach is applied. The intuition is that if two tweets are similar, their polarity has to be the same. With these considerations, we have developed the following runs: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Detecting Topics through a FCA-based Approach</head><p>Topic Detection task is focused on, given a stream of tweets related to an entity; identify topics in this stream. Usually this kind of task is addressed with a classificationbased approach, but this approach is not valid for this task, because topics in the new tweets may be not related to the training topics. All we know is: in the past these topics appeared in the tweets; now there is a set of new tweets, try to take advantage of the prior knowledge to detect topics in the new tweets.</p><p>The best way to address this task is a clustering-based approach. However, a clustering approach also has some drawback: How many clusters are? How can the systems take into account the prior knowledge? Does the running of the systems has to be fixed by the data in the training set or they have to show a certain degree of adaptability? These entire considerations make the Monitoring task an specially challenging task. To solve the clustering drawbacks we proposed a novel approach, especially suitable for the context of this task, based on Formal Concept Analysis (FCA). FCA can be seen as a powerful tool to automatically structure and classify all the resources retrieved and enriched from the Internet. This theory fits on a lattice-based clustering approach improving information access and exploratory tasks on pure Information Retrieval (IR) scenarios <ref type="bibr" coords="5,222.65,532.79,7.51,8.96" target="#b4">[5]</ref><ref type="bibr" coords="5,230.16,532.79,3.76,8.96" target="#b5">[6]</ref><ref type="bibr" coords="5,233.92,532.79,7.51,8.96" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">FCA Highlights</head><p>FCA is a mathematical theory <ref type="bibr" coords="5,256.37,582.74,16.76,8.96" target="#b11">[12]</ref> of concept formation derived from lattice and ordered set theories that provide a theoretical model to organize formal contexts: collections of objects related with sets of attributes. The main construct of the theory is the formal concept. A formal concept is a pair (O, A) with O is a set of objects (the extend of the formal concept), and A a set of attributes (the intend of the formal concept). In addition, O and A are connected as follows:</p><p> If an object o in O is tagged with an attribute a, then a must is included in A (i.e, the intend of the formal concept includes all the attributes shared by the objects in the extend).</p><p> Conversely, if an object o is tagged with all the attributes in A, then o must be included in A (i.e., the extend of the formal concept includes all those objects filtered out by the intend).</p><p>Formal concepts can be ordered by their extends. More formally, (O,A)  (O',A')  O  O'; in this case (O',A') is called a super-concept of (O,A) and, conversely, (O,A) a sub-concept of (O',A'). The order that results can be proved to be a lattice, which is called the concept lattice associated to the formal context.</p><p>In a concept lattice, two interesting kinds of formal concepts are object concepts and attribute concepts. Indeed:</p><p> The object concept associated with an object o is the most specific concept including o in its extend. In order to construct it, it is possible to include in its intend all the attributes of o, and to include in its extend, in addition to o, all those objects tagged exactly with the same attributes than o.  Conversely, the attribute concept associated with the attribute a is the most generic concept including a in its intend. It can be constructed in a dual way to an object concept: (i) add all the objects tagged by a to the extend, and (ii) in addition to a, add all the attributes shared by those objects to the intend.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Modelling</head><p>As FCA allows modelling a set of objects according to their attributes, in order to adapt this context to the Monitoring task, the tweets are identified as the objects, terminology of the tweets is identified as the attributes and, consequently, formal concepts can be identified as topics, containing a set of tweets according to a set of common terminology.</p><p>Since the modelling performance is highly dependent on the terminology, before applying this modelling we have pre-processed the contents in the next way: we have removed generic and domain stop-words; we have stemmed the terms; we have disambiguated the named entities, unifying them in common labels (e.g. bmw_m3 and m3 will be considered the same entity); and, finally, we have expand the terminology with the identified hashtags (i.e. if there is a hashtag #m3, all the tweets with the term m3 will be expand with the hashtag #m3). All of this pre-processing pursues expand the content of the tweets in order to facilitate the finding of relationships between contents.</p><p>Although in the theoretical model all the tweet terms can be considered as attributes, in the real scenario this would generate an unmanageable lattice with a huge number of concepts. For that we have applied an algorithm for filtering attributes according to their representativeness <ref type="bibr" coords="6,273.41,609.50,11.72,8.96" target="#b6">[7]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Topic Annotation</head><p>In spite of the attribute reduction, the number of generated formal concepts is very high to consider every concept as a cluster. So, it remains the decision of what concepts are suitable to represent a topic. In this sense, a desirable characteristic of the concepts is the cohesion between their objects. Otherwise it would indicate that this concept it isn't really a cluster but an aggrupation of different topics/clusters. To reflect how much each concept in the lattice fits with this requirement (object cohesion), we propose the use of the stability concept. Stability was first introduced in <ref type="bibr" coords="7,124.70,198.18,11.72,8.96" target="#b8">[9]</ref> in relation to hypotheses generated from positive and negative examples, and it was extended to formal concepts in <ref type="bibr" coords="7,268.48,210.18,15.44,8.96" target="#b9">[10]</ref>. In <ref type="bibr" coords="7,301.13,210.18,16.78,8.96" target="#b10">[11]</ref> they present an algorithm to calculate it based on an original concept lattice. Briefly explained, the stability of a concept (i.e. also known intentional stability) indicates how much the concept intent depends on particular objects of the extent. In other words, the stability of a concept is the probability of preserving its intent after leaving out an arbitrary number of objects. Thus, a high stability value indicates that the concept represents a cohesive set of tweets or, what is the same, it can represent a proper cluster.</p><p>We have experimented with different stability values as threshold to select the clusters (all the concepts with a stability value higher than the threshold will be taken as cluster), from 40% to 90%. We have also experimented with two values for attribute selection in the reduction algorithm presented in the previous section. More concretely, the experiments developed are: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Filtering</head><p>In the Table <ref type="table" coords="7,176.06,582.38,4.98,8.96" target="#tab_3">4</ref> it is shown the results achieved by our experiments in this task. Results are expressed in terms of Reliability Sensitivity and F measure <ref type="bibr" coords="7,386.71,594.38,10.69,8.96" target="#b1">[2]</ref>. For this task we proposed the experimentation with 3 different data sources: Wikipedia (filtering_1 and filtering_2), contents of the external webs in the tweets (filtering_5), and Twitter; in this sense, besides of the tweets contents (filtering_3 and filtering_4), we also used named entities (filtering_7) and Hashtags (filtering_6) in the tweets.</p><p>As general comments we can point out the low performance of the proposed approaches, if we compare them with the best approach. Looking in detail the results; regarding to the data type, the best results is obtained with the external webs contents, followed by Wikipedia and finally Twitter contents; within Twitter contents, the named entities achieves the highest performance, followed by twitter raw contents and finally Hashtags. One aspect to remark here is that the performance obtained with the external webs content is driven by the improvement in the sensitivity value; that is, the use of these contents increases the coverage of the annotation process. On the other hand, the use of specific modelling doesn't improve the performance of the generic modelling, either using Wikipedia data (filtering_1 and filtering_3), or Twitter data (filtering_2 and filtering_4). This confirms the results that we obtained when we experimented with these approaches in the training step.</p><p>Taking into consideration the use of unrelated models, this modelling obtains a significant improvement of the results offered by the run used as baseline of these approaches (filtering_4). This improvement is mainly due to the improvement of the Reliability value, that is, they are more precise. Among these results, Related vs. Unrelated based modelling (filtering_9) is the best performing method. Only the approach using the Wikipedia Filter doesn't get the baseline result despite of the improvement of the Reliability value, due to the low Sensitivity value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Polarity</head><p>In the Table <ref type="table" coords="8,176.30,562.10,4.98,8.96">5</ref> it is shown the results of the Polarity runs, expressed in terms of Reliability, Sensitivity and F-Measure <ref type="bibr" coords="8,260.93,574.10,10.68,8.96" target="#b1">[2]</ref>. In this task we experiment with 2 different ideas. The first one was based on the data used to model: tweet contents (polarity_3 y polarity_4) and adjectives in the tweets (polarity_5 and polarity_6). In this sense it is remarkable the very low performance obtained by the adjective based approach; looking in more detail these results, the low performance can be explained with the extremely low sensitivity value. That is, the adjective based approaches only annotate a small number of tweets; however almost without error, as it can be seen in the Reliability value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 5. Polarity Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Description</head><p>Reliability Sensitivity F(R,S) BEST_APPROACH X 0,7288 0,4507 0,4885 polarity_1</p><p>Most-Similar-Approach-Specific-Modelling 0,3337 0,3093 0,3169 polarity_2</p><p>Most-Similar-Approach-Generic-Modelling 0,3328 0,3044 0,3115 polarity_3</p><p>Twitter-Content-Generic-Modelling 0,3162 0,2967 0,2956 polarity_4</p><p>Twitter-Content-Specific-Modelling 0,3210 0,2943 0,2958 polarity_5</p><p>Twitter-Adjectives-Specific-Modelling 0,9369 0,0054 0,0099 polarity_6</p><p>Twitter-Adjectives-Generic-Modelling 0,9337 0,0062 0,0111</p><p>The other approach that was proposed in this task is the use of the most similar modelling. The results of this approach outperform the baseline modelling results according to all of the measures. Finally, like in the filtering task, the application of specific modelling doesn't offer any improvement. In fact, the results for generic and specific approaches can be considered as equal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Topic Detection</head><p>Table <ref type="table" coords="9,150.14,370.05,4.98,8.96" target="#tab_4">6</ref> shows the results obtained for the experiments sent to the topic detection task. Results are expressed in terms of Reliability Sensitivity and F measure <ref type="bibr" coords="9,429.43,382.05,10.71,8.96" target="#b1">[2]</ref>. Some interesting general considerations are that in general their reliability values are very high, some of them in the Pareto Frontier of the Reliability-Sensitivity Curve (top-ic_detection_6 and topic_detection_10). Going into detail, these results can be divided according to the threshold applied to the attribute reduction algorithm (1 and 5 %). The best performance according to F measure is obtained by the first set of runs which use a threshold equal to 1% (top-ic_detection_1 -topic_detection_5). If we focused on the stability value applied (from 90% to 40%), as the stability value decreases also F-Measure decreases, but the Reliability value increases. This latter behaviour relies in the fact that, the lower is the stability value, the lower the number of generated clusters is; so, it makes sense this precision improvement. If we look at the performance of runs which use a threshold equal to 5%, the results barely differs between them. Given that the threshold for the attribute selection algorithm is higher, less attributes for the application of FCA algorithm are taken into account; leading on a general reduction in the stability value of the generated concepts.</p><p>In spite of good Reliability values, the general performance of our application is quite low (according F-Measure). But here there is something affecting the performance of our proposal. Previously to the application of FCA, we filtered out the unrelated tweets. However we didn't the filtering goldstandard at the time of sending the runs, so we had to apply one of our filtering approaches; which as it can be seen before, it doesn't have very accurate results. In order to address this problem, we used the filtering goldstandard as a filter, once it was released by the organizers, and we obtain the results shown in the Table <ref type="table" coords="10,444.94,332.13,3.77,8.96" target="#tab_5">7</ref>. The table shows only the experiments using a stability value of 90%, the value which a higher performance achieves. Both runs outperform the sent runs, so the low performance of our approach can be attributed to the low performance of the filtering step, previous to the FCA modelling. However the improvement is much clearer for the enhanced_run_1; in fact this result would be placed in the first third of the overall RepLab results. This seems to indicate that a threshold equal to 5% is too restrictive and it leaves out an important part of the knowledge contained in the tweet terminology. As a final comment, we want to remark one strange result obtained during the evaluation step. We can see that if we considered only two clusters (the root of the lattice as one cluster and the rest of the lattice as another cluster) the results are surprisingly good (see Table <ref type="table" coords="10,234.89,561.98,3.72,8.96" target="#tab_6">8</ref>); in fact they improve the performance of the best approach. Analysing in more detail results, all of our ideas to enhance filtering models was confirmed, outperforming baseline results. In general, the use of specific information (named entities, content of external webs, Wikipedia) seems to be better than only the use of tweet contents for this task. Also remark that the use of unrelated contents was the best approach; as we supposed, on a collection where the contents was mostly related to the entities, looking only for the unrelated contents is more precise.</p><p>Focusing on Polarity task, our approach works well for the proposed task. The use of models generated through the most similar approach has proven to be more representative than baseline models, even though these models are more dependent on the coverage of training set and that the test set are greater than the training set(1500 vs 750 tweets per entity). Results obtained by the adjective based approaches are interesting; they achieved an almost perfect precision value; however the low coverage made that these approaches achieved an extremely low F measure results.</p><p>In relation with topic detection, results of the sent runs got a very satisfactory value in terms of precision; however their general performance was not so good. But, as we cited before, we had some problems with the pre-filtering step with our sent runs. Once this problem was solved, by using filtering goldstandard, our FCA-based approach results achieved a significant improvement, positioning them between the best performing approaches according F-measure and in the first place according Reliability. We want to specially remark our 2-cluster approach results, the best among all proposals, according F-measure. At this point, a proper analysis has to be done here to understand the reason for that and how to apply to our proposal.</p><p>As future work, it would be interesting the application of the lessons learnt in the filtering task for modelling enhancement (regarding to the data to use and the ways to model) to other modelling proposals. Focusing on the work done for the polarity task, results point out our approach as a promising way to address this task. Especially interesting would be the use of adjective based modelling as a previous step of other annotation approach, given their high performance in terms of precision.</p><p>Finally, FCA has been proven as a promising technique for the topic detection task. The results obtained by our enhanced runs demonstrate the validity of our approach for addressing the topic diversity. Also a further analysis has to be done in order to explain the results of 2 cluster approach and if it is reproducible in other contexts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,128.30,330.21,317.41,170.69"><head>Table 1 .</head><label>1</label><figDesc>: Filtering Runs</figDesc><table coords="4,128.30,372.14,317.41,128.75"><row><cell>Run</cell><cell>Content used to Model</cell><cell>Modelling</cell></row><row><cell>filtering_1</cell><cell>Wikipedia Entity Pages</cell><cell>Specific</cell></row><row><cell>filtering_2</cell><cell>Wikipedia Entity Pages</cell><cell>Generic</cell></row><row><cell>filtering_3</cell><cell>Content of the Related Tweets</cell><cell>Specific</cell></row><row><cell>filtering_4</cell><cell>Content of the Related Tweets</cell><cell>Generic</cell></row><row><cell>filtering_5</cell><cell>External Webs Content</cell><cell>Generic</cell></row><row><cell>filtering_6</cell><cell cols="2">Hashtags in Content of the Related Tweets Generic</cell></row><row><cell>filtering_7</cell><cell>NER in Content of the Related Tweets</cell><cell>Generic</cell></row><row><cell>filtering_8</cell><cell>Content of the Unrelated Tweets</cell><cell>Generic</cell></row><row><cell>filtering_9</cell><cell>Content of the Unrelated Tweets</cell><cell>Generic RvsU</cell></row><row><cell>filtering_10</cell><cell>Content of the Unrelated Tweets</cell><cell>Generic RvsU + Wiki Filter</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,128.30,197.99,298.40,93.36"><head>Table 2 .</head><label>2</label><figDesc>Polarity Runs</figDesc><table coords="5,128.30,216.11,298.40,75.24"><row><cell>Run</cell><cell>Content used to Model</cell><cell>Modelling</cell></row><row><cell>polarity_1</cell><cell>Tweet Content</cell><cell>Specific</cell></row><row><cell>polarity_2</cell><cell>Tweet Content</cell><cell>Generic</cell></row><row><cell>polarity_3</cell><cell>Tweet Content</cell><cell>Generic</cell></row><row><cell>polarity_4</cell><cell>Tweet Content</cell><cell>Specific</cell></row><row><cell>polarity_5</cell><cell>Tweet Adjectives</cell><cell>Most Similar Specific</cell></row><row><cell>polarity_6</cell><cell>Tweet Adjectives</cell><cell>Most Similar Generic</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,135.26,366.02,290.48,146.87"><head>Table 3 .</head><label>3</label><figDesc>Topic Detection Runs</figDesc><table coords="7,135.26,384.14,290.48,128.75"><row><cell>Run</cell><cell cols="2">Attribute Reduction Threshold Stability Threshold</cell></row><row><cell>topic_detection_1</cell><cell>1%</cell><cell>90%</cell></row><row><cell>topic_detection_2</cell><cell>1%</cell><cell>80%</cell></row><row><cell>topic_detection_3</cell><cell>1%</cell><cell>70%</cell></row><row><cell>topic_detection_4</cell><cell>1%</cell><cell>60%</cell></row><row><cell>topic_detection_5</cell><cell>1%</cell><cell>40%</cell></row><row><cell>topic_detection_6</cell><cell>5%</cell><cell>90%</cell></row><row><cell>topic_detection_7</cell><cell>5%</cell><cell>80%</cell></row><row><cell>topic_detection_8</cell><cell>5%</cell><cell>70%</cell></row><row><cell>topic_detection_9</cell><cell>5%</cell><cell>60%</cell></row><row><cell>topic_detection_10</cell><cell>5%</cell><cell>40%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,124.70,221.99,325.83,159.72"><head>Table 4 .</head><label>4</label><figDesc>Filtering Results</figDesc><table coords="8,124.70,240.14,325.83,141.57"><row><cell>Run</cell><cell>Description</cell><cell cols="3">Reliability Sensitivity F(R,S)</cell></row><row><cell cols="2">BEST_APPROACH X</cell><cell>0,7288</cell><cell>0,4507</cell><cell>0,4885</cell></row><row><cell>filtering_1</cell><cell>WP-Specific-Modelling</cell><cell>0,1443</cell><cell>0,2482</cell><cell>0,1341</cell></row><row><cell>filtering_2</cell><cell>WP-Generic-Modelling</cell><cell>0,1483</cell><cell>0,2606</cell><cell>0,1406</cell></row><row><cell>filtering_3</cell><cell>Twitter-Content-Specific-Modelling</cell><cell>0,1467</cell><cell>0,2155</cell><cell>0,1151</cell></row><row><cell>filtering_4</cell><cell>Twitter-Content-Generic-Modelling</cell><cell>0,1511</cell><cell>0,2190</cell><cell>0,1206</cell></row><row><cell>filtering_5</cell><cell>ExternalLinks-Content</cell><cell>0,1440</cell><cell>0,2927</cell><cell>0,1468</cell></row><row><cell>filtering_6</cell><cell>Twitter-Hashtags</cell><cell>0,1527</cell><cell>0,2245</cell><cell>0,1084</cell></row><row><cell>filtering_7</cell><cell>Twitter-NER</cell><cell>0,1631</cell><cell>0,2169</cell><cell>0,1287</cell></row><row><cell>filtering_8</cell><cell>Unrelated-Modelling</cell><cell>0,3095</cell><cell>0,1878</cell><cell>0,1598</cell></row><row><cell>filtering_9</cell><cell>Unrelated-RvsU-Modelling</cell><cell>0,2899</cell><cell>0,2184</cell><cell>0,1738</cell></row><row><cell>filtering_10</cell><cell cols="2">Unrelated-RvsU-Modelling-WikiFilter 0,3521</cell><cell>0,1198</cell><cell>0,1085</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="10,124.70,149.99,322.23,159.72"><head>Table 6 .</head><label>6</label><figDesc>Topic Detection Results</figDesc><table coords="10,124.70,168.11,322.23,141.60"><row><cell>Run</cell><cell>Description</cell><cell cols="3">Reliability Sensitivity F(R,S)</cell></row><row><cell cols="2">BEST_APPROACH X</cell><cell>0,4624</cell><cell>0,3246</cell><cell>0,3252</cell></row><row><cell>topic_detection_1</cell><cell>Attribute-Treshold-1-Stability-90</cell><cell>0,6735</cell><cell>0,1092</cell><cell>0,1711</cell></row><row><cell>topic_detection_2</cell><cell>Attribute-Treshold-1-Stability-80</cell><cell>0,6806</cell><cell>0,1061</cell><cell>0,1669</cell></row><row><cell>topic_detection_3</cell><cell>Attribute-Treshold-1-Stability-70</cell><cell>0,6930</cell><cell>0,1026</cell><cell>0,1624</cell></row><row><cell>topic_detection_4</cell><cell>Attribute-Treshold-1-Stability-60</cell><cell>0,6958</cell><cell>0,1018</cell><cell>0,1615</cell></row><row><cell>topic_detection_5</cell><cell>Attribute-Treshold-1-Stability-40</cell><cell>0,7470</cell><cell>0,0969</cell><cell>0,1560</cell></row><row><cell>topic_detection_6</cell><cell>Attribute-Treshold-5-Stability-90</cell><cell>0,8331</cell><cell>0,1076</cell><cell>0,1548</cell></row><row><cell>topic_detection_7</cell><cell>Attribute-Treshold-5-Stability-80</cell><cell>0,8331</cell><cell>0,1076</cell><cell>0,1548</cell></row><row><cell>topic_detection_8</cell><cell>Attribute-Treshold-5-Stability-70</cell><cell>0,8333</cell><cell>0,1076</cell><cell>0,1547</cell></row><row><cell>topic_detection_9</cell><cell>Attribute-Treshold-5-Stability-60</cell><cell>0,8333</cell><cell>0,1076</cell><cell>0,1547</cell></row><row><cell cols="2">topic_detection_10 Attribute-Treshold-5-Stability-40</cell><cell>0,8338</cell><cell>0,1075</cell><cell>0,1546</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="10,128.06,451.96,329.91,63.69"><head>Table 7 .</head><label>7</label><figDesc>Topic Detection Enhanced Runs Results</figDesc><table coords="10,128.06,470.08,329.91,45.57"><row><cell>Run</cell><cell>Description</cell><cell cols="2">Reliability Sensitivity</cell><cell>F(R,S)</cell></row><row><cell>BEST_APPROACH</cell><cell>X</cell><cell>0,4624</cell><cell>0,3246</cell><cell>0,3252</cell></row><row><cell>enhanced_run_1</cell><cell>Attribute-Treshold-1-Stability-90</cell><cell>0,6615</cell><cell>0,1940</cell><cell>0,2336</cell></row><row><cell>enhanced_run_2</cell><cell>Attribute-Treshold-5-Stability-90</cell><cell>0,6184</cell><cell>0,2469</cell><cell>0,1730</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="11,124.70,149.99,346.12,206.10"><head>Table 8 .</head><label>8</label><figDesc>2 Cluster Approach ResultsThe work done in the RepLab campaign was divided in two sides. First, we participated in the Filtering and Polarity tasks by proposing the application of an IR approach to annotate tweets, instead of common classification approaches. For the Topic Detection task our work was focused on the application of Formal Concept Analysis in order to model tweet contents and to detect a set of topics in these contents. The results obtained by our IR approach are opposite. While for the Filtering task we don't achieve satisfactory results, for the Polarity task our results are quite satisfactory, comparing them with the rest of presented approaches.</figDesc><table coords="11,124.70,168.11,333.27,80.18"><row><cell></cell><cell>Run</cell><cell>Description</cell><cell cols="2">Reliability Sensitivity</cell><cell>F(R,S)</cell></row><row><cell cols="2">BEST_APPROACH</cell><cell>X</cell><cell>0,4624</cell><cell>0,3246</cell><cell>0,3252</cell></row><row><cell></cell><cell>2_cluster_run_1</cell><cell>Attribute-Treshold-1-Stability-90</cell><cell>0,5510</cell><cell>0,3537</cell><cell>0,3477</cell></row><row><cell></cell><cell>2_cluster_run_2</cell><cell>Attribute-Treshold-1-Stability-40</cell><cell>0,5556</cell><cell>0,3483</cell><cell>0,3459</cell></row><row><cell>5</cell><cell cols="2">Conclusions and Future Work</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,129.98,686.23,130.41,8.10"><p>http://api.daedalus.es/stiluscore-info</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,129.98,686.23,130.41,8.10"><p>http://api.daedalus.es/stiluscore-info</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. This work has been partially supported by the <rs type="funder">Regional Government of Madrid under Research Network MA2VIRMR</rs> (<rs type="grantNumber">S2009/TIC-1542</rs>), and <rs type="projectName">HOLOPEDIA</rs> (<rs type="grantNumber">TIN 2010-21128-C02</rs>). Special thanks to <rs type="institution">Daedalus</rs> for licencing the utilization of Stilus Core.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_FwjtsJf">
					<idno type="grant-number">S2009/TIC-1542</idno>
					<orgName type="project" subtype="full">HOLOPEDIA</orgName>
				</org>
				<org type="funding" xml:id="_r4sPvQ5">
					<idno type="grant-number">TIN 2010-21128-C02</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="12,127.03,297.02,343.68,8.10;12,136.10,308.06,334.76,8.10;12,136.10,319.10,334.26,8.10;12,136.10,330.02,132.37,8.10" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,225.65,308.06,245.21,8.10;12,136.10,319.10,42.25,8.10">Overview of RepLab 2013: Evaluating Online Reputation Monitoring Systems</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carrillo De Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Chugur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Corujo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Martín</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Meij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,197.81,319.10,269.43,8.10">Proceedings of the Fourth International Conference of the CLEF initiative</title>
		<meeting>the Fourth International Conference of the CLEF initiative<address><addrLine>CLEF; Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,127.03,341.06,343.83,8.10;12,136.10,352.10,334.64,8.10;12,136.10,363.02,143.65,8.10" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,310.85,341.06,160.01,8.10;12,136.10,352.10,230.29,8.10">Combining evaluation metrics via the unanimous improvement ratio and its application to clustering tasks</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Artiles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Verdejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,372.63,352.10,98.11,8.10;12,136.10,363.02,54.46,8.10">Journal of Artifical Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="689" to="718" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,127.03,374.06,343.45,8.10;12,136.10,385.10,249.14,8.10" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Castellanos</surname></persName>
		</author>
		<title level="m" coord="12,198.29,374.06,272.19,8.10;12,136.10,385.10,136.55,8.10">Recomendación de contenidos digitales basada en modelos del lenguaje: Diseño, experimentación y evaluación</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
		<respStmt>
			<orgName>UNED</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master Thesis</note>
</biblStruct>

<biblStruct coords="12,127.03,396.04,343.71,8.10;12,136.10,407.08,334.47,8.10;12,136.10,418.12,24.09,8.10" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,317.71,396.04,153.03,8.10;12,136.10,407.08,153.87,8.10">Using IR Techniques for topic-based sentiment analysis through divergence models</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Castellanos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cigarrán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>García-Serrano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,309.29,407.08,161.28,8.10">Workshop on Sentiment Analysis at SEPLN</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,127.03,429.04,343.55,8.10;12,136.10,440.08,334.29,8.10;12,136.10,451.12,334.76,8.10;12,136.10,462.04,75.12,8.10" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,313.99,429.04,156.58,8.10;12,136.10,440.08,155.84,8.10">Browsing search results via formal concept analysis: Automatic selection of attributes</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cigarrán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Verdejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,378.92,440.08,86.75,8.10;12,287.96,451.12,182.89,8.10;12,136.10,462.04,48.62,8.10">Second International Conference on Formal Concept Analysis</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Eklund</surname></persName>
		</editor>
		<meeting><address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2961. 2004</date>
			<biblScope unit="page" from="74" to="87" />
		</imprint>
	</monogr>
	<note>Concept Lattices. LNAI</note>
</biblStruct>

<biblStruct coords="12,127.03,473.08,343.83,8.10;12,136.10,484.12,334.49,8.10;12,136.10,495.04,334.64,8.10;12,136.10,506.08,90.60,8.10" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,310.73,473.08,160.13,8.10;12,136.10,484.12,226.78,8.10">Automatic selection of noun phrases as document descriptors in an fca-based information retrieval system</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cigarrán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Verdejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,159.50,495.04,117.91,8.10">Formal Concept Analysis, LNAI</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Ganter</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Godin</surname></persName>
		</editor>
		<meeting><address><addrLine>Lens, France</addrLine></address></meeting>
		<imprint>
			<publisher>Third International Conference</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3403</biblScope>
			<biblScope unit="page" from="49" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,127.03,517.12,343.71,8.10;12,136.10,528.04,114.85,8.10" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cigarrán</surname></persName>
		</author>
		<title level="m" coord="12,183.50,517.12,287.24,8.10;12,136.10,528.04,9.62,8.10">Agrupación de Resultados de Búsqueda Mediante Análisis Formal de Conceptos</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
		<respStmt>
			<orgName>UNED</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD. Thesis</note>
</biblStruct>

<biblStruct coords="12,127.03,539.08,343.59,8.10;12,136.10,550.12,88.58,8.10" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,238.73,539.08,112.65,8.10">On information and sufficiency</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kullback</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="middle">R A</forename><surname>Leibler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,357.52,539.08,113.10,8.10;12,136.10,550.12,11.79,8.10">Annals of Mathematical Statistics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="86" />
			<date type="published" when="1951">1951</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,127.03,561.07,343.83,8.10;12,136.10,572.11,334.76,8.10;12,136.10,583.15,99.12,8.10" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,201.65,561.07,269.21,8.10;12,136.10,572.11,152.99,8.10">Stability as an estimate of the degree of substantiation of hypotheses derived on the basis of operational similarity</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">O</forename><surname>Kuznetsov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,295.07,572.11,175.79,8.10;12,136.10,583.15,72.69,8.10">Journal of Automatic Documentation and Mathematical Linguistics</title>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,126.64,594.07,343.98,8.10;12,136.10,605.11,109.58,8.10" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,198.77,594.07,115.48,8.10">On stability of a formal concept</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">O</forename><surname>Kuznetsov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,320.82,594.07,149.80,8.10;12,136.10,605.11,33.79,8.10">Annals of Mathematics and Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="101" to="115" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,126.64,616.15,343.98,8.10;12,136.10,627.07,293.69,8.10" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,268.13,616.15,202.49,8.10;12,136.10,627.07,66.78,8.10">Towards concise representation for taxonomies of epistemic communities</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Obiedkov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kourie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,209.23,627.07,144.74,8.10">Concept Lattices and Their Applications</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="240" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,126.64,638.11,344.10,8.10;12,136.10,649.15,188.16,8.10" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="12,176.06,638.11,294.68,8.10;12,136.10,649.15,60.49,8.10">Ordered Sets, chap. Restructuring lattice theory: An approach based on hierarchies of concepts</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Wille</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982">1982</date>
			<publisher>Prentice Hall</publisher>
			<biblScope unit="page" from="445" to="470" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
