<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,150.19,115.90,314.97,12.90">Authorship Verification with Compression Features</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,240.12,153.95,63.36,8.64"><forename type="first">Cor</forename><forename type="middle">J</forename><surname>Veenman</surname></persName>
							<email>c.veenman@nfi.minvenj.nl</email>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Faculty Technology</orgName>
								<orgName type="department" key="dep2">Policy and Management Delft</orgName>
								<orgName type="institution">University of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,327.32,153.95,43.45,8.64"><forename type="first">Zhenshi</forename><surname>Li</surname></persName>
							<email>zhenshili@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Knowledge and Expertise Centre for Intelligent Data-Analysis Digital Technology and Biometrics Department Netherlands Forensic Institute</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,150.19,115.90,314.97,12.90">Authorship Verification with Compression Features</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DC94665785F9D3000B85DA9F3F2D2D23</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the PAN 2013 Author Identification task, the problem was to verify whether a document was written by the same author as a small set of given reference documents. We approached the problem as a classification task for which the reference documents are from the target class. We further collected a set of documents for the non-target or outlier class. For this classification problem we prepared three submissions for the English Authorship Verification task. The first submission applies the nearest neighbor rule using compression distances from the "questioned" document to the reference and outlier documents. The second and third submission utilize a document representation with compression distances to random prototype documents. In the resulting prototype space the Lowest Error in Sparse Subspace (LESS) classifier is applied. The third submission additionally uses document resampling or bootstrapping to mitigate the small sample problem in case the number of reference documents is low. The evaluation result of our submission achieved the best performance of 16 teams with precision = 0.80 , recall = 0.80 and F1 = 0.80.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In the PAN 2013 Author Identification task, the problem was to verify whether a unknown document was written by the same author as a small set of given reference documents. The given reference documents were parts of books with approximately 1000 words per document. The number of reference documents varied between 1 and 10. We followed a statistical pattern recognition approach. There are two possible learning paradigms to apply. The unsupervised way is to establish whether or not the unknown document could be from the same distribution as the reference documents by using the reference documents only. In a supervised approach, a learned classifier establishes a boundary between the reference documents and documents written by other authors using labeled examples of both groups.</p><p>In either approach a suitable vector representation of the documents is required. Representations of text documents are typically high dimensional, while the number of reference documents is low. Especially is such small sample cases, an unsupervised approach will expectedly lead to mediocre performing recognition models. On the other hand, to have a representative sampling of documents written by all possible authors, as is required for the supervised approach, is nearly impossible. Fortunately, the given reference documents all had similar genre, theme, and date of writing and the same would hold for the final test cases according to the contest descriptions. As a result, we would only need a representative sample of documents for the given language, genre, theme, and date of writing. Therefore, we followed the supervised learning paradigm. Below we elaborate on the different aspects of this learning task, being: selection of the labeled dataset, the representation of the documents, and the model learning.</p><p>Because of time limitations, we only participated in the English Authorship Verification tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data collection</head><p>We considered the verification problem as a two-class pattern recognition problem. The reference author is the first target class and all other authors are in the second outlier class. From the reference author, we have a limited number of given documents: 1-10. From the outlier class, there are no examples given. Therefore, we needed to collect similar documents as given in the training set to obtain information about the writing style of other authors. It was stated in the task description that in the final test, the documents would have the same language and similar genre, theme, and date of writing as the given training samples. Accordingly, we collected documents with these properties.</p><p>In order to obtain similar English documents as the ones provided by the PAN 2013 organization, we searched the Internet for substrings of the provided documents. We found several of the training documents in he bookboon.com repository, which provides open access for students to text books. From this repository we selected 66 textbooks from the Engineering (Chemical Engineering, Construction Engineering, Electrical Engineering, Energy Engineering, Environmental Engineering, Mechanical Engineering, Nanotechnology and Petroleum Engineering) and IT &amp; Programming sections. The books were authored by 46 different authors.</p><p>We prepared the documents similarly as the training/reference material. That is, we converted the text sections to UTF8 format and split the books into documents of 6,000 to 8,000 characters each. This resulted in 2 to 75 documents per text book with roughly 1,000 words each.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Document representation</head><p>As document representation, we chose the compression distance to other documents. Several compression distance measures have been proposed in the past <ref type="bibr" coords="2,416.34,568.70,10.58,8.64" target="#b5">[6]</ref>. We used the Compression Dissimilarity Measure (CDM) <ref type="bibr" coords="2,312.98,580.66,10.79,8.64" target="#b2">[3]</ref>:</p><formula xml:id="formula_0" coords="2,244.33,601.30,236.26,22.31">CDM (x, y) = C(xy) C(x) + C(y) ,<label>(1)</label></formula><p>where C(x) is the size of the compressed object x and xy is the concatenation of x and y. To obtain C(x), we used the best text compressor currently available. In such a way, the best approximation of the Kolmogorov complexity of a text string is obtained, which is the underlying theory behind the compression based distance measure <ref type="bibr" coords="3,455.40,119.31,10.58,8.64" target="#b0">[1]</ref>. In <ref type="bibr" coords="3,134.77,131.27,10.58,8.64" target="#b1">[2]</ref>, we showed that better compressors indeed result in better recognition performance.</p><p>From the text compression benchmark <ref type="bibr" coords="3,293.15,143.22,10.58,8.64" target="#b4">[5]</ref>, it can be seen that adaptive statistical data compressors using context modeling and prediction are the current best compressors.</p><p>In particular, we used the Prediction by Partial Matching (PPMd) compressor by <ref type="bibr" coords="3,457.68,167.13,10.58,8.64" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Model learning</head><p>We submitted three approaches to the English Authorship Verification task, with an increasing modeling complexity. All approaches used the collected documents to represent the outlier class and compression distances as document representation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Nearest Neighbor with Compression Distances</head><p>The simplest approach we prepared is purely based on compression distances between the unknown document on the one hand and the reference documents and collected documents on the other hand, see Figure <ref type="figure" coords="3,296.48,311.27,3.74,8.64" target="#fig_0">1</ref>. The decision rule is as follows: if the closest document in the dataset is from the reference author, we conclude that the unknown document is from that author too. Otherwise, if a document from any author from our collected corpus is closer, we conclude that the unknown document is not written by the reference author. Such a 1-nearest neighbor approach is known to be sensitive for overfitting or outliers in the data. On the other hand, the length of documents probably mitigates this problem to a certain extend. That is, for longer documents it is less probable that accidentally a document of another author is more similar than that of the true author. On the provided cases, this approach resulted in 1 error out of 10 (10%). For the second approach, we learned a two-class classifier in prototype space as in <ref type="bibr" coords="3,134.77,656.44,10.58,8.64" target="#b3">[4]</ref>, see Figure <ref type="figure" coords="3,196.35,656.44,3.74,8.64">2</ref>. The first (target) class is the class of the documents of the reference author and the second (outlier) class is that with all collected documents (by other authors). All documents are represented by their compression distance toward a number of selected documents from the training set, i.e. the prototypes. To be able to compute as much of the compression distances beforehand, the prototypes are selected from the collected documents, i.e. the outlier class. Since this class is diverse, the distances to these documents will give a rich representation. Because of the limited amount of available documents, the prototypes themselves were not removed from the dataset for model learning. Per test case, we learned a classifier with the reference and collected documents and applied the resulting classifier to the unknown document. The classifier decides if the document is from the reference author or not. As classifier, we used the Lowest Error in a Sparse Subspace (LESS) classifier <ref type="bibr" coords="4,348.19,238.86,11.62,8.64" target="#b7">[8]</ref> that is able to deal with small sample size problems, see Eq. 2.</p><formula xml:id="formula_1" coords="4,248.95,275.41,231.64,30.79">min p j=1 w j + C nt i=1 ξ ti + no i=1 ξ oi ,<label>(2)</label></formula><p>subject to:</p><formula xml:id="formula_2" coords="4,212.99,312.02,204.59,61.34">x ∈ X t , p j=1 w j φ(x, j) ≥ 1 -ξ ti x ∈ X o , p j=1 w j φ(x, j) &lt; -1 + ξ oi where φ(x, j) = x j -µ tj 2 -x j -µ oj 2 and w j ≥ 0, ξ i ≥ 0.</formula><p>Here, w is the model vector with weights w j per dimension, X t and X o contain the target and outlier samples, n t and n o are the sizes of X t and X o , µ t and µ o are the mean vectors of X t and X o , p is the number of dimensions (in this case prototypes), and ξ ti and ξ oi are the slack variables for documents from the respective classes to enable the modeling of inseparable classes. Further, C is a tunable parameter that balances model sparseness against model accuracy.</p><p>Our collected dataset is a lot bigger than the provided reference documents. Without precautions, the scarce target class would be neglected by the model, just because it is scarce. From the training cases it turned out that roughly in 50% of the cases the unknown document is from the reference author (target). Therefore, we made both classes equally important in the LESS model in order to deal with these strongly unbalanced classes, see Eq. 3.</p><formula xml:id="formula_3" coords="4,248.04,538.00,232.55,30.79">min p j=1 w j + C 1 n t nt i=1 ξ ti + 1 n o no i=1 ξ oi ,<label>(3)</label></formula><p>subject to:</p><formula xml:id="formula_4" coords="4,212.08,574.60,204.59,46.39">x ∈ X t , p j=1 w j φ(x, j) ≥ 1 -ξ ti x ∈ X o , p j=1 w j φ(x, j) &lt; -1 + ξ oi where φ(x, j) = x j -µ tj 2 -x j -µ oj 2</formula><p>and w j ≥ 0, ξ i ≥ 0.</p><p>The number of prototypes and the C trade-off parameter for LESS, we optimized on the collected corpus. In turn, we selected one of the 46 authors as reference author and took up to 10 of his documents as reference documents. We put a selection of documents from the that author and from other authors aside for testing. In this way, we established p = 200 and C = 10, 000.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Decision boundary</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2. Classifier in prototype space</head><p>We ran several experiments with different samples of 200 prototypes on the provided cases. This resulted in 26% average error on the 10 cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Bootstrapped document samples</head><p>In the last approach, we attempt to make the method more robust for the low number of document samples in the reference class. Ultimately, there could be only one reference document. Therefore, we resampled the available reference documents as we did in <ref type="bibr" coords="5,134.77,446.15,10.58,8.64" target="#b1">[2]</ref>, see Figure <ref type="figure" coords="5,195.82,446.15,3.74,8.64" target="#fig_1">3</ref>. To make the method generic, we first merged the available reference documents (1-10) in given order into a single document. Then, we sampled 50 documents from the merged document with the same average size as the given reference documents (±1000 words). Now, the target class always contains 50 documents and the outlier class all other collected documents. The method proceeds as the previous one. The tuning parameters for the number p of prototypes and LESS trade-off parameter C, were not that sensitive and were kept the same.</p><p>We ran several experiments with different bootstrapped document samples and different prototypes on the provided cases. This resulted in 16% average error on the 10 cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We prepared three submissions for the PAN 2013 Authorship Verification task. An important part of our approach, was careful selection of documents not authored by the reference author, the outlier class. All our submissions used compression distances as document representation. Two of our submissions additionally used a representation with compression distances to prototypes, that were selected as a subset of the outlier </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,203.82,578.43,207.72,8.06;3,204.73,437.02,206.71,126.59"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Nearest neighbor with compression distances</figDesc><graphic coords="3,204.73,437.02,206.71,126.59" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,205.98,286.19,203.40,8.06;6,203.93,115.79,205.05,156.06"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Bootstrapped documents in prototype space</figDesc><graphic coords="6,203.93,115.79,205.05,156.06" type="bitmap" /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,138.13,423.62,340.60,7.77;6,146.47,434.58,134.72,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,254.65,423.62,94.42,7.77">Clustering by compression</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Cilibrasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">M B</forename><surname>Vitányi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,355.28,423.62,123.45,7.77;6,146.47,434.58,25.90,7.77">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1523" to="1545" />
			<date type="published" when="2005-04">Apr 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.13,445.54,330.93,7.77;6,146.47,456.50,233.56,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,248.33,445.54,204.83,7.77">Bootstrapped authorship attribution in compression space</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>De Graaff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Veenman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,146.47,456.50,207.41,7.77">CLEF 2012 Evaluation Labs: PAN -Author Identification</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.13,467.45,314.43,7.77;6,146.47,478.41,328.35,7.77;6,146.47,489.37,136.23,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,308.11,467.45,128.30,7.77">Towards parameter-free data mining</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Keogh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lonardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Ratanamahatana</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,146.47,478.41,328.35,7.77;6,146.47,489.37,58.91,7.77">Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</title>
		<meeting>the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="206" to="215" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.13,500.33,333.53,7.77;6,146.47,511.29,297.14,7.77;6,146.47,522.25,326.91,7.77;6,146.47,533.21,65.82,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,247.82,500.33,223.84,7.77;6,146.47,511.29,36.45,7.77">Forensic authorship attribution using compression distances to prototypes</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lambers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Veenman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,201.01,511.29,242.60,7.77;6,146.47,522.25,32.83,7.77">Proceedings of the Third International Workshop on Computational Forensics</title>
		<meeting>the Third International Workshop on Computational Forensics<address><addrLine>The Hague, The Netherlands; Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2009">August 13-14. 2009</date>
			<biblScope unit="page" from="13" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.13,544.17,189.11,7.77;6,146.47,555.13,154.11,7.77" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mahoney</surname></persName>
		</author>
		<ptr target="http://www.mattmahoney.net/text/text.html" />
		<title level="m" coord="6,199.05,544.17,123.98,7.77">Large text compression benchmark</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.13,566.08,341.51,7.77;6,146.47,577.04,332.31,7.77;6,146.47,588.00,198.69,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,243.66,566.08,235.98,7.77;6,146.47,577.04,46.66,7.77">Compression and machine learning: A new perspective on feature space vectors</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Sculley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">E</forename><surname>Brodley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,211.07,577.04,177.32,7.77;6,443.91,577.04,31.32,7.77">Proceedings of the Data Compression Conference</title>
		<meeting>the Data Compression Conference<address><addrLine>Washington, DC, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="332" to="332" />
		</imprint>
	</monogr>
	<note>DCC &apos;06</note>
</biblStruct>

<biblStruct coords="6,138.13,598.96,309.85,7.77;6,146.47,609.92,238.89,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,192.29,598.96,102.54,7.77">PPM: one step to practicality</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Shkarin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,312.51,598.96,135.47,7.77;6,146.47,609.92,39.61,7.77">Proceedings of the Data Compression Conference</title>
		<meeting>the Data Compression Conference</meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">02</biblScope>
			<biblScope unit="page">202</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.13,620.88,301.22,7.77;6,146.47,631.84,319.55,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,228.18,620.88,185.69,7.77">LESS: a model-based classifier for sparse subspaces</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Veenman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Tax</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,419.92,620.88,19.42,7.77;6,146.47,631.84,211.22,7.77">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1496" to="1500" />
			<date type="published" when="2005-09">Sep 2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
