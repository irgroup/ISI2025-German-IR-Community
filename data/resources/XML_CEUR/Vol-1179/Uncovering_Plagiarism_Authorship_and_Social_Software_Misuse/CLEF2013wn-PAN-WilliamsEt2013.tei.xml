<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,139.48,115.90,336.40,12.90;1,223.43,135.94,168.50,10.75">Unsupervised Ranking for Plagiarism Source Retrieval Notebook for PAN at CLEF 2013</title>
				<funder ref="#_5vt9Q85">
					<orgName type="full">National Science Foundation</orgName>
				</funder>
				<funder>
					<orgName type="full">PAN Lab</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,141.76,172.53,57.74,8.64"><forename type="first">Kyle</forename><surname>Williams</surname></persName>
							<email>kwilliams@psu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Information Sciences and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,208.96,172.53,74.43,8.64"><forename type="first">Hung-Hsuan</forename><surname>Chen</surname></persName>
							<email>hhchen@psu.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">Pennsylvania State University University Park</orgName>
								<address>
									<postCode>16802</postCode>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,292.84,172.53,93.54,8.64"><forename type="first">Sagnik</forename><forename type="middle">Ray</forename><surname>Choudhury</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information Sciences and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,412.70,172.53,50.08,8.64"><forename type="first">C</forename><forename type="middle">Lee</forename><surname>Giles</surname></persName>
							<email>giles@ist.psu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Information Sciences and Technology</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Computer Science and Engineering</orgName>
								<orgName type="institution">Pennsylvania State University University Park</orgName>
								<address>
									<postCode>16802</postCode>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,139.48,115.90,336.40,12.90;1,223.43,135.94,168.50,10.75">Unsupervised Ranking for Plagiarism Source Retrieval Notebook for PAN at CLEF 2013</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BE976493AC6674E1B431DE3937E60CEB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The source retrieval task for plagiarism detection involves the use of a search engine to retrieve candidate sources of plagiarism for a suspicious document and provides a way to efficiently identify candidate documents so that more accurate comparisons can take place. We describe a strategy for source retrieval that makes use of an unsupervised ranking method to rank the results returned by a search engine by their similarity with the query document and that only retrieves documents that are likely to be sources of plagiarism. Evaluation shows the performance of our approach, which achieved the highest F1 score (0.47) among all task participants.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The advent of the Web has led to unprecedented levels of information access and an exponential increase in the amount of information available. These new levels of access have had a number of benefits, such as easy and immediate access to information on important topics, such as healthcare, disaster management, and research. However, one of the consequences of this access is that it has become increasingly easy to plagiarize. For instance, a study in 2010 found that 1 in 3 American high school students admitted to plagiarizing information from the Internet<ref type="foot" coords="1,319.50,496.79,3.49,6.05" target="#foot_0">1</ref> and a study of college students from 2002-2005 found that 36% of undergraduates admitted to plagiarizing or copying from the Internet without citing the source <ref type="bibr" coords="1,283.79,522.37,10.58,8.64" target="#b6">[7]</ref>. Thus, the detection of plagiarism has become an important problem in academic institutions and other organizations around the world and many approaches for detecting plagiarism have been developed <ref type="bibr" coords="1,407.87,546.28,10.58,8.64" target="#b5">[6]</ref>. Generally, the most common task in plagiarism detection is: Problem 1. Given a suspicious document and a potential source document for plagiarism, find all areas of overlapping text, which may have been subjected to exact copying. This is the classic plagiarism text alignment task; however, another task for plagiarism detection involves the identification of potential sources of plagiarism before text alignment takes place. This task, known as source retrieval, involves querying an information retrieval system in order to retrieve documents that may be sources of plagiarism so that text alignment can be performed on the retrieved documents. This task of source retrieval can be described as: Problem 2. Given a suspicious document and a search engine, use a search engine to retrieve candidate documents from the Web that may be sources of plagiarism.</p><p>There are a number of issues in solving Problem 2. For instance, it is desirable to achieve high recall by retrieving as many correct sources of plagiarism (true positives) as possible. Similarly, it is desirable to achieve high precision by, to the maximum extent possible, only retrieving sources that are true positives so as to minimize unnecessary computation and bandwidth usage. Achieving high recall is relatively simple since all that is required is to submit as many queries as possible to the search engine and download as many results as possible. Similarly, high precision can be maintained by having strict criteria for what is considered a source of plagiarism and only downloading documents that are highly likely to be true positives. However, there is a tradeoff between precision and recall since an increase in one usually comes as the expense of the other. Other goals for source retrieval involve minimizing the amount of stress put on the information retrieval system in terms of the number of queries submitted as well as minimizing bandwidth utilization and the number of documents downloaded.</p><p>In this paper, we describe a solution to Problem 2 that attempts to achieve both high precision and recall, while minimizing the amount of bandwidth utilized and documents downloaded. Core to the solution is the use of an unsupervised ranking method that re-ranks the search results from a search engine before they are downloaded in order to increase the probability that only true positives are retrieved (high precision) while increasing the likelihood that the true positives that exist are retrieved (high recall). In describing this solution, the rest of this paper is structured as follows. Section 2 describes related work, while Section 3 describes the approach we used to solve the problem. Section 4 describes the evaluation of our approach and, lastly, conclusions are drawn in Section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The source retrieval task was first introduced as a sub-task at PAN 2012 and thus the approaches used in that year serve as a good starting point for a discussion of related work. As mentioned in the overview of the plagiarism detection task <ref type="bibr" coords="2,391.00,548.84,15.27,8.64" target="#b9">[10]</ref>, most approaches to source retrieval in 2012 included the separation of text into chunks, followed by the extraction of keyphrases and query formulation, and then the control and downloading of results. The majority of the approaches taken seemed to be very similar, with the most significant differences occurring in the steps for query formulation.</p><p>The source retrieval task can be formulated within the framework of the search methodology known as Query by Document (QBD). In QBD, whole documents are submitted to a search engine that supports QBD, usually with the goal of retrieving similar documents <ref type="bibr" coords="2,212.82,644.48,15.27,8.64" target="#b13">[14]</ref>. In previous works investigating QBD, the workflow usually includes the submission of a whole document as a query, the automatic extraction of queries from the document, the submission of the queries, and the ranking of results by their similarity with the query document <ref type="bibr" coords="3,298.89,131.27,10.58,8.64" target="#b1">[2]</ref>. QBD has been used for retrieving similar documents on the Web <ref type="bibr" coords="3,231.35,143.22,11.62,8.64" target="#b8">[9]</ref> and research paper recommendation <ref type="bibr" coords="3,396.21,143.22,10.58,8.64" target="#b7">[8]</ref>, among other applications. Applying QBD to the PAN source retrieval task, a suspicious document is received as input and the goal is to use the document to construct queries that can be used to retrieve candidate plagiarism sources and rank the returned results by the level of plagiarism that occurs. Since this task is concerned only with the retrieval of sources of plagiarism, the actual overlap among the texts is not calculated but rather an Oracle is consulted to determine whether or not a downloaded text is a source of plagiarism.</p><p>A key aspect of source retrieval and QBD is the construction of the queries that are submitted to a search engine in order to retrieve plagiarized sources from the Web. The construction of queries could be viewed as a keyword extraction problem since the goal is to identify words in a document that can be used to construct good queries. There have been a number of studies investigating different methods for keyword extraction. For instance, two studies compared unsupervised methods for keyword extraction and, in both cases, found that TF-IDF ranking of keywords in a document performed well for different corpora <ref type="bibr" coords="3,220.37,311.82,22.05,8.64">[5][3]</ref>. TF-IDF-based ranking was used in the PAN 2012 source retrieval task by several participants <ref type="bibr" coords="3,278.41,323.77,15.27,8.64" target="#b9">[10]</ref>, though one of the best performing approaches at PAN 2012 constructed queries from sequences of POS-tagged words <ref type="bibr" coords="3,420.95,335.73,10.58,8.64" target="#b3">[4]</ref>.</p><p>Lastly, commercial tools like Turnitin<ref type="foot" coords="3,301.47,347.24,3.49,6.05" target="#foot_1">2</ref> and The Essay Verification Engine (EVE)<ref type="foot" coords="3,476.61,347.24,3.49,6.05" target="#foot_2">3</ref> also exist for plagiarism detection. For Turnitin, users upload documents via a Web interface and plagiarism detection takes place remotely and EVE takes a document as input, constructs queries from the document and conducts a Web-based search in order to identify similar documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approach</head><p>Our approach involves four main steps: 1) query generation, 2) query submission, 3) result ranking; and 4) candidate document downloading. The general approach methodology of our approach is based on the idea that it is easy to achieve either high precision or recall for source retrieval, though achieving both is relatively more difficult. In order to do this, it is essential to submit queries that are likely to return true positives as well as only download documents for evaluation that are likely to be true positives. Our approach to accomplishing these goals involves the use of unsupervised ranking method to re-rank the results returned by the search engine for a set of queries by their similarity to the suspicious document before downloading them. Algorithm 1 shows our source retrieval algorithm, which we describe in more detail in the sections below.</p><p>For most of the steps in Algorithm 1, there are parameters for which the values need to be set. In the majority of cases, the best values for the parameters were empirically found by varying each parameter while keeping the others constant and then measuring precision and estimating recall.</p><p>Algorithm 1 General overview of source retrieval strategy end for 22: end procedure</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Query Generation</head><p>We automatically generate queries that are submitted to a search engine where the goal is to maximize the probability that the results they return contain true positives. Our query generation strategy is based on the idea that different parts of a document are plagiarized from different sources and similar to that of Jayapal <ref type="bibr" coords="4,400.11,453.20,10.58,8.64" target="#b3">[4]</ref>. The text is first partitioned into paragraphs that are made up of 5 sentences as tagged by the Stanford Tagger <ref type="bibr" coords="4,165.65,477.11,16.60,8.64" target="#b12">[13]</ref> and stop words are removed. It was found that the number of sentences included in a paragraph had a large effect on the performance; for instance, increasing the number of sentences to 10 led to an increase in precision by about 2%, but a decrease in estimated recall of over 20%.</p><p>After paragraphs are extracted, each word in each paragraph is tagged using the Stanford POS Tagger and, following Liu et al. <ref type="bibr" coords="4,318.97,536.89,10.58,8.64" target="#b4">[5]</ref>, only verbs, nouns, and adjectives are considered as keywords. Queries are constructed by combining each non-overlapping sequence of k keywords, where k = 10, in order to create a set of queries for each paragraph. Furthermore, each keyword was only included in a query once per paragraph.</p><p>We also tried constructing queries by ranking keywords by TF-IDF and BM25 and then combining the top k keywords. We empirically found that: TF-IDF keyword ranking performed the poorest; BM25 performed better with similar precision to TF-IDF but with estimated recall that was approximately 15% higher; and sequential keywords had a precision that was approximately 8% lower but that had recall that was about 13% higher than BM25. Furthermore, we found that sequential keywords required that fewer queries be submitted to the search engine in order for it to return true positives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Query Submission</head><p>The first 3 queries extracted from each paragraph are submitted to the ChatNoir search engine <ref type="bibr" coords="5,164.61,150.00,15.27,8.64" target="#b10">[11]</ref>. This number was chosen since it was empirically found that, in the majority of cases, the first true positive would be returned by one of the first 3 queries. The queries are submitted as a batch based on the intuition that the results returned by all three queries combined are more likely to contain true positives than the results returned by any query individually. For each query, only the top 3 results are returned since this value was found to perform well. Returning more results increased recall and decreased precision, while returning fewer had the opposite effect. The top 3 results are then combined for the 3 queries leaving a final maximum of 9 results; however, there may be fewer if a query returned fewer than 3 results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Result Ranking</head><p>High precision is achieved by assuming that the order in which the results were ranked by the search engine does not truly reflect the probability that a result is a true positive. Thus, all results for the three queries are combined and re-ranked before downloading.</p><p>For any document in the ChatNoir search engine, it is possible to submit the document ID and a selection of keywords and a snippet of the document is returned that shows the matched keywords and the context in which they occur. Thus, for each of the results returned, a snippet of the document is downloaded using the original query that returned that result as the keywords and then all results are ranked by the similarity of their snippet (after stripping HTML markup) with the suspicious document.</p><p>The similarity between the snippet of each document and the suspicious document is calculated based on an unsupervised method for calculating document similarity <ref type="bibr" coords="5,466.48,412.63,10.58,8.64" target="#b0">[1]</ref>. For each snippet and the suspicious document, the w-shingles are extracted, where the w-shingles are the overlapping sequences of w tokens in the snippet or the document. The similarity between a snippet s and a suspicious document d is then calculated as:</p><formula xml:id="formula_0" coords="5,254.31,472.09,226.28,8.96">Sim(s, d) = S(s) ∩ S(d),<label>(1)</label></formula><p>where S(•) is a set of shingles. The pairs of snippets and suspicious documents are then ranked by their similarity. We set w = 5 and found that decreasing w led to higher recall and lower precision, while increasing it had the opposite effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Candidate Document Downloading</head><p>Each document for which the similarity was above a threshold t was downloaded in the order in which they were ranked. We set t = 5 and found that decreasing t led to higher recall and lower precision, while increasing it had the opposite effect. For each downloaded document, the ChatNoir Oracle is used to determine if the candidate document is a true positive for the suspicious document. If it is, no more candidate results are downloaded for the current paragraph and the whole process is repeated for the next paragraph. Furthermore, a list is maintained that contains a record of each document downloaded since, if a candidate document has already been downloaded, downloading it again does not improve performance for the current suspicious document.</p><p>Table <ref type="table" coords="6,158.89,142.78,4.98,8.64" target="#tab_1">1</ref> shows that performance of our approach on the test data and as evaluated by the PAN organizers using the PAN corpus<ref type="foot" coords="6,286.82,153.06,3.49,6.05" target="#foot_3">4</ref>  <ref type="bibr" coords="6,293.30,154.73,15.27,8.64" target="#b11">[12]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Retrieval Performance</head><p>As can be seen from Table <ref type="table" coords="6,246.88,301.72,3.74,8.64" target="#tab_1">1</ref>, our approach achieved precision and recall of 0.55 and 0.50 respectively. Overall, both the precision and recall were the second highest achieved by all participants; however, the harmonic mean F 1 score, which captures the tradeoff between precision and recall, was the highest achieved by all participants in the task. Thus, in terms of the overall retrieval performance, our approach was very competitive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Workload</head><p>An average of 116.4 queries were submitted per document and 14.05 results downloaded. The number of queries is directly related to the size of the paragraphs extracted from the text because increasing the number of sentences per paragraph increases the number of queries since a fixed number of queries are submitted per paragraph. Thus, it is possible to vary the number of queries submitted by changing the number of sentences and queries per paragraph. However, as already mentioned, the values for these variables were chosen based on their performance. The average number of downloads per document was 14.05 and thus on average at least 14 of the results returned per document had at least 5 shingles in common with the query document. It is possible that there were more; however, they may not have been downloaded due to previously being downloaded or due to a true positive already being found. Of these 14.05 documents downloaded, on average just over half of them were true positives as is evident from the precision of 0.55.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Detection</head><p>On average, 2.45 results were downloaded until the first true positive. This suggests that the unsupervised results ranking method employed worked relatively well with relatively few false positive documents being downloaded. The average number of queries until first detection suggest that, on average, a true positive was identified based on queries generated from one of the first 6 paragraphs that occurred in the text (6 paragraphs * 3 queries). Furthermore, the fact that the first true positive was within the first 3 queries confirms that submitting 3 queries per paragraph was a good approach.</p><p>No plagiarism sources were detected for 5 suspicious documents, which was 8.6% of the suspicious documents in the test data. This was the second fewest among all participants, thereby demonstrating that the method performs relatively well at retrieving sources of plagiarism for the majority of documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Bandwidth Utilization</head><p>The number of queries was relatively high compared to the other methods; however, this was a feature of our approach rather than a shortcoming. We estimated the amount of bandwidth used by our approach by storing the data returned by any HTML request in a text file and checking the size of the text file. We found that the amount of bandwidth used to submit the top 3 queries with each returning 3 results for a single test document (suspicious-document001) was &lt; 4 KiB and the size of each of the snippets downloaded was around 1 KiB. Contrasting this with amount of bandwidth used to download the first result for the first query, which was 90 KiB, and it can be seen that queries are relatively cheap from a bandwidth perspective compared to downloading documents. Thus, there is evidence that our approach is quite efficient when it comes to bandwidth utilization; however, since a relatively large number of queries are submitted, the one downside is the additional query processing that needs to take place on the server.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>The goal in source retrieval is, ultimately, to retrieve as many sources of true plagiarism as possible while minimizing unnecessary computation. The first and perhaps most important step is query formulation where the question is: how best can queries be formulated that capture the information content of suspicious documents? This is an open research question that has importance not only in plagiarism detection, but also in keyword extraction, text summarization, and other query by document applications.</p><p>In addition to query formulation, the management of the potentially large number of results returned by search engines is important since it is desirable to determine which of those results are likely to be true positives so as to minimize unnecessary downloads and document comparisons in order to improve processing speed.</p><p>Our approach to the source retrieval task addressed both issues. Query construction was based on a method that has previously been shown to work well <ref type="bibr" coords="7,424.82,548.84,10.58,8.64" target="#b3">[4]</ref>, while the result management was based on an unsupervised re-ranking method that, to the best of our knowledge, is novel in its application. Using this approach, competitive recall and precision were achieved as well as the best performing tradeoff between the two.</p><p>The method employed involved a number of parameters for which values that performed well were found empirically. However, there may be some theoretical foundations for estimating some of these parameter values so as to maximize performance and investigating this could form the basis for future work. Future work could also investigate new methods for query formulation as well additional methods for result ranking so as to improve both precision and recall.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,134.77,185.82,349.73,51.41"><head>Table 1 .</head><label>1</label><figDesc>Performance of approach on test data</figDesc><table coords="6,134.77,206.79,349.73,30.44"><row><cell cols="3">Retrieval Performance</cell><cell cols="2">Workload</cell><cell cols="2">Time to 1st Detection</cell><cell>No</cell><cell>Runtime</cell></row><row><cell cols="8">F1 Precision Recall Queries Downloads Queries Downloads Detection</cell><cell></cell></row><row><cell>0.47</cell><cell>0.55</cell><cell>0.50</cell><cell>116.40</cell><cell>14.05</cell><cell>17.59</cell><cell>2.45</cell><cell>5</cell><cell>69781436</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,646.13,318.84,7.77;1,144.73,657.08,48.36,7.77"><p>http://charactercounts.org/programs/reportcard/2010/installment02_report-card_honestyintegrity.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,144.73,645.94,89.09,7.77"><p>http://www.turnitin.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,144.73,657.08,160.19,7.77"><p>http://www.canexus.com/eve/abouteve.shtml</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="6,144.73,645.84,335.86,8.06;6,144.73,657.08,72.46,7.77"><p>The F1 score is computed by averaging the F1 score of each run rather than from the average precision and recall.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We gratefully acknowledge partial support by the <rs type="funder">National Science Foundation</rs> under Grant No. <rs type="grantNumber">1143921</rs> and the <rs type="funder">PAN Lab</rs> organizers for their effort in organizing PAN 2013.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_5vt9Q85">
					<idno type="grant-number">1143921</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.61,210.62,337.98,7.77;8,150.95,221.58,246.21,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,340.57,210.62,112.18,7.77">Syntactic clustering of the Web</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Broder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Glassman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Manasse</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zweig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,460.16,210.62,20.43,7.77;8,150.95,221.58,125.92,7.77">Computer Networks and ISDN Systems</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">8-13</biblScope>
			<biblScope unit="page" from="1157" to="1166" />
			<date type="published" when="1997-09">Sep 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,232.54,337.98,7.77;8,150.95,243.50,329.64,7.77;8,150.95,254.46,240.45,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,325.14,232.54,155.45,7.77;8,150.95,243.50,105.64,7.77">Automatic retrieval of similar content using search engine query interface</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dasdan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>D'alberto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kolay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Drome</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,275.42,243.50,205.18,7.77;8,150.95,254.46,146.14,7.77">Proceeding of the 18th ACM conference on Information and knowledge management -CIKM &apos;09</title>
		<meeting>eeding of the 18th ACM conference on Information and knowledge management -CIKM &apos;09</meeting>
		<imprint>
			<date type="published" when="2009-11">Nov 2009</date>
			<biblScope unit="page" from="701" to="710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,265.42,337.98,7.77;8,150.95,276.37,329.64,7.77;8,150.95,287.33,100.61,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,220.17,265.42,260.42,7.77;8,150.95,276.37,52.25,7.77">Conundrums in unsupervised keyphrase extraction: making sense of the state-of-the-art</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,208.76,276.37,271.83,7.77;8,150.95,287.33,12.45,7.77">roceedings of the 23rd International Conference on Computational Linguistics</title>
		<imprint>
			<date type="published" when="1999">1999. 2010</date>
			<biblScope unit="page" from="365" to="373" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,298.29,337.98,7.77;8,150.95,309.25,235.65,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,197.22,298.29,283.37,7.77;8,150.95,309.25,33.39,7.77">Similarity Overlap Metric and Greedy String Tiling at PAN 2012: Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jayapal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,190.30,309.25,166.01,7.77">CLEF (Online Working Notes/Labs/Workshop</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,320.21,337.98,7.77;8,150.95,331.17,329.64,7.77;8,150.95,342.13,329.64,7.77;8,150.95,353.09,174.34,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,282.14,320.21,198.45,7.77;8,150.95,331.17,123.91,7.77">Unsupervised Approaches for Automatic Keyword Extraction Using Meeting Transcripts</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Pennell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,292.65,331.17,187.94,7.77;8,150.95,342.13,329.64,7.77;8,150.95,353.09,61.26,7.77">Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2009-06">June (2009</date>
			<biblScope unit="page" from="620" to="628" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,364.05,337.98,7.77;8,150.95,375.00,158.63,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,317.34,364.05,81.13,7.77">Plagiarism -A Survey</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Maurer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Media</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Kappe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Zaka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,405.66,364.05,74.93,7.77;8,150.95,375.00,65.99,7.77">Journal of Universal Computer Science</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1050" to="1084" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,385.96,337.98,7.77;8,150.95,396.92,248.53,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,204.51,385.96,276.08,7.77;8,150.95,396.92,12.27,7.77">Cheating among college and university students : A North American perspective</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">L</forename><surname>Mccabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,168.53,396.92,165.21,7.77">International Journal for Educational Integrity</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,407.88,337.98,7.77;8,150.95,418.84,329.64,7.77;8,150.95,429.80,328.12,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,399.44,407.88,81.15,7.77;8,150.95,418.84,169.02,7.77">A source independent framework for research paper recommendation</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Nascimento</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">H</forename><surname>Laender</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">S</forename><surname>Da Silva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Gonçalves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,339.81,418.84,140.78,7.77;8,150.95,429.80,236.66,7.77">Proceeding of the 11th annual international ACM/IEEE joint conference on Digital libraries -JCDL &apos;11</title>
		<meeting>eeding of the 11th annual international ACM/IEEE joint conference on Digital libraries -JCDL &apos;11</meeting>
		<imprint>
			<date type="published" when="2011-06">Jun 2011</date>
			<biblScope unit="page" from="297" to="306" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,440.76,337.98,7.77;8,150.95,451.72,106.08,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,239.43,440.76,156.11,7.77">Retrieving similar documents from the web</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ziviani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,402.53,440.76,78.06,7.77;8,150.95,451.72,26.89,7.77">Journal of Web Engineering</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="247" to="261" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,462.68,338.35,7.77;8,150.95,473.63,329.64,7.77;8,150.95,484.59,238.60,7.77" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="8,394.61,473.63,85.99,7.77;8,150.95,484.59,174.34,7.77">Overview of the 4th International Competition on Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Graß Egger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Oberländer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tippmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cede No</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="17" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,495.55,338.35,7.77;8,150.95,506.51,329.64,7.77;8,150.95,517.47,329.64,7.77;8,150.95,528.43,70.73,7.77" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,150.95,506.51,196.88,7.77">ChatNoir: A Search Engine for the ClueWeb09 Corpus</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Graß Egger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tippmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Welsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,366.69,506.51,113.90,7.77;8,150.95,517.47,326.09,7.77">Proceedings of the35th International ACM Conference on Research and Development in Information Retrieval (SIGIR 12)</title>
		<meeting>the35th International ACM Conference on Research and Development in Information Retrieval (SIGIR 12)</meeting>
		<imprint>
			<date type="published" when="2012-08">Aug 2012</date>
			<biblScope unit="page">1004</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,539.39,338.35,7.77;8,150.95,550.35,329.64,7.77;8,150.95,561.31,99.52,7.77" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,325.72,539.39,154.87,7.77;8,150.95,550.35,113.38,7.77">Crowdsourcing Interaction Logs to Understand Text Reuse from the Web</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Völske</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,284.77,550.35,195.83,7.77;8,150.95,561.31,99.52,7.77">51st Annual Meeting of the Association of Computational Linguistics (ACL 13)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,572.26,338.35,7.77;8,150.95,583.22,329.64,7.77;8,150.95,594.18,329.64,7.77;8,150.95,605.14,212.94,7.77" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,351.21,572.26,129.38,7.77;8,150.95,583.22,124.83,7.77">Feature-rich part-of-speech tagging with a cyclic dependency network</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,296.37,583.22,184.22,7.77;8,150.95,594.18,329.64,7.77;8,150.95,605.14,92.77,7.77">Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology -NAACL &apos;03</title>
		<meeting>the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology -NAACL &apos;03</meeting>
		<imprint>
			<date type="published" when="2003-05">May 2003</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="173" to="180" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,616.10,338.35,7.77;8,150.95,627.06,329.64,7.77;8,150.95,638.02,77.95,7.77" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,407.52,616.10,68.89,7.77">Query by document</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Bansal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Dakka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ipeirotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Koudas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Papadias</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,162.95,627.06,317.64,7.77;8,150.95,638.02,10.28,7.77">Proceedings of the Second ACM International Conference on Web Search and Data Mining</title>
		<meeting>the Second ACM International Conference on Web Search and Data Mining</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="34" to="43" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
