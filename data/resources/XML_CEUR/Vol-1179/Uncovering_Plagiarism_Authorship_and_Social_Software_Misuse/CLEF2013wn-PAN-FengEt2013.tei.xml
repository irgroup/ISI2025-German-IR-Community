<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,151.67,115.90,312.02,12.90;1,212.55,133.83,190.26,12.90;1,223.43,153.68,168.50,10.75">Authorship Verification with Entity Coherence and Other Rich Linguistic Features Notebook for PAN at CLEF 2013</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,234.62,190.08,72.80,8.64"><forename type="first">Vanessa</forename><forename type="middle">Wei</forename><surname>Feng</surname></persName>
						</author>
						<author>
							<persName coords="1,326.79,190.08,53.95,8.64"><forename type="first">Graeme</forename><surname>Hirst</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Toronto</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,151.67,115.90,312.02,12.90;1,212.55,133.83,190.26,12.90;1,223.43,153.68,168.50,10.75">Authorship Verification with Entity Coherence and Other Rich Linguistic Features Notebook for PAN at CLEF 2013</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">754739E34BADE4E59D2A9E7D59D4391B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We adopt Koppel et al.'s unmasking approach <ref type="bibr" coords="1,368.88,276.12,10.45,7.77" target="#b4">[5]</ref> as the major framework of our authorship verification system. We enrich Koppel et al.'s original word frequency features with a novel set of coherence features, derived from our earlier work [2], together with a full set of stylometric features. For texts written in languages other than English, some stylometric features are unavailable due to the lack of appropriate NLP tools, and their coherence features are derived from their translations produced by Google Translate service. Evaluated on the training corpus, we achieve an overall accuracy of 65.7%: 100.0% for both English and Spanish texts, while only 40% for Greek texts; evaluated on the test corpus, we achieve an overall accuracy of 68.2%, and roughly the same performance across three languages.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Authorship verification, a sub-task of authorship identification, deals with the demand of identifying whether a two documents are written by the same author or not. Typically, a set of documents which are known to be written by the author of interest is given, and an authorship verification system needs to determine whether a given unknown document is written by this author.</p><p>We follow the unmasking approach described by Koppel et al. <ref type="bibr" coords="1,411.73,495.08,10.58,8.64" target="#b4">[5]</ref>, which is designed specifically for the task of authorship verification, as the major framework of our authorship verification system. However, rather than using word-frequency features as Koppel et al. did, we unmask a pair of documents by using a set of linguistic features, including our own coherence features and well-established stylometric features. Moreover, as sophisticated coreference resolution tools, available only for English, are required for extracting our novel coherence features, we first translate non-English texts into English, and from the translations, we extract the coherence features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Unmasking</head><p>Unmasking <ref type="bibr" coords="1,183.88,644.48,11.62,8.64" target="#b4">[5]</ref> is a technique developed specifically for the task of authorship verification. Its underlying idea is that, if two documents were written by the same author, then any features a classifier finds that (spuriously) discriminate their authorship must be weak and few in number. On the other hand, if the texts were written by different authors, then many more features will support their (correct) discrimination.</p><p>Our modified unmasking approach is as follows: From all known documents in the training corpus, we extract: (1) S same , the set of pairs of documents written by same authors; (2) S diff , the set of pairs of documents written by different authors. For each document pair d i , d j , written by author A i and A j respectively, the two documents, d i and d j , are segmented into equal-sized and non-overlapping small chunks. If the number of chunks of either document is less than 5, an up-sampling is first performed to pad the size to at least 5. If the number of segmented chunks of each document is unequal, a balanced sample is obtained by randomly discarding surplus chunks in the larger set. The following procedure is repeated N times.</p><p>1. A weak classifier with a set of unmasking features is trained to label each chunk as being from document d i or d j . The sampling is repeated five times, and the averaged leave-one-out cross-validation accuracy is reported to represent the discrimination performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Remove the top 3 most discriminating features of the weak classifier, and repeat</head><p>Step 1 using the remaining features.</p><p>Pair d i , d j is therefore unmasked by the degradation of the cross-validation accuracy after each iteration of feature removal. Such degradation of accuracies is encoded by a numeric vector using the original representation in <ref type="bibr" coords="2,354.52,382.39,10.58,8.64" target="#b4">[5]</ref>. Finally, a binary classifier, called a meta-classifier, is trained to differentiate same degradation curves (A i = A j ) vs. different degradation curves (A i = A j ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Enhanced features for unmasking</head><p>Our important extension to Koppel et al.'s unmasking approach is the enhancement of the features used in building the weak classifiers for unmasking the degradation curves (Step 1 in Section 2.1). Although Koppel et al.'s word frequency feature set achieved competitive performance for verifying novel-length texts, we found that word frequency features are too unreliable for much shorter texts. Therefore, we use a more comprehensive feature set, including various rich linguistic features, which can be partitioned into two categories:</p><p>Coherence features As we have shown in earlier work <ref type="bibr" coords="2,361.33,560.80,10.58,8.64" target="#b1">[2]</ref>, coherence features, based on the local entity transition patterns derived from Barzilay and Lapata's entity grids <ref type="bibr" coords="2,134.77,584.71,10.58,8.64" target="#b0">[1]</ref>, can be useful discourse-level authorship features. The entity grid model is based on the assumption that a text naturally makes repeated reference to the elements of a set of entities that are central to its topic. It represents local coherence as a sequence of transitions, from one sentence to the next, in the grammatical role of these references.</p><p>For example, an entity may be mentioned in the subject of one sentence and then in the object of the next -or not at all in the next. These coherence features are encoded as a vector consisting of the relative proportions of a set of predefined entity transition patterns. As in our earlier work, <ref type="bibr" coords="3,267.50,119.31,10.58,8.64" target="#b1">[2]</ref>, we use Reconcile-1.0<ref type="foot" coords="3,371.25,117.38,3.69,6.39" target="#foot_0">3</ref> to extract entities in texts and resolve coreferences. Since we are not aware of any available coreference resolution systems for languages other than English, it is nontrivial to extract coherence features for Spanish and Greek texts. However, we believe that, while surface-form authorship features, such as word usage, are generally obfuscated in the process of being translated to English, coherence features, as a kind of discourse-level feature, are relatively well preserved. Therefore, we first use the Google Translate service <ref type="foot" coords="3,336.93,201.37,3.69,6.39" target="#foot_1">4</ref> to obtain their English translations, then perform the entity extraction on these translations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Stylometric features</head><p>In addition, we use a set of well-established stylometric features, the majority of which are from our earlier work <ref type="bibr" coords="3,332.54,258.61,10.58,8.64" target="#b3">[4]</ref>, including (1) Basic features: the average sentence length (in words), the average word length (in characters), lexical density, word length distribution; (2) Lexical features: frequencies of function words, hapax legomena, and hapax dislegomena; (3) Character features: frequencies of various characters; (4) Syntactic features: part-of-speech entropy, frequencies of part-of-speech bigrams, and frequencies of syntactic production rules. English texts are parsed by the Stanford CoreNLP toolkit <ref type="foot" coords="3,238.86,328.41,3.69,6.39" target="#foot_2">5</ref> , and Spanish texts are parsed by the FreeLing toolkit<ref type="foot" coords="3,458.10,328.41,3.69,6.39" target="#foot_3">6</ref> . We use the AUEB Greek part-of-speech tagger<ref type="foot" coords="3,305.42,340.36,3.69,6.39" target="#foot_4">7</ref> to obtain the part-of-speech tags for Greek texts (full syntactic parsing is not available for Greek texts).</p><p>The total number of features is 538 for English, 568 for Greek, and 399 for Spanish texts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Parameter configurations</head><p>There are a few parameters that can be adjusted in our approach. We tested several parameter combinations, and decided to use the following configurations which achieved the best performance on the training data.</p><p>Chunk sizes: English and Spanish texts are chunked into 200 words, while Greek texts are chunked into 100 words. In both cases, any leftover in a document is discarded.</p><p>Unmasking iterations: The unmasking procedures in Section 2.1 are repeated N times in order to obtain the degradation curve. For English texts, N = 20, while for both Greek and Spanish texts, N = 10.</p><p>Classifiers: For the weak classifier used in unmasking degradation curves, we use the linear-kernel LibSVM classifier, implemented by Weka 3.7.7 <ref type="bibr" coords="3,386.09,579.28,10.58,8.64" target="#b2">[3]</ref>, and the top 3 most discriminating features to be removed in each unmasking iteration are chosen as the 3 features with the highest absolute-value weight in the linear kernel. For the metaclassifier to differentiate same degradation curves vs. different degradation curves, we use the Bagging classifier offered by the Weka package. All these classifiers use the default parameters setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Result</head><p>We use only the training corpus released by PAN 2013 Authorship Identification task (10 English cases, 20 Greek cases, and 5 Spanish cases) and no other complementary materials. A separate model is built for each language.</p><p>In training, for a particular language, we use all known documents written in this language in the training corpus to unmask same and different degradation curves. Since there are typically many more different degradation curves than same ones, we sampled at most 500 same curves and 1000 different curves.</p><p>For evaluation, we unmask each unknown document in the corpus, against the given known documents of the same case, to get a degradation curve corresponding to this unmasking. We then use the trained meta-classifier to classify the resulting degradation curve as same or different, and thus determine the final answer.</p><p>We produce a yes/no answer for all cases, and obtained an overall accuracy of 65.7% for all 35 cases in the corpus. Specifically, for each language, we obtained 100.0% for both English and Spanish, while only 40% for Greek texts. The final evaluation result of our system is an overall accuracy of 68.2%, with roughly the same performance across three languages.</p><p>Because the unmasking features in our authorship verification system are designed specifically for English texts, by using well-established stylometric features and our novel coherence features, we expect that by better understanding a particular language, especially those with fewer available NLP tools, more effective unmasking features can be designed to achieve competitive performance on non-English languages as well.</p></div>			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="3,144.73,612.19,134.65,7.77"><p>http://www.cs.utah.edu/nlp/reconcile/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="3,144.73,623.46,98.63,7.77"><p>http://translate.google.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="3,144.73,634.73,164.53,7.77"><p>http://nlp.stanford.edu/software/corenlp.shtml</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3" coords="3,144.73,646.00,106.85,7.77"><p>http://nlp.lsi.upc.edu/freeling/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4" coords="3,144.73,657.08,123.08,7.77"><p>http://nlp.cs.aueb.gr/software.html</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,138.13,505.52,301.09,7.77;4,146.47,516.47,328.00,7.77;4,146.47,527.43,316.29,7.77;4,146.47,538.39,23.90,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,237.28,505.52,185.84,7.77">Modeling local coherence: an entity-based approach</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Barzilay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lapata</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,146.47,516.47,311.04,7.77;4,182.34,527.43,35.96,7.77">Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 43rd Annual Meeting on Association for Computational Linguistics<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="141" to="148" />
		</imprint>
	</monogr>
	<note>ACL 2005</note>
</biblStruct>

<biblStruct coords="4,138.13,549.35,317.23,7.77;4,146.47,560.31,193.09,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,226.67,549.35,228.69,7.77;4,146.47,560.31,36.14,7.77">Patterns of local discourse coherence as a feature for authorship attribution</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">W</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hirst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,188.14,560.31,125.28,7.77">Literary and Linguistic Computing</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,138.13,571.27,327.05,7.77;4,146.47,582.23,251.68,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,422.10,571.27,43.07,7.77;4,146.47,582.23,115.96,7.77">The WEKA data mining software: An update</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Reutemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,268.41,582.23,81.93,7.77">SIGKDD Explorations</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,138.13,593.19,338.60,7.77;4,146.47,604.15,81.43,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,226.67,593.19,188.25,7.77">Changes in style in authors with Alzheimer&apos;s disease</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hirst</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">W</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,420.68,593.19,56.05,7.77">English Studies</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="357" to="370" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,138.13,615.10,310.87,7.77;4,146.47,626.06,320.11,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,306.27,615.10,142.73,7.77;4,146.47,626.06,80.96,7.77">Measuring differentiability: Unmasking pseudonymous authors</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Bonchek-Dokow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,233.26,626.06,155.62,7.77">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1261" to="1276" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
