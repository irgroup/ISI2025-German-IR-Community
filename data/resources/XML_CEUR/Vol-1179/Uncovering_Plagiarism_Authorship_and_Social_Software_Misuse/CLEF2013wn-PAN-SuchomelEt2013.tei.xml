<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,163.41,115.90,288.54,12.90;1,242.68,133.83,130.00,12.90;1,223.43,153.68,168.50,10.75">Diverse Queries and Feature Type Selection for Plagiarism Discovery Notebook for PAN at CLEF 2013</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,200.32,190.08,66.15,8.64"><forename type="first">Å imon</forename><surname>Suchomel</surname></persName>
							<email>suchomel@fi.muni.cz</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Informatics</orgName>
								<orgName type="institution">Masaryk University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,273.66,190.08,51.42,8.64"><forename type="first">Jan</forename><surname>Kasprzak</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Informatics</orgName>
								<orgName type="institution">Masaryk University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,348.91,190.08,66.13,8.64"><forename type="first">Michal</forename><surname>Brandejs</surname></persName>
							<email>brandejs@fi.muni.cz</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Informatics</orgName>
								<orgName type="institution">Masaryk University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,163.41,115.90,288.54,12.90;1,242.68,133.83,130.00,12.90;1,223.43,153.68,168.50,10.75">Diverse Queries and Feature Type Selection for Plagiarism Discovery Notebook for PAN at CLEF 2013</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F0397E763BD3404241BE251F727B9E73</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes approaches used for the Plagiarism Detection task in PAN 2013 international competition on uncovering plagiarism, authorship, and social software misuse. We present modified three-way search methodology for Source Retrieval subtask and analyse snippet similarity performance. The results show, that presented approach is adaptable in real-world plagiarism situations. For the Detailed Comparison task, we discuss feature type selection and global postprocessing. Resulting performance is significantly better with the described modifications, and further improvement is still possible.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In PAN 2013 <ref type="foot" coords="1,187.75,391.51,3.49,6.05" target="#foot_0">1</ref> competition on plagiarism detection we participated in both the Source Retrieval and the Text Alignment subtasks. In both tasks we adapted methodology used in PAN 2012 2  <ref type="bibr" coords="1,194.20,417.09,15.27,8.64" target="#b10">[11]</ref>. Section 2 describes querying approach for source retrieval, where we used three different types of queries. We present a new type of query based on text paragraphs. The query execution was controlled by its type and by preliminary similarities discovered during the searches. Section 3 describes our approach for the text alignment (pairwise comparison) subtask. We briefly introduce our system, and then we discuss the feature types, which are usable for pairwise comparison, including the evaluation of their feasibility for this purpose. We then describe the global (corpus-wide) optimizations used, and finally we discuss the results achieved and further development.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Source Retrieval</head><p>The source retrieval is a subtask in a plagiarism detection process during which only a relatively small subset of documents are retrieved from the large corpus. Those candidate documents are usually further compared in detail with the suspicious document. In PAN 2013 source retrieval subtask the main goal was to identify web pages which have been used as a source of plagiarism for test corpus creation.</p><p>The test corpus contained 58 documents each discussing one topic only. Those documents were created intentionally by semiprofessional writers, thus they featured nearly realistic plagiarism cases <ref type="bibr" coords="2,236.91,119.31,10.58,8.64" target="#b7">[8]</ref>. Resources were looked up in the ClueWeb<ref type="foot" coords="2,422.62,117.64,3.49,6.05" target="#foot_2">3</ref> corpus. Such conditions are similar to a realistic plagiarism detection scenario.The main difference between real-world corpus of suspicious documents such as for example corpus created from theses stored in the Information System of Masaryk University and the corpus of suspicious documents used during the PAN 2013 competition is that in the PAN corpus each document contains plagiarized passages. Therefore we can expected existence of a plagiarized passage and deepen the search during the process in certain parts of the document where no similar passage has yet been found.</p><p>An online plagiarism detection can be viewed as a reverse engineering task where we need to find original documents from which the plagiarized document was created. During the process the plagiarist locates original documents with the use of a search engine. The user decides what query the search engine to ask and which of the results from the result page to use.</p><p>The same methodology -utilizing a search engine; is used for source retrieval. This approach is based on the fact that we do not possess enough resources to download and effectively process the whole corpus. In the case of PAN 2013 competition we utilized the ChatNoir <ref type="bibr" coords="2,189.00,315.33,11.62,8.64" target="#b6">[7]</ref> search engine which indexes the English subset of the ClueWeb. The reverse engineering decision process resides in creation of suitable queries on the basis of the suspicious document and in decision what to actually download and what to report as a plagiarism case from the search results.</p><p>These first two stages are shown in Figure <ref type="figure" coords="2,325.79,580.15,4.98,8.64">1</ref> as Querying and Selecting. Selected results from the search engine are then textually aligned with the suspicious document (see section 3 for more details). If there is any continuous passage of reused text detected, the result document is reported and the continuous passages in the suspicious document are marked as discovered and no further processing of those parts is done.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Querying</head><p>Querying means to effectively utilize the search engine in order to retrieve as many relevant documents as possible with the minimum amount of queries. We consider the resulting document relevant if it shares some of text characteristics with the suspicious document. In real-world queries as such represent appreciable cost, therefore their minimization should be one of the top priorities.</p><p>We used 3 different types of queries<ref type="foot" coords="3,296.73,196.80,3.49,6.05" target="#foot_3">4</ref> : i) keywords based queries, ii) intrinsic plagiarism based queries, and iii) paragraph based queries. Three main properties distinguish each type of query: i) Positional; ii) Phrasal; iii) Deterministic. Positional queries carry extra information about a textual interval in the suspicious document which the query represents. A phrasal query aims for retrieval of documents containing the same small piece of text. They are usually created from closely coupled words. Deterministic queries for specific suspicious document are always the same no matter how many times we run the software.</p><p>Keywords Based Queries. The keywords based queries are composed of automatically extracted keywords from the whole suspicious document. Their purpose is to retrieve documents concerning the same theme. As a method for automated keywords extraction, we used a frequency based approach described in <ref type="bibr" coords="3,351.12,347.36,15.27,8.64" target="#b10">[11]</ref>. The method combines term frequency analysis with TF-IDF score. As a reference corpus we used English web corpus <ref type="bibr" coords="3,151.09,371.27,11.62,8.64" target="#b0">[1]</ref> crawled by SpiderLink <ref type="bibr" coords="3,258.85,371.27,16.60,8.64" target="#b11">[12]</ref> in 2012 which contains 4.65 billion tokens.</p><p>Each keywords based query was constructed from five top ranked keywords consecutively. Each keyword was used only in one query. In order to direct the search more at the highest ranked keywords we also extracted their most frequent two and three term long collocations. These were combined also into queries of 5 words. Resulting the 4 top ranked keywords alone can appear in two different queries, one from the keywords alone and one from the collocations.</p><p>The keywords based queries are non-positional, since they represent the whole document. They are also non-phrasal since they are constructed of tokens gathered from different parts of the text. And they are deterministic; for certain input document the extractor always returns the same keywords.</p><p>Intrinsic Plagiarism Based Queries. The second type of queries purpose to retrieve pages which contain text detected as different, in a manner of writing style, from other parts of the suspicious document. For this purpose we implemented vocabulary richness method <ref type="bibr" coords="3,187.31,556.03,11.62,8.64" target="#b1">[2]</ref> together with sliding windows concept for text chunking as described in <ref type="bibr" coords="3,145.01,567.99,15.27,8.64" target="#b10">[11]</ref>.</p><p>A representative sentence longer than 6 words was randomly selected among those that apply from the suspicious part of the document. The query was created from the representative sentence leaving out stop words. The intrinsic plagiarism based queries are positional. They carry the position of the representative sentence.They are phrasal, since they represent a search for a specific sentence. And they are nondeterministic, because the representative sentence is selected randomly.</p><p>Paragraph Based Queries. The purpose of paragraph based queries is to check some parts of the text in more depth. Those are parts for which no similarity has been found during previous searches. For this case we considered a paragraph as a minimum text chunk for plagiarism to occur. Despite the fact, that paragraphs differ in length, we represent one paragraph by only one query.</p><p>From each paragraph we extracted the longest sentence from which the query was constructed. Ideally the extracted sentence should carry the highest information gain. The query was maximally 10 words in length which is the upper bound of ChatNoir and was constructed from the selected sentence by omitting stop words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Search Control</head><p>For each suspicious document we prepared all three types of queries during the first phase at once. Queries were executed stepwise. After processing each query the results were evaluated. From all textual similarities between each result and the suspicious document, the document intervals of those similarities were marked as discovered.</p><p>Firstly, there were always all of the keywords based queries executed. Secondly the intrinsic plagiarism based queries were executed according to their creation sequence. During the execution, if any of the query position intersected with any of the discovered interval, the query was dropped out. Analogically, the last there were paragraph based queries processed.</p><p>This search control results in two major properties. Firstly, the source retrieval effort was increased in parts of the suspicious document, where there has not yet been found any textual similarity. And secondly, after detection a similarity for a certain part of the text, no more intentionally retrieval attempts for that part were effectuated. Meaning that all discovered search engine results were evaluated, but there were executed no more queries regarding that passage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Result Selection</head><p>The second main decisive area about source retrieval task is to decide which from the search engine results to download. This process is represented in Figure <ref type="figure" coords="4,422.85,535.14,4.98,8.64">1</ref> as Selecting.</p><p>The ChatNoir offers snippets for discovered documents. The snippet generation is considered costless operation. The snippet purpose is to have a quick glance at a small extract of resulting page. The extract is maximally 500 characters long and it is a portion of the document around given keywords. On the basis of snippet, we needed to decide whether to actually download the result or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Snippet Control</head><p>Since the snippet is relatively small and it can be discontinuous part of the text, the text alignment methods described in section 3 were insufficient in decision making over document download. Therefore we chose to compare existence of snippet word tuples in the suspicious document.</p><p>We used 2-tuples measurement, which indicates how many neighbouring word pairs coexist in the snippet and in the suspicious document. We decided according to this value whether to download the source or not. For the deduction of the threshold value we used 4413 search results from various queries according to documents in the training corpus. Each resulting document was textually aligned to its corresponding suspicious document. In this way we calculated 248 similarities in total after downloading all of the 4431 documents.</p><p>The 2-tuples similarity performance is depicted in Figure <ref type="figure" coords="5,382.32,383.39,3.74,8.64" target="#fig_0">2</ref>. Horizontal axis represents threshold of the 2-tuples similarity percentage between the snippet and the suspicious document. The graph curves represent obtained resource percentage according to the snippet similarity threshold. A profitable threshold is the one with the largest distance between those two curves. We chose threshold of the snippet similarity to 20%, which in the graph corresponds to 20% of all downloads and simultaneously with 70% discovered similarities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Source Retrieval Results</head><p>In PAN 2013 Source Retrieval subtask we competed with other 8 teams. There can not be selected the best approach because there were several independent performance measures. Possibly each approach has its pros and cons and many approaches are usable in different situations.</p><p>We believe that in the realistic plagiarism detection the most important is to keep the number of queries low and simultaneously maximize recall. It is also advisable to keep the number of downloads low, but on the other hand, it is relatively cheep and easily scalable operation.</p><p>Our approach had the second best ratio of recall to the number of used queries, which tells about the query efficacy. The approach with the best ratio used few queries (4.9 queries per document which was 0.4 of the amount we used), but also obtained the lowest recall (0.65 of our recall). The approach with the highest recall (and also lowest precision) achieved 2.8 times higher recall with 3.9 times more queries compared to ours.</p><p>Our approach achieved also low precision, which means we reported many more results and they were not considered as correct hits. On the other hand each reported result contained some textual similarity according to text alignment subtask score, which we believe is still worthwhile to report.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Text Alignment</head><p>Our approach at the text alignment subtask of PAN 2013 uses the same basic principles as our previous work in this area, described in <ref type="bibr" coords="6,324.73,228.46,15.27,8.64" target="#b10">[11]</ref>, which in turn builds on our work for previous PAN campaigns <ref type="bibr" coords="6,252.02,240.41,10.58,8.64" target="#b2">[3]</ref>, <ref type="bibr" coords="6,268.62,240.41,10.79,8.64" target="#b3">[4]</ref>:</p><p>We detect common features between source and suspicious documents, where the features we currently use are word n-grams, and stop-word m-grams <ref type="bibr" coords="6,413.56,264.88,15.27,8.64" target="#b9">[10]</ref>. From those common features (each of which can occur multiple times in both source and suspicious document), we form valid intervals<ref type="foot" coords="6,298.26,287.12,3.49,6.05" target="#foot_4">5</ref> of characters from the source and suspicious documents, where the interval in both of these documents is covered "densely enough" by the common features.</p><p>We then postprocess the valid intervals, removing the overlapping detections, and merging the detections which are close enough to each other.</p><p>For the training corpus, our unmodified software from PAN 2012 gave the following results <ref type="foot" coords="6,160.78,359.96,3.49,6.05" target="#foot_5">6</ref> : plagdet = 0.7235, recall = 0.6306, precision = 0.8484, granularity = 1.0000 We take the above as the baseline for further improvements. In the next sections, we summarize the modifications we did for PAN 2013.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Alternative Features</head><p>In PAN 2012, we used word 5-grams and stop-word 8-grams. This year we experimented with different word n-grams, and also with contextual n-grams as described in <ref type="bibr" coords="6,145.79,477.86,15.27,8.64" target="#b12">[13]</ref>. Modifying the algorithm to use contextual n-grams created as word 5-grams with the middle word removed (i.e. two words before and two words after the context) yielded better score: plagdet = 0.7421, recall = 0.6721, precision = 0.8282, granularity = 1.0000</p><p>We then made tests with plain word 4-grams, and to our surprise, it gave even better score than contextual n-grams: plagdet = 0.7447, recall = 0.7556, precision = 0.7340, granularity = 1.0000 It should be noted that these two quite similar approaches (both use the features formed from four words), while having a similar plagdet score, have their precision and recall values completely different. Looking at the training corpus parts, plain word 4-grams were better at all parts of the corpus (in terms of plagdet score), except the 02-no-obfuscation part.</p><p>In our final submission, we used word 4-grams and stop-word 8-grams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Global Postprocessing</head><p>For PAN 2013, the algorithm had access to all of the source and suspicious documents at once. It was not limited to a single document pair, as it was in 2012. We have rewritten our software to handle all of the documents in one run, in order to be able to do crossdocument optimizations and postprocessing, similar to what we did for PAN 2010.</p><p>For PAN 2010, we used the following postprocessing heuristics: If there are overlapping detections inside a suspicious document, keep the longer one, provided that it is long enough. For overlapping detections up to 600 characters, drop them both. We implemented this heuristics, but found that it led to a lower score than without this modification. Further experiments with global postprocessing of overlaps led to a new heuristics: we unconditionally drop overlapping detections with up to 250 characters both, but if at least one of them is longer, we keep both detections. This is probably a result of plagdet being skewed too much towards recall (because the percentage of plagiarized cases in the corpus is way too high compared to real-world), so it is favourable to keep the detection even though the evidence for it is rather low.</p><p>The global postprocessing improved the score even more: plagdet = 0.7469, recall = 0.7558, precision = 0.7382, granularity = 1.0000</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Evaluation Results and Future Work</head><p>The evaluation on the competition corpus had the following results: plagdet = 0.7448, recall = 0.7659, precision = 0.7251, granularity = 1.0003 This is quite similar to what we have seen on a training corpus, with only the granularity different from 1.000 being a bit surprising. Compared to the other participants, our algorithm performs especially well for human-created plagiarism (the 05-summaryobfuscation sub-corpus), which is where we want to focus for our production systems <ref type="foot" coords="7,474.12,426.07,3.49,6.05" target="#foot_6">7</ref> .</p><p>We plan to experiment further with combining more than two types of features, be it continuous n-grams or contextual features. This should allow us to tune down the aggressive heuristics for joining neighbouring detections, which should lead to higher precision, hopefully without sacrificing recall.</p><p>As for the computational performance, it should be noted that our software is prototyped in a scripting language (Perl), so it is not the fastest possible implementation of the algorithm used. The code contains about 800 non-comment lines of code, including the parallelization of most parts and debugging/logging statements.</p><p>The system is mostly language independent. The only language dependent part of the code is the list of English stop-words for stop-word n-grams. We use no stemming or other kinds of language-dependent processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>We introduced querying strategy with snippet similarity measure. In source retrieval subtask the strategy performed with the second best ratio of recall to the number of used queries. We focused our queries on selected parts of text and on parts with no discovered external similarities. Unfortunately the ChatNoir search engine currently does not support phrasal search, therefore it is possible that evaluated results may be quite distorted in this manner.</p><p>In the text alignment subtask, we have achieved a significant improvement with respect to our system from PAN 2012. Further development in this area is still possible. For a real-world system, however, a completely different set of parameters and heuristics needs to be used, as a result of plagdet score together with the structure of the competition corpus being too different from the real world.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,215.98,243.46,183.39,8.12"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Downloads and similarities performance.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,645.94,113.22,7.77"><p>See<ref type="bibr" coords="1,159.92,645.94,10.45,7.77" target="#b5">[6]</ref> for an overview of PAN</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2013" xml:id="foot_1" coords="1,280.36,645.94,112.31,7.77;1,139.00,655.22,2.99,5.18;1,144.73,657.08,247.95,7.77"><p>plagiarism detection campaign.<ref type="bibr" coords="1,139.00,655.22,2.99,5.18" target="#b1">2</ref> See<ref type="bibr" coords="1,159.92,657.08,10.45,7.77" target="#b4">[5]</ref> for an overview of PAN 2012 plagiarism detection campaign.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,144.73,657.08,140.57,7.77"><p>http://lemurproject.org/clueweb09.php/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="3,144.73,635.17,335.86,7.77;3,144.73,646.13,335.86,7.77;3,144.73,657.08,300.80,7.77"><p>We used similar three-way based methodology in PAN 2012 Candidate Document Retrieval subtask. However, this time we completely replaced the headers based queries with paragraph based queries, since the headers based queries did not pay off in the overall process.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="6,144.73,645.94,335.86,7.77"><p>See<ref type="bibr" coords="6,159.78,645.94,10.45,7.77" target="#b3">[4]</ref> for the algorithm for computing valid intervals; a similar approach is also used in<ref type="bibr" coords="6,463.41,645.94,13.74,7.77" target="#b9">[10]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="6,144.73,656.92,275.84,7.93"><p>See<ref type="bibr" coords="6,159.92,657.08,10.45,7.77" target="#b8">[9]</ref> for definition of plagdet and the rationale behind this type of scoring.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="7,144.73,646.13,290.24,7.77;7,144.73,657.08,53.55,7.77"><p>Our production systems include the Czech National Archive of Graduate Theses, http://theses.cz</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.61,267.36,325.41,7.77;8,150.95,278.32,23.90,7.77" xml:id="b0">
	<monogr>
		<ptr target="http://trac.sketchengine.co.uk/wiki/Corpora/enTenTen" />
		<title level="m" coord="8,150.96,267.36,117.15,7.77">Sketch Engine EnTenTen Corpus</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,288.94,326.87,7.77;8,150.95,299.90,199.01,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,244.36,288.94,103.83,7.77">Intrinsic plagiarism detection</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">M Z</forename><surname>Eissen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,366.14,288.94,103.34,7.77;8,150.95,299.90,172.86,7.77">Proceedings of the European Conference on Information Retrieval (ECIR-06)</title>
		<meeting>the European Conference on Information Retrieval (ECIR-06)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,310.52,335.94,7.77;8,150.95,321.48,256.65,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,250.81,310.52,211.67,7.77">Improving the reliability of the plagiarism detection system</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kasprzak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brandejs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,150.95,321.48,194.65,7.77">Notebook Papers of CLEF 2010 LABs and Workshops</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,332.10,307.74,7.77;8,150.95,343.06,308.57,7.77;8,150.95,354.02,173.56,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,294.39,332.10,155.96,7.77;8,150.95,343.06,38.86,7.77">Finding plagiarism by evaluating document similarities</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kasprzak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brandejs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>KÅipaÄ</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,207.50,343.06,252.03,7.77;8,150.95,354.02,147.42,7.77">SEPLN&apos;09: The 25th edition of the Annual Conference of the Spanish Society for Natural Language Processing</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,364.64,333.25,7.77;8,150.95,375.60,302.24,7.77;8,150.95,386.56,328.80,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,334.02,375.60,119.17,7.77;8,150.95,386.56,127.99,7.77">Overview of the 4th international competition on plagiarism detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>OberlÃ¤nder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tippmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>BarrÃ³n-CedeÃ±o</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,296.90,386.56,156.71,7.77">CLEF 2012 Evaluation Labs and Workshop</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,397.18,324.18,7.77;8,150.95,408.14,325.16,7.77;8,150.95,419.10,199.28,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,186.83,408.14,249.40,7.77">Overview of the 5th international competition on plagiarism detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tippmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,454.19,408.14,21.92,7.77;8,150.95,419.10,132.54,7.77">CLEF 2013 Evaluation Labs and Workshop</title>
		<imprint>
			<date type="published" when="2013-09">September 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,429.72,328.34,7.77;8,150.95,440.68,320.28,7.77;8,150.95,451.63,329.64,7.77;8,150.95,462.59,229.31,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,150.95,440.68,195.48,7.77">ChatNoir: A Search Engine for the ClueWeb09 Corpus</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>GraÃegger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tippmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Welsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,257.57,451.63,223.02,7.77;8,150.95,462.59,128.24,7.77">International ACM Conference on Research and Development in Information Retrieval (SIGIR 12)</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Hersh</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Callan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Maarek</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</editor>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012-08">Aug 2012</date>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page">1004</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,473.21,301.42,7.77;8,150.95,484.17,295.35,7.77;8,150.95,495.13,248.83,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,321.97,473.21,122.06,7.77;8,150.95,484.17,123.79,7.77">Crowdsourcing interaction logs to understand text reuse from the web</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>VÃ¶lske</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,293.39,484.17,152.91,7.77;8,150.95,495.13,139.12,7.77">51st Annual Meeting of the Association of Computational Linguistics (ACL 13)</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013-08">Aug 2013</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct coords="8,142.61,505.75,310.16,7.77;8,150.95,516.71,280.40,7.77;8,150.95,527.67,317.06,7.77;8,150.95,538.63,96.14,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,344.98,505.75,107.78,7.77;8,150.95,516.71,73.99,7.77">An Evaluation Framework for Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>BarrÃ³n-CedeÃ±o</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,243.10,516.71,188.25,7.77;8,150.95,527.67,313.55,7.77">Proceedings of the 23rd International Conference on Computational Linguistics (COLING 2010). Association for Computational Linguistics</title>
		<meeting>the 23rd International Conference on Computational Linguistics (COLING 2010). Association for Computational Linguistics<address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-08">Aug 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,549.25,318.68,7.77;8,150.95,560.21,200.58,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,207.24,549.25,160.58,7.77">Plagiarism detection using stopword n-grams</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,374.02,549.25,86.90,7.77;8,150.95,560.21,174.43,7.77">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,570.83,296.24,7.77;8,150.95,581.79,316.02,7.77;8,150.95,592.75,322.94,7.77" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,302.87,570.83,135.61,7.77;8,150.95,581.79,215.13,7.77">Three way search engine queries with multi-feature document comparison for plagiarism detection</title>
		<author>
			<persName coords=""><forename type="first">Å </forename><surname>Suchomel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kasprzak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brandejs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,246.21,592.75,164.28,7.77">CLEF (Online Working Notes/Labs/Workshop</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Karlgren</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Womser-Hacker</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,603.37,326.62,7.77;8,150.95,614.33,315.29,7.77;8,150.95,625.29,48.56,7.77" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,256.65,603.37,157.74,7.77">Efficient web crawling for large text corpora</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Suchomel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>PomikÃ¡lek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,227.18,614.33,221.02,7.77">Proceedings of the seventh Web as Corpus Workshop (WAC7)</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Kilgarriff</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Sharoff</surname></persName>
		</editor>
		<meeting>the seventh Web as Corpus Workshop (WAC7)</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="39" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,635.91,329.76,7.77;8,150.95,646.87,272.76,7.77" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,276.51,635.91,195.50,7.77;8,150.95,646.87,27.23,7.77">Detailed comparison module in coremo 1.9 plagiarism detector</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A R</forename><surname>TorrejÃ³n</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M M</forename><surname>Ramos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,196.03,646.87,168.34,7.77">CLEF (Online Working Notes/Labs/Workshop)</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
