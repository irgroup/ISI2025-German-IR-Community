<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,152.70,146.06,301.29,18.78;1,166.02,163.46,263.21,18.78;1,227.64,180.86,140.00,18.78;1,211.32,202.14,172.63,14.06">CopyCaptor : Plagiarized Source Retrieval System using Global word frequency and Local feedback Notebook for PAN at CLEF 2013</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,166.74,240.25,48.10,11.09"><forename type="first">Taemin</forename><surname>Lee</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science Education</orgName>
								<orgName type="institution">Korea University</orgName>
								<address>
									<country key="KR">Republic of Korea</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<address>
									<settlement>onacloud</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,223.08,240.25,61.93,11.09"><forename type="first">Jeongmin</forename><surname>Chae</surname></persName>
						</author>
						<author>
							<persName coords="1,293.28,240.25,48.05,11.09"><forename type="first">Kinam</forename><surname>Park</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Software Engineering</orgName>
								<orgName type="institution">Soonchunhyang University</orgName>
								<address>
									<country>Republic of Korea {taeminlee</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,366.49,240.25,67.03,11.09"><forename type="first">Soonyoung</forename><surname>Jung</surname></persName>
						</author>
						<title level="a" type="main" coord="1,152.70,146.06,301.29,18.78;1,166.02,163.46,263.21,18.78;1,227.64,180.86,140.00,18.78;1,211.32,202.14,172.63,14.06">CopyCaptor : Plagiarized Source Retrieval System using Global word frequency and Local feedback Notebook for PAN at CLEF 2013</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1460241CAC46551EC6B2C92900DFC68E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present a plagiarized source retrieval system called CopyCaptor using global word frequency and local feedback to generate an effective query for finding plagiarized source documents from the given suspicious document on PAN'13 source retrieval task. The system achieved 3 rd place in competition with 0.33 F1 score, 0.50 precision and 0.33 recall on the test which find appropriate source documents of 58 suspicious documents from approx. 1 billion web pages.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Plagiarism is referred as "use or close imitation of the language and thoughts of another author and the representation of them as one's own original work" <ref type="bibr" coords="1,429.95,466.75,13.77,11.09" target="#b0">[1]</ref> and it becomes a significant problem. Since mid-1990s, automatic plagiarism detection methods have been developed. Many of them used a relatively small corpus (approx. 100~10000 documents). However, in the real situation, plagiarized documents are made from web resources (at least, 4.63 billion web pages <ref type="bibr" coords="1,390.99,512.71,12.08,11.09" target="#b1">[2]</ref>). Therefore, a plagiarism detection method should consider characteristic of web resources.</p><p>Since 2012, PAN (Plagiarism analysis, Authorship identification and Nearduplicate detection) research community made two core tasks 'source retrieval' and 'text alignment' for plagiarism detection. First, 'source retrieval' focuses finding source documents from the given suspicious document using a web search engine. Second, 'text alignment' focuses on finding similarity between two documents in a plagiarism detection manner. Detailed information about these tasks is described in <ref type="bibr" coords="1,124.74,604.63,10.64,11.09" target="#b2">[3]</ref>. We believe the former one is the key task to solve detecting plagiarized documents in consideration of web resources.</p><p>In this paper, we propose a plagiarized source retrieval system called 'CopyCaptor' which uses global word matrix and local feedback for 'Source retrieval' task on PAN'13. In section 2, we describe the framework and method based on heuristics. Section 3 shows its results of evaluation and section 4 summarizes the result of our research and discusses about the future work.</p><p>To find the source documents from a suspicious document, we developed a plagiarized source retrieval system called 'CopyCaptor' based on a query generation method using global word frequency and local feedback. In this section, we present components of CopyCaptor and describe it briefly. In the 'Pre-processing', suspicious document divided into paragraphs, and each word in paragraphs are tokenized and stemmed. Also, stop-words are removed. In the 'Query generating' process, our system made query strings with contiguous k words of each paragraph, and select the most unique query string. A detailed method and the definition of uniqueness of a query are described in the section 2.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Framework of CopyCaptor</head><p>For the 'Retrieving candidate', our system uses Indri search engine <ref type="bibr" coords="2,413.28,553.21,12.75,11.09" target="#b3">[4]</ref> because it supports structured query operators from INQUERY. We also retrieve snippet of candidate documents using ChatNoir <ref type="bibr" coords="2,276.76,576.19,13.36,11.09" target="#b4">[5]</ref> API. If our system seen the same snippet beforehand or snippet has no words, its URL is discarded. In the 'Downloading document', we download top-k URLs from candidates and also download URLs which frequently appeared in candidates URLs from different query strings.</p><p>Of course, downloaded documents are weather related to suspicious document or not. Therefore, in 'Matching document pair', we align (suspicious document, download document) pairs using simple n-gram match method. If the matching ratio (how many share the same n-gram between suspicious and a download document pair) is over some threshold (e.g. 5% or 100 words), we accept it as a source document.</p><p>When the most part of the suspicious document appeared in source documents or a number of querying on a suspicious document is over the number of paragraphs, the system stop retry querying and returns gathered source documents. Otherwise, our system retry generating query with local feedbacks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Generating query using global word frequency and local feedback</head><p>Our generating query method acquired on some heuristics from an analysis of PAN 13' training data set. We set up three heuristics as follows:</p><p>1. The most unique query is the best query. 2. A query should be differ from the previously executed queries. 3. A query formed with contiguous words in a phrase.</p><p>To find out 'most unique query', we define the uniqueness of a query as follow: GWF(Global Word Frequency) is a dictionary that contains a word as a key and an occurrence of a word in different documents on a corpus as a value. Lower occurrence means more uniqueness on a corpus. There are a lot of corpora to get a global word frequency. In this paper, we use google n-gram corpus <ref type="bibr" coords="3,341.43,393.97,12.79,11.09" target="#b5">[6]</ref> because of its generality and a wide span of topics. From the above definition, we can calculate a uniqueness of a query string and rank query strings.</p><p>We get a local feedback from previous executed queries to generate a more effective query. Because a suspicious documents comply with multiple source documents and the source documents have different words, we prefer choosing a word not exists in previous query string and not exists in match words from 'Matching Document Pair' process. Query strings are made by contiguous k words in our system.</p><p>From these rules, we design a generating query algorithm using global word frequency and local feedback. Figure <ref type="figure" coords="3,275.89,508.87,5.01,11.09">2</ref> depicts its pseudocode.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiment</head><p>We implemented CopyCaptor system using PHP language. Therefore, our system is well attached on internet service and can be simply meshed up with other web services. Using the system, we evaluated of the performance of the proposed system with 'Source Retrieval' task on PAN'13 corpora. PAN'13 corpora contain 40 suspicious documents for training and 58 suspicious documents for the test. We used training corpus to find out appropriate parameters only. We used parameters for the system as follows: search engine = Indri, number of query words = 8, number of n of n-gram = 4, matched penalty = 2. Our system uses Indri search engines built on ClueWeb09 corpus which contains approx. 1 billion web pages. Overall, CopyCaptor system achieved 3 rd rank in source retrieval task with 0.34 F1 score. The detailed experiment result of the system is shown in Table <ref type="table" coords="3,326.20,677.05,3.77,11.09">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Definition 1. The uniqueness of a</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper, we design and implemented a system called CopyCaptor for source retrieval task on PAN'13. Retrieval performance of CopyCaptor shows that the system is based on simple heuristics but it well suited for solving the problem. However, also results shows that the research in this field is not yet conquered. Furthermore, The performance of our proposed system will be improved by applying of the better text alignment algorithm because matching results from text alignment affects query generation by local feedback.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,228.06,432.31,150.53,11.09;2,136.08,449.77,334.52,11.09;2,124.74,461.29,345.94,11.09;2,124.74,472.75,345.89,11.09;2,124.74,484.27,63.37,11.09;2,136.08,495.73,334.51,11.09;2,124.74,507.25,345.98,11.09;2,124.74,518.71,345.88,11.09;2,124.74,530.23,345.98,11.09;2,124.74,541.69,268.69,11.09;2,136.08,553.21,334.44,11.09;2,124.74,564.67,345.87,11.09;2,124.74,576.19,346.07,11.09;2,124.74,587.65,345.86,11.09;2,124.74,599.17,345.86,11.09;2,124.74,610.63,303.88,11.09;2,136.08,622.15,334.64,11.09;2,124.74,633.61,345.96,11.09;2,124.74,645.13,345.86,11.09;2,124.74,656.59,345.85,11.09;2,124.74,668.11,345.91,11.09;2,124.74,679.57,41.94,11.09;2,189.48,252.48,227.52,177.42"><head>Figure 1</head><label>1</label><figDesc>Figure 1 Architecture of CopyCaptor Figure 1 illustrates the CopyCaptor system for the plagiarized source retrieve task on PAN'13 competition. The CopyCaptor consists five components, 'Pre-processing', 'Query generating', 'Retrieving candidates', 'Downloading document' and 'Matching document pair'.In the 'Pre-processing', suspicious document divided into paragraphs, and each word in paragraphs are tokenized and stemmed. Also, stop-words are removed. In the 'Query generating' process, our system made query strings with contiguous k words of each paragraph, and select the most unique query string. A detailed method and the definition of uniqueness of a query are described in the section 2.2.For the 'Retrieving candidate', our system uses Indri search engine<ref type="bibr" coords="2,413.28,553.21,12.75,11.09" target="#b3">[4]</ref> because it supports structured query operators from INQUERY. We also retrieve snippet of candidate documents using ChatNoir<ref type="bibr" coords="2,276.76,576.19,13.36,11.09" target="#b4">[5]</ref> API. If our system seen the same snippet beforehand or snippet has no words, its URL is discarded. In the 'Downloading document', we download top-k URLs from candidates and also download URLs which frequently appeared in candidates URLs from different query strings.Of course, downloaded documents are weather related to suspicious document or not. Therefore, in 'Matching document pair', we align (suspicious document, download document) pairs using simple n-gram match method. If the matching ratio (how many share the same n-gram between suspicious and a download document pair) is over some threshold (e.g. 5% or 100 words), we accept it as a source document.</figDesc><graphic coords="2,189.48,252.48,227.52,177.42" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,124.74,320.29,345.34,34.07"><head>Table 1</head><label>1</label><figDesc>Query: Given a query formed with words QW (w 1 , w 2 … w n ), and global frequency of words QGWF (GWF[w 1 ], GWF[w 2 ], …, GWF[w n ]), we will say uniqueness of a query is inverse proportional to the product of QGWF. Experiment results of proposed method on the PAN'13 corpuses</figDesc><table coords="4,124.74,149.30,343.18,252.88"><row><cell cols="3">Generating Query Algorithm</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">Input paragraph, GWF, previous_queries, matched_words, matched_panelty, #_query_words</cell></row><row><cell cols="2">Output Qstr</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1</cell><cell cols="4">Qstr = NaN; Qw = Queue(); Qgwf = Queue();</cell><cell>max_uniqueness = 0;</cell></row><row><cell>2</cell><cell cols="3">Foreach word in paragraph</cell><cell></cell><cell></cell></row><row><cell>3</cell><cell cols="4">if (word exists previous_queries) continue;</cell><cell></cell></row><row><cell>4</cell><cell cols="6">if (word exists matched_words) Qgwf.EnQueue(GWF[word] * matched_panelty);</cell></row><row><cell>5</cell><cell cols="3">else Qgwf.EnQueue(GWF[word]);</cell><cell></cell><cell></cell></row><row><cell>6</cell><cell cols="2">Qw.EnQueue(word);</cell><cell></cell><cell></cell><cell></cell></row><row><cell>7</cell><cell cols="3">if (Qw.Count() == #_query_words)</cell><cell></cell><cell></cell></row><row><cell>8</cell><cell cols="3">uniqueness = 1 / Product(Qgwf);</cell><cell></cell><cell></cell></row><row><cell>9</cell><cell cols="4">if (uniqueness &gt; max_uniqueness)</cell><cell></cell></row><row><cell>10</cell><cell></cell><cell cols="2">Qstr = implode(" ", Qw);</cell><cell></cell><cell></cell></row><row><cell>11</cell><cell></cell><cell cols="3">max_uniqueness = uniqueness;</cell><cell></cell></row><row><cell>12</cell><cell cols="2">Qw.DeQueue();</cell><cell cols="2">Qgwf.DeQueue();</cell><cell></cell></row><row><cell>13</cell><cell>return Qstr;</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="4">Figure 2 Pseudocode of generating query algorithm</cell></row><row><cell cols="3">Retrieval Performance</cell><cell cols="2">Workload</cell><cell cols="2">Time to 1 st Detection</cell></row><row><cell>F1</cell><cell cols="5">Precision Recall Queries Downloads Queries</cell><cell>Downloads</cell></row><row><cell cols="2">0.35 0.50</cell><cell>0.33</cell><cell>44.04</cell><cell>11.16</cell><cell>7.74</cell><cell>1.72</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,127.75,565.23,247.21,8.83" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="4,141.72,565.23,159.49,8.83">Random House Webster&apos;s Unabridged Dictionary</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Random House</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,127.75,574.41,342.85,8.83;4,141.72,583.59,118.39,8.83" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="4,141.72,574.41,170.42,8.83">The size of the World Wide Web (The Internet)</title>
		<ptr target="http://www.worldwidewebsize.com/" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>cited 2013 06.14</note>
</biblStruct>

<biblStruct coords="4,127.73,592.77,342.91,8.83;4,141.72,602.01,328.97,8.83;4,141.72,611.19,197.89,8.83" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,255.66,602.01,215.03,8.83;4,141.72,611.19,29.80,8.83">Overview of the 5th International Competition on Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">G</forename><surname>Martin Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthias</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Tippmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Johannes</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Efstathios</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,176.76,611.19,138.91,8.83">CLEF 2013 Evaluation Labs and Workshop</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,127.74,620.37,342.81,8.83;4,141.72,629.55,328.85,8.83;4,141.72,638.73,90.20,8.83" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,367.92,620.37,102.63,8.83;4,141.72,629.55,119.27,8.83">A language model-based search engine for complex queries</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">A M</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Howard</forename><surname>Donald And Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Bruce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,268.80,629.55,201.77,8.83;4,141.72,638.73,26.68,8.83">Proceedings of the International Conference on Intelligent Analysis</title>
		<meeting>the International Conference on Intelligent Analysis</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2" to="6" />
		</imprint>
	</monogr>
	<note>Indri</note>
</biblStruct>

<biblStruct coords="4,127.74,647.97,342.88,8.83;4,141.72,657.15,328.90,8.83;4,141.72,666.33,168.95,8.83" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,284.10,657.15,183.11,8.83">ChatNoir: a search engine for the ClueWeb09 corpus</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A H</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Matthias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jan</forename><surname>Graßegger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maximilian</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Tippmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Clement</forename><surname>Welsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,141.72,666.33,116.97,8.83">Proceedings of the 35th ACM SIGIR</title>
		<meeting>the 35th ACM SIGIR</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page">1004</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,127.74,675.51,342.84,8.83;4,141.72,684.69,115.57,8.83" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="4,171.66,675.51,199.94,8.83">Google books Ngram Viewer raw data Version 20120701</title>
		<author>
			<persName coords=""><surname>Google</surname></persName>
		</author>
		<ptr target="http://goo.gl/3IIA9" />
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>cited 2013 06.13</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
