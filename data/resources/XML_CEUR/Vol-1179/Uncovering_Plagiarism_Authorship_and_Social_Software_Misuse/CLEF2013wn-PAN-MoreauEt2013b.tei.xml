<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,149.67,115.90,176.66,12.90">Style-based distance features</title>
				<funder ref="#_bt3uDYm">
					<orgName type="full">Science Foundation Ireland</orgName>
				</funder>
				<funder>
					<orgName type="full">Trinity College, University of Dublin</orgName>
				</funder>
				<funder>
					<orgName type="full">Centre for Next Generation Localisation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,242.48,170.33,59.38,8.64"><forename type="first">Erwan</forename><surname>Moreau</surname></persName>
							<email>moreaue@cs.tcd.ie</email>
							<affiliation key="aff0">
								<orgName type="laboratory">CNGL and Computational Linguistics Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,325.70,170.33,42.71,8.64"><forename type="first">Carl</forename><surname>Vogel</surname></persName>
							<email>vogel@cs.tcd.ie</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Computational Linguistics Group</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Centre for Computing and Language Studies School of Computer Science</orgName>
								<orgName type="institution">Statistics Trinity College Dublin</orgName>
								<address>
									<settlement>Dublin</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,149.67,115.90,176.66,12.90">Style-based distance features</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FA339FF8F7230D93291A6D8ADF013D48</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we present the approach we took in our participation to the PAN 2013 Author Identification task. It relies on a complex process to select the features which represent the author's writing, using potentially multiple statistics and distance measures computed from the training set.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this author identification task, a training set containing 35 different problems with their corresponding answer in three languages (10 in English, 20 in Greek and 5 in Spanish) is provided. Each problem consists in a small set of "known" documents by a single person and a "questioned" document; the task is to determine whether the questioned document was written by the same person.</p><p>In such an author verification task, the difficulty is the lack of negative evidence, i.e. the fact that there can be no representative corpus of text written by "any other author". To overcome this issue, our approach is inspired by the unmasking technique, introduced by Koppel and Schler in <ref type="bibr" coords="1,280.20,428.93,10.58,8.64" target="#b1">[2]</ref>. More precisely, we are interested in capturing the relevant features which are unmasked with their method, and similarly in rejecting the spurious features. However we aim to find the features which help identifying the given author a priori, i.e. before applying supervised learning algorithm to them. Our strategy is the following: 1. Compute a set of features based on different n-grams patterns (e.g. character trigrams, Part-Of-Speech (POS) bigrams, etc.). Each feature represents the distance between the unknown document and the author's style for this n-grams pattern. 2. For every language, feed a classification algorithm with this set of features for all the instances. Each task in the training set, that is, each set of documents known to have been written by a given author together with the target unknown document, corresponds to an instance.</p><p>It is worth noticing that the supervised learning stage is intended to be applied to a set of pre-selected features, which are supposed to capture individually the probability (in a broad sense) that the unknown document was written by the given author. The goal of the training stage is thus only to measure the individual contributions of the features and combine them in an optimal way. We choose this strategy because:</p><p>-The good results of the unmasking approach show that the key to solving this task lies in distinguishing between the n-grams which actually characterize the author and the ones which are rather specific to a particular document.</p><p>-The training set provided contains only a small set of cases (10 for English, 20 for Greek and 5 for Spanish). Thus we want to avoid using many features in the supervised training stage in order to avoid model overfitting.</p><p>We present how the features (distance values) were computed in ยง2. Then in ยง3 we explain how different models were trained and how the final ones were selected. Finally we analyze the results in ยง4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Features 2.1 author-specific n-grams</head><p>We consider a fixed set of 14 n-grams patterns which contains tokens unigrams and bigrams, characters 4-grams, POS 3 unigrams to trigrams, plus several combinations of tokens and POS, some of which including skip-grams. For each pattern, we aim to select the set of n-grams which is the most likely to characterize the author's style.</p><p>We have observed that the more frequent a particular n-gram is, the most likely it is to follow a normal-shaped distribution accross documents by the same author. 4  This is why we use various statistics applied to the (relative) frequency of each n-gram, such as the mean, standard deviation, median and other quantiles, but also for instance the difference between the minimum and maximum or between first and third quantile. Such values are expected to provide a range against which an observed value can be compared in order to quantify how close the use if this n-gram in the unknown document is w.r.t the author's style. For each n-grams pattern, the selection of the potentially representative subset of n-grams is done by: 1. Filtering the n-grams based on one of the statistics above. A typical fitering step would be to select the n-grams for which the minimum frequency by document is higher than some threshold t &gt; 0, but a few other possibilities have been tested. 2. Selecting the n-grams corresponding to the N highest or lowest values for one the statistics above. For instance the n-grams which have the smallest range between the first and third quartile are expected to characterize the author's style in the sense that the author's use of these n-grams is rather stable accross documents, while in the same time excluding possible outliers in the distribution.</p><p>We have also tried to use negative evidence by taking into account how the distribution of a selected n-gram for the given author differ from its distribution in documents written by other authors. This was done by comparing it to the each of the other authors cases in the trainining set, computing a value which represent how different the two distributions are (several methods were tested), and using the average value as criterion 3 Part-Of-Speech tagging was done using TreeTagger (http://www.cis.unimuenchen.de/ schmid/tools/TreeTagger) for English and Spanish, and the AUEB tagger for Greek (http://nlp.cs.aueb.gr/software.html). 4 It is worth noticing that here we consider the frequency of a given n-gram accross different documents, independently from the other n-grams. This observation must also be taken with care because normality tests are not very reliable with small samples (here at most 10 distinct documents by the same author). Nevertheless the clear relation between frequency and normality accross documents shows that the assumption holds in general at least for frequent n-grams.</p><p>for selecting the n-gram or not.<ref type="foot" coords="3,262.30,117.64,3.49,6.05" target="#foot_0">5</ref> This approach gave good resuts but did not bring an improvement over using only data from the author. This is why we ended not using it, since it is more complex and significantly more costly in computation time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Comparing a document to an author profile</head><p>With the above method we can select a set of n-grams whose frequency distributions are supposed to represent the author's style. The value which will be used as feature in the supervised training stage is a distance between the questionned document and the author's style, as represented by these n-grams. Other n-grams in the unknown document are ignored, but their cumulated global frequency is indirectly taken into account in the frequencies of the selected n-grams.</p><p>Various classical distance measures have been used, like Euclidean, Cosine, ฯ 2 , but also some ad-hoc measures which assume that the reference distribution is normal: for instance the probability of the frequency in the unknown document to belong to this distribution according to the Cumulative Distribution Function, or the simple difference between this frequency and the mean, as well as other variants involving the ranges between quantiles. Additionally it was possible to compute the final value for these ad-hoc measures according to different means: arithmetic, geometric or harmonic. <ref type="foot" coords="3,461.82,312.45,3.49,6.05" target="#foot_1">6</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Models training</head><p>In the following we call distance configuration a unique set of parameters which describe a selection and a distance method, such that applying the different steps described by these parameters to a task (set of known documents and questioned document) gives only one final value (which can be used as the value of the feature for this task/instance). Such parameters include for example the threshold and the statistic to which it is applied for a filtering step, or a distance identifier and possibly its corresponding parameters for a distance method. In order to select the best selection and comparison methods, a wide set of possible configurations have been tested.</p><p>A small set of 17 "best distance configurations" has been obtained through an incremental semi-manual evaluation based on the individual performance of the configurations: since each configuration gives a distance value for each task, it can be evaluated simply by computing the distances for all task (by language) in the training set, and then computing an optimal threshold to separate the Yes/No answers.<ref type="foot" coords="3,408.40,490.86,3.49,6.05" target="#foot_2">7</ref> A manual analysis was carried out to assess the contribution of the various parameters, which lead to the selection of the final best distance configurations. Finally the supervised learning stage was applied to a few thousands of randomly chosen global configurations specified by: a random subset of features/n-grams patterns; for each pattern in the subset, a random distance configuration selected randomly from the set of 17 best distance configurations;</p><p>-A classification algorithm with its parameters, selected randomly from a set of 20 possible cases. The possible algorithms are SVM <ref type="bibr" coords="4,351.44,130.43,10.58,8.64" target="#b0">[1]</ref>, logistic regression <ref type="bibr" coords="4,443.84,130.43,10.58,8.64" target="#b2">[3]</ref>, decision trees <ref type="bibr" coords="4,192.10,141.55,11.62,8.64" target="#b3">[4]</ref> and Naive Bayes, with variants depending on their parameters.</p><p>Each random global configuration is used to produce the corresponding features and is evaluated on the training set using cross-validation Finally for each language the best performing global configuration and its corresponding model has been used in the submitted version of the software. Our approach performed noticeably well on English, but very bad on Greek, and in the average for Spanish. At the time of writing we cannot analyze the disappointing results on Greek, which are rather surprising since this was the biggest part of the training set (thus overfitting was less likely than with the other languages). This might be due to some technical or design problem with the POS tagger, which is the main difference compared to the two other languages.</p><p>More generally the approach is probably sensitive to overfitting, especially when trained on a small number of instances as it is the case with the training set. There are also other potential flaws which might cause an accuracy drop:</p><p>-The semi-manual features selection process might not be optimal: it relies on predefined possible parameters, and it is evaluated only on the basis of individual distance configurations, thus possibly discarding relevant combinations of features. -The selection of the best configuration (including the set n-grams selected for an author) is a supervised process. Even if it is more indirect that the last stage of supervised learning, there might be some overlap in the information used in both stages, which could be a cause of overfitting, despite the use of cross-validation.</p><p>We intend to study these issues as future work.</p></div>			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_0" coords="3,144.73,594.64,335.86,7.77;3,144.73,604.55,335.87,8.06;3,144.73,615.02,276.56,7.77"><p>Thus the fact that some authors appear several times in the dataset does not matter, since the impact on the average value is limited and is used only to compare n-grams from the same author (hence even if there is a bias, it is the same for all comparable values).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_1" coords="3,144.73,625.94,327.30,7.77"><p>It turned out that the arithmetic mean was less often the optimal choice than the two others.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_2" coords="3,144.73,636.70,335.86,7.77;3,144.73,646.89,335.86,7.77;3,144.73,657.08,70.36,7.77"><p>This is similar to using the correlation between the distance and the binary answer in order to compare configurations against each other, except that the result here is a maximum accuracy (more informative).</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This research is supported by the <rs type="funder">Science Foundation Ireland</rs> (Grant <rs type="grantNumber">12/CE/I2267</rs>) as part of the <rs type="funder">Centre for Next Generation Localisation</rs> (www.cngl.ie) funding at <rs type="funder">Trinity College, University of Dublin</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_bt3uDYm">
					<idno type="grant-number">12/CE/I2267</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,138.13,580.97,328.30,7.77;4,146.47,591.16,313.80,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,381.51,580.97,84.91,7.77;4,146.47,591.16,149.26,7.77">Improvements to platt&apos;s SMO algorithm for SVM classifier design</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">S</forename><surname>Keerthi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">K</forename><surname>Shevade</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">R K</forename><surname>Murthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,301.63,591.16,57.78,7.77">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="637" to="649" />
			<date type="published" when="2001-03">Mar 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,138.13,600.50,310.87,7.77;4,146.47,610.69,303.92,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,306.27,600.50,142.73,7.77;4,146.47,610.69,80.96,7.77">Measuring differentiability: Unmasking pseudonymous authors</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Bonchek-Dokow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,233.26,610.69,139.44,7.77">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1261" to="1276" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,138.13,620.04,325.24,7.77;4,146.47,630.23,210.05,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,272.61,620.04,72.27,7.77">Logistic model trees</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Landwehr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10994-005-0466-3</idno>
		<ptr target="http://dx.doi.org/10.1007/s10994-005-0466-3" />
	</analytic>
	<monogr>
		<title level="j" coord="4,350.32,620.04,48.05,7.77">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="161" to="205" />
			<date type="published" when="2005-05">May 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,138.13,639.57,339.35,7.77;4,146.47,649.76,100.36,7.77" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Quinlan</surname></persName>
		</author>
		<title level="m" coord="4,198.53,639.57,131.46,7.77">C4.5: programs for machine learning</title>
		<meeting><address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
