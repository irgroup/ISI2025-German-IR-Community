<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,235.63,115.90,144.11,12.90;1,200.74,133.83,213.88,12.90;1,223.43,153.68,168.50,10.75">Authorship Verification via k-Nearest Neighbor Estimation Notebook for PAN at CLEF 2013</title>
				<funder>
					<orgName type="full">CASED Center for Advanced Security Research Darmstadt, Germany</orgName>
				</funder>
				<funder ref="#_SPJyPnS">
					<orgName type="full">German state government of Hesse</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,193.81,190.08,51.97,8.64"><forename type="first">Oren</forename><surname>Halvani</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Fraunhofer Institute for Secure Information Technology SIT</orgName>
								<address>
									<addrLine>Rheinstrasse 75</addrLine>
									<postCode>64295</postCode>
									<settlement>Darmstadt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,252.49,190.08,71.61,8.64"><forename type="first">Martin</forename><surname>Steinebach</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Fraunhofer Institute for Secure Information Technology SIT</orgName>
								<address>
									<addrLine>Rheinstrasse 75</addrLine>
									<postCode>64295</postCode>
									<settlement>Darmstadt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,347.67,190.08,73.88,8.64"><forename type="first">Ralf</forename><surname>Zimmermann</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Fraunhofer Institute for Secure Information Technology SIT</orgName>
								<address>
									<addrLine>Rheinstrasse 75</addrLine>
									<postCode>64295</postCode>
									<settlement>Darmstadt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,235.63,115.90,144.11,12.90;1,200.74,133.83,213.88,12.90;1,223.43,153.68,168.50,10.75">Authorship Verification via k-Nearest Neighbor Estimation Notebook for PAN at CLEF 2013</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3EAC56715A0C5BF721BA9992C01B421D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe our k-Nearest Neighbor (k-NN) based Authorship Verification method for the Author Identification (AI) task of the PAN 2013 challenge. The method follows an ensemble classification technique based on the combination of suitable feature categories. For each chosen feature category we apply a k-NN classifier to calculate a style deviation score between the training documents of the true author A and the document from an author, who claims to be A. Depending on the score and a given threshold, a decision for or against the alleged author is generated and stored into a list. Afterwards, the final decision regarding the alleged authorship is determined through a majority vote among all decisions within this list. The method provides a number of benefits as for instance the independence of linguistic resources like ontologies, thesauruses or even language models. A further benefit is the language-independency among different Indo-European languages as the approach is applicable on languages like Spanish, English, Greek or German. Another benefit is the low runtime of the method, since there is no need for deep linguistic processing like POS-tagging, chunking or parsing. Moreover, the method can be extended or modified for instance by replacing the classification function, the threshold or the underlying features including their parameters (e.g. n-Gram sizes or the amount of feature frequencies). In addition to the PAN 2013 AI-training-corpus, where we gained an overall accuracy score of 80%, we also evaluated the algorithm on our own dataset with an accuracy of 77.50%.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Authorship Verification (AV ) is a subdiscipline of Authorship Analysis <ref type="bibr" coords="1,430.27,534.73,10.79,8.64" target="#b5">[8,</ref><ref type="bibr" coords="1,444.44,534.73,32.56,8.64">Page: 3]</ref>, where the task is to verify if a given document D A? of an alleged author A has been really written by A or not. In order to verify the authorship of D A? some components are mandatorily required. Generally, this includes a set of sample documents from A, a set of features (concrete "style markers") and at least one classification method that makes the decision regarding the alleged authorship. From the perspective of Machine Learning, AV appears to be an instance of binary classification problems, since the expected output of AV system regarding the alleged authorship is either "yes" or "no" (formally A or Â¬A). On a second glance, however, it turns out that AV must describe an one-class-classification problem, <ref type="bibr" coords="1,267.71,642.32,11.62,8.64" target="#b1">[3]</ref> since A is the only target class to be distinguished among all other classes (authors), which can be theoretically infinite.</p><p>In contrast to the related discipline Authorship Attribution (AA), which is also a subfield of Authorship Analysis, AV has not gained the same popularity in research. This statement can be observed from the number of publications within scientific gateways/portals as for instance ACM, CiteCeer or Springer in Table <ref type="table" coords="2,394.95,155.18,3.74,8.64" target="#tab_1">1</ref>.  One possible reason for this is that AV can be more complicated to handle as AA, since it represents an open-class problem by default, while AA can be both an open or a closed-set problem. Open-set means that the true author of a given document is not included in a set, while in a closed-set the opposite is the case. Upendra et al. mentioned in <ref type="bibr" coords="2,145.04,325.83,11.62,8.64" target="#b4">[6]</ref> that most of the research focusses on the closed-set case, which is easier to solve as the open-set case problem. The latter one, however, is closely related to AV , since a decision must be formulated that descibes if an alleged author is accepted to be the true author or not.</p><p>In this paper we propose an intuitive scheme for AV , based on our previous work in <ref type="bibr" coords="2,146.40,385.61,10.79,8.64" target="#b0">[2,</ref><ref type="bibr" coords="2,161.08,385.61,37.69,8.64">Page: 99]</ref>. The core of the method relies on the Nearest Neighbor one-classclassification technique described in <ref type="bibr" coords="2,284.94,397.56,10.79,8.64" target="#b6">[9,</ref><ref type="bibr" coords="2,299.10,397.56,37.19,8.64">Page: 69]</ref>. The main idea of our approach is to compute and compare style deviation scores depending on so-called feature category combinations between D A? and a set of training documents of A. Afterwards the overall decision regarding the alleged authorship is determined, based on a majority vote among all single decisions (according to the chosen feature category combinations).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Notation</head><p>To increase the readability of this paper we decided to follow the notation in Table <ref type="table" coords="2,473.11,498.83,3.74,8.64" target="#tab_3">2</ref>, which we have also defined in our previous work <ref type="bibr" coords="2,332.35,510.79,10.58,8.64" target="#b0">[2]</ref>. The notation will be used both in tables and in continuous text.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Features</head><p>In this section we describe which features we used in our AV system for the PAN task.</p><p>Typically features are taken from linguistic layers, which can be understood as structured units of an unstructured text. Stamatatos <ref type="bibr" coords="3,323.91,167.95,11.62,8.64" target="#b5">[8]</ref> and Loose <ref type="bibr" coords="3,383.15,167.95,11.62,8.64" target="#b3">[5]</ref> for instance mention the following linguistic layers, which can be looked-up for features:</p><p>1. Phoneme layer: This layer includes phoneme-based features that can be won out of texts by using (pronouncing) dictionaries, e.g. IPA. 2. Character layer: This layer includes character-based features as for instance prefixes, suffixes or letter n-Grams.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Lexical layer: This layer includes token-based features as for instance function</head><p>words or Pos-Tags (Part-Of-Speech Tags). 4. Syntactic layer: This layer includes syntax-based features as for instance constituents (e.g. nominal phrases) or collocations. 5. Semantic Layer: This layer includes semantic-based features especially semantic relations (homonyms, hyponymous, synonymys, meronyms, etc. ).</p><p>Instead of utilizing features according to these layers, we decided to define the term "feature categories" that allows us to distinguish more precisely among single features. For example, considering the features a,o and u, the appropriate feature category would be letters. Hence, a feature category can be seen as concrete concept of features belonging to a specific (more abstract) linguistic layer. </p><formula xml:id="formula_0" coords="3,138.50,520.14,334.31,14.49">n = 3, k = 2 F12 Token n-Gram k-suffixes (has been more) (as, en, re) n = 3, k = 2</formula><p>Table <ref type="table" coords="3,277.20,546.29,3.88,8.64">3</ref>: Feature categories</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Parameters</head><p>The majority of the feature categories in Table <ref type="table" coords="3,321.58,620.57,4.98,8.64">3</ref> can be parameterized in various ways, e.g. n-Gram sizes, k-prefix/suffix lengths or the number of entries within dictionarybased feature categories (for instance F 6 ). Moreover, the frequencies of the extracted features for each F i can be adjusted, such that one can decide to use all or just the top t extracted features. As a consequence, there is a dependency of these parameters when constructing feature vectors, which also affects our AV system regarding accuracy and runtime. For the PAN competition, however, we could not find the best parameters, due to the fact that the parameter-space is extremely huge and can only be searched through by special techniques as for instance evolutionary algorithms. Such techniques, however, are beyond the scope of our approach and are subject of future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Verification via k-NN Estimation</head><p>In this section we give a detailed description of our AV system. For overview purposes we divided the entire process into three subsections, where we first explain what kind of preprocessing we perform to clean and normalize the data, then we describe the core verification algorithm and finally we show how our system determines the regarding the alleged authorship.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Preprocessing</head><p>Given D A? as an input document which is going to be verified regarding the alleged authorship and D A as the set of sample documents of the true author, the first step is to perform preprocessing on all documents in terms of normalization and noise reduction. Normalization is essential to treat all documents uniquely, while noise reduction is important to increase the quality of extracted features. We normalize the documents by several operations as for instance substituting successive blanks by only one or by replacing diacritics by their appropriate representatives, e.g. "Ã±" "n". Moreover, we equalize the lengths of the training documents. For this we concatenate all D iA â D A into a single document, which is then splitted up into + 1 (near) equal-sized training documents D 1A , D 2A , . . . , D +1 A . Regarding noise reduction we remove citations, markup tags, formulas and non-words as for instance "DFT-Eq.(6.1)".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Verification</head><p>Our verification algorithm is based on a k-NN classifier which, by its nature, is only able to work on numeric values. Therefore, we first must construct the feature vector representations F A? from D A? and F 1A , F 2A , . . . , F +1 A from all the training documents. Beforehand, we have to choose a set of feature categories that should be taken into account. This set is denoted by F and is always odd-numbered, otherwise the later majority-vote determination would be inapplicable. Each feature vector consists of exactly n = |F i | values that represent relative frequencies within its underlying document, according to F i â F. It should be noted that in our scheme it can never be the case that a feature vector is mixed (includes features among more than one category). After all feature vectors have been constructed, we calculate style deviation scores between F A? and each F j A for all F i â F. A style deviation score describes a value s j â R + âª{0} and is calculated through a distance function dist( â¢ , â¢ ) as for example the euclidean distance. Hence, the deviation score can be written formally as s j = dist(F A? , F j A ). The lower s j is, the lower is the style deviation between F A? and F j A . Therefore s j = 0 is interpretated as absolutely identical, while s j â â is interpretated as totally different in terms of style. The resulting deviation scores are stored together with their corresponding feature vectors into a list, which is sorted (according to the scores) by ascending order:</p><formula xml:id="formula_1" coords="5,171.49,176.09,266.15,10.98">Outer_Distances = (s 1 , F 1A ), (s 2 , F 2A ), . . . , (s +1 , F +1 A )</formula><p>Next, we pick s 1 (which represents the smallest style deviation) and its corresponding feature vector F 1A from the first tuple within Outer_Distances and discard the remaining list. After that, we calculate again style deviation scores but this time between F 1A and each F iA â { F 2A , F 3A , . . . , F +1 A }. The scores s j = dist(F 1A , F iA ) are then stored (without their feature vectors) into the following list:</p><formula xml:id="formula_2" coords="5,223.88,267.46,160.88,10.62">Inner_Distances = s 2 , s 3 , . . . , s +1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Decision</head><p>To obtain a single decision (A or Â¬A) regarding a chosen feature category F i we first calculate the average of the k scores within Inner_Distances and denote it as avg_dist. Here, k refers to the k nearest neighbours of F 1A . Then, we define the acceptance decision as follows:</p><formula xml:id="formula_3" coords="5,279.85,368.69,56.58,22.31">s 1 avg_dist â¤ Î¸</formula><p>If the acceptance decision holds such that the threshold Î¸ is not exceeded, A is accepted as the true author of D A? , otherwise not. It should be noted that in all our experiments we chose Î¸ = 1, since we have observed quite stable results with it in comparison with other thresholds. After all the decisions concerning F have been determined, we store them into a list denoted by Decisions, which can look like this, for example:</p><formula xml:id="formula_4" coords="5,237.18,484.55,134.77,8.74">Decisions = A, A, A, Â¬A, Â¬A</formula><p>Finally we apply a majority-vote over Decisions and treat the resulting outcome as the overall decision. In the case of the above example the AV system will judge that D A? has been written by A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>In our experiments we consider the PAN corpus ("PAN 2013 AI-training-corpus"), which has been provided for the Author Identification task. It consists of 189 training documents across the languages Greek (GR), English (EN) and Spanish (SP) and is divided into the datasets |C GR | = 20, |C EN | = 10 and |C SP | = 5.</p><p>For our AV system we tested ten different combinations of feature categories and the parameters listed in Table <ref type="table" coords="5,256.09,644.48,3.74,8.64">4</ref>. The results are calculated in simple and weighted accuracies, where a simple accuracy is calculated as:</p><p>It can be seen easily that the resulting (simple) accuracies, which range between 56.67 % and 80 %, are highly depending on the various settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion &amp; future work</head><p>In this paper we presented an intuitive scheme to automatically verify alleged authorships of text documents. Our method provides several benefits as for instance language independence (at least for Indo-European languages) and also independence of linguistic resources (e.g. ontologies, thesauruses, language models, etc.). A further benefit is the low runtime of the method, since there is no need for deep linguistic processing like POS-tagging, chunking or parsing. Another benefit is that the involved components within the method can be replaced easily as for example the style deviation method, the acceptance-threshold or the feature categories including their parameters. Moreover, the components can be extended or combined e.g. through ensemble-techniques (combination of several style deviation methods).</p><p>Unfortunately, besides benefits our approach includes several pitfalls, too. One of the biggest challenges, for example, is the inscrutability of the methods parameterspace, due to the fact that the number of configuration settings is near infinite. Such settings include for instance the number of extracted features from a specific category or feature-specific parameters (e.g. n-Gram sizes, k-prefix/suffix lengths, etc.). Therefore, it must be investigated how to find the very best corpus-independent parameter settings. This could be accomplished, for instance, with evolutionary algorithms.</p><p>Another challenge that remains unsolved is the influence of the text topic, which can distort the verification results. For some feature categories, e.g. F 3 (Letter n-Grams), we encountered the presence of content words which are mostly topic related. Yet it is not clear if the verification results remains the same if training documents derive from different sources (e.g. e-Mails, scientific papers, social networks messages, movie reviews, etc.), which may differ heavily in register, genre and style. Hence, a more detailed investigation is required in the near future, which involves special corpora construction.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,208.73,243.96,195.42,8.64"><head>Table 1 :</head><label>1</label><figDesc>Publishing statistics of scientific portals.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="2,234.47,632.19,143.93,8.64"><head>Table 2 :</head><label>2</label><figDesc>Notation used in this paper.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="3,134.77,381.27,345.82,144.98"><head></head><label></label><figDesc>Table 3 lists all feature categories that have been used by our AV system.</figDesc><table coords="3,138.50,426.04,334.37,100.21"><row><cell>Fi Feature category</cell><cell>Examples</cell><cell></cell><cell></cell><cell></cell><cell>Remarks</cell></row><row><cell>F1 Punctuation marks</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>-</cell></row><row><cell>F3 Letter n-Grams</cell><cell cols="2">en, er, th, ted, ough</cell><cell></cell><cell></cell><cell>n â {2, 3, 4}</cell></row><row><cell>F4 Token k-prefixes</cell><cell>[removed]</cell><cell cols="2">[re], [confirmed]</cell><cell cols="2">[con]</cell><cell>k â {2, 3}</cell></row><row><cell>F5 Token k-suffixes</cell><cell>[extended]</cell><cell cols="2">[ed], [available]</cell><cell cols="2">[able]</cell><cell>k â {2, 4}</cell></row><row><cell>F6 Function words</cell><cell cols="3">and, or, the, on, in, while</cell><cell></cell><cell>-</cell></row><row><cell>F7 Function word n-Grams</cell><cell cols="4">(which, is, or), (that, on, the, above)</cell><cell>k â {3, 4}</cell></row><row><cell cols="4">F8 Sentence k-beginning function words (The . . . ), (Since the . . . )</cell><cell></cell><cell>k â {1, 2}</cell></row><row><cell>F9 Token n-Grams</cell><cell cols="3">(such that), (it could not)</cell><cell></cell><cell>k â {2, 3}</cell></row><row><cell>F10 Token n-Gram lengths</cell><cell>(of the)</cell><cell cols="3">(2,3), (are known as)</cell><cell>(3,5,2) k â {2, 4}</cell></row><row><cell>F11 Token n-Gram k-prefixes</cell><cell cols="2">(has been more)</cell><cell>(ha, be, mo)</cell><cell></cell></row></table><note coords="3,260.47,437.33,78.11,4.91;3,448.65,436.45,6.23,6.12;3,140.19,444.82,32.73,6.12;3,260.47,444.82,117.90,6.27"><p>-, _, ,, ., :, ;, (), [], {} -F2 Letters a, b, c, . . . , x, y, z, A, B, C, . . . , X, Y, Z</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="7">Acknowledgements</head><p>This work was supported by the <rs type="funder">CASED Center for Advanced Security Research Darmstadt, Germany</rs> funded by the <rs type="funder">German state government of Hesse</rs> under the <rs type="programName">LOEWE programme</rs> (http://www.CASED.de).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_SPJyPnS">
					<orgName type="program" subtype="full">LOEWE programme</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>, with â Ci = Number of correct answers per dataset C i Total number of documents per dataset C i while in contrast, a weighted accuracy is calculated as: It should be highlighted that, due to the low accuracies of some feature categories, not all F i appear within the feature category combinations in Table <ref type="table" coords="6,403.90,482.31,3.74,8.64">5</ref>.  In order to test the language independence of our method, we decided to extend the PAN corpus with an additional german dataset denoted by C DE . The C DE dataset consists of 400 documents, extracted from various German-speaking e-Books from the publicly available "Online Book Catalog" of the Gutenberg Project website: http://www.gutenberg.org/browse/languages/de C DE includes 40 problem-cases, where each case includes nine sample documents of A and one document from an author, who claims to be A. The average size of one document is 18 KByte, where each document comprises â 4KByte of data. Table <ref type="table" coords="7,134.77,229.74,4.98,8.64">6</ref> summarizes the results according to the extended PAN corpus. In our experiments we observed several phenomenons, where the most important one is that the parameter settings seems to have a very strong influence on the results. In Table <ref type="table" coords="7,159.30,459.74,4.98,8.64">7</ref> we list alternative parameter settings for the best feature category combination  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="8,138.13,613.47,334.23,7.77;8,146.47,624.42,120.53,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,192.56,613.47,169.46,7.77">Autorschaftsanalyse im Kontext der Attribution</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Halvani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="8,367.76,613.47,104.60,7.77;8,146.47,624.42,40.87,7.77">Verifikation und intrinsischer Exploration</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
	<note type="report_type">Master thesis</note>
</biblStruct>

<biblStruct coords="8,138.13,635.17,329.19,7.77;8,146.47,646.13,334.12,7.77;8,146.47,657.08,309.92,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,229.23,635.17,221.81,7.77">Authorship Verification as a One-Class Classification Problem</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schler</surname></persName>
		</author>
		<idno type="DOI">10.1145/1015330.1015448</idno>
		<ptr target="http://doi.acm.org/10.1145/1015330.1015448" />
	</analytic>
	<monogr>
		<title level="m" coord="8,146.47,646.13,274.59,7.77;8,458.18,646.13,22.42,7.77;8,146.47,657.08,10.65,7.77">Proceedings of the twenty-first international conference on Machine learning</title>
		<meeting>the twenty-first international conference on Machine learning<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">62</biblScope>
		</imprint>
	</monogr>
	<note>ICML &apos;04</note>
</biblStruct>

<biblStruct coords="9,138.13,119.96,314.43,7.77;9,146.47,130.92,59.62,7.77" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="9,206.48,119.96,136.33,7.77">Association for Computing Machinery</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">A D</forename><surname>Library</surname></persName>
		</author>
		<ptr target="http://dl.acm.org" />
		<imprint>
			<date type="published" when="2013">2013</date>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.13,141.88,302.75,7.77;9,146.47,152.84,281.33,7.77" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Loose</surname></persName>
		</author>
		<title level="m" coord="9,184.11,141.88,200.95,7.77">Paarweise Autorenschaftsverifikation von kurzen Texten</title>
		<meeting><address><addrLine>Medieninformatik</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-05">May 2011</date>
		</imprint>
		<respStmt>
			<orgName>Bauhaus-UniversitÃ¤t Weimar, FakultÃ¤t Medien</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master thesis</note>
</biblStruct>

<biblStruct coords="9,138.13,163.80,328.27,7.77;9,146.47,174.76,307.31,7.77;9,146.47,185.71,144.74,7.77;9,146.47,196.67,230.70,7.77;9,134.77,207.63,258.25,7.77;9,146.47,218.59,103.53,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,235.63,163.80,230.77,7.77;9,146.47,174.76,57.08,7.77">Sub-Profiling by Linguistic Dimensions to Solve the Authorship Attribution Task</title>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Sapkota</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Solorio</surname></persName>
		</author>
		<ptr target="http://www.springerlink.com" />
	</analytic>
	<monogr>
		<title level="m" coord="9,402.22,174.76,51.56,7.77;9,146.47,185.71,112.21,7.77">CLEF (Online Working Notes/Labs/Workshop</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Karlgren</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Womser-Hacker</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag GmbH</publisher>
			<date type="published" when="2012">2012. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.13,229.55,333.91,7.77;9,146.47,240.51,261.22,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,202.76,229.55,190.36,7.77">A Survey of Modern Authorship Attribution Methods</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<idno type="DOI">10.1002/asi.v60:3</idno>
		<ptr target="http://dx.doi.org/10.1002/asi.v60:3" />
	</analytic>
	<monogr>
		<title level="j" coord="9,399.56,229.55,72.48,7.77;9,146.47,240.51,31.00,7.77">J. Am. Soc. Inf. Sci. Technol</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="538" to="556" />
			<date type="published" when="2009-03">Mar 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.13,251.47,278.57,7.77;9,146.47,262.43,259.83,7.77;9,146.47,273.39,167.47,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,193.57,251.47,87.26,7.77">One-Class Classification</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M J</forename><surname>Tax</surname></persName>
		</author>
		<ptr target="http://www-ict.ewi.tudelft.nl/Ëdavidt/thesis.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="9,286.47,251.47,130.23,7.77;9,146.47,262.43,65.22,7.77">Concept Learning In the Absence of Counter-Examples</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>Delft University of Technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
