<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,162.58,116.95,290.20,12.62;1,206.74,134.89,201.87,12.62">Intui2: A Prototype System for Question Answering over Linked Data</title>
				<funder ref="#_hEB5RAx">
					<orgName type="full">European Commission</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,279.51,173.62,56.34,8.74"><forename type="first">Corina</forename><surname>Dima</surname></persName>
							<email>corina.dima@uni-tuebingen.de</email>
							<affiliation key="aff0">
								<orgName type="department">Seminar für Sprachwissenschaft</orgName>
								<orgName type="institution">University of Tübingen</orgName>
								<address>
									<addrLine>Wilhemstr. 19</addrLine>
									<postCode>72074</postCode>
									<settlement>Tübingen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,162.58,116.95,290.20,12.62;1,206.74,134.89,201.87,12.62">Intui2: A Prototype System for Question Answering over Linked Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">16990E184A4B8CC2AB5897E91EF1BF58</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Question Answering</term>
					<term>Linked Data</term>
					<term>Semantic Search</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>An ever increasing amount of Linked Data is made available every day. Public triple stores offer the possibility of querying hundreds of millions of triples. But this information can only be retrieved using specialized query languages like SPARQL, so for the majority of Internet users, it is still unavailable. This paper presents a prototype system aimed at streamlining the access to the information stored as RDF. The system takes as input a natural language question formulated in English and generates an equivalent SPARQL query. The mapping is based on the analysis of the syntactic patterns present in the input question. In the initial evaluation results, against the 99 questions in the QALD-3 DBpedia test set, the system provides a correct answer to 30 questions and a partial answer for another 3 questions, achieving an F-measure of 0.32.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The rise of semantic web technologies in the last decade has had an important outcome: large amounts of structured data have been made available in standard formats such as RDF and OWL. Big data repositories fostered the development of efficient algorithms for storing, indexing and querying RDF.</p><p>Collaborative knowledge bases such as DBpedia <ref type="bibr" coords="1,356.01,536.50,10.52,8.74" target="#b1">[2]</ref> and Yago2 <ref type="bibr" coords="1,416.15,536.50,10.52,8.74" target="#b7">[8]</ref> now contain millions of interlinked facts extracted with high accuracy from manually created structured data, like Wikipedia, GeoNames and WordNet. The access to all this information is, however, restricted. Specialized query languages, such as SPARQL, are the only interfaces available. For this reason, finding information in RDF stores presupposes, on one hand, being comfortable with the store's query language, and on the other hand, having a good understanding of how the data was modelled.</p><p>Consider, for example, Q71 from the QALD-3 test set, When was the Statue of Liberty built? The SPARQL query that would provide the correct answer is shown below. As you can see, there is no string similarity between the property that provides the correct answer, dbp:beginningDate <ref type="foot" coords="2,362.10,118.42,3.97,6.12" target="#foot_0">1</ref> , and the verb used in the question, built. Additional knowledge about how buildings are modelled in DBpedia, specifically how the building date is defined, is necessary in order to select the correct predicate.</p><p>SPARQL query for Q71 from the QALD-3 test set, "When was the Statue of Liberty built?" PREFIX dbp: &lt;http://dbpedia.org/property/&gt; PREFIX res: &lt;http://dbpedia.org/resource/&gt; SELECT DISTINCT ?date WHERE { res:Statue_of_Liberty dbp:beginningDate ?date . }</p><p>The need for more advanced, semantic, question answering systems that operate over large repositories of Linked Data has also been the motivation for the QALD (Question Answering over Linked Data) series of workshops. The first workshop, QALD-1 <ref type="bibr" coords="2,220.64,315.23,14.61,8.74" target="#b11">[12]</ref>, was organized in 2011 and it offered a test set containing 100 questions whose answer could be found in the DBpedia and MusicBrainz <ref type="bibr" coords="2,465.09,327.18,15.50,8.74" target="#b12">[13]</ref> datasets (50 each). QALD-2 and QALD-3 offered 200 questions over the same datasets (100 each). The questions vary in length and complexity and are meant to be indicative of what a typical user of such a semantic question answering system would ask.</p><p>This paper presents Intui2, a prototype for an RDF backed question answering system that can transform transform natural language questions into SPARQL queries, thus giving the end users access to the information stored in RDF repositories. The name of the system comes from the Romanian verb a intui (Engl. to intuit), which means "to know, sense or understand by intuition"<ref type="foot" coords="2,463.07,433.20,3.97,6.12" target="#foot_1">2</ref> .</p><p>The system is based on three central ideas:</p><p>(1) Grammatically correct questions are built of synfragments. A synfragment corresponds, from a syntactic point of view, to a subtree of the syntactic parse tree of the question. From a semantic point of view, a synfragment is a minimal span of text that can be interpreted as a concept URI, as an RDF triple or as a complex RDF query (see Fig. <ref type="figure" coords="2,342.85,512.87,4.98,8.74" target="#fig_0">1</ref> for an example). (2) The interpretation of a parent synfragment is obtained by combining the interpretations of its child synfragments in a way that is particular to the parent synfragment due to its syntactic and/or semantic characteristics (see end of section 2.2 for details). (3) The interpretation of a question in an RDF query language can be composed though a recursive interpretation of its synfragments, visited in a most-informative-first order (see section 2.2 for details). The system interprets the question with respect to the provided RDF backend, by mapping the occurring natural language expressions to concepts in the triple store.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Description</head><p>The system receives as input a natural language question formulated in English and outputs the query that will retrieve the answer to the question from the RDF backend. The architecture of the system is illustrated in Fig. <ref type="figure" coords="3,427.58,485.92,3.87,8.74" target="#fig_1">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preprocessing Phase</head><p>The natural language question is first preprocessed using the Stanford CoreNLP suite ( <ref type="bibr" coords="3,162.81,549.52,14.76,8.74" target="#b10">[11]</ref>, <ref type="bibr" coords="3,185.09,549.52,14.76,8.74" target="#b13">[14]</ref>), in particular tokenized, lemmatised, POS tagged and parsed. An additional preprocessing step is retrieving the information rank (IR) for each token. The IR gives an estimation of the specificity of a token: frequently occurring words, such as determiners, pronouns, verbs like is, has, does, give, married or nouns such as country, river, city get a small IR, while less common words like monarchical, astronauts or proper names are assigned a high IR. To compute the information rank we constructed a large word list by taking all the words in a Wikipedia dump, converting them to lower case, computing their frequencies over the whole Wikipedia and then sorting them in decreasing order of frequency. The information rank of a word is the index of the word in this sorted word list. The list has about 880,000 entries, and does not contain the words that appear less than 10 times in the whole Wikipedia. If a word is not in the list, it is assigned the rank -1. To ensure good coverage of the DBpedia concepts in the QALD-3 test set, we generated the word list using the same Wikipedia dump used to extract DBpedia 3.8. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Analysis Phase</head><p>All the data gathered in the preprocessing phase is provided as input for the analysis phase. The analysis of a question entails the recursive traversal of the question's parse tree, starting at the ROOT node, in a most-informative-first order. The order is established by computing the cumulative rank (CR) of each subtree of the current node. The cumulative rank of a tree is the sum of the information ranks of all its leaf nodes. The subtrees of each node are then traversed in decreasing cumulative rank order. In the case of the parse tree in Fig. <ref type="figure" coords="4,134.77,513.51,3.87,8.74" target="#fig_2">3</ref>, the nodes are processed in the following order: first the NP over "the same timezone" with the highest CR, 135.633, then the NP over "Utah" with the CR 3.303, than the IN over "as", with the CR 16, then the parent PP, with the CR 3.319, than the NP with CR 138.952, the IN with CR 6, the PP with CR 138.958 and so on until the whole tree has been processed.</p><p>The system distinguishes between two types of nodes: those that correspond to low-level syntactic patterns (preterminals and pre-preterminals) and those corresponding to high-level syntactic patterns (non-terminal nodes that are neither preterminals nor pre-preterminals). The syntactic pattern of a node is the label of the node plus the labels of all its immediate children, in a left-to-right order. For example, in Fig. <ref type="figure" coords="4,260.20,633.20,3.87,8.74" target="#fig_2">3</ref>, the syntactic pattern corresponding to the NP node above "the same timezone" is NP DT JJ NN. The difference between the two levels is that a node with a low-level syntactic pattern is always analysed as a URI whereas for the high-level syntactic patterns the system must construct the interpretation of the node's subtrees before the actual interpretation of the node.</p><p>The syntactic patterns for the QALD-3 DBpedia test set were obtained by parsing the questions and then doing a recursive traversal of each of the parse trees. During the traversal, the syntactic pattern of each non-terminal node was added to the global set of patterns. We obtained this way 138 syntactic patterns, split into 16 groups based on the syntactic category of the head node: 52 patterns that start with an NP node, 26 patterns that start with a VP node, 13 patterns with a WHNP node, etc. As an exercise, we computed the number of syntactic patterns in the QALD-3 DBpedia training set, and we discovered 154 syntactic patterns grouped in 19 categories. To measure the overlap between the two, we counted the number of patterns in the combined test and training set, which resulted in 204 syntactic patterns grouped in 19 categories. This shows that while the number of possible syntactic patterns is virtually infinite, in practice a relatively small number of syntactic patterns can cover a large amount of natural language questions similar to the ones in the QALD datasets.</p><p>For each syntactic pattern we then manually provided a mapping suggestion. Due to the larger number of patterns that had to be mapped, we only provided mapping suggestions for the syntactic patterns covering the QALD-3 DBpedia test set. A mapping suggestion specifies two attributes:</p><p>(i) The slot that this syntactic pattern should fill in the triple: either subject, object or predicate. In ambiguous cases, the pattern can used to fill two or even all three slots. (ii) The URI pattern: for example, predicate URI patterns are built through concatenation using the camel-case convention, while the subject and object URI patterns are formed by concatenation using the underscore as a delimiter.</p><p>For example, one of the most frequent syntactic patterns is NP NNP NNP, that is a noun phrase made of two proper nouns, like Benjamin Franklin. The mapping suggestion provided by the system for this pattern is: (slot -subject or object, URI pattern -NNP NNP). Another frequent pattern is NP DT NN, a noun phrase made from a determiner and a common noun. For this pattern the system generates a mapping suggestion covering all three slots (subject, predicate, object). The URI pattern for the subject and object slots is the capitalized version of the NN, and the URI pattern for the predicate slot is the NN itself. So for example the capital has the URI pattern Capital when in the subject or object slot and the URI pattern capital when in the predicate slot. Observe that both URI patterns ignore the determiner, which proved uninformative in the case of this syntactic pattern.</p><p>The analysis begins with an empty queue of analysis results. At this point, the current node can only be analysed as a single URI, depending on the mapping suggestion for the current syntactic pattern. The result of this step is one or more lists of URIs, depending on how many slots were defined by the mapping. This result is added to the queue of analysis results and the analysis is continued with the next node.</p><p>When the analysis queue is non-empty, the analysis can proceed along one of the following two paths:</p><p>• The top of the queue is of type URI. In this case, the result that is the head of the queue is popped out and the current node is analysed with respect to it. If the result specifies a subject or object URI, then the current node is interpreted as a predicate. If the result specifies a predicate URI, then the current node is first interpreted as a subject/object URI and then the existing result predicate is reinterpreted with respect to it. The interpretation of a predicate given a subject or object URI involves querying the triple store for all the triples with that subject or object and then scoring each of the predicates obtained with respect to the specified predicate pattern.</p><p>If at the end of this analysis there is no resulting query, the initial URI result is re-added to the queue, with a flag that specifies that it has already been analysed once. This allows the system to give the answer "OUT OF SCOPE" when no corresponding predicate is found, which means that the answer to a specific question is not covered by the data in the current RDF backend. • The top of the queue is of type Query. In this case, the top result is removed from the queue and it is rewritten by transforming any occurrence of the answer variable into a variable with a random name, e.g. randomVar.</p><p>Then the system generates two queries: one where the randomVar is the subject, and one where randomVar is the object of the query. The queries are then scored and added to the queue of analysis results, and the analysis continues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Scoring Synfragments</head><p>Every synfragment is assigned a score between 0 and 1. Complex synfragments are scored by multiplying the scores of all their constituents. URI synfragments are scored in the following manner:</p><p>• Subject/object URIs are scored using a simple, bigram-based string similarity measure between the words in the question and the concepts in the RDF backend. • Predicate URIs are scored initially using the same string similarity measure between the surface form of the predicate and the properties in the backend. If the score is under a specified threshold (0.5), then the predicate is re-scored using the WordNet similarity measure described by Hirst and St. Onge (HSO) <ref type="bibr" coords="7,226.78,351.08,10.52,8.74" target="#b6">[7]</ref> and implemented in WS4J <ref type="bibr" coords="7,362.67,351.08,14.61,8.74" target="#b15">[16]</ref>. For example, the pair (nicknames, http://dbpedia.org/property/nickname) has a string similarity score of 0.93, whereas the pair (mayor, http://dbpedia.org/ontology/leader) has a string similarity score of 0, but a HSO score of 0.375.</p><p>Additionally, the URIs that belong to the http://dbpedia.org/ontology/ namespace are boosted by doubling the initially assigned score. This makes the system favour the URIs from the manually corrected DBpedia ontology as opposed to those that are part of the automatically extracted http://dbpedia.org/property/ namespace.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Reranking Phase</head><p>All the possible partial analyses of a question are scored and kept until all the synfragments of the question are analysed. Given the syntactic patterns present in the question, the expected answer type can sometimes be very easily inferred. For example, questions that begin with Who... expect an answer of type dbo:agent or dbo:person. This can be easily specified in the query by means of the rdf:type property in the following manner: PREFIX dbo: &lt;http://dbpedia.org/ontology/&gt; PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; SELECT DISTINCT ?answer WHERE { ?answer rdf:type dbo:Person . }</p><p>The correctness of a given query is then measured as the number of results that have the correct answer type divided by the total number of answers. The final score of the query is obtained by multiplying the existing score with the computed correctness. This technique provides us with a very precise reranking of the end results, but unfortunately not all the questions have an easy to extract pattern when it comes to the expected answer type. The current system only has rerankers for the case when the answer should be an Agent/Person and for when the answer should be a number.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">System Evaluation</head><p>The QALD-3 challenge offered 99 test questions whose answer had to be found either in DBpedia or in a federated triple store containing additional data from Yago2 and MusicBrainz. In terms of complexity, the test questions are either simple questions, whose interpretation only involves recognizing the components of a triple, or complex questions that require aggregation or some form of semantic resolution to be interpreted.</p><p>Our prototype system currently focuses on the simple questions, as it is not yet equipped for dealing with complex natural language constructions. This reduces the number of questions our system could actually have constructed a correct query for to 67. Our system got 30 of the questions right, and for another 3 it got a partially right answer. Out of these, 26 questions could be answered via a query with a single triple, 3 with a query with two triples and 4 had the answer OUT OF SCOPE. The results over the QALD-3 test and training sets are detailed in Table <ref type="table" coords="8,208.91,428.71,3.87,8.74" target="#tab_0">1</ref>. The difference in the F-measure between the training and the test set can be explained by the fact that the train set was run against the same system as the test set, without manual addition of mapping suggestions for the syntactic patterns that occurred only in the training set. The system, running on a single core 2.4Ghz Intel processor with 4GB of RAM, needed on average 103 seconds to answer a question. The required time depends directly on the complexity of the question itself (how many triples have to be constructed) and on the concepts that appear in it (a question containing the name of a country or continent will take longer to process because there are usually many triples referring to such a concept, while processing a proper name will usually involve the analysis of much fewer triples).</p><p>For efficiency reasons, we made use of a locally installed version of DBpedia, powered by Jena TDB <ref type="bibr" coords="8,235.99,573.43,14.61,8.74" target="#b9">[10]</ref>. The repository can be queried using the Jena ARQ query engine <ref type="bibr" coords="8,195.14,585.38,9.96,8.74" target="#b8">[9]</ref>. Given that the triple store contains over 150 million triples, doing string matching queries directly is very ineffective and time consuming.</p><p>To mitigate this problem we generated 3 index files, containing all the unique subjects, predicates and objects of the triples in the repository. We used these index files to speed up the lookup times for URIs. The additional markup existent in DBpedia is used to ensure a better mapping from concepts to their lexicalisations. The system searches for triples with the predicate dbo:wikiPageRedirects for all the URIs retrieved via the index. If such triples are found, they are then added to the list of candidate URIs for the specified pattern. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Problematic Cases</head><p>We analysed the questions where our system gave a wrong answer. These questions can be split into the following categories:</p><p>• Synfragments that should be interpreted directly as a query. We discovered synfragments that correspond to another interpretation paradigm: the answer is an entity of a specified type with a specified property. For example, books by Kerouac, from Q81, should not be interpreted by looking at the concept Kerouac and then searching for triples with a predicate like books, but rather directly using the query PREFIX dbo: &lt;http://dbpedia.org/ontology/&gt; PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; SELECT DISTINCT ?answer WHERE { ?answer rdf:type dbo:Book . ?answer dbo:author res:Jack_Kerouac . }</p><p>The system could be improved by constructing multiple possible interpretations of a question, e.g. by interpreting upfront such a synfragment using both the general triple matching and the more specialised type matching paradigms. Other synfragments that display the same problem are are lakes in Denmark, Argentine films, companies in Munich, etc.</p><p>• Cases when both the string similarity and the HSO scorer failed to assign a high score to the correct predicate. The actual reasons for this are quite diverse, but this is obviously one of the biggest challenges for such a system. An RDF predicate can be verbalized in tens of different ways in natural language, so finding a mapping between the two is not always trivial.</p><p>The predicate used to model the relation can be lexically and semantically different from the verbalisation used in the question, as is the case with the pair (beginningDate, built) from Q71 that was described in the Introduction.</p><p>The WordNet similarity measures also fail when the compared items have separate POS tags, but clearly belong to the same semantic field, like the pair (die, death) from Q74, or when the words are not in the WordNet database, like in the example (placeOfBurial, buried), where burial is not covered by WordNet. Moreover, there are cases when the DBpedia predicate maps to complex natural language expressions, like in the case of Q98, Where does the creator of Miffy come from?, where the pattern Where does X come from? should be mapped to the predicate dbo:nationality. Solving these cases would imply finding new ways of mapping predicates to natural language expressions. Promising methods include concept embeddings <ref type="bibr" coords="10,178.77,203.87,9.96,8.74" target="#b2">[3]</ref>, Extended Semantic Analysis (ESA) <ref type="bibr" coords="10,358.80,203.87,10.52,8.74" target="#b4">[5]</ref> and using automatically extracted pattern libraries such as BOA <ref type="bibr" coords="10,329.50,215.83,9.96,8.74" target="#b5">[6]</ref>. • Predicates that have a given property both as a subject and as an object, like dbo:parent. For Q67, Who are the parents of the wife of Juan Carlos I?, the Queen Sofia of Spain is the object of the relation dbo:parent whose subject are her parents and the subject of the same relation when the object are her own children. The system generates both interpretations and gives them both the score 1, and chooses randomly one of them at the end of the analysis, in this case the wrong one.</p><p>For choosing the correct triple in this case, the system would have to offer a more precise specification of the predicate, for example by adding an extra test triple with the inverse relation. • Named Entity Recognition In Q97, Who painted The Storm on the Sea of Galilee?, the system fails to recognize that The Storm on the Sea of Galilee is the name of a famous painting by Rembrandt and tries to interpret Galilee as a location and then the sea and the storm as predicates relating to it. Such errors can be avoided through an extra preprocessing step for identifying such named entities with the help of large indexes of proper names (which could be directly extracted from Wikipedia).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Existing Approaches</head><p>Several systems were already tested in the context of the QALD workshops, all presenting different approaches to the interpretation of natural language questions as SPARQL queries. The system of Unger et. al <ref type="bibr" coords="10,377.95,501.50,15.50,8.74" target="#b14">[15]</ref> operates under the assumption that the template of the target SPARQL query can be determined by analysing the syntactic structure of the question and by interpreting it with respect to an ontology-based grammar. The constructed template contains empty slots, that have to be further specified in a second step of the analysis, that deals with entity identification and property detection. Their system, evaluated on the QALD-1 test set of 50 DBpedia-related question, answered 19 questions right and got a partial answer for another 2 questions. Aggarwal et. al <ref type="bibr" coords="10,223.69,597.34,10.52,8.74" target="#b0">[1]</ref> describe an approach that uses typed dependency information to guide the identification of DBpedia concepts. The predicates are matched using relatedness measures based on WordNet. The evaluation against the QALD-2 test set of 100 DBpedia questions revealed that the system could answer 32 questions right and had a partially correct answer for an extra 7 questions.</p><p>The QAKiS system presented by Cabrio et. al <ref type="bibr" coords="11,364.79,119.99,10.52,8.74" target="#b3">[4]</ref> introduces yet another method of interpreting natural language questions as SPARQL queries. Their approach is based on the automatic identification of a set of relevant relations between entities in the natural language question and their subsequent matching against a repository of relational patterns automatically extracted from Wikipedia. The system answers 11 questions correctly and is partially right in the case of 4 questions from the 100 test questions in the QALD-2 challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>We have presented a prototype system for question answering over Linked Data, that can answer natural language questions with respect to a given RDF backend by analysing them in terms of the synfragments they are composed of.</p><p>We plan to further improve the system, first by redesigning the synfragment interpretation paradigm to accommodate the interpretation of the same synfragment on multiple levels (as a URI, triple or query). Also, we plan to look into more advanced techniques for mapping natural language input to database concepts, like concept embeddings and Explicit Semantic Analysis.</p><p>The mapping of the syntactic patterns to slots and URI patterns was done manually for this version of the system. We intend to enhance the system with an automatically induced mapping, obtained through the exploration of large amounts of syntactic patterns.</p><p>Our intention is to extend the system to other input languages, either directly, by integrating a machine translation module that would translate the initial queries to English, or by integrating language processing tools for other languages and then mapping directly to the DBpedia concepts from those languages.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,134.77,314.00,345.83,7.89;3,134.77,324.98,345.82,7.86;3,134.77,335.94,345.83,7.86;3,134.77,346.90,277.35,7.86;3,191.68,116.83,232.00,182.40"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Synfragments for Q2 from the QALD-3 DBpedia test set, Who was the successor of John F. Kennedy? Solid boxes surround synfragments that are interpreted as URIs, dashed boxes mark synfragments that are interpreted as one triple and dotted boxes indicate synfragments that correspond to a complex SPARQL query.</figDesc><graphic coords="3,191.68,116.83,232.00,182.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,238.11,356.63,139.14,7.89;4,170.13,199.51,275.10,142.35"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Intui2 system architecture.</figDesc><graphic coords="4,170.13,199.51,275.10,142.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,134.77,340.80,345.82,7.89;5,134.77,351.78,294.89,7.86;5,162.68,116.83,290.00,209.20"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Information ranks (enclosed by square brackets) and cumulative ranks (enclosed by parentheses). Punctuation marks are assigned the information rank 0.</figDesc><graphic coords="5,162.68,116.83,290.00,209.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="9,159.13,163.00,294.03,50.58"><head>Table 1 .</head><label>1</label><figDesc>Evaluation results for the Intui2 system</figDesc><table coords="9,159.13,183.40,294.03,30.18"><row><cell>Test Set</cell><cell cols="6">Total Right Partially Recall Precision F-measure</cell></row><row><cell cols="2">QALD-3 DBpedia test 99</cell><cell>30</cell><cell>3</cell><cell>0.32</cell><cell>0.32</cell><cell>0.32</cell></row><row><cell cols="3">QALD-3 DBpedia train 100 18</cell><cell>2</cell><cell>0.2</cell><cell>0.19</cell><cell>0.19</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,613.96,335.87,7.86;2,144.73,624.92,335.86,7.86;2,144.73,635.88,198.60,7.86"><p>dbp denotes the DBpedia property namespace, http://dbpedia.org/property/,dbo the DBpedia ontology namespace, http://dbpedia.org/ontology/ and res the DBpedia resource namespace, http://dbpedia.org/resource/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,144.73,646.84,335.86,7.86;2,144.73,657.79,142.45,7.86"><p>according to the definition in the Merriam-Webster online dictionary, http://www.merriam-webster.com/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The research leading to these results has received funding from the <rs type="funder">European Commission</rs>'s <rs type="programName">7th Framework Program</rs> under grant agreement no. <rs type="grantNumber">238405</rs> (CLARA).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_hEB5RAx">
					<idno type="grant-number">238405</idno>
					<orgName type="program" subtype="full">7th Framework Program</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="11,138.35,527.52,342.24,7.86;11,146.91,538.47,333.68,7.86;11,146.91,549.43,55.90,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,260.90,527.52,219.70,7.86;11,146.91,538.47,33.15,7.86">A System Description of Natural Language Query over DBpedia</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Aggarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Buitelaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,203.36,538.47,181.54,7.86">Proceedings of Interacting with Linked Data</title>
		<meeting>Interacting with Linked Data<address><addrLine>Heraklion, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="96" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.35,559.98,342.24,7.86;11,146.91,570.94,333.67,7.86;11,146.91,581.90,333.68,7.86;11,146.91,592.86,47.10,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,161.26,570.94,231.72,7.86">DBpedia -A Crystallization Point for the Web of Data</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Kobilarov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Cyganiak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hellmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,416.68,570.94,63.91,7.86;11,146.91,581.90,259.89,7.86">Journal of Web Semantics: Science, Services and Agents on the World Wide Web</title>
		<imprint>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="154" to="165" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.35,603.41,342.25,7.86;11,146.91,614.37,333.68,7.86;11,146.91,625.33,157.87,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,347.28,603.41,133.31,7.86;11,146.91,614.37,76.63,7.86">Learning Structured Embeddings of Knowledge Bases</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bordes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Weston</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Collobert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,243.27,614.37,237.32,7.86;11,146.91,625.33,41.47,7.86">Proceedings of the 25th Conference on Artificial Intelligence (AAAI-11)</title>
		<meeting>the 25th Conference on Artificial Intelligence (AAAI-11)<address><addrLine>San Francisco, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.35,635.88,342.24,7.86;11,146.91,646.84,333.68,7.86;11,146.91,657.79,170.47,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,451.67,635.88,28.92,7.86;11,146.91,646.84,42.36,7.86">QAKiS @ QALD-2</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Cabrio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>Aprosio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cojan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Gandon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lavelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,212.34,646.84,268.25,7.86;11,146.91,657.79,17.92,7.86">Proceedings of the ESWC 2012 workshop Interacting with Linked Data</title>
		<meeting>the ESWC 2012 workshop Interacting with Linked Data<address><addrLine>Heraklion, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="87" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.35,120.67,342.24,7.86;12,146.91,131.63,333.68,7.86;12,146.91,142.59,234.54,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,275.96,120.67,204.63,7.86;12,146.91,131.63,134.19,7.86">Computing Semantic Relatedness using Wikipediabased Explicit Semantic Analysis</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Markovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,303.47,131.63,177.12,7.86;12,146.91,142.59,143.29,7.86">Proceedings of the 20th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 20th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1606" to="1611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.35,153.55,342.24,7.86;12,146.91,164.51,333.68,7.86;12,146.91,175.46,278.49,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,289.90,153.55,190.69,7.86;12,146.91,164.51,100.67,7.86">Extracting Multilingual Natural Language Patterns for RDF Predicates</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Gerber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A.-C</forename><surname>Ngonga Ngomo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,268.98,164.51,211.61,7.86;12,146.91,175.46,211.80,7.86">Proceedings of the 18th International Conference on Knowledge Engineering and Knowledge Management</title>
		<meeting>the 18th International Conference on Knowledge Engineering and Knowledge Management<address><addrLine>Galway</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.35,186.42,342.24,7.86;12,146.91,197.38,333.68,7.86;12,146.91,208.34,195.01,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,239.83,186.42,240.76,7.86;12,146.91,197.38,127.68,7.86">Lexical chains as representations of context for the detection and correction of malapropisms</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hirst</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>St-Onge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,425.40,197.38,55.19,7.86;12,146.91,208.34,110.72,7.86">WordNet: An Electronic Lexical Database</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Miller</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="305" to="332" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.35,219.30,342.25,7.86;12,146.91,230.26,333.68,7.86;12,146.91,241.22,25.60,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,315.38,219.30,165.21,7.86;12,146.91,230.26,158.73,7.86">YAGO2: a spatially and temporally enhanced knowledge base from Wikipedia</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hoffart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Berberich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,313.40,230.26,83.41,7.86">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">194</biblScope>
			<biblScope unit="page" from="28" to="61" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.35,252.18,342.24,7.86;12,146.91,263.14,230.19,7.86" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="12,146.91,252.18,329.47,7.86">Jena ARQ query engine for the SPARQL RDF query language</title>
		<ptr target="http://jena.apache.org/documentation/query/index.html" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,274.09,280.35,7.86" xml:id="b9">
	<monogr>
		<ptr target="http://jena.apache.org/documentation/tdb/" />
		<title level="m" coord="12,151.52,274.09,86.25,7.86">Jena TDB RDF store</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,285.05,337.97,7.86;12,146.91,296.01,333.67,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,260.04,285.05,124.37,7.86">Accurate Unlexicalized Parsing</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,405.90,285.05,74.69,7.86;12,146.91,296.01,250.08,7.86">Proceedings of the 41st Meeting of the Association for Computational Linguistics</title>
		<meeting>the 41st Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="423" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,306.97,337.97,7.86;12,146.91,317.93,287.65,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,334.92,306.97,145.67,7.86;12,146.91,317.93,48.25,7.86">Evaluating Question Answering over Linked Data</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Unger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cimiano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Motta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,216.80,317.93,103.43,7.86">Journal of Web Semantics</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct coords="12,142.62,328.89,291.48,7.86" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><surname>Musicbrainz</surname></persName>
		</author>
		<ptr target="http://musicbrainz.org/" />
		<title level="m" coord="12,207.52,328.89,122.34,7.86">The Open Music Encyclopedia</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,339.85,337.98,7.86;12,146.91,350.81,333.68,7.86;12,146.91,361.77,76.80,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,365.89,339.85,114.70,7.86;12,146.91,350.81,173.67,7.86">Feature-Rich Part-of-Speech Tagging with a Cyclic Dependency Network</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,341.51,350.81,134.88,7.86">Proceedings of HLT-NAACL 2003</title>
		<meeting>HLT-NAACL 2003</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="252" to="259" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,372.73,337.97,7.86;12,146.91,383.68,333.68,7.86;12,146.91,394.64,333.68,7.86;12,146.91,405.60,75.26,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="12,160.60,383.68,204.83,7.86">Template-based question answering over RDF data</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Unger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bühmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A.-C</forename><surname>Ngonga Ngomo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Gerber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cimiano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,386.66,383.68,93.93,7.86;12,146.91,394.64,234.49,7.86">Proceedings of the 21st International Conference on World Wide Web (WWW &apos;12)</title>
		<meeting>the 21st International Conference on World Wide Web (WWW &apos;12)<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="639" to="648" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,416.56,297.31,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="12,183.55,416.56,111.00,7.86">WordNet Similarity for Java</title>
		<ptr target="https://code.google.com/p/ws4j/" />
	</analytic>
	<monogr>
		<title level="m" coord="12,151.52,416.56,23.93,7.86">WS4J</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
