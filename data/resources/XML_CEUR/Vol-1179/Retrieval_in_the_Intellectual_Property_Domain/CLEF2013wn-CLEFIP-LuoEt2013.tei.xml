<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,160.36,116.95,283.89,12.62;1,387.45,134.89,65.30,12.62">Query Formulation for Prior Art Search</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,253.58,172.74,44.28,8.74"><forename type="first">Jiyun</forename><surname>Luo</surname></persName>
						</author>
						<author role="corresp">
							<persName coords="1,320.55,172.74,41.23,8.74"><forename type="first">Hui</forename><surname>Yang</surname></persName>
							<email>huiyang@cs.georgetown.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Georgetown University at CLEF</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">Georgetown University</orgName>
								<address>
									<addrLine>37th and O Streets NW</addrLine>
									<settlement>Washington</settlement>
									<region>DC</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,160.36,116.95,283.89,12.62;1,387.45,134.89,65.30,12.62">Query Formulation for Prior Art Search</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1D5DF4F01051C361E9751404F195743D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Patent Search</term>
					<term>Prior Art Search</term>
					<term>Query Formulation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Our group participated in the CLEF-IP 2013 Passage Retrieval starting from Claims task. We focus on formulating representative queries from various metadata that is embedded in a patent document. We then submit the queries to a state-of-the-art search engine to perform document level retrieval. For passage level retrieval, we implement a TF-IDF algorithm that calculates the sum of query keywords' TF-IDF scores. We submitted six runs, which tested different uses of the metadata and different retrieval algorithms. We find that carefully constructed structured queries from titles and terms with mid-range IDF values are effective for patent prior art retrieval.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A patent is a set of legal documents authorized by a government's patent office. It is used to grant exclusive rights for exploitation of the invention for a span of time, usually 20 years. A Patent Application document is written by the patent applicant to describe the background and the description of the invention, and to declare a set of claims. The claims are usually drafted with the help of a patent attorney, and are used to specify what exactly the patent should protect.</p><p>The novelty search, also called Prior Art Search, is the procedure that patent examiners search for existing patent documents, which are called prior arts, to prove that the all or part of the claims in a newly filed patent application document are not novel and hence can be rejected. CLEF-IP 2013 Passage Retrieval starting from Claims task exactly captures the procedure of the novelty search. Given one or a few claims, the participants are asked to retrieve relevant patent documents in the collection and mark out the relevant passages. The following is an example of a CLEF-IP query: &lt;tfile&gt;EP-1752179-A2.xml&lt;/tfile&gt; &lt;title&gt;Needle guard clip with stylus&lt;/title&gt; &lt;abstract&gt;A needle guard (10) includes a clip (12) with a canting wall (16) to grip the needle shaft (56) and a distal wall (22) to block the tip (58) thereof, wherein the canting and distal walls may be interconnected by an angled strut (24,26). . . &lt;/abstract&gt; &lt;tclaims&gt;/patent-document/claims/claim <ref type="bibr" coords="2,311.67,131.63,13.22,7.86" target="#b0">[1]</ref>[8]&lt;/tclaims&gt; &lt;claim num="1"&gt; A safety catheter device comprising a catheter hub and a catheter tube extending therefrom, a needle having a needle shaft terminating in a sharp tip, . . . &lt;/claim&gt; &lt;claim num="8"&gt; A needle protector device comprising a housing adapted to slidably receive a needle therethrough, a clip positioned in the housing and having a first wall with an aperture adapted to slidably receive a needle shaft of the needle. . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;/claim&gt;</head><p>In the example, the participants are asked to search the given patent corpus and to retrieve prior arts for the patent file EP-1752179-A2.xml with relevant passages being marked out. These retrieved documents and passages should be evidence to help patent examiners reject the 1 st and the 8 th claims in the patent application.</p><p>The data collection <ref type="bibr" coords="2,241.61,307.89,10.52,8.74" target="#b2">[3]</ref>  We adopt the Lemur Search Engine<ref type="foot" coords="3,297.79,144.89,3.97,6.12" target="#foot_0">1</ref> to build index and retrieve the patent documents. Specifically, we use Lemur to build inverted index for each word in the CLEF-IP collection except the stopwords. We stem the terms using the Krovetz stemmer <ref type="bibr" coords="3,214.46,182.33,9.96,8.74" target="#b1">[2]</ref>. To allow structured retrieval, we also index many fields that are present in the patent application documents. Table <ref type="table" coords="3,400.43,194.28,4.98,8.74" target="#tab_0">1</ref> gives a complete list of indexed fields and their detail descriptions.</p><p>The Lemur Search Engine implements many retrieval algorithms, including the vector space model, Language Modeling, and Okapi BM25 <ref type="bibr" coords="3,410.02,230.66,9.96,8.74" target="#b0">[1]</ref>. In our work, we focus at generating highly representative query keywords. During retrieval, we adopt the algorithms that implemented by Lemur directly. The two particular algorithms that we use are Language Modeling with Dirichlet smoothing and Okapi BM25.</p><p>The language modeling with Dirichlet smoothing can be shown as in the following scoring formula:</p><formula xml:id="formula_0" coords="3,248.83,324.30,231.76,24.72">P (t|d) = tf t,d + µP (t|M C ) t ∈V tf t ,d + µ<label>(1)</label></formula><p>where tf t,d means term t's term frequency in document d, M C is the corpus model, V is the Vocabulary. In order to get the best value for parameter µ, we fixed the input query keywords, and switched µ between {3000, 3500, 3700, 3800, 3900, 3950, 4000, 4050, 4100, 4200, 4300, 4500, 5000, 5500}. Our experiments shows that 4050 is the best µ value. Okapi BM25 follows the scoring formula as below:</p><formula xml:id="formula_1" coords="3,163.90,441.97,312.45,26.80">t∈Q (log N -df t + 0.5 df t + 0.5 ) (k 1 + 1)tf t k 1 ((1 -b) + b doc len avg doc len ) + tf t (k 3 + 1)qtf t k 3 + qtf t (<label>2</label></formula><formula xml:id="formula_2" coords="3,476.35,448.71,4.24,8.74">)</formula><p>where Q is the query keywords set, N is the number of documents in the corpus, df t is term t's document frequency, tf t is term t's term frequency in document d, doc len is the length of document d as the number of terms, avg doc len is the average length of a document, qtf t is term t's term frequency in query set Q. There are 3 parameters (k 1 , b ,k 3 ) in Okapi's scoring formula. In order to evaluate the best value set for (k 1 , b ,k 3 ), we fixed b=0.75, k 3 =7, and varied k 1 through 1.0 to 10. We perform parameter tuning to b and k 3 . The experiments show that the best value set for (k 1 , b ,k 3 ) is (8.0, 0.85, 1000).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Query Formulation</head><p>In this section, we present several approaches to formulate queries from patent documents.</p><p>Extracting claim texts We directly extract task claims out of patent documents and use these claims as query keywords to retrieve documents. For patent EP-1752179-A2, we get query:</p><p>A safety catheter device comprising a catheter hub and a catheter tube extending therefrom, a needle having a needle shaft terminating in a sharp tip, . . . A needle protector device comprising a housing adapted to slidably receive a needle therethrough, a clip positioned in the housing and having a first wall with an aperture adapted to slidably receive a needle shaft of the needle. . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Extracting hyphenating phrases</head><p>We believe that hyphenating phrases like "water-bed' are usually representative words, hence we propose to form queries by extracting hyphenating phrases from the claims.</p><p>Extracting titles We believe that a document's title usually summarizes a document well. In this approach, we use patent title to generate queries. Some patent application documents may have multiple titles; each title is written in English, German, or French. We refer the title written in English as the English Title, and the title which shares the consistent language with the patent application document as the Consistent Title. For example, patent EP-0195350-A2 is written in German and has three titles:</p><p>English Title: Method for regenerating carbon articles German Title: Verfahren zur Regenerierung von Formkörpern aus Kohlenstoff French Title: Procédé pour régénérer des corps en carbone</p><p>The first title is called the English Title and the second title is called the Consistent Title since it matches with the language document of the application. For a patent document written in English like EP-1752179-A2 (see Section 1), its English Title is also the Consistent Title. Through experiments on last year's data, we find out that if we retrieve results using the Language Modeling approach, we get better results when we use the Consistent Title; on the other hand, if we retrieve results using the Okapi BM25 Model, we get better results when we add both the Consistent Title and the English Title into the query keywords.</p><p>IDF filtering Each of the previous three approaches alone or their combinations can provide us with a set of query keywords. Even though we remove stopwords out of the query keywords, there are still many terms like "water" which are not stopwords but are also common in the document collection; hence they are not representative. In this approach, we propose that using IDF (inverse document frequency) <ref type="bibr" coords="4,184.70,585.19,10.52,8.74" target="#b4">[5]</ref> to filter query keywords. Terms with a very low IDF value are common words in the corpus, while terms with a very high IDF value has a high possibility to be a typo.</p><p>We propose a two layer filtering strategy. We believe that hyphenating phrases and terms extracted from title are better words than words extracted from claims. Based on this assumption, we split query keywords into two sets. One set is called the Standard Query, it contains terms extracted from claims. The other set is called the Refined Query, it contains hyphenating phrases and terms extracted from titles. We conduct a stricter filtering strategy on the Standard Query and a looser one on the Refined Query. That is when we filter the Standard Query, we set the IDF's lower bound to be 0.7 and the upper bound to be 3.2, while when we filter the Refined Query, we set the best IDF lower bound to be 0.65 and the upper bound to be 3. POS tagging Another way to filter query keywords is using POS <ref type="bibr" coords="5,431.51,225.64,10.52,8.74" target="#b3">[4]</ref> tagging. We use Stanford Log-linear Part-Of-Speech Tagger<ref type="foot" coords="5,355.14,236.02,3.97,6.12" target="#foot_1">2</ref> to identify query keywords. Initially we thought only nouns and adjectives are representative words and need to be kept, but our experiment results shows that this strategy is too aggressive. In the end, we loosed it a bit that we kept verbs in the query keywords set too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>The runs that we submitted to this year's CLEF-IP Prior Art Retrieval Task used a combination of some or all of the approaches that we list in Section 3. These runs are:</p><p>1. Run ID: OnlyClaimLM -extract the task claims to be query keywords 2. Run ID: coOnlyTtlLM -use patent application's Consistent Title as query keywords 3. Run ID: HypCoTtlNoIdfUpperBoundLM -extract claims, hyphenating phrases and the Consistent Title to form query keyword set -filter the Original Query with IDF lower bound 0.7 and the Refined Query with IDF lower bound 0.65, no IDF upper bound is set -POS tagging query keywords and only leave nouns, adjectives and verbs 4. Run ID: HypCoTtlWithIdfUpperBoundLM -the same as &lt;HypCoTtlNoIdfUpperBoundLM&gt;, but also filter the Standard Query and the Refined Query using IDF upper bound 3.2 5. Run ID: HypDuTtlNoIdfUpperBoundBM -the same as &lt;HypCoTtlNoIdfUpperBoundLM&gt;, but different in 2 ways:</p><p>• add not only the Consistent Title but also the English title into the Refined Query • use Okapi Model instead of Language Model 6. Run ID: HypDuTtlWithIdfUpperBoundBM -the same as &lt;HypDuTtlNoIdfUpperBoundBM&gt;, but also filter the Original Query and the Refined Query using IDF upper bound 3.2</p><p>Each patent document has a kind code. The code can be A1, A2, A3, . . . or B1, B2, . . . The A* kind codes means that patent documents are published during the patent application phase, while the B* kind codes means that patent documents are published during the granting phase. In our runs, we filtered the retrieval list to make sure that only A1, A2 and A* type patent documents will show in the final result list.</p><p>The top run in the English sub task comes from our submission. Table <ref type="table" coords="6,475.61,196.04,4.98,8.74">4</ref> lists the official evaluation results from CLEF-IP 2013. The results show that our approaches of generating highly representative queries are effective. The results also show that the Okapi BM25 retrieval model outperforms the Language Modeling retrieval model in the Novelty Search Task. Our experiments show that in the Novelty Search Task, using long queries helps to find more relevant patent documents than using short queries, e.g. only using document titles. Hence although titles and hyphenating phrases are good resources, we also added claim texts as one resource to extract qualified query keywords. But very long queries always contain noise, in our best run, our strategy to balance this is to control the query keywords in less than 20 words. Specifically, after filtering qualified terms from titles, hyphenating phrases and claims texts by using IDF and POS tagging, if the query keywords coming from titles and hyphenating phrases are less than 20 words, we ranked query keywords from claims texts by IDF score and added the top ranked terms into the query keywords set until it contains 20 words.</p><p>All the approaches we talked above are about document level retrieval. At passage retrieval level, in all runs, we used the sum of query keywords' T F ×IDF score to rank passages, where TF is the query keyword's term frequency in a passage and IDF is its corpus inverse document frequency. Only the top 10 ranked passages will be returned. Our approaches have good passage MAP and Precision scores which proves that our approach is effective. In summary, our approach is highly effective in finding Patent Prior Arts written in English, as well as effective in finding Patent Prior Arts written in German or French.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>CLEF-IP 2013 Passage Retrieval starting from Claims task precisely captures the procedure of the Prior Art Search. Participants are given one or a few claims, and are asked to retrieve relevant patent documents in the collection and mark out the relevant passages.</p><p>In this paper we present an integrated process of Prior Art Search.We focus on formulating representative queries from various metadata that is embedded in a patent document. We then submit the queries to the Lemur search engine to perform document level retrieval. We mainly used two retrieval algorithms, Language Modeling and Okapi BM25. We tuned the parameters for CLEF-IP 2012 dataset. We believe that the parameter setting we list in Section 2 are also suitable for other Patent collections. Moreover, in the paper, we present six approaches to formulate queries from patent documents. The experimental results from CLEF-IP 2012 and 2013 both support that our approaches are effective to identify representative query keywords.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,311.98,179.77,168.61,8.74;5,134.77,191.72,345.82,8.74;5,134.77,203.68,139.78,8.74"><head>2 .</head><label>2</label><figDesc>These values are decided by a series of experiments based on CLEF-IP 2012 Passage Retrieval starting from Claims training tasks and testing tasks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,134.77,307.89,357.24,331.10"><head>Table 1 .</head><label>1</label><figDesc>used in CLEF-IP 2013 Passage Retrieval starting from Claims task is consisted by XML patent documents from European Patent Office (EPO) prior to year 2002 as well as over 400,000 documents published by the World Intellectual Property Organization (WIPO). The documents are multilingual, including English, German and French. No images are kept in the collection. Data Fields Indexed by Lemur</figDesc><table coords="2,136.16,417.30,355.85,221.69"><row><cell>Field</cell><cell>Description</cell></row><row><cell>abstract</cell><cell>the abstract section in a patent document</cell></row><row><cell>applicants</cell><cell>metadata about the applicants in a patent document, including the</cell></row><row><cell></cell><cell>name, address and country of each applicant</cell></row><row><cell>application-date</cell><cell>the application date</cell></row><row><cell cols="2">application-reference includes country code, application document number, patent kind</cell></row><row><cell></cell><cell>code and application-date</cell></row><row><cell>claim-num</cell><cell>claim number used as the identification number of a claim</cell></row><row><cell>claims</cell><cell>the claims section in a patent, including all claim texts, and claim</cell></row><row><cell></cell><cell>numbers</cell></row><row><cell>date</cell><cell>all date fields in a patent document</cell></row><row><cell>description</cell><cell>the description section in a patent document</cell></row><row><cell>inventors</cell><cell>metadata about the inventors in a patent document, including the</cell></row><row><cell></cell><cell>name, address, and country of each inventor</cell></row><row><cell>priority-claims</cell><cell>the priority claim section in a patent document</cell></row><row><cell>publication-date</cell><cell>the publication date</cell></row><row><cell cols="2">publication-reference includes country code, publication document number, patent kind</cell></row><row><cell></cell><cell>code, and publication-date</cell></row><row><cell>title</cell><cell>the English title</cell></row><row><cell>docno</cell><cell>the external document id</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,134.77,284.00,376.10,141.04"><head>Table 2 .</head><label>2</label><figDesc>Evaluation Result for our runs &amp; the statistical data for all 19 submitted runs in CLEF-IP 2013 Passage Retrieval starting from Claims -English Task</figDesc><table coords="6,136.16,315.75,374.71,109.28"><row><cell>Runs</cell><cell cols="5">PRES@100 Recall@100 MAP@100 MAP(D) Precision(D)</cell></row><row><cell>HypDuTtlWithIdfUpperBoundBM</cell><cell>0.433</cell><cell>0.540</cell><cell>0.191</cell><cell>0.132</cell><cell>0.213</cell></row><row><cell>HypDuTtlNoIdfUpperBoundBM</cell><cell>0.432</cell><cell>0.540</cell><cell>0.190</cell><cell>0.132</cell><cell>0.214</cell></row><row><cell>HypCoTtlWithIdfUpperBoundLM</cell><cell>0.403</cell><cell>0.497</cell><cell>0.167</cell><cell>0.132</cell><cell>0.210</cell></row><row><cell>HypCoTtlNoIdfUpperBoundLM</cell><cell>0.391</cell><cell>0.486</cell><cell>0.165</cell><cell>0.125</cell><cell>0.201</cell></row><row><cell>OnlyClaimLM</cell><cell>0.356</cell><cell>0.453</cell><cell>0.147</cell><cell>0.120</cell><cell>0.171</cell></row><row><cell>coOnlyTtlLM</cell><cell>0.132</cell><cell>0.198</cell><cell>0.064</cell><cell>0.038</cell><cell>0.092</cell></row><row><cell>best score</cell><cell>0.433</cell><cell>0.540</cell><cell>0.191</cell><cell>0.142</cell><cell>0.214</cell></row><row><cell>median</cell><cell>0.396</cell><cell>0.488</cell><cell>0.166</cell><cell>0.038</cell><cell>0.092</cell></row><row><cell>mean</cell><cell>0.357</cell><cell>0.444</cell><cell>0.146</cell><cell>0.064</cell><cell>0.081</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,144.73,657.79,122.69,7.86"><p>http://www.lemurproject.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="5,144.73,657.79,186.58,7.86"><p>http://nlp.stanford.edu/software/tagger.shtml</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,138.35,410.58,342.24,7.86;7,146.91,421.54,175.57,7.86" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="7,330.11,410.58,150.48,7.86;7,146.91,421.54,41.06,7.86">Search engines: Information retrieval in practice</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strohman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Addison-Wesley Reading</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,432.50,342.24,7.86;7,146.91,443.46,333.68,7.86;7,146.91,454.42,200.66,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,201.54,432.50,181.58,7.86">Viewing morphology as an inference process</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Krovetz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,406.73,432.50,73.86,7.86;7,146.91,443.46,333.68,7.86;7,146.91,454.42,82.63,7.86">Proceedings of the 16th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 16th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="191" to="202" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,465.38,342.25,7.86;7,146.91,476.34,330.22,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,453.71,465.38,26.88,7.86;7,146.91,476.34,254.23,7.86">Clef-ip 2012: Retrieval experiments in the intellectual property domain</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Piroi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lupu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>Sexton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Magdy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">V</forename><surname>Filippov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,421.35,476.34,52.08,7.86">CLEF-IP &apos;12</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,487.30,342.24,7.86;7,146.91,498.25,333.68,7.86;7,146.91,509.21,199.98,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,241.82,487.30,220.14,7.86">A maximum entropy model for part-of-speech tagging</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ratnaparkhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,146.91,498.25,329.80,7.86">Proceedings of the conference on empirical methods in natural language processing</title>
		<meeting>the conference on empirical methods in natural language processing<address><addrLine>Philadelphia, PA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="133" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,520.17,342.24,7.86;7,146.91,531.13,333.68,7.86;7,146.91,542.09,275.50,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,282.51,520.17,177.79,7.86">Automatically labeling hierarchical clusters</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Treeratpituk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Callan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,146.91,531.13,329.81,7.86">Proceedings of the 2006 international conference on Digital government research</title>
		<meeting>the 2006 international conference on Digital government research</meeting>
		<imprint>
			<publisher>Digital Government Society of North America</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="167" to="176" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
