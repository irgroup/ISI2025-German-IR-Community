<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,121.11,100.02,360.79,12.62">CEA LIST&apos;s participation at the CLEF CHiC 2013</title>
				<funder ref="#_fDSN9qE">
					<orgName type="full">Egonomy</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,266.94,138.58,69.13,8.74"><forename type="first">Adrian</forename><surname>Popescu</surname></persName>
							<email>adrian.popescu@cea.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Vision &amp; Content Engineering Laboratory</orgName>
								<orgName type="institution" key="instit1">CEA</orgName>
								<orgName type="institution" key="instit2">LIST</orgName>
								<address>
									<settlement>Gif sur Ivette</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,121.11,100.02,360.79,12.62">CEA LIST&apos;s participation at the CLEF CHiC 2013</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0BBC51C9315DEAA1C430B995E39E52A0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Multilingual Information Retrieval</term>
					<term>Semantic Enrichment</term>
					<term>Explicit Semantic Analysis</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For our first participation to the CLEF CHiC Lab, we submitted runs to the multilingual ad-hoc and multilingual semantic enrichment tasks. Given the strong multilingual character of the evaluation corpus, the main objectives of the experiments were to test the efficiency of semantic topic expansion and consolidation based on Explicit Semantic Analysis (ESA) versions in different languages. Another objective was multilingual fusion of results obtained in the different languages of the corpus. ESA was adapted for the 10 languages that are best represented in the Europeana corpus. Wikipedia dumps from March 2012 were used for French and English and from March 2013 for the other languages. One problem that arises when modeling short documents, such as queries, with classical ESA vectors no information is available whether the concept is related to the entire topic only to a part of it. To overcome this problem, two adaptations of ESA (ESA-C) are Wikipedia concepts that are linked to the highest number of concepts from the original topic. In the ad-hoc task, ESA and ESA-C have two roles: to expand the topic with related concepts and to create consolidated topic models which contain the original topic words along with other related keywords. We submitted both monolingual and multilingual runs without topic expansion and using topic expansion and consolidation with classical ESA and ESA-C. The best results are obtained in a multilingual setting with no expansion and ESA-C topic consolidation. For the semantic enrichment task, we propose lists of related Wikipedia concepts using either a monolingual ranking or a voting scheme that surfaces related concepts that appear in the largest number of languages. Here, the best results are obtained in a monolingual ranking configuration that exploits ESA-C.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The CHiC evaluation lab 1 aims to explore different aspects related to the retrieval of cultural heritage content stored in digital libraries such as Europeana 2 . There are two subtasks in the multilingual task, dealing with multilingual ad-hoc retrieval and multilingual semantic enrichment. For the ad-hoc task, participants were provided with metadata in 13 different languages and were free to use any automatic method in order to return ranked lists of results for a set of 50 diversified topics. For the semantic enrichment task, a subset of 25 topics from the initial pool was provided and the objective was to return a ranked list of 10 related concepts that could be used to enrich the initial topic and might help to precise the user's information need.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Explicit Semantic Analysis (ESA)</head><p>Explicit Semantic Analysis <ref type="bibr" coords="2,207.29,127.87,10.52,8.74" target="#b0">[1]</ref> is a method that maps textual documents onto a structured semantic space. Since its introduction in 2007, ESA was successfully exploited in different natural language processing and information retrieval tasks. The success of this simple method lies in the richness and the quality of the underlying conceptual space. In the original evaluation, ESA outperformed state of the art methods in a word relatedness estimation task and different developments were subsequently proposed.</p><p>Radinsky and al. <ref type="bibr" coords="2,183.46,199.78,10.52,8.74" target="#b3">[4]</ref> added a temporal temporal dimension to ESA vectors and showed that this addition improves the results for word relatedness.</p><p>Hassan and Mihalcea <ref type="bibr" coords="2,199.90,223.87,10.52,8.74" target="#b1">[2]</ref> introduced Salient Semantic Analysis, a variant of ESA that relies on the detection of salient concepts prior to linking words and concepts. The merits of their method are difficult to estimate since the comparison is often made with an in-house ESA implementation whose results are significantly poorer than those presented in <ref type="bibr" coords="2,360.29,259.74,9.96,8.74" target="#b0">[1]</ref>.</p><p>We proposed an ESA adaptation to information retrieval tasks that gives priority to categorical information <ref type="bibr" coords="2,144.61,283.83,9.96,8.74" target="#b2">[3]</ref>. The comparison with a classical ESA implementation showed that a significant improvement was obtained in an image retrieval setting. Moreover, the method compared favorably with other state of the art indexing and retrieval schemes. Here, we extend the work in <ref type="bibr" coords="2,482.55,307.74,10.52,8.74" target="#b2">[3]</ref> and propose to use ESA for query expansion and consolidation, two operations that are explained in more details in Subsection 4.</p><p>ESA has only weak language dependence and was already deployed in several languages. Sorg and Cimiano <ref type="bibr" coords="2,149.06,355.74,10.52,8.74" target="#b4">[5]</ref> proposed an extension of the method to different languages and showed that the method is useful in cross-lingual and multilingual retrieval settings. Here we create ESA vectors in the 10 most represented languages out of the 13 present in the Europeana collection. The following languages are supported: English, German, French, Spanish, Italian, Dutch, Swedish, Norwegian, Polish and Finnish. Adaptations to different languages include detection and removal of Wikipedia disambiguation and list pages and detection of category section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Classical Formulation of ESA</head><p>Put simply, ESA exploits classical text weighting schemes, such a tf-idf, to model concepts from a structured resource, such a Wikipedia. A relation between words and the concepts that structure the space is established by inverting the concepts' vectorial representations. Thus, each word of the vocabulary has an associated high-dimension projection onto the concept space of the underlying resource. Finally, in order to compare two words or two documents, the representations of individual words are summed and the resulting vectors compared. In information retrieval, the most useful component of ESA is the mapping of words onto concepts that can be used for topic expansion or consolidation (see Subsection 2.2.</p><p>Classical ESA representations are well adapted for single words, since there is nothing to be done, and for long documents, since the summing operation smooths individual contributions and an accurate semantic representation of the document is obtained. However, the method has some drawbacks for documents such as retrieval topics that contain only few words (typically 2 to 4 words). Here, the smoothing of individual contributions is not sufficient because the contribution of a single word can be higher than that of the others and the obtained related concepts could be related to a part of the topic only. An illustration of this type of problem is provided in table 1 which presents the top 10 ESA concepts associated to topics Freshwater Fish and Jean-Jaques Rousseau 3 . The results from table 1 indicate that most ESA top ranked concepts are not related to the entire query. When examining results for topic CHiC-051, Freshwater bivalve and Freshwater, Isle of Wight are related to freshwater while Bait fish and Bank fishing are related to fish. Similarly, when examining results for topic CHiC-058, we notice that several ESA top concepts are brought up by the family name textitRousseau and have little semantic relatedness with the original topic. Concepts found for topic CHiC-064 (crockery doll house) are related to doll but not the other terms from the query.</p><p>We use an in-house implementation of ESA that includes only the optimization cues publicly available until recently<ref type="foot" coords="3,192.17,143.17,3.97,6.12" target="#foot_1">4</ref> . To validate our implementation, we performed the word similarity task described in <ref type="bibr" coords="3,145.87,156.70,9.96,8.74" target="#b0">[1]</ref>, with the same version of Wikipedia, and the method achieved a 0.72 correlation with human judgments (to be compared with 0.75 reported by <ref type="bibr" coords="3,366.60,168.65,10.30,8.74" target="#b0">[1]</ref>). We already proposed a version of ESA that gives a privileged role to categorical information in <ref type="bibr" coords="4,90.00,135.70,9.96,8.74" target="#b2">[3]</ref>. There, we used two scores to rank Wikipedia concepts:</p><p>a boolean score that captures the number of common words between the initial topic and the words found in the categories associated to Wikipedia concepts. the score used in the classical ESA in order to rank concepts, based on the sum of the contributions of the individual words.</p><p>Since topics are often short, ties are often obtained with the boolean score and their are broke using the second, finer grained score.</p><p>The introduction of the boolean score has two main objectives. First, categorical information should be favored in order to obtain concepts that are hierarchically related (i.e. isA relation) to the initial topic or to parts of it. Second, it is possible to identify which parts of the initial query an ESA related concept is related to. For instance, the categories of Tropical Fish are Fish stubs and Aquaria and the topic would have a boolean score of 1 (out of a maximum of 2). Similarly, Freshwater bivalve, the top ranked concept with classical ESA, only loosely related to the initial topic, has a boolean score of 0 since its only category is Bivalves. The categorical ranking rightly gives a better position to Tropical Fish compared to Freshwater bivalve since the first concepts is more closely related to Freshwater fish.</p><p>Here we modified our ESA adaptation for IR in two directions. First, given that categorical information is often sparse, we added the words contained in the first 150 characters after the concepts name in the first paragraph of the category words. This enrichment of the categorical space is motivated by the fact that the first paragraph of Wikipedia article is often a definition that contains salient concepts related to the target one. The limitation to words contained in string of 150 character is useful since the first paragraph has varying length and contains information that is only loosely related to the concepts when it is long. The second modification is a concept detection that is used to produce a third score which favors articles that contain longer concepts from the initial query over other articles. At equal categorical scores, the inclusion of concept detection allows us to favor a Wikipedia concept that includes Jean-Jacques Rousseau in its text when compared to another concept that includes Jean-Jacques and Rousseau separately. The top related concepts obtained with ESA-C for Freshwater fish and Jean-Jacques Rousseau are presented in the third column of table 1. In both cases, the top 10 concepts are much more closely related to the initial topics compared to the use of classical ESA. The list for topic CHiC-051 contains only fish and the list for CHiC-058 includes different works of Jean-Jacques Rousseau. Crockery doll house is a specialized one, which is not well represented in Wikipedia and the retrieved concepts are still unrelated to the entire topic in a large majority of cases. This last topic illustrates one limitation of all ESA implementation, namely the poor mapping between the initial document and the knowledge included in the underlying conceptual space.</p><p>The use of the lists of related ESA concepts for both semantic enrichment and for ad-hoc retrieval is detailed in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Europeana Collection Processing</head><p>We kept documents of the Europeana Collection that belong to the 10 languages processed with ESA. Separate indexes were created for each of the modeled languages. Then selected metadata associated to the following fields: "dc:title", "dc:description", "dc:subject", "dc:type", "dcterms:medium", "dc:date". The retained fields were merged into a bag-of-words representation and then modeled using a tf-idf scheme. Due to the use of probabilistic models of the topics (see Subsection 4.2), the tf-idf representation of documents was subsequently transformed into a probabilistic form by dividing the weight of each word by the sum of the scores of all words in the document. Monolingual collections are stemmed using the corresponding Perl Snowball stemmer implementation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Enrichment and retrieval framework</head><p>The framework devised here was used for both semantic enrichment and ad-hoc retrieval and is summarized in figure <ref type="figure" coords="5,185.38,373.96,3.87,8.74" target="#fig_0">1</ref>. The semantic enrichment process exploits only topic expansion with the ESA versions (ESA and ESA-C) and returns ranked lists of results using different ranking schemes detailed in Subsection 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Semantic Topic Enrichment Framework</head><p>The purpose of the semantic enrichment process is to return a ranked list of concepts that are semantically related to the initial topic and could be use for query expansion. To test multilingual rankings, we introduced fusion methods that exploit the explicit interlingual links available in Wikipedia using either different fusion schemes based on the scores in individual languages. In all cases, the proposed enrichments are collection independent. Only Wikipedia concepts formed of at most 4 words were retained in the final rankings. Lists of related concepts obtained with the original version of ESA and with the adapted ESA-C version are presented in table 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Ad-hoc Retrieval Framework</head><p>Within CHiC, the objective of the ad-hoc retrieval process is to return the best results possible using whatever automatic method at hand. In our approach, the target topic is first processed using ESA resources to expand and consolidate it. The initial words and the expanded concepts are then compared to the index of the collection in order to retrieve a raw list of results. The elements of this list are then compared to the consolidated version of the topic in order to obtain the final list of results. Similarly to the ranking of ESA related concepts, two similarity measures are used:</p><p>a boolean score to measure a coarse similarity between the initial topic or its related concepts and the documents in the collection. the cosine similarity is used to measure the degree of similarity between a topic and corresponding documents.</p><p>The boolean score has a higher priority than the cosine similarity, which is used only to break ties. For multilingual runs, the process is performed for each of the languages processed and then results are combined by ranking results by decreasing scores. Topic expansion is performed in a way similar to description provided in Subsection 4.1. Consolidation is a by-product of the expansion process and aims to obtain an expanded version of the initial topic that contains, in addition to the original words, other words that are semantically related to the topic but are not part of it. The words are ranked by summing their individual scores associated to the top 100 ESA related concepts and then by multiplying this sum with the log of the number of different articles in which they appear. This last score is used in order to favor words that are associated to a large number of Wikipedia concepts related to the initial articles. Up to 1000 related words are retained for each topic and a probabilistic model of the consolidated versions is obtained by dividing individual word scores by the sum of all scores. In table 2, we present top 10 words related to each topic obtained with ESA and ESA-C. A majority of the obtained words are semantically related to the initial topic, although some outliers appear. For freshwater fish, all top 10 words are related to the initial topic and thus useful for ranking results. In the case of Jean-Jaques Rousseau, there are French stop words that were not removed. For Crockery doll house, nrhp (abbreviation of National Register of Historic Places) appears since this acronym is strongly related to house. Similarly to the collection processing, the consolidated versions of the topics are stemmed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments</head><p>As we mentioned, we have submitted runs for both the semantic enrichment and the ad-hoc retrieval subtasks and we analyse them here. Unfortunately, this analysis is altered by the fact that an important bug in the scoring of related was discovered after the release of official results. This bug had a strong negative impact on the quality of results for all runs that exploited fusion techniques for semantic enrichment and automatic topic expansion for ad-hoc retrieval. The bug biases individual boolean scores but the order of concepts is not affected and a comparison of ESA versions remains possible. Boolean scores of expanded concepts were overrated compared to the boolean scores of documents found using terms from the original topic. All affected runs are indicated by a "*" sign in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Semantic Enrichment</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Submitted runs</head><p>The following eight runs were submitted to the semantic enrichment subtask: Results Even though the results for 6 out of 8 runs are biased here, there are some interesting conclusions that we can draw from table <ref type="table" coords="8,287.70,352.33,3.87,8.74" target="#tab_3">3</ref>. The comparison between ceaListEnglishMonolin-gualOriginal and ceaListEnglishMonolingual is favorable to the latter method. The original ESA implementation has significantly poorer performances compared to the adapted method introduced (P@10 0.365 vs. 0.66). The privileged role given to categories and to the first words in the concept text, coupled with concept detection in the queries have a positive impact on semantic enrichments. None of the fusion methods proposed improves results compared to the best submitted run but this is at least in part due to the bug that affected the values of boolean concept scores. When comparing the fusion schemes, there are no significant differences between monolingual and multilingual fusions. Since the same concepts were proposed but languages differed, this results show that the ground truth is of high quality. The cosine-based fusion strongly degrades results, while the fusion based on ranks is closer to the original results. Important differences occur at the topic level. For ceaListEnglishMonolingual, when examining CHiC-51 (freshwater fish) and CHiC-58 (Jean-Jacques Rousseau), all top 10 related concepts are at least partly related to the initial topic. Inversely, results are very poor (9 out of 10 irrelevant enrichments) for topics CHiC-64 (crockery doll houses) and CHiC-65 (sea sunset). These failures are probably due to a poor mapping of the topic in the Wikipedia corpus for CHiC-64 and to the very small number of Wikipedia concepts that cover both sea and sunset.</p><formula xml:id="formula_0" coords="7,96.23,488.46,171.61,8.77">-ceaListEnglishMonolingual -Related</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Ad-hoc retrieval</head><p>Submitted runs For "noExpansion" runs, results are ranked first by the number of terms from the initial topic that appear in the document and then by the the cosine similarity between the consolidated version of the topic and document representations. For the other runs, the boolean score of related ESA concepts biases the results. As we mentioned, multilingual fusion was performed by The following 16 runs were submitted to the semantic enrichment subtask:</p><p>-ceaListMultilingualNoExpansion -Multilingual run that retrieves only documents which contain at least one word from the initial topic. -ceaListFrenchNoExpansion -Monolingual French run that retrieves documents which contain at least one word from the initial topic. -ceaListGermanNoExpansion -Monolingual German run that retrieves documents which contain at least one word from the initial topic. Results Due to the bug that affected all the runs that involved ESA based topic expansion, it is difficult to compare runs that did not involved expansion and the others. However, it is worthwhile noticing the the best submitted run, i.e. ceaListMultilingualNoExpansion a simple fusion of results obtained for individual languages, gave interesting results compared to monolingual runs that involved no ESA expansion. When comparing ceaListMultilingualOriginal and ceaListMultilingualFiltered, the two multilingual runs that exploit ESA and ESA-C, obtained results are better for the second run (MAP 0.0805 vs. O.0977). This result confirms the one obtained for semantic enrichment, where ESA-C was also superior to classical ESA. It is also in line with our findings from <ref type="bibr" coords="10,415.45,198.98,9.96,8.74" target="#b2">[3]</ref>, which showed that giving a privileged role to categorical information is beneficial in an image retrieval scenario. The favorable comparison of ESA-C with ESA is also confirmed for English (MAP 0.321 vs. 0.304) and Italian (MAP 0.165 vs. 0.0222). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>The results obtained at CLEF CHiC 2013 encourage us to pursue the investigation of enrichment and retrieval techniques for cultural heritage. The obtained results are especially encouraging for the semantic enrichment task. The ESA-C adaptation of Explicit Semantic Analysis clearly outperforms the original version of the method. The ad-hoc retrieval results were hampered by the overrated value of boolean scores and we plan to correct these experiments in order to have an accurate assessment of the influence of automatic topic expansion. Future work includes adding supplementary material to the conceptual space (i.e. Wikipedia corpus) in order to enrich concept descriptions and to try to cover a larger range of concepts. A second line of work involves a shift towards a more semantic representation of ESA concepts, that goes beyond the current bag-of-words modeling and involves concept detection and disambiguation. A third research axis will focus on ways to predict the chances of success of automatic expansion in order to perform this task only when the topic is suited.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,160.10,305.57,282.80,7.89;5,90.00,99.90,425.20,190.90"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Overview of the semantic enrichment and retrieval framework.</figDesc><graphic coords="5,90.00,99.90,425.20,190.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,90.00,212.35,423.00,449.78"><head>Table 1 .</head><label>1</label><figDesc>Top 10 ESA related concepts for topics Freshwater Fish, Jean-Jaques Rousseau and crockery doll house. The second column contains results for classical ESA, presented in subsection 2.1, while the third results for the adapted version of ESA (ESA-C) presented in subsection 2.2.</figDesc><table coords="3,105.93,255.94,391.14,406.20"><row><cell></cell><cell cols="2">Topic CHiC-051 Freshwater Fish</cell></row><row><cell>Rank</cell><cell>ESA</cell><cell>ESA-C</cell></row><row><cell>1</cell><cell>Freshwater bivalve</cell><cell>Eastern freshwater cod</cell></row><row><cell>2</cell><cell>Freshwater mollusc</cell><cell>Ide (fish)</cell></row><row><cell>3</cell><cell>Tropical fish</cell><cell>New Zealand longfin eel</cell></row><row><cell>4</cell><cell>Freshwater, Humboldt County, California</cell><cell>Common galaxias</cell></row><row><cell>5</cell><cell>Fish fillet processor</cell><cell>European perch</cell></row><row><cell>6</cell><cell>Bait fish</cell><cell>Green swordtail</cell></row><row><cell>7</cell><cell>Fish marketing</cell><cell>Rainbowfish</cell></row><row><cell>8</cell><cell>Bottom fishing</cell><cell>Common rudd</cell></row><row><cell>9</cell><cell>Freshwater, Isle of Wight</cell><cell>Spotted bass</cell></row><row><cell>10</cell><cell>Bank fishing</cell><cell>Common bream</cell></row><row><cell></cell><cell cols="2">Topic CHiC-058 Jean-Jaques Rousseau</cell></row><row><cell>Rank</cell><cell>ESA</cell><cell>ESA-C</cell></row><row><cell>1</cell><cell>Confessions (Rousseau)</cell><cell>Confessions (Rousseau)</cell></row><row><cell>2</cell><cell>Saint-Jean</cell><cell>Considerations on the Government of Poland</cell></row><row><cell cols="2">3 Considerations on the Government of Poland</cell><cell>Discourse on the Arts and Sciences</cell></row><row><cell>4</cell><cell>Eugne Rousseau (chess player)</cell><cell>Emile, or On Education</cell></row><row><cell>5</cell><cell>John Jacques, Baron Jacques</cell><cell>Essay on the Origin of Languages</cell></row><row><cell>6</cell><cell>Eugene Rousseau (saxophonist)</cell><cell>Discourse on Inequality</cell></row><row><cell>7</cell><cell>Jean-Jacques Henner</cell><cell>Letter to M. D'Alembert on Spectacles</cell></row><row><cell>8</cell><cell>Victor Rousseau</cell><cell>Pygmalion (Rousseau)</cell></row><row><cell>9</cell><cell>Bobby Rousseau</cell><cell>Julie, or the New Heloise</cell></row><row><cell>10</cell><cell>Discourse on the Arts and Sciences</cell><cell>Le devin du village</cell></row><row><cell></cell><cell cols="2">Topic CHiC-064 Crockery doll house</cell></row><row><cell>Rank</cell><cell>ESA</cell><cell>ESA-C</cell></row><row><cell>1</cell><cell>Peg wooden doll</cell><cell>Mabel Lucie Attwell</cell></row><row><cell>2</cell><cell>Composition doll</cell><cell>Bringing Up Father</cell></row><row><cell>3</cell><cell>Anatomically correct doll</cell><cell>The Tale of Mrs. Tiggy-Winkle</cell></row><row><cell>4</cell><cell>Bisque doll</cell><cell>China doll</cell></row><row><cell>5</cell><cell>Black doll</cell><cell>Japanese traditional dolls</cell></row><row><cell>6</cell><cell>Paper doll</cell><cell>Queen Mary's Dolls' House</cell></row><row><cell>7</cell><cell>Madame Alexander</cell><cell>Bild Lilli doll</cell></row><row><cell>8</cell><cell>Fashion doll</cell><cell>Vivien Greene</cell></row><row><cell>9</cell><cell>Doll</cell><cell>Paper Dolls (band)</cell></row><row><cell>10</cell><cell>China doll</cell><cell>Wall House (Elkins Park, Pennsylvania)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,90.00,191.50,423.00,458.50"><head>Table 2 .</head><label>2</label><figDesc>Top 10 words form the consolidated version of the topics for Freshwater Fish, Jean-Jaques Rousseau and crockery doll house. The second column contains results for classical ESA, presented in subsection 2.1 while the third column presents results for the adapted version of ESA (ESA-C) presented in subsection 2.2.</figDesc><table coords="6,211.65,243.81,178.85,406.20"><row><cell cols="3">Topic CHiC-051 Freshwater Fish</cell></row><row><cell>Rank</cell><cell>ESA</cell><cell>ESA-C</cell></row><row><cell>1</cell><cell>fish</cell><cell>fish</cell></row><row><cell cols="2">2 freshwater</cell><cell>freshwater</cell></row><row><cell cols="2">3 acquarium</cell><cell>galaxia</cell></row><row><cell>4</cell><cell>fillet</cell><cell>aquarium</cell></row><row><cell>5</cell><cell>fishery</cell><cell>species</cell></row><row><cell>6</cell><cell>bait</cell><cell>fin</cell></row><row><cell>7</cell><cell>water</cell><cell>water</cell></row><row><cell>8</cell><cell>species</cell><cell>river</cell></row><row><cell>9</cell><cell>lake</cell><cell>trout</cell></row><row><cell>10</cell><cell>fin</cell><cell>carp</cell></row><row><cell cols="3">Topic CHiC-058 Jean-Jaques Rousseau</cell></row><row><cell>Rank</cell><cell>ESA</cell><cell>ESA-C</cell></row><row><cell>1</cell><cell>jacques</cell><cell>rousseau</cell></row><row><cell>2</cell><cell>jean</cell><cell>jean</cell></row><row><cell>3</cell><cell>rousseau</cell><cell>de</cell></row><row><cell>4</cell><cell>de</cell><cell>jacques</cell></row><row><cell>5</cell><cell>french</cell><cell>french</cell></row><row><cell>6</cell><cell>le</cell><cell>le</cell></row><row><cell>7</cell><cell>saint</cell><cell>paris</cell></row><row><cell>8</cell><cell>paris</cell><cell>philosopher</cell></row><row><cell>9</cell><cell>la</cell><cell>pygmalion</cell></row><row><cell>10</cell><cell>baptiste</cell><cell>pierre</cell></row><row><cell cols="3">Topic CHiC-064 Crockery doll house</cell></row><row><cell>Rank</cell><cell>ESA</cell><cell>ESA-C</cell></row><row><cell>1</cell><cell>doll</cell><cell>doll</cell></row><row><cell>2</cell><cell>house</cell><cell>house</cell></row><row><cell>3</cell><cell>toy</cell><cell>toy</cell></row><row><cell>4</cell><cell>barbie</cell><cell>barbie</cell></row><row><cell>5</cell><cell>goo</cell><cell>mattel</cell></row><row><cell>6</cell><cell>album</cell><cell>album</cell></row><row><cell>7</cell><cell>mattel</cell><cell>goo</cell></row><row><cell>8</cell><cell>nrhp</cell><cell>film</cell></row><row><cell>9</cell><cell>licca</cell><cell>licca</cell></row><row><cell>10</cell><cell>song</cell><cell>song</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,96.23,488.49,416.78,256.93"><head></head><label></label><figDesc>concepts are obtained with ESA-C. The experiment is monolingual since it only exploits the English Wikipedia version. Proposed expansions are collection independent. -ceaListEnglishMonolingualOriginal -Related concepts are obtained with classical ESA. The experiment is monolingual since it only exploits the English Wikipedia version. Proposed expansions are collection independent. -ceaListEnglishRankEnglish -Rank fusion for monolingual results obtained with ceaListEnglish-Monolingual. The rank of the concept is obtain by averaging its ranks in different languages. For a Wikipedia concept to be considered, it has to appear in at least three languages. The experiment is multilingual since different Wikipedia versions (9 languages: en, fr, de, es, it, nl, no, sv, pl) are used. Only concepts that have an English version are considered. -ceaListEnglishRankMultilingual -Rank fusion for monolingual results obtained with ceaLis-tEnglishMonolingual. For a Wikipedia concept to be considered, it has to appear in at least three languages. The experiment is multilingual since different Wikipedia versions (9 languages: en, fr, de, es, it, nl, no, sv, pl) are used. Given different translations of a concept, the one that has the highest score in an individual language is presented. -ceaListEnglishBooleanMultilingual * -Fusion of boolean scores monolingual results obtained with ceaListEnglishMonolingual. For a Wikipedia concept to be considered, it has to appear in at least three languages. The experiment is multilingual since different Wikipedia versions (9 languages: en, fr, de, es, it, nl, no, sv, pl) are used. Given different translations of a concept, the one that has the highest score in an individual language is presented. Only concepts that have an English version are considered. -ceaListEnglishCosineEnglish * -Fusion of cosine similarity scores for monolingual results obtained with ceaListEnglishMonolingualOriginal. For a Wikipedia concept to be considered, it has to appear in at least three languages. The experiment is multilingual since different Wikipedia versions (9 languages: en, fr, de, es, it, nl, no, sv, pl) are used. Only English versions of Wikipedia concepts are presented. Only concepts that have an English version are considered. -ceaListEnglishCosineMultilingual * -Fusion of cosine similarity scores monolingual results obtained with ceaListEnglishMonolingualOriginal. For a Wikipedia concept to be considered, it has to appear in at least three languages. The experiment is multilingual since different Wikipedia versions (9 languages: en, fr, de, es, it, nl, no, sv, pl) are used. Given different translations of a concept, the one that has the highest score is presented. Only concepts that have an English version are considered.</figDesc><table /><note coords="7,96.23,676.87,416.77,8.77;7,106.94,688.86,406.06,8.74;7,106.94,700.81,406.06,8.74;7,106.94,712.77,406.07,8.74;7,106.94,724.72,406.07,8.74;7,106.94,736.68,171.13,8.74"><p>-ceaListEnglishBooleanEnglish * -Fusion of boolean scores for monolingual results obtained with ceaListEnglishMonolingual. For a Wikipedia concept to be considered, it has to appear in at least three languages. The experiment is multilingual since different Wikipedia versions (9 languages: en, fr, de, es, it, nl, no, sv, pl) are used. Only English versions of Wikipedia concepts are presented. Proposed expansions are collection independent. Only concepts that have an English version are considered.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,90.00,517.14,423.00,128.74"><head>Table 3 .</head><label>3</label><figDesc>Semantic enrichment accuracy measured using P@10 of relevant and of relevant + partly relevant results.</figDesc><table coords="8,168.97,547.15,265.07,98.72"><row><cell>Run name</cell><cell cols="2">P@10 P@10 (rel + part.rel)</cell></row><row><cell>ceaListEnglishMonolingual</cell><cell>0.468</cell><cell>0.66</cell></row><row><cell cols="2">ceaListEnglishMonolingualOriginal 0.212</cell><cell>0.364</cell></row><row><cell>ceaListEnglishRankEnglish</cell><cell>0.34</cell><cell>0.56</cell></row><row><cell cols="2">ceaListEnglishRankMultilingual 0.3382</cell><cell>0.5556</cell></row><row><cell>ceaListEnglishBooleanEnglish *</cell><cell>0.228</cell><cell>0.436</cell></row><row><cell cols="2">ceaListEnglishBooleanMultilingual * 0.22</cell><cell>0.428</cell></row><row><cell>ceaListEnglishCosineEnglish *</cell><cell>0.076</cell><cell>0.164</cell></row><row><cell cols="2">ceaListEnglishCosineMultilingual * 0.076</cell><cell>0.164</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,96.23,265.44,416.78,478.04"><head></head><label></label><figDesc>-ceaListMultilingualOriginal * -Multilingual run that retrieves documents which contain at least one word from the initial topic and/or the full name of one of query's 1000 most related Wikipedia concepts obtained with classical ESA. -ceaListMultilingualFiltered * -Multilingual run that retrieves documents which contain at least one word from the initial topic and/or the full name of one of query's 1000 most related Wikipedia concepts obtained with ESA-C. -ceaListDutchFiltered * -Monolingual Dutch run that retrieves documents which contain at least one word from the initial topic and/or the full name of one of query's 1000 most related Dutch Wikipedia concepts obtained with a version of Explicit Semantic Analysis adapted to short documents (topics). -ceaListEnglishFiltered * -Monolingual English run that retrieves documents which contain at least one word from the initial topic and/or the full name of one of query's 1000 most related English Wikipedia concepts obtained with ESA-C. -ceaListFrenchFiltered * -Monolingual French run that retrieves documents which contain at least one word from the initial topic and/or the full name of one of query's 1000 most related French Wikipedia concepts obtained with ESA-C. -ceaListGermanFiltered * -Monolingual German run that retrieves documents which contain at least one word from the initial topic and/or the full name of one of query's 1000 most related German Wikipedia concepts obtained with ESA-C. -ceaListItalianFiltered * -Monolingual Italian run that retrieves documents which contain at least one word from the initial topic and/or the full name of one of query's 1000 most related Italian Wikipedia concepts obtained with ESA-C. -ceaListNorwegianFiltered * -Monolingual Norwegian run that retrieves documents which contain at least one word from the initial topic and/or the full name of one of query's 1000 most related Norwegian Wikipedia concepts obtained with ESA-C. -ceaListPolishFiltered * -Monolingual Polish run that retrieves documents which contain at least one word from the initial topic and/or the full name of one of query's 1000 most related Polish Wikipedia concepts obtained with ESA-C. -ceaListSpanishFiltered * -Monolingual Spanish run that retrieves documents which contain at least one word from the initial topic and/or the full name of one of query's 1000 most related Spanish Wikipedia concepts obtained with ESA-C. -ceaListSwedishFiltered * -Monolingual Swedish run that retrieves documents which contain at least one word from the initial topic and/or the full name of one of query's 1000 most related Swedish Wikipedia concepts obtained with ESA-C. -ceaListEnglishOriginal * -Monolingual English run that retrieves documents which contain at least one word from the initial topic and/or the full name of one of query's 1000 most related English Wikipedia concepts obtained with ESA-C.</figDesc><table /><note coords="9,96.23,710.80,416.77,8.77;9,106.94,722.79,406.06,8.74;9,106.94,734.74,277.90,8.74"><p>-ceaListItalianOriginal * -Monolingual Italian run that retrieves documents which contain at least one word from the initial topic and/or the full name of one of query's 1000 most related Italian Wikipedia concepts obtained with classical ESA.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="10,190.72,267.48,221.57,210.38"><head>Table 4 .</head><label>4</label><figDesc>MAP performances for ad-hoc retrieval runs.</figDesc><table coords="10,219.79,288.28,163.43,189.58"><row><cell>Run name</cell><cell>MAP</cell></row><row><cell cols="2">ceaListMultilingualNoExpansion 0.1878</cell></row><row><cell>ceaListFrenchNoExpansion</cell><cell>0.0478</cell></row><row><cell>ceaListFrenchFiltered *</cell><cell>0.0290</cell></row><row><cell cols="2">ceaListGermanNoExpansion 0.0631</cell></row><row><cell>ceaListGermanFiltered *</cell><cell>0.0505</cell></row><row><cell cols="2">ceaListMultilingualOriginal * 0.0805</cell></row><row><cell cols="2">ceaListMultilingualFiltered * 0.0977</cell></row><row><cell>ceaListDutchFiltered *</cell><cell>0.0377</cell></row><row><cell>ceaListEnglishOriginal *</cell><cell>0.0304</cell></row><row><cell>ceaListEnglishFiltered *</cell><cell>0.0321</cell></row><row><cell>ceaListItalianOriginal *</cell><cell>0.0165</cell></row><row><cell>ceaListItalianFiltered *</cell><cell>0.0222</cell></row><row><cell>ceaListNorwegianFiltered *</cell><cell>0.0251</cell></row><row><cell>ceaListPolishFiltered *</cell><cell>0.0109</cell></row><row><cell>ceaListSpanishFiltered *</cell><cell>0.0204</cell></row><row><cell>ceaListSwedishFiltered *</cell><cell>0.0123</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="2,99.96,726.40,413.04,7.86;2,99.96,737.36,35.12,7.86"><p>The wrong spelling of Rousseau's name was extracted from Europeana logs and provided as such for the task.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="3,99.96,726.40,413.04,7.86;3,99.96,737.36,252.31,7.86"><p>A full list was recently made public at https://github.com/faraday/wikiprep-esa/wiki/roadmap but the remaining cues were not yet integrated in our implementation.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was supported via <rs type="funder">Egonomy</rs>, a <rs type="programName">French "Grand Emprunt"</rs> project.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_fDSN9qE">
					<orgName type="program" subtype="full">French &quot;Grand Emprunt&quot;</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="11,93.58,126.65,419.42,7.86;11,102.15,137.61,410.85,7.86;11,102.15,148.57,285.69,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,288.21,126.65,224.79,7.86;11,102.15,137.61,102.84,7.86">Computing semantic relatedness using wikipedia-based explicit semantic analysis</title>
		<author>
			<persName coords=""><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shaul</forename><surname>Markovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,227.93,137.61,285.07,7.86;11,102.15,148.57,77.81,7.86">Proceedings of the 20th international joint conference on Artifical intelligence, IJCAI&apos;07</title>
		<meeting>the 20th international joint conference on Artifical intelligence, IJCAI&apos;07<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1606" to="1611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,93.58,170.48,419.42,7.86;11,102.15,181.44,20.99,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,251.86,170.48,212.21,7.86">Semantic relatedness using salient semantic analysis</title>
		<author>
			<persName coords=""><forename type="first">Samer</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rada</forename><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,486.37,170.48,21.30,7.86">AAAI</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,93.58,192.40,419.42,7.86;11,102.15,203.36,239.59,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,277.53,192.40,139.87,7.86">Social media driven image retrieval</title>
		<author>
			<persName coords=""><forename type="first">Adrian</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gregory</forename><surname>Grefenstette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,435.90,192.40,77.10,7.86;11,102.15,203.36,143.54,7.86">ACM International Conference on Multimedia Retrieval</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,93.58,214.32,419.42,7.86;11,102.15,225.28,410.85,7.86;11,102.15,236.24,377.40,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,436.58,214.32,76.43,7.86;11,102.15,225.28,245.69,7.86">A word at a time: computing word relatedness using temporal semantic analysis</title>
		<author>
			<persName coords=""><forename type="first">Kira</forename><surname>Radinsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eugene</forename><surname>Agichtein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shaul</forename><surname>Markovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,366.46,225.28,146.54,7.86;11,102.15,236.24,169.73,7.86">Proceedings of the 20th international conference on World wide web, WWW &apos;11</title>
		<meeting>the 20th international conference on World wide web, WWW &apos;11<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="337" to="346" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,93.58,247.20,419.42,7.86;11,102.15,258.15,194.01,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,204.25,247.20,305.19,7.86">Exploiting wikipedia for cross-lingual and multilingual information retrieval</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Sorg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cimiano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,102.15,258.15,125.31,7.86">Data &amp; Knowledge Engineering</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="26" to="45" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
