<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,171.00,116.95,273.36,12.62;1,144.72,134.89,325.91,12.62;1,192.63,152.82,230.10,12.62">Multimedia Information Modeling and Retrieval(MRIM)/Laboratoire d&apos;Informatique de Grenoble (LIG) at CHiC2013</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,147.58,190.49,61.96,8.74"><forename type="first">Kian</forename><surname>Lam Tan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">UJF-Grenoble</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">UPMF</orgName>
								<address>
									<settlement>-Grenoble 2</settlement>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory" key="lab1">LIG laboratory</orgName>
								<orgName type="laboratory" key="lab2">MRIM group</orgName>
								<orgName type="institution">CNRS</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,222.72,190.49,85.44,8.74"><forename type="first">Mohannad</forename><surname>Almasri</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">UJF-Grenoble</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">UPMF</orgName>
								<address>
									<settlement>-Grenoble 2</settlement>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory" key="lab1">LIG laboratory</orgName>
								<orgName type="laboratory" key="lab2">MRIM group</orgName>
								<orgName type="institution">CNRS</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,321.74,190.49,92.97,8.74"><forename type="first">Jean-Pierre</forename><surname>Chevallet</surname></persName>
						</author>
						<author>
							<persName coords="1,431.38,190.49,36.40,8.74;1,229.80,202.44,32.05,8.74"><forename type="first">Philippe</forename><surname>Mulhem</surname></persName>
							<email>philippe.mulhem@imag.fr</email>
						</author>
						<author>
							<persName coords="1,305.91,202.44,74.83,8.74"><forename type="first">Catherine</forename><surname>Berrut</surname></persName>
							<email>catherine.berrut@imag.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">UJF-Grenoble</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">UPMF</orgName>
								<address>
									<settlement>-Grenoble 2</settlement>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="laboratory" key="lab1">LIG laboratory</orgName>
								<orgName type="laboratory" key="lab2">MRIM group</orgName>
								<orgName type="institution">CNRS</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,211.22,234.96,75.29,7.86"><roleName>Mohannad</roleName><forename type="first">Lam</forename><surname>Tan</surname></persName>
						</author>
						<author>
							<persName coords="1,291.21,234.96,89.40,7.86"><forename type="first">Jean-Pierre</forename><surname>Almasri</surname></persName>
						</author>
						<author>
							<persName coords="1,385.32,234.96,42.35,7.86"><surname>Chevallet</surname></persName>
						</author>
						<title level="a" type="main" coord="1,171.00,116.95,273.36,12.62;1,144.72,134.89,325.91,12.62;1,192.63,152.82,230.10,12.62">Multimedia Information Modeling and Retrieval(MRIM)/Laboratoire d&apos;Informatique de Grenoble (LIG) at CHiC2013</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5FA974FCE0F053498F686565AB4B1800</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Information Retrieval</term>
					<term>Language Model</term>
					<term>Query Enrichment</term>
					<term>Query Expansion</term>
					<term>Semantic Resource</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Numerous cultural heritage materials are accessible through online digital library portals. However, this conversion resulted in the issues of inconsistency and incompleteness. The Cultural Heritage in CLEF 2013 (CHiC) takes the initiative to organize an evaluation campaign which involve several tasks such as 1) multilingual task, 2) polish task and 3) interactive task. We present the results of the MRIM/LIG team for the Ad-Hoc task and for the Semantic Enrichment task. For the Ad-Hoc task, we incorporate Term Links based on Wikipedia into the Language Model. Our approach has the following advantages: 1) it is easy and simple to generate the Term Similarity Matrix based on statistical information 2) a light weight integration in the Language Model. For the semantic query enrichment task, we deal with short queries found in this collection. These short queries can not describe a specific information need. Hence, the goal of this task is to find best ten terms for a query to semantically enrich the topic and guess the user's information need or original query intent. We use the Wikipedia as a semantic resource in order to find these related terms.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Cultural heritage is an expression of the ways of living developed by a community and passed on from generation to generation, including customs, practices, places, objects, artistic expressions and values. Basically, cultural heritage can be distinguished in two types such as artifacts and built environment. Artifacts consist of books, objects, documents and pictures such as Mona Lisa portrait that display at Musee du Louvre, Paris and The Last Supper painting that display at Santa Maria delle Grazie, Milan by Leonardo da Vinci.</p><p>Basically, Europeana provides the flexibility for all the people around the world to access the information of cultural heritage such as text, image, audio and video. Therefore, Cultural Heritage in CLEF (CHiC) takes the initiative to organize the evaluation lab since 2012 to address the key problem from Europeana.</p><p>We participated in the English monolingual ad-hoc retrieval task and English monolingual semantic enrichment task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Ad-hoc Retrieval Task</head><p>This is a standard ad-hoc retrieval task, which measure the effectiveness of the Information Retrieval System (IRS). The ad-hoc task is the standard setting for IRS which returns a relevance-ranked list of documents based on the query and the collection of the documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Approach</head><p>The main idea of this approach is to integrate the term links into the current Dirichlet formula. Firstly, we assume that a term w is w ∈ d which can play the role of w where w is w ∈ q during the matching process. More specifically, we consider that if w does not occur in the initial document d, but it occurs in the document d ext , which is the result of the extension of d according to the query and some knowledge 1 . Then, the probability of the term will define according to the extended document d ext .</p><p>The knowledge assumes to form a symmetrical similarity function which is Sim : V × V → [0, 1], that denotes the strength of the similarity between two terms from the vocabulary (the larger the value, the higher the strength). We propose that: ∀w ∈ V, Sim(w, w ) = 1 if exact matching between w with w , and ∀w ∈ V, Sim(w, w ) = 0 if w does not contain any link with w .</p><p>To achieve this, we use some simple and sensible heuristics:</p><p>1. If a query term w occurs in a document d, then the term will not change the length of the document. 2. If a query term w does not occur in a document d but the term w contains a link with w (term from document), then we define w = argmax w ∈d,w =w Sim(w, w ) as the term from the document will serve as the basis count of the pseudo occurrences of w in d as c(w ; d).Sim(w , w). This pseudo occurrences of the term w are then included into the size of the extended document. 3. If a query term w does not occur in the document and does not contains any link, then it's occurrences is counted in the extended document.</p><p>Eventually, using usual set of notations for the terms that occur in the document and the query, then the new length of the document (|d ext |) is:</p><formula xml:id="formula_0" coords="2,149.71,614.96,296.24,24.36">|d ext | = w∈d∩q c(w; d) + w ∈d\q;Sim(w,w ) =0 c(w ; d).Sim(w , w) + w ∈d\q;Sim(w,w )=0 c(w ; d)</formula><p>with w" defined above for one query term w so that:</p><formula xml:id="formula_1" coords="3,232.18,143.90,248.42,9.65">w = argmax w ∈d,w =w Sim(w, w )<label>(1)</label></formula><p>Using the fact above, the expression of |d ext | can be easily simplified into:</p><formula xml:id="formula_2" coords="3,192.95,185.52,287.64,20.53">|d ext | = |d| + w ∈d\q;Sim(w,w ) =0 c(w ; d).Sim(w , w)<label>(2)</label></formula><p>With all the elements described above, the extended Dirichlet Smoothing leads to the following probability for the term w of the vocabulary V in the document extended d ext according to a query q, noted that p µ (w|d ext ) is defined as:</p><formula xml:id="formula_3" coords="3,138.97,274.01,341.62,33.65">1. if w ∈ d ∩ q : P µ (w|d ext ) = c(w; d) + µP (w |C) |d ext | + µ<label>(3)</label></formula><p>2. if ∃w ∈ d \ q; Sim(w, w ) = 0 :</p><formula xml:id="formula_4" coords="3,212.82,335.63,267.77,23.22">P µ (w|d ext ) = c(w"; d).Sim(w, w") + µP (w"|C) |d ext | + µ<label>(4)</label></formula><p>with w = argmax w ∈d,w =w Sim(w, w ) .</p><formula xml:id="formula_5" coords="3,138.97,393.88,341.62,44.00">3. if \ ∃w ∈ d \ q; Sim(w, w ) = 0 P µ (w|d ext ) = c(w; d) + µP (w|C) |d ext | + µ<label>(5)</label></formula><p>with w = argmax w ∈d,w =w Sim(w, w ) .</p><p>In the specific case when all the query terms from q occur in the document d, the first case in the above is used where |d ext | = |d| leads to p µ (w|d) = p µ (w|d ext ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Term Links</head><p>Basically, we make the assumption that two terms are considered link to each other if both terms co-occur in the same context. So, the term links contains the link between the term w and w . In this experiment, we only used Cosine Similarity (CS) to generate the term links. The DC between term w and w are calculated as follows:</p><p>The CS between term w and w is represented using a dot product and magnitude as follows: </p><formula xml:id="formula_6" coords="3,234.99,638.81,245.60,22.31">Sim cosine (w, w ) = n(w ∩ w ) n(w).n(w ) (6)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Experiment, Result and Discussion</head><p>All the experiments are done by using the XIOTA engine <ref type="bibr" coords="4,389.54,227.23,9.96,8.74" target="#b2">[3]</ref>. The performance is measured by Mean Average Precision (MAP). The optimal value for Dirichlet prior smoothing for baseline is 100 and 350 for all the Extended Dirichlet. Besides, we only use the title without any description form the queries and index the title, subject, and description from the documents (CHiC collection).</p><p>As for pre-processing, we remove all the stop words which contains 571 words and non-character, and apply the Porter Stemming method. On the other hand, we convert all the upper case to lower case. In addition, we use the English Wikipedia (version 2012-01-01) which contains 3.835 million articles to generate the two types of Term Links (we called it as "TermLinks1" and "TermLinks2") based on Cosine Similarity (6). We do not apply Porter Stemming method on "TermLinks1" while we apply Porter Stemming method on "TermLinks2". The approaches used for the experiments in the following section are:</p><p>-LMED-Cos-TL1: LM with Extended Dirichlet, CS, and TermLinks1 -LMED-Cos-TL2: LM with Extended Dirichlet, CS, and TermLinks2</p><p>We only submitted two results (since we participated in the English monolingual ad-hoc task) based on our propose approach. Table <ref type="table" coords="4,400.92,434.17,4.98,8.74" target="#tab_0">1</ref> shows the MAP for the the ad-hoc experiments. Basically, we achieved the highest MAP if we compare to others in the English monolingual ad-hoc retrieval task. Besides, both of our results (LMED-Cos-TL1 and LMED-Cos-TL2) outperforms the rest of the participants in the English multilingual ad-hoc retrieval task except the team from Chemnitx University of Technology, Germany.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Semantic Query Enrichment</head><p>In this part, we address short queries in ChiC collection which have no sufficient information to express its semantic. For example, assume the query "last supper". A retrieval model will retrieve documents which contain these two words or one of them without any attention to the meaning of this query in the Christian religion. Whereas, if we know this information, some related terms to this meaning like "Jesus", "crucifixion", "twelve apostles", and "Judas" could be found. Then, we can enrich the original query using these related terms. Therefore, the ability of an IRS to retrieve the relevant document to this query can be enhanced. Semantic query enrichment is to find and add these terms which are semantically related to a query. These added terms provide a semantic context for a query. This context is used by IRS to enhance its relevance estimation in its retrieval task.</p><p>Pseudo-Relevance Feedback is one of the most popular methods for finding these enrichment terms using the top k retrieved document to the original query. Whereas, if top retrieved documents for a given query contains a few number of relevant document. In this case, selected terms using Pseudo-Relevance Feedback will not be strongly related to the original query and will introduce noise into the enriched query. As a result, the relevance estimation for the enriched query would be less or equal than the original query <ref type="bibr" coords="5,338.37,215.63,10.52,8.74" target="#b3">[4,</ref><ref type="bibr" coords="5,350.54,215.63,7.75,8.74" target="#b1">2,</ref><ref type="bibr" coords="5,359.95,215.63,7.01,8.74" target="#b0">1]</ref>.</p><p>We present another method in order to select related terms for a given query using an external knowledge. Many resources are available in order to achieve this task: ontologies, encyclopedias, lexical resources. We use, in our task, Wikipedia as an external knowledge in order to achieve semantic query enrichment. Given a query q, in our case, this query talks about one well known thing: person, place, event, etc.. Wikipedia is a freely available large knowledge which contains a huge number of articles and links between them. First, we present the structure of Wikipedia. Then, we present our semantic query enrichment approach which is based on this structure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Wikipedia Structure</head><p>Wikipedia is a knowledge base which can be represented as a directed weighted graph of articles. The basic entry in Wikipedia is an entity page, which is an article that contains information focusing on one single entity. Furthermore, each article is linked to other articles by a number of weighted links. This weights represent how much the two entities are semantically related. An article point to a collection of articles and is pointed by a collection of other articles Figure <ref type="figure" coords="5,134.77,437.98,3.87,8.74" target="#fig_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Enrichment Steps</head><p>As we mentioned before, our semantic query enrichment use Wikipedia as a knowledge base. We see from the previous section, Wikipedia is organized as directed weighted graph of articles. Each article is identified by its title, links in, and links out. Using Wikipedia, each text can be mapped into a collection of articles. Relaying on what mentioned about Wikipedia, we present our semantic query enrichment steps:</p><p>• Given a query, first, finding all articles which correspond this query in Wikipedia, we call them: identified articles. • Using the identified articles we have different variants to enrich the original query q: o Links in: candidate articles to enrich the original query, in this first case, all articles which point out to at least one article of the identified articles. o Links out: candidate articles to enrich the original query, in this second case, all articles which are pointed out by at least one article of the identified articles. o Mixed: candidate articles to enrich the original query, in this last case, contain the union between articles form first and second case. • Sort candidate articles depending on its relatedness to the identified concepts. • Take best k articles titles from candidate articles and add them to the original query. • For weighting these articles, we multiplied the relatedness values using different values between [0, 1] like the following (0, 0.1, 0.2, 0.3, ,1). The value which provided the best precision enhancement was 0.3.</p><p>Using these steps, we obtain best k related titles to a given query with their wights. These titles are added to this query to obtain a long query. We claim that this long query has sufficient information to express the information need. Therefore, it is proposed to help IRS to enhance its relevance estimation or in other words its precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Experiment and Result</head><p>Experiments are done using WikipediaMiner<ref type="foot" coords="6,335.31,565.90,3.97,6.12" target="#foot_0">2</ref> which is an API for searching and accessing Wikipedia content. We mean by content articles and their links. WikipediaMiner is a toolkit for tapping the rich semantics encoded within Wikipedia. It helps to integrate Wikipedia's knowledge into applications, by:1) providing simplified, object-oriented access to Wikipedia's structure and content.2) Measuring how terms and concepts in Wikipedia are semantically related to each other.</p><p>We validate our approach over CHIC2013 English collection. For the query enrichment task we have 25 queries. These queries contain well known entities like persons, events, etc. The task requires systems to present a ranked list of at most 10 related terms for a query to semantically enrich the topic and/or guess the user's information need or original query intent. Related terms in our case are extracted using WikipediaMiner.</p><p>The evaluation metric for the semantic enrichment task is precision (precision@1, @3, @10) Table <ref type="table" coords="7,252.84,204.45,3.87,8.74">2</ref>. Precision at a given index k measure if the first k enrichment terms to a given query are related to this query or not. In this table, we have two runs, in first run we use in enrichment a mix between links in and links out. We select the 5 top articles titles form link in and the 5 top articles titles from link out. In the second run, we use best 10 articles titles from links out (best means most semantically related depending on Wikipedia relatedness values between Wikipedia articles). Basically, our second result (MRIM SE13 EN WM 1) outperforms the other participants for monolingual English enrichment by means P @1 and P @3. Whereas, it is slightly less of them by means of P @10.</p><p>Table <ref type="table" coords="7,202.93,345.59,4.13,7.89">2</ref>. Semantic enrichment task results(precision@1, @3, @10) Run Name P @1 P @3 P @10 MRIM SE13 EN WM 0.2800 0.1333 0.1448 MRIM SE13 EN WM 1 0.2800 0.1467 0.1598</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>For the ad-hoc retrieval task, our results indicated that both results (LMED-Cos-TL1 and LMED-Cos-TL2) achieved almost the same MAP. Based on this scenario, we can conclude that there is not much different to apply Porter Stemming method on the Term Links since the gap between these two results is very small. Whereas, in the semantic enrichment task, our results show that using links out is better of using the mix between links in and out.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,162.38,635.05,290.60,7.89;5,169.35,465.76,276.67,154.52"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Example of Wikipedia article and its relation with other articles</figDesc><graphic coords="5,169.35,465.76,276.67,154.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,219.74,116.91,175.87,61.85"><head>Table 1 .</head><label>1</label><figDesc>MAP for the ad-hoc experiments.</figDesc><table coords="4,248.88,140.01,117.60,38.75"><row><cell cols="2">Types of Approaches MAP</cell></row><row><cell>LMED-Cos-TL1</cell><cell>0.06340</cell></row><row><cell>LMED-Cos-TL2</cell><cell>0.06430</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="6,144.73,657.79,215.36,7.86"><p>http://wikipedia-miner.cms.waikato.ac.nz/index.html</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,138.35,602.23,342.24,7.86;7,146.91,613.19,333.68,7.86;7,146.91,624.14,333.68,7.86;7,146.91,635.10,120.30,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,217.74,613.19,262.86,7.86;7,146.91,624.14,219.55,7.86">The sheffield and basque country universities entry to chic: Using random walks and similarity to access cultural heritage</title>
		<author>
			<persName coords=""><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><forename type="middle">D</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Samuel</forename><surname>Fernando</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Arantxa</forename><surname>Otegi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Stevenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,385.13,624.14,95.46,7.86;7,146.91,635.10,91.65,7.86">CLEF (Online Working Notes/Labs/Workshop)</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,646.84,342.24,7.86;7,146.91,657.79,191.70,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,355.38,646.84,75.54,7.86">Unine at clef 2012</title>
		<author>
			<persName coords=""><forename type="first">Mitra</forename><surname>Akasereh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nada</forename><surname>Naji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,455.98,646.84,24.61,7.86;7,146.91,657.79,163.06,7.86">CLEF (Online Working Notes/Labs/Workshop)</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,120.67,342.25,7.86;8,146.91,131.63,333.68,7.86;8,146.91,142.59,333.68,7.86;8,146.91,153.55,197.13,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,241.52,120.67,221.27,7.86">X-iota: An open xml framework for ir experimentation</title>
		<author>
			<persName coords=""><forename type="first">Jean-Pierre</forename><surname>Chevallet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,476.59,131.63,4.01,7.86;8,146.91,142.59,122.74,7.86">formation Retrieval Technology</title>
		<title level="s" coord="8,338.26,142.59,138.30,7.86">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Sunghyon</forename><surname>Myaeng</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ming</forename><surname>Zhou</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kam-Fai</forename><surname>Wong</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Hong-Jiang</forename><surname>Zhang</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3411</biblScope>
			<biblScope unit="page" from="263" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,164.51,342.24,7.86;8,146.91,175.46,333.68,7.86;8,146.91,186.42,298.41,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,276.45,164.51,204.14,7.86;8,146.91,175.46,30.35,7.86">Query expansion using local and global document analysis</title>
		<author>
			<persName coords=""><forename type="first">Jinxi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,205.28,175.46,275.31,7.86;8,146.91,186.42,221.30,7.86">Proceedings of the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="4" to="11" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
