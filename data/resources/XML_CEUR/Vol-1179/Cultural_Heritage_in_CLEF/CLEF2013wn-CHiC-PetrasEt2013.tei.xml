<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,132.02,152.67,331.02,12.64;1,250.01,170.67,90.61,12.64;1,340.63,169.07,4.50,8.10">Cultural Heritage in CLEF (CHiC) 2013 -Multilingual Task Overview 1</title>
				<funder ref="#_CK3EzM8">
					<orgName type="full">European Commission</orgName>
				</funder>
				<funder ref="#_rqvt2gW">
					<orgName type="full">PROMISE (</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,174.98,210.18,54.09,8.96"><forename type="first">Vivien</forename><surname>Petras</surname></persName>
							<email>vivien.petras@ibi.hu-berlin.de</email>
							<affiliation key="aff0">
								<orgName type="department">Berlin School of Library and Information Science</orgName>
								<orgName type="institution">Humboldt-Universitätzu Berlin</orgName>
								<address>
									<addrLine>Dorotheenstr. 26</addrLine>
									<postCode>10117</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,237.41,210.18,54.22,8.96"><forename type="first">Toine</forename><surname>Bogers</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Royal School of Library and Information Science</orgName>
								<orgName type="institution">Copenhagen University</orgName>
								<address>
									<addrLine>Birketinget 6</addrLine>
									<postCode>2300</postCode>
									<settlement>Copenhagen S</settlement>
									<country key="DK">Denmark</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,299.81,210.18,50.78,8.96"><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
							<email>ferro@dei.unipd.it</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Information Engineering</orgName>
								<orgName type="institution">University of Padova</orgName>
								<address>
									<addrLine>Via Gradenigo 6/B</addrLine>
									<postCode>35131Padova</postCode>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,358.97,210.18,57.85,8.96"><forename type="first">Ivano</forename><surname>Masiero</surname></persName>
							<email>masieroi@dei.unipd.it</email>
							<affiliation key="aff2">
								<orgName type="department">Department of Information Engineering</orgName>
								<orgName type="institution">University of Padova</orgName>
								<address>
									<addrLine>Via Gradenigo 6/B</addrLine>
									<postCode>35131Padova</postCode>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,132.02,152.67,331.02,12.64;1,250.01,170.67,90.61,12.64;1,340.63,169.07,4.50,8.10">Cultural Heritage in CLEF (CHiC) 2013 -Multilingual Task Overview 1</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7EF8116E8ED7C0FD25827890BBAF9BB1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>cultural heritage</term>
					<term>Europeana</term>
					<term>ad-hoc retrieval</term>
					<term>semantic enrichment</term>
					<term>multilingual retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The Cultural Heritage in CLEF 2013 multilingual task comprised two sub-tasks: multilingual ad-hoc retrieval and semantic enrichment. The multilingual ad-hoc retrieval sub-task evaluated retrieval experiments in 13 languages (Dutch, English, German, Greek, Finnish, French, Hungarian, Italian; Norwegian, Polish, Slovenian, Spanish, Swedish). More than 140,000 documents were assessed for relevance on a tertiary scale. The ad-hoc task had 7 participants submitting 30 multilingual and 41 monolingual runs. The semantic enrichment task evaluated monolingual and multilingual semantic enrichments (suggestions based on a query) in the same 13 languages. Two participants submitted 10 runs. Results indicated that different languages contribute differently to the overall retrieval effectiveness, probably dependent on collection size. Experiments showed that using more or all of the provided languages usually increases retrieval effectiveness, but not always. For a multilingual task of this scale (13 languages), more participants are necessary in order to provide enough variations in runs to allow for comparative analyses.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Cultural heritage collectionspreserved by archives, libraries, museums and other institutions -consist of "sites and monuments relating to natural history, ethnography, archaeology, historic monuments, as well as collections of fine and applied arts" <ref type="bibr" coords="1,456.58,625.82,10.60,8.96" target="#b2">[3]</ref>. Cultural heritage content is often multilingual and multimedia (e.g. text, photographs, images, audio recordings, and videos), usually described with metadata in multiple formats and of different levels of complexity. Cultural heritage institutions have dif-ferent approaches to managing information and serve diverse user communities, often with specialized needs. The targeted audience of the CHiC lab and its tasks are developers of cultural heritage information systems, information retrieval researchers specializing in domain-specific (cultural heritage) and / or structured information retrieval on sparse text (metadata) and semantic web researchers specializing on semantic enrichment with LOD data. Evaluation approaches (particularly system-oriented evaluation) in this domain have been fragmentary and often non-standardized. CHiC aims at moving towards a systematic and large-scale evaluation of cultural heritage digital libraries and information access systems. After a pilot lab in 2012, where a standard ad-hoc information retrieval scenario was tested together with two use-case-based scenarios (diversity task and semantic enrichment task), the 2013 lab diversifies and becomes more realistic in its tasks organization. The pilot lab has shown that cultural heritage is a truly multilingual area, where information systems contain objects in many different languages. Cultural heritage information systems also differ from some more specified information systems in that ad-hoc searching might not be the prevalent form of access to this type of content. The 2013 CHiC lab therefore focuses on multilinguality in the retrieval tasks and adds an interactive task, where different usage scenarios for cultural heritage information systems were tested. The multilingual tasks described in this paper required multilingual retrieval in up to 13 languages, making CHiC the most multilingual CLEF lab ever.</p><p>CHiC has teamed up with Europeana<ref type="foot" coords="2,292.85,396.66,3.24,5.83" target="#foot_2">2</ref> , Europe's largest digital library, museum and archive for cultural heritage objects to provide a realistic environment for experiments. Europeana provided the document collection (digital representations of cultural heritage objects) and queries from their query logs. The interactive task also provided a topic clustering algorithm and a customized browsable portal based on Europeana data.</p><p>The paper is structured as follows: Chapter 2 introduces the Europeana document collection. Chapters 3 and 4 describe the sub-tasks multilingual ad-hoc and multilingual semantic enrichment in detail, their requirements, participants and results. The conclusion provides an outlook on the future of CHiC and the potential synergies of combining ad-hoc and interactive information retrieval evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>The Europeana Collection However, the overlap to the current content is about 80%.</p><p>The collection consists of metadata records describing cultural heritage objects, e.g. the scanned version of a manuscript, an image of a painting of sculpture or an audio or video recording. Roughly, 62% of the metadata records describe images, 35% describe text, 2% describe audio and 1% video recordings.</p><p>The collection was divided into 14 sub-collections according to the language of the content provider of the record (which usually indicates the language of the metadata record). A threshold was set: all languages with less than 100,000 documents were grouped together under the name "Others". The 13 language collections included Dutch, English, German, Greek, Finnish, French, Hungarian, Italian; Norwegian, Polish, Slovenian, Spanish, Swedish. For the CHiC 2013 experiments, all subcollections except the "Others" were used, totaling roughly 20 million documents. The 14 sub-collections are listed in table <ref type="table" coords="3,289.24,282.21,3.76,8.96" target="#tab_1">1</ref>. The XML metadata contains title and description data, media type and chronological data as well as provider information. For ca. 30% of the records, content-related enrichment keywords were added automatically by Europeana based on a mapping between metadata terms and terms from controlled lists like DBpedia names. In the Europeana portal, object records commonly also contain thumbnails of the object if it is an image and links to related records. These were not included with the test collection, but relevance assessors were able to look at them at the original source. Figure <ref type="figure" coords="3,465.51,607.82,4.98,8.96">1</ref> shows </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3</head><p>The CHiC Multilingual Ad-hoc Task</p><p>The sub-tasks are a continuation of the 2012 CHiC lab, using a similar task scenarios, but requiring multilingual retrieval and results. Two sub-tasks were defined: multilingual ad-hoc retrieval and multilingual semantic enrichment.</p><p>The traditional multilingual ad-hoc retrieval task measures information retrieval effectiveness with respect to user input in the form of queries. The 13 language subcollections form the multilingual collection (ca. 20 million documents) against which experiments were run. Participants were asked to submit ad-hoc information retrieval runs based on 50 topics (provided in all 13 languages) and including at least 2 and at most all 13 collection languages. For pooling purposes, participants were also asked to submit monolingual runs choosing any of the collection languages. Because the topics were provided in all collection languages, the focus of the task was not on topic translation, but on multilingual retrieval across different collection languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Topic Creation</head><p>A new set of 50 topics was created for the 2013 edition of CHiC, where topic selection was determined partially by the potential for retrieving a sufficient number of relevant documents in each of the collection languages. CHiC 2012 used topics from the Europeana query logs alone, which resulted in zero results for some of the 3 languages <ref type="bibr" coords="4,155.66,685.34,15.43,8.96">[13]</ref>. The problem of having zero relevant results is aggravated when collec-tion languages are varied, especially in the cultural heritage area. Many topics are relevant for only a few languages or cultures. For 2013, more focus was put on testing all topics in all languages for retrieving relevant documents, which resulted in fewer zero relevant result topics. The topic creation process started with creating a pool of candidate topics, which derived from four different sources:  15 topics that showed promising retrieval performance were re-used from the 2012 topic set (only in 3 languages) to test their performance in 13 languages.  Another 19 topics that were not specific to only a handful of languages were taken from an annotated snapshot of the Europeana query log (the same procedure was used for the 2012 topics).  The Polish task also suggested topics, 17 were not considered to be relevant only in Polish and input in the candidate pool.  Finally, two of the track organizers generated another 21 test queries covering a wide range of topics contained in Europeana's collections that would span all collection languages. These 73 candidate topics were then translated into all 13 languages by volunteers. The translated candidate topics were run against the 13 language collections using Indri 5.2 with default settings 3 . We retained the 50 topics that returned the highest number of relevant documents for all thirteen languages. Another factor that affected the final selection of the 2013 topics was the abundance of named-entity queries (around 60%) in the 2012 topic set. While named-entity queries are a common type of query for Europeana <ref type="bibr" coords="5,213.85,403.19,10.80,8.96" target="#b8">[9]</ref>, they are less challenging than non-entity queries that describe a more complex information need. For this we wished to down-sample the proportion of named-entity queries to around 20%.</p><p>The final topics set covers a wide range of topics and consisted of 12 topics from the 2012 topic set, 13 log-based topics, 13 topics from the Polish subtask, and 12 intellectually derived queries. In form and type, the different query types are indistinguishable and usually include 1-3 query terms (e.g. "silent film", "ship wrecks", and "last supper"). The underlying information need for a query can be ambiguous if the intention of the query is not clear. In this case, the track organizers discussed the query and agreed on the most likely information need. These were not admissible for information retrieval. Figure <ref type="figure" coords="5,241.25,523.19,4.98,8.96">2</ref> shows an example of an English query. &lt;topic lang="en"&gt; &lt;identifier&gt;CHIC-004&lt;/identifier&gt; &lt;title&gt;silent film&lt;/title&gt; &lt;description&gt;documents on the history of silent film, silent film videos, biographies of actors and directors, characteristics of silent film and decline of this genre&lt;/description&gt; &lt;/topic&gt; Fig. <ref type="figure" coords="5,263.09,628.03,3.41,8.10">2</ref>. CHiC Sample Query 3 Jelinek-Mercer smoothing with λ set to 0.4 and no stemming or stopword filtering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Pooling and Relevance Assessments</head><p>This year, we produced 13 pools, one for each target language using different depths depending on the language and the available number of documents. The pools were created using all the submitted runs. A 14th pool, for the multilingual task, is the union of the 13 pools described above. Table <ref type="table" coords="6,300.29,206.22,4.98,8.96" target="#tab_4">2</ref> provides details about the created pools, their size, the number of relevant and not relevant documents, and the pooled runs. We used graded relevance, i.e. highly relevant, partially relevant, and not relevant. To compute the standard performance measures reported in Section 3.3, we used binary relevance and conflated highly relevant and partially relevant to just relevant. The DIRECT system <ref type="bibr" coords="8,197.61,500.27,11.69,8.96" target="#b0">[1]</ref> was used to collect runs, perform relevance assessment, and compute performances. The system's interfaces and processes were also described in last year's CHiC Paper <ref type="bibr" coords="8,219.17,524.17,11.58,9.05" target="#b4">[5]</ref> For all languages except English, native language speakers performed the relevance assessments. Fifteen assessors took 2 weeks to assess the ca. 140,000 documents. The assessors received detailed instructions on how to use the assessor interface and guidelines, how the relevance assessments were to be approached. Constant communication via a common mailing list ensured that assessors across languages treated topics from the same perspective.</p><p>Despite our efforts in topic creation, some topics in some languages did not have any relevant documents in the pool. Besides not all queries having relevant documents in the Europeana collection, the problem was exacerbated by receiving very few monolingual runs that could be used for pooling, sometimes resulting in very small pools. While 11 languages have at least 40 topics with relevant documents (5 with 48 or more topics with relevant documents), Finnish (only 16 topics with relevant docu-ments) and Slovenian (only 37 topics with relevant documents) give raise for concern in comparative analyses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Participants and Runs</head><p>Seven different teams participated in the 2013 edition of the ad-hoc track (table <ref type="table" coords="9,444.88,212.22,3.65,8.96" target="#tab_7">3</ref>). Out of the 71 runs submitted, 30 were multilingual runs using at least 2 collection languages; 10 runs used all available languages for both topics and collections. All languages were also represented in the monolingual or bilingual runs (41 total). English, German, French and Italian were the popular languages for the monolingual runs, all other languages had only 1 or 2 runs. Toine Bogers (RSLIS) provided 2 more baseline runs for each language collection using the Indri information retrieval system using language modelling with either the Dirichlet (no stopword list, no stemming) or the Jelinek-Mercer smoothing algorithm (with stopword list, no stemming), which are used in the comparison. Table <ref type="table" coords="9,250.10,455.75,4.98,8.96" target="#tab_8">4</ref> shows the submitted runs and their language combinations including the baseline runs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Results &amp; Participant Approaches</head><p>Because of the many variations in topic and collection language configurations, comparisons between runs is difficult. Since language combinations are then varied by different system configurations, the matrix of possible impact factors becomes very big. However, several comparisons can give indications into further research questions that should be analyzed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Multilingual Runs: All Languages vs. Fewer languages</head><p>Table <ref type="table" coords="10,152.06,453.23,4.98,8.96" target="#tab_10">5</ref> shows the best multilingual run per participating group ordered by MAP showing the topic and collection languages that were used for retrieval. Note that only the best run is selected for each group, even if the group may have more than one top run. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.93%</head><p>Figure <ref type="figure" coords="10,153.38,660.26,4.98,8.96">3</ref> shows the best 5 multilingual runs in an interpolated recall vs. average precision graph.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 3. Best 5 Multilingual Runs -Interpolated Recall / Precision</head><p>It is difficult to interpret these figures in terms of which languages have the most input for retrieval success as the applied IR systems play a much bigger role in this cross-system comparison. UC Berkeley compared experiments with different topic languages against a multilingual collection of English, French and German combined. Results show that using the exact same languages for topics achieves a slightly higher result than using just one of the topic languages or even more languages (table <ref type="table" coords="11,362.08,473.99,3.62,8.96" target="#tab_11">6</ref>). In this experiment, differences between runs are probably not all statistically significant. However it is interesting to note that English and French seem not to contribute to the retrieval effectiveness as much as German, for example, and that a topic language, which is not represented in the collection languages (ES) can still achieve almost as high a MAP as the topic language English.  For pooling purposes, participants submitted monolingual runs as well. We can compare them using the whole multilingual pool (results are also available in the DIRECT<ref type="foot" coords="13,160.82,185.07,3.24,5.83" target="#foot_3">4</ref> system) or using the monolingual pools. While a multilingual pool is what the real use case prescribes (all languages are potentially relevant), we can also look at monolingual pools to achieve an improved system comparison (less variation because of language). We will concentrate on the 4 languages with the most submitted experiments: English <ref type="bibr" coords="13,214.37,234.18,15.50,8.96" target="#b9">(10)</ref>, Italian (8), German and French <ref type="bibr" coords="13,370.79,234.18,10.66,8.96" target="#b5">(6)</ref>. Table <ref type="table" coords="13,415.75,234.18,10.02,8.96" target="#tab_12">10</ref> shows the best monolingual run for each participant in those languages.  <ref type="table" coords="13,150.02,551.75,10.02,8.96" target="#tab_1">11</ref> briefly summarizes the participants' approaches to the ad-hoc track.</p><p>Table <ref type="table" coords="13,170.18,575.59,7.19,8.10" target="#tab_1">11</ref>.Participating groups and their approaches to the multilingual ad-hoc track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Group Description of approach</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Chemnitz</head><p>Apache Solr with special focus on comparing different types of stemmers (generic, rule-based, dictionary-based) <ref type="bibr" coords="13,391.75,617.78,15.34,8.96" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CEA LIST</head><p>Query expansion of a Vector Space model with tf-idf weighting by using related concepts extracted from Wikipedia using Explicit Semantic Analysis <ref type="bibr" coords="13,261.05,654.26,10.69,8.96" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MRIM</head><p>Language modeling approach using Dirichlet smoothing and Wikipedia as external document collection to estimate the word probabilities in case of sparsity of the original term-document matrix <ref type="bibr" coords="14,449.50,174.66,15.43,8.96" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Neuchâtel</head><p>Probabilistic IR using Okapi model with stopword filtering and light stemming. Collection fusion on the results lists from 13 different monolingual indexes using z-score normalization merging <ref type="bibr" coords="14,429.43,211.26,10.69,8.96" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RSLIS</head><p>Language modeling with Jelinek-Mercer smoothing and no stopword filtering or stemming. One run each for English, French, and German where these topic languages are run against a multilingual index. Two fusion runs using the CombSUM and CombMNZ methods combining these three monolingual runs against the multilingual index <ref type="bibr" coords="14,218.57,283.77,10.69,8.96" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>UC Berkeley</head><p>Probabilistic text retrieval model based on logistic regression together with pseudo-relevance feedback for all of the runs. Runs with English, French, and German topic sets and sub-collections, as well translations generated by Google Translate <ref type="bibr" coords="14,367.99,332.25,10.69,8.96" target="#b3">[4]</ref>.</p><p>Westminster Divergence from randomness algorithm using Terrier on the English and Italian collections <ref type="bibr" coords="14,284.69,356.73,15.43,8.96" target="#b10">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The CHiC Multilingual Semantic Enrichment Task</head><p>The multilingual semantic enrichment task requires systems to present a ranked list of related concepts for query expansion. Related concepts can be extracted from Europeana data or from other resources in the Linked Open Data cloud or other external resources (e.g. Wikipedia). Participants were asked to submit up to 10 query expansion terms or phrases per topic. This task included 25 topics in all 13 languages. Participants could choose to experiment on monolingual or multilingual semantic enrichments. The suggested concepts were assessed with respect to their relatedness to the original query terms or query category. Only 2 groups participated in the semantic enrichment task, making a comparison more difficult. Almost all experiments contained either only English concepts or concepts from several languages (multilingual). In total, 10 experiments were submitted.</p><p>MRIM/LIG (Univ. of Grenoble) used Wikipedia as a knowledge base and the query terms in order to identify related Wikipedia articles for enrichment candidates. Both in-links and out-links to and from these related articles (in particular their titles) were then used to extract terms for enrichment <ref type="bibr" coords="14,313.49,582.26,15.45,8.96" target="#b9">[10]</ref>.</p><p>CEA List used Explicit Semantic Analysis (documents are mapped to a semantic structure) also with Wikipedia as a knowledge base. Whereas MRIM/LIG used the title of Wikipedia articles and their in-and out-links for concept expansion, CEA List concentrated on the categories and the first 150 characters within a Wikipedia article. When Wikipedia category terms overlapped with query terms, these concepts were boosted for expansion. In ad-hoc retrieval, the topic and expanded concepts were matched against the collection and the results were then matched again to a consolidated version of the topics (favoring more frequent concept phrases) before outputting the result. For multilingual query expansion, the interlingua links to parallel language versions of a Wikipedia article were used in a fusion model. For most expansion experiments, only concepts were considered that appear in at least 3 Wikipedia language versions, allowing for multilingual expansions <ref type="bibr" coords="15,313.01,186.18,10.70,8.96" target="#b6">[7]</ref>.</p><p>The semantic enrichments were evaluated using a tertiary relevance assessment (definitely relevant, maybe relevant, not relevant) and P@1, P@3 and P@10 measurements. Table <ref type="table" coords="15,193.85,222.18,10.02,8.96" target="#tab_13">12</ref> shows the results for the best 2 runs for each participants using either the strict relevance measurement (just definitely relevant) or the relaxed relevance measurement (definitely relevant and maybe relevant). Only CEA List experimented with multilingual enrichments. Interestingly, a multilingual enrichment run was the best with a relaxed relevance measurement, while the monolingual run was the best with a strict relevance measurement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Outlook</head><p>The results of this year's multilingual CHiC task show that multilingual information retrieval experiments are challenging not only because of the number of languages that need to be processed but also because of the number of participants necessary in order to produce comparable results. As the number of possible language variations increases (CHiC had 13 source languages and 13 target languages), very few experiments across participants can be compared. While this year's results have shown that searching in several languages increases the overall performance (an obvious result), we could not show which languages contributed more to retrieval results. Future research in the multilingual task needs to focus on narrower defined tasks (e.g. particular source languages against the whole collection) or define a GRID experiment where a particular information retrieval system performs all possible run variation to arrive at better answers.</p><p>The interactive study collected a rich data set of questionnaire and log data for further use. Because the task was designed for easy entrance (predetermined system and research protocol, this is somewhat different that the traditional lab and is planned to follow a 2-year cycle (assuming the lab's continuation). In year two, the data gathered this year should be released to the community in aggregate form having been assessed by the user interaction community with the goal of identifying a set of objects that need to be developed. The ad-hoc retrieval tasks can benefit from the interactive task by re-using the real queries in ad-hoc retrieval test scenarioseffectively merging both evaluation methods.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,124.70,574.82,345.88,68.96"><head></head><label></label><figDesc>The Europeana information retrieval document collection was prepared for the CHiC pilot lab in 2012<ref type="bibr" coords="2,194.69,586.82,77.48,8.96" target="#b4">(Petras et al., 2012)</ref>. It consists of the complete Europeana metadata index as downloaded from the production system in March 2012. It contains 23,300,932 documents with a size of 132 GB. With the move of Europeana to an open data license in the summer of 2012 and the subsequent changes in content, this test document collection represents a snapshot of Europeana data from a particular time.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,130.10,306.02,329.46,201.89"><head>Table 1 .</head><label>1</label><figDesc>CHiC Collections by Language and Media Type.</figDesc><table coords="3,130.10,323.97,329.46,183.94"><row><cell>Language</cell><cell>Sound</cell><cell>Text</cell><cell>Image</cell><cell>Video</cell><cell>Total</cell></row><row><cell>German</cell><cell>23,370</cell><cell>664,816</cell><cell>3,169,122</cell><cell>8,372</cell><cell>3,865,680</cell></row><row><cell>French</cell><cell>13,051</cell><cell>1,080,176</cell><cell>2,439,767</cell><cell>102,394</cell><cell>3,635,388</cell></row><row><cell>Swedish</cell><cell>1</cell><cell>1,029,834</cell><cell>1,329,593</cell><cell>622</cell><cell>2,360,050</cell></row><row><cell>Italian</cell><cell>21,056</cell><cell>85,644</cell><cell>1,991,227</cell><cell>22,132</cell><cell>2,120,059</cell></row><row><cell>Spanish</cell><cell>1,036</cell><cell>1,741,837</cell><cell>208,061</cell><cell>2,190</cell><cell>1,953,124</cell></row><row><cell>Norwegian</cell><cell>14,576</cell><cell>207,442</cell><cell>1,335,247</cell><cell>555</cell><cell>1,557,820</cell></row><row><cell>Dutch</cell><cell>324</cell><cell>60,705</cell><cell>1,187,256</cell><cell>2,742</cell><cell>1,251,027</cell></row><row><cell>English</cell><cell>5,169</cell><cell>45,821</cell><cell>1,049,622</cell><cell>6,564</cell><cell>1,107,176</cell></row><row><cell>Polish</cell><cell>230</cell><cell>975,818</cell><cell>117,075</cell><cell>582</cell><cell>1,093,705</cell></row><row><cell>Finnish</cell><cell>473</cell><cell>653,427</cell><cell>145,703</cell><cell>699</cell><cell>800,302</cell></row><row><cell>Slovenian</cell><cell>112</cell><cell>195,871</cell><cell>50,248</cell><cell>721</cell><cell>246,952</cell></row><row><cell>Greek</cell><cell>0</cell><cell>127,369</cell><cell>67,546</cell><cell>2,456</cell><cell>197,371</cell></row><row><cell>Hungarian</cell><cell>34</cell><cell>14,134</cell><cell>107,603</cell><cell>0</cell><cell>121,771</cell></row><row><cell>Others</cell><cell>375,730</cell><cell>1,488,687</cell><cell>1,106,220</cell><cell>19,870</cell><cell>2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,130.10,498.95,329.45,21.56"><head>,990,507 Total 455,162 8,371,581 14,304,289 169,899 23,300,932</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="3,152.05,619.82,255.84,8.96"><head></head><label></label><figDesc>an extract example record from the Europeana CHiC collection.</figDesc><table coords="4,124.70,152.51,339.58,254.61"><row><cell>&lt;ims:metadata ims:identifier="http://www.europeana.eu/resolve/record/10105/5E1618BFAF</cell></row><row><cell>072B8953B30701A6A6C3BB655ACF9D" ims:namespace="http://www.europeana.eu/"</cell></row><row><cell>ims:language="eng"&gt;</cell></row><row><cell>&lt;ims:fields&gt;</cell></row><row><cell>&lt;dc:identifier&gt;Orn.0240&lt;/dc:identifier&gt;</cell></row><row><cell>&lt;dc:subject&gt;Tachymarptis melba&lt;/dc:subject&gt;</cell></row><row><cell>&lt;dc:title&gt;RundunZaqquBajda (Orn.0240)&lt;/dc:title&gt;</cell></row><row><cell>&lt;dc:title&gt;Alpine Swift (Orn.0240)&lt;/dc:title&gt;</cell></row><row><cell>&lt;dc:type&gt;mounted specimen&lt;/dc:type&gt;</cell></row><row><cell>&lt;europeana:country&gt;malta&lt;/europeana:country&gt;</cell></row><row><cell>&lt;europeana:dataProvider&gt;Heritage Malta&lt;/europeana:dataProvider&gt;</cell></row><row><cell>&lt;europeana:isShownAt&gt;http://www.heritagemalta.org/sterna/orn.php?id=0240</cell></row><row><cell>&lt;/europeana:isShownAt&gt;</cell></row><row><cell>&lt;europeana:language&gt;en&lt;/europeana:language&gt;</cell></row><row><cell>&lt;europeana:provider&gt;STERNA&lt;/europeana:provider&gt;</cell></row><row><cell>&lt;europeana:type&gt;IMAGE&lt;/europeana:type&gt;</cell></row><row><cell>&lt;europeana:uri&gt;http://www.europeana.eu/resolve/record/10105/5E1618BFAF072B8953B307</cell></row><row><cell>01A6A6C3BB655ACF9D&lt;/europeana:uri&gt;</cell></row><row><cell>&lt;/ims:fields&gt;</cell></row><row><cell>&lt;/ims:metadata&gt;</cell></row><row><cell>Fig.1. Europeana CHiC Collection Sample Record</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,141.74,242.06,323.30,320.36"><head>Table 2 .</head><label>2</label><figDesc>CHiC 2013 Multilingual Pools</figDesc><table coords="6,141.74,259.22,323.30,303.20"><row><cell></cell><cell>CHiC 2013 Multilingual -Dutch Pool</cell><cell></cell></row><row><cell>Depth</cell><cell></cell><cell>125</cell></row><row><cell cols="2">Total documents</cell><cell>10,548</cell></row><row><cell></cell><cell>Highly Relevant documents</cell><cell>1,583</cell></row><row><cell>Size</cell><cell>Partially Relevant documents</cell><cell>811</cell></row><row><cell></cell><cell>Not relevant documents</cell><cell>8,154</cell></row><row><cell cols="2">Topics with relevant documents / Total Topics</cell><cell>out of 50</cell></row><row><cell cols="2">Assessors</cell><cell>2</cell></row><row><cell cols="2">CHiC 2013 Multilingual -English Pool</cell><cell></cell></row><row><cell>Depth</cell><cell></cell><cell>50</cell></row><row><cell cols="2">Total documents</cell><cell>16,696</cell></row><row><cell></cell><cell>Highly Relevant documents</cell><cell>2,530</cell></row><row><cell>Size</cell><cell>Partially Relevant documents</cell><cell>70</cell></row><row><cell></cell><cell>Not relevant documents</cell><cell>14,096</cell></row><row><cell cols="2">Topics with relevant documents / Total Topics</cell><cell>out of 50</cell></row><row><cell cols="2">Assessors</cell><cell>2</cell></row><row><cell cols="2">CHiC 2013 Multilingual -Finnish Pool</cell><cell></cell></row><row><cell>Depth</cell><cell></cell><cell>200</cell></row><row><cell cols="2">Total documents</cell><cell>2,465</cell></row><row><cell></cell><cell>Highly Relevant documents</cell><cell>276</cell></row><row><cell>Size</cell><cell>Partially Relevant documents</cell><cell>19</cell></row><row><cell></cell><cell>Not relevant documents</cell><cell>2,170</cell></row><row><cell cols="2">Topics with relevant documents / Total Topics</cell><cell>out of 50</cell></row><row><cell cols="2">Assessors</cell><cell>1</cell></row><row><cell cols="2">CHiC</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,141.74,554.32,323.30,131.25"><head>2013 Multilingual -French Pool Size</head><label></label><figDesc></figDesc><table coords="6,141.74,566.59,323.30,118.98"><row><cell></cell><cell>Highly Relevant documents</cell><cell>3,510</cell></row><row><cell></cell><cell>Partially Relevant documents</cell><cell>50</cell></row><row><cell></cell><cell>Not relevant documents</cell><cell>14,900</cell></row><row><cell></cell><cell>Topics with relevant documents / Total Topics</cell><cell>out of 50</cell></row><row><cell></cell><cell>Assessors</cell><cell>2</cell></row><row><cell></cell><cell>CHiC 2013 Multilingual -Greek Pool</cell><cell></cell></row><row><cell></cell><cell>Depth</cell><cell>125</cell></row><row><cell></cell><cell>Total documents</cell><cell>10,032</cell></row><row><cell></cell><cell>Highly Relevant documents</cell><cell>265</cell></row><row><cell>Size</cell><cell>Partially Relevant documents</cell><cell>145</cell></row><row><cell></cell><cell>Not relevant documents</cell><cell>9622</cell></row><row><cell></cell><cell>Topics with relevant documents / Total Topics</cell><cell>out of 50</cell></row><row><cell></cell><cell>Assessors</cell><cell>1</cell></row><row><cell></cell><cell>CHiC 2013 Multilingual -Hungarian Pool</cell><cell></cell></row><row><cell></cell><cell>Depth</cell><cell>200</cell></row><row><cell></cell><cell>Total documents</cell><cell>5,834</cell></row><row><cell></cell><cell>Highly Relevant documents</cell><cell>332</cell></row><row><cell>Size</cell><cell>Partially Relevant documents</cell><cell>491</cell></row><row><cell></cell><cell>Not relevant documents</cell><cell>5,011</cell></row><row><cell></cell><cell>Topics with relevant documents / Total Topics</cell><cell>out of 50</cell></row><row><cell></cell><cell>Assessors</cell><cell>1</cell></row><row><cell></cell><cell>CHiC 2013 Multilingual -Italian Pool</cell><cell></cell></row><row><cell></cell><cell>Depth</cell><cell>75</cell></row><row><cell></cell><cell>Total documents</cell><cell>13,387</cell></row><row><cell></cell><cell>Highly Relevant documents</cell><cell>2,176</cell></row><row><cell>Size</cell><cell>Partially Relevant documents</cell><cell>721</cell></row><row><cell></cell><cell>Not relevant documents</cell><cell>10,490</cell></row><row><cell></cell><cell>Topics with relevant documents / Total Topics</cell><cell>out of 50</cell></row><row><cell></cell><cell>Assessors</cell><cell>1</cell></row><row><cell></cell><cell>CHiC</cell><cell></cell></row><row><cell></cell><cell>Depth</cell><cell>50</cell></row><row><cell></cell><cell>Total documents</cell><cell>17,978</cell></row><row><cell></cell><cell>Highly Relevant documents</cell><cell>2,508</cell></row><row><cell></cell><cell>Partially Relevant documents</cell><cell>436</cell></row><row><cell></cell><cell>Not relevant documents</cell><cell>15,034</cell></row><row><cell></cell><cell>Topics with relevant documents / Total Topics</cell><cell>out of 50</cell></row><row><cell></cell><cell>Assessors</cell><cell>1</cell></row><row><cell></cell><cell>CHiC 2013 Multilingual -German Pool</cell><cell></cell></row><row><cell>Size</cell><cell>Depth Total documents</cell><cell>50 18,460</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="7,141.74,507.76,323.30,181.29"><head>2013 Multilingual -Norwegian Pool Size</head><label></label><figDesc></figDesc><table coords="7,141.74,520.00,323.30,169.05"><row><cell cols="2">Assessors</cell><cell>1</cell></row><row><cell cols="2">CHiC 2013 Multilingual -Slovenian Pool</cell><cell></cell></row><row><cell>Depth</cell><cell></cell><cell>200</cell></row><row><cell cols="2">Total documents</cell><cell>6,718</cell></row><row><cell></cell><cell>Highly Relevant documents</cell><cell>481</cell></row><row><cell>Size</cell><cell>Partially Relevant documents</cell><cell>195</cell></row><row><cell></cell><cell>Not relevant documents</cell><cell>6,042</cell></row><row><cell cols="2">Topics with relevant documents / Total Topics</cell><cell>37 out of 50</cell></row><row><cell cols="2">Assessors</cell><cell>1</cell></row><row><cell cols="2">CHiC 2013 Multilingual -Spanish Pool</cell><cell></cell></row><row><cell>Depth</cell><cell></cell><cell>100</cell></row><row><cell cols="2">Total documents</cell><cell>11,373</cell></row><row><cell></cell><cell>Highly Relevant documents</cell><cell>1,689</cell></row><row><cell>Size</cell><cell>Partially Relevant documents</cell><cell>446</cell></row><row><cell></cell><cell>Not relevant documents</cell><cell>9,238</cell></row><row><cell cols="2">Topics with relevant documents / Total Topics</cell><cell>46 out of 50</cell></row><row><cell cols="2">Assessors</cell><cell>1</cell></row><row><cell cols="2">CHiC 2013 Multilingual -Swedish Pool</cell><cell></cell></row><row><cell>Depth</cell><cell></cell><cell>150</cell></row><row><cell cols="2">Total documents</cell><cell>11,640</cell></row><row><cell></cell><cell>Highly Relevant documents</cell><cell>941</cell></row><row><cell>Size</cell><cell>Partially Relevant documents</cell><cell>342</cell></row><row><cell></cell><cell>Not relevant documents</cell><cell>10,357</cell></row><row><cell cols="2">Topics with relevant documents / Total Topics</cell><cell>43 out of 50</cell></row><row><cell cols="2">Assessors</cell><cell>1</cell></row><row><cell>Depth</cell><cell></cell><cell>125</cell></row><row><cell cols="2">Total documents</cell><cell>10,287</cell></row><row><cell></cell><cell>Highly Relevant documents</cell><cell>1,723</cell></row><row><cell></cell><cell>Partially Relevant documents</cell><cell>289</cell></row><row><cell></cell><cell>Not relevant documents</cell><cell>8,275</cell></row><row><cell cols="2">Topics with relevant documents / Total Topics</cell><cell>out of 50</cell></row><row><cell cols="2">Assessors</cell><cell>2</cell></row><row><cell></cell><cell>CHiC 2013 Multilingual -Polish Pool</cell><cell></cell></row><row><cell>Depth</cell><cell></cell><cell>125</cell></row><row><cell cols="2">Total documents</cell><cell>11,342</cell></row><row><cell>Size</cell><cell>Highly Relevant documents Partially Relevant documents</cell><cell>1,086 624</cell></row><row><cell></cell><cell>Not relevant documents</cell><cell>9,632</cell></row><row><cell cols="2">Topics with relevant documents / Total Topics</cell><cell>out of 50</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="9,130.10,236.03,307.66,114.18"><head>Table 3 .</head><label>3</label><figDesc>Participating groups and country.</figDesc><table coords="9,130.10,254.01,28.23,8.96"><row><cell>Group</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="9,153.38,491.56,288.42,8.10"><head>Table 4 .</head><label>4</label><figDesc>Submitted Runs in the CHiC 2013 Multilingual Ad-hoc Retrieval Task</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="9,131.66,510.40,327.67,181.41"><head>Topic Language(s) Collection Language(s) Runs Topic Language(s) Collection Language(s) Runs Monolingual runs Multilingual runs</head><label></label><figDesc></figDesc><table coords="9,148.94,559.60,305.06,132.21"><row><cell>Topic</cell><cell>Collection</cell><cell>Runs</cell><cell>Topic</cell><cell>Collection</cell><cell>Runs</cell></row><row><cell>Language(s)</cell><cell>Language(s)</cell><cell></cell><cell>Language(s)</cell><cell>Language(s)</cell><cell></cell></row><row><cell>NO</cell><cell>NO</cell><cell>4</cell><cell>DE</cell><cell>DE,EN,FR</cell><cell>1</cell></row><row><cell>PO</cell><cell>PO</cell><cell>4</cell><cell>EN</cell><cell>DE,EN,FR</cell><cell>1</cell></row><row><cell>SL</cell><cell>SL</cell><cell>3</cell><cell>ES</cell><cell>DE,EN,FR</cell><cell>1</cell></row><row><cell>SV</cell><cell>SV</cell><cell>4</cell><cell>FI</cell><cell>DE,EN,FR</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>FR</cell><cell>DE,EN,FR</cell><cell>1</cell></row><row><cell cols="2">Bilingual runs</cell><cell></cell><cell>IT</cell><cell>DE, EN, FR</cell><cell>1</cell></row><row><cell>DE</cell><cell>FR</cell><cell>1</cell><cell>NL</cell><cell>DE,EN,FR</cell><cell>1</cell></row><row><cell>DE</cell><cell>EN</cell><cell>1</cell><cell>EN</cell><cell>EN, IT</cell><cell>1</cell></row><row><cell>EN</cell><cell>DE</cell><cell>1</cell><cell>IT</cell><cell>EN, IT</cell><cell>1</cell></row><row><cell>EN</cell><cell>FR</cell><cell>1</cell><cell></cell><cell></cell><cell></cell></row><row><cell>FR</cell><cell>DE</cell><cell>1</cell><cell></cell><cell></cell><cell></cell></row><row><cell>FR</cell><cell>EN</cell><cell>1</cell><cell></cell><cell></cell><cell></cell></row><row><cell>DE</cell><cell>DE</cell><cell>6</cell><cell>All</cell><cell>All</cell><cell>10</cell></row><row><cell>EL</cell><cell>EL</cell><cell>3</cell><cell>DE</cell><cell>All</cell><cell>1</cell></row><row><cell>EN</cell><cell>EN</cell><cell>10</cell><cell>EN</cell><cell>All</cell><cell>1</cell></row><row><cell>ES</cell><cell>ES</cell><cell>4</cell><cell>FR</cell><cell>All</cell><cell>1</cell></row><row><cell>FI</cell><cell>FI</cell><cell>3</cell><cell>All NOT EL</cell><cell>All NOT EL</cell><cell>1</cell></row><row><cell>FR</cell><cell>FR</cell><cell>6</cell><cell>All NOT EL, HU, SL</cell><cell>All NOT EL, HU, SL</cell><cell>4</cell></row><row><cell>HU</cell><cell>HU</cell><cell>3</cell><cell>All</cell><cell>DE,EN,FR</cell><cell>1</cell></row><row><cell>IT</cell><cell>IT</cell><cell>8</cell><cell>DE, EN, ES, FR, IT</cell><cell>DE,EN,FR</cell><cell>1</cell></row><row><cell>NL</cell><cell>NL</cell><cell>4</cell><cell>DE,EN,FR</cell><cell>DE,EN,FR</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="10,124.70,513.04,346.04,137.73"><head>Table 5 .</head><label>5</label><figDesc>Best Multilingual Experiments per Group (in MAP)</figDesc><table coords="10,124.70,531.88,346.04,118.89"><row><cell>Participant</cell><cell>Experiment Identifier</cell><cell>Topic</cell><cell>Collection</cell><cell>MAP</cell></row><row><cell></cell><cell></cell><cell>Languages</cell><cell>Languages</cell><cell></cell></row><row><cell>Chemnitz</cell><cell>TUC_ALL_LA</cell><cell>All</cell><cell>All</cell><cell>23.38%</cell></row><row><cell>CEA List</cell><cell>MULTILINGUALNOEXPANSION</cell><cell>All NOT EL, HU, SL</cell><cell>All NOT EL, HU, SL</cell><cell>18.78%</cell></row><row><cell>Neuchatel</cell><cell>UNINEMULTIRUN5</cell><cell>All</cell><cell>All</cell><cell>15.45%</cell></row><row><cell>RSLIS</cell><cell>RSLIS_MULTI_FUSION_COMBS UM</cell><cell>All</cell><cell>All</cell><cell>8.37%</cell></row><row><cell cols="2">Westminster R005</cell><cell>EN</cell><cell>EN,IT</cell><cell>6.30%</cell></row><row><cell>Berkeley</cell><cell>BERKMLENFRDE19</cell><cell cols="2">EN,FR,DE EN,FR,DE</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" coords="11,150.14,557.80,295.00,126.21"><head>Table 6 .</head><label>6</label><figDesc>UC Berkeley: Comparing Topic and Collection Languages (in MAP)<ref type="bibr" coords="11,434.59,557.80,10.55,8.10" target="#b3">[4]</ref> </figDesc><table coords="11,152.90,576.67,289.55,107.34"><row><cell>Experiment Identifier</cell><cell>Topic</cell><cell>Collection</cell><cell>MAP</cell></row><row><cell></cell><cell>Languages</cell><cell>Languages</cell><cell></cell></row><row><cell>BERKMLENFRDE19</cell><cell>EN,FR,DE</cell><cell>EN,FR,DE</cell><cell>3.93%</cell></row><row><cell>BERKMLALL17</cell><cell>All</cell><cell>EN,FR,DE</cell><cell>3.57%</cell></row><row><cell>BERKMLSPENFRDEIT18</cell><cell>EN,FR,DE, ES, IT</cell><cell>EN,FR,DE</cell><cell>3.53%</cell></row><row><cell>BERKMLDE12</cell><cell>DE</cell><cell>EN,FR,DE</cell><cell>3.31%</cell></row><row><cell>BERKMLFR11</cell><cell>FR</cell><cell>EN,FR,DE</cell><cell>2.22%</cell></row><row><cell>BERKMLEN10</cell><cell>EN</cell><cell>EN,FR,DE</cell><cell>1.66%</cell></row><row><cell>BERKMLSP16</cell><cell>ES</cell><cell>EN,FR,DE</cell><cell>1.33%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" coords="13,123.38,270.02,347.01,290.69"><head>Table 10 .</head><label>10</label><figDesc>Best Monolingual Experiments per Group (in MAP)</figDesc><table coords="13,123.38,288.86,347.01,271.85"><row><cell>Participant</cell><cell>Experiment Identi-fier</cell><cell>MAP</cell><cell>Participant</cell><cell>Experiment Identifier</cell><cell>MAP</cell></row><row><cell cols="2">Monolingual English</cell><cell></cell><cell cols="2">Monolingual Italian</cell><cell></cell></row><row><cell>MRIM</cell><cell>MRIM_AR_2</cell><cell>40.43%</cell><cell cols="2">Westminster R004</cell><cell>29.41%</cell></row><row><cell cols="2">Westminster R001</cell><cell>28.30%</cell><cell>RSLIS</cell><cell cols="2">BASELINE.ITA3 24.90%</cell></row><row><cell>Berkeley</cell><cell>BERKBIDEEN04</cell><cell>19.42%</cell><cell>CEA List</cell><cell>CEALISTITALIA NFILTERED</cell><cell>16.50%</cell></row><row><cell>RSLIS</cell><cell>BASELINE.ENG1</cell><cell>18.35%</cell><cell></cell><cell></cell><cell></cell></row><row><cell>CEA List</cell><cell>CEALISTENGLIS HFILTERED</cell><cell>16.68%</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Monolingual French</cell><cell></cell><cell cols="2">Monolingual German</cell><cell></cell></row><row><cell>CEA List</cell><cell>CEALISTFRENCH NOEXPANSION</cell><cell>27.62%</cell><cell>RSLIS</cell><cell>BASELINE.GER2</cell><cell>29.79%</cell></row><row><cell>Berkeley</cell><cell>BERKMONOFR02</cell><cell>20.14%</cell><cell>CEA List</cell><cell>CEALISTGERMA NNOEXPANSION</cell><cell>28.99%</cell></row><row><cell>RSLIS</cell><cell>BASELINE.FRE3</cell><cell></cell><cell>Berkeley</cell><cell cols="2">BERKBIENDE09 17.85%</cell></row><row><cell cols="6">Unfortunately, only 2 groups (RSLIS &amp; CEA List) submitted runs to all 4 languages</cell></row><row><cell cols="5">so that a comparison among even those 4 languages becomes difficult.</cell><cell></cell></row><row><cell cols="2">3.4.3 Participant Approaches</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Table</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13" coords="15,145.94,270.02,303.57,164.21"><head>Table 12 .</head><label>12</label><figDesc>Semantic Enrichment: Best 2 Runs for each Participant</figDesc><table coords="15,145.94,287.97,303.57,146.26"><row><cell>Run name</cell><cell>P@1</cell><cell>P@3</cell><cell>P@10</cell></row><row><cell></cell><cell></cell><cell>Strict relevance</cell><cell></cell></row><row><cell>ceaListEnglishMonolingual</cell><cell>0.5200</cell><cell>0.5467</cell><cell>0.4680</cell></row><row><cell>ceaListEnglishRankMultilingual</cell><cell>0.4800</cell><cell>0.4533</cell><cell>0.3400</cell></row><row><cell>MRIM_SE13_EN_WM_1</cell><cell>0.0800</cell><cell>0.0667</cell><cell>0.0522</cell></row><row><cell>MRIM_SE13_EN_WM</cell><cell>0.0400</cell><cell>0.0533</cell><cell>0.0422</cell></row><row><cell></cell><cell cols="2">Relaxed relevance</cell><cell></cell></row><row><cell>ceaListEnglishRankMultilingual</cell><cell>0.6800</cell><cell>0.7200</cell><cell>0.5600</cell></row><row><cell>ceaListEnglishMonolingual</cell><cell>0.6800</cell><cell>0.7067</cell><cell>0.6600</cell></row><row><cell>MRIM_SE13_EN_WM_1</cell><cell>0.2800</cell><cell>0.1467</cell><cell>0.1598</cell></row><row><cell>MRIM_SE13_EN_WM</cell><cell>0.2800</cell><cell>0.1333</cell><cell>0.1448</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,129.86,686.23,197.23,8.10"><p>Parts of this paper were already published in the CHIC</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2013" xml:id="foot_1" coords="1,349.87,686.23,97.95,8.10"><p>LNCS Overview paper<ref type="bibr" coords="1,434.90,686.23,9.69,8.10" target="#b5">[6]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2" coords="2,127.70,686.23,90.97,8.10"><p>http://www.europeana.eu</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="13,129.98,686.23,85.29,8.10"><p>http://direct.dei.unipd.it</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements.</head><p>This work was supported by <rs type="funder">PROMISE (</rs><rs type="programName">Participative Research Laboratory for Multimedia and Multilingual Information Systems Evaluation, Network of Excellence</rs> cofunded by the <rs type="programName">7th Framework Program</rs> of the <rs type="funder">European Commission</rs>, grant agreement no. <rs type="grantNumber">258191</rs>. We would like to thank <rs type="institution">Europeana</rs> for providing the data for collection and topic preparation and providing valuable feedback on task refinement. We would like to thank <rs type="person">Maria Gäde</rs>, <rs type="person">Preben Hansen</rs>, <rs type="person">Anni Järvelin</rs>, <rs type="person">Birger Larsen</rs>, <rs type="person">Simone Peruzzo</rs>, <rs type="person">Juliane Stiller</rs>, <rs type="person">Theodora Tsikrika</rs> and <rs type="person">Ariane Zambiras</rs> for their invaluable help in translating the topics. We would also like to thank our relevance assessors <rs type="person">Tom Bekers</rs>, <rs type="person">Veronica Estrada Galinanes</rs>, <rs type="person">Vanessa Girnth</rs>, <rs type="person">Ingvild Johansen</rs>, <rs type="person">Georgios Katsimpras</rs>, <rs type="person">Michael Kleineberg</rs>, <rs type="person">Kristoffer Liljedahl</rs>, <rs type="person">Giuliano Migliori</rs>, <rs type="person">Christophe Onambélé</rs>, <rs type="person">Timea Peter</rs>, <rs type="person">Oliver Pohl</rs>, <rs type="person">Siri Soberg</rs>, <rs type="person">Tanja Špec</rs>, <rs type="person">Emma Ylitalo</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_rqvt2gW">
					<orgName type="program" subtype="full">Participative Research Laboratory for Multimedia and Multilingual Information Systems Evaluation, Network of Excellence</orgName>
				</org>
				<org type="funding" xml:id="_CK3EzM8">
					<idno type="grant-number">258191</idno>
					<orgName type="program" subtype="full">7th Framework Program</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>RSLIS used a similar approach with equivalent results: using one topic language against the whole multilingual index did result in lower retrieval effectiveness than the fusion runs using 3 topic languages (table <ref type="table" coords="12,308.34,174.18,3.62,8.96">7</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.70%</head><p>Both groups found that the German topics seem to have the highest retrieval impact. The Westminster group <ref type="bibr" coords="12,224.30,333.21,16.61,8.96" target="#b10">[11]</ref> showed in a similar experiment that English seemed to have a higher impact than Italian. More runs would be necessary to be able to perform a complete analysis. Unine experimented with removing topic and collection languages equally and different fusion algorithms (merging results from separate language indexes) and showed that leaving out the smaller collection languages can result in an increase in performance, however, the impact of an individual language is unclear (table <ref type="table" coords="12,434.95,405.23,3.63,8.96">8</ref>). Finally, TU Chemnitz experimented with different stemming algorithms for all languages and found that using a less aggressive stemmer worked best compared to the standard rule-based stemmers used in Solr or a no-stemming approach (table <ref type="table" coords="12,433.74,575.78,3.62,8.96">9</ref>). </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="16,121.39,437.56,348.97,8.10;16,130.34,448.60,339.95,8.10;16,130.34,459.52,315.89,8.10" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="16,213.29,437.56,253.32,8.10">Towards an Evaluation Infrastructure for DL Performance Evaluation</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Agosti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,303.31,448.60,166.98,8.10;16,130.34,459.52,119.14,8.10">Evaluation of Digital Libraries: An Insight to Useful Applications and Methods</title>
		<editor>
			<persName><forename type="first">G</forename><surname>Tsakonas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Papatheodorou</surname></persName>
		</editor>
		<meeting><address><addrLine>Oxford, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Chandos Publishing</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="93" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,121.39,470.47,349.22,8.19;16,130.34,481.60,82.27,8.10" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="16,249.77,470.47,109.20,8.19">UniNE at CLEF -CHIC 2013</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Akasereh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Naji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,378.31,470.56,88.25,8.10">Proceedings CLEF 2013</title>
		<meeting>CLEF 2013</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>Working Notes</note>
</biblStruct>

<biblStruct coords="16,121.39,492.52,348.88,8.10;16,130.34,503.56,182.36,8.10" xml:id="b2">
	<monogr>
		<ptr target="http://www.cidoc-crm.org/scope.html" />
		<title level="m" coord="16,285.96,492.52,184.30,8.10;16,130.34,503.56,40.24,8.10">Scope Definition of the CIDOC Conceptual Reference Model</title>
		<imprint>
			<publisher>International Council of Museums</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,121.39,514.60,349.23,8.10;16,130.34,525.52,82.27,8.10" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="16,171.02,514.60,190.01,8.10">Pseudo-Relevance Feedback for CLEF-CHiC Adhoc</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Larson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,378.31,514.60,88.28,8.10">Proceedings CLEF 2013</title>
		<meeting>CLEF 2013</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>Working Notes</note>
</biblStruct>

<biblStruct coords="16,121.39,536.56,348.88,8.10;16,130.34,547.60,340.27,8.10;16,130.34,558.52,50.60,8.10" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="16,130.34,547.60,169.70,8.10">Cultural Heritage in CLEF (CHiC) Overview</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Petras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gäde</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Isaac</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kleineberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Masiero</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Nicchio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Stiller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,342.43,547.60,89.27,8.10">Proceedings CLEF-2012</title>
		<meeting>CLEF-2012</meeting>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
	<note>Working Paper</note>
</biblStruct>

<biblStruct coords="16,121.39,569.50,349.26,8.19;16,130.34,580.63,340.36,8.10;16,130.34,591.55,86.52,8.10" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="16,173.78,580.63,129.03,8.10">Cultural Heritage in CLEF (CHiC)</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Petras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Bogers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Toms</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Malak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pawłowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Masiero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,340.15,580.63,99.54,8.10">Proceedings of CLEF 2013</title>
		<meeting>CLEF 2013</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>forthcoming</note>
</biblStruct>

<biblStruct coords="16,121.39,602.50,349.22,8.19;16,130.34,613.63,82.27,8.10" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="16,176.74,602.50,184.29,8.19">CEA LIST&apos;s participation at the CLEF CHiC 2013</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Popescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,378.07,602.59,88.49,8.10">Proceedings CLEF 2013</title>
		<meeting>CLEF 2013</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>Working Notes</note>
</biblStruct>

<biblStruct coords="16,121.39,624.55,349.14,8.10;16,130.34,635.59,210.82,8.10" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="16,389.91,624.55,80.61,8.10">RSLIS/AAU at CHiC</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Skov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Bogers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Lund</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Wistrup</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Larsen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,164.90,635.59,87.66,8.10">Proceedings CLEF 2013</title>
		<meeting>CLEF 2013</meeting>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
	<note>Working Notes</note>
</biblStruct>

<biblStruct coords="16,120.91,646.34,349.53,8.96;16,130.34,657.91,340.31,8.10;16,130.34,668.83,270.96,8.10" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="16,303.17,646.99,167.27,8.10;16,130.34,657.91,105.46,8.10">Ambiguity of Queries and the Challenges for Query Language Detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Stiller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gäde</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vivien</forename><surname>Petras</surname></persName>
		</author>
		<ptr target="http://clef2010.org/resources/proceedings/clef2010labs_submission_41.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="16,261.05,657.91,139.04,8.10">CLEF 2010 LABs and Workshops</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="17,121.00,149.99,349.56,8.10;17,130.34,161.03,340.34,8.10;17,130.34,172.07,176.38,8.10" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="17,353.44,149.99,117.12,8.10;17,130.34,161.03,324.19,8.10">Multimedia Information Modeling and Retrieval(MRIM)/Laboratoire d&apos;Informatique de Grenoble (LIG) at CHiC2013</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Almasri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Chevallet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mulhem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Berrut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,130.34,172.07,87.76,8.10">Proceedings CLEF 2013</title>
		<meeting>CLEF 2013</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>Working Notes</note>
</biblStruct>

<biblStruct coords="17,121.00,182.99,349.68,8.10;17,130.34,194.03,176.38,8.10" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="17,173.75,182.99,281.88,8.10">Using the Divergence Framework for Randomness: CHiC 2013 Lab Report</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Tanase</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,130.34,194.03,87.76,8.10">Proceedings CLEF 2013</title>
		<meeting>CLEF 2013</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>Working Notes</note>
</biblStruct>

<biblStruct coords="17,121.00,205.07,349.55,8.10;17,130.34,215.99,278.15,8.10" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="17,280.97,205.07,189.58,8.10;17,130.34,215.99,86.38,8.10">Identifying the most suitable stemmer for the CHiC multilingual ad-hoc task</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Wilhelm-Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Schürer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Eibl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="17,232.25,215.99,87.66,8.10">Proceedings CLEF 2013</title>
		<meeting>CLEF 2013</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>Working Notes</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
