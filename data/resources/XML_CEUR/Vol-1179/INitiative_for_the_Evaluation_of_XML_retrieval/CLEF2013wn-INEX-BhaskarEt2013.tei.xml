<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,137.05,151.63,321.40,13.13;1,161.88,169.15,271.68,13.13">Tweet Contextualization (Answering Tweet Question) -the Role of Multi-document Summarization</title>
				<funder ref="#_5Mrqj6u">
					<orgName type="full">Department of Electronics and Information Technology (DeitY), Ministry of Communications &amp; Information Technology</orgName>
					<orgName type="abbreviated">MCIT</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,171.64,207.67,58.89,9.11"><forename type="first">Pinaki</forename><surname>Bhaskar</surname></persName>
							<email>pinaki.bhaskar@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Jadavpur University</orgName>
								<address>
									<postCode>700032</postCode>
									<settlement>Kolkata</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,237.47,207.67,71.82,9.11"><forename type="first">Somnath</forename><surname>Banerjee</surname></persName>
							<email>s.banerjee1980@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Jadavpur University</orgName>
								<address>
									<postCode>700032</postCode>
									<settlement>Kolkata</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,332.99,207.67,90.73,9.11"><forename type="first">Sivaji</forename><surname>Bandyopadhyay</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Jadavpur University</orgName>
								<address>
									<postCode>700032</postCode>
									<settlement>Kolkata</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,137.05,151.63,321.40,13.13;1,161.88,169.15,271.68,13.13">Tweet Contextualization (Answering Tweet Question) -the Role of Multi-document Summarization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">926BCC8E1D21CFC53FEF485BD291919E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Question Answering</term>
					<term>Multi-document Summarization</term>
					<term>Automatic Summarization</term>
					<term>Information Retrieval</term>
					<term>Information Extraction</term>
					<term>Tweet Contextualization</term>
					<term>INEX 2013</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The article presents the experiments carried out as part of the participation in the Tweet Contextualization (TC) track of INEX 2013. In our system there are three major sub-systems; i) Offline multi-document summarization, ii) Focused IR and iii) online multi-document Summarization. The Offline multi-document summarization system is based on document graph, clustering and sentence compression. In the Focused IR system, Wikipedia documents are indexed using Lucene with NE field. The most relevant documents are retrieved using the tweet. Online multi-document summary are generated from the most relevant Wikipedia documents and the offline summary of entity (if any). Most relevant sentences are retrieved and each retrieved sentence is assigned a ranking score in the online summary with a limit of 500 words. The three unique runs differ in the way of how many documents are retrieved per tweet. The evaluation score of informativeness is 0.9397 and Readability is 46.72% and both of which achieved 7 th rank among the automatic runs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the explosion of information in Internet, Natural language Question Answering (QA) is recognized as a capability with great potential. Traditionally, QA has attracted many AI researchers, but most QA systems developed are toy systems or games confined to laboratories and to a very restricted domain. Several recent conferences and workshops have focused on aspects of the QA research. Starting in 1999, the Text Retrieval Conference (TREC) <ref type="foot" coords="1,313.92,594.98,3.00,5.56" target="#foot_0">1</ref> has sponsored a question-answering track, which evaluates systems that answer factual questions by consulting the documents of the TREC corpus. A number of systems in this evaluation have successfully combined information retrieval and natural language processing techniques. More recently, Conference and Labs of Evaluation Forums (CLEF) <ref type="foot" coords="1,451.92,641.06,3.00,5.56" target="#foot_1">2</ref> are organizing QA lab from 2010. INEX <ref type="foot" coords="2,282.24,149.30,3.00,5.56" target="#foot_2">3</ref> has also started Question Answering track. INEX 2011 designed a QA track <ref type="bibr" coords="2,278.12,161.35,11.61,9.11" target="#b0">[1]</ref> to stimulate the research for real world application. The Question Answering (QA) task performed by the participating groups of INEX 2011 is contextualizing tweets, i.e., answering questions of the form "what is this tweet about?" using a recent cleaned dump of the Wikipedia (April 2011). In 2012 they renamed this task as Tweet Contextualization <ref type="bibr" coords="2,390.57,207.67,10.59,9.11" target="#b2">[2]</ref>.</p><p>Current INEX 2013 Tweet Contextualization (TC) track gives QA research a new direction by fusing IR and summarization with QA. The TC track of INEX 2013 had two major sub tasks. The first task is to identify the most relevant document from the Wikipedia dump, for this we need a focused IR system. And the second task is to extract most relevant passages from the most relevant retrieved document. So we need an automatic summarization system. The general purpose of the task involves tweet analysis, passage and/or XML elements retrieval and construction of the answer, more specifically, the summarization of the tweet topic.</p><p>Automatic text summarization <ref type="bibr" coords="2,265.42,311.59,11.60,9.11" target="#b3">[3]</ref> has become an important and timely tool for assisting and interpreting text information in today's fast-growing information age. Text Summarization methods can be classified into abstractive and extractive summarization. An Abstractive Summarization ( <ref type="bibr" coords="2,324.81,346.15,11.21,9.11" target="#b4">[4]</ref> and <ref type="bibr" coords="2,357.97,346.15,11.21,9.11" target="#b5">[5]</ref>) attempts to develop an understanding of the main concepts in a document and then expresses those concepts in clear natural language. Extractive Summaries <ref type="bibr" coords="2,322.98,369.19,11.65,9.11" target="#b6">[6]</ref> are formulated by extracting key text segments (sentences or passages) from the text, based on statistical analysis of individual or mixed surface level features such as word/phrase frequency, location or cue words to locate the sentences to be extracted. Our approach is based on Extractive Summarization.</p><p>In this paper, we describe a hybrid Tweet Contextualization system of offline multi-document summarization, focused IR and online multi-document summarization for TC track of INEX 2013. The offline multi-document summarization system is based on document graph, clustering and sentence compression. The focused IR system is based on Nutch architecture and the online multi-document summarization system is based on TF-IDF based sentence ranking and sentence extraction techniques. The same sentence scoring and ranking approach of <ref type="bibr" coords="2,136.04,507.91,11.61,9.11" target="#b7">[7]</ref> and <ref type="bibr" coords="2,167.95,507.91,11.62,9.11" target="#b8">[8]</ref> has been followed. We have submitted three runs in the TC track (267, 270 and 271).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Works</head><p>Recent trend shows hybrid approach of tweet contextualization using Information Retrieval (IR) can improve the performance of the TC system. Reference <ref type="bibr" coords="2,421.35,596.47,11.62,9.11" target="#b9">[9]</ref> removed incorrect answers of QA system using an IR engine. Reference <ref type="bibr" coords="2,381.27,607.99,16.64,9.11" target="#b10">[10]</ref> successfully used methods of IR into QA system. Reference <ref type="bibr" coords="2,299.63,619.51,16.62,9.11" target="#b11">[11]</ref> used the IR system into QA and <ref type="bibr" coords="2,453.93,619.51,16.66,9.11" target="#b12">[12]</ref> and <ref type="bibr" coords="2,141.74,631.03,16.61,9.11" target="#b13">[13]</ref> proposed an efficient hybrid QA system using IR in QA.</p><p>Reference <ref type="bibr" coords="2,186.00,642.55,16.62,9.11" target="#b14">[14]</ref> presents an investigation into the utility of document summarization in the context of IR, more specifically in the application of so-called query-biased summaries: summaries customized to reflect the information need expressed in a query. Employed in the retrieved document list displayed after retrieval took place, the summaries' utility was evaluated in a task-based environment by measuring users' speed and accuracy in identifying relevant documents. This was compared to the performance achieved when users were presented with the more typical output of an IR system: a static predefined summary composed of the title and first few sentences of retrieved documents. The results from the evaluation indicate that the use of query-biased summaries significantly improves both the accuracy and speed of user relevance judgments.</p><p>A lot of research work has been done in the domain of both query dependent and independent summarization. MEAD <ref type="bibr" coords="3,285.61,265.27,16.63,9.11" target="#b15">[15]</ref> is a centroid based multi document summarizer, which generates summaries using cluster centroids produced by topic detection and tracking system. NeATS <ref type="bibr" coords="3,286.20,288.55,16.62,9.11" target="#b16">[16]</ref> selects important content using sentence position, term frequency, topic signature and term clustering. XDoX <ref type="bibr" coords="3,412.91,300.07,16.61,9.11" target="#b17">[17]</ref> identifies the most salient themes within the document set by passage clustering and then composes an extraction summary, which reflects these main themes. Graph based methods have been also proposed for generating summaries. A document graph based query focused multi-document summarization system has been described by <ref type="bibr" coords="3,436.87,346.15,15.30,9.11" target="#b18">[18]</ref>, <ref type="bibr" coords="3,458.99,346.15,11.61,9.11" target="#b7">[7]</ref> and <ref type="bibr" coords="3,141.74,357.67,10.59,9.11" target="#b8">[8]</ref>.</p><p>In the present work, we have used the offline multi-document summarization system as described in <ref type="bibr" coords="3,217.37,380.71,11.61,9.11" target="#b7">[7]</ref> and <ref type="bibr" coords="3,248.63,380.71,10.59,9.11" target="#b8">[8]</ref>. The IR system as described in <ref type="bibr" coords="3,388.72,380.71,15.30,9.11" target="#b11">[11]</ref>, <ref type="bibr" coords="3,410.47,380.71,15.30,9.11" target="#b12">[12]</ref>, <ref type="bibr" coords="3,432.23,380.71,15.30,9.11" target="#b13">[13]</ref>, <ref type="bibr" coords="3,453.98,380.71,16.61,9.11" target="#b19">[19]</ref> and <ref type="bibr" coords="3,142.73,392.47,16.61,9.11" target="#b20">[20]</ref> and the online multi-document summarization system as discussed in <ref type="bibr" coords="3,451.49,392.47,15.30,9.11" target="#b19">[19]</ref>, <ref type="bibr" coords="3,124.80,403.99,15.30,9.11" target="#b20">[20]</ref>, <ref type="bibr" coords="3,148.35,403.99,16.61,9.11" target="#b21">[21]</ref> and <ref type="bibr" coords="3,188.20,403.99,15.30,9.11" target="#b22">[22]</ref>. In the later part of this paper, section 3 describes the corpus statistics and section 4 shows the system architecture of combined TC system of offline summarization, focused IR and online summarization for INEX 2013. The Offline Multi-document Summarization technique is described in section 5. Section 6 details the Focused Information Retrieval system architecture. Section 7 details the Online Multi-document Summarization system architecture. The evaluations carried out on submitted runs are discussed in Section 8 along with the evaluation results. The conclusions are drawn in Section 9.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Corpus statistics</head><p>The training data is the collection of documents that has been rebuilt based on recent English Wikipedia dump (from November 2012). All notes and bibliographic references have been removed from Wikipedia pages to prepare plain xml corpus for an easy extraction of plain text answers. Each training document is made of a title, an abstract and sections. Each section has a sub-title. Abstract and sections are made of paragraphs and each paragraph can have entities that refer to Wikipedia pages. Therefore, the resulting corpus has this simple DTD as shown in table <ref type="table" coords="3,407.33,619.51,3.73,9.11" target="#tab_0">1</ref>.</p><p>A two columned text file containing the Entity list are provided in the test data set. The file contains all the entities extracted from the entire Wikipedia dump. Entity id is in the first column and corresponding entity is given in the second column. There are total 39,02,345 entities in the list.</p><p>Test data is made up of 598 tweets in English have been collected by the organizers from Twitter®. They were selected among informative accounts (for example, @CNN, @TennisTweets, @PeopleMag, @science...), in order to avoid purely personal tweets that could not be contextualized. There are two different formats of tweets, one is the full JSON format with all information such as the user name, tags or URLs as shown in the table 2 and another is a single xml file with three fields: topic, title and txt. The topic field contains the tweet id as attribute, the title field shows the tweet text, for people not wanting to bother with JSON format and the txt field contains full JSON format with all tweet metadata, as shown in the table <ref type="table" coords="4,146.74,253.75,3.73,9.11" target="#tab_2">3</ref>.  "created_at":"Fri, 03 Feb 2012 09:10:20 +0000", "from_user":"XXX", "from_user_id":XXX, "from_user_id_str":"XXX", "from_user_name":"XXX", "geo":null, "id":XXX, "id_str":"XXX", "iso_language_code":"en", "metadata":{"result_type":"recent"}, "profile_image_url":"http://XXX", "profile_image_url_https":"https://XXX", "source":"&lt;a href='http://XXX'&gt;", "text":"blahblahblah", "to_user":null, "to_user_id":null, "to_user_id_str":null, "to_user_name":null </p><formula xml:id="formula_0" coords="4,203.04,295.17,184.10,119.81">&lt;!ELEMENT xml (page)+&gt; &lt;!ELEMENT page (ID, title, a, s*)&gt; &lt;!ELEMENT ID (#PCDATA)&gt; &lt;!ELEMENT title (#PCDATA)&gt; &lt;!ELEMENT a (p+)&gt; &lt;!ELEMENT s (h, p+)&gt; &lt;!ATTLIST s o CDATA #REQUIRED&gt; &lt;!ELEMENT h (#PCDATA)&gt; &lt;!ELEMENT p (#PCDATA | t)*&gt; &lt;!ATTLIST p o CDATA #REQUIRED&gt; &lt;!ELEMENT t (#PCDATA)&gt; &lt;!ATTLIST t e CDATA #IMPLIED&gt;</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">System Architecture</head><p>In this section the overview of the system framework of the current INEX system has been shown. The current INEX system has three major sub-systems; i) Offline multidocument summarization, ii) Focused IR and iii) online multi-document Summarization. The Offline multi-document summarization system is based on document graph and clustering. The Focused IR system has been developed on the basic architecture of Nutch<ref type="foot" coords="5,234.48,487.46,3.00,5.56" target="#foot_3">4</ref> , which use the architecture of Lucene<ref type="foot" coords="5,393.12,487.46,3.00,5.56" target="#foot_4">5</ref> . Nutch is an open source search engine, which supports only the monolingual Information Retrieval in English, etc. The Higher-level system architecture of the combined Tweet Contextualization system of INEX 2013 is shown in the Figure <ref type="figure" coords="5,379.74,522.55,3.73,9.11" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Offline Multi-document Summarization</head><p>All the entities in the Wikipedia documents are tagged using the entity tag and a list of all the entities present in the entire test Wikipedia documents are provided along with the test data set. Entities are the key terms or topic of a document. So, we retrieved most relevant 10 Wikipedia documents for each entity and then we generated a multi-document summary for each entity. This process does not need the tweets and that's why it is a complete offline process. We can prepare the offline summaries using the Wikipedia documents and their entities only. For retrieval, traditional Lucene indexer and Nutch have been used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Wikipedia Document Parsing, Indexing and Retrieval</head><p>The web documents are full of noises mixed with the original content. In that case it is very difficult to identify and separate the noises from the actual content. INEX 2013 corpus, i.e., Wikipedia dump, had some noise in the documents and the documents are in XML tagged format. So, first of all, the documents had to be preprocessed. The document structure is checked and reformatted according to the system requirements.</p><p>XML Parser. The corpus was in XML format. All the XML test data has been parsed before indexing using our XML Parser. The XML Parser extracts the Title of the document along with the paragraphs.</p><p>Noise Removal. The corpus has some noise as well as some special symbols that are not necessary for our system. The list of noise symbols and the special symbols is initially developed manually by looking at a number of documents and then the list is used to automatically remove such symbols from the documents. Some examples are "&amp;quot;", "&amp;amp;", "'''", multiple spaces etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Named Entity Recognizer (NER).</head><p>After cleaning the corpus, the named entity recognizer identifies all the named entities (NE) in the documents using Stanford NER engine <ref type="foot" coords="7,175.20,336.02,3.00,5.56" target="#foot_5">6</ref> and tags them according to their types, which are indexed during the document indexing. Document Indexing. After parsing the Wikipedia documents, they are indexed using Lucene, an open source indexer. Document Retrieval. After indexing, each entity is searched into the Lucene index using Nutch and a set of retrieved top 10 documents in ranked order for each entity is received. First of all, all entities were fired with AND operator. If at least ten documents are retrieved using the entity with AND operator then the entity is removed from the entity list and need not be searched again. If less than 10 documents are retrieved using AND search then the entity are fired again with OR operator. OR searching retrieves at least 10 documents for each entity. Now, the top 10 ranked relevant documents for each entity is considered for offline multi-document summary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Graph based Multi-document Summarization</head><p>Graph Based Clustered Model. The proposed graph based multi-document summarization method consists of following steps:</p><p>(1) The document set D = {d 1 ,d 2 , … d 10 } is processed to extract text fragments, which are sentences in this system as it has been discussed earlier. Here, It has been assumed that the entire documents in a particular set are related i.e. they describe the same event. Some document clustering techniques may be adopted to find related documents from a large collection. Document clustering is out of the scope of this current discussion and is itself a research interest. Let for a document d i , the sentences are {s i1 , s i2 , … s im }. But the system can be easily modified to work with phrase level extraction. Each text fragment becomes a node of the graph i.e. all the sentences become a node.</p><p>(2) Next, edges are created between nodes across the documents where edge score represents the degree of correlation between inter-documents nodes.</p><p>(3) Seed nodes are extracted which identify the relevant sentences within D and a search graph is built to reflect the semantic relationship between the nodes.</p><p>(4) Now, each node is assigned a entity dependent score and the search graph is expanded.</p><p>(5) A entity dependent multi-document summary is generated from the search graph.</p><p>Each sentence is represented as a node in the graph. The text in each document is split into sentences and each sentence is represented with a vector of constituent words. If pair of related document is considered, then the inter document graph can be represented as a set of nodes in the form of bipartite graph. The edges connect two nodes corresponding to sentences from different documents.</p><p>Construct the Edge and Calculate Edge Score. The similarity between two nodes is expressed as the edge weight of the bipartite graph. Two nodes are related if they share common words (except stop words) and the degree of relationship can be measured by equation 1 adapting some traditional IR formula from <ref type="bibr" coords="8,395.29,373.75,15.30,9.11" target="#b23">[23]</ref>.</p><p>(</p><p>where, tf(d , w) is number of occurrence of w in d, idf (w) is the inverse of the number of documents containing w, and size(d) is the size of the documents in words. Actually for a particular node, total edge score is defined as the sum of scores of all out going edges from that node. The nodes with higher total edge scores than some predefined threshold are included as seed nodes.</p><p>But the challenge for multi-document summarization is that the information stored in different documents inevitably overlap with each other. So, before inclusion of a particular node (sentence), it has to be checked whether it is being repeated or not. Two sentences are said to be similar if they share for example, 70% words in common.</p><p>Construction of Search Graph. After identification of seed/topic nodes a search graph is constructed. For nodes, pertaining to different documents, edge scores are already calculated, but for intra document nodes, edge scores are calculated in the similar fashion as said earlier. Since, highly dense graph leads to higher search / execution time, only the edges having edge scores well above the threshold value might be considered.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Identification of Sub-topics through Markov Clustering.</head><p>In this section, we will discuss the process to identify shared subtopics from related multi source documents. We already discussed that the subtopics shared by different news articles on same event form natural (separate) clusters of sentences when they are represented using Edge_Score =</p><formula xml:id="formula_2" coords="8,230.97,382.49,173.56,38.08">((tf (t(u), w) + tf (t(v), w)) × idf (w)) w∈(t (u)∩t (v )) ∑ size(t(u)) + size(t(v))</formula><p>document graph. We use Markov principle of graph clustering to identify those clusters from the document graph.</p><p>Markov Graph Clustering Principle. The MCL algorithm is designed specifically for the settings of simple and weighted graph <ref type="bibr" coords="9,313.10,200.47,15.30,9.11" target="#b24">[24]</ref>. Given that the multi document summarization problem can be represented in the framework of weighted graph structure, it is possible to apply MCL for identifying subtopical groups already present in the input document set. MCL process consists of following steps: In the first step, the associated matrix of the input (document) graph M G is transformed into Markov Matrix T G according to T G = M G d -1 , where d denote the diagonal matrix that has diagonal entries as the column weights of M G , thus , 0</p><formula xml:id="formula_3" coords="9,352.72,269.41,88.63,24.04">kk ik ij i d M d = =</formula><p>∑ , and i≠j. The Markov matrix T G is associated with a graph G′, which is called the associated Markov graph of G. In the second step, the MCL process simulates random walks in the Markov graph by iteratively performing two operations, expansion and inflation. The process will converge to a limit. The MCL process generates a sequence of stochastic matrices starting from the given Markov matrix. Expansion coincides with taking the power of stochastic matrix using the normal matrix product and Inflation corresponds to taking the Hadamard power (entrywise power) of the matrix, followed by scaling step, such that the resulting matrix is stochastic again, i.e., the matrix elements correspond to probability value. The MCL algorithm is described in figure <ref type="figure" coords="9,161.47,401.11,3.72,9.11" target="#fig_1">2</ref>. Entity Dependent Process. The nodes of the already constructed search graph are given a entity dependent score. Using the combined scores of entity independent score and dependent score, clusters are reordered and relevant sentences are collected from each cluster in order. Then each collected sentence has processed and compressed removing the unimportant phrases. After that the compressed sentences are used to construct the summary.</p><p>Recalculate the Cluster Score. There are three basic components in the sentence weight like entity terms dependent score, title words dependent score and synonyms of entity terms dependent score. We collect the list of synonyms of the each word in the entities from the WordNet 3.0<ref type="foot" coords="10,259.68,308.42,3.00,5.56" target="#foot_6">7</ref> and form a set of synonyms.</p><p>The entity terms dependent score is calculated using equation 2.</p><formula xml:id="formula_4" coords="10,191.88,331.12,278.63,35.23">𝑤 ! = 𝑛 ! -𝑒 + 1 1 - 𝑓 ! ! -1 𝑁 ! ! ×3 ! ! !!!<label>(2)</label></formula><p>where, w e is the entity terms dependent score of the sentence i, e is the no. of the entity term, n e is the total no. of entity term, 𝑓 ! ! is the possession of the word which was matched with the entity term e in the sentence i, N i is the total no. of words in sentence i. A boost factor of the entity term, which is 3 for entity term, is multiplied at the end for boosting the entity dependent score.</p><p>The title words dependent score is calculated using equation 3.</p><formula xml:id="formula_5" coords="10,193.48,440.32,277.02,35.23">𝑤 ! = 𝑛 ! -𝑡 + 1 1 - 𝑓 ! ! -1 𝑁 ! ! ×2 ! ! !!!<label>(3)</label></formula><p>where, w t is the title words dependent score of the sentence i, t is the no. of the title words, n t is the total no. of title word, 𝑓 ! ! is the possession of the word which was matched with the title word t in the sentence i. A boost factor of the title words, which is 2, is multiplied at the end for boosting the title words dependent score.</p><p>The synonyms of entity terms dependent score is calculated using equation 4.</p><formula xml:id="formula_6" coords="10,195.37,538.00,276.39,35.23">𝑤 ! = 𝑛 ! -𝑠 + 1 1 - 𝑓 ! ! -1 𝑁 ! ! ! ! !!!<label>(4)</label></formula><p>where, w s is the synonyms dependent score of the sentence i, s is the no. of synonyms, n s is the total no. of synonym, 𝑓 ! ! is the possession of the word which was matched with the synonym s in the sentence i. There is no boosting the synonyms dependent score.</p><p>These three components i.e. w q , w t and w s , are added to get the final weight of a sentence.</p><p>Recalculate the Cluster Ranking. We start by defining a function that attributes values to the sentences as well as to the clusters. We refer to sentences indexed by i and entity terms indexed by j. We want to maximize the number of entity term covered by a selection of sentences:</p><formula xml:id="formula_7" coords="11,236.41,198.64,231.78,22.99">𝑚𝑎𝑥𝑖𝑚𝑖𝑧𝑒 𝑤 ! ! 𝑒 ! !<label>(5)</label></formula><p>where, 𝑤 ! ! is the weight of entity term j in the sentence i and e j is a binary variable indicating the presence of that entity term in the cluster. We also take the selection over title words. We refer to title words indexed by k. We want to maximize the number of title word covered by a selection of sentences:</p><formula xml:id="formula_8" coords="11,236.19,274.96,231.95,22.75">𝑚𝑎𝑥𝑖𝑚𝑖𝑧𝑒 𝑤 ! ! 𝑡 ! !<label>(6)</label></formula><p>where, 𝑤 ! ! is the weight of title word k in the sentence i and t k is a binary variable indicating the presence of that title word in the cluster.</p><p>To take the selection over synonyms of the entity terms, we refer to synonyms indexed by l. We want to maximize the number of synonyms covered by a selection of sentences:</p><formula xml:id="formula_9" coords="11,236.64,365.68,231.45,22.75">𝑚𝑎𝑥𝑖𝑚𝑖𝑧𝑒 𝑤 ! ! 𝑠 ! !<label>(7)</label></formula><p>where, 𝑤 ! ! is the weight of synonym l in the sentence i and s l is a binary variable indicating the presence of that synonym in the cluster.</p><p>So, the entity dependent score of a cluster is the weighted sum of the entity terms it contains. If clusters are indexed by x, the entity dependent score of the cluster x is:</p><formula xml:id="formula_10" coords="11,190.87,433.84,279.63,33.79">𝑐 ! ! = 𝑤 ! ! 𝑒 ! + ! 𝑤 ! ! 𝑡 ! + ! 𝑤 ! ! 𝑠 ! ! ! !!! ! !!! ! !!!<label>(8)</label></formula><p>where, 𝑐 ! ! is the entity dependent score of the cluster x, n is the total no. of sentences in cluster x. Now, the new recalculated combined score of cluster x is:</p><formula xml:id="formula_11" coords="11,260.52,491.92,208.02,13.63">𝑐 ! = 𝑐 ! ! + 𝑐 ! !<label>(9)</label></formula><p>where, c x is the new score of the cluster x and is the entity independent cluster score in the graph of cluster x. Now, all the clusters are ranked with their new score c x .</p><p>Retrieve Sentences for Summary. Get the highest weighted two sentences of each cluster, by the following equation:</p><formula xml:id="formula_12" coords="11,190.78,600.16,277.93,23.95">max 𝑤 ! ! 𝑞 ! + ! 𝑤 ! ! 𝑡 ! + ! 𝑤 ! ! 𝑠 ! ! ∀𝑖<label>(10)</label></formula><p>where, i is the sentence index of a cluster. The original sentences in the documents are generally very lengthy to place in the summary. So, we are actually interested in a selection over phrases of sentence. After getting the top two sentences of a cluster, c x g they are split into multiple phrases. The Stanford Parser<ref type="foot" coords="12,348.00,149.30,3.00,5.56" target="#foot_7">8</ref> is used to parse the sentences and get the phrases of the sentence.</p><p>Sentence Compression. All the phrases which are in one of those 34 relations in the training file, whose probability to drop was 100% and also do not contain any entity term, are removed from the selected summary sentence as described by <ref type="bibr" coords="12,418.69,211.99,10.59,9.11" target="#b7">[7]</ref>. Now the remaining phrases are identified from the parser output of the sentence and search phrases that contain at least one entity term then those phrases are selected. The selected phrases are combined together with the necessary phrases of the sentence to construct a new compressed sentence for the summary. The necessary phrases are identified from the parse tree of the sentence. The phrases with nsubj and the VP phrase related with the nsubj are some example of necessary phrases.</p><p>Sentence Selection for Summary. The compressed sentences for summary have been taken until the length restriction of the summary is reached, i.e. until the following condition holds:</p><formula xml:id="formula_13" coords="12,257.07,349.36,211.41,20.83">𝑙 ! 𝑆 ! &lt; 𝐿 ! (11)</formula><p>where, l i is the length (in no. of words) of compressed sentence i, S i is a binary variable representing the selection of sentence i for the summary and L (=1000 words) is the maximum summary length. After taking the top two sentences from all the clusters, if the length restriction L is not reached, then the second iteration is started similar to the first iteration and the next top most weighted sentence of each cluster are taken in order of the clusters and compressed. If after the completion of the second iteration same thing happens, then the next iteration will start in the same way and so on until the length restriction has been reached.</p><p>Sentence Ordering and Coherency. In this paper, we will propose a scheme of ordering; in that, it only takes into consideration the semantic closeness of information pieces (sentences) in deciding the ordering among them. First, the starting sentence is identified which is the sentence with lowest positional ranking among selected ones over the document set. Next for any source node (sentence) we find the summary node that is not already selected and have (correlation value) with the source node. This node will be selected as next source node in ordering. This ordering process will continue until the nodes are totally ordered. The above ordering scheme will order the nodes independent of the actual ordering of nodes in the original document, thus eliminating the source bias due to individual writing style of human authors. Moreover, the scheme is logical because we select a sentence for position p at output summary, based on how coherent it is with the (p-1)th sentence. The main sentence's number has been taken as the sentence number of the fused sentence. Offline Summary. Now, each generated multi-document summary is indexed along with it entity. There are 39,02,345 entities in the entity list provided in the test data set. So it will be very time consuming to generate such a huge numbers of multidocument summaries. For the time constrain, we have simplified the task. We have selected all the entities, those are present in the tweets and then we have created multi-document summary of such matched entities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Focused Information Retrieval (IR) 6.1 Tweets Parsing</head><p>The tweets had to be processed to retrieve relevant documents. Each tweet / topic was processed to identify the query words for submission to Lucene. The tweets processing steps are described below: Stop Word Removal. In this step the tweet words are identified from the tweets. The stop words and question words (what, when, where, which etc.) are removed from each tweet and the words remaining in the tweets after the removal of such words are identified as the query tokens. The stop word list used in the present work can be found at http://members.unine.ch/jacques.savoy/clef/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Named Entity Recognizer (NER).</head><p>After removing the stop words, the named entity recognizer identifies all the named entities (NE) in the tweet using Stanford NER engine and tags them according to their types, which are used during the scoring of the sentences of the retrieved document.</p><p>Stemming. Query tokens may appear in inflected forms in the tweets. For English, standard Porter Stemming algorithm <ref type="foot" coords="13,274.08,501.14,3.00,5.56" target="#foot_8">9</ref> has been used to stem the query tokens. After stemming all the query tokens, queries are formed with the stemmed query tokens.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Document Retrieval using Tweet</head><p>The same Lucene index described in the section 5.1, has been used to retrieve documents using tweet. After searching each query into the Lucene index, a set of top 10 retrieved documents in ranked order for each tweet is received. Same Boolean logic as proposed in section 5.1, are used to retrieved the top ranked 10 relevant documents for each tweet and considered for final multi-document summarization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Online Multi-document Summarization</head><p>The entity words are identified and marked by the # before each entity word in the tweet. So the entity words are extracted from the tweet and searched into the entity list. Then the pre-generated offline summaries of the matched entities and taken for the final / online summary generation. E.g. if a tweet contains a entity word of entity e i and s i is the offline summary of entity e i , then offline summary s i will also be taken along with the 10 retrieved Wikipedia documents for generating the final/online summary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Sentence Extraction</head><p>The documents texts and the summary text are parsed and the parsed text is used to generate the summary. This module will take the parsed text of the documents as input, filter the input parsed text and extract all the sentences from the parsed text. So this module has two sub modules, Text Filterization and Sentence Extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text Filterization.</head><p>The parsed text may content some junk or unrecognized character or symbol. First, these characters or symbols are identified and removed. The text in the query language are identified and extracted from the document using the Unicode character list, which has been collected from Wikipedia <ref type="foot" coords="14,355.44,399.38,5.88,5.56" target="#foot_9">10</ref> . The symbols like dot (.), coma (,), single quote ('), double quote ("), '!', '?' etc. are common for all languages, so these are also listed as symbols Sentence Extraction. In Sentence Extraction module, filtered parsed text has been parsed to identify and extract all sentences in the documents. Sentence identification and extraction is not an easy task for English document. As the sentence marker '.' (dot) is not only used as a sentence marker, it has other uses also like decimal point and in abbreviations like Mr., Prof., U.S.A. etc. So it creates lot of ambiguity. A possible list of abbreviation had to created to minimize the ambiguity. Most of the times the end quotation (") is placed wrongly at the end of the sentence like .". These kinds of ambiguities are identified and removed to extract all the sentences from the document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Key Term Extraction</head><p>Key Term Extraction module has three sub modules like Query Term, i.e., tweet term extraction, tweet text extraction and Title words extraction. All these three sub modules have been described in the following sections.</p><p>Query/Tweet Term Extraction. First the query generated from the tweet, is parsed using the Query Parsing module. In this Query Parsing module, the Named Entities (NE) are identified and tagged in the given query using the Stanford NER engine. Title Word Extraction. The title of the retrieved document is extracted and forwarded as input given to the Title Word Extraction module. After removing all the stop words from the title, the remaining tile words are extracted and used as the keywords in this system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Top Sentence Identification</head><p>All the extracted sentences are now searched for the keywords, i.e., query terms, tweet's text keywords and title words. Extracted sentences are given some weight according to search and ranked on the basis of the calculated weight. For this task this module has two sub modules: Weight Assigning and Sentence Ranking, which are described below.</p><p>Weight Assigning. This sub module calculates the weights of each sentence in the document. There are three basic components in the sentence weight like query term dependent score, tweet's text keyword dependent score and title word dependent score. These three components are calculated and added to get the final weight of a sentence.</p><p>Query/Tweet Term dependent score: Query/Tweet term dependent score is the most important and relevant score for summary. Priority of this query/tweet dependent score is maximum. The query dependent scores are calculated using equation 12.</p><formula xml:id="formula_14" coords="15,189.08,473.55,281.45,32.47">Q s = F q 20 + n q -q +1 ( ) 1 -f p q -1 N s ⎛ ⎝ ⎜ ⎞ ⎠ ⎟ p ∑ ⎛ ⎝ ⎜ ⎞ ⎠ ⎟ × p ⎛ ⎝ ⎜ ⎞ ⎠ ⎟ q=1 n q ∑ (12)</formula><p>where, Q S is the query/tweet term dependent score of the sentence s, q is the no. of the query/tweet term, n q is the total no. of query terms, f p q is the possession of the word which was matched with the query term q in the sentence s, N s is the total no. of words in sentence s, At the end of the equation 12, the calculated query term dependent score is multiplied by p to give the priority among all the scores. If the query term is NE and contained in a sentence then the weight of the matched sentence are multiplied by 5 as the value of p is 5, to give the highest priority, other wise it has been multiplied by 3 (as p=3 for non NE query terms).</p><formula xml:id="formula_15" coords="15,229.80,568.42,37.84,17.20">F q = 0; if</formula><p>Title Word dependent score: Title words are extracted from the title field of the top ranked retrieved document. A title word dependent score is also calculated for each sentence. Generally title words are also the much relevant words of the document. So the sentence containing any title words can be a relevant sentence of the main topic of the document. Title word dependent scores are calculated using equation 15.</p><p>T s = F t n tt +1 ( )</p><formula xml:id="formula_16" coords="16,240.35,207.91,229.95,31.95">1 - f p t -1 N s ⎛ ⎝ ⎜ ⎞ ⎠ ⎟ p ∑ ⎛ ⎝ ⎜ ⎞ ⎠ ⎟ t=0 n t ∑<label>(15)</label></formula><p>where, T S is the title word dependent score of the sentence s, t is the no. of the title word, n t is the total number of title words, f p t is the position of the word which matched with the title word t in the sentence s, N s is the total number of words in sentence s and</p><formula xml:id="formula_17" coords="16,243.48,302.07,222.90,23.13">F t = 0; if title word t is not found 1; if title word t is found . (<label>16</label></formula><formula xml:id="formula_18" coords="16,466.38,305.11,4.15,9.11">)</formula><p>After calculating all the above three scores the final weight of each sentence is calculated by simply adding all the two scores as mentioned in the equation 17.</p><p>W s = Q s + T s <ref type="bibr" coords="16,453.99,357.19,16.61,9.11" target="#b17">(17)</ref> where, W S is the final weight of the sentence s.</p><p>Sentence Ranking. After calculating weights of all the sentences in the document, sentences are sorted in descending order of their weight. In this process if any two or more than two sentences get equal weight, then they are sorted in the ascending order of their positional value, i.e., the sentence number in the document. So, this Sentence Ranking module provides the ranked sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Summary Generation</head><p>This is the final and most critical module of this system. This module generates the Summary from the ranked sentences. As in <ref type="bibr" coords="16,300.73,513.67,16.59,9.11" target="#b15">[15]</ref> using equation 11, the module selects the ranked sentences subject to maximum length L (=500 words) of the summary. Now, the selected sentences along with their weight are presented as the INEX output format.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1">Informative Content Evaluation</head><p>The organizers did the Informative Content evaluation <ref type="bibr" coords="16,352.69,644.23,10.59,9.11" target="#b0">[1]</ref>, <ref type="bibr" coords="16,370.45,644.23,11.61,9.11" target="#b2">[2]</ref> by selecting relevant passages. The organizers have used a standalone evaluation toolkit based on Porter stemmer and implementing a new normalized ad-hoc dissimilarity defined as following:</p><formula xml:id="formula_19" coords="17,453.88,158.23,16.61,63.35">(18) (19) (<label>20</label></formula><formula xml:id="formula_20" coords="17,466.33,212.47,4.15,9.11">)</formula><p>where T is the set of terms in the reference and for every 𝑡 ∈ 𝑇, fT(t) is its frequency in the reference and fS(t) its frequency in the summary. The idea was to have a dissimilarity which complement has similar properties to usual IR Interpolate Precision measures. Actually, 1-Dis(T, S) increases with the Interpolated Precision at 500 tokens where Precision is defined as the number of word n-grams in the reference. The introduction of the log is necessary to deal with highly frequent words.</p><p>As previously announced, we used this software to evaluate informativeness and like in INEX QA tracks, we considered as T three different sets based on Porter stemming:</p><p>-Unigrams made of single lemmas (after removing stop-words).</p><p>-Bigrams made of pairs of consecutive lemmas (in the same sentence).</p><p>-Bigrams with 2-gaps also made of pairs of consecutive lemmas but allowing the insertion between them of a maximum of two lemmas. Informativity has been evaluated based on three overlapping references: Ranking. Runs are ranked by decreasing score of divergence with the final reference (All.skip). The organizers rank both manual and automatic runs. But we have recalculate the rank considering only the automatic runs, which has been shown here.</p><p>Before our run there are two manual runs in the ranked list. So, the rank provided by the organizers are 2 more than what we have shown in the rank column.</p><p>We have submitted three runs (267, 270 and 271). The evaluation scores of informativeness by organizers of all topics are shown in the table <ref type="table" coords="17,387.78,551.59,3.73,9.11" target="#tab_4">4</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2">Readability Evaluation</head><p>For Readability evaluation <ref type="bibr" coords="18,238.42,172.39,10.59,9.11" target="#b0">[1]</ref>, <ref type="bibr" coords="18,256.58,172.39,11.61,9.11" target="#b2">[2]</ref> all passages in a summary have been evaluated according to Syntax (S), Anaphora (A), Redundancy (R) and Trash (T). If a passage contains a syntactic problem (bad segmentation for example) then it has been marked as Syntax (S) error. If a passage contains an unsolved anaphora then it has been marked as Anaphora (A) error. If a passage contains any redundant information, i.e., an information that have already been given in a previous passage then it has been marked as Redundancy (R) error. If a passage does not make any sense in its context (i.e., after reading the previous passages) then these passages must be considered as trashed, and readability of following passages must be assessed as if these passages were not present, so they were marked as Trash (T). Readability has been evaluated by organizers over the ten tweets having the largest text references (t-rels). For these tweets, summaries are expected to have almost 500 words since the reference is much larger. For each participant summary, we have then check the number of words over 500 in passages that are:</p><p>1. Relevant (T) i.e. clearly related to the tweet, 2. Sound (A) i.e. no issues about resolving references to earlier or later items in the discourse. 3. Non redundant (R) with previous passages. 4. Syntactically (S) correct. Non-relevant passages have also been considered non-sound, redundant and syntactically incorrect.</p><p>Ranking. Runs are ranked according to mean average scores per summary over Soundness, Non redundancy and Syntactically correctness among Relevant passages. The readability evaluation scores are shown in the table 5. Here also we have recalculate the rank considering only the automatic runs, which has been shown here. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion and Future Works</head><p>The tweet contextualization system has been developed as part of the participation in the Tweet Contextualization track of the INEX 2013 evaluation campaign. The overall system has been evaluated using the evaluation metrics provided as part of this track of INEX 2013. Considering that this is the second participation in the track, the evaluation results are satisfactory, which will really encourage us to continue work on it and participate in this track in future. Future works will be motivated towards improving the performance of the system by concentrating on co-reference and anaphora resolution, multi-word identification, para phrasing, feature selection etc. In future, we will also try to use semantic similarity, which will increase our relevance score.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,182.16,563.37,231.14,8.37;6,124.75,147.40,345.82,407.00"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Higher level system architecture of current INEX system</figDesc><graphic coords="6,124.75,147.40,345.82,407.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="9,228.86,508.17,137.69,8.37;9,136.15,530.95,334.48,9.11;9,124.80,542.47,194.34,9.11;9,185.04,414.24,222.72,78.96"><head>Fig. 2 :</head><label>2</label><figDesc>Fig. 2: Pseudo code of MCL PrincipleThe construction of entity independent part of the Markov clusters completes the document-based processing phase of the system.</figDesc><graphic coords="9,185.04,414.24,222.72,78.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="17,142.80,394.70,327.96,9.28;17,160.80,406.63,192.10,9.11;17,142.80,418.94,327.89,9.28;17,160.80,430.63,292.76,9.11;17,142.80,442.94,327.78,9.28;17,160.80,454.87,306.45,9.11"><head>1 .</head><label>1</label><figDesc>prior set of relevant pages selected by organizers while building the 2013 topics (40 tweets, 380 passages, 11 523 tokens), 2. pool selection of most relevant passages from participant submissions for tweets selected by organizers (45 tweets, 1 760 passages, 58 035 tokens), 3. all relevant text merged together with an extra selection of relevant passages from a random pool of ten tweets (70 tweets, 2 378 passages, 77 043 tokens)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,226.11,276.81,143.17,8.37"><head>Table 1 .</head><label>1</label><figDesc>The DTD for Wikipedia pages</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,155.14,429.93,285.12,8.37"><head>Table 2 .</head><label>2</label><figDesc>A full JSON format with all tweet metadata of INEX 2013 test corpus</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,157.02,149.37,281.35,8.37"><head>Table 3 .</head><label>3</label><figDesc>An example of a tweet topic in xml format of INEX 2013 test corpus</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="17,122.86,574.65,346.89,74.37"><head>Table 4 .</head><label>4</label><figDesc>The evaluation scores of Informativeness by organizers of all topics</figDesc><table coords="17,122.86,592.94,346.89,56.08"><row><cell>Run Rank</cell><cell>All. skip</cell><cell>All .bi</cell><cell>All .uni</cell><cell>Pool .skip</cell><cell>Pool. bi</cell><cell>Pool .uni</cell><cell>Prior .skip</cell><cell>Prior .bi</cell><cell>Prior .uni</cell></row><row><cell cols="10">270 7 0.9397 0.9365 0.8481 0.9274 0.9246 0.8418 0.9686 0.9642 0.8529</cell></row><row><cell cols="10">267 8 0.9468 0.9444 0.8838 0.9389 0.9362 0.8802 0.9625 0.9596 0.883</cell></row><row><cell>271 9</cell><cell cols="9">0.95 0.9475 0.8569 0.9446 0.9421 0.8543 0.9793 0.9759 0.867</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="18,130.43,493.77,337.43,78.93"><head>Table 5 .</head><label>5</label><figDesc>The evaluation scores of Readability Evaluation</figDesc><table coords="18,130.43,514.22,337.43,58.48"><row><cell cols="2">Run Rank</cell><cell>Mean Average</cell><cell>Relevancy (T)</cell><cell>Non redundancy (R)</cell><cell>Soundness (A)</cell><cell>Syntax (S)</cell></row><row><cell>267</cell><cell>7</cell><cell>46.72%</cell><cell>50.54%</cell><cell>40.90%</cell><cell>49.56%</cell><cell>49.70%</cell></row><row><cell>270</cell><cell>8</cell><cell>44.17%</cell><cell>46.84%</cell><cell>41.20%</cell><cell>45.30%</cell><cell>46.00%</cell></row><row><cell>271</cell><cell>9</cell><cell>38.76%</cell><cell>41.16%</cell><cell>35.38%</cell><cell>39.74%</cell><cell>41.16%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,130.05,675.60,68.40,8.22"><p>http://trec.nist.gov/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,130.05,686.40,107.33,8.22"><p>http://www.clef-initiative.eu//</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,130.05,686.40,123.10,8.22"><p>https://inex.mmci.uni-saarland.de/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="5,130.05,675.60,85.38,8.22"><p>http://nutch.apache.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="5,130.05,686.40,88.86,8.22"><p>http://lucene.apache.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="7,130.05,686.40,118.86,8.22"><p>http://www-nlp.stanford.edu/ner/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="10,130.05,686.40,104.88,8.22"><p>http://wordnet.princeton.edu/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7" coords="12,130.05,686.40,174.06,8.22"><p>http://nlp.stanford.edu/software/lex-parser.shtml</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8" coords="13,130.05,686.40,179.65,8.22"><p>http://tartarus.org/~martin/PorterStemmer/java.txt</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_9" coords="14,133.05,686.40,204.82,8.22"><p>http://en.wikipedia.org/wiki/List_of_Unicode_characters</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. We acknowledge the support of the <rs type="funder">Department of Electronics and Information Technology (DeitY), Ministry of Communications &amp; Information Technology (MCIT), Government of India</rs> funded project "<rs type="projectName">Development of Cross Lingual Information Access (CLIA) System Phase II</rs>".</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_5Mrqj6u">
					<orgName type="project" subtype="full">Development of Cross Lingual Information Access (CLIA) System Phase II</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="19,128.16,330.48,342.45,8.22;19,138.30,340.80,332.35,8.22;19,138.30,351.12,332.32,8.22" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="19,365.83,330.48,104.77,8.22;19,138.30,340.80,148.20,8.22">Overview of the INEX 2011 Question Answering Track (QA@INEX)</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Moriceau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Tannier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bellot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mothe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="19,307.87,340.80,162.78,8.22;19,138.30,351.12,328.08,8.22">Focused Retrieval of Content and Structure, 10th International Workshop of the Initiative for the Evaluation of XML Retrieval (INEX)</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="19,138.30,361.68,323.13,8.22" xml:id="b1">
	<monogr>
		<title level="m" coord="19,288.14,361.68,107.12,8.22">Lecture Notes in Computer Sc</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Geva</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Kamps</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Schenkel</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,128.16,372.00,342.49,8.22;19,138.30,382.32,332.34,8.22;19,138.30,392.88,332.32,8.22;19,138.30,403.20,332.22,8.22;19,138.30,413.52,332.40,8.22;19,138.30,424.32,332.08,8.22" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="19,138.30,382.32,213.29,8.22">Overview of the INEX 2012 tweet contextualization track</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Moriceau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Tannier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bellot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mothe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012-09">2012, September</date>
			<biblScope unit="page" from="148" to="159" />
		</imprint>
	</monogr>
	<note>Copyright cG2012 remains with the author/owner. The unreviewed pre-proceedings are collections of work submitted before the December workshops. They are not peer reviewed, are not quality controlled, and contain known errors in content and editing. The proceedings, published after the Workshop, is the authoritative reference for the work done at INEX.</note>
</biblStruct>

<biblStruct coords="19,128.16,434.64,342.44,8.22;19,138.30,444.96,332.29,8.22;19,138.30,455.52,117.44,8.22" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="19,240.31,434.64,114.61,8.22">Automatic Text summarization</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Jezek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Steinberger</surname></persName>
		</author>
		<editor>Snasel, V.</editor>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
			<publisher>FIIT STU Brarislava</publisher>
			<biblScope unit="page" from="1" to="12" />
			<pubPlace>Znalosti</pubPlace>
		</imprint>
	</monogr>
	<note>Ustav Informatiky a softveroveho inzinierstva</note>
</biblStruct>

<biblStruct coords="19,128.16,465.84,342.46,8.22;19,138.30,476.16,329.92,8.22" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="19,247.35,465.84,223.27,8.22;19,138.30,476.16,53.12,8.22">LexRank: Graph-based Centrality as Salience in Text Summarization</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Erkan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="19,210.04,476.16,149.77,8.22">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="457" to="479" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,128.16,486.72,342.46,8.22;19,138.30,497.04,332.29,8.22;19,138.30,507.36,233.23,8.22" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="19,236.17,486.72,185.50,8.22">The SYNDIKATE text Knowledge base generator</title>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Hahn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Romacker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="19,441.87,486.72,28.76,8.22;19,138.30,497.04,332.29,8.22;19,138.30,507.36,95.69,8.22">the first International conference on Human language technology research, Association for Computational Linguistics</title>
		<meeting><address><addrLine>Morristown, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,128.16,517.92,342.40,8.22;19,138.30,528.24,332.29,8.22;19,138.30,538.56,311.44,8.22" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="19,352.59,517.92,117.97,8.22;19,138.30,528.24,80.32,8.22">Optimizing Text Summarization Based on Fuzzy Logic</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Kyoomarsi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Khosravi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">K</forename><surname>Dehkordy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="19,237.81,528.24,232.78,8.22;19,138.30,538.56,71.67,8.22">Seventh IEEE/ACIS International Conference on Computer and Information Science</title>
		<meeting><address><addrLine>UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="347" to="352" />
		</imprint>
		<respStmt>
			<orgName>University of Shahid Bahonar Kerman</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="19,128.16,548.88,342.46,8.22;19,138.30,559.44,332.25,8.22;19,138.30,569.76,251.46,8.22" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="19,279.43,548.88,191.19,8.22;19,138.30,559.44,53.13,8.22">A Query Focused Multi Document Automatic Summarization</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bandyopadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="19,216.02,559.44,254.53,8.22;19,138.30,569.76,97.17,8.22">the 24th Pacific Asia Conference on Language, Information and Computation (PACLIC 24)</title>
		<meeting><address><addrLine>Sendai, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
		<respStmt>
			<orgName>Tohoku University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="19,128.16,580.08,342.37,8.22;19,138.30,590.64,332.33,8.22;19,138.30,600.96,141.21,8.22" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="19,279.43,580.08,191.10,8.22;19,138.30,590.64,42.00,8.22">A Query Focused Automatic Multi Document Summarizer</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bandyopadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="19,199.67,590.64,252.81,8.22">the International Conference on Natural Language Processing (ICON)</title>
		<meeting><address><addrLine>Kharagpur, India</addrLine></address></meeting>
		<imprint>
			<publisher>IIT</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="241" to="250" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,128.16,611.28,342.39,8.22;19,138.30,622.08,272.67,8.22" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="19,383.80,611.28,86.75,8.22;19,138.30,622.08,195.02,8.22">A Question Answering System based on Information Retrieval and Validation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rodrigo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Iglesias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pe˜nas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Garrido</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Araujo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="19,339.26,622.20,45.43,7.80">ResPubliQA</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,132.28,632.40,338.36,8.22;19,138.30,642.72,332.30,8.22;19,138.30,653.28,39.72,8.22" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="19,368.68,632.40,101.96,8.22;19,138.30,642.72,220.86,8.22">Question Answering using Integrated Information Retrieval and Information Extraction</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Schiffman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">R</forename><surname>Mckeown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Grishman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="19,379.33,642.72,49.07,8.22">NAACL HLT</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="532" to="539" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,132.28,663.60,338.34,8.22;19,138.30,673.92,332.30,8.22;19,138.30,684.48,215.71,8.22" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="19,421.60,663.60,49.02,8.22;19,138.30,673.92,200.66,8.22">JU_CSE_TE: System Description QA@CLEF 2010 -ResPubliQA</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pakray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bandyopadhyay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="19,362.49,673.92,108.11,8.22;19,138.30,684.48,139.71,8.22">Multiple Language Question Answering (MLQA 2010)</title>
		<meeting><address><addrLine>Padua, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>CLEF-2010</note>
</biblStruct>

<biblStruct coords="20,132.28,149.52,338.35,8.22;20,138.30,159.84,332.36,8.22;20,138.30,170.40,332.28,8.22;20,138.30,180.72,251.75,8.22" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="20,138.30,159.84,220.17,8.22">Question Answering System for QA4MRE@CLEF 2012</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pakray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bandyopadhyay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,381.11,159.84,89.55,8.22;20,138.30,170.40,332.28,8.22;20,138.30,180.72,118.47,8.22">the proceedings of the Question Answering for Machine Reading Evaluation (QA4MRE) at Conference and Labs of the Evaluation Forum (CLEF)</title>
		<meeting><address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012-09">2012. Sep. 2012</date>
			<biblScope unit="page" from="17" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,132.28,191.04,338.29,8.22;20,138.30,201.60,332.31,8.22;20,138.30,211.92,332.32,8.22;20,138.30,222.24,68.18,8.22" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="20,436.24,191.04,34.34,8.22;20,138.30,201.60,314.94,8.22">A Hybrid Question Answering System based on Information Retrieval and Answer Validation</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pakray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">C</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bandyopadhyay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,138.30,211.92,327.80,8.22">Question Answering for Machine Reading Evaluation (QA4MRE), CLEF-2011</title>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,132.28,232.80,338.30,8.22;20,138.30,243.12,99.45,8.22" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="20,255.21,232.80,215.38,8.22;20,138.30,243.12,31.70,8.22">Advantages of Query Biased Summaries in Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Tombros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,188.03,243.12,23.42,8.22">SIGIR</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,132.28,253.44,338.35,8.22;20,138.30,264.00,275.95,8.22" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="20,306.88,253.44,163.75,8.22;20,138.30,264.00,37.10,8.22">Centroid-based summarization of multiple documents</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Jing</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Styś</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Tam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="20,181.81,264.00,154.51,8.22">J. Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="919" to="938" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,132.28,274.32,338.31,8.22;20,138.30,284.64,176.97,8.22" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="20,223.22,274.32,247.38,8.22;20,138.30,284.64,63.46,8.22">From Single to Multidocument Summarization: A Prototype System and its Evaluation</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,220.03,284.64,15.17,8.22">ACL</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="457" to="464" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,132.28,294.96,338.34,8.22;20,138.30,305.52,253.19,8.22" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="20,411.64,294.96,58.98,8.22;20,138.30,305.52,143.53,8.22">Cross-document summarization by concept classification</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hardy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Shimizu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strzalkowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ting</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">B</forename><surname>Wise</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="middle">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,299.75,305.52,21.43,8.22">SIGIR</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="65" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,132.28,315.84,338.32,8.22;20,138.30,326.16,332.41,8.22;20,138.30,336.72,119.97,8.22" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="20,271.19,315.84,199.40,8.22;20,138.30,326.16,82.52,8.22">A Document Graph Based Query Focused Multi-Document Summarizer</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Paladhi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bandyopadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,241.10,326.16,229.61,8.22;20,138.30,336.72,52.78,8.22">the 2nd International Workshop on Cross Lingual Information Access (CLIA)</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="55" to="62" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,132.28,347.04,338.29,8.22;20,138.30,357.36,332.32,8.22;20,138.30,367.92,332.29,8.22;20,138.30,378.24,332.31,8.22;20,138.30,388.56,332.29,8.22;20,138.30,398.88,332.30,8.22;20,138.30,409.44,279.23,8.22" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="20,364.60,347.04,105.97,8.22;20,138.30,357.36,227.32,8.22">A Hybrid QA System with Focused IR and Automatic Summarization for INEX 2011</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Neogi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bandyopadhyay</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-35734-3_18</idno>
	</analytic>
	<monogr>
		<title level="m" coord="20,217.13,367.92,253.46,8.22;20,138.30,378.24,274.76,8.22">Focused Retrieval of Content and Structure: 10th International Workshop of the Initiative for the Evaluation of XML Retrieval, INEX 2011</title>
		<title level="s" coord="20,372.10,388.56,98.49,8.22;20,138.30,398.88,27.93,8.22">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Geva</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Kamps</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Schenkel</surname></persName>
		</editor>
		<meeting><address><addrLine>Saarbruecken, Germany; Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2012">December 12-14, 2012. 2012. 2012</date>
			<biblScope unit="volume">7424</biblScope>
			<biblScope unit="page" from="207" to="218" />
		</imprint>
	</monogr>
	<note>Revised and Selected Papers</note>
</biblStruct>

<biblStruct coords="20,132.28,419.76,338.35,8.22;20,138.30,430.08,332.26,8.22;20,138.30,440.64,332.33,8.22;20,138.30,450.96,332.28,8.22;20,138.30,461.28,324.05,8.22" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="20,336.20,419.76,134.43,8.22;20,138.30,430.08,130.71,8.22">A Hybrid Tweet Contextualization System using IR and Summarization</title>
		<author>
			<persName coords=""><forename type="middle">P</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="middle">S</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="middle">S</forename><surname>Bandyopadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,287.92,430.08,182.64,8.22;20,138.30,440.64,332.33,8.22;20,138.30,450.96,16.18,8.22;20,351.03,450.96,119.56,8.22;20,138.30,461.28,35.31,8.22">the proceedings of the Initiative for the Evaluation of XML Retrieval, INEX 2012 at Conference and Labs of the Evaluation Forum (CLEF) 2012</title>
		<editor>
			<persName><forename type="middle">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="middle">J</forename><surname>Karlgren</surname></persName>
		</editor>
		<editor>
			<persName><forename type="middle">C</forename><surname>Womser-Hacker</surname></persName>
		</editor>
		<meeting><address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="164" to="175" />
		</imprint>
	</monogr>
	<note>CLEF 2012 Evaluation Labs and Workshop</note>
</biblStruct>

<biblStruct coords="20,132.28,471.84,338.22,8.22;20,138.30,482.16,332.34,8.22;20,138.30,492.48,332.36,8.22;20,138.30,503.04,332.34,8.22;20,138.30,513.36,332.30,8.22;20,138.30,523.68,214.49,8.22" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="20,288.40,471.84,182.10,8.22;20,138.30,482.16,38.38,8.22">Language Independent Query Focused Snippet Generation</title>
		<author>
			<persName coords=""><forename type="middle">P</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="middle">S</forename><surname>Bandyopadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,287.43,482.16,183.20,8.22;20,138.30,492.48,332.36,8.22;20,138.30,503.04,78.21,8.22">Information Access Evaluation. Multilinguality, Multimodality, and Visual Analytics: Third International Conference of the CLEF Initiative, CLEF 2012</title>
		<title level="s" coord="20,361.00,503.04,109.64,8.22;20,138.30,513.36,66.32,8.22">Proceedings, Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">T</forename><surname>Catarci</surname></persName>
		</editor>
		<meeting><address><addrLine>Rome, Italy; Berlin, Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2012">September 17-20, 2012. 2012. 2012</date>
			<biblScope unit="volume">7488</biblScope>
			<biblScope unit="page" from="138" to="140" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,132.28,534.00,338.34,8.22;20,138.30,544.80,332.25,8.22;20,138.30,555.12,207.76,8.22" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="20,275.74,534.00,191.05,8.22">Cross Lingual Query Dependent Snippet Generation</title>
		<author>
			<persName coords=""><forename type="middle">P</forename><surname>Bhaskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="middle">S</forename><surname>Bandyopadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="20,152.70,544.80,314.04,8.22">International Journal of Computer Science and Information Technologies (IJCSIT)</title>
		<idno type="ISSN">0975-9646</idno>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="4603" to="4609" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,132.28,565.44,338.23,8.22;20,138.30,576.00,76.74,8.22" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="20,271.63,565.44,194.90,8.22">A system for query specific document summarization</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Varadarajan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Hristidis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,138.30,576.00,20.57,8.22">CIKM</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="622" to="631" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,132.28,586.32,338.36,8.22;20,138.30,596.64,93.44,8.22" xml:id="b24">
	<monogr>
		<title level="m" type="main" coord="20,227.59,586.32,136.09,8.22">Graph clustering by flow simulation</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Van Dongen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<pubPlace>The Netherlands</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Utrecht</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD Thesis</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
