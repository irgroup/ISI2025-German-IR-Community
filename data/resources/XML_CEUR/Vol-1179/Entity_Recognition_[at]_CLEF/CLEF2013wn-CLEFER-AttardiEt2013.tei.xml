<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,145.70,152.67,303.67,12.64;1,187.37,170.67,220.48,12.64">Machine Translation for Entity Recognition across Languages in Biomedical Documents</title>
				<funder ref="#_vrUy9EA">
					<orgName type="full">CUP</orgName>
				</funder>
				<funder>
					<orgName type="full">RIS</orgName>
				</funder>
				<funder ref="#_VXF226n">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder>
					<orgName type="full">POR RIS</orgName>
				</funder>
				<funder>
					<orgName type="full">Regione Toscana</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,192.17,210.18,67.14,8.96"><forename type="first">Giuseppe</forename><surname>Attardi</surname></persName>
							<email>attardi@di.unipi.it</email>
							<affiliation key="aff0">
								<orgName type="department">Dipartimento di Informatica</orgName>
								<orgName type="institution">Università di Pisa</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,265.79,210.18,63.63,8.96"><forename type="first">Andrea</forename><surname>Buzzelli</surname></persName>
							<email>buzzelli@di.unipi.it</email>
							<affiliation key="aff0">
								<orgName type="department">Dipartimento di Informatica</orgName>
								<orgName type="institution">Università di Pisa</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,335.92,210.18,66.75,8.96"><forename type="first">Daniele</forename><surname>Sartiano</surname></persName>
							<email>sartiano@di.unipi.it</email>
							<affiliation key="aff0">
								<orgName type="department">Dipartimento di Informatica</orgName>
								<orgName type="institution">Università di Pisa</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,145.70,152.67,303.67,12.64;1,187.37,170.67,220.48,12.64">Machine Translation for Entity Recognition across Languages in Biomedical Documents</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A2682DB952CAAEC34FEE95E35CE367F9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We report on our experiments for the CLEF 2013 Entity Recognition Challenge. Our approach is based on a combination of machine translation and NE tagging techniques. The Silver Standard Corpus (SSC) is used to obtain a corresponding annotated corpus in the target language. The plain text of the SSC is translated and a mapping is created between entities in the original and phrases in the translation, to which are associated the same CUIs as in the original. This produces a Bronze Standard Corpus (BSC) in the target language. A dictionary of entities is also created, which associates to each pair (entity text, semantic group) the corresponding CUIs that appeared in the SSC. The BSC is used to train a model for a Named Entity tagger. The model is used for tagging entities in sentences in the target language with the proper semantic group and the entity dictionary is used for associating CUIs to each of them.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="706.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The CLEF-ER Challenge 2013 targets the task of multilingual identification of mentions of named entities in several corpora. Patent texts, titles of Medline abstracts and EMEA documents serve as corpora.</p><p>The task is to produce mention annotations in a multilingual document, i.e. assignment of Concept Unique Identifiers (CUIs, from the UMLS) to phrases in the corpus.</p><p>The challenge organizers provide several resources such as 1. a terminological resource (TR) produced from UMLS, containing English and non-English concepts together with their CUIs. 2. a selection of corpora in English, i.e. patent texts, Medline titles and EMEA documents, where the entity mentions have been annotated automatically with their CUIs. 3. a selection of corpora in different languages other than English, i.e. in DE, FR, SP, and NL, that have to be annotated with entity mentions and their CUIs.</p><p>The English corpora have been annotated automatically with the help of several annotation solutions (for English) from the project partners and a harmonisation scheme to generate a Silver Standard Corpus (CALBC approach). The English corpus thus serves as additional input, but does not serve as a Gold Standard.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head><p>We designed our system while we did not have yet access to the UMLS TR resources provided by the organizers, therefore we just exploited the annotated English Silver Standard Corpus (SSC) as a source of information. We will discuss later how the TR resources could be integrated in our approach.</p><p>Our approach combines techniques of machine translation with NER techniques.</p><p>The following is an overview of the approach:</p><p>1. we apply phrase-based statistical machine translation to the SSC in order to obtain a corresponding annotated corpus in the target language. The plain text of the SSC is translated and a mapping is created between entities in the original and phrases in the translation, to which are associated the same CUIs as in the original. This produces a Bronze Standard Corpus (BSC) in the target language. A dictionary of entities is also created, which associates to each pair (entity text, semantic group) all the corresponding CUIs that appeared in the SSC. 2. the BSC is used to train a model for a Named Entity tagger, whose output classes are the possible semantic groups of entities. 3. the model built at step 2) is used for tagging entities in sentences in the target language with the proper semantic group. 4. the annotated document is converted to XML format and enriched by adding CUIs to each entity, looking up the pair (entity, group) in the dictionary of CUIs built in step 1.</p><p>One advantage of this approach is that it produces data, a NER model and an entity dictionary, that can be readily applied to a document in the target language without any further reference to the source corpora in the original language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Creating the Bronze Standard Corpus</head><p>The Bronze Standard Corpus is obtained by translating the SSC and transferring to it the entity annotations.</p><p>For translating the original English SSC into the target language (Spanish), we use Moses <ref type="bibr" coords="2,153.62,581.27,10.71,8.96" target="#b6">[7]</ref>, a statistical phrase-based machine translation system that allows automatically learning translation models for any language pair. Moses is trained through a collection of parallel corpora. An efficient decoder algorithm finds the highest probability translation among an exponential number of possible translations.</p><p>We exploited the word alignment information produced by Moses to determine the correspondence between entities in the source and target sentences.</p><p>Moses was trained on texts pertaining to the biomedical domain, obtained by joining the EMEA corpus <ref type="bibr" coords="2,216.17,665.30,11.72,8.96" target="#b4">[5]</ref> with from the Medline resource provided for the CLEF-ER challenge.</p><p>In our experiments we only dealt with English to Spanish translation, but the approach can be applied to any language pair for which there exist suitable parallel corpora.</p><p>In order to identify in the target language the phrases that correspond to entities in the original, we exploit the word alignment information obtained by invoking the Moses decoder with the option:</p><p>-alignment-output-file file Let's illustrate this step with the following example.</p><p>"This medicine/CHEM relieves headaches/DISO" By invoking the Moses decoder, we obtain the following best translation: "Este medicamento alivia los dolores de cabeza" and the following word alignment:</p><formula xml:id="formula_0" coords="3,251.33,350.13,92.48,8.96">1-1 2-2 3-3 3-4 3-5 3-6</formula><p>Each pair of numbers in the alignment provides a correspondence between a token in the original sentence identified by its left number position and a token in its translation identified by its right number position.</p><p>The word alignment allows us to map an entity in the source to its translation. For example, the entity "medicine", located at position '1' in the original sentence, is mapped to the single word "medicamento", at position '1' in the translation.</p><p>The case is less clear for the second entity: the word alignment indicates that the source word "headaches", located at position '3', maps to the list of tokens <ref type="bibr" coords="3,438.19,454.31,10.87,8.96" target="#b2">[3,</ref><ref type="bibr" coords="3,452.18,454.31,7.52,8.96" target="#b3">4,</ref><ref type="bibr" coords="3,462.83,454.31,7.52,8.96" target="#b4">5,</ref><ref type="bibr" coords="3,124.70,466.21,7.24,9.05" target="#b5">6]</ref>, leading to the phrase "los dolores de cabeza", as a possible entity text in the target language. This candidate text is cleaned up by removing articles and punctuations that occur at the beginning or end of the entity text, in order to obtain more consistent phrases.</p><p>In the example, article "los" gets dropped from the beginning, producing the final entity "dolor de cabeza". This step is performed by simply checking the part of speech tags of tokens, obtained by using the Tanl POS tagger <ref type="bibr" coords="3,347.95,536.63,10.69,8.96" target="#b0">[1]</ref>, trained for Spanish on the Ancora corpus <ref type="bibr" coords="3,185.81,548.15,10.69,8.96" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Building the NER Training Set</head><p>The training set for the NE tagger is obtained from the BSC, converting it into IOB notation and adding POS tags to each token. The example in previous section would be represented as follows: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Training the NE tagger</head><p>For performing NE recognition, we used the Tanl Tagger <ref type="bibr" coords="4,359.11,236.70,10.68,8.96" target="#b0">[1]</ref>, a generic, customizable statistical sequence labeller, suitable for many tasks of sequence labelling, such as POS tagging or Named Entity recognition. The tagger implements a Conditional Markov Model (CMM, aka MEMM) <ref type="bibr" coords="4,276.65,272.73,11.85,8.96" target="#b1">[2]</ref> for sequence labeling that combines features of Hidden Markov models (HMMs) and Maximum Entropy models. The Tagger can be configured to use alternative types of classifiers: Maximum Entropy or Linear Support Vector <ref type="bibr" coords="4,258.77,308.73,10.59,8.96" target="#b5">[6]</ref>. By complementing the classifier with dynamic programming the Tanl Tagger can achieve similar levels of accuracy than SVM with much faster speed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Mention Identification</head><p>In order to identify mentions of named entities in a document in the target language, we can apply the previously built NE tagger model and entity dictionary. The input for the NER tagger must be prepared performing sentence splitting (if needed), tokenization and POS tagging, producing a TSV file for the NE tagger, containing two fields for each token, FORM and POS tag.</p><p>The NER tagger applies the previously build model, producing a three column file, with the third column denoting with the semantic group, in the IOB notation.</p><p>Finally CUIs are added to each mention by looking it up in the previously built dictionary of entities and CUIs. The output is then formatted in the standoff notation required for the task.. Notice that the process could actually be performed fully in memory, using the Tanl pipeline, passing tokens from one stage to the next, without producing any intermediate file.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data</head><p>For training moses we used a parallel corpus consisting of 247,655 sentences from the English-Spanish version of Medline and 1,098,333 sentences from the EMEA corpus <ref type="bibr" coords="4,124.70,633.74,10.69,8.96" target="#b4">[5]</ref>. We tokenized the corpus with the Tanl Tokenizer <ref type="bibr" coords="4,350.65,633.74,11.77,8.96" target="#b0">[1]</ref> and then split into a train part with 1,323,588 sentences and a development part with 11,000 sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Moses training</head><p>We ran the training of Moses, using the KenLM <ref type="bibr" coords="5,319.27,170.22,11.72,8.96" target="#b8">[9]</ref> language model, created using the text of the text of the whole Spanish Wikipedia, extracted using the Tanl Wikipedia Extractor tool <ref type="bibr" coords="5,182.57,194.22,10.60,8.96" target="#b7">[8]</ref>.</p><p>Word alignment was done using MGIZA, a multi thread version of GIZA++ <ref type="bibr" coords="5,451.07,206.22,15.71,8.96" target="#b9">[10]</ref>. After training, we performed a tuning process using the development corpus, created as mentioned earlier.</p><p>The Moses decoder was run using this model with default settings except for a beam size of 500.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">NER Training</head><p>The Tanl NE tagger can be customized by specifying the set of features to use. Features are divided into local and global features. Local features include attribute features, extracted from attributes (e.g. Form, PoS, NE) of tokens in the vicinity of current token, and morphological features, binary features extracted from a token matching a given regular expression. For CLEFER we did not use any global feature: properties holding at the document level. We tested several configurations, starting from the one that proved best for Italian at Evalita 2011 <ref type="bibr" coords="5,328.78,376.29,10.92,8.96" target="#b2">[3]</ref>. The submitted official run uses the same morphological features and these attribute features:</p><formula xml:id="formula_1" coords="5,240.53,402.26,107.75,46.52">Attribute Token Position FORM POSTAG NETAG -2 -1 0 -1 0 1 -<label>1</label></formula><p>For CLEFER we used a Linear SV classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>We submitted three runs for evaluation. The official submission (EMEA_es_man.LR-5.xml) identified 417,390 entities in the 140,552 units present in the Spanish test corpus EMEA_es_man.xml. Some of the identified entities appear without the corresponding CUI while others appear with a very large number of CUIs. The former occurs typically for entities with a general meaning, that during translation get associated to several different original English words in the entity dictionary.</p><p>After the submission, we were able to address this problem by performing a cleanup of the entity dictionary, in this way:</p><p>for each pair (e, cl) in the dictionary for each c in cl retrieve the set of text entities te associated to c in the UMLS for target language if e is not present in te remove it from cl</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>We reported our experiments in the CLEF-ER Challenge 2013 for English to Spanish. By exploiting phrase-base machine translation and NE tagging we were able to build a system that can operate standalone, on any text in the target language, effectively transferring the knowledge on entities from one language to another.</p><p>The accuracy of the solution can be further refined by making use of data from the UMLS, as we started doing in our latest experiments.</p></div>		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. Partial support for this work was provided by project <rs type="funder">RIS</rs> (<rs type="funder">POR RIS</rs> of the <rs type="funder">Regione Toscana</rs>, <rs type="funder">CUP</rs> n° <rs type="grantNumber">6408</rs>.<rs type="grantNumber">30122011.026000160</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_vrUy9EA">
					<idno type="grant-number">6408</idno>
				</org>
				<org type="funding" xml:id="_VXF226n">
					<idno type="grant-number">30122011.026000160</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,132.67,354.02,338.07,8.10;6,141.74,365.06,191.67,8.10" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,273.98,354.02,63.34,8.10">The Tanl Pipeline</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Attardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dei Rossi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Simi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,355.75,354.02,114.99,8.10;6,141.74,365.06,137.36,8.10">Proc. of Workshop on Web Services and Processing Pipelines in HLT</title>
		<meeting>of Workshop on Web Services and essing Pipelines in HLT<address><addrLine>Malta</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,132.67,376.10,337.98,8.10;6,141.74,387.02,244.81,8.10" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,283.38,376.10,187.26,8.10;6,141.74,387.02,102.71,8.10">Maximum Entropy Markov Models for Information Extraction and Segmentation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Freitag</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,260.45,387.02,62.05,8.10">Proc. ICML 2000</title>
		<meeting>ICML 2000</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="591" to="598" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,132.67,398.06,337.95,8.10;6,141.74,409.10,328.96,8.10;6,141.74,420.02,264.65,8.10" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,309.31,398.06,161.31,8.10;6,141.74,409.10,171.01,8.10">The Tanl Tagger for Named Entity Recognition on Transcribed Broadcast News at Evalita</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Attardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Berardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">Dei</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Simi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,441.22,409.10,29.47,8.10;6,141.74,420.02,44.54,8.10">Proc. of Evalita 2011</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Magnini</surname></persName>
		</editor>
		<meeting>of Evalita 2011</meeting>
		<imprint>
			<date type="published" when="2011">2011. 2013</date>
			<biblScope unit="volume">7689</biblScope>
			<biblScope unit="page" from="116" to="125" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,132.67,431.06,337.83,8.10;6,141.74,442.12,298.24,8.10" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,332.83,431.06,137.67,8.10;6,141.74,442.12,15.80,8.10">Design Principles for a Spanish Treebank</title>
		<author>
			<persName coords=""><forename type="first">M</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Civit</forename><surname>Torruella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Martì Antonìn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,173.57,442.12,262.32,8.10">Proc. of the First Workshop on Treebanks and Linguistic Theories (TLT)</title>
		<meeting>of the First Workshop on Treebanks and Linguistic Theories (TLT)</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,132.67,453.04,337.79,8.10;6,141.74,464.08,329.00,8.10;6,141.74,475.12,328.76,8.10;6,141.74,486.04,195.58,8.10" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,200.11,453.04,270.34,8.10;6,141.74,464.08,73.68,8.10">News from OPUS -A Collection of Multilingual Parallel Corpora with Tools and Interfaces</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tiedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,458.26,464.08,12.48,8.10;6,141.74,475.12,179.53,8.10">Recent Advances in Natural Language Processing</title>
		<editor>
			<persName><forename type="first">V</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">John</forename><surname>Benjamins</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam/Philadelphia, Borovets, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="237" to="248" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,132.67,497.08,338.07,8.10;6,141.74,508.12,314.66,8.10" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,319.99,497.08,150.75,8.10;6,141.74,508.12,60.81,8.10">Large linear classification when data cannot fit in memory</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">F</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,209.57,508.12,176.97,8.10">ACM Trans. on Knowledge Discovery from Data</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,132.67,519.04,338.03,8.10;6,141.74,530.08,328.67,8.10;6,141.74,541.12,77.83,8.10" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,260.92,519.04,206.41,8.10">Open source toolkit for statistical machine translation</title>
		<author>
			<persName coords=""><forename type="first">Philipp</forename><surname>Koehn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,151.58,530.08,318.83,8.10;6,141.74,541.12,29.23,8.10">Proc. of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions</title>
		<meeting>of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,132.67,552.04,293.62,8.10" xml:id="b7">
	<monogr>
		<ptr target="http://medialab.di.unipi.it/wiki/Wikipedia_Extractor" />
		<title level="m" coord="6,141.74,552.04,90.54,8.10">Tanl Wikipedia Extractor</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,132.67,563.08,338.10,8.10;6,141.74,574.12,231.58,8.10" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,214.85,563.08,193.05,8.10">KenLM: Faster and smaller language model queries</title>
		<author>
			<persName coords=""><forename type="first">Kenneth</forename><surname>Heafield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,426.10,563.08,44.66,8.10;6,141.74,574.12,182.74,8.10">Proc. of the Sixth Workshop on Statistical Machine Translation</title>
		<meeting>of the Sixth Workshop on Statistical Machine Translation</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,132.40,585.04,338.23,8.10;6,141.74,596.08,26.34,8.10" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="6,284.95,585.04,181.65,8.10">Giza++: Training of statistical translation models</title>
		<author>
			<persName coords=""><forename type="first">Franz</forename><surname>Och</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hermann</forename><surname>Josef</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
