<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,180.15,116.95,255.07,12.62;1,157.52,134.89,300.32,12.62;1,223.81,152.82,167.74,12.62">Multilingual semantic resources and parallel corpora in the biomedical domain: the CLEF-ER challenge</title>
				<funder ref="#_6d8rPxq">
					<orgName type="full">European Commission STREP</orgName>
				</funder>
				<funder ref="#_6YQSSQR">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,159.98,190.51,127.05,8.74"><forename type="first">Dietrich</forename><surname>Rebholz-Schuhmann</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computational Linguistics</orgName>
								<orgName type="institution">University of Zürich</orgName>
								<address>
									<addrLine>Ch (rebholz</addrLine>
									<settlement>clematide</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">European Bioinformatics Institute</orgName>
								<orgName type="institution">Wellcome Trust Genome Campus</orgName>
								<address>
									<postCode>CB10 1SD</postCode>
									<settlement>Hinxton, Cambridge</settlement>
									<country>U.K. (</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,303.92,190.51,74.73,8.74"><forename type="first">Simon</forename><surname>Clematide</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computational Linguistics</orgName>
								<orgName type="institution">University of Zürich</orgName>
								<address>
									<addrLine>Ch (rebholz</addrLine>
									<settlement>clematide</settlement>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,389.20,190.51,58.95,8.74"><forename type="first">Fabio</forename><surname>Rinaldi</surname></persName>
							<email>rinaldi@ifi.uzh.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computational Linguistics</orgName>
								<orgName type="institution">University of Zürich</orgName>
								<address>
									<addrLine>Ch (rebholz</addrLine>
									<settlement>clematide</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,194.94,202.47,58.17,8.74"><forename type="first">Senay</forename><surname>Kafkas</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">European Bioinformatics Institute</orgName>
								<orgName type="institution">Wellcome Trust Genome Campus</orgName>
								<address>
									<postCode>CB10 1SD</postCode>
									<settlement>Hinxton, Cambridge</settlement>
									<country>U.K. (</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,263.67,202.47,93.70,8.74"><forename type="first">Erik</forename><forename type="middle">M</forename><surname>Van Mulligen</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">Erasmus University Medical Center</orgName>
								<address>
									<settlement>Rotterdam</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,367.93,202.47,45.25,8.74"><forename type="first">Chinh</forename><surname>Bui</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">Erasmus University Medical Center</orgName>
								<address>
									<settlement>Rotterdam</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,161.82,214.42,77.16,8.74"><forename type="first">Johannes</forename><surname>Hellrich</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Universität Jena</orgName>
								<address>
									<addrLine>Fürstengraben 30</addrLine>
									<postCode>D-07743</postCode>
									<settlement>Jena</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,249.53,214.42,43.59,8.74"><forename type="first">Ian</forename><surname>Lewin</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">Linguamatics Ltd</orgName>
								<address>
									<addrLine>324 Science Park, Milton Road</addrLine>
									<postCode>CB4 0WG</postCode>
									<settlement>Cambridge</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,303.68,214.42,65.20,8.74"><forename type="first">David</forename><surname>Milward</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">Linguamatics Ltd</orgName>
								<address>
									<addrLine>324 Science Park, Milton Road</addrLine>
									<postCode>CB4 0WG</postCode>
									<settlement>Cambridge</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,379.43,214.42,66.86,8.74"><forename type="first">Michael</forename><surname>Poprat</surname></persName>
							<affiliation key="aff5">
								<orgName type="institution">Averbis GmbH</orgName>
								<address>
									<addrLine>Tennenbacher Strasse 11</addrLine>
									<postCode>D-79106</postCode>
									<settlement>Freiburg</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,185.92,226.38,97.88,8.74"><forename type="first">Antonio</forename><surname>Jimeno-Yepes</surname></persName>
							<affiliation key="aff6">
								<orgName type="institution">National ICT Australia</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,294.36,226.38,44.84,8.74"><forename type="first">Udo</forename><surname>Hahn</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Universität Jena</orgName>
								<address>
									<addrLine>Fürstengraben 30</addrLine>
									<postCode>D-07743</postCode>
									<settlement>Jena</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,369.13,226.38,53.07,8.74"><forename type="first">Jan</forename><forename type="middle">A</forename><surname>Kors</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">Erasmus University Medical Center</orgName>
								<address>
									<settlement>Rotterdam</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,180.15,116.95,255.07,12.62;1,157.52,134.89,300.32,12.62;1,223.81,152.82,167.74,12.62">Multilingual semantic resources and parallel corpora in the biomedical domain: the CLEF-ER challenge</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">74B27485A0DE428AE0C0433006799CA2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Multilingual terminological resources can be drawn from parallel corpora in the languages of interest, possibly exploiting machine translation solutions for term identification. This main objective of the CLEF-ER challenge involves parallel corpora in English and other languages. The challenge organisers have gathered and normalized documents from the biomedical domain: titles from scientific articles, drug labels from the European Medicines Agency, and patent texts from the European Patent Office. The parallel units have been identified, marked-up and formatted for future use. The three different corpora show comparable sizes. In preparation of the CLEF-ER challenge, the documents have been annotated with terminologies in English and non-English languages (de, fr, es, and nl) and the pre-existing terminological resource has been optimized for the entity recognition task in CLEF-ER. Finally a silver standard corpus for entity annotations and their identifiers has been produced on the English documents for the evaluation of challenge contributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Motivation</head><p>Biomedical IT solutions require terminological resources (TRs) to achieve interoperability of modules and data. Increasingly such IT solutions require multilingual TRs, since they are used in different countries to capture and encode patient related information in the home language. To this end, the biomedical terminologies have to be produced in different languages and entities have to</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>be identifiable across languages, i.e. the concepts should carry the same identifier, to enable their reuse and to improve the exchange of data across cultural and language borders. However, existing biomedical multilingual TRs are too limited in their size and their development has to be supported by automatic means that analyse available document resources for the acquisition of novel biomedical terms.</p><p>The production of multilingual TRs is time-consuming and requires novel approaches to produce them at a large scale. One way to improve the development is the exploitation of multilingual parallel documents ("corpora") and to use automatic annotation and alignment methods to identify relevant terms. Such multilingual documents are available from the European Patent Office<ref type="foot" coords="2,473.36,237.97,3.97,6.12" target="#foot_0">1</ref> , EMEA<ref type="foot" coords="2,164.93,249.92,3.97,6.12" target="#foot_1">2</ref> and the Medline<ref type="foot" coords="2,243.31,249.92,3.97,6.12" target="#foot_2">3</ref> distribution. Although they cover different topics, all of them contain potentially novel terms.</p><p>The documents from the available corpora can be annotated with automatic means for the identification of entities in the different languages and subsequently mined for novel terms. When different annotations have been provided, computational methods have to be applied to align the annotations in a single corpus (called "silver standard corpus", SSC). Under the provision of the SSC, we achieve two goals: (1) we can evaluate the results from other annotation solutions against the SSC, and (2) we can attribute the concept unique identifiers (CUIs) from the English annotated documents to the non-English documents. No gold standard corpus (GSC) is available for the assessment of the correct annotation of concept identifiers to the terms in the parallel corpora.</p><p>After the term candidates have been collected -including their CUIs -they have to be validate and integrated into the existing TR, i.e. the novel terms have to be aligned with the existing state of the art TRs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Background</head><p>The main terminological resources in the biomedical domain are maintained and partially produced by the National Library of Medicine (NLM). In addition, the NLM provides sophisticated resources for the processing of natural language text such as MetaMap, a text categorizer that attributes CUIs to text passages. The following terminological resources -amongst others -play an important role in the biomedical domain: The Medical Subject Headings (MeSH) have been produced to categorize the abstracts in PubMed in such a way that information retrieval is performed at high efficiency. The headings are assigned manually to text documents, but computer programmes support the assignment by attributing also headings by automatic means (see MetaMap above). The Systematized Nomenclature of Human and Veterinary Medicine (SNOMED-CT) resource is a medical terminology for the encoding of diseases. It forms a standard that is well established throughout health organisations in different countries and has been included into the distribution of Unified Medical Language System (UMLS) under specific licensing requirements. The Medical Dictionary for Regulatory Activities (MedDRA) is a terminological resource that enables encoding of adverse drug events for regulatory affairs.</p><p>The analysis of clinical and biomedical documents requires tools and resources for efficient processing. Advanced technologies have been developed in recent years that enable semantic annotations, e.g. entity recognitions of a large number of biomedical entities, as well as the efficient and precise parsing of the literature. The research has focused on the development of solutions for the bioinformatics research community, but increasingly solutions from the research domain are used in the clinical environment as well.</p><p>Clinical data is best described by the standardized reporting of clinical parameters, for example the measurements of physiological and patho-physiological parameters from a sample of blood, and of phenotypic parameters given in the natural language of the country. It remains a challenge to read the notes of the clinical doctor, but efficient solutions have been developed to transform the patient record into a standardized representation for further exploitation.</p><p>A number of challenges have been introduced for the assessment of tools and solutions that process biomedical text and normalize identified facts and entities. In the domain of molecular biology, the main focus resided on the correct identification of entities such as genes, proteins, drugs and diseases, and after that, the extraction of molecular interactions, gene regulatory events and gene-disease associations. The sequel of BioCreAtIve challenges engaged the research community into several challenges with different characteristics. As an alternative, the BioNLP Shared Task tackled similar problems, and from early on supported the exploitation of ontological resources for the challenges. All the challenges provide manually annotated corpora as a gold standard corpus to measure performances of the annotation solutions. As an alternative to this general paradigm, the CALBC challenge made use of a corpus at a very large scale that has been generated with automatic means from existing annotation solutions, and it thus represented a "silver-standard" corpus.</p><p>The "Conference and Labs of the Evaluation Forum" (CLEF) has been formed to tackle challenges and their evaluation as a joint effort. It is organized on a yearly basis and has over and over again suggested new challenges for the research community, including the analysis of patents for improved information retrieval (CLEF-IP), the analysis of medical records (CLEFeHealth) and even the analysis of multilingual and multimodal data.</p><p>The CLEF-ER challenge tackles a combination of different tasks: (1) entity mention annotation, (2) entity normalisation, and (3) also multilingual analysis in the sense that participants could use a resource in English to annotate the non-English parallel document. Furthermore, the challenge is not only tuned to a single corpus, but includes patent texts and scientific medical texts alike, provides a reference terminological resource, and demands to process a largescale corpus, larger than typically available in challenges that make use of a gold standard corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Material and Method</head><p>The CLEF-ER challenge is focused to the languages English (en), Spanish (es), French (fr), German (de), and Dutch (nl). This selection has been motivated by the availability of resources, i.e. terminologies and documents alike, in the different languages. It was an important requirement that documents in a non-English language must have a parallel document in English, and -at the same time -it was not relevant that a pair of documents in English and a non-English language should be accompanied by yet another document in a third language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Terminologies</head><p>A number of resources have been prepared for the CLEF-ER challenge: terminological resources and documents. The terminological resource is based on the UMLS and makes use of the contained terms, the standardized file formats and the licensing server of the National Center of Bioinformatics (NCBI) for access to the terminological resource.</p><p>In principle, the full set of UMLS terms could be relevant for the annotation of the multilingual documents, but a number of constraints have to be considered. First, not all terms are relevant for the documents that have been prepared for the CLEF-ER challenge. Second, the overhead for the processing of the full set of terms may be high and may distract from the challenge tasks; in other terms, it is advantageous for challenge participants to handle only a reduced set of the terms relevant for the challenge. Third, the evaluation of the results can be improved by reducing the term set, since the excluded terms and categories will reduce ambiguities, i.e. less semantic categories (called "semantic types" and "semantic groups") could be distinguished if a term is polysemous with regards to the semantic categories. The TR is required for the term normalization: the contained English and non-English concepts are provided with their CUIs. The CUIs form the key result as part of the annotation task in the CLEF-ER challenge, since the challenge participants have to annotate the text with the CUIs, and the challenge organizers evaluate the anntotations against a silver standard corpus (SSC). This subselection of the UMLS terminological resource is called the MANTRA terminological resource (MTR). The terminology is delivered in the OBO file format, which has been proposed by the Open Biomedical Ontology (OBO) Foundry and is maintained by the National Center of Biomedical Ontologies. Its aim is to create a common format for controlled vocabularies.</p><p>The UMLS licence agreement requires that users validate their licenses when accessing the TR. This task is performed by querying the license server from the NLM with the right credentials, for example using restful services through a server<ref type="foot" coords="5,169.56,238.77,3.97,6.12" target="#foot_3">4</ref> validating the username and the password of the licensee. The Terminological Resource is accessible through the download site at the Erasmus University Medical Center Rotterdam.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Selection of parallel corpora</head><p>The corpora have been selected from different resources and for the purpose to serve two objectives: (1) enabling extraction of novel terms for the multilingual TR as part of the MANTRA project work and the outcomes from the CLEF-ER challenge, and (2) offering parallel corpora to the CLEF-ER challenge participants as an input to solve term recognition tasks with and without machine-translation solutions.</p><p>A number of requirements have to be met to fulfill the given objectives. The corpora have to cover the domain knowledge that is under investigation. This is the case for the scientific literature, but also for documents that deal with drug labels. In addition, the MANTRA project partners selected patent documents from the European Patent Office, since this distribution of documents covers a significant amount of documents, deal with biomedical domain knowledge, but also differ in their language from the above mentioned types of documents.</p><p>The diversity between the document repositories is high with regards to the amount of available content, the type of the documents and the languages that are supported in the repository. From the patent corpus, mainly the claim section is available as parallel document, and from Medline only the titles of the scientific articles can be aligned across languages. The EMEA repository allows to identify full documents in parallel. For the patent claims we could produce parallel documents for English, German and French, whereas EMEA and Medline covers all selected languages. The EMEA corpus has already been exploited to train and test statistical machine translation solutions.</p><p>Note that Medline abstracts have always been translated from the non-English language into English and as a consequence the parallel units, i.e. the titles, are restricted to language pairs between the English and the non-English language. More in detail, all non-English units, i.e. patent claim sections, Medline titles, or EMEA document, have a parallel unit in English. Also, every English unit has a parallel non-English unit, but only a smaller portion of English units has a parallel non-English unit in two, three or four languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Optimizing the TR for the challenge</head><p>The MANTRA project partners have annotated the documents with their inhouse annotation solutions, e.g. OntoGene, Peregrine, UIMA-based annotation solutions from the JulieLab and from Averbis. All annotation solutions apply the provided UMLS terminological resource. After this phase, the English annotated corpora have been harmonized and evaluated. This included the assessment on the number of annotations that resulted from the different semantic categories in the UMLS. From the distribution of the annotations, the MANTRA project partners took the decision to reduce the number of categories in the UMLS terminological resource and to extract those categories from UMLS that have higher relevance to the multilingual terminological resource and show -in addition -good coverage in the annotated corpora. The final solution is called the MTR and covers the semantic groups: anatomy, chemicals and drugs, devices, disorders, geographic areas, living beings, objects, phenomena and physiology (ANAT, CHEM, DEVI, DISO, GEOG, LIVB, OBJC, PHEN, PHYS). All terms that are categorized with other semantic groups have then been removed to produce the final terminological resources for the CLEF-ER challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preparation of the silver standard corpus</head><p>The annotated corpora in English have been processed to produce the silver standard corpus as describe in.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Resource and evaluation</head><p>The following resources have been made available to the challenge participants: terminologies and corpora. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistics across the corpora</head><p>The corpora differ in their quality and also in the type of units that have been identified from the documents, i.e. Medline titles in contrast to paragraphs in EMEA documents and claim sections in the patents. On the other side, all corpora are sufficiently large to support the needs of the CLEF-ER: the corpora pose a challenge to the participants since the annotation of the corpora requires automatic means, and also a challenge to the MANTRA project partners, since the harmonization of the annotations should deliver a valuable resource to the public for future exploitation (as in the CALBC challenge).</p><p>The corpora also differ in their sizes (see tbl. 2). The Medline titles form the biggest corpus regarding the number of units and the number of words (as well as the number of characters). The EMEA corpus appears to be larger than the patent corpus when considering the number of units, but is evenly large when measuring the size based on words and characters. Since the EMEA corpus is available in all languages, it is well suited for the CLEF-ER challenge.</p><p>The units from the patent corpus are available in English, French and German as stated before, whereas the other two corpora are provided in all languages. In addition, the annotation of the patent corpus has shown that the language in the corpus has a high diversity and the terms from the MTR are often used in a non-specific way with regards to the biomedical purpose of the MTR, which makes the patent corpus less suitable for the entity recognition task.</p><p>By contrast, the pairwise units from the Medline titles show high heterogeneity and at the same time, the use of the terminology in Medline is most specific with regards to the purpose of the MeSH, MedDRA, and SNOMED-CT terms in the MTR.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation</head><p>The partners have contributed sets of annotated documents where each corpus is either in English or a non-English language (de, fr, es, nl). All identified mentions of an entity have been annotated with a CUI. The following analyses have been performed to determine which corpora will be included into the challenges, and what languages should be covered in the challenges.</p><p>One assumption is that those corpora are most suitable for the challenges that comply best with the terminological resources and -after all -with the domain knowledge over all. The following parameters can be used to measure "compliance" between the terminological resources and/or the domain knowledge and the corpora.</p><p>1. The number of annotations that can be identified using the prepared terminological resource in the English corpus (L1 for language 1, see fig. <ref type="figure" coords="7,447.04,620.54,3.87,8.74" target="#fig_0">1</ref>). 2. The number of annotations that can be identified using the prepared terminological resource in the non-English language in the parallel corpus (L2 for language two, i.e. the non-English language, see fig. <ref type="figure" coords="7,379.99,657.11,3.87,8.74" target="#fig_0">1</ref>). The table shows the number of annotations, i.e. the number of provided CUIs with the annotations, for the different corpora: EMEA, Medline (Mdl), patents (EPO) and an average figure over all corpora. All terms from the provided terminological resource have been used. L1 refers to the English documents, and L2 refers to the non-English documents. The average has been calculated the following way: for a single language all annotations from all partners have been added and then averaged across all three corpora. Then these average values have been averaged across all languages (for L2), which was not required for English alone (L1). The right section shows the percentage of annotations from L1 that have been re-identified in the non-English languages (L2). Note: the quota is not the direct fraction of L2 over L1, but has been calculated as the average fraction across the different languages and corpora.</p><p>3. The previous parameter, but now only all those English annotations are counted where non-English translation is available for the same CUI in the non-English language (L2, see fig. <ref type="figure" coords="8,302.09,440.13,3.87,8.74" target="#fig_1">2</ref>).</p><p>Counting all English annotations as reference (see tbl. 1, parameter 2) gives an analysis that is less generous to the annotation solutions ("pessimistic" or "real world" evaluation) than counting only those English annotations that comply with the third parameter ("optimistic" or "idealistic" evaluation, parameter 3). The latter evaluate the performances under the condition that for each English term there exists a non-English transcript in the TR, i.e. it ignores a number of English annotations where no translation of the term can be found in L2 anyway.</p><p>A number of open questions have been resolved through the analysis of the results that were given by the annotation of the corpora in English and the non-English languages from the project partners. The open questions were concerned with the selection of the languages for the challenge, the selection of corpora and of the semantic groups in the TR.</p><p>First, the languages have been limited to German, Spanish, French and Dutch apart from English. Second, the corpora have been limited to: Medline, patents, and EMEA. Actually, the sizes of these three corpora is quite similar and the diversity between the corpora should contribute to the diversity in the challenge. The numbers in the table have been produced in the same way as the numbers in the previous figure (see fig. <ref type="figure" coords="9,433.35,138.35,3.58,7.86" target="#fig_0">1</ref>), only the number of CUIs has been determined in a different way. In this table, only those CUIs have been counted for the English corpora, where the non-English transcription of the English term exists in the terminological resource. This way, a number of English annotations have been ignored, since the non-English term would not exist anyways. This table shows values that are more generous to the annotation solutions, since they would not be able to identify terms that do not exist in the non-English form in the TR.</p><p>Finally, the terminological resource is limited to the semantic groups: ANAT, CHEM, DEVI, DISO, GEOG, LIVB, OBJC, PHEN, PHYS. The other groups have been excluded, since they did not show enough coverage (GENE, ORGA, OCCU), or it was too unspecific, i.e. not specific enough for the biomedical domain (CONC) resulting to very heterogeneous annotation results across the different corpora and languages. It is obvious that the TR has been reduced to the sets of terms that are required for the challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>The CLEF-ER challenge organized from the MANTRA project partners is the first of its kind tackling a number of challenges in a large-scale annotation task allowing multilingual approaches. The main objective is the identification of biomedical entities (and concepts) in multilingual documents, where the documents are available as part of parallel corpora involving the English language and at least one non-English language.</p><p>The corpora stem from the scientific literature (Medline abstracts), drug labels (EMEA documents) and from the patent text (European patent office). A reference terminology has been provided from UMLS and has been optimized for the challenge participants. The English corpora have been annotated with the terms from the MTR using the annotation solutions of the project partners leading to a silver standard corpus, which has been distributed to the challenge participants. These annotated corpora give the challenge participants different opportunities to contribute to the challenge.</p><p>Altogether, the CLEF-ER challenge will work towards solutions that identify biomedical terms in multilingual documents of different kinds, where the proposed solutions have to cope with large amounts of terms and large data resources. The overall outcome will help to establish the semantic web in healthcare and to allow interoperability of IT solutions across country borders and languages.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="8,134.77,259.63,345.83,7.89;8,134.77,270.61,345.83,7.86;8,134.77,281.57,345.82,7.86;8,134.77,292.53,345.82,7.86;8,134.77,303.49,345.83,7.86;8,134.77,314.45,345.82,7.86;8,134.77,325.41,345.83,7.86;8,134.77,336.37,345.83,7.86;8,134.77,347.33,345.83,7.86;8,134.77,358.28,345.82,7.86;8,134.77,369.24,345.83,7.86;8,134.77,380.20,129.39,7.86;8,137.60,116.83,340.15,128.02"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. (Annotations with all terms):The table shows the number of annotations, i.e. the number of provided CUIs with the annotations, for the different corpora: EMEA, Medline (Mdl), patents (EPO) and an average figure over all corpora. All terms from the provided terminological resource have been used. L1 refers to the English documents, and L2 refers to the non-English documents. The average has been calculated the following way: for a single language all annotations from all partners have been added and then averaged across all three corpora. Then these average values have been averaged across all languages (for L2), which was not required for English alone (L1). The right section shows the percentage of annotations from L1 that have been re-identified in the non-English languages (L2). Note: the quota is not the direct fraction of L2 over L1, but has been calculated as the average fraction across the different languages and corpora.</figDesc><graphic coords="8,137.60,116.83,340.15,128.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="9,134.77,127.37,345.82,7.89;9,134.77,138.35,345.82,7.86;9,134.77,149.31,345.83,7.86;9,134.77,160.27,345.83,7.86;9,134.77,171.23,345.83,7.86;9,134.77,182.19,345.83,7.86;9,134.77,193.15,345.83,7.86;9,134.77,204.11,345.83,7.86;9,134.77,215.07,16.00,7.86;9,137.60,222.19,340.15,127.89"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. (Annotations with selected terms):The numbers in the table have been produced in the same way as the numbers in the previous figure (see fig.1), only the number of CUIs has been determined in a different way. In this table, only those CUIs have been counted for the English corpora, where the non-English transcription of the English term exists in the terminological resource. This way, a number of English annotations have been ignored, since the non-English term would not exist anyways. This table shows values that are more generous to the annotation solutions, since they would not be able to identify terms that do not exist in the non-English form in the TR.</figDesc><graphic coords="9,137.60,222.19,340.15,127.89" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,134.77,487.63,345.83,106.57"><head>Table 1 .</head><label>1</label><figDesc>(Terminological resource): The English part of the TR contains most terms. Only Spanish is covered in SNOMED-CT. MedDRA terms have been translated in all languages.</figDesc><table coords="4,228.07,530.34,159.21,63.85"><row><cell cols="4">Terms MeSH SNOMED-CT MedDRA</cell></row><row><cell cols="3">en 764,000 1,184,005</cell><cell>56,061</cell></row><row><cell cols="2">de 77,249</cell><cell>-</cell><cell>50,128</cell></row><row><cell cols="2">fr 105,758</cell><cell>-</cell><cell>49,586</cell></row><row><cell>es</cell><cell>59,678</cell><cell>1,089,723</cell><cell>49,499</cell></row><row><cell>nl</cell><cell>40,808</cell><cell>-</cell><cell>50,932</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,134.77,512.94,345.83,117.13"><head>Table 2 .</head><label>2</label><figDesc>(Units and word counts, all corpora): The number of units (and words) is highest in English for Medline. German and French are evenly well covered in all three corpora, and Spanish shows similar coverage, except that Spanish (and Dutch) are not represented for patent texts.</figDesc><table coords="6,165.92,566.62,283.51,63.45"><row><cell cols="2">Units EMEA Medline Patent Words EMEA Medline Patent</cell></row><row><cell>en 364,005 1,593,546 120,638</cell><cell>en 5,120,067 15,775,814 6,034,104</cell></row><row><cell>de 364,005 719,232 120,637</cell><cell>de 4,571,203 5,996,504 5,194,032</cell></row><row><cell>fr 373,152 572,176 120,636</cell><cell>fr 5,515,157 6,023,945 6,689,812</cell></row><row><cell>es 366,769 247,655</cell><cell>es 5,897,467 2,573,056</cell></row><row><cell>nl 360,418 54,483</cell><cell>nl 5,130,890 435,390</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,636.52,89.44,7.47"><p>http://www.epo.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,144.73,647.48,160.05,7.47"><p>http://opus.lingfil.uu.se/EMEA.php</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,144.73,658.44,164.76,7.47"><p>http://www.ncbi.nlm.nih.gov/pubmed/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="5,144.73,658.44,311.18,7.47"><p>https://uts-ws.nlm.nih.gov/restful/isValidUMLSUser?licenseCode=...</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>This work was funded by the <rs type="funder">European Commission STREP</rs> grant number <rs type="grantNumber">296410</rs> ("<rs type="projectName">Mantra</rs>", <rs type="grantNumber">FP7-ICT-2011-4.1</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_6d8rPxq">
					<idno type="grant-number">296410</idno>
					<orgName type="project" subtype="full">Mantra</orgName>
				</org>
				<org type="funding" xml:id="_6YQSSQR">
					<idno type="grant-number">FP7-ICT-2011-4.1</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
