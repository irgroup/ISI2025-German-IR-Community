<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,139.22,152.67,316.71,12.64;1,138.86,170.67,317.40,12.64">Combining image retrieval, metadata processing and naive Bayes classification at Plant Identification 2013</title>
				<funder ref="#_yxcaFx3">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,193.61,231.98,54.14,8.19"><forename type="first">Cristina</forename><surname>Şerban</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">&quot;Alexandru Ioan Cuza&quot; University</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,253.93,231.98,70.94,8.18"><forename type="first">Alexandra</forename><surname>Siriţeanu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">&quot;Alexandru Ioan Cuza&quot; University</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,330.64,231.98,66.79,8.18"><forename type="first">Claudia</forename><surname>Gheorghiu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">&quot;Alexandru Ioan Cuza&quot; University</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,211.49,243.11,47.06,8.10"><forename type="first">Adrian</forename><surname>Iftene</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">&quot;Alexandru Ioan Cuza&quot; University</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,264.15,243.02,54.09,8.18"><forename type="first">Lenuţa</forename><surname>Alboaie</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">&quot;Alexandru Ioan Cuza&quot; University</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,324.36,243.02,61.71,8.18"><forename type="first">Mihaela</forename><surname>Breabăn</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science</orgName>
								<orgName type="institution">&quot;Alexandru Ioan Cuza&quot; University</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,139.22,152.67,316.71,12.64;1,138.86,170.67,317.40,12.64">Combining image retrieval, metadata processing and naive Bayes classification at Plant Identification 2013</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9B61EA8EF85BDA85FCB59B78F812CD47</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>ImageCLEF</term>
					<term>plant identification</term>
					<term>image retrieval</term>
					<term>metadata processing</term>
					<term>naive Bayes</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper aims to combine intuition and practical experience in the context of ImageCLEF 2013 Plant Identification task. We propose a flexible, modular system which allows us to analyse and combine the results after applying methods such as image retrieval using LIRe, metadata clustering and naive Bayes classification. Although the training collection is quite extensive, covering a large number of species, in order to obtain accurate results with our photo annotation algorithm we enriched our system with new images from a reliable source. As a result, we performed four runs with different configurations, and the best run was ranked 5 th out of a total of 12 group participants.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>ImageCLEF 2013 <ref type="foot" coords="1,208.85,493.04,3.24,5.83" target="#foot_0">1</ref> Plant Identification task <ref type="foot" coords="1,311.57,493.04,3.24,5.83" target="#foot_1">2</ref> is a competition that aims to improve the state-of-the-art of the Computer Vision field by addressing the problem of image retrieval in the context of botanical data <ref type="bibr" coords="1,293.92,519.23,10.70,8.96" target="#b0">[1]</ref>. The task is similar to those from 2011 and 2012, but there are two main differences: <ref type="bibr" coords="1,317.32,531.23,11.69,8.96" target="#b0">(1)</ref> the organizers offered the participants more species (around 250, aiming to better cover the entire flora from a given region) and (2) they preferred multi-view plant retrieval instead of leaf-based retrieval (the training and test data contain different views of the same plant: entire, flower, fruit, leaf and stem).</p><p>In 2013, the organizers offered a collection based on 250 herb and tree species, most of them from the French area. The training data contains 20985 pictures and the test data contains 5092 pictures, divided in two categories: SheetAsBackground (42%) and NaturalBackground (58%). In Fig. <ref type="figure" coords="1,314.69,627.26,4.98,8.96" target="#fig_0">1</ref> we can see some examples from the pictures used in 2013 in the Plant Identification task. The rest of the article is organized as follows: Section 2 presents the visual and textual features we extracted to describe the images, Section 3 covers the pre-processing and enrichment of the data, Section 4 describes the classification process, Section 5 details our submitted runs and Section 6 outlines our conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head><p>Visual and textual features</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Visual features</head><p>The system we used for extracting and using image features is LIRe (Lucene Image Retrieval) <ref type="bibr" coords="2,185.18,533.75,10.71,8.96" target="#b1">[2]</ref>. LIRe is an efficient and light weight open source library built on top of Lucene, which provides a simple way for performing content based image retrieval. It creates a Lucene index of images and offers the necessary mechanism for searching this index and also for browsing and filtering the results. Being based on a light weight embedded text search engine, it is easy to integrate in applications without having to rely on a database server. Furthermore, LIRe scales well up to millions of images with hash based approximate indexing.</p><p>LIRe is built on top of the open source text search engine Lucene 3 . As in text retrieval, images have to be indexed in order to be retrieved later on. Documents consisting of fields, having a name and a value, are organized in the form of an index that is typically stored in the file system. Some of the features that LIRe can extract from raster images are:  Color histograms in RGB and HSV color space;  MPEG-7 descriptors scalable color, color layout and edge histogram. Formally known as Multimedia Content Description Interface, MPEG-7 includes standardized tools (descriptors, description schemes, and language) that enable structural, detailed descriptions of audio-visual information at different granularity levels (region, image, video segment, collection) and in different areas (content description, management, organization, navigation, and user interaction). <ref type="bibr" coords="3,381.67,242.70,10.90,8.96" target="#b2">[3]</ref>;  The Tamura texture features coarseness, contrast and directionality. In <ref type="bibr" coords="3,456.68,254.82,10.50,8.96" target="#b3">[4]</ref>,</p><p>the authors approximated in computational form six basic textural features, namely, coarseness, contrast, directionality, line-likeness, regularity, and roughness. The first three of these features are available in LIRe;  Color and edge directivity descriptor (CEDD). This feature incorporates color and texture information in a histogram and is limited to 54 bytes per image <ref type="bibr" coords="3,438.19,315.09,10.92,8.96" target="#b4">[5]</ref>;  Fuzzy color and texture histogram (FCTH). This feature also combines, in one histogram, color and texture information. It is the result of combining three fuzzy systems and is limited to 72 bytes per image <ref type="bibr" coords="3,315.79,351.33,10.90,8.96" target="#b5">[6]</ref>;  Joint Composite Descriptor (JCD). One of the Compact Composite Descriptors available for visual description, JCD was designed for natural color images and results from the combination of two compact composite descriptor, CEDD and FCTH <ref type="bibr" coords="3,164.18,399.57,10.90,8.96" target="#b6">[7]</ref>;  Auto color correlation feature. This feature distills the spatial correlation of colors, and is both effective and inexpensive for content-based image retrieval. <ref type="bibr" coords="3,441.94,423.69,10.69,8.96" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Metadata</head><p>The ImageCLEF Pl@ntView dataset consists of a total of 20985 images from 250 herb and tree species in the French area. The dataset is subdivided into two main categories based on the acquisition methodology used: SheetAsBackground (42%) and NaturalBackground (58%), as stated in The training data is further divided based on the content as follows: 3522 "flower", 2080 "leaf", 1455 "entire", 1387 "fruit", 1337 "stem". The test dataset has 1233 "flower", 790 "leaf", 694 "entire", 520 "fruit", 605 "stem" items.</p><p>Each image has a corresponding .xml file which describes the metadata of the plant:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3</head><p>Pre-processing and enrichment</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Training data and Wikimedia</head><p>In order to expand our image collection we searched for a public plant database. Having a larger training dataset to rely on would increase the performance of our photo annotation algorithm. Our choice was Wikimedia Commons 4 , one of the various projects of the Wikimedia Foundation, which hosts a wide variety of photos, including plants. Wikimedia Commons provides a human annotated image repository, uploaded and maintained by a collaborative community of users, thus ensuring a reliable content.</p><p>For downloading the images, we used the Wikimedia public API <ref type="foot" coords="5,409.87,171.99,3.24,5.83" target="#foot_4">5</ref> , by issuing a query for each plant ClassId found in the training dataset. To retrieve relevant results, we used several key API parameters. Each request had the search parameter set to the current ClassId value, the fulltext parameter set to "Search" and the profile parameter to "images".</p><p>To determine the content of each new image, particular filters were used, as follows:</p><p> Flower -flowers, flora, floret, inflorescence, bloom, blossom;  Stem -bark, wood, trunk, branch substrings;  Leaf -leaf, folie, foliage;  Fruit -fruit, fruits, seed, seeds, fructus;</p><p>For every downloaded image, we created an .xml file having the PlantCLEF2013 file format. Thus, we managed to expand our image collection with 507 files.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Extraction of visual features and indexing</head><p>Using LIRe, we extracted the following features from the train images: color histogram, edge histogram, Tamura features <ref type="bibr" coords="5,286.77,397.17,10.73,8.96" target="#b3">[4]</ref>, CEDD <ref type="bibr" coords="5,334.23,397.17,10.66,8.96" target="#b4">[5]</ref>, FCTH <ref type="bibr" coords="5,380.21,397.17,10.58,8.96" target="#b5">[6]</ref>, JCD <ref type="bibr" coords="5,418.07,397.17,10.84,8.96" target="#b6">[7]</ref>. Then we created an index in which we added a document for each train image, containing the previously mentioned features.</p><p>Using this index, we tried to see which feature is better for searches involving each type of plant (entire, flower, fruit, leaf or stem). We chose some images from the train set (for which we already knew the ClassId) and used them as queries to search the index. By comparing the results, we concluded that the JCD (Joint Composite Descriptor) gave us the most satisfying results in all cases.</p><p>The Joint Composite Descriptor <ref type="bibr" coords="5,270.17,493.19,11.69,8.96" target="#b6">[7]</ref> is one of the Compact Composite Descriptors available for visual description. It was designed for natural color images and results from the combination of two compact composite descriptors, namely the Color and Edge Directivity Descriptor <ref type="bibr" coords="5,239.69,529.19,11.69,8.96" target="#b4">[5]</ref> (CEDD) and the Fuzzy Color and Texture Histogram <ref type="bibr" coords="5,124.70,541.19,11.69,8.96" target="#b5">[6]</ref> (FCTH). JCD It is made up of 7 texture areas, with each area made up of 24 subregions that correspond to color areas. The texture areas are as follows: JCD(0) Linear Area, JCD(1) Horizontal Activation, JCD(2) 45 Degrees Activation, JCD(3) Vertical Activation, JCD(4) 135 Degrees Activation, JCD(5) Horizontal and Vertical Activation and JCD(6) Non Directional Activation. For more information on this visual feature, see <ref type="bibr" coords="5,172.64,601.19,10.66,8.96" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Classification</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Using LIRe</head><p>In order to obtain a single score for each ClassId from a result set, we tried three different approaches:</p><p> Using only the maximum score of a ClassId in the result set;  Computing the sum for all the scores of a ClassId and then dividing by the largest sum in that specific result set;  Training a naive Bayes classifier <ref type="foot" coords="6,271.37,626.87,3.24,5.83" target="#foot_5">6</ref> . For the training set, the first 100 ClassIds in the ranking given by LIRe are used as predictors for the (real) ClassId. Then the classifier is used to predict the ClassId on test data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.2</head><p>Using training data set tags: author, organization, location</p><p>Image annotation task has usually relied on training data that has been manually, and thus reliably done but at an expensive and laborious endeavor. To automate this task, we have focused not only on visual information analysis, which is lacking in case of small data set training, but also on image associated meta tags: GPS coordinates, author and organization.</p><p>First, we clustered the training images based on their location to classify the test data using their geo-tags. This proved not to be as we have anticipated. The main reason is the fact that most of the training and test plants are located in France and so most species of the dataset are uniformly distributed in the covered area. Geo-tags would have been, probably, more useful at a global scale (continent, countries).</p><p>To cluster the images based on their geo-tags we used the quadtree data structure<ref type="foot" coords="7,467.38,288.06,3.24,5.83" target="#foot_6">7</ref>  <ref type="bibr" coords="7,124.70,302.25,10.69,8.96" target="#b8">[9]</ref>, in which every internal node has exactly four sons and every child represents a quadrant (NE, NW, SE, and SW) of a given square at a corresponding level (see Fig. <ref type="figure" coords="7,124.70,326.25,3.63,8.96">2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 2. An example of the quadrants of a plant GPS location and the corresponding quadtree</head><p>The quadtree <ref type="foot" coords="7,189.89,453.68,3.24,5.83" target="#foot_7">8</ref> was built based on the training data geo location and was used to classify our test data by retrieving the nearest results in a 100 km area. To compute the distance between two locations, we used the Haversine formula <ref type="foot" coords="7,396.55,477.68,3.24,5.83" target="#foot_8">9</ref> , which computes the great-circle distance (the shortest distance over earth surface) between two points on a sphere from their latitude and longitude values:  Where d is the distance between the two points;  r is the radius of the sphere;  : latitude of point 1 and latitude of point 2;  : longitude of point 1 and longitude of point 2.</p><p>Next, the results were further refined and ranked based on author and organization tags, assuming that certain authors and organizations would have a greater interest in certain plant classes.</p><p>For every test image we have created a recommendation list of 20 items containing the author's most photographed plants. If no results were found, the algorithm continued searching for recommendations based on the author's organization tag.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Submitted runs and results</head><p>Our system (Fig. <ref type="figure" coords="8,197.93,549.71,4.18,8.96" target="#fig_1">4</ref>) has a modular and flexible structure and can easily be extended with some other feature extractors' algorithms. From the beginning, our intention was to use both features extracted from pictures and metadata information, and to find a way to combine them. then used as classifier and the posterior probabilities are used to obtain the final ranking.  Run 4 (run_wiki_max_1): We perform image retrieval using an extended collection of images obtained from the training set and an extracted collection from Wikimedia. For final score of a ClassId we consider the maximum value from the partial results obtained after retrieval.</p><p>In the cases of runs 1, 3, 4, only visual information was used, while in the case of run 2 the textual information from the metadata was also used. Our best run was the one with Run 4 configuration and it was ranked 5 th of a total of 12 group participants (see Table <ref type="table" coords="10,258.12,375.81,3.65,8.96" target="#tab_2">4</ref>). This run was based on the extended collection of training data obtained by getting new images from Wikimedia. Run 3, using naive Bayes, clearly suffered from overfitting: on the training data it recorded 100% accuracy while on the test data it shows to be the worst run. 0,026 0,102 0,082 0,161 0,166 0,092 7 Vicomtech Run 1 0,095 0,117 0 0 0,1 0,081 8 LAPI Run 1 0,026 0,073 0,025 0,084 0,043 0,058 9 Mica Run 2 0,016 0,086 0,048 0,014 0,014 0,053 10 SCG USP Run 3 0,017 0,025 0,042 0,047 0,054 0,03 11 I3S Run 1 0,017 0,023 0,041 0,038 0,025 0,026 12 AgSPPR Run 1 0 0 0 0 0 0</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>This paper proposes a modular system that allowed us to offer different solutions in the ImageCLEF 2013 Plant Identification task.</p><p>Even though we started with a large image collection, containing different views of the same plant (entire, flower, fruit, leaf, stem) with various backgrounds, we decided to add new images in the data test. We used Wikimedia Commons which offers human annotated images, thus ensuring a reliable content.</p><p>From this point on, we started to analyze and process our image repository in two directions. Firstly, in order to extract relevant features (see Section 2.1) from the available image set, we used LIRe. We performed different tests and we decided that JCD was the better choice for our image types, as far as visual features are concerned. Using JCD, we obtained an index from the train set and we started to search for the images in the test set. We obtained a list of train images (a list of ClassIds) corresponding to each query test image. At this point, in order to have a single score for each ClassId we decided on three approaches: using the maximum score for a ClassId, computing the sum of all scores for a ClassId and then dividing by the largest sum, or training a naive Bayes classifier.</p><p>Additionally, we performed various tests using the metadata of the images. Some results obtained using geo-tags metadata proved not to be relevant for our task. But during our tests we observed some patterns that allowed us to use author and GPS coordinates metadata in our final results.</p><p>After trying different configurations, we obtained four results depicted in Section 5. Run 4 is our best result and was ranked 5 th out of the 12 competitors.</p><p>Due to the increased complexity of the task from year to year, we believe that, in the future, our modular architecture will allow us to dynamically integrate new techniques and new algorithms to achieve suitable matches.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,126.62,385.58,342.20,8.10;2,124.70,147.40,345.87,229.35"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Examples of train images (image was taken from http://www.imageclef.org/2013/plant)</figDesc><graphic coords="2,124.70,147.40,345.87,229.35" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="9,223.49,463.60,148.23,8.10;9,137.75,147.40,319.80,306.76"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. UAIC Plant Identification System</figDesc><graphic coords="9,137.75,147.40,319.80,306.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="8,181.92,183.40,231.44,216.80"><head></head><label></label><figDesc></figDesc><graphic coords="8,181.92,183.40,231.44,216.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,134.42,509.75,333.29,93.96"><head>Table 1Error! Reference source not found.. Table 1. Statistics of images in the dataset Type SheetAsBackground NaturalBackground Total</head><label></label><figDesc></figDesc><table coords="3,134.42,567.28,323.25,36.42"><row><cell>Training</cell><cell>9781</cell><cell>11204</cell><cell>20985</cell></row><row><cell>Test</cell><cell>1250</cell><cell>3842</cell><cell>5092</cell></row><row><cell>Total</cell><cell>11031</cell><cell>15046</cell><cell>26077</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="10,117.38,266.30,357.93,80.93"><head>Table 3 .</head><label>3</label><figDesc>Results of our submitted runs</figDesc><table coords="10,117.38,284.48,357.93,62.76"><row><cell>#Run</cell><cell cols="2">Entire Flower</cell><cell>Fruit</cell><cell>Leaf</cell><cell>Stem</cell><cell>Natural Background</cell></row><row><cell>4 run_wiki_max_1</cell><cell>0,09</cell><cell>0,136</cell><cell>0,12</cell><cell>0,08</cell><cell>0,128</cell><cell>0,127</cell></row><row><cell>1 run_wiki_sum_3</cell><cell>0,089</cell><cell>0,109</cell><cell>0,132</cell><cell cols="2">0,093 0,104</cell><cell>0,119</cell></row><row><cell>2 run_author10_GSP10_lire80</cell><cell>0,092</cell><cell>0,105</cell><cell>0,127</cell><cell>0,096</cell><cell>0,11</cell><cell>0,117</cell></row><row><cell>3 run_lire_naivebayes</cell><cell>0,068</cell><cell>0,055</cell><cell>0,111</cell><cell cols="2">0,049 0,102</cell><cell>0,081</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="10,117.38,435.62,357.93,102.67"><head>Table 4 .</head><label>4</label><figDesc>Best result of each participant in Plant Identification task at ImageCLEF 2013</figDesc><table coords="10,117.38,453.82,357.93,84.48"><row><cell>#Run</cell><cell cols="2">Entire Flower</cell><cell>Fruit</cell><cell>Leaf</cell><cell>Stem</cell><cell>Natural Background</cell></row><row><cell>1 NlabUTokyo Run 3</cell><cell>0,297</cell><cell>0,472</cell><cell>0,311</cell><cell cols="2">0,275 0,253</cell><cell>0,393</cell></row><row><cell>2 Inria PlantNet Run 2</cell><cell>0,274</cell><cell>0,494</cell><cell>0,26</cell><cell>0,272</cell><cell>0,24</cell><cell>0,385</cell></row><row><cell>3 Sabanci Okan Run 1</cell><cell>0,174</cell><cell>0,223</cell><cell>0,194</cell><cell cols="2">0,049 0,106</cell><cell>0,181</cell></row><row><cell>4 DBIS Run 2</cell><cell>0,102</cell><cell>0,264</cell><cell>0,082</cell><cell cols="2">0,034 0,095</cell><cell>0,159</cell></row><row><cell>5 UAIC Run 4</cell><cell>0,09</cell><cell>0,136</cell><cell>0,12</cell><cell>0,08</cell><cell>0,128</cell><cell>0,127</cell></row><row><cell>6 Liris ReVeS Run 2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,129.98,675.10,180.70,8.18"><p>ImageCLEF2013: http://www.imageclef.org/2013</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,129.86,686.14,227.68,8.18"><p>Plant Identification Task: http://www.imageclef.org/2013/plant</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,129.98,686.23,157.85,8.10"><p>Lucene is hosted at http://lucene.apache.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,129.98,686.23,256.54,8.10"><p>Wikimedia Commons, http://commons.wikimedia.org/wiki/Main_Page</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="5,129.98,686.23,179.03,8.10"><p>Wikipedia API, http://en.wikipedia.org/w/api.php</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="6,129.98,686.23,276.17,8.10"><p>Naive Bayes classifier, https://en.wikipedia.org/wiki/Naive_Bayes_classifier</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="7,129.98,653.23,262.78,8.10"><p>Quadtree data structure, http://www.cs.umd.edu/~hjs/pubs/Samet85k.pdf</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7" coords="7,130.34,664.27,340.28,8.10;7,136.10,675.19,115.06,8.10"><p>QuadTree -Java implementation, http://openmap.bbn.com/svn/openmap/trunk/src/openmap/ com/bbn/openmap/util/quadtree</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8" coords="7,129.98,686.23,244.36,8.10"><p>Haversine formula: http://en.wikipedia.org/wiki/Haversine_formula</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_9" coords="9,132.98,686.14,155.69,8.18"><p>Wikimedia: http://commons.wikimedia.org</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgement. The research presented in this paper was funded by the project <rs type="projectName">MUCKE (Multimedia and User Credibility Knowledge Extraction)</rs>, number <rs type="grantNumber">2 CHIST-ERA/01.10.2012</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_yxcaFx3">
					<idno type="grant-number">2 CHIST-ERA/01.10.2012</idno>
					<orgName type="project" subtype="full">MUCKE (Multimedia and User Credibility Knowledge Extraction)</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="11,132.67,518.95,337.97,8.19;11,141.74,530.08,328.88,8.10;11,141.74,541.12,46.86,8.10" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,141.74,530.08,172.23,8.10">The ImageCLEF 2013 Plant Identification Task</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bakić</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Barthelemy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,330.75,530.08,99.32,8.10">CLEF 2013 Working Notes</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,132.67,551.95,337.81,8.19;11,141.74,563.08,328.95,8.10;11,141.74,574.12,97.35,8.10" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,230.09,551.95,236.73,8.19">Lire: Lucene Image Retrieval -An Extensible Java CBIR Library</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C</forename><surname>Savvas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,151.92,563.08,256.62,8.10">proceedings of the 16th ACM International Conference on Multimedia</title>
		<meeting>the 16th ACM International Conference on Multimedia<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1085" to="1088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,132.67,585.04,337.98,8.10;11,141.74,596.08,286.08,8.10" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,265.25,585.04,120.18,8.10">Overview of the mpeg-7 standard</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">F</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sikora</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Puri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,391.49,585.04,79.15,8.10;11,141.74,596.08,156.07,8.10">IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="688" to="695" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,132.67,607.12,338.05,8.10;11,141.74,618.07,318.36,8.10" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,279.17,607.12,187.87,8.10">Textural features corresponding to visual perception</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Tamura</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Yamawaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,141.74,618.07,193.38,8.10">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="460" to="472" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,132.67,629.11,337.95,8.10;11,141.74,640.15,328.92,8.10;11,141.74,651.07,328.88,8.10;11,141.74,662.11,328.85,8.10;11,141.74,673.15,24.09,8.10" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,284.45,629.11,186.17,8.10;11,141.74,640.15,182.55,8.10">Cedd: Color and edge directivity descriptor. a compact descriptor for image indexing and retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Chatzichristofis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Boutalis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,202.88,651.07,267.74,8.10;11,141.74,662.11,63.80,8.10">Proceedings of the 6th International Conference on Computer Vision Systems, ICVS 2008</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Gasteratos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vincze</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Tsotsos</surname></persName>
		</editor>
		<meeting>the 6th International Conference on Computer Vision Systems, ICVS 2008<address><addrLine>Santorini, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008-05">May. 2008</date>
			<biblScope unit="volume">5008</biblScope>
			<biblScope unit="page" from="312" to="322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,132.67,149.99,337.77,8.10;12,141.74,161.03,328.84,8.10;12,141.74,172.07,329.12,8.10;12,141.74,182.99,115.21,8.10" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,284.09,149.99,186.34,8.10;12,141.74,161.03,128.16,8.10">Fcth: Fuzzy color and texture histogram a low level feature for accurate image retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Chatzichristofis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Boutalis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,286.46,161.03,184.12,8.10;12,141.74,172.07,225.41,8.10">Proceedings of the 9th International Workshop on Image Analysis for Multimedia Interactive Services, WIAMIS</title>
		<meeting>the 9th International Workshop on Image Analysis for Multimedia Interactive Services, WIAMIS<address><addrLine>Klagenfurt, Austria</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2008-05">2008. May. 2008</date>
			<biblScope unit="page" from="191" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,132.67,194.03,337.83,8.10;12,141.74,205.07,328.88,8.10;12,141.74,215.99,179.63,8.10" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,344.23,194.03,126.27,8.10;12,141.74,205.07,310.00,8.10">Investigating the behavior of compact composite descriptors in early fusion, late fusion, and distributed image retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Chatzichristofis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Arampatzis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Boutalis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,457.64,205.07,12.98,8.10;12,141.74,215.99,54.03,8.10">Radioengineering</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="725" to="733" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,132.67,227.03,338.19,8.10;12,141.74,238.07,328.94,8.10;12,141.74,248.90,320.54,8.19" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,354.55,227.03,116.31,8.10;12,141.74,238.07,34.32,8.10">Image indexing using color correlograms</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zabih</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,197.14,238.07,273.54,8.10;12,141.74,248.90,85.00,8.18">Proceedings of the 1997 Conference on Computer Vision and Pattern Recognition, CVPR &apos;97</title>
		<meeting>the 1997 Conference on Computer Vision and Pattern Recognition, CVPR &apos;97<address><addrLine>San Juan, Puerto Rico</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="1997-06">June. 1997</date>
			<biblScope unit="volume">00</biblScope>
			<biblScope unit="page" from="762" to="768" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,132.67,260.03,337.91,8.10;12,141.74,271.10,166.69,8.10" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,236.81,260.03,229.66,8.10">Quad Trees: A Data Structure for Retrieval on Composite Keys</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Bentley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,141.74,271.10,59.60,8.10">Acta Informatica</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="1974">1974</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
