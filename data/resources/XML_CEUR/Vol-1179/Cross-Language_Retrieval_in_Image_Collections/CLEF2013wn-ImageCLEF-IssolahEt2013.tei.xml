<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,152.28,65.79,310.86,12.90;1,223.00,83.72,169.37,12.90">SIFT, BoW architecture and one-against-all Support vector machine</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,192.28,120.96,74.64,9.96"><forename type="first">Mohamed</forename><surname>Issolah</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">I3S Lab -UMR 7271 UNS-CNRS 2000</orgName>
								<address>
									<addrLine>route des Lucioles -Les Algorithmes -bt. Euclide B</addrLine>
									<postCode>06900</postCode>
									<settlement>Sophia Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,274.30,120.96,66.20,9.96"><forename type="first">Diane</forename><surname>Lingrand</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">I3S Lab -UMR 7271 UNS-CNRS 2000</orgName>
								<address>
									<addrLine>route des Lucioles -Les Algorithmes -bt. Euclide B</addrLine>
									<postCode>06900</postCode>
									<settlement>Sophia Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,348.52,120.96,74.58,9.96"><forename type="first">Frederic</forename><surname>Precioso</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">I3S Lab -UMR 7271 UNS-CNRS 2000</orgName>
								<address>
									<addrLine>route des Lucioles -Les Algorithmes -bt. Euclide B</addrLine>
									<postCode>06900</postCode>
									<settlement>Sophia Antipolis</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,152.28,65.79,310.86,12.90;1,223.00,83.72,169.37,12.90">SIFT, BoW architecture and one-against-all Support vector machine</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">21E7E5CC51A19668FB53CD3E59ABD628</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For this first participation to ImageClef Plant Identification, we build on the reference Bag-of-Word framework (BoW). We extract Points-of-Interest (PoI) using the SIFT detector in every image and describe each local feature with the SIFT descriptor. The visual dictionary is built with a K-means algorithm of 100 clusters on the local features. Each image is then represented by its histogram onto the dictionary using hard-assignment strategy. We classify the images with as many binary one-against-all Support Vector Machines as the number of plant classes per organ types. Our aim is to evaluate for the plant identification task a classic baseline of multi-class image categorization. Our first results illustrate how difficult this task is and that a framework which has become a standard baseline for classifying general image datasets is not immediately relevant on Plant Identification data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Our system</head><p>Our system for ImageClef Plant Identification task <ref type="bibr" coords="1,361.94,394.96,10.51,9.96" target="#b0">[1]</ref> is built on the reference Bag-of-Word framework (BoW) and a set of binary Support Vector Machines. We use the XML metadata file provided with the images to extract information as Type of content or Background type. Let us now detail our settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Feature extraction and Image description</head><p>We extract Points-of-Interest (PoI) using both the SIFT detector and the SIFT descriptor in each image. We extract about 1000 points in each image, with standard settings of Opencv C++ library:</p><p>-Number of layers per Octave: 3 -The minimum threshold to consider a point as PoI: 0.04 -σ of Gaussian: 1.6</p><p>Then we build a visual dictionary using a K-means where K is set to 100. Finally we represent each image by its histogram obtained by the hard assignment of each local feature to BoW clusters. The histogram is normalized by the size of the BoW.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Learning</head><p>We build one-against-all SVMs for each plant class and for each organ type and we exploit the XML metadata provided by the Challenge during the training phase. We thereby identify type of content information to train separately organoriented SVMs. The same SVM configuration is used for any organ:</p><p>-C = 100 -The kernel type is LINEAR -Number of iteration = 10000</p><p>In the end, we obtain a trained SVM per class of plant and per organ type among:</p><formula xml:id="formula_0" coords="2,140.99,200.36,119.81,64.89">-Entire -Stem -Fruit -Flower -Leaf NaturalBackground -Leaf SheetAsBackground</formula><p>SVM outputs are organized into vectors, one vector per organ type, as depicted in figure 1 In 2013 dataset, the max number of plant classes is n = 250.</p><formula xml:id="formula_1" coords="2,220.64,333.95,174.08,59.98">      classc 1 1 classc 1 2 classc 1 3 . . . classc 1 n             classc 2 1 classc 2 2 classc 2 3 . . . classc 2 n       . . .       classc 6 1 classc 6 2 classc 6 3 . . . classc 6 n      </formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Confidence computation</head><p>For one test image, our system performs keypoint extraction and description, then from the XML file associated to the test image, we extract organ and type information. We then classify the test image histogram using all the SVMs corresponding to the associated organ. For example, if the organ of the image is Leaf and the type is SheetAsBackground, our system executes the set of n SVMs corresponding to Leaf vector. The final class corresponds to the class associated with the SVM providing the highest confidence score.</p><p>Figure <ref type="figure" coords="2,184.47,605.45,4.98,9.96" target="#fig_1">2</ref> summarizes all the steps of our system. For the first configuration, different parameters are to be determined but the main one to choose is K, the number of clusters. The higher the number of clusters, the more discriminant the Bag-of-Words histogram representation. The number of clusters is fixed to 100 because the K-means configuration is common to all different organs and plant classes, it must preserve the generalization capability of the BoW representation and must require a reasonable computation time.</p><p>The same holds for the SVMs which have common settings for all organs and all classes in our baseline implementation. The bigger the parameter C, the lower the error rate. C is set to 100.</p><p>The Clustering is the most demanding step in terms of computational intensity. In order to reduce its impact, only 100 points among the 1000 extracted in each image are considered during the clustering. The keypoints to be discarded are chosen randomly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Resources</head><p>For implementation we use the OpenCV libraries which offers different type of detection and different methods for learning. The implementation language is C++ for efficiency and speed. The LibXML libraries are used for XML parsing.</p><p>The program has been launched on a server made of 2 Processors Intel Xeon X5675 at 3,06GHz, 6 Cores and 24GB RAM DDR3-1333MHz.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Results</head><p>The goal of our proposition is to evaluate a standard framework for image categorization in multimedia databases, using the classic local feature, SIFT, (both for the detector and the descriptor), a BoW architecture and as many one-againstall SVMs as binary classification required.</p><p>The results are presented in figure <ref type="figure" coords="4,287.53,317.05,3.87,9.96">3</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Conclusion</head><p>As a first participation to ImageClef Plant Identification challenge, we have implemented a standard framework which proved to be powerful for image categorization in multimedia database. To do so, we have considered SIFT algorithm for both local feature detection and description, then represented each image with its histogram on the visual dictionary. The resulting histograms for each image are classified by one-against-all SVMs, one SVM per plant class and per organ. Despite the efficiency of such architecture for image categorization, the results are somewhat disappointing on ImageClef Plant Identification task. We are currently working on how to optimize all the parameters of our method to achieve better results. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,134.77,413.89,345.81,8.96;2,134.77,424.85,306.04,8.96;2,134.77,435.81,2.56,8.96"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. Each vector contains the classification scores obtained with n one-against-all SVMs (one SVM score per plant class) with respect to one of the 6 organs . .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,242.30,374.47,130.72,8.96;3,134.81,66.91,453.45,283.33"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Global schema of system</figDesc><graphic coords="3,134.81,66.91,453.45,283.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,240.11,301.21,135.14,8.96;5,134.85,66.02,345.64,210.94"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. NaturalBackgroundScores</figDesc><graphic coords="5,134.85,66.02,345.64,210.94" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="6,134.85,217.57,345.39,211.11"><head></head><label></label><figDesc></figDesc><graphic coords="6,134.85,217.57,345.39,211.11" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,136.16,317.05,359.26,94.97"><head></head><label></label><figDesc>, 4 and 5</figDesc><table coords="4,136.16,360.66,359.26,51.36"><row><cell>Run name</cell><cell>runfilename</cell><cell cols="2">Entire Flower Fruit Leaf Stem NaturalBackground</cell></row><row><cell cols="3">I3S Run 1 1368034466828 new 100 0.017 0.023 0.041 0.038 0.025</cell><cell>0.026</cell></row><row><cell cols="3">I3S Run 2 1368165605197 new2 100 0.017 0.023 0.041 0.038 0.025</cell><cell>0.026</cell></row><row><cell></cell><cell cols="2">Fig. 3. Results on ImageClef 2013 with respect to the organs</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,138.35,358.50,342.20,8.96;5,146.92,369.46,333.68,8.96;5,146.92,380.41,324.85,8.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,403.50,369.46,77.09,8.96;5,146.92,380.41,160.79,8.96">Imageclef 2013: the vision, the data and the open challenges</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thomee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Paredes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zellhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">G</forename><surname>Varea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Cazorla</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,315.69,380.41,95.69,8.96">Proceedings CLEF 2013</title>
		<meeting>CLEF 2013</meeting>
		<imprint>
			<publisher>LNCS</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
