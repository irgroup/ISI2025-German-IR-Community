<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,160.80,65.77,293.62,12.91;1,215.88,83.77,183.55,12.91">Fast filtering techniques in medical image classification and retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,208.56,121.56,39.05,8.85"><forename type="first">Xin</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Advanced Medical Equipment Research Center</orgName>
								<orgName type="laboratory">Medical Image Information Laboratory</orgName>
								<orgName type="institution" key="instit1">Shanghai Advanced Research Institute</orgName>
								<orgName type="institution" key="instit2">Chinese Academy of Sciences</orgName>
								<address>
									<addrLine>99 Haike Road, Building No. 3</addrLine>
									<postCode>201210</postCode>
									<settlement>Pudong, Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,255.84,121.56,50.99,8.85"><forename type="first">Miaofei</forename><surname>Han</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Advanced Medical Equipment Research Center</orgName>
								<orgName type="laboratory">Medical Image Information Laboratory</orgName>
								<orgName type="institution" key="instit1">Shanghai Advanced Research Institute</orgName>
								<orgName type="institution" key="instit2">Chinese Academy of Sciences</orgName>
								<address>
									<addrLine>99 Haike Road, Building No. 3</addrLine>
									<postCode>201210</postCode>
									<settlement>Pudong, Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,315.39,121.56,45.13,8.85"><forename type="first">Yanli</forename><surname>Song</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Advanced Medical Equipment Research Center</orgName>
								<orgName type="laboratory">Medical Image Information Laboratory</orgName>
								<orgName type="institution" key="instit1">Shanghai Advanced Research Institute</orgName>
								<orgName type="institution" key="instit2">Chinese Academy of Sciences</orgName>
								<address>
									<addrLine>99 Haike Road, Building No. 3</addrLine>
									<postCode>201210</postCode>
									<settlement>Pudong, Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,368.53,121.56,38.27,8.85"><forename type="first">Qiang</forename><surname>Li</surname></persName>
							<email>liqiang@sari.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Advanced Medical Equipment Research Center</orgName>
								<orgName type="laboratory">Medical Image Information Laboratory</orgName>
								<orgName type="institution" key="instit1">Shanghai Advanced Research Institute</orgName>
								<orgName type="institution" key="instit2">Chinese Academy of Sciences</orgName>
								<address>
									<addrLine>99 Haike Road, Building No. 3</addrLine>
									<postCode>201210</postCode>
									<settlement>Pudong, Shanghai</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,160.80,65.77,293.62,12.91;1,215.88,83.77,183.55,12.91">Fast filtering techniques in medical image classification and retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8D9B84183193D03DD7CDBD2FC26DF5F1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This article presents the participation of the MIILab (Medical Image Information Laboratory) group in ImageCLEFmed2013. There are three types of tasks for ImageCLEFmed2013: modality classification, image retrieval and compound-image separation. Image modality classification and medical image retrieval are targeted according to MIILab's research interest. The main goal is to perform a feasibility test on applying existing techniques on new applications, such as applying image denoising techniques on image retrieval and classification. Both global features and local features were employed. Fast filtering techniques were used to obtain global features on color, shape and texture. These global features serves to perform a pre-classification on images. Both low-level and high-level local features were extracted. Bags of features model was used to build final feature vector. Both kNN and SVM classifiers were tried out in modality classification task. Reciprocal kNN was used to perform result fusion in image retrieval task. The modality classification task was decomposed into a compound image classification and a non-compound image classification. Our approaches achieved 89.9% classification accuracy on training data and 85.1% on testing data for compound image classification. For non compound image classification, accuracy is around 68.3% on training data and 67.7% on testing data. The overall classification accuracy is around 65% on 31 classes. False alarms are mainly from large classes such as compound images (312), X-ray images (101) and organ photos (63), but accuracy per class shows that performance bottleneck also comes from small/medium classes with large content diversity such as statistic figures, chemical structure and 3D images. Best result was around 80% (IBM research lab). For the image retrieval task, one baseline using SURFContext+BoF was submitted and the corresponding MAP (mean average precision) is 0.0086. Even best visual retrieval run obtained only a MAP of 0.018, which is still not comparable with textual approaches (average score 0.2).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Cross Language Evaluation Forum (CLEF) organizes contests for the evaluation of information retrieval systems each year. The image retrieval track of CLEF is called ImageCLEF<ref type="foot" coords="2,255.48,66.95,3.97,6.97" target="#foot_0">1</ref> . ImageCLEFmed has been part of ImageCLEF focusing on medical images <ref type="bibr" coords="2,248.01,81.00,10.55,8.85" target="#b0">[1]</ref> since 2004. More about the ImageCLEF tasks and results in 2013 can be found in <ref type="bibr" coords="2,272.76,93.00,10.56,8.85" target="#b1">[2,</ref><ref type="bibr" coords="2,284.88,93.00,7.04,8.85" target="#b2">3]</ref>.</p><p>MIILab (Medical Image Information Laboratory) is a medical imaging group with research focus in medical imaging technology, particularly those tightly related to advanced medical imaging equipments. This is the first year that MIILab participates in the medical imaging tasks of ImageCLEF (ImageCLEFmed). The main objective is to perform a feasibility test on applying existing techniques on new applications, such as applying image denoising techniques on image retrieval and classification.</p><p>Two tasks of ImageCLEFmed2013 fit MIILab's research interests, i.e.: image modality classification and medical image retrieval. The fundamental difficulty for ImageCLEFmed tasks is the diversity of image content. It is due to the fact that the collection contains not only biomedical images, but also figures, mathematic formulas, tables, non-clinical photos, etc. Such a diversity of content generate numerous types of similarity which are difficult to cover in feature space. In this paper, we propose to use fast filtering techniques (monochrome filter, Laplace filter, and line/dot filter <ref type="bibr" coords="2,304.84,273.60,10.82,8.85" target="#b3">[4]</ref>) and BoBB(bags of bounding box) to address this problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>This section describes the basic techniques and collections used by MIILab in ImageCLEFmed2013. All runs submitted to ImageCLEFmed2013 are purely visual-based. Techniques used can be divided into: 1) pre-processing, 2) features, 3) classifiers and 4) fusion strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Techniques used</head><p>Pre-processing Images in ImageCLEFmed2013 collections are from journal papers, which were mainly converted into JPEG (Joint Photographic Experts Group) format. Certain monochrome images became color images after the conversion, others changed their dynamic range. Hence, images are no longer comparable between them, which introduces additional complication to the task. Normalization on images is required before any other operations take place, and all images are converted into a unified range.</p><p>Another issue is the color space. By default JPEG use the RGB (red, green, blue) color space. However, the RGB color spaces is well known for not being tightly corresponded to human color perception and thus less used in image retrieval and classification <ref type="bibr" coords="2,252.06,560.52,9.99,8.85" target="#b4">[5]</ref>. On the other hand, it has also been proved that the HSV (Hue, Saturation, Value) color space can give promising results in image retrieval <ref type="bibr" coords="2,173.91,584.40,10.55,8.85" target="#b5">[6,</ref><ref type="bibr" coords="2,186.02,584.40,7.04,8.85" target="#b6">7]</ref>.</p><p>Therefore, the pre-processing step consists of 2 parts. The HSV (Hue, Saturation, Value) color space decomposition and a 0-255 normalization on each channel.</p><p>Features In this paper, both global features and local features were employed. Fast filtering techniques, such as monochrome filter, line/dot filter <ref type="bibr" coords="3,427.24,132.36,9.99,8.85" target="#b3">[4]</ref>, were applied to obtain global features on color, shape and texture. First to third statistical moments were also extracted in certain subregions as low-level local features. SURFContext [8] (an early fusion version of SURF <ref type="bibr" coords="3,360.26,168.24,10.55,8.85" target="#b8">[9]</ref> and Shape Context <ref type="bibr" coords="3,461.21,168.24,15.56,8.85" target="#b9">[10]</ref>) were implemented to obtain high-level local features. The number of visual keywords is set to be 3000. The classical BoF (bags of features) approach was used to form the final feature vector.</p><p>Classifiers Classifiers were only used in modality classification task. Both kNN (k-Nearest Neighbors) and SVM (Support Vector Machine) classifiers were employed, but the latter significantly outperformed the former. Therefore, only SVM classifier-based runs were submitted for evaluation.</p><p>Two-level classification is performed: compound image classification and modality classification. The former uses only global features and low-level local features (first to third statistical moments, surface, ratio) of all detectable bounding box. The bounding box detection is based on open source toolbox and the final feature space is built with BoBB. The latter is based on high-level local features with classical BoF approach. Open source machine learning libraries (weka, libsvm) were used with a grid search for parameter selection.</p><p>Fusion Techniques Fusion techniques were used in image retrieval task to combine result lists of different techniques. Classical fusion strategies, such as combSUM, combMNZ, combSUM(2)MAX were used with a score normalization based on rank-number based logarithmic weighting function <ref type="bibr" coords="3,408.79,414.48,14.67,8.85" target="#b10">[11]</ref>. Recently, a reciprocal kNN based fusion technique was reported to obtain promising result in nature image classification and retrieval <ref type="bibr" coords="3,330.89,438.48,14.68,8.85" target="#b11">[12]</ref>. One of the advantage of using this technique is that no score normalization is required. This technique is implemented and labeled as combRKNN in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Image Collections</head><p>306'538 medical images were available for ImageCLEFmed 2013. Among them, 2'905 images were labeled with modality information and were provided as training data, and 2'582 images were provided without modality information as test data for modality classification task. Details about the setup and collections of the ImageCLEFmed tasks can be found in an overview paper <ref type="bibr" coords="3,405.97,555.12,9.98,8.85" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>This section describes our results for the two medical tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Modality Classification</head><p>For modality classification task, evaluation is based on the percentage of correctly classified images. For runs of various technique approaches (textual, visual, mixed), the best accuracy and average accuracy together with our results are shown in Table <ref type="table" coords="4,220.68,127.08,3.90,8.85" target="#tab_0">1</ref>. The average accuracy per class is shown in Table <ref type="table" coords="4,372.24,282.48,3.89,8.85" target="#tab_1">2</ref>. This year we separate compound image classification as an independent task. Once an image was not classified as compound image, it was passed to a non-compound classification for the rest 30 classes.</p><p>The overall classification accuracy is around 65% on 31 classes. False alarms are mainly from large classes, such as compound images (COMP), X-ray images (DRXR), etc. Actually, the accuracy in % of COMP and DRXR are around 68%, which limited the overall performance. Certain other classes obtained scores below overall accuracy and became also performance bottleneck. These classes usually contains image of large diversity, such as organ photos (DVOR), nonclinical photos (GNCP), statistic figures (GFIG), tables and forms (GTAB), and 3D images (D3DR). Previous experience shows that compound image classification is of key importance for modality classification. Two specificities exist for compound image classification: 1) compound image share the same image content with 30 other image classes; 2) about 40% of the whole collection are compound images. Hence, a big percentage of incorrectly classified images come from the class of compound images.</p><p>Through experiments, it is found that high-level semantic features can hardly provide useful information for compound image classification. However, visual perception can easily make a distinction, as a compound image is consisted of several unconnected figures, invisible bounding boxes are produced in human brain for each figure. Based on connected region detection toolbox in Matlab, the 10 biggest bounding boxes without overlapping were extracted from the value channel of image, and 5 biggest bounding boxes without overlapping were extracted from hue and saturation channels of image. The whole image was always considered as a bounding box. For each bounding box, height, width, ratio, surface, first to third statistical moments (mean, variance, skewness) were used to build a descriptor. Hence, 7 features per bounding box were extracted from in total 21 bounding boxes, the final dimension of feature space is 147. We call this approach BoBB-based approach. As compound image classification is a one-to-one classification problem, only the SVM classifier was applied on BoBB feature space. A grid searching on cost and value was used for parameter selection. Figure <ref type="figure" coords="6,211.39,116.88,4.26,8.85">3</ref>.1 shows the classification performance obtained by various BoBB strategies. Even color information was discarded, applying BoBB graylevel image (the value channel of image) can already obtain around 85% accuracy. Adding color features(approach 2), removing background (approach 3), enhancing connectivity (approach 4) can all improve the performance. Adding color or tensor features makes classifier more robust. Removing background eliminated false alarms, and archived the best improvement. Combining all these features, the best BoBB-based approach achieved 89.0% classification accuracy on training data and 85.1% on testing data using SVM classifier.</p><p>In non-compound classification, SURFContext + BoF approach was used. Both SVM classifiers and classical kNN classifiers were tested on BoF feature space. However, experiments on training data has shown that SVM classifiers significantly outperformed kNN classifiers (69.1% vs 48.1%). Therefore, only two runs using SVM classifiers were submitted to the modality classification task. Accuracy by class on training data shows most diagnosis image classes obtained over 80% accuracy, but on test data, the scores are around 70%, which shows the performance of this approach is not stable. Classes with large content diversity constantly obtained poor performance, Furthermore improvement is required on these classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Image-based Retrieval</head><p>For the image-based retrieval task, Mean average precision (MAP), binary preference (Bpref), and early precision (P10, P30) are shown as measures. Only one baseline (sari SURFContext HI baseline) using was submitted and the corresponding MAP is 0.0086. Further tests on fusion strategies failed to improve the performance, because the runs to be fused themselves contain too few relevant results. The textual runs still largely outperforms the visual runs for both best score and average score. Results of our run and best runs of various nature are shown in Table <ref type="table" coords="6,204.01,493.20,3.90,8.85" target="#tab_2">3</ref>.  2) convert image to HSV space and apply BoBB approach; 3) using Laplace filter to remove background area, and then apply BoBB approach only on content region; 4) using structure tensor to enhance connectivity, and then apply BoBB approach; 5) combining 3) and 4); 6) combining 2), 3), and 4).</p><p>Apply fast filtering techniques to reduce the dimension and diversity of data was tried out. As most query images are diagnosis images, the goal is to reject those images which are completely not related to the query image in processing. Online query requires a quick indexing and search. Line/dot filter, Laplace filter, monochrome filter can process one image within 0.1 second. We used them to reject unwanted images from the huge database by the following order shown in Table <ref type="table" coords="8,162.49,140.76,3.90,8.85" target="#tab_3">4</ref>. In our experiments, we define the region where standard derivation is smaller than a threshold t. When all images were normalized to 0-255, t was set to be 5. Using line filter, the area of line-like structure can be obtained. If the area of whole image is equal to the sum of the area of line-like structure and the area of background, it is labeled as "all line". All line rejection aims to reject images containing only curves and lines. The risk of this filter is that it rejects also diagnostic printed signals, such as electrocardiography, etc. However, this is in general a safe solution, as query images are mainly diagnosis image. Figure rejection aims to reject the man-made images, such as flowchart, system overviews, screenshots, etc. The Laplace filter was applied and where laplace equals 0 were located as "even" regions. If the area of whole image is equal to the sum of the area of line-like structure, the area of even regions and the area of background, it is labeled as "figures".</p><p>The third round, images containing only text, such as program listing, DNA sequences, tables and formulas, are rejected. This step is called "all text rejection". A orientation histogram was calculated on the line-like structures. Those images containing high repeatability in orientation histogram were rejected.</p><p>Finally, only 92'785 images are left for retrieval, 66% of data are quickly rejected. A comparison is made between the 92'785 images and the qrel file. There are 18'961 non identical image ids in qrel file, 17'415 of 18'961 (about 92%) are found in 92'785 images. All image labeled as "relevant" are not lost. In other words, fast filtering techniques reduced largely the diversity of content, but has little negative impact on image retrieval performance. This approach can be helpful to reduce the quantity of data for all the groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Conclusions</head><p>This paper describes the techniques used and results obtained by the MIILab group in ImageCLEFmed 2013. Two tasks are targeted: modality classification and medical image retrieval. The techniques used by MIILab are purely visualbased. Classical BoF approach based on SURFContext was used as baselines, and several variants were tried to improve the performance. Bags of bounding boxes-based approach was proved to be useful for compound image classification. Fast filtering techniques were applied to reduce the scale of data, and was proved to be a safe strategy. For both modality classification and image retrieval tasks, MIILab was ranked in the middle among all the groups. This is the first year for MIILab to participate ImageCLEFmed, there is still room for performance improvement.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="7,134.76,522.31,345.79,7.96;7,134.76,533.23,345.74,7.96;7,134.76,544.27,345.87,7.96;7,134.76,555.19,345.83,7.96;7,134.76,566.11,345.81,7.96;7,134.76,577.16,199.12,7.96"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. The performance obtained with grid searching approach on training data. From left up to right bottom: 1) convert image to gray-level image and apply BoBB approach; 2) convert image to HSV space and apply BoBB approach; 3) using Laplace filter to remove background area, and then apply BoBB approach only on content region; 4) using structure tensor to enhance connectivity, and then apply BoBB approach; 5) combining 3) and 4); 6) combining 2), 3), and 4).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,147.24,157.51,321.00,83.92"><head>Table 1 .</head><label>1</label><figDesc>Results of the runs for the modality classification task.</figDesc><table coords="4,147.24,177.91,321.00,63.52"><row><cell>Run ID</cell><cell cols="2">best accuracy in % average accuracy in %</cell></row><row><cell>mixed run</cell><cell>81.68</cell><cell>61.97</cell></row><row><cell>textual run</cell><cell>64.17</cell><cell>50.79</cell></row><row><cell>visual run</cell><cell>80.79</cell><cell>61.24</cell></row><row><cell>sari modality baseline</cell><cell>66.46</cell><cell></cell></row><row><cell>sari modality CCTBB DRxxDict</cell><cell>65.60</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,136.20,133.39,366.59,400.36"><head>Table 2 .</head><label>2</label><figDesc>Results of the runs on each class.</figDesc><table coords="5,136.20,162.91,366.59,370.84"><row><cell>Run id</cell><cell></cell><cell cols="4">sari modality baseline sari modality CCTBB DRxxDict</cell></row><row><cell>class</cell><cell cols="4">number of images false alarm accuracy in % false alarm</cell><cell>accuracy in %</cell></row><row><cell>COMP</cell><cell>1014</cell><cell>312</cell><cell>69.2</cell><cell>320</cell><cell>68.4</cell></row><row><cell>D3DR</cell><cell>26</cell><cell>16</cell><cell>38.5</cell><cell>17</cell><cell>34.6</cell></row><row><cell>DMEL</cell><cell>20</cell><cell>16</cell><cell>20.0</cell><cell>17</cell><cell>15.0</cell></row><row><cell>DMFL</cell><cell>33</cell><cell>7</cell><cell>78.8</cell><cell>9</cell><cell>72.7</cell></row><row><cell>DMLI</cell><cell>121</cell><cell>23</cell><cell>81.0</cell><cell>28</cell><cell>76.9</cell></row><row><cell>DMTR</cell><cell>20</cell><cell>8</cell><cell>60.0</cell><cell>5</cell><cell>75.0</cell></row><row><cell>DRAN</cell><cell>18</cell><cell>5</cell><cell>72.2</cell><cell>5</cell><cell>72.2</cell></row><row><cell>DRCO</cell><cell>1</cell><cell>1</cell><cell>0 . 0 0</cell><cell>1</cell><cell>0 . 0 0</cell></row><row><cell>DRCT</cell><cell>186</cell><cell>25</cell><cell>86.6</cell><cell>28</cell><cell>84.9</cell></row><row><cell>DRMR</cell><cell>90</cell><cell>27</cell><cell>70.0</cell><cell>26</cell><cell>71.1</cell></row><row><cell>DRPE</cell><cell>3</cell><cell>2</cell><cell>33.3</cell><cell>2</cell><cell>33.3</cell></row><row><cell>DRUS</cell><cell>85</cell><cell>12</cell><cell>85.9</cell><cell>16</cell><cell>81.2</cell></row><row><cell>DRXR</cell><cell>344</cell><cell>101</cell><cell>70.6</cell><cell>112</cell><cell>67.4</cell></row><row><cell>DSEC</cell><cell>96</cell><cell>33</cell><cell>65.6</cell><cell>32</cell><cell>66.7</cell></row><row><cell>DSEE</cell><cell>9</cell><cell>4</cell><cell>55.6</cell><cell>5</cell><cell>44.4</cell></row><row><cell>DSEM</cell><cell>1</cell><cell>0</cell><cell>100.0</cell><cell>0</cell><cell>100.0</cell></row><row><cell>DVDM</cell><cell>28</cell><cell>16</cell><cell>42.9</cell><cell>13</cell><cell>53.6</cell></row><row><cell>DVEN</cell><cell>20</cell><cell>5</cell><cell>75.0</cell><cell>5</cell><cell>75.0</cell></row><row><cell>DVOR</cell><cell>92</cell><cell>63</cell><cell>31.5</cell><cell>61</cell><cell>33.7</cell></row><row><cell>GCHE</cell><cell>19</cell><cell>12</cell><cell>36.8</cell><cell>14</cell><cell>26.3</cell></row><row><cell>GFIG</cell><cell>102</cell><cell>46</cell><cell>54.9</cell><cell>40</cell><cell>60.8</cell></row><row><cell>GFLO</cell><cell>20</cell><cell>13</cell><cell>35.0</cell><cell>13</cell><cell>35.0</cell></row><row><cell>GGEL</cell><cell>30</cell><cell>15</cell><cell>50.0</cell><cell>13</cell><cell>56.7</cell></row><row><cell>GGEN</cell><cell>21</cell><cell>16</cell><cell>23.8</cell><cell>11</cell><cell>47.6</cell></row><row><cell>GHDR</cell><cell>54</cell><cell>19</cell><cell>64.8</cell><cell>25</cell><cell>53.7</cell></row><row><cell>GMAT</cell><cell>5</cell><cell>5</cell><cell>0 . 0 0</cell><cell>5</cell><cell>0 . 0 0</cell></row><row><cell>GNCP</cell><cell>37</cell><cell>22</cell><cell>40.5</cell><cell>24</cell><cell>35.1</cell></row><row><cell>GPLI</cell><cell>22</cell><cell>10</cell><cell>54.5</cell><cell>3</cell><cell>86.4</cell></row><row><cell>GSCR</cell><cell>20</cell><cell>10</cell><cell>50.0</cell><cell>10</cell><cell>50.0</cell></row><row><cell>GSYS</cell><cell>16</cell><cell>7</cell><cell>56.3</cell><cell>9</cell><cell>43.8</cell></row><row><cell>GTAB</cell><cell>29</cell><cell>15</cell><cell>48.3</cell><cell>19</cell><cell>34.5</cell></row><row><cell>overall</cell><cell>2582</cell><cell>866</cell><cell>66.5</cell><cell>888</cell><cell>65.6</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,147.48,527.83,320.22,73.36"><head>Table 3 .</head><label>3</label><figDesc>Results of the runs for the image-based topics.</figDesc><table coords="6,147.48,548.11,320.22,53.08"><row><cell>Run</cell><cell>run type MAP Bpref P10 P30</cell></row><row><cell>best textual run (XRCE)</cell><cell>Textual 0.3196 0.2982 0.3886 0.2686</cell></row><row><cell>best visual run</cell><cell>Visual 0.0185 0.0361 0.0629 0.0581</cell></row><row><cell>sari SURFContext HI baseline</cell><cell>Visual 0.0086 0.0181 0.0429 0.0352</cell></row><row><cell>best mixed run</cell><cell>Mixed 0.3196 0.2983 0.3886 0.2686</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,158.64,173.47,297.89,61.60"><head>Table 4 .</head><label>4</label><figDesc>Number of images rejected by fast filtering approach.</figDesc><table coords="8,158.64,193.75,297.89,41.32"><row><cell>filtering</cell><cell>rejected</cell><cell>left</cell></row><row><cell>all line rejection</cell><cell>117'228 189'310</cell><cell></cell></row><row><cell>figure rejection</cell><cell cols="2">62'237 127'073</cell></row><row><cell>all text rejection</cell><cell></cell><cell>34'288 92'785</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.72,606.18,117.04,8.78"><p>http://www.imageclef.org/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,142.88,216.43,337.62,7.96;9,151.56,227.35,328.83,7.96;9,151.56,238.39,328.98,7.96;9,151.56,249.31,329.05,7.96;9,151.56,260.23,294.89,7.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,311.39,216.43,169.11,7.96;9,151.56,227.35,100.72,7.96">The CLEF cross-language image retrieval track (ImageCLEF) 2004</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,268.36,238.39,212.18,7.96;9,151.56,249.31,222.46,7.96">Multilingual Information Access for Text, Speech and Images: Result of the fifth CLEF evaluation campaign</title>
		<title level="s" coord="9,450.30,249.31,30.31,7.96;9,151.56,260.23,135.35,7.96">Lecture Notes in Computer Science (LNCS</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Kluck</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Magnini</surname></persName>
		</editor>
		<meeting><address><addrLine>Bath, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3491</biblScope>
			<biblScope unit="page" from="597" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.89,270.79,337.69,7.96;9,151.56,281.83,329.11,7.96;9,151.56,292.76,133.32,7.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,214.80,281.83,183.82,7.96">Overview of the imageclef 2013 medical tasks</title>
		<author>
			<persName coords=""><forename type="first">Garcia</forename><surname>Seco De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,422.08,281.83,58.60,7.96;9,151.56,292.76,54.93,7.96">Working notes of CLEF 2013</title>
		<imprint>
			<date type="published" when="2013-09">September 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.88,303.31,337.66,7.96;9,151.56,314.23,328.98,7.96;9,151.56,325.16,328.86,7.96;9,151.56,336.20,328.97,7.96;9,151.56,347.12,328.94,7.96;9,151.56,358.04,328.91,7.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,453.24,314.23,27.30,7.96;9,151.56,325.16,229.54,7.96">Image-CLEF 2013: the vision, the data and the open challenges</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thomee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Paredes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zellhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Martinez Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Garcia Varea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Cazorla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,394.47,347.12,86.03,7.96;9,151.56,358.04,16.67,7.96">Proceedings of CLEF 2013</title>
		<title level="s" coord="9,174.88,358.04,166.33,7.96">Lecture Notes in Computer Science (LNCS</title>
		<editor>
			<persName><forename type="first">B</forename><surname>Caputo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Thomee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Villegas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Paredes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Zellhofer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Goeau</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Joly</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Martinez Gomez</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Garcia Varea</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">I</forename><surname>Cazorla</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename></persName>
		</editor>
		<meeting>CLEF 2013<address><addrLine>Velencia, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.88,368.60,337.67,7.96;9,151.56,379.64,328.91,7.96;9,151.56,390.56,41.08,7.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,260.41,368.60,220.15,7.96;9,151.56,379.64,205.04,7.96">Selective enhancement filters for nodules, vessels, and airway walls in two-and three-dimensional ct scans</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Doi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,363.73,379.64,63.85,7.96">Medical Physics</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2040" to="2051" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.88,401.12,337.68,7.96;9,151.56,412.04,329.11,7.96;9,151.56,422.96,235.37,7.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,374.26,401.12,106.30,7.96;9,151.56,412.04,297.84,7.96">A review of content-based image retrieval systems in medicine-clinical benefits and future directions</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Michoux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Bandon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Geissbuhler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,458.05,412.04,22.63,7.96;9,151.56,422.96,159.74,7.96">International Journal of Medical Informatics</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.88,433.52,337.61,7.96;9,151.56,444.56,328.98,7.96;9,151.56,455.48,193.67,7.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,263.90,433.52,216.60,7.96;9,151.56,444.56,52.62,7.96">VisualSEEk: a fully automated content-based image query system</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">F</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,231.71,444.56,248.83,7.96;9,151.56,455.48,40.83,7.96">The Fourth ACM International Multimedia Conference and Exhibition</title>
		<meeting><address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996-11">November 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.88,466.04,337.63,7.96;9,151.56,476.96,328.97,7.96;9,151.56,488.00,328.91,7.96;9,151.56,498.92,113.63,7.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,354.98,466.04,125.53,7.96;9,151.56,476.96,168.09,7.96">Content-based query of image databases: inspirations from text retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Squire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Pun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,448.26,476.96,32.27,7.96;9,151.56,488.00,328.91,7.96">Selected Papers from The 11th Scandinavian Conference on Image Analysis SCIA &apos;99)</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1193" to="1198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,268.75,498.92,127.44,7.96;9,139.32,509.48,341.17,7.96;9,151.56,520.40,112.76,7.96" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="9,193.47,509.48,232.55,7.96">Grid-based Medical Image Retrieval Using Local Features</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">K</forename><surname>Ersboll</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Johansen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">;</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">8</biblScope>
		</imprint>
		<respStmt>
			<orgName>University of Geneva</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="9,142.88,530.96,337.76,7.96;9,151.56,541.88,271.13,7.96" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,339.18,530.96,137.81,7.96">Speeded-up robust features (surf)</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Bay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ess</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,151.56,541.88,176.59,7.96">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">110</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="346" to="359" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.56,552.44,337.89,7.96;9,151.56,563.36,328.98,7.96;9,151.56,574.40,122.50,7.96" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,368.08,552.44,112.37,7.96;9,151.56,563.36,129.70,7.96">Shape matching and object recognition using shape contexts</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Greenspan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Puzicha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,289.54,563.36,191.00,7.96;9,151.56,574.40,68.44,7.96">IEEE transactions on pattern analysis and machine intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.55,584.96,337.95,7.96;9,151.56,595.88,329.00,7.96;9,151.56,606.80,188.45,7.96" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,317.73,584.96,162.78,7.96;9,151.56,595.88,109.75,7.96">Information fusion for combining visual and textual image retrieval</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Depeursinge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,285.35,595.88,195.21,7.96;9,151.56,606.80,78.84,7.96">20th IEEE International Conference on Pattern Recognition (ICPR)</title>
		<imprint>
			<date type="published" when="2010-08">August 2010</date>
			<biblScope unit="page" from="1590" to="1593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.55,69.67,337.93,7.96;10,151.56,80.71,328.90,7.96;10,151.56,91.63,329.00,7.96;10,151.56,102.55,171.16,7.96" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,358.95,69.67,121.53,7.96;10,151.56,80.71,31.97,7.96">Query specific fusion for image retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Cour</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metaxas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,151.56,91.63,172.60,7.96">European Conference on Computer Vision</title>
		<title level="s" coord="10,332.07,91.63,144.53,7.96">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Fitzgibbon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Perona</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Sato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="660" to="673" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
