<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,159.15,152.82,297.06,12.62;1,141.05,170.75,333.27,12.62;1,286.26,188.68,42.83,12.62">Scalable Concept Image Annotation Task: Winning Annotations with Context Dependent SVMs</title>
				<funder ref="#_aCWHnty">
					<orgName type="full">Research Agency ANR (Agence Nationale de la Recherche)</orgName>
				</funder>
				<funder ref="#_4Y5SHMK #_qhcDwSw">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,274.12,226.53,67.11,8.74"><forename type="first">Hichem</forename><surname>Sahbi</surname></persName>
							<email>hichem.sahbi@telecom-paristech.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">CNRS -TELECOM ParisTech</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">CNRS TELECOM ParisTech</orgName>
								<address>
									<addrLine>46 rue Barrault</addrLine>
									<postCode>75013</postCode>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,159.15,152.82,297.06,12.62;1,141.05,170.75,333.27,12.62;1,286.26,188.68,42.83,12.62">Scalable Concept Image Annotation Task: Winning Annotations with Context Dependent SVMs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">ECD491E7EE19D232783A868A354DA6F9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Context-Dependent Kernels</term>
					<term>Support Vector Machines</term>
					<term>Image Annotation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we describe the participation of CNRS TELE-COM ParisTech in the ImageCLEF 2013 Scalable Concept Image Annotation challenge. This edition promotes the use of many contextual cues attached to visual contents. Image collections are supplied with visual features as well as tags taken from different sources (web pages, etc.). Our framework is based on training support vector machines (SVMs) using a class of kernels referred to as context dependent. These kernels are designed by minimizing objective functions mixing visual features and their contextual cues resulting from surrounding tags. The results clearly corroborate the complementarity of tags and visual features and the effectiveness of these context dependent SVMs for image annotation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Conventionally, visual information search requires a preliminary step known as image annotation. The latter is a major challenge (see for instance <ref type="bibr" coords="1,421.93,525.43,15.50,8.74" target="#b15">[14,</ref><ref type="bibr" coords="1,439.08,525.43,12.73,8.74" target="#b34">33,</ref><ref type="bibr" coords="1,453.47,525.43,12.73,8.74" target="#b32">31,</ref><ref type="bibr" coords="1,467.87,525.43,12.73,8.74" target="#b24">23,</ref><ref type="bibr" coords="1,134.77,537.39,12.73,8.74" target="#b25">24,</ref><ref type="bibr" coords="1,149.16,537.39,12.73,8.74" target="#b18">17,</ref><ref type="bibr" coords="1,163.54,537.39,7.75,8.74" target="#b6">5,</ref><ref type="bibr" coords="1,172.96,537.39,7.75,8.74" target="#b9">8]</ref>) and consists in assigning list of keywords (a.k.a concepts) to given visual content. These concepts may either correspond to physical entities (pedestrians, cars, etc.) or to high level aspects resulting from the interaction of many entities into scenes (races, fights, etc.). In both cases, image annotation is challenging due to the perplexity when assigning concepts to scenes especially when the number of possible concepts is taken from a large vocabulary and when analyzing highly semantic contents.</p><p>Existing annotation methods (see for instance <ref type="bibr" coords="1,337.82,633.20,10.52,8.74" target="#b6">[5,</ref><ref type="bibr" coords="1,350.00,633.20,12.45,8.74" target="#b18">17]</ref>) are usually content-based; they first model image observations using low level features (color, texture, shape, etc.), treat each concept as an independent class, and then train the corresponding concept-specific classifier to identify images belonging to that concept using a variety of machine learning and inference techniques such as latent Dirichlet allocation <ref type="bibr" coords="2,253.67,143.90,9.96,8.74" target="#b3">[2]</ref>, Markov models <ref type="bibr" coords="2,343.72,143.90,15.50,8.74" target="#b18">[17,</ref><ref type="bibr" coords="2,360.88,143.90,11.62,8.74" target="#b24">23]</ref>, probabilistic latent semantic analysis <ref type="bibr" coords="2,205.29,155.86,15.50,8.74" target="#b22">[21]</ref> and support vector machines (SVMs) <ref type="bibr" coords="2,390.73,155.86,15.50,8.74" target="#b11">[10,</ref><ref type="bibr" coords="2,407.88,155.86,11.62,8.74" target="#b31">30]</ref>. These learning machines are used to model correspondences between concepts and low level features and make it possible to assign concepts to new images.</p><p>The above annotation methods heavily rely on their visual content for image annotation <ref type="bibr" coords="2,185.62,215.89,14.61,8.74" target="#b27">[26]</ref>. Due to the semantic gap, they are unable to fully explore the semantic information inside images; this comes from the statistical inconsistency of low level features with respect to the learned concepts and also complexity of scenes. Another class of annotation methods, referred to as context-based, has emerged that takes advantage of extra information (such as contextual cues in social networks <ref type="bibr" coords="2,204.90,275.67,10.79,8.74" target="#b8">[7]</ref>) in order to better capture the correlations between images and their semantic concepts. Early methods started to emerge for text documents in social networks <ref type="bibr" coords="2,248.54,299.58,15.50,8.74" target="#b42">[41]</ref> and now recent work is handling visual content annotation, in different contexts; such as the approach of <ref type="bibr" coords="2,391.75,311.53,15.50,8.74" target="#b19">[18,</ref><ref type="bibr" coords="2,408.91,311.53,12.73,8.74" target="#b12">11]</ref> that uses visual links as context in social networks, in order to propagate image tags and the method of <ref type="bibr" coords="2,183.78,335.44,15.50,8.74" target="#b35">[34]</ref> that uses friendship connections and conditional random fields in order to improve the performance of photo annotation. Other works consider distances between tags using Flickr <ref type="bibr" coords="2,288.85,359.35,14.61,8.74" target="#b39">[38]</ref>, or context informations taken from personal calendars <ref type="bibr" coords="2,205.07,371.31,9.96,8.74" target="#b10">[9]</ref>, GPS locations <ref type="bibr" coords="2,288.44,371.31,14.61,8.74" target="#b16">[15]</ref>, visual appearances <ref type="bibr" coords="2,396.31,371.31,10.52,8.74">[4,</ref><ref type="bibr" coords="2,408.49,371.31,12.73,8.74" target="#b20">19]</ref> and multiple cues <ref type="bibr" coords="2,156.40,383.26,15.50,8.74" target="#b41">[40]</ref> in order to improve annotation.</p><p>In this paper, we describe the participation of "CNRS-TELECOM Paris-Tech" at ImageCLEF 2013 Scalable Concept Image Annotation Task <ref type="bibr" coords="2,441.61,419.39,14.61,8.74" target="#b37">[36]</ref>. Our proposed solution is based on the design of similarity functions that compare images, using context-dependent kernels. The latter are designed using multiple visual features as well as multiple contextual (text) informations provided in this task. When plugged into SVMs, for image classification and annotation, these kernels turned out to be very effective. The rest of this paper is organized as follows; in Section 2, we describe motivation and proposed method at a glance. In Section 3, we describe our participation and different runs submitted to this task as well as our results and comparison against other participants' runs. Finally, we conclude the paper in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Motivation and Proposed Method at a Glance</head><p>Among image annotation methods mentioned earlier, those based on machine learning and particularly kernel methods (such as SVMs) are particularly successful but their success remains highly dependent on the choice of kernels. The latter, defined as symmetric and positive semi-definite functions <ref type="bibr" coords="2,416.42,621.25,15.49,8.74" target="#b36">[35,</ref><ref type="bibr" coords="2,433.57,621.25,11.62,8.74" target="#b33">32]</ref>, should reserve large values to very similar content and vice-versa. Usual kernels, either holistic <ref type="bibr" coords="2,168.92,645.16,15.50,8.74" target="#b17">[16,</ref><ref type="bibr" coords="2,186.08,645.16,12.73,8.74" target="#b23">22]</ref> or alignment-based <ref type="bibr" coords="2,287.64,645.16,15.50,8.74" target="#b13">[12,</ref><ref type="bibr" coords="2,304.79,645.16,7.75,8.74" target="#b2">1,</ref><ref type="bibr" coords="2,314.20,645.16,12.73,8.74" target="#b14">13,</ref><ref type="bibr" coords="2,328.59,645.16,7.75,8.74" target="#b4">3,</ref><ref type="bibr" coords="2,338.00,645.16,12.73,8.74" target="#b21">20,</ref><ref type="bibr" coords="2,352.39,645.16,12.73,8.74" target="#b38">37,</ref><ref type="bibr" coords="2,366.79,645.16,7.75,8.74" target="#b7">6,</ref><ref type="bibr" coords="2,376.19,645.16,11.62,8.74" target="#b26">25]</ref>, consider similarities as decreasing functions of distances between patterns or proportional to the qual-</p><formula xml:id="formula_0" coords="3,227.01,185.38,150.08,101.15">(A) (C) (B)</formula><p>Fig. <ref type="figure" coords="3,154.40,329.52,4.13,7.89">1</ref>. This figure shows examples of images (taken from Flickr) and their social tag links. Even though images (A), (B) are visually identical, they should be declared as dissimilar as their contexts are different (i.e., they belong to two different communities: "cars" and "landscape" respectively) while images (A), (C) should be declared as strongly related or similar, as they have similar contexts (i.e., they belong to similar communities: "cars").</p><p>ity of aligning primitives inside patterns. In both cases, kernels rely only on the intrinsic properties of patterns without taking into account their contextual cues.</p><p>We are interested, in this work, in the integration of context in kernels in order to further enhance their discrimination power, for image annotation, while ensuring their positive definiteness and also their efficiency. The guiding principle relies on a basic assertion: kernels should not depend only on intrinsic aspects of images (as images with the same semantic may have different visual and textual features), but also on different sources of knowledge including context. The designed family of kernels, takes high values not only when images share the same content but also the same context. The context of an image is defined as the set of images sharing links (eg. tags) and exhibiting better semantic descriptions, compared to both pure visual and tag based descriptions. The issue of combining context and visual content for image annotation and search has been investigated in previous related work (see for instance <ref type="bibr" coords="3,403.10,597.34,10.52,8.74" target="#b10">[9,</ref><ref type="bibr" coords="3,415.28,597.34,7.75,8.74">4,</ref><ref type="bibr" coords="3,424.69,597.34,12.73,8.74" target="#b41">40,</ref><ref type="bibr" coords="3,439.08,597.34,12.73,8.74" target="#b40">39,</ref><ref type="bibr" coords="3,453.47,597.34,12.73,8.74" target="#b30">29,</ref><ref type="bibr" coords="3,467.87,597.34,12.73,8.74" target="#b29">28,</ref><ref type="bibr" coords="3,134.77,609.29,12.73,8.74" target="#b31">30,</ref><ref type="bibr" coords="3,149.16,609.29,12.73,8.74" target="#b28">27]</ref> and work discussed earlier); the novel part of this work aims to integrate context (from the ImageCLEF 2013 collection), in kernel design for classification and annotation, and plug these kernels in support vector machines in order to take benefit from their well established generalization power <ref type="bibr" coords="3,400.66,645.16,14.61,8.74" target="#b36">[35]</ref>.</p><p>In this work, we use a novel class of kernels (referred to as explicit and context-dependent) for image annotation <ref type="bibr" coords="4,312.18,131.95,15.50,8.74" target="#b28">[27]</ref> (see also <ref type="bibr" coords="4,367.64,131.95,15.50,8.74" target="#b30">[29,</ref><ref type="bibr" coords="4,384.80,131.95,11.62,8.74" target="#b29">28]</ref>). An image database is modeled as a graph where nodes are pictures and edges correspond to the shared tagged links. The proposed kernel design method is based on the optimization of an objective function mixing a fidelity term, a context criterion and a regularization term. The fidelity term, takes into account the visual content of images, so highly visually similar contents encourage high kernel values. The context criterion, considers the local graph structure and allows us to further enhance the relevance of our designed kernel, by diffusing and restoring the similarity iff pairs of images are also surrounded by highly similar images that should also recursively share the same context. The regularization term controls the smoothness of the learned kernel and makes it possible to obtain a closed form solution. Solving this minimization problem results into a recursive similarity function (with an explicit kernel map) that converges to a positive semi-definite fixed-point. Again, our proposed method goes beyond the naive use of low level features and usual context free kernels (established as the standard baseline in image annotation) in order to design a family of kernels applicable to annotation and suitable to integrate the "contextual" information taken from tagged links in interconnected datasets. In the proposed context-dependent kernel, two images (even with different visual content and even sharing different tags) will be declared as similar if they share the same visual context (see also Fig. <ref type="figure" coords="4,399.84,371.05,3.87,8.74">1</ref>). This is usually useful as tags in interconnected data may be noisy and misspelled. Furthermore, the intrinsic visual content of images might not always be relevant especially for concepts exhibiting large variation of the underlying visual aspects. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">ImageCLEF 201Evaluation</head><p>The targeted task is image annotation also known as "concept detection"; given a picture of a database, the goal is to predict which concepts (classes) are present into that picture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">ImageCLEF 2013 Collection</head><p>The annotation task, of this year, concentrated on developing annotation algorithms that rely only on data obtained automatically from the web. A very large amount of images was gathered from the web by the organizers, and using associated web pages, tags were also obtained. As tags are noisy (i.e., the degree of relationship between images and the surrounding tags varies greatly), we use some preprocessing in order to assign tags to images. Dev set. this set is labeled and consists in 1,000 images belonging to 95 categories including "aerial", "bridges", "clouds", etc. Sample of images belonging to the dev set is shown in Fig. <ref type="figure" coords="5,270.40,322.31,3.87,8.74" target="#fig_0">2</ref>, top.</p><p>Test set. as the objective, of this year task, is to develop algorithms that can easily change or scale the list of concepts used for image annotation, an unlabeled test set was provided and includes 2,000 images belonging to 116 categories; 21 of them are not available in the dev set and are considered as out of list concepts. These concepts include "bottle", "butterfly", "chair", etc. Sample of images belonging to the out of list concepts is shown in Fig. <ref type="figure" coords="5,357.35,406.00,3.87,8.74" target="#fig_0">2</ref></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>, bottom.</head><p>Training set label generation. a larger set including 250,000 images was provided with meta-data but without labels. The meta-data, associated to a given image, includes a list of keywords used in order to retrieve that image, in the web, with different search engines. For a given concept (among the 116 concepts), we extract a training set, by collecting among the 250k images those which include that concept, in their meta-data. As keywords associated to a given concept may appear in different forms, we applied some morphological expansions in order to increase the recall when searching for training images belonging to a given concept.</p><p>Context matrix generation. we design a left stochastic adjacency matrix (denoted P) between images with each entry proportional to the number of shared keywords in the meta-data of the underlying images. We use this adjacency matrix in order to build our context dependent kernels as discussed in section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">ImageCLEF 2013 Visual Features</head><p>We used only the visual features provided in this imageCLEF task including GIST, Color Histograms, SIFT, C-SIFT, RGB-SIFT and OPPONENT-SIFT.</p><p>For all the SIFT-based descriptors, a bag-of-words representation is provided. Even though provided, images were not used in order to extract any extra features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">CNRS-TELECOM ParisTech Runs and Comparison</head><p>All our submitted runs (discussed below) are based on SVM training. Again the goal is to achieve image annotation also known as concept detection. For this purpose, we trained "one-versus-all" SVM classifiers for each concept; we use many random folds (taken from training data) for multiple SVM training and we use these SVMs in order to predict the concepts on the dev and test sets. We repeat this training process, for each concept, through different random folds from the training set and we take the average scores of the underlying SVM classifiers. This makes classification results less sensitive to the sampling of the training set.</p><p>For all the submitted runs (see runs 1 -6 below), the only difference resides in the used kernels. We plug the latter into SVMs in order to achieve concept detection. Performances are evaluated using the mean F-measures (at concept and sample levels) as well as the mean average precisions. Details about these measures are given in the ImageCLEF 2013 web page 1 .</p><p>Run 1. for this run, we build 7 gram matrices 2 associated to the visual features mentioned earlier. Then, we linearly combine those matrices into a single one. Notice that this combination does not result from multiple kernel learning but just a convex combination of kernels with uniform weights. We plug the resulting kernel into SVMs for training and testing. A given test image is assigned to a given concept, iff the underlying SVM score is ≥ τ (with τ = 0.5 in practice).</p><p>Run 2. the setting of this run is exactly the same as run 1 except that the cut-off threshold τ is set to 1.</p><p>Run 3. the linear combination of kernel matrices (denoted K (0) ) obtained in runs 1 and 2 is used as an initialization to the context dependent kernel (CDK) defined as K (t+1) = K (0) + γ PK (t) P , with γ ≥ 0 (see <ref type="bibr" coords="6,376.74,529.30,14.76,8.74" target="#b28">[27]</ref>). The latter is computed iteratively (in two iterations) using the adjacency matrix P introduced earlier. Once designed, we plug CDK into SVMs for training and testing. A given test image is again assigned to a given concept, iff the underlying SVM score is ≥ τ (with τ = 0.5 in practice) Run 4. the setting of this run is exactly the same as run 3 except that the cut-off threshold τ is set to 1. Run 5. before computing the convex combination of kernels (as done in runs 3, 4), we first evaluate for each kernel matrix (associated to a given visual feature) its underlying CDK (K (t+1) = K (0) + γ PK (t) P with K (0) being the linear kernel matrix). Then, we apply histogram intersection kernel to these CDKs and we linearly combine the resulting kernels with uniform weights. Again, the number of iterations in CDK is set to 2. Once designed, we plug the final kernel matrix into SVMs, for training and testing. A given test image is again assigned to a given concept, iff the underlying SVM score is ≥ τ (with τ = 0.5 in practice) Run 6. the setting of this run is exactly the same as run 5 except that the cut-off threshold τ is set to 1. Diagrams in Figs. <ref type="figure" coords="7,214.47,263.45,15.73,8.74">3, 4</ref> and<ref type="figure" coords="7,252.25,263.45,3.87,8.74" target="#fig_4">5</ref>, show the mean F-measures and mean average precisions of our runs and their comparisons with respect to different participants' runs. From all these results it is clear that our best runs (runs 6 and 4) outperform the others for almost all the evaluation measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We discussed in this paper, the participation of "CNRS-TELECOM ParisTech" in ImageCLEF 2013 Scalable Concept Image Annotation Task. Our submissions include pure visual runs based on linear combination of elementary histogram intersection kernels, as well as combined visual/textual runs, that consider the context of images through context dependent kernels. The latter turned out to be the most effective and achieved the best performance among 57 participants' runs.   </p><formula xml:id="formula_1" coords="8,146.77,253.97,298.71,39.82">-4 ISI-1 ISI-4 ISI-2 UNIMORE-2 UNIMORE-5 UNIMORE-1 TPT-2 UNIMORE-6 RUC-4 ISI-5 RUC-5 ISI-3 UNIMORE-3 UNEDUV-3 UNEDUV-5 TPT-5 RUC-3 TPT-3 RUC-2 UNIMORE-4 UNEDUV-4 UNEDUV-1 RUC-1 UNEDUV-2 CEALIST-4 CEALIST-5 CEALIST-3 CEALIST-2 CEALIST-1 KDEVIR-1 URJCyUNED-3 MICC-5 MICC-4 URJCyUNED-2 MICC-3 URJCyUNED-1 MICC-2 MICC-1 KDEVIR-3 TPT-1 KDEVIR-6 KDEVIR-4 KDEVIR-2 KDEVIR-5 SZTAKI-1 INAOE-3 SZTAKI-2 THSSMPAM-3 THSSMPAM-2 LMCHFUT-1 INAOE-1 THSSMPAM-1 INAOE-2 THSSMPAM-<label>4</label></formula><formula xml:id="formula_2" coords="9,146.77,253.97,293.22,39.82">-4 ISI-1 ISI-4 ISI-2 UNIMORE-2 UNIMORE-5 UNIMORE-1 TPT-2 UNIMORE-6 RUC-4 ISI-5 RUC-5 ISI-3 UNIMORE-3 UNEDUV-3 UNEDUV-5 TPT-5 RUC-3 TPT-3 RUC-2 UNIMORE-4 UNEDUV-4 UNEDUV-1 RUC-1 UNEDUV-2 CEALIST-4 CEALIST-5 CEALIST-3 CEALIST-2 CEALIST-1 KDEVIR-1 URJCyUNED-3 MICC-5 MICC-4 URJCyUNED-2 MICC-3 URJCyUNED-1 MICC-2 MICC-1 KDEVIR-3 TPT-1 KDEVIR-6 KDEVIR-4 KDEVIR-2 KDEVIR-5 SZTAKI-1 INAOE-3 SZTAKI-2 THSSMPAM-3 THSSMPAM-2 LMCHFUT-1 INAOE-1 THSSMPAM-1 INAOE-<label>2</label></formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,134.77,635.85,345.82,7.89;4,134.77,646.84,345.82,7.86;4,134.77,657.79,31.85,7.86;4,136.16,536.49,113.39,85.04"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Figures in the top are taken from the dev set and correspond to the concepts "aerial", "bridge" and "cloud" respectively. Figures in the bottom are taken from the test set.</figDesc><graphic coords="4,136.16,536.49,113.39,85.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,137.50,645.07,3.65,5.24;6,144.73,646.84,180.24,7.86;6,137.50,656.03,3.65,5.24;6,144.73,657.79,159.07,7.86"><head>1</head><label></label><figDesc>http://imageclef.org/2013/photo/annotation 2 Based on histogram intersection kernel.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="10,134.77,311.47,345.82,7.89;10,134.77,320.83,345.83,6.12;10,134.77,328.78,345.83,6.14;10,134.77,336.75,345.82,6.14;10,134.77,344.72,345.83,6.14;10,134.77,352.69,345.83,6.14;10,134.77,360.66,345.82,6.14;10,134.77,368.63,345.83,6.14;10,134.77,376.62,22.97,6.12"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. This diagram shows a comparison (as released by the ImageCLEF 2013 organizers in http://imageclef.org/2013/photo/annotation) of the mean average precision of our runs (denoted TPT-*) and other participants' runs on the test set. Acronyms stand for ISI: Tokyo U., UNI-MORE: U. of Modena and Reggio Emilia, RUC: Renmin U. of China, UNEDUV: National U. of Distance Education at Spain, CEALIST: CEA, France, KDEVIR: Toyohashi U. of Technology in Japan, URJCyUNED: King Juan Carlos U. in Spain, MICC: Florence U. in Italy, SZTAKI: Hungarian Academy of Sciences, INAOE: National Institute of Astrophysics, Optics and Electronics in Mexico, THSSMPAM: Tsinghua U., Beijing, China. LMCHFUT: Hefei University of Technology, China.</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was supported in part by a grant from the <rs type="funder">Research Agency ANR (Agence Nationale de la Recherche)</rs> under the <rs type="projectName">MLVIS</rs> project and a grant from <rs type="projectName">DIGITEO</rs> under the <rs type="projectName">RELIR</rs> project.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_aCWHnty">
					<orgName type="project" subtype="full">MLVIS</orgName>
				</org>
				<org type="funded-project" xml:id="_4Y5SHMK">
					<orgName type="project" subtype="full">DIGITEO</orgName>
				</org>
				<org type="funded-project" xml:id="_qhcDwSw">
					<orgName type="project" subtype="full">RELIR</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="9,138.15,621.84,27.20,16.50;9,165.61,622.11,16.21,31.93;9,182.09,621.84,5.22,16.50;9,187.58,622.11,5.22,31.93;9,193.08,621.90,5.22,18.01;9,198.57,622.11,5.22,12.87;9,204.06,621.90,5.22,18.01;9,209.55,622.11,5.22,12.87;9,215.05,622.11,16.21,31.93;9,231.53,621.84,21.70,18.07;9,253.50,622.11,16.21,31.93;9,269.98,621.90,5.22,18.01;9,275.47,622.11,38.18,29.22;9,313.92,622.11,5.22,38.89;9,319.41,622.11,10.72,20.13;9,330.40,622.11,5.22,38.89;9,335.89,622.11,5.22,20.13;9,341.39,622.11,5.22,38.89;9,346.88,622.11,10.72,20.13;9,357.87,622.11,5.22,26.49;9,363.36,621.84,5.22,16.50;9,368.85,621.46,38.18,27.14;9,407.30,621.18,16.21,37.08;9,423.78,621.95,5.22,23.16;9,429.27,621.18,5.22,37.08;9,434.77,621.95,5.22,23.16;9,440.26,621.18,10.72,37.08;9,451.25,621.95,5.22,23.16;9,134.77,678.68,17.87,7.89" xml:id="b0">
	<monogr>
		<idno>TPT-6 TPT-4 ISI-1 ISI-4 ISI-2 UNIMORE-2 UNIMORE-5 UNIMORE-1 TPT-2 UNIMORE-6 RUC-4 ISI-5 RUC-5 ISI-3 UNIMORE-3 UNEDUV-3 UNEDUV-5 TPT-5 RUC-3 TPT-3 RUC-2 UNIMORE-4 UNEDUV-4 UNEDUV-1 RUC-1 UNEDUV-2 CEALIST-4 CEALIST-5 CEALIST-3 CEALIST-2 CEALIST-1</idno>
		<title level="m" coord="9,308.43,622.11,5.22,26.49;9,313.92,622.11,5.22,38.89;9,319.41,622.11,10.72,20.13;9,330.40,622.11,5.22,38.89;9,335.89,622.11,5.22,20.13;9,341.39,622.11,5.22,38.89;9,346.88,622.11,10.72,20.13;9,357.87,622.11,5.22,26.49;9,363.36,621.84,5.22,16.50;9,368.85,621.46,38.18,27.14;9,407.30,621.18,16.21,37.08;9,423.78,621.95,5.22,23.16;9,429.27,621.18,5.22,37.08;9,434.77,621.95,5.22,23.16;9,440.26,621.18,10.72,37.08;9,451.25,621.95,5.22,23.16;9,134.77,678.68,13.40,7.89">KDEVIR-1 URJCyUNED-3 MICC-5 MICC-4 URJCyUNED-2 MICC-3 URJCyUNED-1 MICC-2 MICC-1 KDEVIR-3 TPT-1 KDEVIR-6 KDEVIR-4 KDEVIR-2 KDEVIR-5 SZTAKI-1 INAOE-3 SZTAKI-2 THSSMPAM-3 THSSMPAM-2 LMCHFUT-1 INAOE-1 THSSMPAM-1 INAOE-2 THSSMPAM-4 THSSMPAM-5 INAOE-4 Fig</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,158.53,678.68,322.06,7.89;9,134.77,688.02,345.83,6.14;9,134.77,695.99,345.82,6.14;9,134.77,703.96,345.82,6.14;9,134.77,711.93,345.83,6.14;9,134.77,719.90,345.83,6.14;9,134.77,727.87,345.83,6.14;9,134.77,735.84,345.83,6.14;9,134.77,743.81,345.83,6.14;9,134.77,751.80,120.68,6.12;10,138.15,254.63,27.20,16.50;10,165.61,254.90,16.21,31.93;10,182.09,254.63,5.22,16.50;10,187.58,254.90,5.22,31.93;10,193.08,254.69,5.22,18.01;10,198.57,254.90,5.22,12.87;10,204.06,254.69,5.22,18.01;10,209.55,254.90,5.22,12.87;10,215.05,254.90,16.21,31.93;10,231.53,254.63,21.70,18.07;10,253.50,254.90,16.21,31.93;10,269.98,254.69,5.22,18.01;10,275.47,254.90,38.18,29.22;10,313.92,254.90,5.22,38.89;10,319.41,254.90,10.72,20.13;10,330.40,254.90,5.22,38.89;10,335.89,254.90,5.22,20.13;10,341.39,254.90,5.22,38.89;10,346.88,254.90,10.72,20.13;10,357.87,254.90,5.22,26.49;10,363.36,254.63,5.22,16.50;10,368.85,254.25,38.18,27.14;10,407.30,253.97,16.21,37.08;10,423.78,254.74,5.22,23.16;10,429.27,253.97,5.22,37.08;10,434.77,254.74,5.22,23.16;10,440.26,253.97,10.72,37.08;10,451.25,254.74,5.22,23.16;10,134.77,405.03,62.94,10.52" xml:id="b1">
	<monogr>
		<idno>TPT-6 TPT-4 ISI-1 ISI-4 ISI-2 UNIMORE-2 UNIMORE-5 UNIMORE-1 TPT-2 UNIMORE-6 RUC-4 ISI-5 RUC-5 ISI-3 UNIMORE-3 UNEDUV-3 UNEDUV-5 TPT-5 RUC-3 TPT-3 RUC-2 UNIMORE-4 UNEDUV-4 UNEDUV-1 RUC-1 UNEDUV-2 CEALIST-4 CEALIST-5 CEALIST-3 CEALIST-2 CEALIST-1 KDEVIR-1 URJCyUNED-3 MICC-5 MICC-4 URJCyUNED-2 MICC-3 URJCyUNED-1 MICC-2 MICC-1 KDEVIR-3 TPT-1 KDEVIR-6 KDEVIR-4 KDEVIR-2 KDEVIR</idno>
		<ptr target="http://imageclef.org/2013/photo/annotation)ofourruns" />
		<title level="m" coord="10,428.26,254.74,0.75,23.16;10,429.27,253.97,5.22,37.08;10,434.77,254.74,5.22,23.16;10,440.26,253.97,10.72,37.08;10,451.25,254.74,5.22,23.16;10,134.77,405.03,62.94,10.52">1 THSSMPAM-1 INAOE-2 THSSMPAM-4 THSSMPAM-5 INAOE-4 References</title>
		<meeting><address><addrLine>France, KDEVIR; Spain, MICC; Florence U. in Italy; THSSMPAM; Beijing, China, LMCHFUT</addrLine></address></meeting>
		<imprint>
			<publisher>Tsinghua U</publisher>
		</imprint>
		<respStmt>
			<orgName>Tokyo U., UNIMORE: U. of Modena and Reggio Emilia, RUC: Renmin U. of China, UNEDUV: National U. of Distance Education at Spain, CEALIST: CEA ; Toyohashi U. of Technology in Japan ; SZTAKI: Hungarian Academy of Sciences, INAOE: National Institute of Astrophysics, Optics and Electronics in Mexico ; Hefei University of Technology, China</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">-5 SZTAKI-1 INAOE-3 SZTAKI-2 THSSMPAM-3 THSSMPAM-2 LMCHFUT-1 INAOE-</note>
	<note>These diagrams show a comparison (as released by the ImageCLEF 2013 organizers. (denoted TPT-*) and other participants&apos; runs on the test set. Top diagram: mean F-measures for samples, middle: mean F-measures for concepts, and Bottom: mean F-measures for concepts unseen in the dev set</note>
</biblStruct>

<biblStruct coords="10,142.96,429.04,337.64,7.86;10,151.52,440.00,315.93,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,350.75,429.04,129.84,7.86;10,151.52,440.00,194.74,7.86">On-line handwriting recognition with support vector machines, a kernel approach</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bahlmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Haasdonk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Burkhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,354.71,440.00,29.05,7.86">IWFHR</title>
		<imprint>
			<biblScope unit="page" from="49" to="54" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,450.76,337.64,7.86;10,151.52,461.72,257.36,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,415.66,450.76,64.93,7.86;10,151.52,461.72,48.47,7.86">Matching words and pictures</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Barnard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Duygululu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Forsyth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,207.90,461.72,172.74,7.86">The Journal of Machine Learning Research</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,472.48,337.63,7.86;10,151.52,483.44,329.07,7.86;10,151.52,494.40,20.99,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,329.22,472.48,151.36,7.86;10,151.52,483.44,80.08,7.86">The intermediate matching kernel for image local features</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Boughorbel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tarel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,241.51,483.44,234.70,7.86">IEEE International Joint Conference on Neural Networks</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,505.16,337.64,7.86;10,151.52,516.12,249.79,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,280.59,505.16,200.00,7.86;10,151.52,516.12,145.49,7.86">Annotating photo collection by label propagation according to multiple similarity cues</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,305.00,516.12,67.93,7.86">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,526.88,337.64,7.86;10,151.52,537.84,222.88,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,295.09,526.88,185.51,7.86;10,151.52,537.84,111.46,7.86">Formulating semantic image annotation as a supervised learning problem</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Carneiro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,286.33,537.84,58.22,7.86">Proc. of CVPR</title>
		<meeting>of CVPR</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,548.60,337.64,7.86;10,151.52,559.56,159.91,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,204.08,548.60,120.45,7.86">Fast global alignment kernels</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Cuturi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,349.12,548.60,131.48,7.86;10,151.52,559.56,131.67,7.86">Proceedings of the International Conference on Machine Learning</title>
		<meeting>the International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,570.32,337.63,7.86;10,151.52,581.28,329.07,7.86;10,151.52,592.24,329.07,7.86;10,151.52,603.20,329.07,7.86;10,151.52,614.16,167.26,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,335.51,570.32,145.07,7.86;10,151.52,581.28,130.55,7.86">From context to content: leveraging context to infer media metadata</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>King</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Good</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sarvas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,307.60,581.28,172.99,7.86;10,151.52,592.24,131.18,7.86;10,335.90,592.24,144.69,7.86;10,151.52,603.20,329.07,7.86;10,151.52,614.16,49.20,7.86">Brave New Topics Session on From Context to Content: Leveraging Contextual Metadata to infer Multimedia Content in New York</title>
		<meeting><address><addrLine>MM</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2004">2004. 2004</date>
			<biblScope unit="page" from="188" to="195" />
		</imprint>
	</monogr>
	<note>Proceedings of 12th Annual ACM International Conference on Multimedia</note>
</biblStruct>

<biblStruct coords="10,142.96,624.92,337.63,7.86;10,151.52,635.88,329.07,7.86;10,151.52,646.84,329.07,7.86;10,151.52,657.79,140.61,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,391.25,624.92,89.34,7.86;10,151.52,635.88,273.80,7.86">Object recognition as machine translation: Learning a lexicon for a fixed image vocabulary</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Duygulu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Barnard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,342.85,646.84,75.52,7.86">ECCV 2002. LNCS</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Heyden</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Sparr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Nielsen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Johansen</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2353</biblScope>
			<biblScope unit="page" from="97" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,120.67,337.63,7.86;11,151.52,131.63,245.29,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,408.80,120.67,71.79,7.86;11,151.52,131.63,140.86,7.86">Image annotation using personal calendars as context</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Neustaedter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,300.49,131.63,67.93,7.86">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,143.14,337.98,7.86;11,151.52,154.10,329.07,7.86;11,151.52,165.06,88.76,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,304.36,143.14,176.23,7.86;11,151.52,154.10,250.25,7.86">Automatic image annotation by incorporating feature hierarchy and boosting to scale up svm classifiers</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Xue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,422.94,154.10,57.66,7.86;11,151.52,165.06,58.81,7.86">Proc. of ACM MULTIMEDIA</title>
		<meeting>of ACM MULTIMEDIA</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,176.57,337.97,7.86;11,151.52,187.53,329.07,7.86;11,151.52,198.49,35.84,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,382.04,176.57,98.55,7.86;11,151.52,187.53,193.32,7.86">Visual-textual joint relevance learning for tag-based social image search</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z.-J</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,353.56,187.53,123.01,7.86">IEEE Trans. Image Processing</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,210.01,337.97,7.86;11,151.52,220.96,68.60,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,200.81,210.01,151.98,7.86">A survey of kernels for structured data</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gartner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,360.04,210.01,116.11,7.86">Multi Relational Data Mining</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="58" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,232.48,337.98,7.86;11,151.52,243.44,329.07,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,274.52,232.48,206.08,7.86;11,151.52,243.44,58.61,7.86">The pyramid match kernel: Efficient learning with sets of features</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,217.80,243.44,188.83,7.86">Journal of Machine Learning Research (JMLR)</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="725" to="760" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,254.95,337.98,7.86;11,151.52,265.91,103.15,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,293.46,254.95,187.13,7.86;11,151.52,265.91,30.26,7.86">Multiscale conditional random fields for image labeling</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zimel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Carreira</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,201.67,265.91,23.16,7.86">CVPR</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,277.42,337.98,7.86;11,151.52,288.38,323.36,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="11,329.57,277.42,151.02,7.86;11,151.52,288.38,87.20,7.86">Inferring photographic location using geotagged web images</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gallagher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,247.06,288.38,138.33,7.86">Multimedia Tools and Applications</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="131" to="153" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,299.90,337.97,7.86;11,151.52,310.86,233.44,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="11,261.30,299.90,128.52,7.86">A kernel between sets of vectors</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kondor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Jebara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,410.02,299.90,70.57,7.86;11,151.52,310.86,205.20,7.86">proceedings of the 20th International conference on Machine Learning</title>
		<meeting>the 20th International conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,322.37,337.98,7.86;11,151.52,333.33,272.20,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="11,248.26,322.37,232.34,7.86;11,151.52,333.33,74.51,7.86">Automatic linguistic indexing of pictures by a statistical modeling approach</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,234.47,333.33,89.19,7.86">IEEE Trans. on PAMI</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1075" to="1088" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,344.84,337.97,7.86;11,151.52,355.80,193.69,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="11,294.52,344.84,186.07,7.86;11,151.52,355.80,84.08,7.86">Learning tag relevance by neighbor voting for social image retrieval</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Worring</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,255.27,355.80,61.88,7.86">MIR conference</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.62,367.31,337.98,7.86;11,151.52,378.27,329.07,7.86;11,151.52,389.23,161.85,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="11,320.00,367.31,160.59,7.86;11,151.52,378.27,118.07,7.86">Textual query of personal photos facilitated by large-scale web data</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I.-H</forename><surname>Tsang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,278.91,378.27,201.68,7.86;11,151.52,389.23,62.98,7.86">Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1022" to="1036" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>IEEE Transactions on</note>
</biblStruct>

<biblStruct coords="11,142.62,400.75,337.98,7.86;11,151.52,411.70,248.18,7.86" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="11,183.02,400.75,220.20,7.86">Mercer kernels for object recognition with local features</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,421.53,400.75,59.06,7.86;11,151.52,411.70,220.07,7.86">the proceedings of the IEEE Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,423.22,337.98,7.86;11,151.52,434.18,313.93,7.86" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="11,275.95,423.22,204.65,7.86;11,151.52,434.18,46.47,7.86">Plsa-based image autoannotation: Constraining the latent space</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Monay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Gaticaperez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,217.38,434.18,219.69,7.86">Proc. of ACM International Conference on Multimedia</title>
		<meeting>of ACM International Conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,445.69,337.98,7.86;11,151.52,456.65,329.07,7.86;11,151.52,467.61,58.61,7.86" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="11,311.46,445.69,169.13,7.86;11,151.52,456.65,188.28,7.86">A kullback-leibler divergence based kernel for svm classfication in multimedia applications</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Vasconcelos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,358.61,456.65,121.98,7.86;11,151.52,467.61,30.23,7.86">Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,479.12,337.98,7.86;11,151.52,490.08,329.07,7.86;11,151.52,501.04,20.99,7.86" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="11,254.39,479.12,226.20,7.86;11,151.52,490.08,278.18,7.86">Combining support vector machines and markov random fields in an integrated framework for contextual image classification</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Moser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Serpico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,452.44,490.08,22.52,7.86">TGRS</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,512.55,337.98,7.86;11,151.52,523.51,329.07,7.86;11,151.52,534.47,20.99,7.86" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="11,263.27,512.55,217.32,7.86;11,151.52,523.51,163.09,7.86">New strategies for image annotation: Overview of the photo annotation task at imageclef 2010</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Huiskes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,336.05,523.51,140.27,7.86">The Working Notes of CLEF 2010</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,545.99,337.98,7.86;11,151.52,556.94,276.55,7.86" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="11,388.45,545.99,92.15,7.86;11,151.52,556.94,111.79,7.86">A structural alignment kernel for protein structures</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ben-Hur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-P</forename><surname>Vert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">S</forename><surname>Noble</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,271.28,556.94,57.94,7.86">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1090" to="1098" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,568.46,337.97,7.86;11,151.52,579.42,222.61,7.86" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="11,328.08,568.46,152.51,7.86;11,151.52,579.42,85.45,7.86">Image retrieval: Ideas, influences, and trends of the new age</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ritendra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,245.03,579.42,100.89,7.86">ACM Computing Surveys</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,590.93,337.98,7.86;11,151.52,601.89,262.01,7.86" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="11,194.30,590.93,261.51,7.86">Explicit context-aware kernel map learning for image annotation</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sahbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,465.07,590.93,15.53,7.86;11,151.52,601.89,233.80,7.86">The 9th International Conference on Computer Vision systems</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,613.40,337.98,7.86;11,151.52,624.36,329.07,7.86" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="11,329.51,613.40,151.09,7.86;11,151.52,624.36,49.79,7.86">Context-dependent kernels for object classification</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sahbi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-Y</forename><surname>Audibert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Keriven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,220.92,624.36,204.13,7.86">Pattern Analysis and Machine Intelligence (PAMI)</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,635.88,337.97,7.86;11,151.52,646.84,329.07,7.86;11,151.52,657.79,246.87,7.86" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="11,377.06,635.88,103.53,7.86;11,151.52,646.84,168.79,7.86">Context-dependent kernel design for object matching and recognition</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sahbi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-Y</forename><surname>Audibert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rabarisoa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Keriven</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,338.94,646.84,141.65,7.86;11,151.52,657.79,217.60,7.86">the proceedings of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,120.67,337.98,7.86;12,151.52,131.63,329.07,7.86;12,151.52,142.59,177.47,7.86" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="12,240.48,120.67,240.11,7.86;12,151.52,131.63,246.61,7.86">Context based support vector machines for interconnected image annotation (the saburo tsuji best regular paper award)</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sahbi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,418.81,131.63,61.78,7.86;12,151.52,142.59,148.16,7.86">the Asian Conference on Computer Vision (ACCV)</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,153.55,337.98,7.86;12,151.52,164.51,87.77,7.86" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="12,284.69,153.55,195.90,7.86;12,151.52,164.51,14.75,7.86">Geometry aware local kernels for object recognition</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Semenovich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sowmya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,186.05,164.51,23.35,7.86">ACCV</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,175.46,337.98,7.86;12,151.52,186.42,240.61,7.86" xml:id="b33">
	<monogr>
		<title level="m" type="main" coord="12,304.35,175.46,176.24,7.86;12,151.52,186.42,93.08,7.86">Support vector machines and other kernelbased learning methods</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Cristianini</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,197.38,337.97,7.86;12,151.52,208.34,161.86,7.86" xml:id="b34">
	<analytic>
		<title level="a" type="main" coord="12,298.35,197.38,182.24,7.86;12,151.52,208.34,88.46,7.86">Probabilistic spatial context models for scene content understanding</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Jiebo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Weiyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,260.37,208.34,23.16,7.86">CVPR</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,219.30,337.98,7.86;12,151.52,230.26,172.50,7.86" xml:id="b35">
	<analytic>
		<title level="a" type="main" coord="12,295.02,219.30,185.58,7.86;12,151.52,230.26,106.73,7.86">Auto-tagging facebook: Social network context improves photo annotation</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Zickler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,277.81,230.26,16.61,7.86">IVW</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,241.22,337.97,7.86" xml:id="b36">
	<monogr>
		<title level="m" type="main" coord="12,211.26,241.22,102.42,7.86">Statistical learning theory</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>A Wiley-Interscience Publication</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,252.18,337.97,7.86;12,151.52,263.14,329.07,7.86;12,151.52,274.09,20.99,7.86" xml:id="b37">
	<analytic>
		<title level="a" type="main" coord="12,320.70,252.18,159.89,7.86;12,151.52,263.14,138.31,7.86">Overview of the imageclef 2013 scalable concept image annotation subtask</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Paredes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Thomee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,300.36,263.14,106.40,7.86">CLEF 2013 working notes</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,285.05,337.97,7.86;12,151.52,296.01,143.69,7.86" xml:id="b38">
	<analytic>
		<title level="a" type="main" coord="12,310.91,285.05,169.68,7.86;12,151.52,296.01,22.62,7.86">Recognition with local features: the kernel recipe</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Wallraven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Graf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,182.00,296.01,20.90,7.86">ICCV</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="257" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,306.97,337.97,7.86;12,151.52,317.93,88.76,7.86" xml:id="b39">
	<analytic>
		<title level="a" type="main" coord="12,339.93,306.97,58.46,7.86">Flickr distance</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Hua</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">Y</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,423.18,306.97,57.41,7.86;12,151.52,317.93,58.81,7.86">Proc. of ACM MULTIMEDIA</title>
		<meeting>of ACM MULTIMEDIA</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,328.89,337.98,7.86;12,151.52,339.85,329.07,7.86;12,151.52,350.81,186.68,7.86" xml:id="b40">
	<analytic>
		<title level="a" type="main" coord="12,348.42,328.89,132.17,7.86;12,151.52,339.85,58.91,7.86">A unified context model for web image retrieval</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Geng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanjalic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X.-S</forename><surname>Hua</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,218.75,339.85,261.84,7.86;12,151.52,350.81,123.00,7.86">ACM Transactions on Multimedia Computing, Communications, and Applications (TOMCCAP)</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">28</biblScope>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,361.77,337.97,7.86;12,151.52,372.73,329.07,7.86;12,151.52,383.68,96.31,7.86" xml:id="b41">
	<analytic>
		<title level="a" type="main" coord="12,430.34,361.77,50.25,7.86;12,151.52,372.73,324.90,7.86">Contextseer: Context search and recommendation at query time for shared consumer photos</title>
		<author>
			<persName coords=""><forename type="first">Y.-H</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P-T</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C.-W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K.-H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,151.52,383.68,67.93,7.86">ACM Multimedia</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,394.64,337.98,7.86;12,151.52,405.60,280.07,7.86" xml:id="b42">
	<analytic>
		<title level="a" type="main" coord="12,352.58,394.64,128.01,7.86;12,151.52,405.60,82.00,7.86">Exploring social annotations for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Giles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,252.46,405.60,86.48,7.86">the WWW conference</title>
		<meeting><address><addrLine>Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
