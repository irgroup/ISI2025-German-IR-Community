<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,137.52,115.96,340.32,12.62;1,265.51,133.89,84.83,12.62">ITI&apos;s Participation in the 2013 Medical Track of ImageCLEF</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,160.76,171.88,88.40,8.74"><forename type="first">Matthew</forename><forename type="middle">S</forename><surname>Simpson</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Lister Hill National Center for Biomedical Communications</orgName>
								<orgName type="institution" key="instit2">U.S. National Library of Medicine</orgName>
								<orgName type="institution" key="instit3">NIH</orgName>
								<address>
									<settlement>Bethesda</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,257.40,171.88,78.73,8.74"><roleName>Md</roleName><forename type="first">Daekeun</forename><surname>You</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Lister Hill National Center for Biomedical Communications</orgName>
								<orgName type="institution" key="instit2">U.S. National Library of Medicine</orgName>
								<orgName type="institution" key="instit3">NIH</orgName>
								<address>
									<settlement>Bethesda</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,339.45,171.88,85.30,8.74"><forename type="first">Mahmudur</forename><surname>Rahman</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Lister Hill National Center for Biomedical Communications</orgName>
								<orgName type="institution" key="instit2">U.S. National Library of Medicine</orgName>
								<orgName type="institution" key="instit3">NIH</orgName>
								<address>
									<settlement>Bethesda</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,433.70,171.88,20.89,8.74;1,188.58,183.84,74.47,8.74"><forename type="first">Dina</forename><surname>Demner-Fushman</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Lister Hill National Center for Biomedical Communications</orgName>
								<orgName type="institution" key="instit2">U.S. National Library of Medicine</orgName>
								<orgName type="institution" key="instit3">NIH</orgName>
								<address>
									<settlement>Bethesda</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,271.68,183.84,62.89,8.74"><forename type="first">Sameer</forename><surname>Antani</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Lister Hill National Center for Biomedical Communications</orgName>
								<orgName type="institution" key="instit2">U.S. National Library of Medicine</orgName>
								<orgName type="institution" key="instit3">NIH</orgName>
								<address>
									<settlement>Bethesda</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,361.93,183.84,64.86,8.74"><forename type="first">George</forename><surname>Thoma</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Lister Hill National Center for Biomedical Communications</orgName>
								<orgName type="institution" key="instit2">U.S. National Library of Medicine</orgName>
								<orgName type="institution" key="instit3">NIH</orgName>
								<address>
									<settlement>Bethesda</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,137.52,115.96,340.32,12.62;1,265.51,133.89,84.83,12.62">ITI&apos;s Participation in the 2013 Medical Track of ImageCLEF</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B1546D908DB6AA30E58072AEA8932376</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Image Retrieval</term>
					<term>Case-based Retrieval</term>
					<term>Image Modality</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This article describes the participation of the Image and Text Integration (ITI) group in the ImageCLEF medical retrieval, classification, and segmentation tasks. Although our methods are similar to those we have explored at past ImageCLEF evaluations, we describe in this paper the results of our methods on the 2013 collection and set of topics. In doing so, we present our submitted textual, visual, and mixed runs and our results for each of the four tasks. Like our participation in previous evaluations, we found our methods to generally perform well for each task. In particular, our best ad-hoc retrieval submission was again ranked first among all the submissions from the participating groups.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This article describes the participation of the Image and Text Integration (ITI) group in the ImageCLEF 2013 medical retrieval, classification, and segmentation tasks. Our group is from the Communications Engineering Branch of the Lister Hill National Center for Biomedical Communications, which is a research division of the U.S. National Library of Medicine.</p><p>The medical track <ref type="bibr" coords="1,236.19,500.70,10.73,8.74" target="#b3">[4]</ref> of ImageCLEF 2013 consists of an image modality classification task, a compound figure separation task, and two retrieval tasks. For the classification task, the goal is to classify a given set of images according to thirty-one modalities (e.g., "Computerized Tomography," "Electron Microscopy," etc.). The modalities are organized hierarchically into meta-classes such as "Radiology" and "Microscopy," which are themselves types of "Diagnostic Images." For the compound figure separation task, the goal is to segment the panels of multi-panel figures. Figures contained in biomedical articles are often composed of multiple panels (e.g., commonly labeled "a," "b," etc.) and segmenting them can result in improved retrieval performance. In the first retrieval task, a set of ad-hoc information requests is given, and the goal is to retrieve the most relevant images from a collection of biomedical articles for each topic. Finally, in the second retrieval task, a set of case-based information requests is given, and the goal is to retrieve the most relevant articles describing similar cases.</p><p>In the following sections, we describe our methods and results. In Section 2, we briefly outline our approach to each of the four tasks. In Section 3, we describe each of our submitted runs, and in Section 4 we present our results. For the modality classification task, our best submission achieved a classification accuracy of 69.28%, which is better than what we achieved in the previous ImageCLEF evaluation. Our submission for the compound figure separation task achieved a similar accuracy of 69.27%. Our best submission for the ad-hoc image retrieval task was a mixed approach that achieved a mean average precision of 0.3196. This result is comparable to what we achieved in the previous evaluation and is again ranked first among all submissions for the participating groups. Finally, for the case-based article retrieval task, our best submission achieved a mean average precision of 0.0886, which is significantly lower than the top-ranked run. In each of the above tasks, we obtained our best results using mixed approaches, indicating the importance of both textual and visual features for these tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>The methods we used in participating in the 2013 medical track of ImageCLEF are identical to the approaches we explored in the 2012 evaluation <ref type="bibr" coords="2,416.88,364.77,14.32,8.74" target="#b10">[11]</ref>. We briefly summarize these methods below.  <ref type="bibr" coords="2,353.73,477.85,9.73,7.86" target="#b2">[3]</ref> 192 4. Gabor moment 60 5. Gray-level co-occurrence matrix moment (GLCM) <ref type="bibr" coords="2,376.78,499.77,14.34,7.86" target="#b11">[12]</ref> 20 6. Local binary pattern (LBP1) <ref type="bibr" coords="2,290.78,510.72,9.73,7.86" target="#b8">[9]</ref> 256 7. Local binary pattern (LBP2) <ref type="bibr" coords="2,290.78,521.68,9.73,7.86" target="#b8">[9]</ref> 256 8. Scale-invariant feature transformation (SIFT) <ref type="bibr" coords="2,362.85,532.64,9.73,7.86" target="#b6">[7]</ref> 256 9. Shape moment 5 10. Tamura moment <ref type="bibr" coords="2,245.36,554.56,14.34,7.86" target="#b12">[13]</ref> 18 11. Edge histogram (EHD) <ref type="bibr" coords="2,272.16,565.52,9.73,7.86" target="#b0">[1]</ref> 80 12. Color and edge directivity (CEDD) <ref type="bibr" coords="2,321.03,576.48,9.73,7.86" target="#b1">[2]</ref> 144 13. Primitive length 5 14. Color layout (CLD) <ref type="bibr" coords="2,258.16,598.40,9.73,7.86" target="#b0">[1]</ref> 16 15. Color moment 3 16. Semantic concept (SCONCEPT) <ref type="bibr" coords="2,306.55,620.31,14.34,7.86" target="#b9">[10]</ref> 30</p><p>Combined 1391</p><p>Feature computed using the Lucene Image Retrieval library <ref type="bibr" coords="2,388.71,653.51,9.22,7.86" target="#b7">[8]</ref>.</p><p>We represent images and the articles in which they are contained using a combination of textual and visual features. Our textual features include the title, abstract, and Medical Subject Headings (MeSH R terms) of the articles in which the images appear as well as the images' captions and "mentions" (snippets of text within the body of an article that discuss the images). In addition to the above textual features, we also represent the visual content of images using various low-level visual descriptors. Table <ref type="table" coords="3,311.99,190.72,4.88,8.74" target="#tab_0">1</ref> summarizes the descriptors we extract and their dimensionality. Due to the large number of these features, we forego describing them in any detail. However, they are all well-known and discussed extensively in existing literature.</p><p>For the modality classification task, we experimented with both flat and hierarchical classification strategies using support vector machines (SVMs). First, we extract our visual and textual image features from the training images (representing the textual features as term vectors). Then, we perform attribute selection to reduce the dimensionality of the features. We construct the lowerdimensional vectors independently for each feature type (textual or visual) and combine the resulting attributes into a single, compound vector. Finally, we use the lower-dimensional feature vectors to train multi-class SVMs for producing textual, visual, or mixed modality predictions. Our flat classifiers attempt to classify images into one of the thirty-one modality classes whereas our hierarchical classifiers attempt to classify images following the structured organization of modalities provided by the ImageCLEF organizers.</p><p>For the compound figure separation task, our method incorporates both natural language and image processing techniques. Our method first seeks to determine the number of image panels comprising a compound figure by identifying textual panel labels in the figure's caption and visual panel labels overlain on the figure. A border detection method combines this information to determine the appropriate borders and segment the figure.</p><p>For the ad-hoc image retrieval task, we explored a variety of textual, visual, and mixed strategies. Our textual approaches utilize the Essie <ref type="bibr" coords="3,399.69,474.02,10.31,8.74" target="#b4">[5]</ref> retrieval system. Essie is a biomedical search engine developed by the U.S. National Library of Medicine, and it incorporates the synonymy relationships encoded in the Unified Medical Language System R (UMLS R ) Metathesaurus R <ref type="bibr" coords="3,418.28,509.88,9.95,8.74" target="#b5">[6]</ref>. Our visual approaches are based on retrieving images that appear visually similar to the given topic images. We compute the visual similarity between two images as the Euclidean distance between their visual descriptors. For the purposes of computing this distance, we represent each image as a combined feature vector composed of a subset of the visual descriptors listed in Table <ref type="table" coords="3,397.53,569.66,3.80,8.74" target="#tab_0">1</ref>. We also explored methods involving the clustering of visual descriptors and attribute selection. Finally, our mixed approaches combine the above textual and visual approaches in both early and late fusion strategies.</p><p>Our method for performing case-based article retrieval is analogous to our approaches for the ad-hoc image retrieval task. The only substantive difference is that we represent articles by a combination of the textual and visual features of each image they contain.</p><p>In this section we describe each of our submitted runs for the modality classification, compound figure separation, ad-hoc image retrieval, and case-based article retrieval tasks. Each run is identified by its file name or trec_eval run ID and mode (textual, visual or mixed). All submitted runs are automatic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Modality Classification Runs</head><p>We submitted the following six runs for the modality classification task:</p><p>M1. nlm textual only flat (textual): A flat multi-class SVM classification using selected attributes from a combined term vector created from four textual features (article title, MeSH terms, and image caption and mention). M2. nlm visual only hierarchy (visual): A hierarchical multi-class SVM classification using selected attributes from a combined visual descriptor of features 1-15 of Table  <ref type="table" coords="4,292.95,457.89,3.87,8.74" target="#tab_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Compound Figure Separation Runs</head><p>We submitted the following run for the compound figure separation task: S1. nlm multipanel separation (mixed): A combination of figure caption analysis, panel border detection, and panel label recognition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ad-hoc Image Retrieval Runs</head><p>We submitted the following ten runs for the ad-hoc image retrieval task: A1. nlm-image-based-textual (textual): A combination of two queries using Essie. (A1.Q1) A disjunction of modality terms extracted from the query topic must occur within the caption or mention fields of an image's textual features; a disjunction of the remaining terms is allowed to occur in any field. (A1.Q2) A lossy expansion of the verbatim topic is allowed to occur in any field.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A2. nlm-image-based-visual (visual):</head><p>A disjunction of the query images' clustered visual descriptors must occur within the global image feature field. A3. nlm-image-based-mixed (mixed): A combination of Queries A1.Q1-Q2 with Run A2. A4. image latefusion merge (visual): An automatic content-based image retrieval approach. In this approach, features 10-16 of Table <ref type="table" coords="5,415.41,178.77,21.18,8.74" target="#tab_0">1 are</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Case-based Article Retrieval Runs</head><p>We submitted the following three runs for the case-based article retrieval task: C1. nlm-case-based-textual (textual): A combination of three queries for each topic sentence using Essie. (C1.Q1) A disjunction of modality terms extracted from the sentence must occur within the caption or mention fields of an article's textual features; a disjunction of the remaining terms is allowed to occur in any field. (C1.Q2) A lossy expansion of the verbatim sentence is allowed to occur in any field. (C1.Q3) A disjunction of all extracted words in the sentence is allowed to occur in any field. Articles are scored according to the sentence resulting in the maximum score. C2. nlm-case-based-visual (visual): A disjunction of the query images' clustered visual descriptors must occur within the global image feature field. C3. nlm-case-based-mixed (mixed): A combination of Queries A1.Q1-Q3 with Run A2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>Tables 2-5 summarize the results of our modality classification, compound figure separation, ad-hoc image retrieval, and case-based article retrieval runs. In Table 2  and Table <ref type="table" coords="6,183.90,323.09,3.95,8.74" target="#tab_3">3</ref>, we give the accuracy of our figure classification and separation methods. In Table <ref type="table" coords="6,219.54,335.04,5.08,8.74" target="#tab_4">4</ref> and Table <ref type="table" coords="6,276.04,335.04,3.95,8.74" target="#tab_5">5</ref>, we give the mean average precision (MAP), binary preference (bpref) and precision-at-ten (P@10) of our retrieval methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This article describes the methods and results of the Image and Text Integration (ITI) group in the ImageCLEF 2013 medical classification, segmentation, and retrieval tasks. Our methods are similar to those we have developed for previous ImageCLEF evaluations, and they include a variety of textual, visual, and mixed approaches. For the modality classification task, our best submission was a mixed approach that achieved an accuracy of 69.28% and was ranked within the submissions from the top five participating groups. For the compound figure  separation task, our mixed approach resulted in an accuracy of 69.27% and was ranked second among four submissions from three groups participating in this task. Similar to our experience in previous years, our best submission for the ad-hoc image retrieval task was also a mixed approach, achieving a mean average precision of 0.3106 and ranking first overall. Finally, for the case-based article retrieval task, our best submission obtained a mean average precision of 0.0886. This result is much lower than what we have achieved in previous ImageCLEF evaluations. Despite our performance on the case-based task, the effectiveness of our mixed approaches are encouraging and provide evidence that our ongoing efforts at integrating textual and visual information will be successful.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,439.85,178.77,40.74,8.74;5,162.16,190.72,318.43,8.74;5,161.80,202.68,318.79,8.74;5,162.16,214.64,318.43,8.74;5,162.16,226.59,273.98,8.74;5,141.96,238.55,340.29,8.74;5,162.16,250.50,320.09,8.74;5,162.16,262.46,140.53,8.74;5,141.96,274.41,338.63,8.74;5,162.16,286.37,318.68,8.74;5,162.16,298.32,227.29,8.74;5,141.96,310.28,339.63,8.74;5,162.16,322.23,34.59,8.74;5,141.96,334.19,338.63,8.74;5,161.78,346.14,50.37,8.74;5,141.96,358.10,338.63,8.74;5,161.78,370.05,50.37,8.74;5,136.98,382.01,343.61,8.74;5,162.16,393.96,76.02,8.74"><head></head><label></label><figDesc>used, and their individual similarity scores are linearly combined with predefined weights based on modality classification results of the query and collection images. All images in each topic are considered and result lists for each topic are combined to produce a single list of retrieved images. A5. image latefusion merge filter (visual): Like Run A4 but the search is performed after filtering the collection of images based on modality classification results of the query images. A6. latefusion accuracy merge (visual): Like Run A4 but the feature weights are based on their normalized accuracy in classifying images in the 2012 ImageCLEF medical modality classification test set. A7. Txt Img Wighted Merge (mixed): A score-based combination of Runs A1 and A5. A8. Merge RankToScore weighted (mixed): A rank-based combination of Runs A1 and A5. A9. Txt Img Wighted Merge A (mixed): A score-based combination of Runs A1 and A6. A10. Merge RankToScore weighted A (mixed): A rank-based combination of Runs A1 and A6.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,151.80,422.22,311.75,63.49"><head>Table 1 :</head><label>1</label><figDesc>Extracted visual descriptors.</figDesc><table coords="2,151.80,439.94,311.75,45.77"><row><cell>No. Descriptor</cell><cell>Dimensionality</cell></row><row><cell>1. Autocorrelation</cell><cell>25</cell></row><row><cell>2. Edge frequency</cell><cell>25</cell></row><row><cell>3. Fuzzy color and texture histogram (FCTH)</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,142.74,127.33,329.89,96.36"><head>Table 2 :</head><label>2</label><figDesc>Accuracy results for the modality classification task.</figDesc><table coords="6,142.74,145.05,12.13,7.89"><row><cell>ID</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,142.74,251.42,329.89,41.57"><head>Table 3 :</head><label>3</label><figDesc>Accuracy results for the compound figure separation task.</figDesc><table coords="6,142.74,269.14,12.13,7.89"><row><cell>ID</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,142.74,518.66,329.89,140.20"><head>Table 4 :</head><label>4</label><figDesc>Retrieval results for the ad-hoc image retrieval task</figDesc><table coords="6,142.74,536.38,329.89,122.48"><row><cell>ID</cell><cell>Mode</cell><cell>MAP</cell><cell>bpref</cell><cell>P@10</cell></row><row><cell>nlm-se-image-based-mixed</cell><cell>Mixed</cell><cell>0.3196</cell><cell>0.2983</cell><cell>0.3886</cell></row><row><cell>nlm-se-image-based-textual</cell><cell>Textual</cell><cell>0.3196</cell><cell>0.2982</cell><cell>0.3886</cell></row><row><cell>Txt Img Wighted Merge A</cell><cell>Mixed</cell><cell>0.3124</cell><cell>0.3014</cell><cell>0.3886</cell></row><row><cell>Merge RankToScore weighted A</cell><cell>Mixed</cell><cell>0.3120</cell><cell>0.2950</cell><cell>0.3771</cell></row><row><cell>Txt Img Wighted Merge</cell><cell>Mixed</cell><cell>0.3086</cell><cell>0.2938</cell><cell>0.3857</cell></row><row><cell>Merge RankToScore weighted</cell><cell>Mixed</cell><cell>0.3032</cell><cell>0.2872</cell><cell>0.3943</cell></row><row><cell>image latefusion merge</cell><cell>Visual</cell><cell>0.0110</cell><cell>0.0207</cell><cell>0.0257</cell></row><row><cell>image latefusion merge filter</cell><cell>Visual</cell><cell>0.0101</cell><cell>0.0244</cell><cell>0.0343</cell></row><row><cell>latefusuon accuracy merge</cell><cell>Visual</cell><cell>0.0092</cell><cell>0.0179</cell><cell>0.0314</cell></row><row><cell>nlm-se-image-based-visual</cell><cell>Visual</cell><cell>0.0002</cell><cell>0.0021</cell><cell>0.0029</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,142.74,127.33,329.89,63.49"><head>Table 5 :</head><label>5</label><figDesc>Retrieval results for the case-based article retrieval task</figDesc><table coords="7,142.74,145.05,329.89,45.77"><row><cell>ID</cell><cell>Mode</cell><cell>MAP</cell><cell>bpref</cell><cell>P@10</cell></row><row><cell>nlm-se-case-based-mixed</cell><cell>Mixed</cell><cell>0.0886</cell><cell>0.0926</cell><cell>0.1457</cell></row><row><cell>nlm-se-case-based-textual</cell><cell>Textual</cell><cell>0.0885</cell><cell>0.0926</cell><cell>0.1457</cell></row><row><cell>nlm-se-case-based-visual</cell><cell>Visual</cell><cell>0.0008</cell><cell>0.0044</cell><cell>0.0057</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. We would like to thank <rs type="person">Suchet Chandra</rs> for preparing our collection and extracting the textual and visual features used by our methods.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="7,142.96,434.49,337.64,7.86;7,151.19,445.45,330.48,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,300.61,434.49,148.49,7.86">Overview of the MPEG-7 standard</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">F</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sikora</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Puri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,458.01,434.49,22.58,7.86;7,151.19,445.45,240.23,7.86">IEEE Transactions on Circuits and Systems for Video Technology</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="688" to="695" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,456.93,338.92,7.86;7,151.18,467.89,330.69,7.86;7,151.19,478.85,329.59,7.86;7,151.18,489.81,329.60,7.86;7,150.44,500.77,25.60,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,301.35,456.93,180.53,7.86;7,151.18,467.89,207.10,7.86">CEDD: Color and edge directivity descriptor: A compact descriptor for image indexing and retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Chatzichristofis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Boutalis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,232.45,478.85,248.33,7.86;7,151.18,489.81,57.35,7.86">Proceedings of the 6th International Conference on Computer Vision Systems</title>
		<title level="s" coord="7,215.15,489.81,135.77,7.86">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Gasteratos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Vincze</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Tsotsos</surname></persName>
		</editor>
		<meeting>the 6th International Conference on Computer Vision Systems</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">5008</biblScope>
			<biblScope unit="page" from="312" to="322" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,512.25,337.98,7.86;7,151.52,523.21,329.07,7.86;7,151.05,534.16,330.62,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,301.08,512.25,179.86,7.86;7,151.52,523.21,170.14,7.86">FCTH: Fuzzy color and texture histogram: A low level feature for accurate image retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Chatzichristofis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Boutalis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,340.44,523.21,140.15,7.86;7,151.05,534.16,250.69,7.86">Proceedings of the 9th International Workshop on Image Analysis for Multimedia Interactive Services</title>
		<meeting>the 9th International Workshop on Image Analysis for Multimedia Interactive Services</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="191" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,545.65,338.92,7.86;7,151.52,556.60,329.38,7.86;7,151.29,567.56,47.10,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,166.77,556.60,195.54,7.86">Overview of the ImageCLEF 2013 medical tasks</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>M체ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,383.45,556.60,97.45,7.86;7,151.29,567.56,18.43,7.86">Working notes of CLEF 2013</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,579.04,339.17,7.86;7,151.52,590.00,329.07,7.86;7,151.18,600.96,132.19,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,343.64,579.04,138.49,7.86;7,151.52,590.00,139.78,7.86">Essie: A concept-based search engine for structured biomedical text</title>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">C</forename><surname>Ide</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">F</forename><surname>Loane</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,298.14,590.00,182.45,7.86;7,151.18,600.96,46.17,7.86">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="253" to="263" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,612.44,339.43,7.86;7,151.52,623.40,236.61,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,329.16,612.44,148.87,7.86">The unified medical language system</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lindberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Humphreys</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mccray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,151.52,623.40,145.99,7.86">Methods of Information in Medicine</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="281" to="291" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.96,634.88,337.63,7.86;7,151.52,645.84,330.86,7.86;7,151.06,656.80,70.14,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,193.69,634.88,216.64,7.86">Object recognition from local scale-invariant features</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,431.56,634.88,49.03,7.86;7,151.52,645.84,280.25,7.86">Proceedings of the Seventh IEEE International Conference on Computer Vision</title>
		<meeting>the Seventh IEEE International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1150" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,119.67,337.64,7.86;8,151.52,130.63,330.61,7.86;8,151.52,141.59,115.70,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,283.00,119.67,197.60,7.86;8,151.52,130.63,50.55,7.86">LIRe: Lucene image retrival-an extensible java CBIR library</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Chatzichristofis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,222.53,130.63,259.60,7.86;8,151.52,141.59,22.19,7.86">Proceedings of the 16th ACM International Conference on Multimedia</title>
		<meeting>the 16th ACM International Conference on Multimedia</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1085" to="1088" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,152.55,337.63,7.86;8,151.52,163.51,232.41,7.86" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="8,206.51,152.55,274.08,7.86;8,151.52,163.51,66.87,7.86">The Local Binary Pattern Approach to Texture Analysis-Extensions and Applications</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>M채enp채채</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>University of Oulu</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct coords="8,142.62,174.47,337.98,7.86;8,151.52,185.43,329.07,7.86;8,151.52,196.39,309.48,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,318.03,174.47,162.56,7.86;8,151.52,185.43,205.20,7.86">A medical image retrieval framework in correlation enhanced visual concept feature space</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Thoma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,379.67,185.43,100.92,7.86;8,151.52,196.39,280.82,7.86">Proceedings of the 22nd IEEE International Symposium on Computer-Based Medical Systems</title>
		<meeting>the 22nd IEEE International Symposium on Computer-Based Medical Systems</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,207.34,339.26,7.86;8,151.52,218.30,329.07,7.86;8,151.52,229.26,329.07,7.86;8,151.52,240.22,312.33,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,166.84,218.30,313.74,7.86;8,151.52,229.26,19.45,7.86">ITI&apos;s participation in the ImageCLEF 2012 medical retrieval and classification tasks</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">S</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Thoma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,194.78,229.26,285.82,7.86;8,151.52,240.22,156.21,7.86">Working Notes for the Conference on Multilingual and Multimodal Information Access Evaluation (CLEF)</title>
		<meeting><address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012">September 17-20. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,251.18,337.97,7.86;8,151.18,262.14,308.88,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,271.66,251.18,103.86,7.86">Statistical texture analysis</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">N</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Shobha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="8,396.07,251.18,84.52,7.86;8,151.18,262.14,197.09,7.86">Proceedings of World Academy of Science, Engineering and Technology</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="1264" to="1269" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.62,273.10,337.98,7.86;8,151.52,284.06,329.30,7.86;8,150.44,295.02,25.60,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,309.41,273.10,171.18,7.86;8,151.52,284.06,41.56,7.86">Textural features corresponding to visual perception</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Tamura</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Yamawaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,200.64,284.06,225.85,7.86">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="460" to="473" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
