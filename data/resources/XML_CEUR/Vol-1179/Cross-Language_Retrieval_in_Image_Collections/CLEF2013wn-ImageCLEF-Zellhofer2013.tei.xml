<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,154.65,115.96,306.06,12.62;1,221.11,133.89,173.13,12.62">Overview of the ImageCLEF 2013 Personal Photo Retrieval Subtask</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,274.11,172.39,67.13,8.74"><forename type="first">David</forename><surname>Zellh√∂fer</surname></persName>
							<email>david.zellhoefer@tu-cottbus.de</email>
							<affiliation key="aff0">
								<orgName type="department">Database and Information Systems Group</orgName>
								<orgName type="institution">Brandenburg Technical University</orgName>
								<address>
									<addrLine>Walther-Pauer-Str. 1</addrLine>
									<postCode>03046</postCode>
									<settlement>Cottbus</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,154.65,115.96,306.06,12.62;1,221.11,133.89,173.13,12.62">Overview of the ImageCLEF 2013 Personal Photo Retrieval Subtask</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EAF0C8EFD7713036DF71D0CCD965F32D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Content-Based Image Retrieval</term>
					<term>Benchmark</term>
					<term>Experiments</term>
					<term>Personal Photograph Collection</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The subtask assesses the retrieval effectiveness in different retrieval usage scenarios in a personal photo collection and with different user groups. That is, the subtask reveals whether a tested algorithm is stable in terms of effectiveness for 7 different user groups. This perspective on retrieval performance evaluation separates the 2013 version of the subtask from its pilot phase although it relies on the same data set. The data set has been sampled from 19 layperson photographers and consists of 5,555 unprocessed digital photographs. To solve the subtask, the participants are asked to retrieve the 100 best matching documents for 74 sample information needs that consist of visual concepts and events. Each sample information need is modeled by at most one query-by-example document and up to three to browsed documents. The best performing groups, ISI and DBIS, used visual low-level features and metadata to solve the task. The current best-placed run achieves a nDCG at 20 of 0.7427 for the average user group using relevance feedback and all available modalities, i.e., visual data and metadata such as Exif or GPS information. Regarding the stability, roughly 50% of the submitted runs perform equally well over all user groups.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Following a pilot task phase in 2012, the personal photo retrieval task has become an official subtask of the ImageCLEF photo annotation and retrieval challenge in 2013. The subtask focuses on different retrieval usage scenarios and user groups. That is, the subtask reveals whether the tested algorithms are stable in terms of retrieval quality for different user groups or not. This perspective on retrieval performance evaluation separates the 2013 version of the subtask from its pilot phase <ref type="bibr" coords="1,163.14,632.21,10.52,8.74" target="#b6">[7]</ref> although it relies on the same data set. The data set has been sampled from 19 layperson photographers and consists of 5,555 unprocessed digital photographs. A detailed description of the data set is available in <ref type="bibr" coords="1,423.41,656.12,9.96,8.74" target="#b5">[6]</ref>.</p><p>In contrast to system-centric (Cranfield-based) benchmarks, the subtask tries to establish a more user-centered perspective on multimodal information retrieval (MIR) and content-based image retrieval (CBIR). This objective is reflected by three design choices of the subtask.</p><p>First, the subtask is not only providing sample information needs (IN) with one or more relevant query documents that have to be used in a query by example (QBE) fashion. In order to simulate the user's interaction with the MIR system, browsed documents are provided in addition to a number of query documents. Unlike the query documents, browsed documents are not necessarily fully relevant for a given topic. Instead, they vary in their level of relevance and can also be totally irrelevant, e.g., to model erroneous user input caused by a click on an image document that has nothing to do with the current IN but that grabbed the user's attention. From a wider perspective, this form of IN specification reflects the transition between different search strategies that have been described, e.g., by <ref type="bibr" coords="2,216.49,287.44,10.52,8.74" target="#b4">[5]</ref> or <ref type="bibr" coords="2,242.52,287.44,9.96,8.74" target="#b0">[1]</ref>.</p><p>Second, the subtask respects the gradual relevance of documents with respect to an IN. That is, the subtask's ground truth is based on graded relevance judgments. Consequently, an appropriate metric, nDCG <ref type="bibr" coords="2,358.32,324.39,9.96,8.74" target="#b2">[3]</ref>, is used for the evaluation of the participants' submission (see Section 4.1).</p><p>Third, the subtask acknowledges the subjectivity of relevance assessments. Because user groups that interact with an MIR system and their subjective notion of relevance vary, multiple ground truths are provided for different user groups. Hence, it becomes possible to assess the stability of an examined retrieval algorithm in terms of retrieval effectiveness. This experimental idea was motivated by a preliminary study <ref type="bibr" coords="2,262.62,409.15,10.52,8.74" target="#b6">[7]</ref> with the data obtained from the participants of the 2012 pilot task indicating that the algorithms' retrieval performances vary amongst different user groups.</p><p>The paper is structured as follows. The next section briefly describes the resources of the subtask, i.e., the data set, the ground truth, and the accompanying baseline system. Section 3 describes the sample information needs (or topics) that are used for the assessment of the retrieval effectiveness of an investigated retrieval algorithm. Section 4 discusses the results of all participants of the subtask, while the last Section 5 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Resources of the Subtask</head><p>The subtask relies on the Pythia dataset <ref type="bibr" coords="2,318.75,584.39,10.52,8.74" target="#b5">[6]</ref> which equates the data set of the 2012 pilot task on personal photo retrieval that will be described in this section. Hence, the description resembles the publication of 2012 in large parts <ref type="bibr" coords="2,455.59,608.30,25.00,8.74;2,134.77,620.25,38.26,8.74">[7, cf. pp. 1-12]</ref>. To complete the description of the provided resources, Section 2.2 will comment on the acquisition of the ground truth. The following section will then discuss the elicitation of the browsing data offered to the participants as an additional resource.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Pythia Dataset</head><p>To overcome limitations by binary relevance judgments often found in common test collections, the Pythia collection <ref type="bibr" coords="3,303.53,149.98,10.52,8.74" target="#b5">[6]</ref> has been proposed. The collection is aiming at providing a benchmark for user-centered or relevance feedback-related experiments which are affected by subjective relevance levels in particular. The collection differs from collections consisting of Flickr downloads or the like as it has been sampled from 19 layperson photographers. In addition to the image data, the contributors to the collection completed a survey (see Section 6) asking for their photograph taking behavior, their demographics etc. To ensure a variance in photographic motifs and style, the contributors have been chosen from different demographic groups. Thus, one can interpret the content of the collection as a mirror of a photographer's lifespan with typical changing usage behaviors, cameras, topics, and places. The total size of the collection is 5,555 documents.</p><p>The documents within the collection have neither been processed extensively nor have duplicates been removed. Hence, the data can be considered a realistic sample from a typical user's hard-disk. The collection is rich on metadata including GPS, IPTC, EXIF, and information about events depicted on each photography. All this information is available to the participants of the subtask. For an overview, see Table <ref type="table" coords="3,253.73,353.22,3.87,8.74" target="#tab_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Ground Truth Acquisition</head><p>To obtain the ground truth, 42 assessors were asked to participate. With the help a web-based evaluation tool (see <ref type="bibr" coords="3,301.74,548.52,10.52,8.74" target="#b6">[7,</ref><ref type="bibr" coords="3,315.77,548.52,27.72,8.74">Fig. 3]</ref>), the assessors could judge the relevance of an image with respect to a sample IN (topic) on a graded scale ranging from 0 (irrelevant) to 3 (fully relevant). All assessors had to judge all documents with respect to a topic. The topics were associated with the assessors by random. To keep them motivated, the assessors were allowed to work with the collection from a place of their choice. Additionally, they could pause an assessment run and continue from later on. A time constraint has not been defined. In average 2.69 topics were evaluated per assessor (standard deviation: 1.60). The individual assessments were saved separately in order to maintain them for later usage.</p><p>Table <ref type="table" coords="4,177.62,118.99,4.98,8.74" target="#tab_1">2</ref> lists all topics and states whether they belong to an event class or not (see Section 3). In order to associate the relevance assessments with different user groups, the assessors had to answer a questionnaire (see <ref type="bibr" coords="4,346.12,387.42,42.48,8.74">Section 6)</ref>. The questionnaire's outcome is listed in Table <ref type="table" coords="4,251.61,399.37,3.87,8.74">5</ref>. The core characteristics of the assessor group can be subsumed as follows. The majority of the assessors (28 out of 42) are male and born between 1979 and 1991 (median: 1987). Most of the assessors are students with a background in economics (26), the second largest group (13) has a background in computer science and information technology. Regarding their level of expertise in the field of MIR or IR, 9 assessors took classes in MIR while 11 heard IR. When asked directly about their knowledge of the field the median lies at "little knowledge" with an average of 1.40, i.e., a trend towards considering themselves as an 'informed outsiders".</p><p>Calculation of the Ground Truths for each Topic Based on the individual assessments, a ground truth for the average user group has been calculated. First, the frequency of each graded relevance judgement (out of an interval from 0 (irrelevant) to 3 (fully relevant)) was counted per image and topic. Based on these relevance judgment frequencies, an estimation value was calculated and rounded. The rounded estimation value of the relevance of an image regarding a topic was then used as the averaged graded relevance assessment for this image. In consequence, each image could be associated with a graded relevance judgment for each topic.</p><p>In addition to the average user group ground truth, 6 representative user groups could be defined on the basis of the demographics of the assessors that are listed in Table <ref type="table" coords="4,216.49,656.12,3.87,8.74">5</ref>. For each of the user groups listed below, a distinct ground truth was derived. In principle, the acquisition of the user group-specific ground truths follows the aforementioned process with the difference that it relies only on relevance assessments that are associated with the specific user group (e.g., expert MIR users). In the event of a missing relevance assessment for the topicuser group combination, the assessment is taken from the average ground truth. The resulting user groups are as follows:</p><p>Experts A group of users that stated that they have an expertise with IR. Non-Experts The complement of the experts group. Male/Female The assessors divided by gender. IT This groups consists of assessors with an IT background. Non-IT The complement of the IT group.</p><p>Generation of the Browsing Information As we could not obtain real browsing information, it had to be generated artificially. Using the graded relevance assessments, multiple images were chosen as browsing images. The provided browsed images have a relevance grade ranging from 0 to 3, i.e., they range from irrelevant to fully relevant for a given topic. In other words, the browsing data consists of interesting images which were not satisfying the information need of the modeled user and motivated him or her to proceed with the search. In contrast to 2012, browsed images could also be irrelevant in order to include erroneous user input.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Baseline System</head><p>In addition to the resources of the 2012 pilot task, the participants were given access to a baseline system that can be used for feature extraction and similarity calculation. The baseline system<ref type="foot" coords="5,272.88,449.29,3.97,6.12" target="#foot_0">1</ref> is available for Linux, Mac OS X, and Windows as C++ source code and is licensed under the Apache License version 2.0. All participants were free to use the system that offers 17 global and local visual features (and some variants).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Description of the Sample Information Needs</head><p>Unlike in the subtask's pilot phase, the sample information needs (topics) are no longer subdivided into events and visual concepts. An event in the sense of this subtask can be a rock concert or a holiday trip to a region or city. In contrast, a visual concept is a depiction of an object, e.g., a house or a street scene. Table <ref type="table" coords="5,189.93,591.64,4.98,8.74" target="#tab_1">2</ref> lists all topics including their title and their associated event class (see <ref type="bibr" coords="5,155.73,603.60,10.52,8.74" target="#b5">[6]</ref> on the WordNet-based event classes) 2 . The topics 50 to 81 are taken without modifications from the pilot phase's topic set <ref type="bibr" coords="6,378.08,118.99,9.96,8.74" target="#b6">[7]</ref>. The titles were not made available to the participants of the subtask contrasting to 2012 in avoid a manual optimization towards events or visual concepts based on the titles. Additional training data was not released.</p><p>For each topic, the sample IN is modeled by at most one fully relevant QBE document and/or a sequence of up to three browsed documents of varying relevance with respect to the IN. 10.81% of the topics (i.e., topics 15, 17, 21, 22, 24, 28, 36, and 42; see Table <ref type="table" coords="6,245.05,202.73,4.43,8.74" target="#tab_1">2</ref>) contain irrelevant browsed documents. The number of topics has been increased to 74 in comparison to 39 during the pilot phase. To summarize, the subtask can be considered more complex in comparison to the pilot, because the IN specification offers less reliable information that can be exploited for query construction.</p><p>In consequence, the best matching documents for each topic are expected to be retrieved ad hoc without additional knowledge about the user's context. That is, all participants have to rely on at most one QBE document and/or browsing data and are asked to find the best matching documents illustrating an event or depicting a visual concept. Thus, an additional objective of this task is to find out whether the participating retrieval systems can exploit data from different search strategies, i.e., query-by-example and browsing data, in order to find both visual concepts and photos depicting events. To solve the task, the participants have access to pre-extracted visual low-level features, metadata (e.g. GPS information), but are also free to use their own techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>In comparison to the pilot phase of the subtask, the participation rate could be increased by ca. 233 %. In 2012, only 3 groups submitted results. This year, 7 groups participated in the subtask, i.e., ca. 38 % of the groups that took part in the ImageCLEF 2013 photo annotation and retrieval challenge. Unfortunately, none of the last year's participants could be motivated to submit runs to the 2013 subtask.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evaluation Metrics</head><p>As said in the introduction, the relevance of a document with respect to an IN is both highly subjective and relative. That is, a document can be very relevant for an IN while another can be of little value in comparison. To reflect this fact, the presented ground truths are based on a gradual scale of relevance. Unfortunately, traditional measurements such as the mean average precision (MAP) or precision at n cannot deal with this kind of judgements. Hence, the subtask's retrieval effectiveness evaluation relies on the normalized discounted cumulative gain (nDCG) measurement <ref type="bibr" coords="6,306.90,620.25,9.96,8.74" target="#b2">[3]</ref>. As stated in <ref type="bibr" coords="6,379.79,620.25,10.52,8.74" target="#b5">[6]</ref> "DCG also provides more appropriate means to evaluate relevance feedback (RF) or adaptive systems as it can be used to measure slight changes or re-orderings of relevant documents with varying degrees of relevance within the result list". The core idea of DCG is to apply "a discount factor to the relevance scores in order to devaluate lateretrieved documents" <ref type="bibr" coords="7,233.85,130.95,9.96,8.74" target="#b2">[3]</ref>. In other words, the metric rewards highly relevant documents at the first positions in the result ranking and punishes systems retrieving less relevant documents at the first places. A full discussion of the metric is available by J√§rvelin and Kek√§l√§inen <ref type="bibr" coords="7,336.42,166.81,9.96,8.74" target="#b2">[3]</ref>. For the scope of this task, the DCG implementation of trec eval version 9.0 with standard discount settings is used. For the sake of completeness, MAP at a cut-off level of 100 is also used. Table <ref type="table" coords="7,176.56,396.68,4.98,8.74" target="#tab_2">3</ref> lists all participants of the personal photo retrieval subtask including their submitted runs. In total, 7 groups submitted 26 runs. Table <ref type="table" coords="7,433.46,408.63,4.98,8.74" target="#tab_2">3</ref> shows in addition whether relevance feedback (RF) has been used and which kinds of modalities where exploited during the retrieval. The participants could use the following combinations of the provided document data and metadata:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results of the Participants</head><p>visual features alone (IMG) visual features and metadata (IMGMET) visual features and browsing data (IMGBRO) metadata alone (MET) metadata and browsing data (METBRO) browsing data alone (BRO) a combination of all modalities (IMGMETBRO)</p><p>The best performing groups, ISI and DBIS, used visual low-level features and metadata to solve the task. While ISI used relevance feedback for 4 of their 5 runs, DBIS used this technique only for run #3. Table <ref type="table" coords="7,414.44,579.74,4.98,8.74" target="#tab_3">4</ref> shows all the results of the different runs ordered by nDCG at cut-off level 20 for the average user group. The complete results for all other user groups are available on the subtask's website <ref type="foot" coords="7,208.91,614.03,3.97,6.12" target="#foot_2">3</ref> . In accordance with the findings of the last years' ImageCLEF tasks, there is evidence that the utilization of multiple modalities increases the retrieval effectiveness.</p><p>The current best-placed run achieves a nDCG at 20 of 0.7427 (average user group) using relevance feedback and all available modalities (IMGMETBRO). In the last year, the best group achieved a nDCG at 20 of 0.5459 for visual concepts (IMGMET, no RF) and a NDCG at 20 of 0.9697 for event retrieval (MET, no RF). Please note that the values values are not meant to be compared directly because of the adjustments made to the subtask in 2013. Unfortunately, none of the former participants could be motivated to submit runs this year. Thus, a statement about an in-or decrease of retrieval effectiveness cannot be made on the basis of the submitted runs. To complicate the matter, only the first two groups have published their algorithms and approaches towards the task. Hence, we cannot provide a complete methodology or retrieval type listing in Table <ref type="table" coords="8,472.84,238.55,3.87,8.74" target="#tab_2">3</ref>. For a description of the methods used by the two first groups, see <ref type="bibr" coords="8,424.81,250.50,10.52,8.74" target="#b3">[4]</ref> and <ref type="bibr" coords="8,458.03,250.50,9.96,8.74" target="#b1">[2]</ref>. Retrieval Effectiveness for Different User Groups Figure <ref type="figure" coords="8,428.26,560.48,4.98,8.74">1</ref> illustrates the effectiveness variance over the different user groups. The y-axis shows the obtained rank and the x-axis the run ID that is listed in Table <ref type="table" coords="8,430.19,584.39,3.87,8.74" target="#tab_2">3</ref>. Figure <ref type="figure" coords="8,475.61,584.39,4.98,8.74">1</ref> shows clearly that roughly 50% of the submitted runs have a low rank variance. That is, they perform equally well for all examined user groups. The other half -predominantly the weak performing runs -is not very stable. Whether this effect correlates with the used features, matching algorithms, or other variables remains an area for further research and cannot be investigated in this paper due to the missing publications. Obtained ranks over all user groups, see Table <ref type="table" coords="9,383.87,349.17,4.61,7.86" target="#tab_2">3</ref> for the run IDs</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>Although the participation rate in the ImageCLEF 2013 subtask on personal photo retrieval is high, the low publication rate of the participants complicate an interpretation of the results. Anyhow, the results of this subtask strengthen the central finding of the last years of ImageCLEF: the combination of multiple modalities does improve the retrieval effectiveness. The interpretation of the stability of the submitted runs indicates that there might be a correlation between the effectivity and stability of an algorithm. In other words, the better one's algorithm performs the more likely it is that it will do so for different user groups. Whether this effect is due to other (hidden) variables remains an open question. Maybe this question motivates the missing participants to publish their algorithms and approaches towards the solution of the subtask. Because of the low publication rate, a general interpretation of the results is hardly possible.</p><p>Another interesting result of the conducted experiment is that both leading groups -ISI and DBIS -perform almost equally well although ISI is relying on sophisticated techniques such as Fisher vectors and local features while DBIS uses global low-end features embedded in a logical query language. Given the fact, that local features are computationally more intensive than global features, one might further investigate the logical combination of global features in order to achieve comparable results at less computational costs.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="9,162.92,349.14,289.52,7.89"><head></head><label></label><figDesc>Fig.1. Obtained ranks over all user groups, see Table3for the run IDs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,209.34,384.77,196.67,88.34"><head>Table 1 .</head><label>1</label><figDesc>Metadata Characteristics (Excerpt)<ref type="bibr" coords="3,396.28,384.79,9.73,7.86" target="#b5">[6]</ref> </figDesc><table coords="3,227.81,406.04,156.68,67.07"><row><cell>Characteristic</cell><cell>%</cell></row><row><cell cols="2">EXIF (Date, Camera Info. etc.) 100.00</cell></row><row><cell>GPS Data</cell><cell>81.85</cell></row><row><cell>Event Tags</cell><cell>96.71</cell></row><row><cell>Outdoor Photographies</cell><cell>82.64</cell></row><row><cell>Indoor Photographies</cell><cell>17.41</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,142.96,162.85,327.08,186.19"><head>Table 2 .</head><label>2</label><figDesc>Topics of the ImageCLEF 2013 personal photo retrieval subtask</figDesc><table coords="4,142.96,182.87,327.08,166.18"><row><cell>ID Title</cell><cell>Event</cell><cell>ID Title</cell><cell>Event</cell><cell>ID Title</cell></row><row><cell cols="3">1 Scientific Conference conference 26 Schenna</cell><cell>holiday</cell><cell>51 Beach and Seaside</cell></row><row><cell>2 Link√∂ping Fire</cell><cell>event</cell><cell>27 Umag</cell><cell>holiday</cell><cell>52 Street Scene</cell></row><row><cell>3 Babelsberg</cell><cell cols="2">excursion 28 Venice</cell><cell>holiday</cell><cell>53 Statue and Figurine</cell></row><row><cell>4 Brandenburg</cell><cell cols="2">excursion 29 Westendorf</cell><cell>holiday</cell><cell>54 Asian Temple</cell></row><row><cell>5 Eulo</cell><cell cols="2">excursion 30 Zurich</cell><cell>holiday</cell><cell>55 Landscape</cell></row><row><cell>6 Sanssouci</cell><cell cols="2">excursion 31 Die Toten Hosen</cell><cell cols="2">rock concert 58 Architecture (profane)</cell></row><row><cell>7 Telegrafenberg</cell><cell cols="2">excursion 32 Dream Theater</cell><cell cols="2">rock concert 59 Animals</cell></row><row><cell>8 Flight</cell><cell>flight</cell><cell>33 Melt Festival</cell><cell cols="2">rock concert 60 Asian Temple Interior</cell></row><row><cell>9 Altrei</cell><cell>holiday</cell><cell>34 Mike Stern</cell><cell cols="2">rock concert 61 Flower / Botanic Details</cell></row><row><cell>10 Bali</cell><cell>holiday</cell><cell>35 Toto</cell><cell cols="2">rock concert 63 Submarine Scene</cell></row><row><cell>11 Baltic Sea</cell><cell>holiday</cell><cell>36 Transatlantic</cell><cell cols="2">rock concert 64 Ceremony and Party</cell></row><row><cell>12 Cuba</cell><cell>holiday</cell><cell>37 U2 1 (Berlin)</cell><cell cols="2">rock concert 65 Theater / Performing Arts</cell></row><row><cell>13 Delft</cell><cell>holiday</cell><cell>38 U2 2 (Hannover)</cell><cell cols="2">rock concert 66 Clouds</cell></row><row><cell>14 Dublin</cell><cell>holiday</cell><cell>39 Berlin (general)</cell><cell>holiday</cell><cell>68 Church (Christian)</cell></row><row><cell>15 Edinburgh</cell><cell>holiday</cell><cell>40 Cottbus (general)</cell><cell>holiday</cell><cell>69 Art Object</cell></row><row><cell>16 Grafenau</cell><cell>holiday</cell><cell>41 Potsdam (general)</cell><cell>holiday</cell><cell>70 Cars</cell></row><row><cell>17 Holzleiten</cell><cell>holiday</cell><cell>42 Egypt (general)</cell><cell>holiday</cell><cell>71 Ship / Maritime Vessel</cell></row><row><cell>18 Kleinarl</cell><cell>holiday</cell><cell>43 Greece (general)</cell><cell>holiday</cell><cell>73 Temple (Ancient)</cell></row><row><cell>19 Lenggries</cell><cell>holiday</cell><cell>44 Hamburg (general)</cell><cell>holiday</cell><cell>74 Squirrels</cell></row><row><cell>20 Moscow</cell><cell>holiday</cell><cell cols="2">45 Mountainside (general) holiday</cell><cell>75 Sign</cell></row><row><cell>21 Nassfeld</cell><cell>holiday</cell><cell>46 London (general)</cell><cell>holiday</cell><cell>76 Mountains</cell></row><row><cell>22 New York</cell><cell>holiday</cell><cell>47 Party</cell><cell>party</cell><cell>78 Birds</cell></row><row><cell>23 Padua</cell><cell>holiday</cell><cell>48 Rock Concert</cell><cell cols="2">rock concert 79 Trees</cell></row><row><cell>24 Rome</cell><cell>holiday</cell><cell>49 Scuba Diving</cell><cell cols="2">scuba diving 81 City Panorama</cell></row><row><cell>25 Scandinavia</cell><cell>holiday</cell><cell>50 Soccer</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,136.61,259.91,342.14,109.68"><head>Table 3 .</head><label>3</label><figDesc>Submitted runs and IDs including their type and use of relevance feedback</figDesc><table coords="7,158.51,279.93,295.99,89.66"><row><cell>ID Run</cell><cell>RF</cell><cell>Type</cell><cell>ID Run</cell><cell>RF</cell><cell>Type</cell></row><row><cell>1 DBIS run1</cell><cell>None</cell><cell cols="2">IMGMETBRO 14 ISI 4</cell><cell>None</cell><cell>IMGBRO</cell></row><row><cell>2 DBIS run2</cell><cell>None</cell><cell cols="2">IMGMETBRO 15 ISI 5</cell><cell cols="2">Graded IMGMETBRO</cell></row><row><cell>3 DBIS run3</cell><cell cols="4">Graded IMGMETBRO 16 ThssMpam4 5000 NTI CR ?</cell><cell>?</cell></row><row><cell>4 FINKI run1</cell><cell>None</cell><cell>IMGBRO</cell><cell>17 ThssMpam4 5000 TI CR</cell><cell>?</cell><cell>?</cell></row><row><cell>5 FINKI run2</cell><cell>None</cell><cell>IMGBRO</cell><cell cols="2">18 ThssMpam4 5000 TI NCR ?</cell><cell>?</cell></row><row><cell>6 FINKI run3</cell><cell>None</cell><cell>IMGBRO</cell><cell>19 ThssMpam4 5X1000 CR</cell><cell>?</cell><cell>?</cell></row><row><cell cols="2">7 IPL13 visual r1 None</cell><cell>IMG</cell><cell cols="2">20 ThssMpam4 SURFMATCH ?</cell><cell>?</cell></row><row><cell cols="2">8 IPL13 visual r2 None</cell><cell>IMG</cell><cell>21 VCTLab 1</cell><cell>None</cell><cell>IMGBRO</cell></row><row><cell cols="2">9 IPL13 visual r3 None</cell><cell>IMG</cell><cell>22 VCTLab 2</cell><cell>None</cell><cell>IMGBRO</cell></row><row><cell cols="2">10 IPL13 visual r4 None</cell><cell>IMG</cell><cell>23 VCTLab 3</cell><cell>None</cell><cell>IMGBRO</cell></row><row><cell>11 ISI 1</cell><cell cols="3">Graded IMGMETBRO 24 VCTLab 4</cell><cell>None</cell><cell>IMGBRO</cell></row><row><cell>12 ISI 2</cell><cell cols="3">Graded IMGMETBRO 25 VCTLab 5</cell><cell>None</cell><cell>IMGBRO</cell></row><row><cell>13 ISI 3</cell><cell cols="3">Graded IMGMETBRO 26 WideIO</cell><cell>None</cell><cell>IMGBRO</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,134.77,290.46,345.83,201.79"><head>Table 4 .</head><label>4</label><figDesc>Performance of the submitted run for the averaged persona, ordered by nDCG at cut-off level 20</figDesc><table coords="8,138.28,319.69,336.45,172.55"><row><cell>Run</cell><cell cols="6">map cut 100 ndcg cut 5 ndcg cut 10 ndcg cut 20 ndcg cut 30 ndcg cut 100</cell></row><row><cell>ISI 5</cell><cell>0.5034</cell><cell>0.8104</cell><cell>0.7735</cell><cell>0.7427</cell><cell>0.7294</cell><cell>0.6884</cell></row><row><cell>ISI 1</cell><cell>0.5028</cell><cell>0.8086</cell><cell>0.7738</cell><cell>0.7425</cell><cell>0.7288</cell><cell>0.6878</cell></row><row><cell>ISI 2</cell><cell>0.4965</cell><cell>0.8047</cell><cell>0.7633</cell><cell>0.7379</cell><cell>0.7271</cell><cell>0.6986</cell></row><row><cell>ISI 3</cell><cell>0.4952</cell><cell>0.8057</cell><cell>0.7620</cell><cell>0.7365</cell><cell>0.7267</cell><cell>0.6984</cell></row><row><cell>DBIS run3</cell><cell>0.3954</cell><cell>0.7773</cell><cell>0.7197</cell><cell>0.6798</cell><cell>0.6546</cell><cell>0.6084</cell></row><row><cell>DBIS run2</cell><cell>0.3767</cell><cell>0.7694</cell><cell>0.7141</cell><cell>0.6669</cell><cell>0.6407</cell><cell>0.6082</cell></row><row><cell>DBIS run1</cell><cell>0.3333</cell><cell>0.7516</cell><cell>0.6761</cell><cell>0.6258</cell><cell>0.5969</cell><cell>0.5571</cell></row><row><cell>ISI 4</cell><cell>0.1855</cell><cell>0.7181</cell><cell>0.6069</cell><cell>0.5193</cell><cell>0.4829</cell><cell>0.4236</cell></row><row><cell>FINKI run3</cell><cell>0.1354</cell><cell>0.6878</cell><cell>0.5526</cell><cell>0.4410</cell><cell>0.3909</cell><cell>0.3158</cell></row><row><cell>FINKI run2</cell><cell>0.1375</cell><cell>0.6891</cell><cell>0.5510</cell><cell>0.4398</cell><cell>0.3881</cell><cell>0.3133</cell></row><row><cell>FINKI run1</cell><cell>0.1360</cell><cell>0.6813</cell><cell>0.5479</cell><cell>0.4384</cell><cell>0.3853</cell><cell>0.3109</cell></row><row><cell>IPL13 visual r4</cell><cell>0.1162</cell><cell>0.6627</cell><cell>0.5152</cell><cell>0.4173</cell><cell>0.3713</cell><cell>0.3126</cell></row><row><cell>IPL13 visual r1</cell><cell>0.1118</cell><cell>0.6594</cell><cell>0.5152</cell><cell>0.4125</cell><cell>0.3725</cell><cell>0.3077</cell></row><row><cell>IPL13 visual r2</cell><cell>0.1082</cell><cell>0.6303</cell><cell>0.4955</cell><cell>0.3899</cell><cell>0.3499</cell><cell>0.2910</cell></row><row><cell>IPL13 visual r3</cell><cell>0.0771</cell><cell>0.5769</cell><cell>0.4141</cell><cell>0.3138</cell><cell>0.2741</cell><cell>0.2226</cell></row><row><cell>ThssMpam4 5000 TI CR</cell><cell>0.0700</cell><cell>0.5584</cell><cell>0.4005</cell><cell>0.3051</cell><cell>0.2676</cell><cell>0.2126</cell></row><row><cell>ThssMpam4 5000 TI NCR</cell><cell>0.0700</cell><cell>0.5572</cell><cell>0.4009</cell><cell>0.3050</cell><cell>0.2675</cell><cell>0.2126</cell></row><row><cell>VCTLab 2</cell><cell>0.0783</cell><cell>0.4446</cell><cell>0.3574</cell><cell>0.3047</cell><cell>0.2754</cell><cell>0.2382</cell></row><row><cell>ThssMpam4 5000 NTI CR</cell><cell>0.0696</cell><cell>0.5606</cell><cell>0.3974</cell><cell>0.3001</cell><cell>0.2611</cell><cell>0.2104</cell></row><row><cell>ThssMpam4 5X1000 CR</cell><cell>0.0682</cell><cell>0.5547</cell><cell>0.3941</cell><cell>0.2954</cell><cell>0.2579</cell><cell>0.2071</cell></row><row><cell>VCTLab 1</cell><cell>0.0756</cell><cell>0.4206</cell><cell>0.3420</cell><cell>0.2950</cell><cell>0.2731</cell><cell>0.2386</cell></row><row><cell>VCTLab 3</cell><cell>0.0751</cell><cell>0.4282</cell><cell>0.3488</cell><cell>0.2943</cell><cell>0.2654</cell><cell>0.2336</cell></row><row><cell>VCTLab 5</cell><cell>0.0676</cell><cell>0.3816</cell><cell>0.3148</cell><cell>0.2712</cell><cell>0.2447</cell><cell>0.2080</cell></row><row><cell>VCTLab 4</cell><cell>0.0662</cell><cell>0.3778</cell><cell>0.3128</cell><cell>0.2616</cell><cell>0.2412</cell><cell>0.2093</cell></row><row><cell>WideIO</cell><cell>0.0584</cell><cell>0.4431</cell><cell>0.3253</cell><cell>0.2501</cell><cell>0.2192</cell><cell>0.1845</cell></row><row><cell>ThssMpam4 SURFMATCH</cell><cell>0.0529</cell><cell>0.4476</cell><cell>0.3107</cell><cell>0.2302</cell><cell>0.1982</cell><cell>0.1494</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="5,144.73,623.92,188.74,7.86"><p>See http://imageclef.org/2013/photo/retrieval.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="5,144.73,634.88,335.87,7.86;5,144.73,645.84,335.87,7.86;5,144.73,656.80,162.98,7.86"><p>Please note that the focus on events representing a holiday or a city trip is not a freely chosen bias. Instead, it reflects the state of randomly picked images from real-world personal photo collections<ref type="bibr" coords="5,295.42,656.80,9.22,7.86" target="#b5">[6]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="7,144.73,656.80,203.71,7.86"><p>http://imageclef.org/2013/photo/retrieval#results</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>IR) Information Retrieval, MR) Multimedia Retrieval Q1: Are you familiar with the principles of content-based information retrieval? 0) No, 1) A little, 2) I am an informed outsider, 3) Very much, 4) I am an expert Q2: Are you colorblind? 0) I don't know, 1) No, 2) Yes Q3: How many minutes do you use the internet per day? 0) Not at all, 2) 1 -30 minutes, 3) 31 -60 minutes. 4) 61 -90 minutes, 5) 91 -120 minutes, 6) More than 120 minutes, 7) More than 240 minutes Q4: Do you know Web 2.0 services such as Flickr or Fotocommunity.de for sharing holiday, family or other photographs with friends? 0) Never heard of it, 2) Know it by name, 3) I have visited such websites, 4) I do have an account Q5: How often do you use such Web 2.0 services to share photographs with friends? 0) Never, 1) Less than once a month, 2) More than once a month, 3) Weekly, 4) Daily Q6: Which of the following services do you use to upload and administrate holiday, family or other photographs? (Choose one or more.) None, Facebook, Flickr, Fotocommunity.de, Picasa, Other Q7: How often do you take photographs? 0) Seldom, 1) Only at special events, 2) Often, 3) Virtually always  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="10,138.35,545.75,342.24,7.86;10,146.91,556.71,333.68,7.86;10,146.91,567.67,25.60,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,195.11,545.75,260.41,7.86">Intelligent information retrieval: Whose intelligence? In: ISI &apos;96</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Belkin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,463.04,545.75,17.56,7.86;10,146.91,556.71,286.90,7.86">Proceedings of the Fifth International Symposium for Information Science</title>
		<meeting>the Fifth International Symposium for Information Science</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="25" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,579.11,342.24,7.86;10,146.91,590.07,333.68,7.86;10,146.91,601.03,161.05,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,305.87,579.11,174.72,7.86;10,146.91,590.07,80.04,7.86">BTU DBIS&apos; Personal Photo Retrieval Runs at ImageCLEF 2013</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>B√∂ttcher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zellh√∂fer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Schmitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,248.20,590.07,203.56,7.86">CLEF 2013 Labs and Workshop, Notebook Papers</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-09">September 2013. 2013</date>
			<biblScope unit="page" from="23" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,612.48,342.24,7.86;10,146.91,623.43,180.59,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,268.44,612.48,208.10,7.86">Cumulated gain-based evaluation of IR techniques</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>J√§rvelin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kek√§l√§inen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,146.91,623.43,89.96,7.86">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="422" to="446" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,634.88,342.24,7.86;10,146.91,645.84,333.68,7.86;10,146.91,656.80,185.62,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,371.70,634.88,108.89,7.86;10,146.91,645.84,100.71,7.86">MIL at ImageCLEF 2013: Personal Photo Retrieval</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mizuochi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Higuchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Kamada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Harada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,269.59,645.84,206.69,7.86">CLEF 2013 Labs and Workshop, Notebook Papers</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-09">September 2013. 2013</date>
			<biblScope unit="page" from="23" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.35,119.67,342.25,7.86;12,146.91,130.63,333.68,7.86;12,146.91,141.59,333.68,7.86;12,146.91,152.55,313.02,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,368.88,119.67,111.72,7.86;12,146.91,130.63,132.00,7.86">INSYDER -an information assistant for business intelligence</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Reiterer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Mu√üler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Handschuh</surname></persName>
		</author>
		<idno type="DOI">10.1145/345508.345559</idno>
		<ptr target="http://doi.acm.org/10.1145/345508.345559" />
	</analytic>
	<monogr>
		<title level="m" coord="12,299.98,130.63,180.62,7.86;12,146.91,141.59,314.28,7.86;12,184.80,152.55,39.61,7.86">Proceedings of the 23rd annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 23rd annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="112" to="119" />
		</imprint>
	</monogr>
	<note>SIGIR &apos;00</note>
</biblStruct>

<biblStruct coords="12,138.35,163.51,342.25,7.86;12,146.91,174.47,333.68,7.86;12,146.91,185.43,231.21,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,202.80,163.51,277.79,7.86;12,146.91,174.47,133.86,7.86">An Extensible Personal Photograph Collection for Graded Relevance Assessments and User Simulation</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zellh√∂fer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,302.42,174.47,178.17,7.86;12,146.91,185.43,174.12,7.86">Proceedings of the ACM International Conference on Multimedia Retrieval. ICMR &apos;12</title>
		<meeting>the ACM International Conference on Multimedia Retrieval. ICMR &apos;12</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.35,196.39,342.24,7.86;12,146.91,207.34,333.67,7.86;12,146.91,218.30,109.81,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,203.00,196.39,277.59,7.86;12,146.91,207.34,16.79,7.86">Overview of the Personal Photo Retrieval Pilot Task at ImageCLEF 2012</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zellh√∂fer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,388.53,207.34,92.05,7.86;12,146.91,218.30,81.14,7.86">CLEF 2012 Evaluation Labs and Workshop</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Karlgren</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Womser-Hacker</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
