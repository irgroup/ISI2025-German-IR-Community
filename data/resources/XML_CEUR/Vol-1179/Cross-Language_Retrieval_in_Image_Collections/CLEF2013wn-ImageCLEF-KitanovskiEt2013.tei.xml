<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,151.67,116.95,312.03,12.62">FCSE at Medical Tasks of ImageCLEF 2013</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,180.67,154.62,67.22,8.74"><forename type="first">Ivan</forename><surname>Kitanovski</surname></persName>
							<email>ivan.kitanovski@finki.ukim.mk</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Ss Cyril</orgName>
								<address>
									<addrLine>Methodius Rugjer Boshkovikj 16</addrLine>
									<postCode>1000</postCode>
									<settlement>Skopje</settlement>
									<country key="MK">Macedonia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,255.72,154.62,73.77,8.74"><forename type="first">Ivica</forename><surname>Dimitrovski</surname></persName>
							<email>ivica.dimitrovski@finki.ukim.mk</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Ss Cyril</orgName>
								<address>
									<addrLine>Methodius Rugjer Boshkovikj 16</addrLine>
									<postCode>1000</postCode>
									<settlement>Skopje</settlement>
									<country key="MK">Macedonia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,356.67,154.62,78.01,8.74"><forename type="first">Suzana</forename><surname>Loskovska</surname></persName>
							<email>suzana.loshkovska@finki.ukim.mk</email>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Computer Science and Engineering</orgName>
								<orgName type="institution">University of Ss Cyril</orgName>
								<address>
									<addrLine>Methodius Rugjer Boshkovikj 16</addrLine>
									<postCode>1000</postCode>
									<settlement>Skopje</settlement>
									<country key="MK">Macedonia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,151.67,116.95,312.03,12.62">FCSE at Medical Tasks of ImageCLEF 2013</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9C00B7CBFBD915868785C8A52BEEC5E3</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:33+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>information retrieval</term>
					<term>medical imaging</term>
					<term>medical image retrieval</term>
					<term>modality classification</term>
					<term>compound figure separation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the details of the participation of FCSE (Faculty of Computer Science and Engineering) research team in Image-CLEF 2013 medical tasks (modality classification, ad-hoc image retrieval and case-based retrieval). For the modality classification task we used SIFT descriptors and tf -idf weights of the surrounding text (image caption and paper title) as features. SVMs with χ 2 kernel and one-vsall strategy were used as classifiers. For the ad-hoc image retrieval task and case-based retrieval we adopted a strategy which uses a combination of word-space and concept-space approaches. The word-space approach uses the Terrier IR search engine to index and retrieve the text associated with the images/cases. The concept-space approach uses Metamap to map the text data into a set of UMLS (Unified Medical Language System) concepts, which are later indexed and retrieved by the Terrier IR search engine. The results from the word-space and concept-space retrieval are fused using linear combination. For the compound figure separation task, we used unsupervised algorithm based on breadth-first search strategy using only visual information from the medical images. The selected algorithms were tuned and tested on the data from Im-ageCLEF 2012 medical task and based on the selected parameters we submitted the new experiments for ImageCLEF 2013 medical task. We achieved very good overall performance: the best run for the modality classification ranked 2nd in the overall score, the best run for the ad-hoc image retrieval ranked 3rd.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper we present the experiments performed by the Faculty of Computer Science and Engineering (FSCE) team for the medical tasks at ImageCLEF 2013. Our group participated in all medical subtasks. To acquire the optimal parameters we evaluated our approaches on the ImageCLEF 2012 dataset and then based on those parameters we submitted the runs for ImageCLEF 2013.</p><p>The paper is organized as follows: Section 2 describes our approach for the modality classification task, section 3 shows the algorithm for the compound separation task, section 4 presents the ad-hoc image retrieval task, section 5 contains the details for the case-based retrieval task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Modality classification task</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Introduction</head><p>Imaging modality is an important information on the image for medical retrieval. In user studies, clinicians have indicated that modality is one of the most important fillters that they would like to be able to limit their search by. Using the modality information, the retrieval results can often be improved significantly. The ImageCLEF 2013 medical modality classification task is a standardized benchmark for systems to automatically classify medical image modality from PubMed journal articles <ref type="bibr" coords="2,243.53,236.05,9.96,8.74" target="#b0">[1]</ref>. The 2013 dataset has 31 calsses (the same number of classes and the same classification hierarchy as in 2012) but larger number of compound figures are present making the task significantly harder but corresponding much more to the reality of biomedical journals <ref type="bibr" coords="2,388.17,271.92,9.96,8.74" target="#b0">[1]</ref>.</p><p>Our approach uses visual features with combination of textual features extracted from the surrounding text content of the images. SVMs with χ 2 kernel were used as a classifiers. The algorithms are explained in details in the remainder of this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Visual features</head><p>Collections of medical images can contain various images obtained using different imaging techniques. Different feature extraction techniques are able to capture different aspects of an image (e.g., texture, shapes, color distribution...) <ref type="bibr" coords="2,134.77,405.96,9.96,8.74" target="#b1">[2]</ref>. Texture is especially important, because it is difficult to classify medical images using shape or gray level information. Effective representation of texture is needed to distinguish between images with equal modality and layout. Local image characteristics are fundamental for image interpretation: while global features retain information on the whole image, the local features capture the details. They are thus more discriminative concerning the problem of inter and intra-class variability <ref type="bibr" coords="2,229.57,477.69,9.96,8.74" target="#b2">[3]</ref>.</p><p>The bag-of-visual-words approach is commonly used in many state of the art algorithms for image classification <ref type="bibr" coords="2,303.40,501.65,9.96,8.74" target="#b3">[4]</ref>. The basic idea of this approach is to sample a set of local image patches using some method (densely, randomly or using a key-point detector) and calculate a visual descriptor on each patch (SIFT descriptor, normalized pixel values). The resulting distribution of descriptors is then quantified against a pre-specified visual codebook which converts it to a histogram. The main issues that need to be considered when applying this approach are: sampling of the patches, selection of the visual patch descriptor and building the visual codebook.</p><p>We use dense sampling of the patches, which samples an image grid in a uniform fashion using a fixed pixel interval between patches. We use an interval distance of 6 pixels and sample at multiple scales (σ = 1.2 and σ = 2.0). Due to the low contrast of some of the medical images (for example, radiographs), it would be difficult to use any detector for points of interest. Also, it has been pointed by Zhang et al. <ref type="bibr" coords="2,246.25,657.11,9.96,8.74" target="#b3">[4]</ref>, that a dense sampling is always superior to any strategy based on detectors for points of interest. We calculate a opponentSIFT descriptor for each image patch <ref type="bibr" coords="3,271.80,131.95,9.96,8.74" target="#b4">[5]</ref>, <ref type="bibr" coords="3,287.73,131.95,9.96,8.74" target="#b5">[6]</ref>. OpponentSIFT describes all the channels in the opponent color space using SIFT descriptors. The information in the O 3 channel is equal to the intensity information, while the other channels describe the color information in the image. These other channels do contain some intensity information, but due to the normalization of the SIFT descriptor they are invariant to changes in light intensity <ref type="bibr" coords="3,300.94,191.72,9.96,8.74" target="#b5">[6]</ref>.</p><p>The crucial aspect of the bag-of-visual-words approach is the codebook construction. An extensive comparison of codebook construction variables is given by van Gemert et al. <ref type="bibr" coords="3,227.38,227.93,9.96,8.74" target="#b6">[7]</ref>. We employ k-means clustering on 250K randomly chosen descriptors from the set of images available for training. k-means partitions the visual feature space by minimizing the variance between a predefined number of k clusters. Here, we set k to 500 and thus define a codebook with 500 codewords <ref type="bibr" coords="3,183.00,275.76,9.96,8.74" target="#b2">[3]</ref>. Dense sampling gives an equal weight to all key-points, irrespective of their spatial location in the image. To overcome this limitation, we follow the spatial pyramid approach <ref type="bibr" coords="3,217.34,520.13,9.96,8.74" target="#b7">[8]</ref>. We used a spatial pyramid of 1x1, 2x2, and 1x3 regions. Since every region is an image in itself, the spatial pyramid can easily be used in combination with dense sampling. The resulting vector with 4000 bins ((1x1 + 2x2 + 1x3)x500) was obtained by concatenation of the eight histograms (each histogram is L1 normalized). Fig. <ref type="figure" coords="3,278.84,567.96,4.98,8.74" target="#fig_0">1</ref> shows an example of the histograms extarcted from an image for the spatial pyramids of 1x1, 2x2 and 3x1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Textual features</head><p>Images in the collection belong to a medical article, so they can be indexed using the surrounding text content. The text representation adopted in this work included information from the title of the paper and the image caption, which can be found in the XML file corresponding to each image in the data set. With that, a text corpus for the image collection was built, and standard text processing operations were applied, including tokenization, stemming, and stop-word removal using Terrier IR <ref type="bibr" coords="4,289.71,155.86,9.96,8.74" target="#b8">[9]</ref>. We calculate the weight for each term in each document using T F -IDF weighting model. The calculated weights were adopted as textual features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Feature fusion schemes</head><p>Different features (in our case visual and textual) bringing different information about the content of the images clearly outperform single feature approaches <ref type="bibr" coords="4,134.77,255.11,14.61,8.74" target="#b9">[10]</ref>, <ref type="bibr" coords="4,155.47,255.11,9.96,8.74" target="#b2">[3]</ref>. Following these findings, we combine the two different features described above using high level feature fusion scheme. The fusion schemes is depicted in Fig. <ref type="figure" coords="4,155.10,279.02,3.87,8.74" target="#fig_1">2</ref>. The high level fusion scheme averages the predictions from the individual classifiers trained on the separate descriptors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Classifier setup</head><p>We used the libSVM implementation of SVMs (Support Vector Machines) <ref type="bibr" coords="4,465.09,501.70,15.50,8.74" target="#b10">[11]</ref> with probabilistic output <ref type="bibr" coords="4,245.66,513.65,15.50,8.74" target="#b11">[12]</ref> as classifiers. To solve the multi-class classification problems, we employ the one-vs-all approach. Each of the SVMs was trained with a χ 2 kernel. Namely, we build a binary classifier for each modality/class: the examples associated with that class are labeled positive and the remaining examples are labeled negative. This results in an imbalanced ratio of positive versus negative training examples. We resolve this issue by adjusting the weights of the positive and negative class <ref type="bibr" coords="4,289.23,585.38,9.96,8.74" target="#b5">[6]</ref>. In particular, we set the weight of the positive class to #pos+#neg #pos and the weight of the negative class to #pos+#neg #neg , with #pos the number of positive instances in the train set and #neg the number of negative instances. We also optimize the cost parameter C of the SVMs using an automated parameter search procedure <ref type="bibr" coords="4,323.23,633.20,9.96,8.74" target="#b5">[6]</ref>. For the parameter optimization, we used the dataset from 2012. After finding the optimal C value, the SVM is trained on the 2013 set of training images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Results and discussion</head><p>In this section, we present and discuss the results obtained from the experimental evaluation of the proposed method. First, we compare and evaluate the performance of the proposed method for the ImageCLEF 2012 dataset. Next, we present the results obtained for this year, ImageCLEF 2013 dataset.</p><p>The first three rows in Table <ref type="table" coords="5,275.33,187.43,4.98,8.74" target="#tab_0">1</ref> show the results of our method applied on the ImageCLEF 2012 dataset. These results include visual, textual and mixed runs. From the presented results, we can note that the better predictive performance of the visual run compared to the textual run. The high level feature fusion scheme helps in increasing the predictive performance. Furthermore, from the presented results, we can also note that our method has a very high accuracy/performance. Compared with the results from the groups that participate in the ImageCLEF 2012 medical task <ref type="bibr" coords="5,220.09,271.11,15.50,8.74" target="#b12">[13]</ref> our visual run is second best, the textual and mixed runs are ranked first. The mixed run with accuracy of 77.0 will be ranked first in the overall ranking if we have submitted this run in the last years modality classification task. The second three rows in Table <ref type="table" coords="5,287.42,470.43,4.98,8.74" target="#tab_0">1</ref> shows the results of our method applied on this year modality classification task. These results include also visual, textual and mixed runs. The accuracy of 78.04 obtained with the mixed run is second best in the overall ranking. The high level feature fusion scheme increases the predicitve performance for this year dataset also.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Compound figure separation</head><p>Compound figures contain figures of several types, they cannot be classified into unique classes and need to be separated before a detailed classification into the figure types can be performed. In this work, a unsupervised technique of compound figure separation is proposed and implemented based on breadthfirst search strategy using only visual information from the medical figures. All pixel values in the figure are examined/traversed searching for enclosed region separated with white border/pixels. The sensitivity of the border is controlled by threshold parameter. The regions smaller than predefined value are discarded.</p><p>In some of the figures the separating borders between the contained subfigures are in black color, therefore before applying our algorithm we invert the output figure . For the given test dataset our algorithm correctly classified 68.59% of the figures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Ad-hoc image retrieval</head><p>In this section, we give an overview of the application of our methods to adhoc medical image retrieval and present the results of our submitted runs. We participated only in the textual retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Proposed approach</head><p>The approach uses the image caption and the title of medical article in which it is referenced i.e. surrounding text. The approach seeks to combine word-space and concept-space approaches with the goal to achieve better overall retrieval performance.</p><p>The word-space component indexes and retrieves the surrounding text of the medical images in a traditional way. The surrounding text of the medical images is first preprocessed performing stop words removal and stemming, and creating a standard inverted index. In the retrieval phase, the system pre-processes the query and applies stop words removal and stemming to the query as well. Weighting models are applied to calculate the score for the relevancy of every medical article in respect to the given query. Once the score is calculated the documents are sorted and returned.</p><p>The concept-space component works by analyzing the text by the presented medical concepts. The first step is to map the surrounding text of the medical images to medical concepts. The mapping can be done using a variety of toolkits, services or libraries such as <ref type="bibr" coords="6,255.58,500.09,14.61,8.74" target="#b13">[14]</ref>, Meshup <ref type="bibr" coords="6,314.00,500.09,15.50,8.74" target="#b14">[15]</ref> etc. The problem in this approach arises in the way documents will be indexed and then evaluated in the retrieval phase with respect to queries. Classical information retrieval models, directly or indirectly, depend on the number of terms which the document and query share to compute the relevance score <ref type="bibr" coords="6,270.96,547.91,9.96,8.74" target="#b8">[9]</ref>. But, the number of terms which a query and document share in the word-space could be very different in the concept-space. For example, if a query and the document share one term "x-ray" in word-space, they can share up to six terms in concept-space <ref type="bibr" coords="6,344.34,583.77,14.61,8.74" target="#b15">[16]</ref>. On the other hand, if they share a phrase of two terms "lung x-ray" in word-space, then they will share only one term in concept-space.</p><p>The results from both components are then normalized and passed to a fusion component (the diagram is depicted on Figure <ref type="figure" coords="6,342.22,633.20,3.87,8.74">3</ref>). It can use any of the known strategies for late fusion <ref type="bibr" coords="6,241.98,645.16,14.61,8.74" target="#b16">[17]</ref>. In this study, we used a simple linear combination of the normalized results. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Concept-space results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Word-space results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Normalized results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Normalized results</head><p>Fig. <ref type="figure" coords="7,255.63,414.18,4.13,7.89">3</ref>. Diagram of the process flow</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Retrieval framework</head><p>For the word-space approach Terrier IR <ref type="bibr" coords="7,314.04,476.54,10.52,8.74" target="#b8">[9]</ref> is used as a search engine. For the preprocessing stage, Porter stemmer <ref type="bibr" coords="7,301.89,488.50,15.50,8.74" target="#b17">[18]</ref> and stop words are applied. In the retrieval phase, several weighting models were evaluated: PL2 <ref type="bibr" coords="7,410.43,500.45,14.61,8.74" target="#b18">[19]</ref>, BM25 <ref type="bibr" coords="7,462.32,500.45,14.61,8.74" target="#b18">[19]</ref>, BB2 <ref type="bibr" coords="7,156.10,512.41,14.61,8.74" target="#b18">[19]</ref>, DFR-BM25 <ref type="bibr" coords="7,229.77,512.41,14.61,8.74" target="#b18">[19]</ref>, TF-IDF <ref type="bibr" coords="7,287.26,512.41,14.61,8.74" target="#b19">[20]</ref>, DirichletLM <ref type="bibr" coords="7,363.17,512.41,14.61,8.74" target="#b20">[21]</ref>. Additional experiment was performed with query expansion on the best performing model to test its maximum output. The concept-space approach requires a mapping mechanism to match the text data to medical concepts. In this approach, Metamap is used as mapping tool and the extracted medical concepts are UMLS <ref type="bibr" coords="7,360.54,573.43,15.50,8.74" target="#b13">[14]</ref> concepts. The mapping is performed only on the surrounding text of the medical images. After the concepts are extracted, new artificial text is generated containing only the UMLS concepts. The same process is repeated for the queries. Once the artificial text is constructed it is passed to the search engine for indexing. Terrier IR indexes the artificial text, with no additional preprocessing (no stemming and stop words removal). The retrieval is performed by passing the artificial queries to the search engine. In this phase, the same weighting models are applied as in the word-space approach. Basically, the concept-space approach can be viewed as a word-space approach with more complex preprocessing.</p><p>Before the fusion phase, the results from the word-space and concept-space are normalized using min-max normalization <ref type="bibr" coords="8,338.47,155.86,14.61,8.74" target="#b21">[22]</ref>. The normalized results are then passed to the fusion component which applies linear combination. This kind fusion provides modularity and control over the extent in which components influence the final result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Evaluating on ImageCLEF 2012</head><p>The proposed framework was first evaluated on the ImageCLEF 2012 dataset. This phase is used to find the optimal weighting models and appropriate parameters. The results of the word-space assessment are depicted on Table <ref type="table" coords="8,451.45,259.81,3.87,8.74" target="#tab_1">2</ref>. The results show that the BM25 model provides the best performance for the wordspace retrieval. An additional experiment was performed with the best model by assigning weights to key words in the queries using Terri query language (For example. words such as "MRI", "CT" etc. are given 1.5 weight). The results for the experiment with the word weights (BM25-ww) show an increase in performance. The results of the concept-space assessment are depicted on Table <ref type="table" coords="8,441.06,481.87,3.87,8.74" target="#tab_2">3</ref>. In this case the best results are provided with the DirichletLM model. The results of the mixed assessment are depicted on Table <ref type="table" coords="8,420.30,645.16,3.87,8.74" target="#tab_3">4</ref>. The mixed assessment is consisted of two experiments. The first one is by combining the best word-space and concept-space approaches. The second experiment is done by combining the word-space with word weights and concept-space approaches. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Results and discussion</head><p>Based on the results obtained from the experiments over the ImageCLEF 2012 dataset, the runs for the ImageCLEF 2013 ad-hoc retrieval task was submitted. Another experiment was made, only now using ImageCLEF 2013 data and submitted the results only from the best performing techniques. For word-space text-based retrieval we submitted the run using BM25 weighting model word weights and for the concept-space text-based retrieval we submitted the run using DirchletLM weighting model. Finally, for the mixed retrieval we submitted the linear combination of the two previous spaces. The results from our runs on ImgeCLEF 2013 are presented on Table <ref type="table" coords="9,311.85,379.51,3.87,8.74" target="#tab_4">5</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Case-based retrieval</head><p>In this section, we give an overview of the application of our methods to casebased retrieval and present the results of our submitted runs. We participated only in the textual retrieval of the cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Proposed approach</head><p>The proposed approach for this task is similar to the ad-hoc retrieval task, with the difference that in this case the retrieval unit is a medical article, not an image.</p><p>Two approach combines the word-space and concept-space, just as with the adhoc retrieval. For the word-space component, we index the entire text of the medical articles, which includes the title, abstract, article text and captions of the images in the article (we refer to this as "fulltext"). The indexing and retrieval is done using Terrier IR and several weighing models are applied to analyze their performance for this type of task. For the concept-space component, only the title and abstract of the medical article are used for extraction of medical concepts. The tool for medical concept extraction is Metamap and the extracted results are UMLS concepts. The rest of the process for the concept-space approach is identical to the concept-space ad-hoc retrieval. The final result is provided with the late fusion of both components using linear combination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Evaluating on ImageCLEF 2012</head><p>The proposed framework was again evaluated on the ImageCLEF 2012 dataset. The results of the word-space assessment are depicted on Table <ref type="table" coords="10,419.69,324.83,3.87,8.74" target="#tab_5">6</ref>. The results show that the BM25 model provides the best performance for the word-space case-based retrieval. An additional experiment was performed with the best model by adding query expansion. The results for the experiment with the query expansion (BM25-qe) show that the query expansion increase retrieval performance by roughly 4%. The results of the concept-space assessment are depicted on Table <ref type="table" coords="10,441.06,559.12,3.87,8.74" target="#tab_6">7</ref>. In this case the best results are provided with the DirichletLM model. An additional experiment was performed using query expansion on the best performing model, which provides an improvement of roughly 2%.</p><p>The results of the mixed assessment are depicted on Table <ref type="table" coords="10,420.30,609.29,3.87,8.74" target="#tab_7">8</ref>. The mixed assessment is consisted of two experiments. The first one is by combining the best word-space and concept-space approaches. The second experiment is done by combining the word-space and concept-space approaches, both with added query expansion. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Results and discussion</head><p>Using the models and optimal parameters learned with the experiments over the ImageCLEF 2012 dataset, the experiments over the ImageCLEF 2013 dataset were performed. The best results were provided with in the case of the mixed experiment using query expansion. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,134.77,440.38,345.83,7.89;3,134.77,451.36,345.82,7.86;3,134.77,462.32,41.98,7.86;3,259.94,312.41,86.51,113.02"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Three different spatial pyramids used in our experiments, a) 1x1, b) 2x2 and c) 3x1. The spatial pyramid constructs feature vectors for each of the specific part of the image.</figDesc><graphic coords="3,259.94,312.41,86.51,113.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,185.04,404.20,245.28,7.89"><head>classesFig. 2 .</head><label>2</label><figDesc>Fig. 2. High level fusion scheme for the different descriptors.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,134.77,336.38,345.82,104.43"><head>Table 1 .</head><label>1</label><figDesc>Results of the runs of modality classification task for ImageCLEF 2012 and 2013.</figDesc><table coords="5,222.68,366.37,169.84,74.44"><row><cell>Dataset</cell><cell cols="2">Run Type Accuracy</cell></row><row><cell></cell><cell>visual</cell><cell>66.10</cell></row><row><cell>ImageCLEF 2012</cell><cell>textual mixed</cell><cell>62.90 77.00</cell></row><row><cell></cell><cell>visual</cell><cell>77.14</cell></row><row><cell>ImageCLEF 2013</cell><cell>textual mixed</cell><cell>63.71 78.04</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,158.16,350.23,299.04,105.77"><head>Table 2 .</head><label>2</label><figDesc>Comparison of weighting models for word-space ad-hoc retrieval</figDesc><table coords="8,191.44,371.00,228.68,85.00"><row><cell>Model</cell><cell cols="2">MAP P10 P20 Rprec # of rel. docs</cell></row><row><cell>BB2</cell><cell>0.2056 0.3429 0.2714 0.2411</cell><cell>473</cell></row><row><cell>BM25</cell><cell>0.2266 0.3381 0.3000 0.2559</cell><cell>494</cell></row><row><cell cols="2">DFR-BM25 0.2091 0.3476 0.2738 0.2236</cell><cell>474</cell></row><row><cell>PL2</cell><cell>0.2055 0.3429 0.2643 0.2353</cell><cell>472</cell></row><row><cell cols="2">TF-IDF 0.2085 0.3524 0.2714 0.2194</cell><cell>471</cell></row><row><cell cols="2">DirichletLM 0.1601 0.2619 0.2024 0.1614</cell><cell>434</cell></row><row><cell cols="2">BM25-ww 0.2407 0.3619 0.2929 0.2620</cell><cell>490</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,152.66,523.92,310.03,94.81"><head>Table 3 .</head><label>3</label><figDesc>Comparison of weighting models for concept-space ad-hoc retrieval</figDesc><table coords="8,191.44,544.69,228.68,74.04"><row><cell>Model</cell><cell cols="2">MAP P10 P20 Rprec # of rel. docs</cell></row><row><cell>BB2</cell><cell>0.1257 0.1700 0.1025 0.1433</cell><cell>173</cell></row><row><cell>BM25</cell><cell>0.1230 0.1550 0.1025 0.1441</cell><cell>172</cell></row><row><cell cols="2">DFR-BM25 0.1227 0.1550 0.1000 0.1441</cell><cell>173</cell></row><row><cell>PL2</cell><cell>0.1065 0.1500 0.0950 0.1137</cell><cell>168</cell></row><row><cell cols="2">TF-IDF 0.1226 0.1550 0.1025 0.1402</cell><cell>172</cell></row><row><cell cols="2">DirichletLM 0.1568 0.2450 0.1475 0.1888</cell><cell>232</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,146.29,164.02,322.78,50.98"><head>Table 4 .</head><label>4</label><figDesc>Results for the mixed run of the ad-hoc retrieval on ImageCLEF 2012</figDesc><table coords="9,195.29,184.79,220.98,30.21"><row><cell>Type</cell><cell cols="2">MAP P10 P20 Rprec # of rel. docs</cell></row><row><cell cols="2">Mixed 0.2385 0.3762 0.2738 0.2496</cell><cell>492</cell></row><row><cell cols="2">Mixed-ww 0.2528 0.3857 0.2690 0.2600</cell><cell>488</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,194.26,411.58,223.77,82.11"><head>Table 5 .</head><label>5</label><figDesc>Submitted runs for ad-hoc retrieval</figDesc><table coords="9,194.26,430.61,223.77,63.08"><row><cell>Type</cell><cell>MAP GM-MAP bpref P10 P30</cell></row><row><cell cols="2">word-space 0.2435 0.0430 0.2424 0.3314 0.2248</cell></row><row><cell cols="2">word-space-ww 0.2507 0.0443 0.2497 0.3200 0.2238</cell></row><row><cell cols="2">concept-space 0.1456 0.0244 0.1480 0.2000 0.1286</cell></row><row><cell>mixed</cell><cell>0.2464 0.0508 0.2338 0.3114 0.2200</cell></row><row><cell cols="2">mixed-ww 0.2479 0.0515 0.2336 0.3057 0.2181</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="10,150.55,420.81,314.25,105.77"><head>Table 6 .</head><label>6</label><figDesc>Comparison of weighting models for word-space case-based retrieval</figDesc><table coords="10,191.44,441.58,228.68,85.00"><row><cell>Model</cell><cell cols="2">MAP P10 P20 Rprec # of rel. docs</cell></row><row><cell>BB2</cell><cell>0.1598 0.1435 0.1326 0.1604</cell><cell>217</cell></row><row><cell>BM25</cell><cell>0.1818 0.1522 0.1391 0.1757</cell><cell>222</cell></row><row><cell cols="2">DFR-BM25 0.1816 0.1522 0.1413 0.1767</cell><cell>222</cell></row><row><cell>PL2</cell><cell>0.1780 0.1478 0.1370 0.1861</cell><cell>227</cell></row><row><cell cols="2">TF-IDF 0.1805 0.1522 0.1326 0.1662</cell><cell>221</cell></row><row><cell cols="2">DirichletLM 0.1811 0.1652 0.1283 0.1744</cell><cell>225</cell></row><row><cell cols="2">BM25-qe 0.1994 0.1957 0.1522 0.2198</cell><cell>232</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="11,145.06,116.91,325.25,105.77"><head>Table 7 .</head><label>7</label><figDesc>Comparison of weighting models for concept-space case-based retrieval</figDesc><table coords="11,185.42,137.68,240.71,85.00"><row><cell>Model</cell><cell cols="2">MAP P10 P20 Rprec # of rel. docs</cell></row><row><cell>BB2</cell><cell>0.0691 0.1000 0.0630 0.0874</cell><cell>132</cell></row><row><cell>BM25</cell><cell>0.0705 0.1000 0.0652 0.0815</cell><cell>127</cell></row><row><cell cols="2">DFR-BM25 0.0706 0.1000 0.0652 0.0888</cell><cell>127</cell></row><row><cell>PL2</cell><cell>0.0686 0.0826 0.0674 0.0835</cell><cell>129</cell></row><row><cell>TF-IDF</cell><cell>0.0699 0.0957 0.0609 0.0815</cell><cell>131</cell></row><row><cell cols="2">DirichletLM 0.0841 0.0957 0.0565 0.0988</cell><cell>134</cell></row><row><cell cols="2">DirichletLM-qe 0.1073 0.1261 0.0870 0.1069</cell><cell>158</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="11,138.68,235.91,337.99,50.98"><head>Table 8 .</head><label>8</label><figDesc>Results for the mixed run of the case-based retrieval on ImageCLEF 2012</figDesc><table coords="11,197.85,256.68,215.86,30.21"><row><cell cols="2">Type MAP P10 P20 Rprec # of rel. docs</cell></row><row><cell>mixed 0.1758 0.1565 0.1370 0.1915</cell><cell>222</cell></row><row><cell>mixed-qe 0.2186 0.2043 0.1804 0.2337</cell><cell>235</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="11,182.33,398.22,246.89,94.81"><head>Table 9 .</head><label>9</label><figDesc>Results for the ImageCLEF 2013 dataset</figDesc><table coords="11,182.33,418.99,246.89,74.04"><row><cell>Type</cell><cell cols="2">MAP P10 P20 Rprec # of rel. docs</cell></row><row><cell>word-space</cell><cell>0.2026 0.2057 0.1743 0.2115</cell><cell>549</cell></row><row><cell cols="2">word-space-qe 0.2019 0.2314 0.1957 0.2011</cell><cell>596</cell></row><row><cell cols="2">concept-space 0.0438 0.0829 0.0671 0.0730</cell><cell>300</cell></row><row><cell cols="2">concept-space-qe 0.0632 0.0857 0.0771 0.0850</cell><cell>334</cell></row><row><cell>mixed</cell><cell>0.1832 0.1857 0.1586 0.2036</cell><cell>550</cell></row><row><cell>mixed-qe</cell><cell>0.2059 0.2229 0.1957 0.2235</cell><cell>604</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="11,142.96,560.28,337.63,7.86;11,151.52,571.24,329.07,7.86;11,151.52,582.20,25.60,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,151.52,571.24,183.77,7.86">Overview of the imageclef 2013 medical tasks</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">D</forename><surname>Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,358.68,571.24,97.50,7.86">Working notes of CLEF</title>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,592.79,337.64,7.86;11,151.52,603.75,312.44,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,280.07,592.79,196.28,7.86">Content-based retrieval system for X-ray images</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Dimitrovski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Loskovska</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,165.60,603.75,221.06,7.86">International Congress on Image and Signal Processing</title>
		<imprint>
			<biblScope unit="page" from="2236" to="2240" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,614.33,337.63,7.86;11,151.52,625.27,292.93,7.89" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,312.46,614.33,168.13,7.86;11,151.52,625.29,68.51,7.86">Discriminative cue integration for medical image annotation</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tommasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Orabona</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,228.31,625.29,112.86,7.86">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="1996" to="2002" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.96,635.88,337.63,7.86;11,151.52,646.84,329.07,7.86;11,151.52,657.77,238.14,7.89" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,372.74,635.88,107.85,7.86;11,151.52,646.84,297.08,7.86">Local features and kernels for classification of texture and object categories: A comprehensive study</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Marszalek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,458.04,646.84,22.55,7.86;11,151.52,657.79,148.69,7.86">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="213" to="238" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,120.67,337.64,7.86;12,151.52,131.60,223.81,7.89" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,206.92,120.67,230.90,7.86">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,448.31,120.67,32.28,7.86;12,151.52,131.63,138.96,7.86">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,142.60,337.63,7.86;12,151.52,153.56,329.07,7.86;12,151.52,164.49,95.60,7.89" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,313.61,142.60,166.98,7.86;12,151.52,153.56,66.34,7.86">Evaluating color fescriptors for object and scene recognition</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Van De Sande</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gevers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Snoek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,224.28,153.56,256.32,7.86">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1582" to="1596" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,175.48,337.63,7.86;12,151.52,186.44,329.07,7.86;12,151.52,197.37,51.06,7.89" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="12,455.20,175.48,25.39,7.86;12,151.52,186.44,60.28,7.86">Visual word ambiguity</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Van Gemert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Veenman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">W M</forename><surname>Smeulders</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Geusebroek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,219.59,186.44,261.01,7.86">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,208.37,337.64,7.86;12,151.52,219.33,329.07,7.86;12,151.52,230.29,228.18,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,308.76,208.37,171.83,7.86;12,151.52,219.33,199.22,7.86">Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,374.45,219.33,106.14,7.86;12,151.52,230.29,150.78,7.86">IEEE conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<biblScope unit="page" from="2169" to="2178" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,241.25,337.64,7.86;12,151.52,252.21,329.07,7.86;12,151.52,263.17,60.92,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,453.14,241.25,27.46,7.86;12,151.52,252.21,120.99,7.86">Terrier information retrieval platform</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,298.60,252.21,140.25,7.86">Advances in Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="517" to="519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,274.14,337.97,7.86;12,151.52,285.10,329.07,7.86;12,151.52,296.06,329.07,7.86;12,151.52,307.01,51.70,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,414.29,274.14,66.30,7.86;12,151.52,285.10,170.31,7.86">Overview of the clef 2009 medical image annotation track</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tommasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Welter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Güld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deserno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,348.56,285.10,132.03,7.86;12,151.52,296.06,193.41,7.86">Multilingual Information Access Evaluation II. Multimedia Experiments -LNCS</title>
		<meeting><address><addrLine>Berlin/Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6242</biblScope>
			<biblScope unit="page" from="85" to="93" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,317.98,337.98,7.86;12,151.52,328.94,277.66,9.85" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="12,253.18,317.98,193.78,7.86">LIBSVM: a library for support vector machines</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://www.csie.ntu.edu.tw/~cjlin/libsvm" />
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,339.91,337.98,7.86;12,151.52,350.84,255.24,7.89" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,301.07,339.91,179.52,7.86;12,151.52,350.87,96.65,7.86">A note on Platt&apos;s probabilistic outputs for support vector machines</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">T</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">C</forename><surname>Weng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,256.61,350.87,72.34,7.86">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="267" to="276" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,361.84,337.97,7.86;12,151.52,372.79,329.07,7.86;12,151.52,383.75,319.34,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,232.52,372.79,248.06,7.86;12,151.52,383.75,72.92,7.86">Overview of the imageclef 2012 medical image retrieval and classification tasks</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Eggel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,246.43,383.75,186.47,7.86">CLEF (Online Working Notes/Labs/Workshop</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,394.72,337.97,7.86;12,151.52,405.68,329.07,7.86;12,151.52,416.64,155.81,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,217.11,394.72,263.48,7.86;12,151.52,405.68,87.65,7.86">Effective mapping of biomedical text to the umls metathesaurus: the metamap program</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Aronson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,261.21,405.68,149.43,7.86">Proceedings of the AMIA Symposium</title>
		<meeting>the AMIA Symposium</meeting>
		<imprint>
			<publisher>American Medical Informatics Association</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,427.61,337.98,7.86;12,151.52,438.56,329.07,7.86;12,151.52,449.50,161.84,7.89" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="12,169.72,438.56,307.31,7.86">Mesh up: effective mesh text classification for improved document retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Trieschnigg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pezik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jong</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Kraaij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Rebholz-Schuhmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,151.52,449.52,58.56,7.86">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1412" to="1418" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,460.49,337.98,7.86;12,151.52,471.45,329.07,7.86;12,151.52,482.41,106.43,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="12,363.27,460.49,117.33,7.86;12,151.52,471.45,182.32,7.86">Mrim at imageclef2012. from words to concepts: A new counting approach</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Abdulahhad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">P</forename><surname>Chevallet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Berrut</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,358.50,471.45,122.09,7.86;12,151.52,482.41,72.84,7.86">Notebook Papers of Labs and Workshop (CLEF)</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,493.38,337.98,7.86;12,151.52,504.34,329.07,7.86;12,151.52,515.29,153.88,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="12,190.63,504.34,289.97,7.86;12,151.52,515.29,19.07,7.86">Overview of the imageclef 2012 medical image retrieval and classification tasks</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">D</forename><surname>Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Eggel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,178.49,515.29,98.24,7.86">Working Notes of CLEF</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,526.26,337.98,7.86;12,151.52,537.22,329.07,7.86;12,151.52,548.18,329.07,7.86;12,151.52,559.14,32.25,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="12,406.19,526.26,74.40,7.86;12,151.52,537.22,329.07,7.86;12,151.52,548.18,36.91,7.86">University of glasgow at webclef 2005: Experiments in per-field normalisation and language specific stemming</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,213.41,548.18,194.40,7.86">Accessing Multilingual Information Repositories</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="898" to="907" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,570.11,337.98,7.86;12,151.52,581.06,329.07,7.86;12,151.52,592.00,196.83,7.89" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="12,297.10,570.11,183.50,7.86;12,151.52,581.06,213.87,7.86">Probabilistic models of information retrieval based on measuring the divergence from randomness</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,375.66,581.06,104.94,7.86;12,151.52,592.02,107.38,7.86">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="357" to="389" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,602.99,337.97,7.86;12,151.52,613.92,329.07,7.89;12,151.52,624.91,13.82,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="12,215.49,602.99,265.10,7.86;12,151.52,613.95,82.14,7.86">A probabilistic justification for using tf× idf term weighting in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,241.69,613.95,168.20,7.86">International Journal on Digital Libraries</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="131" to="139" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,635.88,337.98,7.86;12,151.52,646.81,329.07,7.89;12,151.52,657.79,60.92,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="12,240.22,635.88,240.37,7.86;12,151.52,646.84,92.26,7.86">A study of smoothing methods for language models applied to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,250.59,646.84,205.05,7.86">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="214" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.62,120.67,337.97,7.86;13,151.52,131.60,219.30,7.89" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="13,300.97,120.67,179.62,7.86;13,151.52,131.63,29.48,7.86">Score normalization in multimodal biometric systems</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Nandakumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,189.30,131.63,78.24,7.86">Pattern recognition</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2270" to="2285" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
