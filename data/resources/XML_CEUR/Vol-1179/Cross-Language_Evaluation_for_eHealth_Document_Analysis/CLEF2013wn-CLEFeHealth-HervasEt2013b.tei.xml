<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,155.46,115.96,304.44,12.62">UCM at CLEF eHealth 2013 Shared Task1</title>
				<funder ref="#_gSPev5t">
					<orgName type="full">United States National Institutes of Health</orgName>
				</funder>
				<funder ref="#_QUjbGuc">
					<orgName type="full">Shared Annotated Resources</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,158.34,153.65,57.23,8.74"><forename type="first">Lucía</forename><surname>Hervás</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">NIL Group University Complutense of Madrid C</orgName>
								<address>
									<addrLine>Profesor García Santesmases</addrLine>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,226.12,153.65,69.80,8.74"><forename type="first">Víctor</forename><surname>Martínez</surname></persName>
							<email>victormartinezsimon@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">NIL Group University Complutense of Madrid C</orgName>
								<address>
									<addrLine>Profesor García Santesmases</addrLine>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,306.47,153.65,59.81,8.74"><forename type="first">Irene</forename><surname>Sánchez</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">NIL Group University Complutense of Madrid C</orgName>
								<address>
									<addrLine>Profesor García Santesmases</addrLine>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,396.21,153.65,56.34,8.74"><forename type="first">Alberto</forename><surname>Díaz</surname></persName>
							<email>albertodiaz@fdi.ucm.es</email>
							<affiliation key="aff0">
								<orgName type="institution">NIL Group University Complutense of Madrid C</orgName>
								<address>
									<addrLine>Profesor García Santesmases</addrLine>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,155.46,115.96,304.44,12.62">UCM at CLEF eHealth 2013 Shared Task1</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6572BD76F562FCC88E0C8818DF051067</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Natural Language Processing</term>
					<term>medical report</term>
					<term>spellcheck</term>
					<term>acronym expansion</term>
					<term>negated phrase</term>
					<term>speculated phrase</term>
					<term>concept detection</term>
					<term>Metamap</term>
					<term>UMLS</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We are developing a system that analyze medical reports and extract a SNOMED-CT based concept representation. The more interesting characteristic of our system is not only that it can detect the concepts. It also takes into account if they appear in an affirmative, negative or speculative context. The system also separates the concept representation according to the structure of the document. Our system takes these steps: automatic orthographic correction, acronyms and abbreviation detection, negation and speculation phrase detection and medical concepts detection. For participating in Task 1 we have adapted our system in order to obtain the mentions that belong to the Disorders UMLS semantic group. The approach is based on using MetaMap to detect the concepts and the spans. Our aim was to identify what was the best way to use MetaMap in our system to solve the Task 1.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the advent of computers and especially the Internet, the information explosion produced has grown by leaps and bounds.We are in a time where progress allow us to generate, store and distribute lots of information. But all this advances have disadvantages too.</p><p>By this moment lots of information are generated, and differentiate the correct information from the wrong information requires a big amount of money and time.</p><p>With the aim of reduce this two problems, the computer engineers, the software developers and the medicine experts, are developing different strategies to extract information from different places and increase the medical knowledge, to improve researches and in the last term, to have a better live.</p><p>With this aim in mind, we decide to develop a tool to help medical experts in their job.</p><p>During our research, we discover the CLEF tasks <ref type="bibr" coords="2,371.26,142.90,15.50,8.74" target="#b11">[12]</ref> for biomedical documents which is very close of what we are developing so we decide to participate to increase our knowing and the performance of our system.</p><p>We develop software to solve the first task that consist in discover where are the different medical concepts in a medical report and catalogue them, using for this the UMLS CUIs.</p><p>We are developing a system that analyze medical records and extract a SNOMED-CT based concept representation. Before the analysis we have other phases: a language corrector and an acronyms expander. The more interesting characteristic of our system is that not only detect the concepts, it also take into account if they appear in an affirmative, negative or speculative context. The system also separates the concept representation according to the structure of the document, that is, there is a different representation for each section of the document.</p><p>For participating in Task 1 we have adapted our system in order to obtain the mentions that belong to the Disorders UMLS semantic group. The approach is based on using MetaMap to detect the concepts and the spans. Our aim was to identify what was the best way to use MetaMap in our system to solve the Task1.</p><p>We have submitted runs with no external annotations, two for task 1a and two for task 1b. The difference between the runs is only the DB used. We used the 2012AA USAbase strict model for the first run and the 2011AA USAbase strict model for the second run. Our best results for task 1a show 0.504 F1 score with strict evaluation, and 0.660 F1 score with relaxed evaluation. Our best results for task 1b show 0.362 Accuracy with strict evaluation and 0.870 Accuracy with relaxed evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">State of the art</head><p>The aim of this part of the text it's explain the different tools and approximations that actually exists in the world of natural language processing and which of them we use in our project and are used in the software developed for Clef task.</p><p>The different tools analyzed were:</p><p>-Ontologies -MetaMap -Concept detection and disambiguation -Orthographic correction -Negation detection -Speculation detection</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Ontologies</head><p>One definition of what it is an ontology is this: "An ontology defines the basic terms and relations comprising the vocabulary of a subject area, as well as the rules for combining these terms and relations define extensions to the vocabulary" <ref type="bibr" coords="3,154.31,130.95,11.72,8.74" target="#b6">[7]</ref>.</p><p>In medical and biomedical reports, there are two important ontologies: SNOMED-CT and UMLS </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">MetaMap</head><p>The MetaMap program has been used extensively for a wide array of BioNLP studies, such as automatic indexing of biomedical literature and concept based text summarization.</p><p>MetaMap finds Metathesaurus concepts by performing a shallow syntactic analysis of the input text, producing a set of noun phrases. The noun phrases are then used to generate sets of variants which are consequently looked up from the Metathesaurus concepts. Matching concepts are evaluated against the original text and the strength of the mappings are calculated. The candidates are finally combined and the final scores are computed, where the highest score of a complete mapping represents MetaMap's interpretation of the text.</p><p>The MetaMap program is provided to be run both locally and remotely. We ran the current version of MetaMap, MetaMap2012 remotely via the batch mode facility.</p><p>The parameter set that influences the performance of MetaMap included; using a Relaxed model, selecting the NLM2102AB Metathesaurus version, including all derivational variants, enabling unique acronym/abbreviation variants only, allowing large N, preferring multiple concepts and using word sense disambiguation.</p><p>Relaxed Model is a model provided by MetaMap in addition to the Strict model. MetaMap offers the Strict model as a default setting in which all types of filterings are applied, however, we applied the Relaxed model in which only Manual and Lexical filterings are used. While the Strict model is most appropriate for experiments that require the highest accuracy, it only covers only 53% of the Metathesaurus strings. As we consider high coverage of concepts an important factor, we thus applied the relaxed model which consists of up to 83% of Metathesaurus strings.</p><p>The versions of Metathesaurus, Base, USAbase and NLM, provided with MetaMap are different in their Metathesaurus coverage and the license type required for using vocabulary sources. The NLM version which is offered at no cost for research purposes and covers all of the provided Metathesaurus was used in our work.</p><p>Variants, such as inflectional and derivational variants, are computed by MetaMap to account for the textual variation in the text. With this setting, many types of variants are generated recursively, and only acronyms and abbreviations are restricted to the unique ones. In addition, the candidates also include words that can be prepositions, conjunctions or determiners if they occur often enough in Metathesaurus.</p><p>Prefer multiple concepts causes MetaMap to score the mappings with more concepts higher than those with fewer concepts. This option is useful for discovering higher-order relationships among concepts found in the text and as such is assumed to be helpful.</p><p>Word sense disambiguation attempts to solve lexical ambiguities by identifying the correct meaning of a word based on its context. By using this option in MetaMap, the program attempts to solve the ambiguities among equally scoring concepts by choosing the concept(s) based on semantic type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Concept detection and disambiguation.</head><p>When we are detecting a concept, we can't only search any word in the text into a database, because is high probably that this same concept has more than one entrance into the database. To do our work, we start searching different ways to detect and disambiguate concept, and we decide to work with MetaMap software.</p><p>As we have just said, MetaMap, includes concept disambiguation, with a very good result ratio.</p><p>They use an algorithm written on C++, that after a few time, it was written into Java and Perl. This algorithm is based in the Hidden Markov Model and was modify to include contextual and grammatical information to improve the system accuracy.</p><p>The developers also using a training set, learn which words can go with another words based on their grammatical category <ref type="bibr" coords="5,363.04,279.72,14.61,8.74" target="#b10">[11]</ref>.</p><p>With all these improvements, they made an algorithm that with a 1000 different phrases, they have a 97,43% precision with 582 phrases correctly marked and 261 phrases with only one error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Orthographic correction.</head><p>When a doctor it's writing a medical report, he or she may have a misspelling because he or she is writing very fast and taking notes. A little orthographic error can change the meaning of all the phrase so good written reports are recommended.</p><p>We can say that an orthographic corrector it's an algorithm that checks every word into a database and says if this word is correct or if it's incorrect and in this case, says some corrections ordered by a score. The best of all these algorithm is the one who says the better suggestions. To increase the suggestions ratio, they use some different methods like:</p><p>-Distance between words With this kind of improvement, we check how far are some words from another words and the closest words are probably the correct one. There are some different ways to develop this issue. Here are some of them:</p><formula xml:id="formula_0" coords="5,158.68,518.15,157.05,42.61">• Differences between characters • Hamming distance [4] • Levenshtein distance [6] • Damerau-Levenshtein distance [2]</formula><p>• Keyboard distance as Manhattan distance using Needleman-Wunsch algorithm <ref type="bibr" coords="5,206.30,575.26,10.52,8.74" target="#b4">[5]</ref> [8] -Phonetic algorithms All of this improvements check how close are different phonetic sounds between all the phonetic sounds from the two words. The different algorithms for this issue are:</p><p>• Soundex <ref type="bibr" coords="5,208.76,631.71,15.50,8.74" target="#b9">[10]</ref> • New York State Identification and Intelligence System (NYSIIIS) <ref type="bibr" coords="5,457.08,643.00,15.50,8.74" target="#b12">[13]</ref> • Metaphone <ref type="bibr" coords="5,220.39,654.29,10.52,8.74" target="#b8">[9]</ref> 2.5 Negation detection.</p><p>When we talk and write, we don't say every phrases affirmed, we use negative phrase to emphasize different things. On medical reports, negated phrases are very important to detect, because they say some concepts that the patient doesn't have and if we misinterpret this phrases and concepts, we will go in the wrong direction. We use 2 approximations to solve this problem. The first was use the NegEx algorithm as is distributed, and the second option was use the MetaMap NegEx algorithm implementation.</p><p>NegEx algorithm The NegEx algorithm <ref type="bibr" coords="6,322.39,261.53,10.52,8.74" target="#b0">[1]</ref> uses regular expressions to detect when a phrase is negated and say witch word of all causes this detection.</p><p>The algorithm uses as regular expressions, four kind of concepts:</p><p>-Negative words: these are the words that negate all the phrase that appear right after them. -PostNegative words: these are the words that negate the phrase right before them. -Conjunctions: these are the words that connect different negative phrases.</p><p>-Pseudo Negations: these are the words that we may think that make a phrase negative, but the really don't do that, so when we detect this words, we skip them.</p><p>NegEx on MetaMap MetaMap include the NegEx algorithm, but in the year 2009, the MetaMap developers improve the algorithm <ref type="foot" coords="6,369.03,440.00,3.97,6.12" target="#foot_0">1</ref> .</p><p>The improvements where this:</p><p>-Add new words to detect negations like: other than, otherwise, to account for, to explain and then. -Add to MetaMap databases, some negated concepts. If any of this concepts appear in the text, then the phrase is negated. -Join different negated concepts into one, to reduce noise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Speculation detection.</head><p>The speculation detection it's a very important task in biomedical report. Sometimes, specialist aren't really sure about what are they detecting, because some different illness have the same symptoms.</p><p>To resolve this issue, after a web search, we learn how to adapt the NegEx algorithm to detect the speculation phrases into a medical report <ref type="bibr" coords="6,422.57,633.70,9.96,8.74" target="#b2">[3]</ref>.</p><p>Participants will be provided training and test datasets. The evaluation for all tasks will be conducted using the withheld test data. Participating teams are asked to stop development as soon as they download the test data. Teams are allowed to use any outside resources in their algorithms. However, system output for systems that use annotations outside of those provided for Tasks 1 will be evaluated separately from system output generated without additional annotations. • Strict: Total = Total number of reference standard named entities. In this case, the system is penalized for incorrect code assignment for annotations that were not detected by the system. • Relaxed: Total = Total number of named entities with strictly correct span generated by the system. In this case, the system is only evaluated on annotations that were detected by the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Evaluation Measures</head><p>As we have just say, we are developing another system that extract affirmative, negative and speculative concepts from medical reports and when we decide participate on Clef tasks, we made a few changes in our software to satisfy the requisites. Here we will explain what our system does and which changes we made to adjust to Clef tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The software tool</head><p>The first action that is done in our system it's transform the medical report to a XML file, so we can use it easily. To do this little task, we use different and configurable regular expressions, where we define different "Beginning words" witch means the beginning of any different sections in our report. For example, we have this sections: "Allergies", "Family history". When a "Beginning word" is detected, we assume that in this moment, a new sections begins and it continues until the end of the report or another "Beginning Word".</p><p>After that, we made a orthographic correction using the Hunspell's algorithms and dictionaries. We only made a correction if there is a lot of score in the suggestion, because if we correct all the things that Hunspell suggest, we'll probably introduce some noise that in future actions will be very dangerous.</p><p>The next step that we do, it's detect acronyms and abbreviation, using for that 3 kinds of detectors:</p><p>1. A Database that we have developed, witch contains some different acronyms and abbreviation and a few rules to make a little disambiguation. 2. The MetaMap acronym and abbreviation detector. 3. Using MetaMap with an UDA file. The next step in our system it's the negation detection. To do this issue first we think in the NegEx algorithm but MetaMap includes a modified NegEx algorithm so we use this last option.</p><p>After this last step, we have a speculation detector which works very easily. We have a NegEx algorithm modified to detect some speculative words as regular expressions.</p><p>Finally, we have the concept detector.</p><p>To do this finally task, we use MetaMap to detect the different concepts and to know their CUI. MetaMap retrieves some concepts, so to reduce the noise, we only take the concepts with the most score of all of them. We also use the MedPost/SKR server included in MetaMap to have a disambiguation between concepts. Another noise reductive technique that we develop, was a custom dataset of concepts using to create it the MetamorphoSys tool and the DataFileBuilder developed by the MetaMap group.</p><p>After all this job, we save the results in a XML file to use them in the future for different things, like use Lucene to search between different medical reports.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Modifications for CLEF task</head><p>We made a several modifications to make our system complete the Clef tasks.</p><p>First we disable the language corrector, because we assume that all the reports will be right written.</p><p>We also disable the acronym and abbreviation detector because this is the task 2 target.</p><p>We disable the negation and speculative phrase detector because this will be useful in task 3, but to detect concepts, it only make the system run slowly.</p><p>Finally, we make the system to accept only the next semantic types:</p><p>- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>For participating in Task 1 we have adapted our system in order to obtain the mentions that belong to the UMLS semantic group Disorders. The approach is based on using MetaMap to detect the concepts and the spans. We have submitted runs with no external annotations, two for task 1a and two for task 1b. The difference between the runs is only the DB used. We used the 2012AA USAbase strict model for the first run and the 2011AA USAbase strict model for the second run. Our best results for task 1a shown a 0.504 F1 score with strict evaluation, and a 0.660 F1 score with relaxed evaluation. In strict evaluation 18th and 20th of 27 runs. In relaxed evaluation, 21th and 22th of 28 runs. Explain the differences between strict and relaxed evaluation. Explain the differences between using 2012AA or 2011AA. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Errors and Analysis</head><p>With respect to Task 1a, our system have a lot of false positive, because the only word sense disambiguation that we use, it's with the MedPost/SKR server included in MetaMap distribution, and better with the databases of 2011. With respect to Task 1b, we have a very good ratio detection of CUIs. MetaMap returns a lot of possible candidates, but we decide to save only the one with bigger score and in case of there are more than one with the same score, the first to appear in the list. We fail in this task for two reasons:</p><p>1. We don't take a look on the other results that MetaMap retrieve, so maybe the good one it's the second with most score. 2. We have the same error than in task 1a, we don't have a good word sense disambiguation, so we have lots of false positive detections.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="7,134.77,282.52,285.60,8.74;7,149.71,295.67,330.88,8.74;7,134.77,307.63,345.83,8.74;7,134.77,319.59,105.13,8.74;7,149.71,332.74,128.30,8.74;7,140.99,357.46,263.77,8.77;7,140.99,370.62,127.49,8.77;7,140.99,383.78,139.62,8.77;7,140.99,396.94,84.02,8.77;7,140.99,410.10,97.80,8.77;7,140.99,423.26,94.59,8.77;7,134.77,446.82,277.40,8.74;7,149.71,459.98,264.31,8.74;7,149.71,473.14,330.88,8.74;7,134.77,485.10,279.48,8.74;7,149.71,498.26,132.25,8.74;7,140.99,522.97,126.19,8.77;7,140.99,536.13,339.60,8.77;7,151.70,548.12,106.36,8.74;7,140.99,561.25,339.60,8.77;7,151.70,573.23,32.16,8.74"><head>Task 1 -</head><label>1</label><figDesc>Named entity recognition and normalization of disorders A. Boundary detection of disorders: identify the span of all named entities that could be classified by the UMLS semantic group Disorder (excluding the semantic type Findings) Evaluation measure: F1-score -F1-score = (2 * Recall * Precision) / (Recall + Precision) -Recall = TP / (TP + FN) -Precision = TP / (TP + FP) -TP = same span -FP = spurious span -FN = missing span Exact F1-score: span is identical to the reference standard span Overlapping F1-score: span overlaps reference standard span B. Named entity recognition and normalization of disorders: identify the boundaries of disorders and map them to a SNOMED-CT code. Evaluation measure: Accuracy -Accuracy = Correct/Total -Correct = Number of disorder named entities with strictly correct span and correctly generated code -Total = Number of disorder named entities, depending on strict or relaxed setting:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,197.99,567.26,219.38,71.15"><head>Table 1 .</head><label>1</label><figDesc>Task 1A. No external annotations. Strict</figDesc><table coords="9,197.99,586.32,219.38,52.10"><row><cell>Team,Country</cell><cell>Precision Recall F1-Score</cell></row><row><cell cols="2">UTHealth CCB.2, UT, USA 0.800 0.706 0.750</cell></row><row><cell>NIL-UCM.2, Spain</cell><cell>0.617 0.426 0.504</cell></row><row><cell>NIL-UCM.1, Spain</cell><cell>0.621 0.416 0.498</cell></row><row><cell>FAYOLA.1, VW, USA</cell><cell>0.024 0.446 0.046</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="10,197.99,167.85,219.38,71.15"><head>Table 2 .</head><label>2</label><figDesc>Task 1A. No external annotations. Relaxed</figDesc><table coords="10,197.99,186.90,219.38,52.10"><row><cell>Team,Country</cell><cell>Precision Recall F1-Score</cell></row><row><cell cols="2">UTHealth CCB.2, UT, USA 0.925 0.827 0.873</cell></row><row><cell>NIL-UCM.2, Spain</cell><cell>0.809 0.558 0.660</cell></row><row><cell>NIL-UCM.1, Spain</cell><cell>0.812 0.543 0.651</cell></row><row><cell>FAYOLA.1, VW, USA</cell><cell>0.504 0.043 0.079</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="10,194.94,352.87,225.47,71.15"><head>Table 3 .</head><label>3</label><figDesc>Task 1B. No external annotations. Strict</figDesc><table coords="10,194.94,371.92,225.47,52.10"><row><cell cols="3">Team,Country Accuracy(sn2012) Accuracy(sn2011)</cell></row><row><cell>NCBI.2, MD, USA</cell><cell>0.589</cell><cell>0.584</cell></row><row><cell>NIL-UCM.2, Spain</cell><cell>0.362</cell><cell>0.362</cell></row><row><cell>NIL-UCM.1, Spain</cell><cell>0.362</cell><cell>0.362</cell></row><row><cell>NCBI.2, MD, USA</cell><cell>0.006</cell><cell>0.006</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="10,175.87,537.89,263.61,71.15"><head>Table 4 .</head><label>4</label><figDesc>Task 1B. No external annotations. Relaxed</figDesc><table coords="10,175.87,556.94,263.61,52.10"><row><cell>Team,Country</cell><cell cols="2">Accuracy(sn2012) Accuracy(sn2011)</cell></row><row><cell>AEHRC.1, QLD, Australia</cell><cell>0.939</cell><cell>0.939</cell></row><row><cell>NIL-UCM.1, Spain</cell><cell>0.871</cell><cell>0.870</cell></row><row><cell>NIL-UCM.2, Spain</cell><cell>0.850</cell><cell>0.850</cell></row><row><cell>UTHealth CCB.1, UT, USA</cell><cell>0.728</cell><cell>0.772</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="6,144.73,656.80,230.91,7.86"><p>http://metamap.nlm.nih.gov/MM09 Release Notes.shtml</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We want to acknowledge the support given by the <rs type="funder">Shared Annotated Resources</rs> (<rs type="projectName">ShARe</rs>) project, funded by the <rs type="funder">United States National Institutes of Health</rs> with grant number <rs type="grantNumber">R01GM090187</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_QUjbGuc">
					<orgName type="project" subtype="full">ShARe</orgName>
				</org>
				<org type="funding" xml:id="_gSPev5t">
					<idno type="grant-number">R01GM090187</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="11,138.35,404.96,342.24,7.86;11,146.91,415.92,333.68,7.86;11,146.91,426.88,324.42,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,163.12,415.92,317.47,7.86;11,146.91,426.88,40.66,7.86">A simple algorithm for identifying negated findings and diseases in discharge summaries</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">W</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Bridewell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">G</forename><surname>Buchanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,195.17,426.88,133.47,7.86">Journal of biomedical informatics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="301" to="310" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.35,437.81,342.24,7.86;11,146.91,448.77,255.27,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,211.25,437.81,265.67,7.86">A technique for computer detection and correction of spelling errors</title>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">J</forename><surname>Damerau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,146.91,448.77,115.05,7.86">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="171" to="176" />
			<date type="published" when="1964">1964</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.35,459.70,342.25,7.86;11,146.91,470.66,333.68,7.86;11,146.91,481.62,333.68,7.86;11,146.91,492.58,295.06,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,382.60,459.70,98.00,7.86;11,146.91,470.66,281.92,7.86">The CoNLL-2010 shared task: learning to detect hedges and their scope in natural language text</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Farkas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vincze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Mra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Csirik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Szarvas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,445.37,470.66,35.22,7.86;11,146.91,481.62,333.68,7.86;11,146.91,492.58,224.18,7.86">Proceedings of the Fourteenth Conference on Computational Natural Language Learning-Shared Task. Association for Computational Linguistics</title>
		<meeting>the Fourteenth Conference on Computational Natural Language Learning-Shared Task. Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="1" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.35,503.52,342.24,7.86;11,146.91,514.48,169.74,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,220.87,503.52,167.05,7.86">Error detecting and error correcting codes</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">W</forename><surname>Hamming</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,394.75,503.52,85.84,7.86;11,146.91,514.48,27.12,7.86">Bell System technical journal</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="147" to="160" />
			<date type="published" when="1950">1950</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.35,525.41,342.24,7.86;11,146.91,536.37,107.84,7.86" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="11,205.29,525.41,238.19,7.86">Taxicab geometry: An adventure in non-Euclidean geometry</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">F</forename><surname>Krause</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>Courier Dover Publications</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.35,547.30,342.24,7.86;11,146.91,558.26,227.29,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,224.98,547.30,255.61,7.86;11,146.91,558.26,25.64,7.86">Binary codes capable of correcting deletions, insertions and reversals</title>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">I</forename><surname>Levenshtein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,190.05,558.26,88.83,7.86">Soviet physics doklady</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page">707</biblScope>
			<date type="published" when="1966">1966</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.35,569.20,342.25,7.86;11,146.91,580.16,333.68,7.86;11,146.91,591.12,25.60,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,164.62,580.16,171.81,7.86">Enabling technology for knowledge sharing</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Neches</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Fikes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Finin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gruber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Senator</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Swartout</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,343.54,580.16,48.86,7.86">AI magazine</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">36</biblScope>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.35,602.05,342.24,7.86;11,146.91,613.01,333.68,7.86;11,146.91,623.97,135.67,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,299.00,602.05,181.59,7.86;11,146.91,613.01,212.57,7.86">A general method applicable to the search for similarities in the amino acid sequence of two proteins</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">B</forename><surname>Needleman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Wunsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,365.81,613.01,110.94,7.86">Journal of molecular biology</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="443" to="453" />
			<date type="published" when="1970">1970</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.35,634.90,342.24,7.86;11,146.91,645.86,47.89,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,193.43,634.90,105.88,7.86">Hanging on the metaphone</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Philips</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,306.60,634.90,79.62,7.86">Computer Language</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
	<note>December</note>
</biblStruct>

<biblStruct coords="11,142.62,656.80,257.45,7.86" xml:id="b9">
	<analytic>
		<title/>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Odell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,259.65,656.80,79.91,7.86">Soundex. US Patent</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<date type="published" when="1918">1918</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,119.67,337.97,7.86;12,146.91,130.63,157.63,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,334.65,119.67,145.94,7.86;12,146.91,130.63,61.03,7.86">MedPost: a part of speech tagger for biomedical text</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rindflesch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Wilbur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,214.76,130.63,57.05,7.86">Bioinformatics</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.62,141.59,337.97,7.86;12,146.91,152.55,244.19,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,322.28,141.59,158.31,7.86;12,146.91,152.55,82.56,7.86">Three Shared Tasks on Clinical Natural Language Processing</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Salantera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Velupillai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,236.64,152.55,86.34,7.86">Proceedings of CLEF</title>
		<meeting>CLEF</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct coords="12,142.62,163.51,337.98,7.86;12,146.91,174.47,225.08,7.86" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="12,200.93,163.51,95.23,7.86">Name search techniques</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L</forename><surname>Taft</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1970">1970</date>
			<publisher>New York State Identification and Intelligence System</publisher>
		</imprint>
		<respStmt>
			<orgName>Bureau of Systems Development</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
