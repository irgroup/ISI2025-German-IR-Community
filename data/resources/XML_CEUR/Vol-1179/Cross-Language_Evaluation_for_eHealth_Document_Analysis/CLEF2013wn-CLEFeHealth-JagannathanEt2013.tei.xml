<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,155.06,152.67,285.07,12.64;1,267.65,170.67,59.95,12.64">WVU NLP Class Participation in ShARe/CLEF Challenge</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,130.58,210.18,61.58,8.96"><forename type="first">V</forename><surname>Jagannathan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">West Virginia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,205.35,210.18,46.59,8.96"><forename type="first">D</forename><surname>Ganesan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">West Virginia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,260.31,210.18,61.57,8.96"><forename type="first">A</forename><surname>Jagannathan</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">West Virginia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,330.15,210.18,31.07,8.96"><forename type="first">R</forename><surname>Kavi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">West Virginia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,369.53,210.18,35.31,8.96"><forename type="first">A</forename><surname>Lamb</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">West Virginia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,413.21,210.18,35.04,8.96"><forename type="first">F</forename><surname>Peters</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">West Virginia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,456.53,210.18,4.01,8.96;1,282.41,222.18,27.06,8.96"><forename type="first">S</forename><surname>Seeger</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">West Virginia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,330.31,244.19,36.20,8.10"><forename type="first">M</forename><forename type="middle">*</forename><surname>Modal</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">West Virginia University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,155.06,152.67,285.07,12.64;1,267.65,170.67,59.95,12.64">WVU NLP Class Participation in ShARe/CLEF Challenge</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">757DF99C7629BFC5900CA160E6FD6169</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The spring 2013 graduate class in NLP decided to participate in the ShARe/CLEF challenge Tasks 1 &amp; 2. The timing for the challenge coincided nicely with the spring semester session. There were six students in the graduate class, and the challenge tasks appeared to be good material to expose students to a practical task faced by healthcare industry. The general approach used by the class is to use CRF learning algorithm using Factoriea scala-language based toolkit. The F-scores for best results for Task 1a relaxed -0.801, 1a strict -0.554, 1b relaxed -0.625 &amp; 1b strict 0.349, respectively. Task 2 was attempted as a group task. F-scores were 0.426 and 0.428 for strict and relaxed respectively. It was a real challenge to focus on the challenge as a class project. The students did learn how to apply NER CRF engine to a practical problem.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Natural Language Processing (NLP) challenges have been a long standing tradition in both the main stream computer science discipline and the medical informatics community. Understanding clinical text and providing practical solutions based on the information extracted from such clinical text is currently a burgeoning industry. The solutions range from supporting revenue cycle tasks, such as computer-assisted coding to extracting quality measures to providing clinical decision support.</p><p>There has been an avalanche of work in the NLP domain by the medical informatics research community. And, a number of research challenges, such as the ones hosted by the i2b2 community. The fifth such challenge focused on the NLP task of coreference resolution <ref type="bibr" coords="1,208.01,550.31,10.69,8.96" target="#b0">[1]</ref>. These challenges in academia serve an important purpose of furthering the state of the art and practice of NLP and equipping the next generation of students to address practical solutions in the marketplace. With this goal in mind, we engaged the entire class, albeit a small one, to focus their energies on participating in the ShARe/CLEF NLP challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Approach</head><p>The challenge task involves recognizing problem concepts in clinical text and encoding them using SNOMED. In the NLP literature the task of recognizing and annotating concepts is described as a "named entity recognition (NER)" task. The same was broken into two tasks: Task 1 and Task 2, where task 1 focused on recognizing problem concepts and encoding them and Task 2 involved recognizing acronyms and encoding them.</p><p>The various broad approaches to addressing NLP processing can be characterized as follows: rules-based, machine learning approaches or hybrid. Rule-based approaches rely on recognizing word patternstypically using "regex" pattern matchers. Of recent, there has been an impressive array of results that show machinelearning approaches can be effective for the tasks at hand. Hybrid approaches take the practical aspect of both approaches to provide a combined solution.</p><p>For the class, we decided to explore machine learning approaches, and in particular to use the Conditional Random Field (CRF) approach. CRF has been used successfully in a number of research efforts. We also decided to use the Scala-based toolkit Factorie <ref type="bibr" coords="2,159.95,294.21,10.66,8.96" target="#b1">[2]</ref>.</p><p>Figure <ref type="figure" coords="2,164.63,306.21,4.98,8.96">1</ref> gives the general pipeline all the students used in creating the solution. The instructor provided the basic conversion routines for the class. The Factorie toolkit utilized an in-line token format, while the contest data was an off-line annotation. So, a sentence such as this:</p><p>The patient is a 40-year-old female with complaints of headache and dizziness.</p><p>Along with this annotation:</p><formula xml:id="formula_0" coords="2,124.70,665.49,283.22,18.44">00098-016139- DISCHARGE_SUMMARY.txt||Disease_Disorder||C0018681||330||338 00098-016139- DISCHARGE_SUMMARY.txt||Disease_Disorder||C0012833||343||352</formula><p>Results in the following token format: The fields of the format are: the word itself, place holder for parts-of-speech tag, place holder for chunking tag, the NER-label (one of Disease-Disorder, or O for other), data file name, character offset to reconstruct the results set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preprocess and features</head><p>Each student tried to use various ways to add features. A few used the OpenNLP tool-kit to add parts-of-speech and chunking (noun phrase, verb phrase etc). Standard lexical features everyone tried included: suffix, prefix, word shape, punctuation and capitalization of tokens. Few tried n-grams features, looking at two tokens before and two tokens after the current token. Another feature tried by one student was a compilation of list of words from SNOMED Core. This list ignored words of length four or less and also a number of stop words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Machine Learner -CRF</head><p>Linear chain CRF is particularly suited to address NER problems. The Factorie toolkit came prepackaged with examples of using it. As a first exercise in the semester, before the current NLP challenge data set was released, the students practiced with data set from i2b2 challenge that provided annotations of problems, medications and tests. They continued to enhance the CRF engine when the challenge data was released. The parameter estimation and training the CRF-model was done using Factorie's default enginewhich used a stochastic gradient descent algorithm. One student experimented with Gibbs sampling. Factorie provides a variety of approaches to optimize and select parameters for machine learning the model that best predicts the label associated with a specific token. The output of the machine learner is simply an assignment of a label to the token. In the case of the challenge, we only had two pos-sible outputs: I_Disease_Disorder or O (for other). This was a simple in-out encoding of a token.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Post-processing the output</head><p>The basic post-processing needed here was to concatenate consecutive I_Disease_Disorder tokens to single NER span. One student attempted to find discontinuous NER spans representing a coherent concept using rules, while all others avoided addressing such spans. The last step of this process was to take the token format and generate the pipe-delimited format of annotations used by the challenge organizers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">SNOMED CUI Mapping</head><p>By and large, all the students landed up trying to use Levenshtein distance to SNOMED CUI descriptions to NER label found in the previous step. Students experimented with various distances from 1 to 4. One student tried using Apache Lucene search on the NER concept over the SNOMED CUI descriptions. The process, however was excruciatingly slowas there are lots of NER labels in the data set and each one needs to be compared with thousands of SNOMED concepts and took for all students many hours of computation time. One student used Scala parallelization and successfully sped up the computation time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Acronym expansion and mapping</head><p>The second task of the challenge which involved recognizing medical abbreviations and mapping them to SNOMED CUIs was tackled as a group class project, as opposed to individual effort. Few students concentrated their efforts in compiling a dictionary of acronyms. We had multiple sources of acronyms to work with: 1) training data, 2) UMLS data sets, 3) general web sites. In addition, tricks to generate acronyms from general descriptions was also attemptedsuch as taking a UMLS description of "Congestive Heart Failure" and generating "CHF" from it. Obviously, it will have lots of noise, but those generated acronyms are unlikely to occur in real text. Some manual pruning of this set was also attempted. The persons who had the highest scores on NER recognition in training data were entrusted to run the machine learner with the acronym lexicon as features. The acronyms output as NER labels were then matched to SNOMED CUIs as before.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results discussions</head><p>The overall results obtained by the class are as follows: F-scores for best results for Task 1a relaxed -0.801, 1a strict -0.554, 1b relaxed -0.625 &amp; 1b strict 0.349. For Task 2, F-scores were 0.426 and 0.428 for strict and relaxed respectively.</p><p>The NER labeling task, using the relaxed scoring, was the best score achieved. This is actually to be expected, as none of the students attempted to code discontinuous spans which require building a collection of post-coordination rules or more sophisticated factor graph models in CRF. The SNOMED CUI mapping was interesting in that the students failed to do well here. CRF models are ideal for recognizing and labeling problems (or medications or labs for that matter)but once you have a label, coding it is its own domain of problem. The solutions attempted were simplistic and time consuming. Here one could approach with a rule-based solutionwhich potentially obviates the need for the machine learner in the first place!</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>One general observation of using the challenge as a class project was that it was simply too much work to be done within the constraints of one class. The students were new to both Scala and Factorie toolkit and though some had exposure to machine learning techniques, they were there to learn NLP techniques. The trade-offs that the class had to make was one really large complex project versus a range of small projects covering various topicsthat are typical of such classes. None the less, it was a learning experience and the complexities of dealing with real problems were selfevident to the students.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,266.97,577.00,91.45,9.13"><head></head><label></label><figDesc>Figure 1: Approach used</figDesc></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We are grateful to the organizers of this challenge to give us the data set for use in a graduate class.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="5,132.67,513.04,337.99,8.10;5,141.74,524.08,328.88,8.10;5,141.74,535.12,130.31,8.10" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,141.74,524.08,328.88,8.10;5,141.74,535.12,14.28,8.10">South: Evaluating the state of the art in coreference resolution for electronic medical records</title>
		<author>
			<persName coords=""><forename type="first">Ã–zlem</forename><surname>Uzuner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andreea</forename><surname>Bodnari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shuying</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tyler</forename><surname>Forbush</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Pestian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Brett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,161.90,535.12,27.36,8.10">JAMIA</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="786" to="791" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,132.67,558.04,337.83,8.10;5,141.74,569.08,328.87,8.10;5,141.74,580.12,328.92,8.10;5,141.74,591.04,64.32,8.10" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,267.78,558.04,202.72,8.10;5,141.74,569.08,85.92,8.10">FACTORIE: probabilistic programming via imperatively defined factor graphs</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Schultz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,425.47,569.08,45.14,8.10;5,141.74,580.12,161.93,8.10">Advances in Neural Information Processing Systems</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Schuurmans</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1249" to="1257" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
