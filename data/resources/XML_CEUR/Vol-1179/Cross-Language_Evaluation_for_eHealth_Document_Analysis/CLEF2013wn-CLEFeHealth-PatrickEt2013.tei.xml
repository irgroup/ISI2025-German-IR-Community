<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,133.94,152.75,327.24,12.54;1,171.14,170.75,252.97,12.54">ShARe/CLEF eHealth 2013 Named Entity Recognition and Normalization of Disorders Challenge</title>
				<funder ref="#_7FCA6M5">
					<orgName type="full">United States National Institutes of Health</orgName>
				</funder>
				<funder>
					<orgName type="full">Shared Annotated Resources (ShARe)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,223.37,210.08,55.57,9.05"><forename type="first">Jon</forename><forename type="middle">D</forename><surname>Patrick</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Technologies</orgName>
								<orgName type="laboratory">Health Language Laboratories</orgName>
								<orgName type="institution">The University of Sydney</orgName>
								<address>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,285.32,210.08,45.40,9.05"><forename type="first">Leila</forename><surname>Safari</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Technologies</orgName>
								<orgName type="laboratory">Health Language Laboratories</orgName>
								<orgName type="institution">The University of Sydney</orgName>
								<address>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,337.00,210.08,34.71,9.05"><forename type="first">Ying</forename><surname>Ou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Technologies</orgName>
								<orgName type="laboratory">Health Language Laboratories</orgName>
								<orgName type="institution">The University of Sydney</orgName>
								<address>
									<region>NSW</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,133.94,152.75,327.24,12.54;1,171.14,170.75,252.97,12.54">ShARe/CLEF eHealth 2013 Named Entity Recognition and Normalization of Disorders Challenge</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">315124DB4D2E0110661DF0ACF150FB8A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:32+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Objective: There are abundant mentions of clinical conditions, anatomical sites, medications and procedures in clinical documents. This paper describes use of a cascade of machine learners to automatically extract mentions of named entities about disorders from clinical notes.</p><p>Tasks: A Conditional Random Field (CRF) machine learner has been used for named entity recognition and to capture more complex (multiple word) named entities we have used Support Vector Machines (SVM). Firstly, the training data was converted to the CRF format. Different feature sets were applied using 10-fold cross validation to find the best feature set for the machine learning model. Secondly, the identified named entities were passed to the SVM to find any relation among the identified disorder mentions to decide whether they are a part of a complex disorder.</p><p>Approach: Our approach was based on a novel supervised learning model which incorporates two machine learning algorithms (CRF and SVM). Evaluation of each step included precision, recall and F-score metrics.</p><p>Resources: We have used several tools which are created in our lab including TTSCT (Text to SNOMED CT) service, Lexical Management System (LMS) and Ring-fencing approach. A set of gazetteers was created from the training data and employed in analysis as well.</p><p>Results: Evaluation results produced a precision of 0.766, recall of 0.726 and F-score of 0.746 for named entity recognition based on 10-fold cross validation; and precision, recall and F-measure of 0.927 for relation extraction based on 5-fold cross validation on the training data. On the official test data on strict mode a precision of 0.686, recall of 0.539 and F-score of 0.604 was achieved. Based on the results our team was the 11 th out of 25 participating teams. In the relaxed mode a precision of 0.912, recall of 0.701 and F-score of 0.793 was recorded and our team was the 12 th . A multi stage supervised machine learning method with mixed computational strategies seems to provide a reasonable strategy for automated extraction of disorders.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="706.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Clinical notes usually contain a large number of references to clinical conditions, anatomical sites, medications and procedures with various surface forms for the same concept. Using the rich lexical and ontological resources in the clinical domain like the Unified Medical Language System (UMLS, https://uts.nlm.nih.gov/home.html) or SNOMED CT (Systematized Nomenclature Of Medicine Clinical Terms) facilitates normalization of mentions for medical concepts in which the results can be used to leverage the upper level applications of information extraction or knowledge discovery. Such a fundamental task is the focus of Task 1 of the ShARe/CLEF eHealth 2013 challenge. Task 1 includes the recognition of references to concepts that belong to the UMLS semantic group disorders and the mapping of each mention to a unique UMLS CUI <ref type="bibr" coords="2,144.38,297.11,10.69,9.05" target="#b0">[1]</ref>.</p><p>Moreover, the context of a clinical concept might have valuable information which helps normalizing and finding the correct CUI for that concept. The context is in turn affected by the type of clinical document. For instance, a mention of a clinical concept may have a different CUI if it is used in a discharge summary compared to a radiology report. Although, the context and the document type may create some trivial criteria for normalization of recognized named entities, it is still a challenging task for NLP systems.</p><p>The document types which have been provided for training in Task 1include discharge summaries, ECG reports, echo reports, and radiology reports. A Conditional Random Field machine learner (CRF) <ref type="bibr" coords="2,283.61,417.13,11.72,9.05" target="#b1">[2]</ref> has been used to identify the spans of the provided text which belong to the disorder semantic group and then used the Support Vector Machine (SVM) to identify any relation among a pair of spans to check whether they are a part of a larger reference to disorders or not. A rule based engine has been created to map these spans to the UMLS CUIs but it is not completed yet, so the focus of current work is only reporting the experiments on Task 1a.</p><p>The paper is organized as follows: Section 2 contains a brief explanation of the related work. Section 3 presents the methods which have been used to identify spans of disorders. Section 4 explains the experimental results followed by a discussion and conclusion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Related work</head><p>Successful NLP techniques have been developed for Named Entity recognition and concept extraction in the general domain while the same tasks are more challenging in the clinical domain. Extracting concepts like drug names, diagnosis, symptoms has attracted several researchers. Patrick et.al <ref type="bibr" coords="2,296.81,618.16,10.60,9.05" target="#b2">[3]</ref>, developed a novel supervised learning model that incorporates two machine learning algorithms and several rule-based engines to automatically extract medication information related to drug names, dosage, mode, frequency, duration and reason for administration of a drug from clinical records with F-score of 85.65%.</p><p>The Mayo Clinic information extraction system <ref type="bibr" coords="3,333.79,150.08,11.72,9.05" target="#b3">[4]</ref> was developed to process and extract information from free-text clinical notes including named entities such as diseases, signs/symptoms, anatomical sites and procedures. Attributes related to the named entities including context, status and relatedness to patient are also extracted from the text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Challenge Requirements</head><p>The main objective of the Task1-ShARe/CLEF eHealth challenge is to identify a span of text in the note that corresponds to the mention of a disorder on the one hand and then mapping it to a CUI from the provided terminology (SNOMED CT) on the other hand <ref type="bibr" coords="3,165.35,311.15,12.60,9.05" target="#b0">[1]</ref>. These two tasks are tightly coupled together as a decision for one affects the decision for the other.</p><p>Based on the annotation guidelines provided for Task1 a disorder reference is defined as any span of text that can be mapped to a concept in the SNOMED-CT terminology, which belongs to the disorder semantic group <ref type="bibr" coords="3,343.15,359.15,10.69,9.05">[5]</ref>. A concept is in the disorder semantic group if it belongs to one of the following UMLS semantic types considering that the Findings semantic type should be excluded: </p><formula xml:id="formula_0" coords="3,124.70,403.33,4.58,9.05"></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Corpus Description</head><p>The dataset for Tasks 1 consists of de-identified clinical free-text notes from the MIMIC II database, version 2.5 (mimic.physionet.org). A set of 200 notes is provided for the training task and 100 notes are provided for testing. Notes were authored in the ICU setting and note types include discharge summaries, ECG reports, echo reports, and radiology reports. The training data consist of 3864 annotations for disorder mentions. Some of them are a single annotation (e.g. "headache" or "hypothyroidism") while the others are multiple adjacent tokens (e.g. "neck stiffness" or "MCA aneurysm") or multiple tokens with a distance from each other (e.g. "abdomen … nontender"). About 30 per cent of the annotated disorders belonged to the last catego-ry, multiple tokens with some distance between each other. In conversion of xml annotations to .ann format (section 3.3) each single token of a phrase disorder was annotated as a single disorder which increased the number of annotations from 3864 to 5949. Then a relation was defined among any 2 sequential tokens of the phrase disorders. The details will be explained in the section 3.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">The Classification Strategy</head><p>Figure <ref type="figure" coords="4,153.58,248.15,4.98,9.05" target="#fig_0">1</ref> shows the main work-follow for identifying references to disorders from the clinical documents. A Conditional Random Field machine learner (CRF) was used to identify mention of disorders in this work. Firstly, the training data was converted to the CRF format. The CRF format is like a spread sheet in which each column represents a feature and the last column represents the output tag. The BIO tagging convention [5] is used here. The token tags with class information were converted to B-ENTITY, I-ENTITY and O to represent the beginning of an entity (disorder here), inside an entity (not at the beginning) and not a member of a disorder structure respectively. So, the boundaries of a disorder structure begins with a B label and ends with either an O label or another B label, indicating a new disorder structure. Different feature sets have been applied with ten-fold cross validation to find the best model. In the feature selection process firstly a feature was added to the CRF feature generator to train the model. Then the result was predicted and the performance was recorded. If the performance increased the F-score with adding a feature, this feature was thought to be useful and retained in the feature set; otherwise, it was removed from the feature set.</p><p>To be able to use the tools which have already been developed in the Health Language Laboratories, School of Information Technology, The University of Sydney, there was a need to do some pre-processing tasks on the corpus and annotations which the challenge organizer has provided for the Task1. One of these tasks was converting the annotations from XML or pipeline format to our own .ann format.</p><p>In addition, the whole corpus was loaded into the Lexicon Management System (LMS). The LMS takes care of all new lexical knowledge generated by experts and automatic agents (Knowledge Discovery) and feeds it into the verification process or any other process that needs this information (Knowledge Reuse). So, by using LMS it was possible to prepare the lexical features of the tokens in the training corpus to feed to the CRF feature generator. The LMS categorizes the types of the all tokens in the corpus as "Known", "Unknown" or "Unseen". "Known" means the token has been learned previously and so the primary characteristics have been defined for token, "Unknown" means the tokens are not resolved yet and "Unseen" means the tokens are un-reviewed yet. LMS enables checking each "Unseen" and "Unknown" token and also adding any known information about that token to make it known. Spelling corrections, expansions and semantic categories can be set to make a token as known. Moreover, the lexicon is not a simple list of words but an organization of the words into semantic groups and the form of different representations of words. The following semantic groups are defined in the LMS as the words class of the tokens in the corpus or the whole lexicon:</p><p> Compound Words: In a great deal of clinical terminology, productive forms of words are regularly used. An example is the word vesicle which has the combining form vesico-. The convention will be that the combing form is shown with the hyphen in the LMS, and the canonical form of the compound will include the hyphen, e.g. vesico-ureturic. Compound words are usually defined by two words separated by a non-letter character, typically a hyphen or slash. The hyphen carries the usual morphological interpretation, but the slash is still to be resolved.   Neologisms: These are the words constructed to represent new forms typically used in names of organizations or products, e.g. HealthCare. This excludes drug names which although neologisms are not to be included in this category.  Abbreviations: Shortened forms of words that are not acronyms. e.g. using "backgrd" instead of "background".  Acronyms: Words which are formed from the first letters of a phrase. The letters are usually in uppercase and should be preserved in their orthographic form.  Automatic: The words that have been processed and categorized by direct computational methods without manual intervention.  Named Entity: A large set of classes of different entity types like drug names, equipment, person names, locations, etc.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Get Semantic Features</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Get Lexical Features</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Get Grammatical Features</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Get SNOMED Features</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Get Context Features</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Get Orthography Features</head><p>Using the above facilities in the LMS valid properties like spelling corrections and expansion of abbreviation/acronyms were assigned and also semantic groups were set to tokens to resolve unknown and unseen tokens. Finally, all properties of the known tokens were extracted from the LMS and applied as one or a set of features in the machine learning model.</p><p>Similar to the feature generation process for CRF machine learning, feature sets for SVM machine learner were created to extract relationships between pairs of entities. The details of CRF and SVM experiments will be explained in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">The CRF Experiment for Disorder Recognition</head><p>To find out the best feature set to feed to the CRF machine learner for identifying spans of disorder references five categories of features have been used in our experiments including:  Context Features. Includes the Bag-of-words which provides the context information for a token. The surrounding words usually convey useful information about a token which help in predicting the correct tag for each token. This feature has been used with a window of five tokens. This means that in addition to the token itself, the 2 tokens before and the 2 tokens after the target token are considered for predicting the output tag.  Orthography Feature. Includes the case tag with the values "Lower" for the tokens with all lowercase characters, "Upper" for the tokens with all uppercase characters and "Title", for the tokens which start with an uppercase character but following with the lowercase ones.  Lexical Features. Includes the expansions of abbreviations/acronyms and correction of misspelling words. As explained before, the LMS provides most of the required lexical features. In addition the lowercase of words has been used as another feature.  Grammatical Features. Includes Lemma, part of speech (POS) and chunk features. The GENIA Tagger has been used to produce these features from the training set. By applying the lemma form of the words a more general description of the words has been possible. Also, as a low level grammatical information the POS tags of the words will help in determining the boundaries of instances. Chunk features in a similar way assists in determining expression boundaries.  Ring-fence Feature. The existence of complex and compound phrases mainly for scores and measurements and also for other named entities in the clinical domain necessitate a solution to welding these complex phrases together. The ring fencing method which was originally invented in this Laboratory to identify complex patterns like scores and measurements is used here. The basic idea is to put a fence around a group of tokens and not allow the tokenizer to break them into smaller chunks but rather keep them together as an indivisible token. To accomplish this task a phase of running a Trainable Finite State Automata (TFSA) <ref type="bibr" coords="7,408.55,270.35,11.72,9.05" target="#b4">[6]</ref> on intended phenomena over the text is required.  SNOMED Features. The final features which were utilized in these experiments were the results from the TTSCT service in this Laboratory on the training corpus.</p><p>TTSCT stands for Text to SNOMED CT conversion <ref type="bibr" coords="7,345.37,318.59,12.44,9.05" target="#b5">[7]</ref>. It takes free text and identifies text segments equivalent to SNOMED CT concepts. The algorithm utilizes a dynamic programming search engine to match different parts of the text with SNOMED CT description terms. The running time of the algorithm is in polynomial order (O(n3)) and the F-score is around 70% <ref type="bibr" coords="7,351.19,366.59,10.60,9.05" target="#b5">[7]</ref>. By applying TTSCT the three features of SNOMED CT term (term-tag), concept id (cid) and also top category (cat-tag) are available to be used in the feature generation engine. For instance, for the token "headache" in the corpus TTSCT produces 3 features of "Headache" as term, "25064002" as concept id and "Clinical Finding" as SNOMED CT top category.</p><p>The focus of the experiments was on identifying spans of any "single token" or "multiple adjacent tokens" which are a reference to a disorder while for identifying the reference to a disorder with "multiple separate tokens" SVMs experiment (section 3.5) were utilized in similar way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">SVM Experiment for Relationship Identification</head><p>Once the named entity recognition (NER) task was completed, an SVM was used to classify the relationships between parts of multi-word disorder mentions. Each token of a complex mention of "Disease_Disorder" has been identified and a relationship defined of "part_of_disorder" between each two consecutive tokens in the mention. Also, six categories of features were used to train the SVM to compute valid relationships between pairs which are:  Context features. Includes three words before and three words after each entity in a relation, words between the two entities, words (inside) of each entity and distance between two of the entities in a relation.  Orthography features. Includes title case of first entity and second entity.  Lexical features. Identifies that if the two entities of a relation are in an acronym form or not.</p><p> Semantic features. Includes the types of the two entities determined by the CRF classifier and the entity types between the two entities.  Grammatical features. Includes lemma, POS tag and chunk feature of both entities. Similar to NER experiment with CRF, theses features were extracted using the GENIA Tagger.  SNOMED features. Includes SNOMED CT id (cid), term (term-tag) and top category (cat-tag) for each of the two entities in a relation. Similar to NER experiment with CRF, theses features extracted using TTSCT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussion</head><p>Table <ref type="table" coords="8,150.48,291.83,4.98,9.05" target="#tab_2">1</ref> presents CRF results for detecting the spans of disorders for different feature sets based on five-fold cross validation which was submitted to the challenge Evaluation. As the number of features increases the model is elaborated and the results improved. CRF takes advantage of context, that is, words around a target word and the target word itself (M1) in these experiments. Model 1 was used as the baseline model.</p><p>Then the lowercase of the tokens was added with window of three to construct model M2 which improved the F-score from 0.585 to 0.624. In the model M3, the ring-fence tag was added to the feature set with a slight increase in precision and slight decrease in the recall. But more improvement would be possible available by defining more patterns to the ring-fencing algorithm to capture complex spans. Adding the 3 features of SNOMED CT cat-tag , term-tag and cid from TTSCT (models M4 and M5), increased the F-score to 0.649 in model M5. Increasing the window size for context features to five improved all the scores in the model M6 as well. Finally, by applying the grammatical features using the GENIA Tagger (model M7), include lemma, POS and chunk features the best feature set in model M7 was achieved. To improve the above result more features were added and another experiment was run with ten-fold cross validation. New patterns were defined in the ring fence algorithm to capture more complex patterns and also the CUIs from the CUI-Gaz were applied as another feature. An orthography feature (case feature) was used in the new experiment as well. The final results in ten-fold cross validation are shown in Table <ref type="table" coords="9,463.30,150.08,3.71,9.05" target="#tab_3">2</ref>. According to Table <ref type="table" coords="9,207.48,162.08,3.73,9.05" target="#tab_3">2</ref>, applying the case feature slightly increased the F-Score while applying the CUI feature improved the F-Score by about 0.07. The best score was recorded for Model M11 with the precision of 0.766, recall of 0.726 and F-score of 0.746. Table <ref type="table" coords="9,161.52,441.97,4.98,9.05" target="#tab_4">3</ref> illustrates the SVM results for classifying the relationships between the adjacent spans of disorders which were identified using the CRF machine learner in the previous step. Class 1 represents a valid relationship of "part_of_disorder" between pairs of adjacent entities where they are both annotated as "Disease_Disorder" and class 0 represents the relationship of any other types of entities. As tokens of a complex mention of a Disease_Disorder all appears in one sentence, to improve the results relationship was only created among entities in a single sentence in the training process.</p><p>According to the results in the Table <ref type="table" coords="9,289.49,537.97,3.76,9.05" target="#tab_4">3</ref>, among the features which have been used for finding the best model for training of the SVM, the majority of context features (used in models M1, M2, M9) and the only semantic feature (used in model M3) were useful and improved the results for both classes while using of the other features in models M4 to M8 and M10 to M14 decreased the scores. So, the best model for training the SVM was model M9 with F-score of 0.622 for class 1, 0.960 for class 0 and 0.927 for both classes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>A cascade of machine learning models that was designed to participate in the ShARe/CLEF eHealth Task1 challenge has been introduced. The models were based on a CRF machine learner for detecting the spans of disorder references and a SVM machine learner to identify relationships between spans which are a part of complex references for disorders. Evaluation results showed precision of 0.766, recall of 0.726 and F-score of 0.746 for NER and 0.927 for all three scores for relation extraction on the training data while the official results on the test data showed precision of 0.686, recall of 0.539 and F-score of 0.604 in the strict mode and precision, recall and Fscore of 0.912, 0.701 and 0.793 in the relaxed mode. The results demonstrated that the performance of this system still needs improvement for the purpose of the task 1 of the challenge; however a multi-stage supervised machine learning method with mixed computational strategies seems to provide a near-optimal strategy for automated extraction of disorders. Further improvements are possible by adding new features to the model and also enhancing the performance of TTSCT and ring fencing algorithms. Thus far not all the features which the LMS provides for lexical verification have been used. These tasks will be the focus of interest in future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,147.62,642.10,299.87,8.18"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Workflow of identifying Disorder mentions in ShARe/CLEF eHealth Task1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,124.70,495.67,345.92,130.76"><head>Table 1 .</head><label>1</label><figDesc>CRF results with five-fold cross validation for 7 different feature sets for BIO token tagging</figDesc><table coords="8,131.66,526.35,331.94,100.09"><row><cell>Model to identify disorder spans</cell><cell>TP FP</cell><cell>FN</cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>NUM</cell></row><row><cell>M1 = bag of word with window(3)</cell><cell cols="6">3053 1432 2896 0.681 0.513 0.585 5949</cell></row><row><cell>M2 = M1+ lower case with window(3)</cell><cell cols="6">3404 1554 2545 0.687 0.572 0.624 5949</cell></row><row><cell>M3 = M2+ ring tag</cell><cell cols="6">3238 1146 2711 0.739 0.544 0.627 5949</cell></row><row><cell>M4 = M3 + cat-tag</cell><cell cols="6">3335 1140 2614 0.745 0.561 0.640 5949</cell></row><row><cell>M5 = M4 + term-tag + cid</cell><cell cols="6">3394 1127 2555 0.751 0.571 0.649 5949</cell></row><row><cell>M6 = M4 with window 5 for tokens and lower</cell><cell cols="6">3535 1017 2414 0.777 0.594 0.673 5949</cell></row><row><cell>M7 = M6+ chunk features</cell><cell cols="6">3695 1030 2254 0.782 0.621 0.692 5949</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,124.70,233.90,345.94,192.82"><head>Table 2 .</head><label>2</label><figDesc>CRF results with ten-fold cross validation for 11 different feature sets with BIO token tagging</figDesc><table coords="9,133.82,264.73,324.95,162.00"><row><cell>Model to identify disorder spans</cell><cell>TP</cell><cell>FP</cell><cell>FN</cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>NUM</cell></row><row><cell>M1 = bag of word with window (5)</cell><cell cols="7">3299 1079 2650 0.753 0.554 0.639 5949</cell></row><row><cell>M2 = M1+ lower case of tokens with win-</cell><cell cols="7">3528 1194 2421 0.747 0.593 0.661 5949</cell></row><row><cell>dow(5)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>M3 = M2+ case feature</cell><cell cols="7">3422 942 2527 0.784 0.575 0.663 5949</cell></row><row><cell>M4 = M3+ CUI</cell><cell cols="7">4216 1331 1733 0760 0.709 0.733 5949</cell></row><row><cell>M5 = M4+ ring tag</cell><cell cols="7">4229 1328 1720 0.761 0.711 0.735 5949</cell></row><row><cell>M6 = M6 + lemma</cell><cell cols="7">4249 1356 1700 0.759 0.714 0.735 5949</cell></row><row><cell>M7 = M6 + POS tag</cell><cell cols="7">4256 1349 1693 0.759 0.715 0.737 5949</cell></row><row><cell>M8 = M7 + chunk feature</cell><cell cols="7">4263 1303 1686 0.766 0.717 0.740 5949</cell></row><row><cell>M9 = M 8 + cid</cell><cell cols="7">4265 1336 1684 0.761 0.717 0.739 5949</cell></row><row><cell>M10 = M 9 + term tag</cell><cell cols="7">4272 1321 1677 0.764 0.718 0.740 5949</cell></row><row><cell>M11 = M10+cat tag</cell><cell cols="7">4321 1319 1628 0.766 0.726 0.746 5949</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,130.10,645.82,332.97,44.57"><head>Table 3 .</head><label>3</label><figDesc>SVM results with five-fold cross validation for 14 different feature sets</figDesc><table coords="9,130.10,665.58,332.97,24.82"><row><cell cols="2">Model to identify relationship Class</cell><cell>TP</cell><cell>FP</cell><cell>FN</cell><cell>P</cell><cell>R</cell><cell>F</cell><cell>NUM</cell></row><row><cell>M1= 3 words before and 3</cell><cell>1</cell><cell>1424</cell><cell cols="6">944 1192 0.601 0.544 0.571 2616</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work is supported by the <rs type="funder">Shared Annotated Resources (ShARe)</rs> project funded by the <rs type="funder">United States National Institutes of Health</rs>: <rs type="grantNumber">R01GM090187</rs>. We also would like to give a special thanks to <rs type="person">Dr. Stephen Crawshaw</rs> and other members in the <rs type="institution">Health Information Technologies Research Laboratory</rs> for their valuable contributions.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_7FCA6M5">
					<idno type="grant-number">R01GM090187</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="11,137.89,520.03,332.68,8.18;11,124.70,532.02,186.00,8.19" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,326.59,520.03,143.97,8.18;11,124.70,532.03,75.13,8.18">Three Shared Tasks on Clinical Natural Language Processing</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Salantera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">&amp;</forename><forename type="middle">S</forename><surname>Velupillai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,209.69,532.02,78.51,8.19">Proceedings of CLEF</title>
		<meeting>CLEF</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,137.53,544.03,209.76,8.18" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="11,142.23,544.03,118.89,8.18">CRF++. Yet Another CRF toolkit</title>
		<imprint/>
	</monogr>
	<note>cited 15 Mar 2013</note>
</biblStruct>

<biblStruct coords="11,138.01,556.03,332.37,8.18;11,124.70,568.05,345.99,8.19;11,124.70,580.06,81.77,8.18" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,216.62,556.03,253.76,8.18;11,124.70,568.06,207.42,8.18">High accuracy information extraction of medication information from clinical notes: 2009 i2b2 medication extraction challenge</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">&amp;</forename><forename type="middle">M</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,342.43,568.05,88.67,8.19">J Am Med Inform Assoc</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="524" to="527" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.49,592.06,332.17,8.18;11,124.70,604.06,111.43,8.18;11,124.70,616.05,345.86,8.19;11,124.70,628.05,51.79,8.19" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,392.38,592.06,78.28,8.18;11,124.70,604.06,111.43,8.18">UIMA-based Clinical Information Extraction System</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Savova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kipper-Schuler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>Buntrock</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">G</forename><surname>Chute</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,143.18,616.05,327.38,8.19;11,124.70,628.05,29.37,8.19">LREC 2008 workshop: towards enhanced interoperability for large HLT systems: UIMA for NLP</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.01,652.06,332.25,8.18;11,124.70,664.05,345.97,8.19;11,124.70,676.05,309.13,8.19" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,240.54,652.06,229.73,8.18;11,124.70,664.06,169.47,8.18">An Active Learning Process for Extraction and Standardisation of Medical Measurements by a Trainable FSA</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sabbagh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,316.85,664.05,153.82,8.19;11,124.70,676.05,56.24,8.19">Computational Linguistics and Intelligent Text Processing</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Gelbukh</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="151" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,137.77,150.98,332.51,8.18;12,124.70,162.97,345.99,8.19;12,124.70,174.97,346.00,8.19;12,124.70,186.98,20.35,8.18" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,261.61,150.98,208.67,8.18;12,124.70,162.98,111.76,8.18">An automated system for conversion of clinical notes into SNOMED clinical terminology</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Budd</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,256.61,162.97,214.08,8.19;12,124.70,174.97,31.10,8.19">Proceedings of the fifth Australasian symposium on ACSW frontiers</title>
		<meeting>the fifth Australasian symposium on ACSW frontiers<address><addrLine>Ballarat, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>Australian Computer Society, Inc</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="219" to="226" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
