<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,157.27,113.78,300.77,15.06">Report on CLEF-2003 Multilingual Tracks</title>
				<funder ref="#_y37Ttdz">
					<orgName type="full">Swiss National Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,276.59,152.15,62.18,10.46"><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
							<email>jacques.savoy@unine.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Institut interfacultaire d&apos;informatique</orgName>
								<orgName type="institution">Université de Neuchâtel</orgName>
								<address>
									<addrLine>Pierre-à-Mazel 7</addrLine>
									<postCode>2001</postCode>
									<settlement>Neuchâtel</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,157.27,113.78,300.77,15.06">Report on CLEF-2003 Multilingual Tracks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">28A01966CE5238A17B91533B24D34292</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For our third participation in the CLEF evaluation campaign, our objective for both multilingual tracks is to propose a new merging strategy that does not require a training sample to access the multilingual collection. As a second objective, we want to verify whether our combined query translation approach would work well with new requests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Bilingual Information Retrieval</head><p>In our experiments, we have chosen the English as the query language from which requests are to be automatically translated into seven different languages, using five different machine translation (MT) systems and one bilingual dictionary. The following freely available translation tools were used:</p><p>1. Systran TM babel.altavista.com/translate.dyn, 2.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Based on our experiments of last year <ref type="bibr" coords="1,300.75,340.18,9.96,10.46" target="#b4">[5]</ref>, we are participating in both the small and large multilingual tracks. In the former, we retrieve documents written in the English, French, Spanish, and German languages based on a request written in one given language. Within the large multilingual track, we also had to consider documents written in Italian, Dutch, Swedish, and Finnish. As explained in Section 2, and for both multilingual tracks, we adopt a combined query translation strategy that is able to produce queries in seven European languages based on an original request written in English. After this translation phase, we search in the corresponding document collection using our retrieval scheme (bilingual retrieval) <ref type="bibr" coords="1,177.43,447.78,9.96,10.46" target="#b4">[5]</ref>, <ref type="bibr" coords="1,193.77,447.78,9.96,10.46" target="#b5">[6]</ref>. In Section 3, we carry out a multilingual information retrieval, investigating various merging strategies based on the results obtained during our bilingual searches.</p><p>"Babylon 1"), the first two terms (labeled "Babylon 2") or the first three available translations (labeled "Babylon 3"). Table <ref type="table" coords="2,342.86,129.47,4.98,10.46" target="#tab_0">1</ref> shows the resulting mean average precision using translation tools, using the Okapi probabilistic model and based on word-based indexing scheme. Of course, not all tools can be used for each language, and thus as shown in Table <ref type="table" coords="2,327.96,165.33,4.98,10.46" target="#tab_0">1</ref> various entries are missing (indicated with the label "N/A"). From this data, we see that usually the Reverso or the FreeTranslation system produce interesting retrieval performance. We found only two translation tools for the Swedish and the Finnish languages but unfortunately their overall performance levels were not very good. A particular translation tool may however produce acceptable translations for a given set of requests, but may perform poorly for other queries. This is a known phenomenon <ref type="bibr" coords="2,232.85,465.56,9.96,10.46" target="#b6">[7]</ref>, even for manual translations. When studying various (manual) translations of the Bible, D. Knuth noted: "Well, my first surprise was that there is a tremendous variability between the different translations. I was expecting the translations do differ here and there, but I thought that the essential meaning and syntax of the original language would come through rather directly into English. On the contrary, I almost never found a close match between one translation and another. ... The other thing that I noticed, almost immediately when I had only looked at a few of the 3:16s, was that no translation was consistently the best. Each translation I looked at seemed to have its good moments and its bad moments." <ref type="bibr" coords="2,335.13,589.65,10.52,10.46" target="#b1">[2]</ref> To date we have not been able to detect when a given translation will produce satisfactory retrieval performance and when it will fail. Thus before carrying out the retrieval, we have chosen to generate a translated query by concatenating two or more translations. Table <ref type="table" coords="2,274.07,642.68,4.98,10.46" target="#tab_1">2</ref> shows the retrieval effectiveness for such combinations, using the Okapi probabilistic model (word-based indexing). The top part of the table indicates the exact query translation combination used while the bottom part shows the mean average precision achieved by our combined query translation approach. The resulting retrieval performance is better than the best single translation scheme indicated in the row labeled "Best" (except for the strategy "Comb 1" in Spanish). As described in <ref type="bibr" coords="3,219.89,523.13,9.96,10.46" target="#b5">[6]</ref>, for each language, we used a data fusion search strategy using both the Okapi and Prosit probabilistic models (word-based for French, Spanish and Italian; word-based, decompounding, and n-grams for German, Dutch, Swedish and Finnish). The data shown in Table <ref type="table" coords="3,391.00,558.99,4.98,10.46" target="#tab_2">3</ref> indicates that our data fusion approaches usually show better retrieval effectiveness (except for the Spanish and Italian language) than do the best single IR models used in these combined approaches (row labeled "Single IR"). Of course, before combining the result lists, we could also automatically expand the translated queries using a pseudo-relevance feedback method (Rocchio's approach in the present case). The resulting mean average precision (as shown in Table <ref type="table" coords="3,362.08,630.72,4.43,10.46" target="#tab_3">4</ref>) results in relatively good retrieval performance, usually better than the mean average precision depicted in Table <ref type="table" coords="3,173.79,654.64,3.87,10.46" target="#tab_2">3</ref>, except for the Finnish language. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Multilingual Information Retrieval</head><p>Using the original and the translated queries, we then search for pertinent items within each of the four and eight corpora respectively. From each of these result lists and using a merging strategy, we need to produce a unique ranked result list showing the retrieved items. As a first approach, we considered the roundrobin (RR) approach whereby we took one document in turn from all individual lists <ref type="bibr" coords="5,155.35,200.10,9.96,10.46" target="#b7">[8]</ref>.</p><p>To account for the document score computed for each retrieved item (denoted RSV k for document D k ), we might formulate the hypothesis that each collection is searched by the same or a very similar search engine and that the similarity values are therefore directly comparable <ref type="bibr" coords="5,313.11,247.92,9.96,10.46" target="#b2">[3]</ref>. Such a strategy is called raw-score merging and produces a final list sorted by the document score computed by each collection.</p><p>Unfortunately the document scores cannot be directly compared, thus as a third merging strategy we normalized the document scores within each collection by dividing them by the maximum score (i.e. the document score of the retrieved record in the first position) and denoted them "Norm Max". As a variant of this normalized score merging scheme (denoted "NormN"), we may normalize the document RSV k scores within the ith result list, according to the following formula:</p><formula xml:id="formula_0" coords="5,205.28,372.27,275.31,25.10">N ormN RSV k = RSV k -M inRSV i M axRSV i -M inRSV i (1)</formula><p>As a fifth merging strategy, we might use the logistic regression <ref type="bibr" coords="5,425.05,404.81,10.52,10.46" target="#b0">[1]</ref> to predict the probability of a binary outcome variable, according to a set of explanatory variables <ref type="bibr" coords="5,175.96,428.72,9.96,10.46" target="#b3">[4]</ref>. In our current case, we predict the probability of relevance of document D k given both the logarithm of its rank (indicated by ln(rank k )) and the original document score RSV k as indicated in Equation <ref type="formula" coords="5,381.77,452.63,3.87,10.46">2</ref>. Based on these estimated relevance probabilities (computed independently for each language using the S+ software <ref type="bibr" coords="5,208.94,476.55,10.30,10.46" target="#b8">[9]</ref>), we sort the records retrieved from separate collections in order to obtain a single ranked list. However, in order to estimate the underlying parameters, this approach requires that a training set be developed. To do so in our evaluations we used the CLEF-2002 topics and their relevance assessments.</p><formula xml:id="formula_1" coords="5,167.21,531.71,313.38,25.28">P rob [D k is rel | rank k , RSV k ] = e α+β1•ln(rank k )+β2•RSV k 1 + e α+β 1 •ln(rank k )+β 2 •RSV k (2)</formula><p>As a new merging strategy, we suggest merging the retrieved documents according to the Z-score, taken from their document scores. Within this scheme, we need to compute, for the ith result list, the average of the RSV k (denoted M eanRSV i ) and the standard deviation (denoted StdevRSV i ). Based on these values, we may normalize the retrieval status value of each document D k provided by the ith result list, by computing the following formula:</p><formula xml:id="formula_2" coords="5,183.14,642.34,297.45,25.11">N ormZ RSV k = α i • RSV k -M eanRSV i StdevRSV i + δ i (3) with δ i = M eanRSV i -M inRSV i</formula><p>StdevRSV i within which the value of δ i is used to generate only positive values, and α i (usually fixed at 1) is used to reflect the retrieval performance of the underlying retrieval model.</p><p>The justification for such a scheme is as follows. If the RSV k distribution is linear, as shown in Table <ref type="table" coords="6,245.88,191.50,4.98,10.46" target="#tab_4">5</ref> and in Figure <ref type="figure" coords="6,315.96,191.50,3.87,10.46" target="#fig_0">1</ref>, there is no great difference between a merging approach based on Equation 1 or the proposed Z-score merging strategy. It is our point of view (and this point must still be verified), that such a distribution may appear when the retrieval scheme cannot detect any relevant items. However, after viewing different result lists provided from various queries and corpora, it seems that the top-ranked retrieved items usually provide a much greater RSV values than do the others (see Table <ref type="table" coords="6,360.32,263.23,4.98,10.46" target="#tab_5">6</ref> and Figure <ref type="figure" coords="6,421.71,263.23,3.87,10.46">2</ref>). Thus, our underlying idea is to emphasis this difference between these first retrieved documents and the rest of the retrieved items, by assigning a greater normalized RSV value to these top-ranked documents. Table <ref type="table" coords="6,176.67,558.99,4.98,10.46" target="#tab_6">7</ref> depicts the mean average precision achieved by each single collection (or language) whether the queries used are manually translated (row labeled "Manual") or translated using our automatic translation scheme (row labeled "Auto.").</p><p>Table <ref type="table" coords="6,176.96,606.81,4.98,10.46" target="#tab_7">8</ref> depicts the retrieval effectiveness of various merging strategies. This data illustrates that the round-robin (RR) scheme presents an interesting performance and this strategy will be used as a baseline. On the other hand, the raw-score merging strategy results in very poor mean average precision. The normalized score merging based on Equation 1 (NormN) shows degradation over the  simple round-robin approach (34.92 vs. 36.71, -4.9% in the small, automatic experiment, and 26.52 vs. 29.81, -11% in the large automatic experiment). Using our logistic model with both the rank and the document score as explanatory variables (row labeled "Logistic"), the resulting mean average precision is better than the round-robin merging strategy. As a simple alternative, we also suggest a biased round-robin ("Biased RR" or "bRR") approach which extracts not one document per collection per round but one document for the French, English, Italian, Swedish and Finnish corpus and two from the German, Spanish and Dutch collection (representing larger corpora). This merging strategy results in interesting retrieval performance. Finally, the new Z-score merging approach seems to provide generally satisfactory performance. Moreover, we may multiply the normalized Z-score by an α value (performance under the label "NormZ α i = 1.25" or "NormZ α i = 1.5"). Under the label "NormZ coll-d", the α values are collection-dependant and are fixed as follows: en: 1, fr: 0.9, de: 1.2, sp: 1.25, it: 0.9, nl: 1.15, sv: 0.95, and fi: 0.9.</p><p>Of course, we may combine the two or three best merging strategies (performance depicted in Table <ref type="table" coords="9,244.44,508.92,3.87,10.46" target="#tab_7">8</ref>, namely the "biased round-robin" (denoted "bRR"), "logistic regression" (or "log.") and the "NormZ α i = 1.5" (or "Z-1.5")). Using various data fusion operators, the retrieval effectiveness of these data fusion approaches are shown in Table <ref type="table" coords="9,269.95,544.78,3.87,10.46" target="#tab_8">9</ref>. Finally, the descriptions of our official runs for the small and large multilingual tracks are shown in Table <ref type="table" coords="9,392.66,556.73,8.49,10.46" target="#tab_9">10</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this fourth CLEF evaluation campaign, we have evaluated various query translation tools, together with a combined translation strategy, resulting in a retrieval performance that is worth considering. However, while a bilingual search can be viewed as easier for some pairs of languages (e.g., from an English query into a French document collection), this task is clearly more complex for other languages pairs (e.g., English to Finnish). On the other hand, the multilingual, and more precisely the large multilingual task, shows how searching documents written in eight different languages can represent a challenge. In this case, we have proposed a new simple merging strategy based on the Z-score computed from the document scores, a merging scheme that seems to result in interesting performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="7,206.21,282.17,202.87,9.41"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Graph of normalized RSV (Result list #1)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,134.77,243.96,345.69,162.98"><head>Table 1 .</head><label>1</label><figDesc>Mean average precision of various single translation devices (TD queries, word-based indexing, Okapi model)</figDesc><table coords="2,156.04,275.79,306.32,131.15"><row><cell></cell><cell></cell><cell></cell><cell cols="3">Mean average precision</cell><cell></cell><cell></cell></row><row><cell cols="8">Language French German Spanish Italian Dutch Swedish Finnish</cell></row><row><cell></cell><cell cols="7">52 que. 56 que. 57 que. 51 que. 56 que. 54 que. 45 que.</cell></row><row><cell>Manual</cell><cell>51.64</cell><cell>44.54</cell><cell>48.85</cell><cell>48.80</cell><cell>46.86</cell><cell>40.54</cell><cell>46.54</cell></row><row><cell>Systran</cell><cell>40.55</cell><cell>32.86</cell><cell>36.88</cell><cell>35.43</cell><cell>N/A</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell>Google</cell><cell>40.67</cell><cell>30.05</cell><cell>36.78</cell><cell>35.42</cell><cell>N/A</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell cols="2">FreeTrans 42.70</cell><cell>31.65</cell><cell>39.37</cell><cell cols="2">37.77 29.59</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell cols="2">InterTran 33.65</cell><cell>24.51</cell><cell>28.36</cell><cell>33.84</cell><cell>22.04</cell><cell>23.08</cell><cell>9.72</cell></row><row><cell>Reverso</cell><cell>42.55</cell><cell>35.01</cell><cell>41.79</cell><cell>N/A</cell><cell>N/A</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell cols="2">Babylon 1 41.99</cell><cell>31.62</cell><cell>33.35</cell><cell>33.72</cell><cell>28.81</cell><cell>26.89</cell><cell>9.74</cell></row><row><cell cols="2">Babylon 2 39.88</cell><cell>31.67</cell><cell>31.20</cell><cell>27.59</cell><cell>27.19</cell><cell>20.66</cell><cell>N/A</cell></row><row><cell cols="2">Babylon 3 36.66</cell><cell>30.19</cell><cell>29.98</cell><cell>26.32</cell><cell>24.93</cell><cell>21.67</cell><cell>N/A</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,134.77,208.28,345.69,264.00"><head>Table 2 .</head><label>2</label><figDesc>Mean average precision of various combined translation devices (TD queries, word-based indexing, Okapi model)</figDesc><table coords="3,142.25,240.11,333.92,232.17"><row><cell></cell><cell></cell><cell></cell><cell cols="3">Mean average precision</cell><cell></cell><cell></cell></row><row><cell cols="2">Language French</cell><cell>German</cell><cell>Spanish</cell><cell>Italian</cell><cell cols="3">Dutch Swedish Finnish</cell></row><row><cell></cell><cell>52 que.</cell><cell>56 que.</cell><cell>57 que.</cell><cell cols="4">51 que. 56 que. 54 que. 45 que.</cell></row><row><cell cols="8">Comb 1 Rev+Ba1 Rev+Ba1 Rev+Ba1 Fre+Ba1 Int+Ba1 Int+Ba1 Int+Ba1</cell></row><row><cell>Comb 2</cell><cell cols="6">Rev+Sy Rev+Sy Rev+Sy Fre+Go Fre+Ba1 Int+Ba2</cell><cell></cell></row><row><cell></cell><cell>+Ba1</cell><cell>+Ba1</cell><cell>+Ba1</cell><cell>+Ba1</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">Comb 2b Rev+Go Rev+Go Rev+Go Fre+Int Fre+Ba2</cell><cell></cell><cell></cell></row><row><cell></cell><cell>+Ba1</cell><cell>+Ba1</cell><cell>+Ba1</cell><cell>+Ba1</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">Comb 3 Rev+Go+ Rev+Sys Rev+Go+ Fre+Go+ Fre+Int</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="5">Fre+Ba1 +Int+Ba1 Fre+Ba1 Int+Ba1 +Ba1</cell><cell></cell><cell></cell></row><row><cell cols="6">Comb 3b Rev+Go+ Rev+Go+ Go+Fre+ Fre+Go+ Fre+Int</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="5">Int+Ba1 Int+Ba1 Sys+Ba2 Sys+Ba1 +Ba2</cell><cell></cell><cell></cell></row><row><cell>Comb 3c</cell><cell></cell><cell cols="2">Rev+Sys Rev+Fre</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">+Fre+Ba1 +Ba1</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Best</cell><cell>42.70</cell><cell>35.01</cell><cell>41.79</cell><cell>37.77</cell><cell>29.59</cell><cell>26.89</cell><cell>9.74</cell></row><row><cell>Comb 1</cell><cell>45.68</cell><cell>37.91</cell><cell>40.77</cell><cell>41.28</cell><cell>31.97</cell><cell>28.85</cell><cell>13.32</cell></row><row><cell>Comb 2</cell><cell>45.20</cell><cell>39.98</cell><cell>42.75</cell><cell>41.10</cell><cell>33.73</cell><cell>26.25</cell><cell></cell></row><row><cell>Comb 2b</cell><cell>45.22</cell><cell>39.74</cell><cell>42.71</cell><cell>41.21</cell><cell>31.19</cell><cell></cell><cell></cell></row><row><cell>Comb 3</cell><cell>46.33</cell><cell>39.25</cell><cell>43.15</cell><cell>42.09</cell><cell>35.58</cell><cell></cell><cell></cell></row><row><cell>Comb 3b</cell><cell>45.65</cell><cell>39.02</cell><cell>42.15</cell><cell>40.43</cell><cell>34.45</cell><cell></cell><cell></cell></row><row><cell>Comb 3c</cell><cell></cell><cell>40.66</cell><cell>42.72</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,134.77,173.64,345.69,141.07"><head>Table 3 .</head><label>3</label><figDesc>Mean average precision of automatically translated queries using various data fusion approaches (Okapi &amp; Prosit models)</figDesc><table coords="4,140.04,205.47,338.33,109.24"><row><cell></cell><cell></cell><cell></cell><cell cols="3">Mean average precision</cell><cell></cell><cell></cell></row><row><cell>Language</cell><cell cols="7">French German Spanish Italian Dutch Swedish Finnish</cell></row><row><cell></cell><cell cols="7">52 que. 56 que. 57 que. 51 que. 56 que. 54 que. 45 que.</cell></row><row><cell>data fusion on</cell><cell>2 IR</cell><cell>3 IR</cell><cell>2 IR</cell><cell>2 IR</cell><cell>6 IR</cell><cell>6 IR</cell><cell>3 IR</cell></row><row><cell cols="8">Q combination Comb 3b Comb 3b Comb 2 Comb 3 Comb 3b Comb 1 Comb 1</cell></row><row><cell>Single IR</cell><cell>45.65</cell><cell>39.02</cell><cell>42.75</cell><cell>42.09</cell><cell>34.45</cell><cell>28.85</cell><cell>13.32</cell></row><row><cell>combSUM</cell><cell>46.37</cell><cell>43.02</cell><cell>42.09</cell><cell>41.18</cell><cell>34.84</cell><cell>34.96</cell><cell>20.95</cell></row><row><cell>combRSV%</cell><cell>46.29</cell><cell>42.68</cell><cell>41.96</cell><cell>40.50</cell><cell>35.51</cell><cell>32.04</cell><cell>17.74</cell></row><row><cell>NormN, Eq. 1</cell><cell>46.30</cell><cell>43.06</cell><cell>41.94</cell><cell>40.52</cell><cell>35.48</cell><cell>32.56</cell><cell>17.93</cell></row><row><cell>round-robin</cell><cell>45.94</cell><cell>40.41</cell><cell>42.18</cell><cell>41.42</cell><cell>31.89</cell><cell>29.88</cell><cell>19.35</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,134.77,451.17,345.69,141.07"><head>Table 4 .</head><label>4</label><figDesc>Mean average precision using various data fusion approaches and blind query expansion (Okapi &amp; Prosit models)</figDesc><table coords="4,140.04,483.00,338.33,109.24"><row><cell></cell><cell></cell><cell></cell><cell cols="3">Mean average precision</cell><cell></cell><cell></cell></row><row><cell>Language</cell><cell cols="7">French German Spanish Italian Dutch Swedish Finnish</cell></row><row><cell></cell><cell cols="7">52 que. 56 que. 57 que. 51 que. 56 que. 54 que. 45 que.</cell></row><row><cell>data fusion on</cell><cell>2 IR</cell><cell>3 IR</cell><cell>2 IR</cell><cell>2 IR</cell><cell>6 IR</cell><cell>6 IR</cell><cell>3 IR</cell></row><row><cell cols="8">Q combination Comb 3b Comb 3b Comb 2 Comb 3 Comb 3b Comb 1 Comb 1</cell></row><row><cell>Single IR</cell><cell>45.65</cell><cell>39.02</cell><cell>42.75</cell><cell>42.09</cell><cell>34.45</cell><cell>28.85</cell><cell>13.32</cell></row><row><cell>combSUM</cell><cell>47.82</cell><cell>51.33</cell><cell>47.14</cell><cell>48.58</cell><cell>43.00</cell><cell>42.93</cell><cell>19.19</cell></row><row><cell>combRSV%</cell><cell>49.05</cell><cell>51.50</cell><cell>48.43</cell><cell>48.57</cell><cell>41.19</cell><cell>40.73</cell><cell>17.07</cell></row><row><cell>NormN, Eq. 1</cell><cell>49.13</cell><cell>51.83</cell><cell>48.68</cell><cell>48.62</cell><cell>41.32</cell><cell>41.53</cell><cell>17.21</cell></row><row><cell>round-robin</cell><cell>48.94</cell><cell>46.98</cell><cell>48.14</cell><cell>48.62</cell><cell>36.64</cell><cell>37.18</cell><cell>16.97</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,222.47,329.37,173.46,194.96"><head>Table 5 .</head><label>5</label><figDesc>Result list #1</figDesc><table coords="6,222.47,350.14,173.46,174.19"><row><cell>Rank</cell><cell>RSV</cell><cell>NormZ</cell><cell>NormN</cell></row><row><cell>1</cell><cell>4</cell><cell>3.13049517</cell><cell>1.0</cell></row><row><cell>2</cell><cell>3.75</cell><cell>2.90688837</cell><cell>0.92857143</cell></row><row><cell>3</cell><cell>3.5</cell><cell>2.68328157</cell><cell>0.85714286</cell></row><row><cell>4</cell><cell>3.25</cell><cell>2.45967478</cell><cell>0.78571429</cell></row><row><cell>5</cell><cell>3</cell><cell>2.23606798</cell><cell>0.71428571</cell></row><row><cell>6</cell><cell>2.75</cell><cell>2.01246118</cell><cell>0.64285714</cell></row><row><cell>7</cell><cell>2.5</cell><cell>1.78885438</cell><cell>0.57142857</cell></row><row><cell>8</cell><cell>2.25</cell><cell>1.56524758</cell><cell>0.5</cell></row><row><cell>9</cell><cell>2</cell><cell>1.34164079</cell><cell>0.42857143</cell></row><row><cell>10</cell><cell>1.75</cell><cell>1.11803399</cell><cell>0.35714286</cell></row><row><cell>11</cell><cell>1.5</cell><cell>0.89442719</cell><cell>0.28571429</cell></row><row><cell>12</cell><cell>1.25</cell><cell>0.67082039</cell><cell>0.21428571</cell></row><row><cell>13</cell><cell>1</cell><cell>0.4472136</cell><cell>0.14285714</cell></row><row><cell>14</cell><cell>0.75</cell><cell>0.2236068</cell><cell>0.07142857</cell></row><row><cell>15</cell><cell>0.5</cell><cell>0</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,222.47,320.85,173.46,194.96"><head>Table 6 .</head><label>6</label><figDesc>Result list #2</figDesc><table coords="7,222.47,341.63,173.46,174.19"><row><cell>Rank</cell><cell>RSV</cell><cell>NormZ</cell><cell>NormN</cell></row><row><cell>1</cell><cell>10</cell><cell>2.57352157</cell><cell>1.0</cell></row><row><cell>2</cell><cell>9.9</cell><cell>2.54726114</cell><cell>0.98979592</cell></row><row><cell>3</cell><cell>9.8</cell><cell>2.52100072</cell><cell>0.97959184</cell></row><row><cell>4</cell><cell>9</cell><cell>2.31091733</cell><cell>0.89795918</cell></row><row><cell>5</cell><cell>8.2</cell><cell>2.10083393</cell><cell>0.81632653</cell></row><row><cell>6</cell><cell>7</cell><cell>1.78570884</cell><cell>0.69387755</cell></row><row><cell>7</cell><cell>6.2</cell><cell>1.57562545</cell><cell>0.6122449</cell></row><row><cell>8</cell><cell>4.5</cell><cell>1.12919824</cell><cell>0.43877551</cell></row><row><cell>9</cell><cell>3</cell><cell>0.73529188</cell><cell>0.28571429</cell></row><row><cell>10</cell><cell>2.1</cell><cell>0.49894806</cell><cell>0.19387755</cell></row><row><cell>11</cell><cell>1.4</cell><cell>0.31512509</cell><cell>0.12244898</cell></row><row><cell>12</cell><cell>1.2</cell><cell>0.26260424</cell><cell>0.10204082</cell></row><row><cell>13</cell><cell>1</cell><cell>0.21008339</cell><cell>0.08163265</cell></row><row><cell>14</cell><cell>0.5</cell><cell>0.07878127</cell><cell>0.03061224</cell></row><row><cell>15</cell><cell>0.2</cell><cell>0</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="7,134.77,556.49,345.70,83.64"><head>Table 7 .</head><label>7</label><figDesc>Mean average precision of each individual result lists used in our multilingual search</figDesc><table coords="7,141.49,586.09,335.43,54.04"><row><cell></cell><cell></cell><cell></cell><cell cols="4">Mean average precision</cell><cell></cell><cell></cell></row><row><cell>Lang.</cell><cell cols="8">English French German Spanish Italian Dutch Swedish Finnish</cell></row><row><cell></cell><cell cols="8">54 que. 52 que. 56 que. 57 que. 51 que. 56 que. 54 que. 45 que.</cell></row><row><cell cols="2">Manual 53.25</cell><cell>52.61</cell><cell>56.03</cell><cell>53.69</cell><cell>51.56</cell><cell>50.24</cell><cell>48.77</cell><cell>54.51</cell></row><row><cell>Auto.</cell><cell>53.60</cell><cell>49.13</cell><cell>51.33</cell><cell>48.14</cell><cell>48.58</cell><cell>43.00</cell><cell>42.93</cell><cell>19.19</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="8,139.78,303.15,338.85,184.40"><head>Table 8 .</head><label>8</label><figDesc>Mean average precision of various merging strategies en, fr, de, sp en, fr, de, sp +it, nl, fi +it, nl, sv, fi Small, manual Small, auto.</figDesc><table coords="8,139.78,323.51,338.85,164.03"><row><cell></cell><cell></cell><cell cols="2">Mean average precision (% change)</cell><cell></cell></row><row><cell>Task</cell><cell cols="2">Multi-4</cell><cell cols="2">Multi-8</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Large, manual</cell><cell>Large, auto.</cell></row><row><cell>Merging</cell><cell>60 queries</cell><cell>60 queries</cell><cell>60 queries</cell><cell>60 queries</cell></row><row><cell>RR, baseline</cell><cell>38.80</cell><cell>36.71</cell><cell>34.18</cell><cell>29.81</cell></row><row><cell>Raw-score</cell><cell cols="4">6.48 (-83.3%) 16.48 (-55.1%) 11.69 (-65.8%) 13.65 (-54.2%)</cell></row><row><cell>Norm Max</cell><cell cols="4">16.82 (-56.6%) 33.91 (-7.6%) 16.11 (-52.9%) 25.62 (-14.1%)</cell></row><row><cell cols="5">NormN (Eq. 1) 16.90 (-56.4%) 34.92 (-4.9%) 15.96 (-53.3%) 26.52 (-11.0%)</cell></row><row><cell>Logistic</cell><cell></cell><cell>37.58 (+2.4%)</cell><cell cols="2">32.85 (+10.2%)</cell></row><row><cell>Biased RR</cell><cell cols="4">42.28 (+9.0%) 39.20 (+6.8%) 37.24 (+9.0%) 32.26 (+8.2%)</cell></row><row><cell>NormZ (Eq 3)</cell><cell cols="2">39.44 (+1.6%) 35.07 (-4.5%)</cell><cell>33.40 (-2.3%)</cell><cell>27.43 (-8.0%)</cell></row><row><cell cols="5">NormZ αi = 1.25 41.94 (+8.1%) 37.46 (+2.0%) 36.80 (+7.7%) 29.72 (-0.3%)</cell></row><row><cell cols="5">NormZ α i = 1.5 42.35 (+9.1%) 37.67 (+2.6%) 37.67 (+10.2%) 29.94 (+0.4%)</cell></row><row><cell>NormZ coll-d</cell><cell cols="4">41.28 (+6.4%) 37.24 (+1.4%) 36.25 (+6.1%) 29.62 (-0.6%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="8,134.77,516.42,345.69,129.61"><head>Table 9 .</head><label>9</label><figDesc>Mean average precision of various data fusion operators on two or three merging strategies</figDesc><table coords="8,145.81,547.76,326.78,98.28"><row><cell></cell><cell></cell><cell cols="2">Mean average precision (% change)</cell><cell></cell></row><row><cell>Task</cell><cell cols="2">Multi-4</cell><cell cols="2">Multi-8</cell></row><row><cell></cell><cell cols="4">en, fr, de, sp en, fr, de, sp +it, nl, sv, fi +it, nl, sv, fi</cell></row><row><cell></cell><cell>Small, manual</cell><cell>Small, auto.</cell><cell>Large, manual</cell><cell>Large, auto.</cell></row><row><cell>Data fusion</cell><cell>bRR, Z-1.5</cell><cell>bRR, log., Z-1.5</cell><cell>bRR, Z-1.5</cell><cell>bRR, log., Z.15</cell></row><row><cell>combSUM</cell><cell>42.86</cell><cell>38.52</cell><cell>37.47</cell><cell>31.37</cell></row><row><cell>combRSV%</cell><cell>43.49</cell><cell>38.71</cell><cell>38.37</cell><cell>32.65</cell></row><row><cell>NormN</cell><cell>43.45</cell><cell>38.68</cell><cell>38.36</cell><cell>32.55</cell></row><row><cell>round-robin</cell><cell>43.35</cell><cell>40.32</cell><cell>38.36</cell><cell>33.68</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="9,134.77,115.13,345.69,152.02"><head>Table 10 .</head><label>10</label><figDesc>Description and mean average precision (MAP) of our official runs (small multilingual runs in the top part, and large multilingual in the bottom)</figDesc><table coords="9,150.28,147.36,317.86,119.79"><row><cell cols="3">Run name Query Lang. Form</cell><cell>Type</cell><cell cols="3">Merging Parameters MAP</cell></row><row><cell>UniNEms</cell><cell>English</cell><cell>TD</cell><cell>manual</cell><cell>biased RR</cell><cell></cell><cell>42.28</cell></row><row><cell>UniNEms1</cell><cell>English</cell><cell cols="2">TD automatic</cell><cell>Logistic</cell><cell></cell><cell>37.58</cell></row><row><cell>UniNEms2</cell><cell>English</cell><cell cols="2">TD automatic</cell><cell>NormZ</cell><cell cols="2">α i = 1.25 37.46</cell></row><row><cell>UniNEms3</cell><cell>English</cell><cell cols="2">TD automatic</cell><cell>NormZ</cell><cell>coll-d</cell><cell>37.24</cell></row><row><cell>UniNEms4</cell><cell>English</cell><cell cols="3">TD automatic biased RR</cell><cell></cell><cell>39.20</cell></row><row><cell>UniNEml</cell><cell>English</cell><cell>TD</cell><cell>manual</cell><cell>biased RR</cell><cell></cell><cell>37.24</cell></row><row><cell>UniNEml1</cell><cell>English</cell><cell cols="2">TD automatic</cell><cell>Logistic</cell><cell></cell><cell>32.85</cell></row><row><cell>UniNEml2</cell><cell>English</cell><cell cols="2">TD automatic</cell><cell>NormZ</cell><cell cols="2">α i = 1.25 29.72</cell></row><row><cell>UniNEml3</cell><cell>English</cell><cell cols="2">TD automatic</cell><cell>NormZ</cell><cell>coll-d</cell><cell>29.62</cell></row><row><cell>UniNEml4</cell><cell>English</cell><cell cols="3">TD automatic biased RR</cell><cell></cell><cell>32.26</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. The author would like to thank <rs type="person">C. Buckley</rs> from <rs type="affiliation">SabIR</rs> for giving us the opportunity to use the SMART system. This research was supported in part by the <rs type="funder">Swiss National Science Foundation</rs> (grant #<rs type="grantNumber">21-66 742.01</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_y37Ttdz">
					<idno type="grant-number">21-66 742.01</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,138.35,292.71,342.11,9.41;10,146.91,303.67,68.59,9.41" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">W</forename><surname>Hosmer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lemeshow</surname></persName>
		</author>
		<title level="m" coord="10,273.27,292.71,150.59,9.41">Applied Logistic Regression. 2nd edn</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,314.62,342.10,9.41;10,146.91,325.58,63.22,9.41" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="10,203.90,314.62,193.56,9.41">Things a Computer Scientist Rarely Talks About</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Knuth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
			<publisher>CSLI Publications</publisher>
			<pubPlace>Stanford</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,336.54,342.10,9.41;10,146.91,347.50,333.54,9.41;10,146.91,358.46,191.56,9.41" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,317.23,336.54,163.22,9.41;10,146.91,347.50,160.47,9.41">TREC-3 Ad-hoc, Routing Retrieval and Thresholding Experiments using PIRCS</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">L</forename><surname>Kwok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Grunfeld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,327.99,347.50,152.46,9.41;10,146.91,358.46,35.25,9.41">Proceedings of TREC&apos;3, NIST Publication #</title>
		<meeting>TREC&apos;3, NIST Publication #<address><addrLine>Gaithersburg</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="247" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,369.42,342.10,9.41;10,146.91,380.38,238.43,9.41" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,246.34,369.42,229.99,9.41">Database Merging Strategy based on Logistic Regression</title>
		<author>
			<persName coords=""><forename type="first">Le</forename><surname>Calvé</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Savoy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,146.91,380.38,155.79,9.41">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="341" to="359" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,391.33,342.10,9.41;10,146.91,402.30,333.54,9.41;10,146.91,413.26,333.54,9.41;10,146.91,424.21,215.19,9.41" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,187.68,391.33,292.77,9.41;10,146.91,402.30,20.90,9.41">Report on CLEF-2002 Experiments: Combining Multiple Sources of Evidence</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,416.74,402.30,63.71,9.41;10,146.91,413.26,146.78,9.41">Cross-Language Information Retrieval and Evaluation</title>
		<title level="s" coord="10,299.96,413.26,137.52,9.41">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Kluck</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct coords="10,138.35,435.18,342.10,9.41;10,146.91,446.13,203.87,9.41" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="10,186.49,435.18,293.96,9.41;10,146.91,446.13,139.73,9.41">Report on CLEF-2003 Monolingual Tracks: Fusion of Probabilistic models for Effective Monolingual Retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
		<imprint/>
	</monogr>
	<note>In this volume</note>
</biblStruct>

<biblStruct coords="10,138.35,457.09,342.10,9.41;10,146.91,468.05,103.29,9.41" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,186.96,457.09,276.95,9.41">Combining Multiple Strategies for Effective Cross-Language Retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,470.34,457.09,10.11,9.41;10,146.91,468.05,28.79,9.41">IR Journal</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct coords="10,138.35,479.01,342.10,9.41;10,146.91,489.97,333.54,9.41;10,146.91,500.92,13.82,9.41" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,352.78,479.01,123.11,9.41">The Collection Fusion Problem</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">K</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Johnson-Laird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,158.64,489.97,183.28,9.41">Proceedings of TREC&apos;3, NIST, Publication #</title>
		<meeting>TREC&apos;3, NIST, Publication #<address><addrLine>Gaithersburg</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="95" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,138.35,511.89,342.11,9.41;10,146.91,522.84,68.59,9.41" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">N</forename><surname>Venables</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">D</forename><surname>Ripley</surname></persName>
		</author>
		<title level="m" coord="10,272.91,511.89,162.43,9.41">Modern Applied Statistics with S-PLUS</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
