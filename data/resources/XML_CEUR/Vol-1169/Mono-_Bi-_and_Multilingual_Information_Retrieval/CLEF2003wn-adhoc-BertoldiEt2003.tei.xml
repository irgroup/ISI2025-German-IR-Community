<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,230.30,90.14,145.41,12.91;1,108.28,108.08,389.44,12.91">ITC-irst at CLEF 2003: Monolingual, Bilingual, and Multilingual Information Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,205.33,136.61,77.35,10.76"><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ITC-irst -Centro per la Ricerca Scientifica e Tecnologica</orgName>
								<address>
									<postCode>38050</postCode>
									<settlement>Povo, Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,307.92,136.61,92.77,10.76"><forename type="first">Marcello</forename><surname>Federico</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ITC-irst -Centro per la Ricerca Scientifica e Tecnologica</orgName>
								<address>
									<postCode>38050</postCode>
									<settlement>Povo, Trento</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,230.30,90.14,145.41,12.91;1,108.28,108.08,389.44,12.91">ITC-irst at CLEF 2003: Monolingual, Bilingual, and Multilingual Information Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">747C221BA1068803267F20965BC2DEB7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper reports on the participation of ITC-irst in the Cross Language Evaluation Forum 2003; in particular, in the monolingual, bilingual, small multilingual, and spoken document retrieval tracks. Considered languages were English, French, German, Italian, and Spanish. With respect to our CLEF 2002 system, the statistical models for bilingual document retrieval have been improved, more languages have been considered, and a novel multilingual information retrieval system has been developed, which combines several bilingual retrieval models into a statistical framework. As in the last CLEF, bilingual models integrate retrieval and translation scores over the set of N-best translations of the source query.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This paper reports on the participation of ITC-irst in the Cross Language Evaluation Forum (CLEF) 2003. Several tracks were faced: monolingual document retrieval in Italian, French, German and Spanish; bilingual document retrieval from German to Italian and from Italian to Spanish; small multilingual document retrieval from English to English, German, French, and Spanish; and, finally, cross-language spoken document retrieval from French, German, Italian, Spanish to English.</p><p>The statistical cross-language information retrieval (CLIR) model presented in the 2002 CLEF evaluation <ref type="bibr" coords="1,107.94,476.11,125.57,8.97" target="#b4">(Federico and Bertoldi, 2002)</ref> was extended in order to cope with a multilingual target collection. Moreover, better query-translation probabilities were obtained by exploiting bilingual dictionaries and statistics from monolingual corpora. Basically, the ITC-irst system presented in the 2002 CLEF evaluation was expanded with a module for merging document rankings of different document collections generated by different bilingual systems.</p><p>Each bilingual system features a statistical model, which generates a list of the N-best query translations, and a basic IR engine, which integrates scores, computed by a standard Okapi model and a statistical language model, over multiple translations. Remarkably, training of the system's parameters just requires a bilingual dictionary, the target document collection, and a document collection in the source language. This paper is organized as follows. Section 2 introduces the statistical approach to multilingual IR. Sections 3 briefly summarizes main features of our system, and describes the retrieval procedure. Section 4 and 5 present experimental results for each tracks we participated in. Section 6 closes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Multilingual Information Retrieval: Statistical approach</head><p>Multilingual information retrieval can be defined as the task of finding and ranking documents, which are relevant for a given topic, within a collection of texts in several language. As we know the language of each document, we may view the multilingual target collection as the union of distinct monolingual collections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Multilingual retrieval model</head><p>Let a multilingual collection D contain documents in L different languages, where D results from the union of L monolingual sub-collections D 1 , . . . , D L . Let f be a query in a given source language, eventually different from any of the L languages. One would like to rank documents d within the multilingual collection D, according to the posterior probability:</p><formula xml:id="formula_0" coords="1,376.13,534.73,146.58,10.63">Pr(d | f ) ∝ Pr(f , d) (1)</formula><p>where the right term of formula (1) follows from the constancy of Pr(f ), with respect to the ranking of documents.</p><p>A hidden variable l is introduced, which represents the language of either a sub-collection or a document.</p><formula xml:id="formula_1" coords="1,347.27,630.49,175.44,49.27">Pr(f , d) = = l Pr(l, f , d) = l Pr(l) Pr(f , d | l) (2)</formula><p>where Pr(l) is an a-priori distribution over languages, which can be estimated from the multilingual collection or taken uniform. Formula (2) shows a weighted mixture of bilingual IR models depending on the subcollection. However, given that we know the language each document is written in, we can assume that the probability Pr(f , d | l) is larger than zero only if d belongs to the sub-collection D l . Next, a hidden variable e is introduced, which represents a (term-by-term) translation of f into one of the L languages. Hence, we derive the following decomposition:</p><formula xml:id="formula_2" coords="2,102.34,166.79,191.76,48.21">Pr(f , d | l) = e Pr(f , e, d | l) ≈ e Pr(f , e | l) Pr(d | e, l) (3)</formula><p>In deriving formula (3), we make the assumption (or approximation) that the probability of document d given query f , translation e and language l, does not depend on f . Formula (3) puts in evidence a language-dependent query-translation model, Pr(f , e | l), and a collection-dependent query-document model, Pr(d | e, l).</p><p>The language-dependent query-translation model is defined as follows:</p><formula xml:id="formula_3" coords="2,84.03,344.55,203.19,76.12">Pr(f , e | l) = Pr(f | l)Pr l (e | f ) ∝            Pr l (f , e) e ∈T l (f ) Pr l (f , e ) if e ∈ T l (f ) 0 otherwise</formula><p>where T l (f ) is the set of all translations of f into language l. For practical reasons, this set is approximated with the set of the N most probable translations computed by the basic query-translation model Pr l (f , e). The term Pr(f | l) can be considered independent from l and hence be discarded. The normalization introduced in formula (4) is needed in order to obtain ranking scores, which are comparable among different languages.</p><p>The collection-dependent query-document model is derived from a basic query-document model Pr l (d | e) as follows: The basic query document and query translation models are now briefly described; more details can be found in <ref type="bibr" coords="2,132.30,712.48,117.81,8.97" target="#b1">(Bertoldi and Federico, 2002)</ref>. The subscript l, which refers to the specific language or collection the models are estimated on, will be omitted without loss of generality.</p><formula xml:id="formula_4" coords="2,83.34,581.52,125.27,61.27">Pr(d | e, l) =            Pr l (d, e)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Basic Query-Document Model</head><p>The query-document model computes the joint probability of a query e and a document d, written in the same language. The query-document model considered in the experiments results from the combination of two different models: a language model and an Okapi based scoring function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language Model</head><p>The joint probability can be factored out as follows:</p><formula xml:id="formula_5" coords="2,362.82,197.27,159.89,10.63">Pr(e, d) = Pr(e | d) Pr(d)<label>(4)</label></formula><p>where the a-priori probability of d, Pr(d), is assumed to be uniform, and the probability of e given d to be an order-free multinomial (bag-of-word) model:</p><formula xml:id="formula_6" coords="2,343.97,263.88,178.74,30.20">Pr(e = e 1 , . . . , e n | d) = n k=1 p(e k | d) (5)</formula><p>Okapi The joint probability can be obtained through the normalization over queries and documents of a generic scoring function s(e, d):</p><formula xml:id="formula_7" coords="2,362.05,349.22,160.66,26.43">Pr(e, d) = s(e, d) e ,d s(e , d )<label>(6)</label></formula><p>The denominator is considered only for the sake of normalization, but can be disregarded in the computation of equation (3).</p><p>A scoring function derived from the standard Okapi formula, is used</p><formula xml:id="formula_8" coords="2,326.67,453.84,196.04,31.76">s(e = e 1 , . . . , e n , d) = n k=1 idf (e k ) W d (e k )<label>(7)</label></formula><p>Combination Previous work <ref type="bibr" coords="2,443.45,497.55,74.69,8.97;2,311.96,509.50,49.48,8.97" target="#b0">(Bertoldi and Federico, 2001)</ref> showed that the two models rank documents almost independently. Hence, information about the relevant documents can be gained by integrating the scores of both methods. Combination of the two models is implemented by just taking the sum of scores, after a suitable normalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Basic Query-Translation Model</head><p>The query-translation model computes the probability of any query-translation pair. This probability is modeled by an HMM <ref type="bibr" coords="2,404.27,631.03,63.86,8.97" target="#b7">(Rabiner, 1990)</ref> in which the observable variable is the query f in the source language, and the hidden variable is its translation e in the target language. According to the HMM, the joint probability of a pair (f , e) is decomposed as follows:</p><formula xml:id="formula_9" coords="2,328.77,700.00,193.94,57.31">P r(f = f 1 , . . . , f n , e = e 1 , . . . , e n ) = p(e 1 ) n k=2 p(e k | e k-1 ) n k=1 p(f k | e k )<label>(8)</label></formula><p>The term translation probabilities p(f | e) are estimated from a bilingual dictionary as follows:</p><formula xml:id="formula_10" coords="3,137.02,100.73,157.08,26.43">Pr(f | e) = δ(f, e) f δ(f , e) (9)</formula><p>where δ(f, e) = 1 if the term e is one of the translations of term f and δ(f, e) = 0 otherwise. This flat distribution can be refined through the EM algorithm <ref type="bibr" coords="3,83.34,172.15,94.19,8.97" target="#b3">(Dempster et al., 1977)</ref>  </p><p>where p(e, e ) is the probability of e co-occurring with e , regardless of the order, within a text window of fixed size. Smoothing of this probability is performed through absolute discounting and interpolation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">System architecture</head><p>As shown in Section 2, the ITC-irst multilingual IR system features several independent bilingual retrieval systems, which return collection-dependent rankings, and a module for merging these results into a global ranking with respect to the whole multilingual Moreover, language-dependent text preprocessing modules have been implemented to process documents and queries. Figure <ref type="figure" coords="3,258.57,462.61,3.74,8.97">3</ref>. shows the architecture of the system. Two merging criteria were developed. The first, we call stat method, implements the statistical model introduced in Section 2: for each language, languagedependent relevance scores of documents, computed by the bilingual IR systems are normalized in order to have language independent scores, and, hence, a global ranking is created.</p><p>The second criterion, we call rank method, exploits the document rank positions only, i.e. all the collection dependent rank lists are joined and documents are globally sorted according to the inverse of their original rank position.</p><p>Monolingual and bilingual versions of the system trivially follows by omitting the query-translation model and by limiting the collection to one language, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Preprocessing</head><p>In order to homogenize the preparation of data, and, hence, to reduce workload, a standard procedure was defined. More specifically, the following preprocessing steps were applied both to documents and queries in every language: • Tokenization was performed to separate words from punctuation marks, to recognize abbreviations and acronyms, correct possible word splits across lines, and discriminate between accents and quotation marks.</p><p>• Stemming was performed by using a languagedependent Porter-like algorithm (Frakes and Baeza-Yates, 1992), freely available at snowball.tartarus.org.</p><p>• Stop-terms removal was applied on the documents by removing terms included in a language-dependent public list (www.unine.ch/info/clef).</p><p>• Proper names and numbers in queries were recognized in order to improve coverage of the dictionary.</p><p>• Out-of-dictionary terms which have not been recognized as proper names or numbers were removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Blind Relevance Feedback</head><p>After document ranking, the following Blind Relevance Feedback (BRF) technique was applied. First, the documents matching the source query e are ranked, then the B best ranked documents are taken and the R most relevant terms in them are added to the query, and the retrieval phase is repeated. In the CLIR framework, R terms are added to each single translation of the N -best list and the retrieval algorithms is repeated once again. In this work, 15 new search terms are selected from the top 5 documents according to the Offer Weight proposed in <ref type="bibr" coords="4,258.12,72.33,35.98,8.97;4,83.34,84.28,45.78,8.97" target="#b6">(Johnson et al., 1999)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Evaluation</head><p>ITC-irst submitted 4 monolingual runs in French, German, Italian, and Spanish, 4 Italian-Spanish bilingual runs, 2 German-Italian bilingual runs, and 4 small multilingual runs using queries in English to search documents in English, French, German, and Spanish. Moreover, some unofficial experiments were performed for the sake of comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data</head><p>In  Bilingual dictionaries from English to the other languages were gathered from public available resources. Unfortunately, German-Italian and Italian-Spanish dictionaries were not available. Hence, the missing dictionaries were built from other available dictionaries using English as a pivot language. For example, an Italian-Spanish dictionary was derived by exploiting the Spanish-English and Italian-English dictionaries as follows: the translation alternatives of an Italian term are all Spanish translations of all English translations of that term. would suggest that they contain two wrong translations per entry, on the average. Moreover, all term translation probabilities, but the German-Italian ones, were estimated through the EM algorithm by using the corresponding document collections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results</head><p>Table <ref type="table" coords="4,338.64,300.04,4.98,8.97" target="#tab_5">4</ref> reports main settings and official mAvPr scores for each run. In particular, the number of Nbest translations (1 vs. 10), the type of bilingual dictionary (flat vs. estimated through EM algorithm), and the merging policy (looking at the rank vs. the stat) are indicated. Source and target languages are indicated in the run name.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Monolingual results</head><p>As shown in Table <ref type="table" coords="4,496.20,387.24,3.74,8.97" target="#tab_5">4</ref>, our monolingual retrieval system achieves good results for all languages. More than 70% of queries have mAvPr greater than or equal to the median values. It is worth noticing that mAvPrs are pretty the same for all languages.</p><p>Bilingual results Italian-Spanish results show that the estimation of translation probabilities through the EM algorithm is quite effective, especially in combination with the 10-best translations. to the median values. The merging method based on the rank is a little more effective, but differences are very low. Again, the EM estimation of term probabilities slightly improves performance. The merging criteria were also applied to the monolingual runs, in order to obtain an upper bound for our multilingual retrieval system. The achieved mAvPrs for this virtual experiment were .3754 and .3667 for the "rank" and "stat" criteria, respectively. The relative degradation is very similar to that observer for bilingual experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Cross-Language Spoken Document Retrieval</head><p>ITC-irst participated also in the Cross-Language Spoken Document Retrieval (CLSDR) track, which consists in searching for relevant stories within a collection of automatically transcribed English broadcast news. Topics correspond in 50 short queries manually translated from English into French, German, Italian, and Spanish. For the CLSDR track, the bilingual version of the ITC-irst IR system was applied, with little changes in the BRF expansion of queries. Moreover, German text were also processed for splitting compound words, by using a DP based algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Query expansion on parallel corpora</head><p>As the number of stories in the SDR target collection was quite small, a double query expansion policy was chosen. New terms are added which are extracted not only from the target collection, but also from a large corpus of written texts, consisting of newspapers and news wires. As a parallel corpus for query expansion, newspaper articles of the North American News Text corpus were used (www.nist.gov/speech/tests/sdr). In particular, 313K documents are extracted from Los Angeles Times, Washington Post, New York Times, and Associated Press Worldstream, issued between September 1997 and April 1998. Unfortunately, the available texts do not entirely cover the test period. The following strategy was chosen: first query expansion was performed on parallel texts, and then on target collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Results</head><p>Table <ref type="table" coords="5,336.55,433.72,4.98,8.97" target="#tab_6">6</ref> reports the official submitted runs, and some unofficial runs (in italics), used for comparison. The official English monolingual run was performed in order to evaluate the quality of the retrieval system. ITC-irst performance is about 10% above the other participants. For this experiment the query expansion on the parallel corpus was not applied. If not so, a relative improvement of 7% is observed. As the double query expansion policy is quite effective, was applied in all the other experiments.</p><p>In the bilingual experiments, query were translated either through our 1-best translation approach or by the Babelfish translation service, powered by Systran, which is available on the Internet (world.altavista.com). Run names are indicating with 1bst and sys, respectively. Commercial translations outperforms our approach. German word decompounding seems to be slightly effective, as shown by comparing the run without decompounding ( de-en-1bst-brf-bfr) and the with (de-en-dec-1bst-brf-bfr).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>This paper presented a multilingual IR system developed at ITC-irst. A complete statistical model was defined which combines several bilingual retrieval model. The system was evaluated in the CLEF2003 campaign in the monolingual, bilingual, and multilingual tracks. The basic monolingual IR model resulted very competitive on every languages. The multilingual IR systems also achieves higher performance than the median. Experiments in the Cross-Language Spoken Document Retrieval task, which uses very short queries, showed that significantly better results are still achieved by using translations produced by a commercial system.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,153.80,618.60,32.46,7.32;2,187.92,603.68,10.68,10.46;2,198.61,607.73,2.52,7.32;2,201.66,603.68,25.41,10.46;2,238.23,594.32,53.88,10.63;2,152.61,639.12,4.98,10.46;2,238.23,640.79,38.74,8.97;2,83.34,662.38,163.66,10.63;2,247.00,664.04,47.09,9.69;2,83.34,674.33,78.74,10.63"><head>d</head><label></label><figDesc>∈I(e,l)    Pr l(d , e)   if d ∈ I(e, l)0 otherwisewhere I(e, l) is the set of documents in D l containing at least a word of e.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,311.96,307.68,210.75,8.97"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Architecture of the multilingual IR system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,83.34,238.37,210.75,139.24"><head>Table 1 :</head><label>1</label><figDesc>Table 1, statistics about the target collections for the five considered languages are reported. Statistics about target collections.</figDesc><table coords="4,112.29,274.38,152.85,81.49"><row><cell>Language</cell><cell></cell><cell>#words</cell></row><row><cell>English</cell><cell>166,754</cell><cell>100,971,969</cell></row><row><cell>French</cell><cell>129,809</cell><cell>52,275,689</cell></row><row><cell>German</cell><cell>294,809</cell><cell>99,461,570</cell></row><row><cell>Italian</cell><cell>153,208</cell><cell>54,434,345</cell></row><row><cell>Spanish</cell><cell>454,045</cell><cell>171,971,487</cell></row><row><cell>Multi-4</cell><cell cols="2">1,045,417 424,680,715</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,83.34,403.69,210.75,129.08"><head>Table 2</head><label>2</label><figDesc></figDesc><table coords="4,83.34,403.69,210.75,129.08"><row><cell cols="3">reports statistics about the topics and corre-</cell></row><row><cell cols="3">sponding relevant documents in each collection (top-</cell></row><row><cell cols="3">ics with no relevant document are not considered).</cell></row><row><cell cols="3">Language #queries #rel.docs</cell></row><row><cell>English</cell><cell>54</cell><cell>1006</cell></row><row><cell>French</cell><cell>52</cell><cell>946</cell></row><row><cell>German</cell><cell>56</cell><cell>1825</cell></row><row><cell>Italian</cell><cell>51</cell><cell>809</cell></row><row><cell>Spanish</cell><cell>57</cell><cell>2368</cell></row><row><cell>Multi-4</cell><cell>60</cell><cell>6145</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,123.92,545.54,129.59,8.97"><head>Table 2 :</head><label>2</label><figDesc>Statistics about queries.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,83.34,71.13,431.23,686.19"><head>Table 3 :</head><label>3</label><figDesc>Statistics about dictionaries.</figDesc><table coords="4,320.09,71.13,194.48,81.90"><row><cell>Dictionary</cell><cell cols="2">#entries avg. # translations</cell></row><row><cell>English-French</cell><cell>44728</cell><cell>1.97</cell></row><row><cell cols="2">English-German 131429</cell><cell>1.88</cell></row><row><cell>English-Italian</cell><cell>44195</cell><cell>1.95</cell></row><row><cell>English-Spanish</cell><cell>47305</cell><cell>1.83</cell></row><row><cell>Italian-Spanish</cell><cell>66059</cell><cell>3.94</cell></row><row><cell>German-Italian</cell><cell>103618</cell><cell>3.91</cell></row></table><note coords="4,249.15,700.52,44.94,8.97;4,83.34,712.48,210.75,8.97;4,83.34,724.44,210.75,8.97;4,83.34,736.39,210.75,8.97;4,83.34,748.35,210.75,8.97"><p>Table 2 reports some statistics of the bilingual dictionaries. It is worth noticing that for the generated dictionaries the average number of translation alternatives is about twice larger than that of original dictionaries. This</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="4,311.96,519.81,210.75,237.50"><head>Table 4 :</head><label>4</label><figDesc>Main settings and results of the official runs. Comparison against the median and best values.</figDesc><table coords="4,311.96,519.81,210.75,198.13"><row><cell cols="3">Language monolingual bilingual from English</cell></row><row><cell>French</cell><cell>.5339</cell><cell>.4297</cell></row><row><cell>German</cell><cell>.5173</cell><cell>.4378</cell></row><row><cell>Italian</cell><cell>.5397</cell><cell>.4184</cell></row><row><cell>Spanish</cell><cell>.5375</cell><cell>.4298</cell></row><row><cell cols="3">Table 5: Comparison of monolingual and bilingual</cell></row><row><cell>performance.</cell><cell></cell><cell></cell></row><row><cell cols="3">Table 5 reports mAvPr for monolingual and bilingual</cell></row><row><cell cols="3">runs for every language; the 10-best translations were</cell></row><row><cell cols="3">obtained with EM estimated translation probabilities.</cell></row><row><cell cols="3">A relative degradation between 15% and 22% is al-</cell></row><row><cell cols="3">ways observed. This means that the translation pro-</cell></row><row><cell cols="3">cess causes almost equal losses in performance for</cell></row><row><cell cols="2">each language pair.</cell><cell></cell></row></table><note coords="4,311.96,736.39,210.75,8.97;4,311.96,748.35,210.75,8.97"><p><p><p><p>Multilingual results</p>As shown in Table</p>4</p>, about 60% of the queries have mAvPr greater than or equal</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="5,311.96,467.09,210.75,176.15"><head>Table 6 :</head><label>6</label><figDesc>mAvPr results of CLSDR track at CLEF 2003</figDesc><table coords="5,317.10,467.09,197.64,142.46"><row><cell>Official run</cell><cell cols="2">Query mAvPr</cell></row><row><cell>mono-brf</cell><cell>EN</cell><cell>.3944</cell></row><row><cell>mono-brf-brf</cell><cell>EN</cell><cell>.4244</cell></row><row><cell>fr-en-1bst-brf-bfr</cell><cell>FR</cell><cell>.2281</cell></row><row><cell>fr-en-sys-brf-bfr</cell><cell>FR</cell><cell>.3064</cell></row><row><cell cols="2">de-en-dec-1bst-brf-bfr DE</cell><cell>.2676</cell></row><row><cell>de-en-1bst-brf-bfr</cell><cell>DE</cell><cell>.2523</cell></row><row><cell>de-en-sys-brf-bfr</cell><cell>DE</cell><cell>.2880</cell></row><row><cell>it-en-1bst-brf-bfr</cell><cell>IT</cell><cell>.2347</cell></row><row><cell>it-en-sys-brf-bfr</cell><cell>IT</cell><cell>.3218</cell></row><row><cell>es-en-1bst-brf-bfr</cell><cell>ES</cell><cell>.2746</cell></row><row><cell>es-en-sys-brf-bfr</cell><cell>ES</cell><cell>.3555</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,83.34,411.13,210.75,8.97;6,93.26,423.09,200.84,8.97;6,93.26,435.05,200.84,8.97;6,93.26,447.00,200.84,8.97;6,93.26,458.96,200.84,8.97;6,93.26,470.91,65.31,8.97" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,249.56,411.13,44.53,8.97;6,93.26,423.09,157.59,8.97">ITC-irst at CLEF 2000: Italian monolingual track</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,153.30,435.05,140.79,8.97;6,93.26,447.00,91.29,8.97">Cross-Language Information Retrieval and Evaluation</title>
		<title level="s" coord="6,264.02,447.00,30.08,8.97;6,93.26,458.96,105.89,8.97">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2001">2001. 2069</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,83.34,483.36,210.75,8.97;6,93.26,495.32,200.84,8.97" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="6,249.56,483.36,44.53,8.97;6,93.26,495.32,197.09,8.97">ITC-irst at CLEF 2001: Monolingual and bilingual tracks</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Federico</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,93.26,507.27,200.84,8.97;6,93.26,519.22,200.85,8.97;6,93.26,531.18,200.84,8.97;6,93.26,543.14,200.84,8.97;6,93.26,555.09,108.09,8.97" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,202.17,519.22,91.94,8.97;6,93.26,531.18,129.82,8.97">Cross-Language Information Retrieval and Evaluation</title>
	</analytic>
	<monogr>
		<title level="s" coord="6,93.26,543.14,145.96,8.97">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzales</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Kluck</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">2406</biblScope>
			<publisher>Springer Verlag</publisher>
			<pubPlace>Heidelberg, Germany</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,83.34,567.54,210.75,8.97;6,93.26,579.49,200.84,8.97;6,93.26,591.45,200.84,8.97;6,93.26,603.41,69.46,8.97" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,93.26,579.49,200.84,8.97;6,93.26,591.45,54.39,8.97">Maximum-likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,155.38,591.45,138.71,8.97;6,93.26,603.41,27.54,8.97">Journal of the Royal Statistical Society, B</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,83.34,615.85,210.75,8.97;6,93.26,627.81,200.84,8.97;6,93.26,639.77,200.83,8.97;6,93.26,651.72,200.85,8.97;6,93.26,663.67,200.84,8.97;6,93.26,675.63,103.38,8.97" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,278.05,615.85,16.05,8.97;6,93.26,627.81,200.84,8.97;6,93.26,639.77,100.21,8.97">Statistical cross-language information retrieval using n-best query translations</title>
		<author>
			<persName coords=""><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,216.34,639.77,77.75,8.97;6,93.26,651.72,200.85,8.97;6,93.26,663.67,200.84,8.97;6,93.26,675.63,24.82,8.97">Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Tampere, Finland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,83.34,688.08,210.75,8.97;6,93.26,700.03,200.84,8.97;6,93.26,711.99,196.42,8.97" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="6,119.65,700.03,174.44,8.97;6,93.26,711.99,42.53,8.97">Information Retrieval: Data Structures and Algorithms</title>
		<editor>Frakes, William B. and Ricardo Baeza-Yates</editor>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Prentice Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,83.34,724.44,210.76,8.97;6,93.26,736.39,200.84,8.97;6,93.26,748.35,200.85,8.97;6,321.87,72.33,200.85,8.97;6,321.87,84.28,18.54,8.97" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,169.07,736.39,125.02,8.97;6,93.26,748.35,132.98,8.97">Spoken document retrieval for TREC-8 at Cambridge University</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Jourlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Spark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">C</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Woodland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,244.74,748.35,49.37,8.97;6,321.87,72.33,140.36,8.97">Proceedings of the 8th Text REtrieval Conference</title>
		<meeting>the 8th Text REtrieval Conference<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,311.96,96.72,210.75,8.97;6,321.87,108.68,200.84,8.97;6,321.87,120.64,200.84,8.97;6,321.87,132.59,200.83,8.97;6,321.87,144.55,189.04,8.97" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,444.71,96.72,78.00,8.97;6,321.87,108.68,200.84,8.97;6,321.87,120.64,74.90,8.97">A tutorial on hidden Markov models and selected applications in speech recognition</title>
		<author>
			<persName coords=""><forename type="first">Lawrence</forename><forename type="middle">R</forename><surname>Rabiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,369.45,132.59,130.38,8.97">Readings in Speech Recognition</title>
		<editor>
			<persName><forename type="first">Alex</forename><surname>Weibel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kay-Fu</forename><surname>Lee</surname></persName>
		</editor>
		<meeting><address><addrLine>Los Altos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="267" to="296" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
