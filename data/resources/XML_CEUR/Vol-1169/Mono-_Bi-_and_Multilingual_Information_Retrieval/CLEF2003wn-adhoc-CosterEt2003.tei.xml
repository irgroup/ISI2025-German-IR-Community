<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,94.65,148.91,413.69,15.11;1,189.38,170.83,224.24,15.11">Selective compound splitting of Swedish queries for Boolean combinations of truncated terms</title>
				<funder ref="#_rhc6sAr #_UuKSm6K">
					<orgName type="full">European Commission</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,165.62,203.31,74.36,10.48"><forename type="first">Rickard</forename><surname>Cöster</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Swedish Institute of Computer Science</orgName>
								<orgName type="institution">SICS</orgName>
								<address>
									<postBox>Box 1263</postBox>
									<postCode>SE-164 29</postCode>
									<settlement>Kista</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,249.09,203.31,87.86,10.48"><forename type="first">Magnus</forename><surname>Sahlgren</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Swedish Institute of Computer Science</orgName>
								<orgName type="institution">SICS</orgName>
								<address>
									<postBox>Box 1263</postBox>
									<postCode>SE-164 29</postCode>
									<settlement>Kista</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,363.61,203.31,73.77,10.48"><forename type="first">Jussi</forename><surname>Karlgren</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Swedish Institute of Computer Science</orgName>
								<orgName type="institution">SICS</orgName>
								<address>
									<postBox>Box 1263</postBox>
									<postCode>SE-164 29</postCode>
									<settlement>Kista</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,94.65,148.91,413.69,15.11;1,189.38,170.83,224.24,15.11">Selective compound splitting of Swedish queries for Boolean combinations of truncated terms</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">269D453F23A661277C3E59431CC5C5C7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Swedish is a compounding language, and therefore it is important to split compound words so that useful word constituents can be found. One of the problems is that it is difficult to find constituents that express a concept similar to that expressed by the compound.</p><p>The approach taken in this paper is to look at how the leading constituent of the compound word can be used to expand a search query. The constituent was added to the original query, while still keeping the compound. Every word was then truncated so as to increase recall by hopefully finding other compounds with the leading constituent as prefix. Since this approach increase recall in a rather uncontrolled way, we also used a Boolean quorum-level type of query combination so that documents were ranked according to both the tf-idf factor but also to the number of matching Boolean combinations.</p><p>The Boolean combinations performed relatively well, taken into consideration that the queries were very short (maximum five search terms).</p><p>Also included in this paper are the results of two other methods we are currently working on in our lab; one for re-ranking search results on the basis of stylistic analysis of documents, and one for dimensionality reduction using Random Indexing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction: Compounds in Swedish</head><p>This year, we focused on the Swedish monolingual track. We submitted four runs, of which the first two deal with the problem of using compound word splitting for query expansion.</p><p>The other two runs test very different approaches: first, how to re-rank search results based on a stylistic analysis of the retrieved documents and, secondly, the effect of aggressive dimensionality reduction using Random Indexing.</p><p>Swedish is a compounding language. This means that new words are often formed by adjoining two or more separate words. Such words are called closed compounds. For example, the Swedish word "Diamantgruva" is a closed compound of "Diamant" (Diamond) and "Gruva" (Mine). The other two forms of compound words are the open form ("Post office") and the hyphenated ("Longterm"). The closed form is common in Swedish (and languages such as German, Finnish and Danish) whereas the open form is more common in English.</p><p>Certainly, it is necessary for a retrieval system to split the compounds into constituents, since such words may be too specific but contain constituents that are useful and content-bearing. One</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>of the problems of compound splitting is that it is difficult to find constituents that express a concept <ref type="foot" coords="2,126.53,122.40,3.97,6.12" target="#foot_0">1</ref> that is similar to that expressed by the compound.</p><p>For example, the word "Diamantgruva" is important to split so that the content-bearing words "Diamant" and "Gruva" can be found. These two words are good query terms, since they are not ambiguous and express the two separate concepts diamond and mine. On the other hand, if the word "Domstol" (Court) is split into "Dom" (Judgement) and "Stol" (Chair), some errors are introduced. "Stol" is not a good search term in this context, and "Dom" is ambiguous; it also means "Them" in spoken Swedish. Splitting "Domstol" thus make more harm than keeping the compound form.</p><p>Another problem that may occur can be exemplified by splitting the compound "Riksdagshus" (Parliament building). The lemmatizer that we used in our experiments split this into the three constituents "Riks", "Dags" and "Hus". It did not find the word "Riksdag" (Parliament) which is an important word in this context. Furthermore, the words "Riks" and "Dags" should not have been extracted as constituents, since "Riksdag(s)" is a not a compound. Moreover, it seems that the lemmatizer does not make a morphological analysis of the constituents. This has the effect that sometimes a joining 's' is left at the end of words that should not have it.</p><p>In summary, some of the problems with using constituents from compound splitting are that they</p><p>• may not express a concept similar to that expressed by the compound</p><p>• may be ambiguous</p><p>• may not always be valid words</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Selective compound splitting and Boolean combinations</head><p>Since compound splitting may not always yield constituents that improve a query, it is desirable to have a method for selecting only a subset of the constituents. Since compounds are often very specific words, one way to improve the query is to find constituents that boost the recall. In our case, we chose to select only the leading constituent for expanding the query.</p><p>The leading constituent is sometimes a modifier to the last constituent, i.e. it determines something about the last constituent. For instance, the leading constituent "Ozon" (Ozone) in "Ozonlager" (Ozone layer) determines that the layer mentioned is the ozone layer. The word "Ozon" is useful as a search term, since documents about ozone layers probably also contain the separate word "Ozon". Such documents might also contain other compounds that begin with "Ozon" such as "Ozonhalt" (Ozone amount) and "Ozonhål" (Ozone hole), so finding these words might also help improve the query.</p><p>By expanding a query with the leading constituent of a compound search word will effectively increase the recall, and hopefully in such a way that the new documents that are found are related to the concept expressed by the compound. And if we also expand the query with all words that begin with the leading constituent, we will find new words that again, hopefully, are related as well. But we will also find words that are not related to the concept at all, so there must be some way of narrowing the query as well.</p><p>Our general approach in runs sicsSVtad and sicsSVtmd was to expand the queries with leading constituent. These were added as search words while also keeping the original compound. Each search word was then truncated, i.e. we found all other indexed words that had the search word as prefix. All search words were truncated, not only the leading compounds. For instance, the truncation of "Diamant" found "Diamantexport" (Diamond export), "Diamantföretag" (Diamond corporation) and also "Diamantgruva" mentioned earlier.</p><p>We decided to do the compounds splitting at query time, so that we could elaborate with how to select good constituents for improving the queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Retrieval engine and model</head><p>The underlying retrieval engine we used is an experimental system developed at SICS. It currently supports Boolean, Vector Space and structured queries. It is designed to handle a large amount of documents and queries, using algorithms described in <ref type="bibr" coords="3,344.79,154.32,10.51,8.74" target="#b7">[8]</ref> and <ref type="bibr" coords="3,379.63,154.32,10.52,8.74" target="#b0">[1]</ref> to effectively manage large amounts of data. The system is described in more detail in our CLEF paper <ref type="bibr" coords="3,427.32,166.27,10.52,8.74" target="#b4">[5]</ref> from last year.</p><p>The Swedish document collection was parsed and normalized using a lemmatizer, but we did not use any compound splitting at indexing time. Also, we used a list of 285 stop words.</p><p>For scoring documents, we used pivoted cosine normalization, or Lnu in Smart notation <ref type="bibr" coords="3,499.72,202.14,9.96,8.74" target="#b6">[7]</ref>. We set the slope to 0.3 after some informal experiments, and set the pivot to the average number of unique terms in a document, as suggested in <ref type="bibr" coords="3,298.91,226.05,9.96,8.74" target="#b6">[7]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Boolean combinations of truncated terms</head><p>We used two different approaches to query formulation. For the first run, sicsSVtad, we used the selective compound splitting on the Title field only. In the second run, sicsSVtmd, we again used the Title words, but also added some words from the Desc field (those with lowest document frequency) so that there was a maximum of 5 words in the query. Each such base word was then truncated, and we performed a ranked Boolean AND between the base words and a ranked Boolean OR between the words found by truncating the base words. In the case where there were less than 1000 documents in a result list, we appended the results of a standard vector space query using all words from the Desc field.</p><p>To illustrate the Boolean combination procedure, let a, b and c be three query terms, and let a 1 , . . . , a n be the expanded words from the truncation of a (and b 1 , . . . , b m , c 1 , . . . , c r for b and c). For each possible Boolean combination of the query terms, we constructed one query. In total this makes 7 queries, displayed in Figure <ref type="figure" coords="3,270.57,403.84,3.88,8.74" target="#fig_0">1</ref>. In general, the number of such Boolean query combinations is</p><formula xml:id="formula_0" coords="3,198.91,426.10,205.19,81.38">(a 1 ∨ . . . ∨ a n ) ∧ (b 1 ∨ . . . ∨ b m ) ∧ (c 1 ∨ . . . ∨ c r ) (a 1 ∨ . . . ∨ a n ) ∧ (b 1 ∨ . . . ∨ b m ) (a 1 ∨ . . . ∨ a n ) ∧ (c 1 ∨ . . . ∨ c r ) (b 1 ∨ . . . ∨ b m ) ∧ (c 1 ∨ . . . ∨ c r ) (a 1 ∨ . . . ∨ a n ) (b 1 ∨ . . . ∨ b m ) (c 1 ∨ . . . ∨ c r )</formula><formula xml:id="formula_1" coords="3,383.32,540.23,31.37,14.56">k i=1 k i ,</formula><p>where k is the number of terms in the query. This type of Boolean combination is sometimes called quorum level search <ref type="bibr" coords="3,90.00,567.11,9.97,8.74" target="#b5">[6]</ref>, although the standard way of performing the search is to include all combinations of the same size in one and the same query, using the OR operator to combine them. This strategy was not appropriate for this task, since then we would have normalized documents differently and would not have been able to merge the result lists in a simple way.</p><p>Since each Boolean combination was a single query, we simply set the RSV for each document to the sum of the RSV values from all queries in that combination. This has the desirable property that documents are not only ranked according to the tf-idf model, but also to the number of combinations of the search words that are spotted in the document. For instance, a document where all search words are found would be at the top of the list, since that document would get positive RSV values from all queries in the combination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Other approaches</head><p>Since the Boolean combinations of truncated terms is designed to increase recall, it is important to make sure that we do not add too much noise in this process. One way of doing this is to use stylistic filtering of the retrieved documents to boost news items with animate agents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Stylistic filtering to boost news items with animate agents</head><p>As the text corpus was composed of news service items with longer more textual pieces, short one-paragraph or one-sentence passages, as well as tables of sports or stock results, a filter to boost the rank of items more likely to be relevant to the textually oriented materials requested for CLEF was designed. The basic assumption of the filter was that items more likely to be relevant would contain more animate agents than others: texts with the personal agents present and with descriptions of actions taken by people or organizations or other animate entities were assumed to be of a higher information value than texts with completely impersonal and non-active constructions.</p><p>The style filter was constructed in a multi-step process. First, a set of prototypical animate agents was drawn up. The list used as a seed set can be seen in Table <ref type="table" coords="4,411.53,265.89,3.88,8.74">1</ref>. Second, all verbs in the corpus were tabulated their occurrence with a subject from the seed set of animate agents. Verbs which occurred at least once with one of the prototypically animate agents were noted to be personal verbs -comprising a set of over 2200 verbs.</p><p>Third, for each textual item, the number of personal verbs was tabulated. This statistic was used as an animacy score for the text item.</p><p>Fourth, the output from other retrieval runs was then reranked using the animacy score as a key. The reranking was done in one pass through the list. If an item has a low animacy score, operationalized as less than 75 per cent of the average animacy score of any text in the retrieved set, and the item just below it has a higher animacy score, their position is swapped. This method avoids large scale movement of items through the ranked list but shifts adjacent items from position to position. han he barn child hon she ungdom youth man man / impersonal "one" pojke boy kvinna woman flicka girl Table <ref type="table" coords="4,200.39,476.99,3.88,8.74">1</ref>: Seed word set for the prototypical animate agents Unfortunately, we could see no effect of the reranking in our results, and are currently investigating why this was the case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Dimensionality Reduction by Random Indexing</head><p>Dimensionality reduction is often important in information retrieval tasks, since the dimensionality of the search space induces constraints on the performance of the retrieval engine; very highdimensional data will require large amounts of memory and processing time, and will severely limit the efficiency of the system. This is especially important in real-world settings, where the user expects both accurate and, sometimes even more important, fast results. A common approach to reduce the dimensionality of the data in information retrieval systems is by using various forms of word filtering techniques, such as stop lists, frequency thresholding and morphological normalization.</p><p>An alternative method for dimensionality reduction in the Vector Space Model (VSM) <ref type="bibr" coords="4,491.94,654.78,10.52,8.74" target="#b5">[6]</ref> is to combine word filtering with the use of reduced representations for the vocabulary. Assuming the standard definition of the VSM, where the dimensionality of the document vectors is given by the size of the vocabulary, i.e. the number w of unique words in the data (normally after word filtering), we can define a reduced representation as vectors of dimensionality d w. One way of producing such reduced representations is to use a random mapping method <ref type="bibr" coords="4,425.94,714.55,9.96,8.74" target="#b3">[4]</ref>, where words are represented by nearly orthogonal random vectors of dimensionality d w, and where document and query vectors are defined as the average (i.e. the vector sum) of the vectors of the words in the document or query. The point of this methodology is that the resulting search space will be significantly smaller than the original search space, while still containing approximately the same information.</p><p>In one of our CLEF 2003 runs (sicsSVind), we used the Random Indexing approach <ref type="bibr" coords="5,485.38,147.89,9.96,8.74" target="#b1">[2]</ref>, <ref type="bibr" coords="5,502.48,147.89,10.52,8.74" target="#b2">[3]</ref> to assign nearly orthogonal sparse random vectors to each unique word in the data. The vectors, which we call index vectors, were 1,000-dimensional with 6 randomly distributed non-zero elements (three +1s and three -1s). We then produced 1,000-dimensional document and query vectors by simply summing the index vectors of the words in the documents and the queries (after aggressive word filtering<ref type="foot" coords="5,148.87,206.09,3.97,6.12" target="#foot_1">2</ref> ). The resulting 1,000-dimensional document and query vectors are much smaller than the standard VSM vectors that will be 121,545-dimensional for the Swedish data (after word filtering).</p><p>The retrieval was then performed by simply calculating the vector similarity between each query vector and all the document vectors. The documents with highest similarity score were ranked as most relevant to the query. As similarity measure, we used the cosine of the angles between the vectors, given by:</p><formula xml:id="formula_2" coords="5,203.78,292.75,193.74,29.23">d cos (x, y) = x • y | x || y | = n i=1 x i y i n i=1 x 2 i n i=1 y 2 i</formula><p>The results are somewhat disappointing; only 2 queries are above the median results, 3 are on the median, and 48 below. It is not clear at this point whether the results are an artefact of the dimensionality reduction, or if they depend on the simple and naive query formulation process used in these runs. Future experiments will investigate this matter more fully.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>A summary of the results of the runs using the Boolean combination queries is displayed in Table <ref type="table" coords="5,505.25,416.98,3.88,8.74" target="#tab_0">2</ref>. The Table shows the number of queries that were above, on, or below the median result as well as the number queries that obtained the maximum or minimum score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>Above The overall results are encouraging but there are also many missed queries. Since we use a maximum of 5 search terms for each query, the misses are easily attributed to the small amount of query terms. However, we believe that it is interesting to evaluate what type of results that can be achieved when using few query terms, since it is well known that many users (especially search engine users) typically use only three or four words to express their query.</p><p>There is an interesting difference between the two runs; the number of queries above the median result and the number of queries that obtained the lowest score. Recall that in sicsSVtad, only terms from the Title field were used. When we added some terms from the Desc field in sicsSVtmd we got fewer (3) queries that obtained lowest score but also fewer queries (2) above the median.</p><p>The fewer number of queries that got lowest score is due to the fact that we added more search terms to the query in the sicsSVtmd. For instance, the average precision of query 165 was improved from 0.3333 to 1.000. The query in sicsSVtad was "GOLDEN GLOBE" whereas in sicsSVtmd it was expanded to "GOLDEN GLOBE KATEGORI DRAMA FILM".</p><p>We noted that for the queries that were above median in sicsSVtad and then below median in sicsSVtmd, the difference was very small in terms of average precision. For instance, the average precision of query 147 was changed from 0.0673 to 0.0619, and the median was 0.0639.</p><p>For a compounding language such as Swedish, it is important to find methods that can effectively manage compound words in information retrieval systems. The approach taken in this paper is to look at how the leading constituent of a compound word can be used to expand the query. The query terms were then truncated to increase recall. To strike a balance between high recall and high precision, we used a Boolean quorum-level type of combination where documents were ranked according to both the tf-idf factor but also according to how many of the Boolean combinations that matched.</p><p>The Boolean combinations performed relatively well, taken into consideration that the queries were very short. This was our first attempt to tackle the problem of using compound word splitting for query expansion, and we will continue to pursue this line of research. What we would like to do to next is to use co-occurrence statistics and perhaps also clustering methods to find words that are related to the compound, so that we can have a more principled way of checking the relation between the concept expressed by the constituent and that expressed by the compound.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,106.90,519.29,389.20,8.74"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The 7 possible Boolean combinations of three truncated query terms a, b and c</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,90.00,461.31,423.01,66.47"><head>Table 2 :</head><label>2</label><figDesc>Number of queries above, on or below the median score for each run. The number of queries with max or min score is displayed in the last two columns</figDesc><table coords="5,196.26,461.31,210.49,33.33"><row><cell></cell><cell></cell><cell cols="4">On Below Max Min</cell></row><row><cell>sicsSVtad</cell><cell>14</cell><cell>10</cell><cell>29</cell><cell>6</cell><cell>5</cell></row><row><cell>sicsSVtmd</cell><cell>12</cell><cell>10</cell><cell>31</cell><cell>6</cell><cell>2</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,105.24,735.65,124.84,6.99"><p>By concept, we mean search term</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="5,105.24,737.54,407.75,6.99;5,90.00,747.00,25.17,6.99"><p>We used a stop list based on document frequencies together with ordinary word frequency thresholds (excluding low (&lt;</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="5,124.58,747.00,234.47,6.99"><p>occurrences) and high (&gt; 12000 occurrences) frequency words).</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements The work reported here is partially funded by the <rs type="funder">European Commission</rs> under contracts <rs type="grantNumber">IST-2000-29452</rs> (<rs type="projectName">DUMAS</rs>) and <rs type="grantNumber">IST-2000-25310</rs> (CLARITY) which is hereby gratefully acknowledged. We thank <rs type="institution">Tidningarnas TelegrambyråAB, Stockholm</rs>, for providing us with the Swedish text collection.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_rhc6sAr">
					<idno type="grant-number">IST-2000-29452</idno>
					<orgName type="project" subtype="full">DUMAS</orgName>
				</org>
				<org type="funding" xml:id="_UuKSm6K">
					<idno type="grant-number">IST-2000-25310</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,105.50,393.83,407.49,8.74;6,105.50,405.79,180.56,8.74" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="6,288.99,393.83,224.01,8.74;6,105.50,405.79,18.88,8.74">File Structures: An Object-Oriented Approach with C++</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Folk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Zoellick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Riccardi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Addison-Wesley</publisher>
		</imprint>
	</monogr>
	<note>3rd edition</note>
</biblStruct>

<biblStruct coords="6,105.50,425.71,407.50,8.74;6,105.50,437.67,407.50,8.74;6,105.50,449.62,92.60,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,289.46,425.71,223.54,8.74;6,105.50,437.67,32.82,8.74">Random indexing of text samples for latent semantic analysis</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kanerva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kristofersson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Holst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,158.62,437.67,327.17,8.74">Proceedings of the 22nd Annual Conference of the Cognitive Science Society</title>
		<meeting>the 22nd Annual Conference of the Cognitive Science Society</meeting>
		<imprint>
			<publisher>Erlbaum</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page">1036</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,469.55,407.51,8.74;6,105.50,481.50,407.50,8.74;6,105.50,493.46,22.70,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,239.99,469.55,128.13,8.74">From words to understanding</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Karlgren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sahlgren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,184.00,481.50,170.52,8.74">Foundations of Real World Intelligence</title>
		<editor>
			<persName><forename type="first">Y</forename><surname>Uesaka</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Kanerva</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Asoh</surname></persName>
		</editor>
		<imprint>
			<publisher>CSLI publications</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="294" to="308" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,513.38,407.50,8.74;6,105.50,525.34,407.51,8.74;6,105.50,537.29,187.32,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,148.15,513.38,364.84,8.74;6,105.50,525.34,24.22,8.74">Dimensionality reduction by random mapping: Fast similarity computation for clustering</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kaski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,151.58,525.34,356.69,8.74">Proceedings of the IJCNN&apos;98, International Joint Conference on Neural Networks</title>
		<meeting>the IJCNN&apos;98, International Joint Conference on Neural Networks</meeting>
		<imprint>
			<publisher>IEEE Service Center</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="413" to="418" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,557.22,407.50,8.74;6,105.50,569.17,387.66,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,354.51,557.22,158.49,8.74;6,105.50,569.17,144.08,8.74">Sics at clef 2002: Automatic query expansion using random indexing</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sahlgren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Karlgren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Cöster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Jrvinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,270.84,569.17,115.34,8.74">The CLEF 2002 Workshop</title>
		<imprint>
			<date type="published" when="2002">September 19-20 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,589.10,407.50,8.74" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="6,221.54,589.10,197.97,8.74">Introduction to Modern Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mcgill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>McGraw-Hill</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,609.02,407.50,8.74;6,105.50,620.98,272.09,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,280.06,609.02,172.23,8.74">Pivoted document length normalization</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,475.05,609.02,37.95,8.74;6,105.50,620.98,183.76,8.74">Research and Development in Information Retrieval</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,640.90,407.49,8.74;6,105.50,652.86,324.25,8.74" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="6,297.19,640.90,215.81,8.74;6,105.50,652.86,99.02,8.74">Managing Gigabytes: Compressing and Indexing Documents and Images</title>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">C</forename><surname>Bell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Morgan Kaufmann Publishing</publisher>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
