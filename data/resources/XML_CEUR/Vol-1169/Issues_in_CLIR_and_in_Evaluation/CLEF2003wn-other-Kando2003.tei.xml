<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,107.46,100.93,380.82,12.19">Evaluation of Information Access Technologies at NTCIR Workshop</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,270.18,143.91,51.99,8.74"><forename type="first">Noriko</forename><surname>Kando</surname></persName>
							<email>kando@nii.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">National Institute of Informatics (NII)</orgName>
								<address>
									<settlement>Tokyo</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,107.46,100.93,380.82,12.19">Evaluation of Information Access Technologies at NTCIR Workshop</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">886F0919750F05AFF2192437E577DC1E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper introduces the NTCIR Workshops, a series of evaluation workshops that are designed to enhance research in information access technologies, such as information retrieval, text summarization, question answering, text mining, etc., by providing infrastructure of large-scale evaluation. A brief history, test collections, and recent progress after the previous CLEF Workshop are described with highlighting the difference from CLEF in this paper. To conclude, some thoughts on future directions are suggested.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The NTCIR Workshops [1]<ref type="foot" coords="1,171.84,329.71,3.24,5.65" target="#foot_0">1</ref> are a series of evaluation workshops designed to enhance research in information access (IA) technologies including information retrieval (IR), cross-lingual information retrieval (CLIR), automatic text summarization, question answering, text mining, etc.</p><p>The aims of the NTCIR project are:</p><p>1. to encourage research in information access technologies by providing large-scale test collections reusable for experiments, 2. to provide a forum for research groups interested in cross-system comparisons and exchanging research ideas in an informal atmosphere, and 3. to investigate methodologies and metrics for evaluation of information access technologies and methods for constructing large-scale reusable test collections.</p><p>That is to say, the main goal of the NTCIR project is to provide infrastructure of large-scale evaluation. The importance of large-scale evaluation infrastructure in IA research has been widely recognized. Fundamental text processing procedures for IA such as stemming and indexing include language-dependent procedures. In particular, processing texts written in Japanese or other East Asian languages such as Chinese is quite different from processing English, French or other European languages, because there are no explicit boundaries (i.e., no spaces) between words in a sentence. The NTCIR project therefore started in late 1997 with emphasis on, but not limited to, Japanese or other East Asian languages, and its series of workshops has attracted international participation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Information Access</head><p>The term "information access" (IA) includes a whole process to make information in the documents usable for the user who has problems or information needs. A traditional IR system returns a ranked list of retrieved documents that are likely to contain information relevant to the user's needs. This is one of the most fundamental and core processes of IA. It is however not the end of the story for the users. After obtaining a ranked list of retrieved documents, the user skims the documents, performs relevance judgments, locates the relevant information, reads, analyses, compares the contents with other documents, integrates, summarizes and performs information-based work such as decision making, problem solving, writing, etc., based on the information obtained from the retrieved documents. We have looked at IA technologies to help users utilize the information in large-scale document collections. IR, summarization, question answering, etc are a "family", in which the same target is aimed while each of the technologies has been investigated by different communities with least interaction<ref type="foot" coords="2,358.44,121.75,3.24,5.65" target="#foot_1">2</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Focus of the NTCIR</head><p>As shown in Figure <ref type="figure" coords="2,145.95,171.93,3.53,8.74" target="#fig_0">1</ref>, we have looked at both traditional laboratory-type IR system testing and the evaluation of challenging technologies. For the laboratory-type testing, we placed emphasis on IR and CLIR with Japanese or other Asian languages and testing on various document genres. For the challenging issues, the targets are the shift from document retrieval to technologies that utilize "information" in documents, and investigation of methodologies and metrics for more realistic and reliable evaluation.</p><p>For the latter, we have paid attention to users' information seeking task in the experiment design. These two directions have been supported by a forum of researchers and discussion among them.</p><p>From the beginning, CLIR has been one of the central interests of the NTCIR, because CLIR between English and own-languages is critical for international information transfer in Asian countries, and it was challenging to perform CLIR between languages with completely different structures and origins such as English and Chinese or English and Japanese.  reports recent progress after our reports at the previous CLFEs <ref type="bibr" coords="2,295.32,499.89,6.66,8.74" target="#b0">[2]</ref><ref type="bibr" coords="2,301.98,499.89,3.33,8.74" target="#b1">[3]</ref><ref type="bibr" coords="2,305.32,499.89,6.66,8.74" target="#b2">[4]</ref>, and Section 5 outlines the features of the coming NTCIR Workshop, NTCIR-4. Section 6 is summary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Focus of NTCIR</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">NTCIR</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">History of NTCIR</head><p>In the NTCIR, a workshop is held once per about one and half years. Since we respect the interaction between participants, we call a whole the process from document release to the final meeting as "workshop". Each workshop selects several research areas called "Task", or "Challenge" for more challenging task. Each task has been organized by the researchers of the domain and a task may consist of more than one subtasks. Figure <ref type="figure" coords="2,252.97,643.89,5.01,8.74">2</ref> shows the evolution of the tasks in the NTCIR Workshops and Table <ref type="table" coords="2,506.14,643.89,5.01,8.74">1</ref> is a list of subtasks and test collections used in the tasks <ref type="bibr" coords="2,252.45,659.91,6.69,8.74" target="#b3">[5]</ref><ref type="bibr" coords="2,259.13,659.91,3.34,8.74" target="#b4">[6]</ref><ref type="bibr" coords="2,262.48,659.91,6.69,8.74" target="#b5">[7]</ref>.</p><p>As shown in Table <ref type="table" coords="2,158.04,675.93,3.51,8.74">1</ref>, the 4 th NTCIR Workshop hosts 5 tasks, CLIR, Patent Retrieval Task (PATENT), Question Answering Challenge (QAC), Text Summarization Challenge (TSC), and WEB Task (WEB) and their sub-tasks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Participants</head><p>As shown in Figures <ref type="figure" coords="4,145.75,99.93,5.01,8.74">3</ref> and<ref type="figure" coords="4,167.15,99.93,3.53,8.74">4</ref>, the number of participants has been gradually increasing. Different tasks attracted different research groups although many are overlapped, or changed the participating tasks over workshops. Many international participants were enrolled to CLIR. Patent Retrieval task attracted many participants from company research laboratories and "veteran" NTCIR participants. WEB task has participants from various research communities like machine learning, DBMS, and so on. The number of collaborating teams across different organizations is increasing in recent NTCIRs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Test Collections</head><p>The test collections constructed for the NTCIR Workshops are listed in Table <ref type="table" coords="4,343.30,423.93,3.50,8.74" target="#tab_2">2</ref>. In the NTCIR project the term "test collection" is used for any kind of data set usable for system testing and experiments although it often means IR test collections used in search experiments. One of our interests is to prepare realistic evaluation infrastructure, and those efforts include scaling up the document collection, document genres, languages, topic structure and relevance judgments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Documents</head><p>Documents were collected from various domains or genres. Format of the documents are basically the same as TREC or CLEF and are plain text with SGML-like tags. Each of the specialized document genre collections contained characteristic fields for the genre -Web collection contains html tags, hyperlinks, URL of the document, etc., and patent collection has tags indicating document structure of patent, and both patent and scientific document collections have parallel corpora of English and Japanese abstracts. The task (experiment) design and relevance judgment criteria were set according to the nature of the document collection and user community who use the type of documents in their everyday tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Topics.</head><p>A sample topic record is shown in Figure . 5. Topics are defined as statements of "user's requests" rather than "queries", which are the strings actually submitted to the system, because we wish to allow both manual and automatic query construction from the topics. Emphasis has been shifted towards the topic structure capable more realistic experiments as well as to see the effect of background information of the topic. The characteristics are summarized as followings;</p><p>Topic Structure: Topic Structure has slightly changed in each NTCIR. A topic basically consists of a &lt;TITLE&gt;, a description &lt;DESC&gt;, and a detailed narrative &lt;NARR&gt; of the search request as similar to those used in CLEF and TREC. It may contain additional fields as shown in Table <ref type="table" coords="4,241.39,743.91,3.52,8.74" target="#tab_3">3</ref>. Most of NTCIR collections contain a list of concepts &lt;CONC&gt;, but they are not heavily used by participants.   *9: Query patent fulltext (fulltext of a patent that is used as a query of the search) *10: BACK=Background knowledge/purpose of search; RELE=relevance judgment criteria; TERM=term definitions *6: ARTICLE=a news article reporting an invention; SUPPLEMENT=memorandam to focus the issues in the article relevant to the user's needs; if a human knowledgeable searcher reads ARTICLE and SUPPLEMENT, he/she understand the user's search request as specif *3: TLANG/LANG=target language, the language of the topic; SLANG=source language, the language the topic originally constructed. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;TITLE&gt; as Query:</head><p>A title is originally defined as a very short description, or "nickname" of the topic, and, since NTCIR-3 WEB 3 , changed to be a "query", a string put into a search engine by users and defined as a comma-separated term lists up to three terms.</p><p>Structured &lt;NARR&gt;: Originally a narrative &lt;NARR&gt; was defined and instructed to the topic authors that it may contain background knowledge, purpose of the search, detailed explanation of the topic, criteria for relevance judgment, term definitions, etc. Since NTCIR-3 WEB, such information categories in &lt;NARR&gt; explicitly marked by tags like &lt;BACK&gt;, &lt;RELE&gt;, etc. as Figure <ref type="figure" coords="7,95.95,171.93,3.53,8.74" target="#fig_2">5</ref>. The purpose of this change is to examine the effect of additional information on the search effectiveness explicitly.</p><p>Mandatory runs: Any combination of topic fields is allowed to use in experiments for research purpose. In the Workshop, the Mandatory Runs are defined in each task, and every participant must submit at least one mandatory run using the specified topic field only. The purpose of this is to enhance the cross-system comparison based on the common condition and see the effectiveness of the additional information over it. Mandatory runs are originally "&lt;DESC&gt; only", then gradually shift to "&lt;TITLE&gt; only as well as &lt;DESC&gt; only".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Relevance Judgments</head><p>Relevance judgments are done by pooling, and the format and methods are basically the same as other evaluation projects including CLEF and TREC. The differences shall be summarized as follows;</p><p>1. Pooling strategies are slightly different according to each of the task ・ Additional interactive recall-oriented searches are done to improve the exhaustivity (NTCIR-1,-2) <ref type="bibr" coords="7,465.31,357.81,10.70,8.74" target="#b6">[8]</ref> ・ Additional interactive recall-oriented search are done by professional patent intermediaries (PATENT) <ref type="bibr" coords="7,482.45,370.05,10.70,8.74" target="#b7">[9]</ref> ・ "One-click distance model", in which hyperlinked documents are allowed to see in WEB <ref type="bibr" coords="7,436.36,382.29,15.22,8.74" target="#b8">[10]</ref> ・ Cross-lingual pooling for parallel or quasi-parallel documents (NTCIR-1,-2) <ref type="bibr" coords="7,386.45,394.53,12.11,8.74" target="#b6">[8]</ref> ・ Graded-depth pooling: pool creating top10, 11-20, 21-30, 31-41, (PATENT) [9] 2. Multi-grade and relative relevance judgments ・ Highly Relevant, Relevant, Partially Relevant <ref type="bibr" coords="7,282.66,430.53,6.67,8.74" target="#b3">[5]</ref><ref type="bibr" coords="7,289.33,430.53,3.34,8.74" target="#b4">[6]</ref><ref type="bibr" coords="7,292.67,430.53,6.67,8.74" target="#b5">[7]</ref>, Irrelevant; Best Relevant, 2 nd Best, 3 rd Best, etc. [10] 3. Judgments includes the extracted passages to show the reason why the assessors assessed the documents as "relevant" 4. Pooled document lists to be judged are sorted in descending order of likelihood to be relevant (not the order of the document IDs) 5. Relevance judgment files may be prepared to each of the target language document sub-collections in CLIR For 4, it helps assessors to judge consistently over a long list of pooled documents to be judged (typically 2000 -3000 documents). Relevance judgments may change over assessors and over time. If relevant documents are appeared intensively in the first part of the list, it is easier for the non-professional assessors to set and confirm their criteria for relevance judgments, and then they can always refer those documents to re-confirm their own relevance judgment criteria when they go down to the lower ranked document. We understand they may be suffered by "order effect" of the ranked list of pooled documents in judgments, but we intentionally have used this strategy as practical and most effective one in our environment based on the comparative tests and interviews with assessors.</p><p>For 5, in multilingual CLIR, a topic can not always obtain sufficient number of relevant documents on every language document sub-collection, and this is the natural situation in multi-lingual CLIR. As a result, some topics can not be usable experiments on specific language documents. We can not find the way to manage this issue and only strategy we could take in NTCIR-4 CLIR is to increase the number of topics, so that larger number of topics can be used common across the document sub-collections and then improve the stableness of the evaluation.</p><p>Assessors are users of the document genre, judgments are done by the topic author except CLIR in NTCIR-3 and -4 since topics are created in cooperation of multiple countries, and then translated into each language and tested usability on each language document sub-collection. Judging other users' topics is sometimes hard for users and take longer time.</p><p>First two NTCIRs used two assessors per topic then tested inter-assessors consistency and found that the inconsistency among multiple assessors on a topic does not affect the stableness of the evaluation when tested on sufficient number of topics.</p><p>Based on this, single assessor per topic is used in and after NTCIR-3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Evaluation</head><p>For the evaluation, trec-eval program <ref type="bibr" coords="8,210.29,171.93,15.21,8.74" target="#b9">[11]</ref> is used by setting two threshold of the levels of relevance judgments, i.e. "Rigid Relevance" for "Relevant" or higher, "Relaxed Relevant" for "Partial Relevant" or higher ranked relevance for IR experiments.</p><p>As additional metrics, several metrics for multi-grade relevance judgments are proposed including weighted mean average precision (wMAP), weighted mean reciprocal rank (wMRR, for WEB task), and used decline cumulated gain (DCG) <ref type="bibr" coords="8,489.87,219.93,10.88,8.74" target="#b10">[12]</ref><ref type="bibr" coords="8,504.37,219.93,10.88,8.74" target="#b11">[13]</ref>.</p><p>For Question Answering, MRR is used for subtask-1, return 5 possible answers and no penalty for wrong answers, and F-measure for subtask-2, return one set of all the answers and penalty will be given for wrong answers, and subtask-3, series of question. For Text Summarization, content based and readability based intrinsic evaluation was done in NTCIR-3 for both single document and multi-document summarization, and proposed new evaluation methodology based on revision (edit distance) on system summaries by professional analysts who created the model summaries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Further Analysis of NTCIR-3</head><p>After our previous reports at CLEFs <ref type="bibr" coords="8,204.88,371.91,7.22,8.74" target="#b0">[2]</ref><ref type="bibr" coords="8,212.09,371.91,3.61,8.74" target="#b1">[3]</ref><ref type="bibr" coords="8,215.70,371.91,7.22,8.74" target="#b2">[4]</ref> and the overview papers in the Proceedings of the NTCIR-3 <ref type="bibr" coords="8,446.85,371.91,9.49,8.74" target="#b5">[7]</ref>, several additional analyses were done on the NTCIR-3 results and collection.</p><p>For PATENT retrieval task, though a new strategy for cross-genre retrieval called "term distillation" was proposed by Ricoh group and worked well on the collection, many research questions regarding patent retrieval were remained unsolved in NTCIR-3. The questions are, for example; 1. Is there any particular IR model (or weighting scheme) specifically effective on Patent? 2. Influence of the wide variation of document length (from 100 words to 30,000 word tokens in a document!) 3. Indexing (Character bi-gram vs. Word-based) 4. Target document collections: Fulltext vs. abstract (many commercialized systems used abstracts only) For 1., it has been reported that tf is not effective on Patent at the SIGIR 2000Workshop on Patent Retrieval, but we could not find the concrete answers to the question through the NTCIR-3.</p><p>To answer these question, the NTCIR-3 Patent Task organizers conducted additional experiments on the patent collection and newspaper collection, and tested 8 different weighting schemes including both vector space as well as probabilistic models, on 6 different document collections, using 4 different indexing strategies, character bi-gram, word, compound terms, hybrid of character bi-gram and word; and 3 different topic length on a system. The results will be reported in <ref type="bibr" coords="8,422.11,595.89,13.70,8.74" target="#b12">[14]</ref>.</p><p>For WEB, one participating group was consisted as a collaboration of research groups with strong background of content-based text retrieval and of web-link analysis, worked well at NTCIR-3 WEB. Further analysis on the effect of link on WEB collection, link-based approaches are generally worked well especially on the short queries like using TITLE only, or more specifically the first term of the TITLE, i.e. the most important terms for the users (topic authors) <ref type="bibr" coords="8,431.90,659.91,13.74,8.74" target="#b13">[15]</ref>. in which the users input the terms as queries. The relation between the terms is specified as an attribute of the &lt;TITLE&gt; in WEB Task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Challenges at NTCIR-4</head><p>As shown in Table <ref type="table" coords="9,145.53,107.91,3.53,8.74">1</ref>, the 4 th NTCIR Workshop hosts 5 tasks, CLIR, PATENT, QAC, TSC, and WEB and their sub-tasks.</p><p>Evaluation schedule varies according to each task. For the further information including late registration of the task participation, please consult NTCIR web sites at; http://research.nii.ac.jp/ntcir and http://research.nii.ac.jp/ntcir/ntc-ws4, or contact the author.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">NTCIR-4CLIR</head><p>Since this is the second multilingual CLIR at NTCIR, the same task design will be continued from the previous one. Minor revision was made only to solve the major problems raised in the assessment on the NTCIR-3 as follows;</p><p>・ Enlarge the English and Korea document collections comparable to Chinese and Japanese. 2.7GB in total. ・ New sub-task of Pivot Language Bilingual CLIR ・ Restrict the pair of topic and document languages, so that comparison will be done in fruitfully ・ Set T-only run as mandatory as well as D-only run ・ Question type -topics were categorized according to the nature and types of the answers in order to take a good balance of the topic set.</p><p>The new sub-task, pivot CLIR uses English as a Pivot language, then test the effectiveness of the transitive CLIR. It is one of the practical approaches of Multilingual CLIR in the environment with less availability of the direct translation resources but rich in those between each of the languages and English.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">NTCIR-4 Question Answering (QAC) and Text Summarization (TSC)</head><p>QAC plans three subtasks as previous one at NTCIR-3. Among the three, subtask-1 and -2 will be done without major change.</p><p>Only exceptions are; use different question sets for each of subtask-1 and -2, and increase the number of topics containing multiple answers. It was decided to avoid overestimate of the groups ignoring the possibility of multiple answers and returning</p><p>the first priority answer only to the every question in subtask 2.</p><p>QAC subtask-3, answering to the series of question, is one of the major focus of the NTCIR-4 QAC. We plan to increase the number of sequence as well as task design aiming to tackle the problems resembling the real-world "Report Writing" task based on a set of relevant documents. The task design also related to the TSC, content-based evaluation of multi-document summarization will be done by set of questions. This is, more fundamentally, what kind of aspects of an event or topic that users want to know. Some of the questions may be more appropriate for the current factoid -oriented QA and others may covered by summarization. IR covered both and those focus of QAC and TSC has many intersection of the focus of the CLIR to see the categorization of question types.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Specialized Genre Related Tasks at NTCIR-4: Patent and WEB</head><p>Both PATENT and WEB plan (1) Main task(s) and (2) Feasibility or Pilot studies for more challenging tasks as follows;</p><p>PATENT-Main: Invalidity Task: To search patents to invalidate the query patents. Claims of the query patents are used as query and they are segmented into components of the invention or technologies consisting of the investigation, then search related patents. A patent may be invalidated by one patent or by combination of multiple patents. Return document IDs as well as relevant passages.</p><p>PATENT -Feasibility: Long term research plan over NTCIR4-5. Automatic Patent Map Creation A kind of Text mining --Detect sets of technologies used in a set of patents, extract them, and make a table to show the relationship between technologies and patents, and evolution or trends among them.</p><p>WEB -Main: Informational Search and Navigation Oriented Search, in which find most informative and reliable page WEB -Pilot: Geographical oriented and Topical Classification of the Search results</p><p>For the details, please visit the website of each task, which are linked from the NTCIR's main web site.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Summary</head><p>Brief history of NTCIR and recent progress after NTCIR-3 are reported in this paper. One of the characteristic features of the NTCIR is targeting "Information Access" technologies, in which a whole process for users to obtain and utilize the information in the documents are interested in and see the intersection between all the related technologies including IR, Summarization, QA, Text mining, etc., and treat them as like a "family". Other aspects are, for see the users' information task behind the laboratory-typed testing. We are in the process of the fourth-iteration in a series. Evaluation must be changed according to the technologies evolution and change of the social needs. We have been and are struggling for this. Collaboration and any leads and advices are always more than welcome.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,357.72,459.75,99.69,8.74"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Focus of NTCIR</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,126.42,362.26,129.72,7.85;4,343.16,362.26,122.87,7.85"><head></head><label></label><figDesc>Fig 3 Number of Participating Groups Fig 4 Participating Groups per Task</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,384.42,249.16,137.06,7.85"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Sample topic (NTCIR-3 WEB)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="6,114.30,686.73,337.07,6.48;6,114.30,695.37,228.68,6.48;6,114.30,376.47,37.17,6.48;6,114.30,345.15,16.01,6.48"><head>* 8 :</head><label>8</label><figDesc>CLAIM=Target claim in the query patent. It was used as qeury of the search and may consists of multiple components; COMP=Component of a claim; CNUM=Claim component ID Topic Field Task</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="9,112.92,149.01,112.90,8.74;9,112.92,160.47,125.20,8.74;9,112.92,171.99,147.63,8.74;9,112.92,183.51,168.87,8.74;9,112.92,194.97,199.75,8.74"><head>April 2003 :</head><label>2003</label><figDesc>Document Release June -September 2003: Dry Run October -December 2003: Formal Run 20 February 2004: Evaluation Results Release 2-5 June 2004: Workshop Meeting at NII, Tokyo Japan</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,102.24,89.60,419.22,652.14"><head>Text Summarization Question Answering Term Extraction/ Role Analysis Web Retrieval Patent Retrieval Cross-lingual IR Start！ Japanese IR 2nd 3rd 4th Nov 98 1st Apr 2003 About once per 1 ½ years Figure 2. Tasks of NTCIR Workshops Table 1. History of NTCIR Workshops Period Tasks Subtasks Test collections</head><label></label><figDesc></figDesc><table coords="3,102.24,89.60,389.81,652.14"><row><cell></cell><cell></cell><cell cols="2">Tasks (Research Areas) of NTCIR Workshops</cell><cell></cell></row><row><cell></cell><cell>t</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>a</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>s</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>k</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>s</cell><cell></cell><cell></cell><cell></cell></row><row><cell>1</cell><cell>Nov.1998-Sept.1999</cell><cell cols="2">Ad Hoc IR CLIR Term Extraction Term Extraction/ Role Analysis J-JE J-E</cell><cell>NTCIR-1</cell></row><row><cell>2</cell><cell>June 2000-March 2001</cell><cell>Chinese Text Retrieval Japanese&amp;English IR Text Summarization</cell><cell>Chiniese IR: C-C CLIR: E-C Monolingual IR: J-J, E-E CLIR: J-E, E-J, J-JE, E-JE Intrinsic -Extraction/Free generated Extrinsic -IR task-based</cell><cell>CIRB010 NTCIR-1, -2 NTCIR-2Summ</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Single Language IR:C-C,K-K,J-J</cell><cell></cell></row><row><cell></cell><cell></cell><cell>CLIR</cell><cell>Bilingual CLIR:x-J,x-C, x-K</cell><cell>NTCIR-3CLIR</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Mulilingual CLIR:x-CJE</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Patent</cell><cell>Cross Genre w/ or wo CLIR CCKE-J [Optional] Alianment, RST Analysis of Claims</cell><cell>NTCIR-3 PATENT</cell></row><row><cell>3</cell><cell>Oct. 2001-Oct. 2002</cell><cell>Question Answering</cell><cell>Subtask-1: Five Possible Answers Subtask-2: One Set of All the Answers Subtask-3: Series of Questions</cell><cell>NTCIR-3QA</cell></row><row><cell></cell><cell></cell><cell>Text Summarization</cell><cell>Single Document Summarization Multi-document Summarization</cell><cell>NTCIR-3 SUMM</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Survey Retrieval</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Web Retrieval</cell><cell>Target Retrieval</cell><cell>NTCIR-3 WEB</cell></row><row><cell></cell><cell></cell><cell></cell><cell>[Optional] Speech-Driven</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>Single Language IR:C-C,K-K,J-J</cell><cell></cell></row><row><cell></cell><cell></cell><cell>CLIR</cell><cell>Bilingual CLIR:x-J,x-C, x-K Pivoted Bilingual CLIR</cell><cell>NTCIR-4CLIR</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Mulilingual CLIR:x-CKJE</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Patent</cell><cell>"Invalidity Search"= Search Patents by a Patent [Feasibility] Automatic Patent Map Creation</cell><cell>NTCIR-4 PATENT</cell></row><row><cell>4</cell><cell>Apr. 2003 -June 2004</cell><cell>Question Answering</cell><cell>Subtask-1: Five Possible Answers Subtask-2: One Set of All the Answers</cell><cell>NTCIR-4 QA</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Subtask-3: Series of Questions</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">Text Summarization Multi-document Summarization</cell><cell>NTCIR-4 SUMM</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Informational Retrieval</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Web Retrieval</cell><cell>Navigational Retrieval [Pilot] Geographical Information</cell><cell>NTCIR-4 WEB</cell></row><row><cell></cell><cell></cell><cell></cell><cell>[Pilot] (Search Results) Topical Classification</cell><cell></cell></row><row><cell cols="5">n-m: n=query language, m=document language(s), J:Japanese, E:English, C:Chinese, K:Korean, x</cell></row><row><cell cols="4">*: number of active participating groups that submitted task results</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,92.82,76.30,406.40,626.04"><head>Table 2 . Test collections constructed through NTCIR NTCIR Test Collections; IR and QA</head><label>2</label><figDesc></figDesc><table coords="5,472.14,124.75,26.35,14.56"><row><cell>relevnce</cell></row><row><cell>judge</cell></row></table><note coords="5,92.82,509.33,302.89,7.57;5,92.82,519.05,206.20,6.76;5,92.82,527.75,291.62,6.76;5,92.82,536.51,349.42,6.76;5,92.82,545.22,188.55,6.76"><p>J:Japanese, E:English, C:Chinese (C t :Traditional Chinese, C s : Simplified Chinese), K:Korean; "+" indicates the document collection newly added for NTCIR-4 * English translation is available ** gakkai subfiles: 1997-1999, kaken subfiles: 1986-1997 *3: kkh : Publication of unexamined patent application, jsh: Japanese abstract, paj: English translation of jsh *4: almost Japanese or English (some in other languages)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,114.30,280.30,362.39,403.08"><head>Table 3 Topic fields</head><label>3</label><figDesc></figDesc><table coords="6,114.30,305.07,362.39,378.31"><row><cell cols="4">Topic Structure of NTCIR IR Test Collections</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">NTCIR-1 NTCIR-2 CIRB010</cell><cell>NTCIR-3 CLIR</cell><cell>NTCIR-3 PATENT</cell><cell>NTCIR-3 WEB</cell><cell>NTCIR-4 CLIR</cell><cell>NTCIR-4 PATENT</cell><cell>NTCIR-4 WEB</cell></row><row><cell></cell><cell>ad hoc, CLIR</cell><cell>ad hoc, CLIR</cell><cell>ad hoc, CLIR</cell><cell>CLIR</cell><cell>Cross-genre, CLIR</cell><cell>ad hoc</cell><cell>CLIR</cell><cell>invalidity</cell><cell>ad hoc, other</cell></row><row><cell>Mandatory Run *</cell><cell>D-only</cell><cell>D-only</cell><cell>N/A</cell><cell>D-only</cell><cell>S+A</cell><cell>T-only, D-only</cell><cell>T-only, D-only</cell><cell>CLAIM-only</cell><cell>T-only, D-only</cell></row><row><cell>TITLE **</cell><cell cols="5">very short very short very short very short very short</cell><cell>query</cell><cell cols="3">query very short query</cell></row><row><cell>DESC</cell><cell>yes</cell><cell>yes</cell><cell>yes</cell><cell>yes</cell><cell>yes</cell><cell>yes</cell><cell>yes</cell><cell>yes</cell><cell>yes</cell></row><row><cell>NARR (unstructured</cell><cell>yes</cell><cell>yes</cell><cell>yes</cell><cell>yes</cell><cell>yes</cell><cell></cell><cell></cell><cell>yes</cell><cell></cell></row><row><cell>NARR (structured)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>yes</cell><cell>yes</cell><cell></cell><cell>yes</cell></row><row><cell>NARR. BACK *10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>yes</cell><cell>yes</cell><cell></cell><cell>yes</cell></row><row><cell>NARR. RELE *10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>yes</cell><cell>yes</cell><cell></cell><cell>yes</cell></row><row><cell>NARR. TERM *10</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>yes</cell><cell>yes</cell><cell></cell><cell>yes</cell></row><row><cell>PURPOSE *7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>yes</cell><cell></cell></row><row><cell>CONC</cell><cell>yes</cell><cell>yes</cell><cell>yes</cell><cell>yes</cell><cell>yes</cell><cell>yes</cell><cell>yes</cell><cell></cell><cell></cell></row><row><cell>FIELDS</cell><cell>yes</cell><cell>yes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>TLANG / LANG *3</cell><cell></cell><cell></cell><cell></cell><cell>yes</cell><cell></cell><cell></cell><cell>yes</cell><cell></cell><cell></cell></row><row><cell>SLANG *3</cell><cell></cell><cell></cell><cell></cell><cell>yes</cell><cell></cell><cell></cell><cell>yes</cell><cell></cell><cell></cell></row><row><cell>RDOC *4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>yes</cell><cell>yes</cell><cell></cell><cell></cell><cell></cell></row><row><cell>PI *4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>USER *5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>yes</cell><cell></cell><cell></cell><cell>yes</cell></row><row><cell>ARTICLE *6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>yes</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>DOC *9</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>yes</cell><cell></cell></row><row><cell>SUPPLEMENT *6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>yes</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>CLAIM *8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>yes</cell><cell></cell></row><row><cell>COMP *8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>yes</cell><cell></cell></row><row><cell>COMP. CNUM *8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>yes</cell><cell></cell></row><row><cell cols="8">*: D-only=DESC only, T-only=TITLE only, A+S= run using ARTICLE and SUPPLEMENT only</cell><cell></cell><cell></cell></row><row><cell cols="8">**: "very short"=very short description of search request; "qeury"=comma separated term list</cell><cell></cell><cell></cell></row><row><cell cols="9">*4: RDOC=known relevant documents; PI=the patent for the invention mentioned in the news articles.</cell><cell></cell></row><row><cell cols="2">*5: USER=users' attribute</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">*7: Purpose of search (only "invalidity search" for NTCIR-4 PATENT)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,75.84,731.36,443.34,8.41;1,70.92,742.24,444.66,7.85;1,70.92,752.56,413.56,7.85;1,70.92,762.94,67.01,7.85"><p>NTCIR-3 and 4 are sponsored by the National Institute of Informatics (NII) and Japanese MEXT Grant-in-Aid for Scientific Research on Informatics (#13224087) in and after FY2001. Patent task is organized by collaboration with Japan Intellectual Property Right Association and NII, and CLIR Task is organized by collaboration with National Taiwan University, Korean Institute for Scientific and Technological Information (KISTI).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,76.80,752.44,431.19,7.85;2,70.92,762.94,121.27,7.85"><p>In addition to the above, how to define the question of the user before the retrieval is also included in the scope of the IA although it has not been explicitly investigated in NTCIR.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,74.06,369.94,447.42,7.85;10,88.92,380.32,432.60,7.85;10,88.92,390.64,167.28,7.85" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,129.41,369.94,392.07,7.85">NTCIR Workshop: Japanese-and Chinese-English cross-lingual information retrieval and multi-grade relevance judgments</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,103.80,380.32,242.89,7.85">Proceedings of the first Cross-Language Evaluation Forum (CLEF2000)</title>
		<title level="s" coord="10,122.31,390.64,110.23,7.85">Lecture Notes in Computer Science</title>
		<meeting>the first Cross-Language Evaluation Forum (CLEF2000)<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000">Sept.17-22, 2000. 2001. 2069</date>
			<biblScope unit="page" from="24" to="33" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,74.05,404.98,447.57,7.85;10,88.92,415.36,386.55,7.85" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,128.79,404.98,177.56,7.85">CLIR system evaluation at the second NTCIR workshop</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,323.58,404.98,198.04,7.85;10,88.92,415.36,41.59,7.85">Proceedings of the second Cross-Language Evaluation Forum (CLEF2001)</title>
		<title level="s" coord="10,341.42,415.36,110.40,7.85">Lecture Notes in Computer Science</title>
		<meeting>the second Cross-Language Evaluation Forum (CLEF2001)<address><addrLine>Darmstadt, German</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2001">Sept 3-4, 2001. 2002. 2406</date>
			<biblScope unit="page" from="371" to="388" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,74.05,429.64,447.47,7.85;10,88.92,440.02,383.86,7.85" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,132.37,429.64,250.81,7.85">CLIR at NTCIR Workshop 3; Cross-Language and Cross-Genre Retrieval</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,400.38,429.64,121.14,7.85;10,88.92,440.02,99.30,7.85">Proceedings of 3rd Cross-Language Evaluation Forum (CLEF2002)</title>
		<title level="s" coord="10,326.23,440.02,107.64,7.85">Lecture Note in Computer Science</title>
		<meeting>3rd Cross-Language Evaluation Forum (CLEF2002)<address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002">Sept. 19-20, 2002</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct coords="10,74.05,454.36,447.53,7.85;10,88.80,464.68,357.87,7.85" xml:id="b3">
	<monogr>
		<ptr target="http://research.nii.ac.jp/ntcir/workshop/OnlineProceedings/)" />
		<title level="m" coord="10,88.92,454.36,406.06,7.85">NTCIR Workshop 1: Proceedings of the First NTCIR Workshop on Research in Japanese Text Retrieval and Term Recognition</title>
		<meeting><address><addrLine>Tokyo Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">30 Aug.-1 Sept., 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,74.05,479.02,447.49,7.85;10,88.80,489.39,247.67,7.85" xml:id="b4">
	<monogr>
		<title level="m" coord="10,88.92,479.02,432.63,7.85;10,88.80,489.39,46.66,7.85">NTCIR Workshop 2: Proceedings of the Second NTCIR Workshop on Research in Chinese and Japanese Text Retrieval and Text Summarization</title>
		<meeting><address><addrLine>Tokyo Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-06">June 2000 -March 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,74.05,503.68,447.48,7.85;10,88.80,514.05,243.18,7.85" xml:id="b5">
	<monogr>
		<title level="m" coord="10,88.92,503.68,432.61,7.85;10,88.80,514.05,46.66,7.85">NTCIR Workshop 3: Proceedings of the Third NTCIR Workshop on Research in Information Retrieval, Question Answering and Summarization</title>
		<meeting><address><addrLine>Tokyo Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-10">Oct. 2001 -Oct. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,74.06,528.39,447.43,7.85;10,88.92,538.71,423.13,7.85" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,223.63,528.39,297.85,7.85;10,88.92,538.71,106.60,7.85">Construction of a Large Scale Test Collection NTCIR-2: The Effect of Additional Interactive Search and Cross-Lingual Pooling</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kuriyama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Yoshioka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,203.40,538.71,100.75,7.85">IPSJ Transactions on Databases</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="48" to="59" />
			<date type="published" when="2002-03">March 2002</date>
		</imprint>
	</monogr>
	<note>in Japanese</note>
</biblStruct>

<biblStruct coords="10,74.06,551.07,446.39,7.85;10,88.92,561.39,422.17,7.85;10,88.92,571.77,72.22,7.85" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,241.10,551.07,145.05,7.85">Overview of Patent Retrieval Task at NTCIR-3</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Iwayama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Fujii</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Takano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,405.48,551.07,114.97,7.85;10,88.92,561.39,335.87,7.85">NTCIR Workshop 3: Proceedings of the Third NTCIR Workshop on Research in Information Retrieval, Question Answering and Summarization</title>
		<meeting><address><addrLine>Tokyo Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-10">Oct. 2001 -Oct. 2002</date>
		</imprint>
	</monogr>
	<note>to appear)</note>
</biblStruct>

<biblStruct coords="10,77.74,582.09,421.17,7.85;10,88.92,592.42,404.25,7.85;10,88.92,602.79,206.43,7.85" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,282.42,582.09,200.44,7.85">Overview of Web Retrieval Task at the Third NTCIR Workshop</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Eguchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Oyama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Ishida</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kuriyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,88.92,592.42,404.25,7.85;10,88.92,602.79,46.66,7.85">NTCIR Workshop 3: Proceedings of the Third NTCIR Workshop on Research in Information Retrieval, Question Answering and Summarization</title>
		<meeting><address><addrLine>Tokyo Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-10">Oct. 2001 -Oct. 2002</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct coords="10,77.74,613.12,305.34,7.85" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<ptr target="ftp://ftp.cs.cornell.edu/pub/smart" />
		<title level="m" coord="10,127.90,613.12,97.45,7.85">trec-eval IR evaluation package</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,77.74,625.47,443.71,7.85;10,88.80,635.80,406.98,7.85" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,184.76,625.47,207.55,7.85">IR evaluation methods for retrieving highly relevant documents</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Jarvelin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kekalainen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,414.42,625.47,107.03,7.85;10,88.80,635.80,295.88,7.85">Proceedings of the 23rd Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 23rd Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Athens Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2000-07">July 2000</date>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,77.74,651.03,443.83,7.85;10,88.92,662.73,341.38,7.85" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,146.55,651.03,138.85,7.85">Evaluation by Highly Relevant Documents</title>
		<author>
			<persName coords=""><forename type="first">，</forename><forename type="middle">E M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,298.86,651.03,222.71,7.85;10,88.92,662.73,228.64,7.85">Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2001)，</title>
		<meeting>the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2001)，<address><addrLine>New Orleans</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-09">Sept. 2001</date>
			<biblScope unit="page" from="74" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,77.74,677.56,443.79,7.85;10,88.92,687.88,432.63,7.85;10,88.92,698.26,239.96,7.85" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,262.11,677.56,259.42,7.85;10,88.92,687.88,59.53,7.85">Empirical study on retrieval models for different document genres: Patents and newspaper articles</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Iwayama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Fujii</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Marukawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,165.24,687.88,356.31,7.85;10,88.92,698.26,111.06,7.85">Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2003)</title>
		<meeting>the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2003)<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-07">July 2003</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct coords="10,78.59,712.89,442.90,8.74;10,88.80,724.41,420.87,8.74" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,348.35,712.89,173.14,8.74;10,88.80,724.41,114.97,8.74">Evaluation Methods for Web Retrieval Tasks Considering Hyperlink Structure</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Eguchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Oyama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Ishida</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Kuriyama</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,212.28,724.41,167.52,8.74">IEICE Transaction on Information and Systems</title>
		<imprint>
			<date type="published" when="2003-09">Sep. 2003</date>
		</imprint>
	</monogr>
	<note>in Japanese, to appear</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
