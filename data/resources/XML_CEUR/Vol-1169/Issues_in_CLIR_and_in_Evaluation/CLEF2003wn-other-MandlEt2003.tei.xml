<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,160.56,49.21,302.17,12.64">Proper Names in the Multilingual CLEF Topic Set</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,230.04,87.28,58.50,8.96"><forename type="first">Thomas</forename><surname>Mandl</surname></persName>
							<email>mandl@uni-hildesheim.de</email>
							<affiliation key="aff0">
								<orgName type="department">Information Science</orgName>
								<orgName type="institution">University of Hildesheim</orgName>
								<address>
									<addrLine>Marienburger Platz 22</addrLine>
									<postCode>D-31141</postCode>
									<settlement>Hildesheim</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,295.84,87.28,97.39,8.96"><forename type="first">Christa</forename><surname>Womser-Hacker</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Information Science</orgName>
								<orgName type="institution">University of Hildesheim</orgName>
								<address>
									<addrLine>Marienburger Platz 22</addrLine>
									<postCode>D-31141</postCode>
									<settlement>Hildesheim</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,160.56,49.21,302.17,12.64">Proper Names in the Multilingual CLEF Topic Set</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8D08FD057133116EA6843D4109815AA8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:05+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The reliability of the topics within the Cross Language Evaluation Forum (CLEF) needs to be evaluated constantly to justify the efforts for experiments within CLEF and to demonstrate the validity of the results as far as possible. The analysis presented in this paper is concerned with several aspects. Continuing and expanding a study from 2002, we investigate the difficulty of topics and the correlation between the retrieval quality for topics and the occurrence of proper names.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Topics are an essential aspect of experiments for information retrieval evaluation <ref type="bibr" coords="1,407.43,278.32,80.13,8.96" target="#b4">(Sparck Jones 1995)</ref>. The topic creation for a multilingual environment requires especial care in order to avoid cultural bias to influence the semantics of a topic formulation <ref type="bibr" coords="1,212.07,301.36,131.07,8.96" target="#b1">(Kluck &amp; Womser-Hacker 2002)</ref>. A thorough translation check of all translated topics in CLEF assures that the translations all include the same semantics <ref type="bibr" coords="1,379.36,312.88,93.34,8.96" target="#b9">(Womser-Hacker 2002)</ref>. Such a high level intellectual assessment cannot guarantee that on a lower level some unidentified linguistic properties lead to a bias. Therefore, we continued an analysis of the CLEF 2001 topics and results <ref type="bibr" coords="1,492.09,335.80,40.78,8.96;1,79.20,347.32,91.06,8.96" target="#b2">(Mandl &amp; Womser-Hacker 2002)</ref>. This time, we concentrated on proper names. In addition, the notion of difficulty of a topic and the validity of the translations is further explored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Analysis of Information Retrieval Evaluation Results</head><p>The validity of large-scale information retrieval experiments has been the subject of a considerable amount of research. Zobel 1998 concluded that the TREC (Text REtrieval Conference<ref type="foot" coords="1,387.48,433.45,3.24,5.83" target="#foot_0">1</ref> ) experiments are reliable as far as the ranking of the systems are concerned. <ref type="bibr" coords="1,247.81,447.16,106.98,8.96" target="#b6">Voorhees &amp; Buckley 2002</ref> have analyzed the reliability of experiments as a function of the size of the topic set. They concluded that the typical size of the topic set in TREC is sufficient for a satisfactory level of reliability. Further research is dedicated toward the question whether the expensive human relevance judgements are necessary or whether the constructed document pool of the highest ranked documents from all runs may serve as an reliable approximation of the human judgements. According to a study by <ref type="bibr" coords="1,393.60,504.64,86.34,8.96" target="#b3">Soboroff et al. (2001)</ref>, the ranking of the systems in TREC correlates positively to a ranking based on the document pool without further human judgement. However, there are considerable differences in the ranking which are especially significant in the highest ranks. As a consequence, the human judgements are necessary to achieve the highest reliability of the system rankings. It has also been shown that different human jurors judge the relevance of documents differently. That means, different jurors find different sets of relevant documents. This disagreement between different jurors does not result in different system rankings <ref type="bibr" coords="1,332.28,573.64,67.39,8.96" target="#b5">(Voorhees 1998)</ref>. Although the different sets of relevant documents lead to different recall and precision values, the final rankings of the runs remain rather stable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Difficulty of Topics</head><p>The notion of difficulty of topics has been of great interest in the IR community. The question of what makes a topic a difficult one remains unsolved.</p><p>Voorhees &amp; Harman 1997 measured the difficulty of TREC topics from two perspectives. One was the estimation of experts and the second was the actual outcome of the systems measured as the average precision which systems achieved for that topic. They found no correlation between the two measures. This result was confirmed in a study of the topics of the Asian languages retrieval evaluation NTCIR<ref type="foot" coords="2,438.84,57.37,3.24,5.83" target="#foot_1">2</ref>  <ref type="bibr" coords="2,446.16,59.56,82.33,8.96" target="#b0">(Eguchi et al. 2002)</ref>. Furthermore, <ref type="bibr" coords="2,134.52,71.08,74.10,8.96" target="#b0">Eguchi et al. 2002</ref> tried to find whether the system ranking changes when different difficult levels of topics were considered. They conclude, that changes in the system ranking occur, however, the Kendall correlation coefficient between the overall rankings does not drop below 0.69. For that analysis, the actual difficulty measured by the precision of the runs was used. The overall rankings remain stable but top ranks could be affected. When considering this result, we need to be aware, that the number of topics in the sub-sets with different difficulties is lower than in the overall set. According to the results from Voorhees &amp; Buckley 2002 who analyzed the reliability of experiments as a function of the size of the topic set, such a small set does not lead to completely reliable results. We conducted a study for the CLEF topics of the year 2003 to investigate the correlation between perceived topic difficulty and actual performance of the systems. We call the average precision of the best run for a topic the system difficulty. The best run was chosen to get the best possible retrieval quality that a system can reach within the CLEF campaign. Accordingly, the human estimation of difficulty is called the intellectual difficulty of a topic. The intellectual difficulty was surveyed during the CLEF topic creation meeting. The topic creators were asked to judge whether a topic would be difficult for systems and whether it would be difficult for the human jurors to assess the relevance of the documents. The system difficulty was extracted from the output of the trec_eval program which was mailed to all participants as part of the result. Surprisingly, only a weak correlation (according to Breavis / Pearson) of 0.14 could be found between the system and the intellectual difficulty. It seems, that the difficulty of a topic cannot even be judged sufficiently well by CLEF experts. However, the judgments about the difficulty of the assessment yielded a stronger positive correlation (0.30) to the topic system difficulty. The CLEF campaign also provides the number of relevant documents for each topic. The judgements about the difficulty of the assessment show a negative correlation (-0.27) to the number of relevant documents found. That means, that for topics which the topic creators consider difficult to assess actual point to fewer relevant documents. The two correlation measures are statistically significant at a level of 95%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Proper Names and Retrieval Performance</head><p>Much of the work in information retrieval needs to be dedicated to natural language processing. Phenomena like different word forms or compound words face challenges for information retrieval systems. Therefore, the occurence of linguistic phenomena may favor some systems especially suited for these phenomena. In this context, it may be interesting to look at systems which generally perform well but demonstrate weaknesses for topics which are overall solved with good quality (or vice versa). A study has been carried out for the CLEF campaign 2001 <ref type="bibr" coords="2,330.50,469.84,136.28,8.96" target="#b2">(Mandl &amp; Womser-Hacker 2002)</ref>. It revealed no correlation between any single linguistic phenomenon and the system difficulty of a topic. Not even the length of a topic showed any effect. However, when calculating the sum of all phenomena assessed, we found a positive correlation. The more phenomena available, the better systems solved a topic in average. This study will be extended to the topics and results quality of all available CLEF runs. Intellectual analysis had identified proper names as a potential indicator for retrieval performance. Because of that, proper names in the CLEF topic set were analyzed in more detail. The analysis included all topics from the campaigns in the years 2001 and 2002. The number of proper names in the topics were assessed intellectually. In addition, the retrieval performance of the runs for the topics was extracted from the appendix of the CLEF proceedings. Overall, we found a significant positive relation between the number of proper names present. The more proper names a topic contains, the better the retrieval results are. There is a high deviation, however, the trend is statistically significant at a level of 95%. . In detail, the following relations were investigated: For the CLEF topics number 41 to 200, the average precision of the best run was available. For the topics 41 throughout 140, the average of all runs for that topic was available. It was calculated as the average of all average precision values. Thus, one best and one average result for each topic was identified. The topics were ordered according to the number of proper names they contained. Each subset of topics and their performance values were assigned to the number of proper names. For these sets, the basic statistics are shown in table <ref type="table" coords="2,229.42,676.84,4.98,8.96" target="#tab_0">1</ref> and<ref type="table" coords="2,253.87,676.84,3.74,8.96" target="#tab_1">2</ref> It needs to be noted that the number of topics is higher for fewer proper names. There are not enough topics with three to six proper names to draw far reaching conclusions. Figure <ref type="figure" coords="3,357.45,308.44,4.98,8.96">1</ref> and 2 visualize the numbers in the tables above. They need to be interpreted the following way: Each sub-set of topics with a certain number of proper names is marked on the X-axis. Within this sub-set, figure <ref type="figure" coords="3,315.67,331.36,4.98,8.96">1</ref> and figure <ref type="figure" coords="3,366.81,331.36,4.98,8.96" target="#fig_1">2</ref> show the best and average performance for that topic. Each figure shows the minimum and the average performance for that sub-set. For the average performance for the topic, the performance for the best topic is also displayed in figure 2. It is not shown for the best performance in figure <ref type="figure" coords="3,187.32,365.92,4.98,8.96">1</ref> because that equals 1 usually.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1. Relation between number of proper names and retrieval performance for the best runs</head><p>The graphic representation of the values of table 1 and 2 in figure <ref type="figure" coords="3,365.16,701.44,4.98,8.96">1</ref> and 2 respectively suggests a positive correlation between the number of proper names present in a topic and the difficulty of that topic expressed as </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Best Performance per Topic</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of Proper names</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Averge Precision</head><p>Average Minimum the performance of the systems for that topic. This impression is confirmed by a mathematical analysis. The average performance correlates with a value of 0.43 to the number of proper names and the best performance with a value of 0.26. Disregarding the topics from the campaign in 2003 leads to a correlation coefficient of 0.35. All relations are statistically significant. The assumption of independence of the two parameters can be rejected with a probability of over 95%. This study suggests that the presence of proper names in queries enhances the chances of retrieval systems to find relevant documents. As a consequence, the presence of proper names in the CLEF topic set should be carefully monitored. The system rankings for topics with and without proper names should be evaluated. This analysis of proper names could be extended to consider the number of tokens, to include the number of individual word present in the proper names as well as abbreviations of proper names. An objection against the reliability of the CLEF experiments could arise from the multilingual aspects of the topic set. Are the topics in one language easier for the systems than in another? Does this lead to a bias in the multilingual track where different languages are used as starting point? For example, due to the stylistic modifications in a language, more occurences of proper names or more heterogeneous word forms may be introduced in the topic formulation. Because proper names were identified as an important aspect, we analyzed the stability of the distribution of proper names over the topic set. The results showed large differences between the number of proper names identified in the topic sets among different languages. This fact seems surprising and several potential explanations seem plausible. One reason could be the different proficiency level of the graduate students analyzing the topics. Better knowledge of one language could lead to the detection of more proper names. Another explanation could be that the stylistic and grammatical necessities lead to different numbers of names. Sometimes, in one language more proper names referring to the same entity are commonly used than in other languages (for example: United Kingdom, England, Great Britain in English vs. Inglaterra in Portuguese or United States of America, United States, America, US , USA in English vs. Estados Unidos, EAU in Portuguese).</p><p>For stylistic reasons, several of these different lexical entries may be used. Definitely, further analysis is necessary. Because the number of proper names seems to have substantial influence on the retrieval quality as shown in chapter 4, this fact needs to be considered. The performance of systems utilizing from different topic languages needs to be analyzed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Average Precision of all</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Outlook</head><p>The investigations reported in this article have found no bias in the topics of the CLEF campaign. No reservations about the validity of the results arise from this research. This work needs to continue throughout the campaign and has to be extended to further aspects in the future.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,96.24,453.33,419.41,8.10"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Relation between number of proper names and retrieval performance for the average of all runs for a topic</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,257.61,676.84,3.74,8.96"><head>Table 1 .</head><label>1</label><figDesc>. Best run for each topic in relation to the number of proper names in the topic(topic 41 to 200)    </figDesc><table coords="3,79.20,59.32,431.47,73.04"><row><cell>Number of proper names</cell><cell>0</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell></row><row><cell>Number of Topics</cell><cell>42</cell><cell>43</cell><cell>40</cell><cell>20</cell><cell>9</cell><cell>4</cell><cell>2</cell></row><row><cell>Average of Best System per Topic</cell><cell>0.62</cell><cell>0.67</cell><cell>0.76</cell><cell>0.83</cell><cell>0.79</cell><cell>0.73</cell><cell>0.81</cell></row><row><cell>Minimum of Best System per Topic</cell><cell cols="4">0.090 0.12 0.036 0.28</cell><cell>0.48</cell><cell>0.40</cell><cell>0.63</cell></row><row><cell>Standard Deviation of Best System per Topic</cell><cell>0.24</cell><cell>0.24</cell><cell>0.24</cell><cell>0.18</cell><cell>0.19</cell><cell>0.29</cell><cell>0.26</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,79.20,161.13,433.67,106.11"><head>Table 2 .</head><label>2</label><figDesc>Average retrieval of runs for topic in relation to the number of proper names in the topic (topic 41 to 140)</figDesc><table coords="3,79.20,178.60,428.71,88.64"><row><cell>Number of proper names</cell><cell>0</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell></row><row><cell>Number of Topics</cell><cell>33</cell><cell>22</cell><cell>20</cell><cell>13</cell><cell>8</cell><cell>3</cell></row><row><cell>Maximum of Average Performance per Topic</cell><cell>0.49</cell><cell>0.52</cell><cell>0.74</cell><cell>0.69</cell><cell>0.58</cell><cell>0.60</cell></row><row><cell>Average of Average Performance per Topic</cell><cell>0.21</cell><cell>0.29</cell><cell>0.39</cell><cell>0.39</cell><cell>0.32</cell><cell>0.46</cell></row><row><cell>Minimum of Average Performance per Topic</cell><cell>0.02</cell><cell>0.10</cell><cell>0.14</cell><cell>0.12</cell><cell>0.17</cell><cell>0.28</cell></row><row><cell>Standard Deviation of Average Performance</cell><cell>0.13</cell><cell>0.13</cell><cell>0.16</cell><cell>0.17</cell><cell>0.15</cell><cell>0.17</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,84.96,722.68,73.31,8.96"><p>http://trec.nist.gov</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,84.96,722.68,115.67,8.96"><p>http://research.nii.ac.jp/ntcir/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to thank <rs type="person">Martin Braschler</rs> for providing the crucial data for our study. We also acknowledge the participation of the CLEF organization team during the topic creation meeting for their judgements on the difficulty of the topics. Furthermore, we acknowledge the work of several students from the <rs type="institution">University of Hildesheim</rs> who contributed to this analysis as part of their course work, especially <rs type="person">Kathrin Wünnemann</rs>, <rs type="person">Nikolaus Küster</rs> and <rs type="person">Carsten Spichal</rs>.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="5,79.20,328.96,453.58,8.96;5,96.24,340.48,436.67,8.96;5,96.24,352.00,279.81,8.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,332.35,328.96,200.43,8.96;5,96.24,340.48,38.09,8.96">Sensitivity of IR systems Evaluation to Topic Difficulty</title>
		<author>
			<persName coords=""><forename type="first">Koji</forename><forename type="middle">;</forename><surname>Eguchi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kazuko</forename><forename type="middle">;</forename><surname>Kuriyama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Noriko</forename><surname>Kando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,158.55,340.48,374.36,8.96;5,96.24,352.00,52.86,8.96">Proceedings of the 3rd International Conference on Language Resources and Evaluation (LREC 2002)</title>
		<meeting>the 3rd International Conference on Language Resources and Evaluation (LREC 2002)<address><addrLine>Las Palmas de Gran Canaria, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="585" to="589" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,79.20,363.52,453.46,8.96;5,96.24,375.04,436.56,8.96;5,96.24,386.44,370.80,8.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,299.23,363.52,233.43,8.96;5,96.24,375.04,432.05,8.96">Inside the Evaluation Process of the Cross-Language Evaluation Forum (CLEF): Issues of Multilingual Topic Creation and Multilingual Relevance Assessment</title>
		<author>
			<persName coords=""><forename type="first">Michael</forename><forename type="middle">;</forename><surname>Kluck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christa</forename><surname>Womser-Hacker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,109.89,386.44,274.39,8.96">3rd International Conference on Language Resources and Evaluation</title>
		<meeting><address><addrLine>Las Palmas, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,79.20,397.96,453.59,8.96;5,96.24,409.48,436.44,8.96;5,96.24,421.00,421.79,8.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,288.04,397.96,225.70,8.96">Linguistic and Statistical Analysis of the CLEF Topics</title>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">;</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christa</forename><surname>Womser-Hacker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,405.93,409.48,126.74,8.96;5,96.24,421.00,293.19,8.96">Evaluation of Cross-Language Information Retrieval Systems</title>
		<editor>
			<persName><forename type="first">Carol</forename><forename type="middle">;</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Martin</forename><forename type="middle">;</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><forename type="middle">;</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Kluck</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin et al.</addrLine></address></meeting>
		<imprint>
			<publisher>LNCS</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note>Proceedings of the CLEF 2002 Workshop</note>
</biblStruct>

<biblStruct coords="5,79.20,432.52,453.59,8.96;5,96.24,444.04,436.55,8.96;5,96.24,455.44,149.50,8.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,332.39,432.52,200.40,8.96;5,96.24,444.04,45.12,8.96">Ranking Retrieval Systems without Relevance Judgements</title>
		<author>
			<persName coords=""><forename type="first">Ian</forename><forename type="middle">;</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Charles</forename><forename type="middle">;</forename><surname>Nicholas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Patrick</forename><surname>Cahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,162.93,444.04,369.86,8.96;5,96.24,455.44,48.60,8.96">Proc Annual Intl ACM Conference on Research and Development in Information Retrieval (SIGIR &apos;01)</title>
		<meeting>Annual Intl ACM Conference on Research and Development in Information Retrieval (SIGIR &apos;01)<address><addrLine>New Orleans</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="66" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,79.20,466.96,453.71,8.96;5,96.24,478.48,20.11,8.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,199.59,466.96,84.98,8.96">Reflections on TREC</title>
		<author>
			<persName coords=""><forename type="first">Sparck</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karen</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,308.35,466.96,161.53,8.96">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="291" to="314" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,79.20,490.00,453.71,8.96;5,96.24,501.52,436.66,8.96;5,96.24,513.04,240.34,8.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,181.06,490.00,333.31,8.96">Variations in relevance judgments and the measurement of retrieval effectiveness</title>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,96.24,501.52,436.66,8.96;5,96.24,513.04,138.02,8.96">Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ´98)</title>
		<meeting>the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR ´98)<address><addrLine>Melbourne</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="315" to="223" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,79.20,524.44,453.70,8.96;5,96.24,535.96,436.54,8.96;5,96.24,547.48,86.50,8.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,247.73,524.44,245.03,8.96">The Effect of Topic Set Size on Retrieval Experiment Error</title>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><forename type="middle">;</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,514.60,524.44,18.30,8.96;5,96.24,535.96,395.70,8.96">Proc Annual Intl ACM Conference on Research and Development in Information Retrieval (SIGIR &apos;02)</title>
		<meeting>Annual Intl ACM Conference on Research and Development in Information Retrieval (SIGIR &apos;02)<address><addrLine>Tampere, Finland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="316" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,79.20,559.00,453.59,8.96" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="5,248.12,559.00,196.36,8.96">Overview of the Sixth Text Retrieval Conference</title>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><forename type="middle">;</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Donna</forename><surname>Harman</surname></persName>
		</author>
		<editor>Voorhees, Ellen</editor>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,96.24,570.52,436.55,8.96;5,96.24,582.04,356.51,8.96" xml:id="b8">
	<monogr>
		<ptr target="http://trec.nist.gov/pubs/" />
		<title level="m" coord="5,192.65,570.52,189.79,8.96">The Sixth Text Retrieval Conference (TREC-6)</title>
		<editor>
			<persName><forename type="first">Donna</forename><surname>Harman</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, Maryland</addrLine></address></meeting>
		<imprint>
			<publisher>NIST Special Publication</publisher>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="5,79.20,593.44,453.47,8.96;5,96.24,604.96,436.78,8.96;5,96.24,616.48,222.57,8.96" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="5,215.01,593.44,269.30,8.96">Multilingual Topic Generation within the CLEF 2001 Experiments</title>
		<author>
			<persName coords=""><forename type="first">Christa</forename><surname>Womser-Hacker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,359.56,604.96,173.46,8.96;5,96.24,616.48,70.35,8.96">Evaluation of Cross-Language Information Retrieval Systems</title>
		<editor>
			<persName><forename type="first">Carol</forename><forename type="middle">;</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Martin</forename><forename type="middle">;</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><forename type="middle">;</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Kluck</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">2406</biblScope>
			<biblScope unit="page" from="389" to="393" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,79.20,628.00,453.59,8.96;5,96.24,639.52,436.66,8.96;5,96.24,650.92,99.82,8.96" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="5,167.01,628.00,330.17,8.96">How Reliable are the Results of Large-Scale Information Retrieval Experiments?</title>
		<author>
			<persName coords=""><forename type="first">Justin</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,514.50,628.00,18.29,8.96;5,96.24,639.52,436.66,8.96">Proc Annual Intl ACM Conference on Research and Development in Information Retrieval (SIGIR &apos;98)</title>
		<meeting>Annual Intl ACM Conference on Research and Development in Information Retrieval (SIGIR &apos;98)<address><addrLine>Melbourne</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="307" to="314" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
