<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,86.12,74.13,422.92,12.64;1,259.40,90.33,76.33,12.64">EXETER at CLEF 2003: Cross-Language Spoken Document Retrieval Experiments</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,212.36,121.32,88.47,8.96"><forename type="first">Adenike</forename><surname>Lam-Adesina</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Exeter</orgName>
								<address>
									<postCode>EX4 4QF</postCode>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,308.12,121.32,71.44,8.96"><forename type="first">Gareth</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Exeter</orgName>
								<address>
									<postCode>EX4 4QF</postCode>
									<country key="GB">U.K</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,86.12,74.13,422.92,12.64;1,259.40,90.33,76.33,12.64">EXETER at CLEF 2003: Cross-Language Spoken Document Retrieval Experiments</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">88AD37BC14D4529388C69C46CB0FB650</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:04+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Cross-Language Spoken Document Retrieval (CLSDR) combines both the complexities of retrieval from collections characterized by speech transcription errors and language translation issues between search requests and documents. Thus achieving effective retrieval in this domain is potentially very challenging. For the CLEF 2003 SDR task we adopted a standard query translation strategy using commercial machine translation tools.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Both Cross-Language Information Retrieval (CLIR) and Spoken Document Retrieval (SDR) are affected by limitations in language processing technologies. In the case of the former this relates to translation between the languages of the document collection and in the latter to the difficulties encountered in transcription of spoken data. These issues are analyzed in more details in <ref type="bibr" coords="1,168.44,319.08,10.69,8.96" target="#b0">[1]</ref>. Spoken Document Retrieval (CLSDR) combines both the difficulties of both CLIR and SDR. Thus retrieval in this domain is very challenging. For CLEF 2003 CLSDR task we adopted a query translation strategy and investigated the use of a large text collection to augmented the spoken document test set. All query statements were translated from the source language into English using two machine translation tools: Systran Version:3.0 (SYS) and Globalink Power Translation Pro Version 6.4 (PRO) Machine Translator (MT) systems. The remainder of this paper summarizes are retrieval system and gives results and initial analysis of our experimental results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Setup</head><p>The basis of the experimental system was the same as that used for our submissions to the monolingual, bilingual and multilingual tasks for CLEF 2003. The system combines Okapi BM25 term weighting with pseudo relevance feedback (PRF), and standard procedures of stop word removal and Porter stemming. Full details are given in <ref type="bibr" coords="1,460.02,470.88,10.69,8.96" target="#b1">[2]</ref>. The parameters of the PRF system were set identically to those for the text retrieval system given in <ref type="bibr" coords="1,394.62,482.40,10.69,8.96" target="#b1">[2]</ref>. The Okapi parameters K1 and b were optimized for the SDR test collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Merged collections</head><p>In our experiments for the CLSDR pilot track held at CLEF 2002 we experimented with the combination of the test collection with a small contemporaneous text document collection for term weight estimation <ref type="bibr" coords="1,438.20,553.68,10.69,8.96" target="#b2">[3]</ref>. This method aims to improve retrieval performance for the test set by better estimated of term weights. Our results for CLEF 2002 indicated that the method can give improvements in retrieval performance even when using only a small number of additional documents. Results for ITC-irst however showed that large improvements can be realized if a much larger number of contemporaneous documents is used <ref type="bibr" coords="1,207.88,599.64,10.67,8.96" target="#b3">[4]</ref>. However, this large collection of truly contemporaneous documents was not available to us. This led us to investigate the use of an alternative large text document collection. In this case we used the document set from the TREC-8 and TREC-9 ad hoc retrieval tasks. This consists of around 500,000 text documents. In addition, we used again used the two small collections of truly contemporaneous text documents. These sources are taken from New York Times Newswire Service (excluding non-NYT sources) and Associated Press Worldstream Service (English content only), totaling about 20,000 news stories, and are taken from exactly the same period as the spoken document test collection. These three text collections were merged collection into a single collection which was used as the pilot collection from which initial query statements are expanded in experiments reported in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>* now at School of Computing, Dublin City University, Ireland email: Gareth.Jones@computing.dcu.ie This section describes our results for the CLEF 2003 SDR Tasks. We report baseline and feedback results for five topic languages, English, French, German, Italian and Spanish. Our results include runs for topic translations using both SYS and PRO MT systems. Results are presented for the following methods:</p><p>1. Baseline run without feedback (exebase) 2. Feedback runs using expanded query from the test collection (exepl) 3. Feedback runs using expanded query from the pilot collection and term weight estimated from the test collection. Initial query terms are upweighted by multiply by 1.5 (exeprn1.5) 4. Same as 3 but initial query terms are upweighted by 3.5 (exeprn3.5) Results for out CLSDR runs are shown in Tables <ref type="table" coords="2,257.89,520.44,4.98,8.96" target="#tab_0">1</ref> and<ref type="table" coords="2,282.86,520.44,4.98,8.96" target="#tab_1">2</ref> for Systran and Power Translator Pro MT respectively. It can be seen that as expected the monolingual English result is the best in all cases with respect to both average precision and number of relevant documents retrieved. CLSDR performance is comparable for the French, Italian and Spanish topic statements with lower results for the German topics. This result is a little surprising for Systran French topic translation which has previously been shown to be more effective than other topic translations in our CLEF bilingual text retrieval experiments <ref type="bibr" coords="2,108.29,577.92,10.64,8.96" target="#b4">[5]</ref>. PRF using only the test collection is observed to be effective for query expansion in all cases. Results for query expansion using the pilot strategy are more mixed. In the case of Italian and Spanish topics this approach clearly outperforms test collection only query expansion. However, there is little difference between the results for these methods when using French and German topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SYS MT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Further Work</head><p>The results for the CLEF 2003 CLSDR task reported in this paper establish baseline performance figures against which the exploration of techniques for CLSDR can be measured. The experiments reported here show that PRF is effective for this task, as would be expected since it is generally a useful techniques for text CLIR and SDR. The use of large additional test collections for parameter estimation for query expansion can produce improvements in performance over test collection only based expansion, but cannot be relied upon to do so. While there is clearly scope to develop a more detailed investigation of the interaction of translation and indexing errors, an initial further set of experiments is planned using the pilot collection weights in the final retrieval phase. This technique was observed to be effective for our small pilot collection in previous experiments <ref type="bibr" coords="3,217.90,84.48,10.69,8.96" target="#b2">[3]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,56.60,188.52,482.05,282.93"><head>Table 1 :</head><label>1</label><figDesc>Average precision retrieval results for topic translation using SYS MT before and after application of different feedback methods</figDesc><table coords="2,133.76,188.52,319.02,282.93"><row><cell></cell><cell>English</cell><cell>French</cell><cell>German</cell><cell>Italian</cell><cell>Spanish</cell></row><row><cell>exebase</cell><cell>311</cell><cell>227</cell><cell>203</cell><cell>231</cell><cell>250</cell></row><row><cell>exepl</cell><cell>382</cell><cell>281</cell><cell>270</cell><cell>279</cell><cell>292</cell></row><row><cell>Rel_ret</cell><cell>1795</cell><cell>1558</cell><cell>1498</cell><cell>1638</cell><cell>1641</cell></row><row><cell>% chg</cell><cell>22.8%</cell><cell>23.8%</cell><cell>33.0%</cell><cell>20.7%</cell><cell>16.8%</cell></row><row><cell>exeprn1.5</cell><cell>364</cell><cell>283</cell><cell>274</cell><cell>299</cell><cell>304</cell></row><row><cell>Rel_ret</cell><cell>1824</cell><cell>1618</cell><cell>1541</cell><cell>1684</cell><cell>1720</cell></row><row><cell>% chg</cell><cell>17.0%</cell><cell>24.7%</cell><cell>34.9%</cell><cell>29.4%</cell><cell>21.6%</cell></row><row><cell>exeprn3.5</cell><cell>371</cell><cell>276</cell><cell>268</cell><cell>296</cell><cell>307</cell></row><row><cell>Rel_ret</cell><cell>1789</cell><cell>1577</cell><cell>1524</cell><cell>1653</cell><cell>1707</cell></row><row><cell>% chg</cell><cell>19.3%</cell><cell>21.6%</cell><cell>32.0%</cell><cell>28.1%</cell><cell>22.8%</cell></row><row><cell>PRO MT</cell><cell>English</cell><cell>French</cell><cell>German</cell><cell>Italian</cell><cell>Spanish</cell></row><row><cell>Exebase</cell><cell>311</cell><cell>235</cell><cell>188</cell><cell>234</cell><cell>235</cell></row><row><cell>exeprn1.5</cell><cell>364</cell><cell>262</cell><cell>242</cell><cell>301</cell><cell>315</cell></row><row><cell>Rel_ret</cell><cell>1824</cell><cell>1589</cell><cell>1431</cell><cell>1624</cell><cell>1710</cell></row><row><cell>% chg</cell><cell>17.0%</cell><cell>11.5%</cell><cell>28.7%</cell><cell>28.6%</cell><cell>34.0%</cell></row><row><cell>exeprn3.5</cell><cell>371</cell><cell>256</cell><cell>229</cell><cell>293</cell><cell>308</cell></row><row><cell>Rel_ret</cell><cell>1789</cell><cell>1574</cell><cell>1420</cell><cell>1602</cell><cell>1682</cell></row><row><cell>% chg</cell><cell>19.3%</cell><cell>8.9%</cell><cell>21.8%</cell><cell>25.2%</cell><cell>31.1%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,56.60,486.00,482.03,20.48"><head>Table 2 :</head><label>2</label><figDesc>Average precision retrieval results for topic translation using PRO MT before and after application of different feedback methods</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="3,72.79,132.84,465.94,8.96;3,56.60,144.36,482.01,8.96;3,56.60,155.76,136.73,8.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="3,200.24,132.84,321.43,8.96">CLEF 2002 Cross-Language Spoken Document Retrieval Pilot Track Report</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,56.60,144.36,445.28,8.96">Proceedings of the CLEF 2002: Workshop on Cross-Language Information Retrieval and Evaluation</title>
		<meeting>the CLEF 2002: Workshop on Cross-Language Information Retrieval and Evaluation<address><addrLine>Rome</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2002-09">September 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,74.34,167.28,464.26,8.96;3,56.60,178.80,482.14,8.96;3,56.60,190.32,259.28,8.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="3,231.19,167.28,88.03,8.96;3,354.05,167.28,184.55,8.96;3,56.60,178.80,204.42,8.96">Experiments with Machine Translation for Monolingual, Bilingual and Multilingual Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Lam-Adesina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,280.04,178.80,258.70,8.96;3,56.60,190.32,149.23,8.96">Proceedings of the CLEF 2003: Workshop on Cross-Language Information Retrieval and Evaluation</title>
		<meeting>the CLEF 2003: Workshop on Cross-Language Information Retrieval and Evaluation<address><addrLine>Trondheim</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-08">2003. August 2003</date>
		</imprint>
	</monogr>
	<note>EXETER AT CLEF</note>
</biblStruct>

<biblStruct coords="3,74.24,201.84,464.40,8.96;3,56.60,213.24,482.13,8.96;3,56.60,224.76,165.65,8.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="3,242.65,201.84,296.00,8.96;3,56.60,213.24,48.49,8.96">Exeter at CLEF 2002: Cross-Language Spoken Document Retrieval Experiments</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Lam-Adesina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,124.04,213.24,410.47,8.96">Proceedings of the CLEF 2002: Workshop on Cross-Language Information Retrieval and Evaluation</title>
		<meeting>the CLEF 2002: Workshop on Cross-Language Information Retrieval and Evaluation<address><addrLine>Rome</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2002-09">September 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,72.08,236.68,466.52,10.80;3,56.60,250.08,482.01,8.96;3,56.60,261.60,136.73,8.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="3,211.64,238.08,310.87,8.96">Cross-Language Spoken Document Retrieval on the TREC SDR Collection</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,56.60,250.08,445.28,8.96">Proceedings of the CLEF 2002: Workshop on Cross-Language Information Retrieval and Evaluation</title>
		<meeting>the CLEF 2002: Workshop on Cross-Language Information Retrieval and Evaluation<address><addrLine>Rome</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2002-09">September 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,71.88,273.12,466.65,8.96;3,56.60,284.64,481.84,8.96;3,56.60,296.04,164.96,8.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="3,228.36,273.12,310.17,8.96;3,56.60,284.64,35.13,8.96">Exeter at CLEF 2001: Experiments with Machine Translation for Bilingual Retrieval</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Lam-Adesina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,112.70,284.64,421.58,8.96">Proceedings of the CLEF 2001: Workshop on Cross-Language Information Retrieval and Evaluation</title>
		<meeting>the CLEF 2001: Workshop on Cross-Language Information Retrieval and Evaluation<address><addrLine>Darmstadt, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="59" to="77" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
