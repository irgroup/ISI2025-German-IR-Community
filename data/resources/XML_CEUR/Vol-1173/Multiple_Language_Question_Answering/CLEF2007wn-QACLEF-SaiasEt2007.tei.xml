<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,115.90,146.21,371.17,18.08;1,181.14,168.13,240.70,18.08">The Senso Question Answering approach to Portuguese QA@CLEF-2007</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,232.21,203.19,43.97,10.46"><forename type="first">José</forename><surname>Saias</surname></persName>
							<email>jsaias@di.uevora.pt</email>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Informática</orgName>
								<orgName type="institution">Universidade de Évora</orgName>
								<address>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,298.88,203.19,71.89,10.46"><forename type="first">Paulo</forename><surname>Quaresma</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Informática</orgName>
								<orgName type="institution">Universidade de Évora</orgName>
								<address>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,115.90,146.21,371.17,18.08;1,181.14,168.13,240.70,18.08">The Senso Question Answering approach to Portuguese QA@CLEF-2007</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">317D4B69ADD405415D55303B66F99355</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.7 Digital Libraries</term>
					<term>I.2 [Artificial Intelligence]: I.2.3 Deduction and Theorem Proving-Answer/reason extraction</term>
					<term>Deduction</term>
					<term>Logic programming,I.2.7 Natural Language Processing Natural Language Processing, Question answering, Questions beyond factoids</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The University of Évora team in QA@CLEF-2007 tested their Senso system in the Portuguese monolingual task. The system uses an ontology semantic information for text search terms expansion and for verification of concept equivalency or IsA/specialization relations. The full text collection is indexed and for each question it's done a search, for retrieval of possible relevant documents that may have one answer. The solver module engine starts by producing a First-Order Logic expression representing the question and a logic facts list representing the texts information. There is a logic-programming based module that looks for answers within the facts list that unify and validate the question logic form. For cases where the answer can be directly detected in the text there is an ad-hoc module. Then the logic and ad-hoc found results are merged and the solution with highest weight is selected. We sent one run result for evaluation. The overall accuracy was 42% and the Confidence Weighted Score was 0.19524. This paper has a description of our system.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper describes the use of Senso Question Answer System in the Question Answering (QA) task of the 2007's edition of Cross Language Evaluation Forum (CLEF)<ref type="foot" coords="1,406.54,681.77,3.97,7.32" target="#foot_0">1</ref> . The presented system has been developed at the Informatics Department of the University of Évora, after two previous participations in 2004 <ref type="bibr" coords="1,188.05,706.75,10.52,10.46" target="#b0">[1]</ref> and 2005 <ref type="bibr" coords="1,244.50,706.75,9.96,10.46" target="#b1">[2]</ref>. The Portuguese monolingual QA had 200 questions that this system processed, looking for an answer in the texts. Besides the usual newspapers collections from Público and Folha de São Paulo, the system had to consider also the Portuguese articles from Wikipedia. Other relevant innovation was the existence of clusters or groups of questions about the same implicit topic, with possible anaphoric references between one question and the others. In such case, the system identifies the topic either in the first question or in the first answer, as referred in the guidelines. This QA system (Senso) is based on the authors previous work <ref type="bibr" coords="2,376.56,182.26,10.52,10.46" target="#b2">[3]</ref> and <ref type="bibr" coords="2,410.44,182.26,9.96,10.46" target="#b3">[4]</ref>. It uses an ontology as a knowedge base with semantic information usefull in several steps along the process. The next section explains the system architecture. The followed methodology is described with examples in section 3. The evaluation of the obtained results is presented in section 4. Finally, some conclusions and future work are pointed out in section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Architecture</head><p>Senso Question Answer System has five major modules: Libs, Query, Solver, Ontology and Web Interface. Figure <ref type="figure" coords="2,166.97,296.81,4.98,10.46" target="#fig_0">1</ref> represents the way they are connected. All the questions are firstly analyzed by the Query Module. The query group identifier determines if a query will be associated with the first from that group. This module will also select a set of relevant documents for each question, as explained later.</p><p>When we have an isolated sentence it's usually difficult to automatically capture its meaning. The Senso Ontology module has a starting knowledge base with semantic information that helps to perform the sentence analysis and the subsequent inference processes. This information is structured by an OWL<ref type="foot" coords="2,186.97,579.18,3.97,7.32" target="#foot_1">2</ref> Ontology including concepts, relations and properties. The OWL language has the intended semantic features and it is suitable for web publications, allowing us to share parts of our knowledge base in a direct and appropriate manner. Besides concept "IsA" relations, the ontology includes some simple facts about everyday life that might be very useful for text analysis. Our current ontology contains about 3500 concepts and has several relations connecting them: isA, usedFor, locatedAt, capableOf and madeOf. These concepts and relations represent a small common sense knowledge base about places, entities and events. Some of the top-level concepts are shown in figure <ref type="figure" coords="2,346.20,663.93,3.87,10.46" target="#fig_1">2</ref>.</p><p>The Solver Module performs a search for plausible answers in the identified relevant documents, being aware of the semantic expressed in the ontology. It has a logic-programming based tool and an ad-hoc answer selector. The Web Interface layer allows an easier and friendly usage of the system, simplifying the analysis of each intermediate step in the process, as illustrated in figure <ref type="figure" coords="3,364.74,282.43,3.87,10.46" target="#fig_2">3</ref>. This interface is used to browse the ontology and to make small changes to it. We can also use a web browser application to search for documents (or queries) and read them. Next section explains the methodology used to find the answers. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>This section explains our approach to CLEF-2007 Question Answer track in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Import the Text Collections</head><p>The starting point is the information source: the document collections. This year we had 210734 newspaper texts and 336622 Wikipedia texts for the Portuguese target language. The XML collection files were processed and split in single texts, along with important metadata. The Libs Module keeps all these individual documents, being aware of their temporal context, which is obtained from the collection. Because we needed to perform some text search operations, the collections were indexed at this point with Lucene<ref type="foot" coords="4,169.33,199.58,3.97,7.32" target="#foot_2">3</ref> , a full-featured text search engine library. Lucene scoring uses a combination of the Vector Space Model and the Boolean model to determine how relevant a given document is to a query. Each text was then processed with Palavras <ref type="bibr" coords="4,288.84,236.52,14.76,10.46" target="#b4">[5]</ref>, a syntactical parser<ref type="foot" coords="4,399.25,235.45,3.97,7.32" target="#foot_3">4</ref> based in the Constraint Grammars formalism that has a good coverage of the Portuguese language. This tool gives a detailed morpho-syntactical representation of the text for latter usage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Question Analysis</head><p>Each question is processed with the syntactical parser Palavras <ref type="bibr" coords="4,368.71,306.21,15.34,10.46" target="#b4">[5]</ref> and a semantic analyzer able to obtain a partial semantic representation. The technique used for this process is based on Discourse Representation Structures (DRS) <ref type="bibr" coords="4,272.41,330.12,9.96,10.46" target="#b7">[7]</ref>. The partial semantic representation of a sentence is a DRS built with two lists, one with the rewritten sentence and the other with the sentence discourse referents. We are only dealing with a restricted semantic analysis and we are not able to handle every aspect of the semantics. The DRS is a First-Order Logic expression which the logic resolution tool will try to understand.</p><p>Let us consider the following definition question, in this year's edition:</p><p>Quem é Boaventura Kloppenburg ?</p><p>Figure <ref type="figure" coords="4,136.32,435.02,4.98,10.46" target="#fig_3">4</ref> shows the morpho-syntactical representation given for that question. We can see the parser tags identifying the subject, the predicate and the interrogative form quem (Who). Figure <ref type="figure" coords="4,90.00,458.93,4.98,10.46" target="#fig_4">5</ref> has the DRS for the same question, with the semantic representation used by the system for latter logic inference process.  Our question answer system does a preliminary information retrieval task, in order to define a set of potentially relevant documents for each question. The amount of chosen documents may be from zero to several hundreds. This avoids the computational complexity of dealing with more than a half million texts. In the case where no candidate documents are found the system cannot find an answer and the result is NIL. The Query Module produces the Lucene search query. This is done with the question text terms and, for some, their related terms. So, if a question has something like "Which bird..." the text search query will include synonyms of bird and specialization terms given by the Senso ontology, such as eagle. This semantic operation in the query allows the retrieval of a text that may not have the word bird but is still relevant as a possible answer source. Question 15 asked which tree is present in the Lebanon flag. The answer was cedro (or cedar, in English). Being aware that cedar is a tree was important to the process. When the question belongs to a cluster and it is not the first from that group the query is fed with more terms, in order to include the implicit topic. The system goes back to that cluster's first question and gets their search terms and answer into the Lucene query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Solver Engine</head><p>The Solver Module is the core piece in our methodology. It is responsible for finding a list of answers for a query. Each answer has a weight and a support note: sentence or expression justifying the answer and it's document identifier, as we can see in figure <ref type="figure" coords="5,350.16,321.19,4.98,10.46" target="#fig_5">6</ref> for the question 17:</p><p>O que é um barrete frígio ? The semantic analyzer used before for the query will now produce a DRS list for the selected texts. This list is seen as a small and question dedicated knowledge base: the facts list. The logic solver is a logic-programming based module that performs a pragmatic interpretation of the query DRS over the full system knowledge base (the ontology and the facts list). It tries to find the best explanations for the question logic form to be true. This strategy for interpretation is known as "interpretation as abduction" <ref type="bibr" coords="5,222.39,701.53,9.96,10.46" target="#b5">[6]</ref>. The inference process is done with the Prolog resolution algorithm, which tries to unify the referents from the query with referents from documents, in the facts list, with help from the semantic information given by the ontology.</p><p>The ad-hoc solver is an answer generator for specific cases where the possible solution can be directly detected in the text. The system verifies each case specific conditions for the query and text expressions. When the conditions are verified, that ad-hoc case gives one answer. Verifying the conditions might include a term semantic test for equivalence or "IsA" relation with another term, which is done by ontology analysis. Figure <ref type="figure" coords="6,121.43,165.33,4.98,10.46" target="#fig_6">7</ref> has a list of answers for question 34:</p><p>Qual o diâmetro de Ceres ? This is a Factoid question about a measure. The ad-hoc solver identified the term diâmetro (diameter) and searched for numerical answers, including the unit of measure (km, metros). The logic and ad-hoc found results are then merged to a final and weight sorted list. The answer merging process checks for repeated values and joins their support data, assigning the highest weight to that result. When the system finds more than one result for a question the QA@CLEF answer is the one with the maximum weight.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>In this QA@CLEF's edition, the Universidade de Évora's group registered for the monolingual Portuguese task, as did in previous participation <ref type="bibr" coords="6,307.91,636.56,9.96,10.46" target="#b1">[2]</ref>, in 2005. The proposed system was applied to the set of 200 questions and one run output was sent for evaluation.</p><p>A correct answer was found for 84 questions, which corresponds to an accuracy score of 42%. This value represents a relative increment of 68% from our department last participation global accuracy (25%). Analyzing the results by question category, we can say that most of the errors were in the 90 wrong NIL returned values, where the system could not find an answer. Then, the List and Temporally Restricted questions represented a challenge and the obtained accuracy for these cases was around 20%. In the Factoids category the system had an accuracy close to the overall value, it was 39.62%. The best relative accuracy result was achieved in the Definition question type: 61.29%. Table <ref type="table" coords="7,117.39,122.49,4.98,10.46" target="#tab_0">1</ref> shows the accuracy values in more detail. The overall Confidence Weighted Score over all assessed questions is 39.048/200 or 0.19524. Comparing the current overall accuracy with the obtained in our department previous participation we believe this system produced good results. However, it needs some improvements as explained in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>In this paper we describe our Question Answering System for QA@CLEF-2007. Compared with the system we used in 2005, the Senso system has a different methodology and is based in a different ontology. The results obtained are quite satisfactory and better since our last participation.</p><p>A preliminary analysis on the incorrect answers showed that some questions had no candidate documents where to search for an answer. This means that the Lucene query used for document retrieval failed in those cases. Our semantic analyzer also had some problems with DRS generation, while analyzing the morphosyntactical representation of non-trivial sentences. Other problems were related to incorrect pragmatic analysis, in the logic solver, due to ontology limitations and some lack of precision on the semantic information taken from the text sentences.</p><p>The Lucene search engine indexes all text collections and gives the system a list of documents that may have an answer and need detailed analysis. This was important to avoid problems with time constraints, because some of the hard work is now done only over the selected documents. However, we need to correct the way the Lucene text search query is built, to fetch the answer candidate documents where it currently cannot do it. We also intend to improve the Senso ontology. Since many operations in our methodology depend on it's content, it should be manually revised and extended. Along with this, some disambiguation tool would help for better precision when a sentence concept is being related with an ontology existent term.</p><p>In a future QA@CLEF participation we intend to apply our system to other languages besides the Portuguese monolingual task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,247.54,436.79,107.92,10.46;2,104.94,460.69,408.06,10.46;2,90.00,472.65,423.02,10.46;2,90.01,484.61,340.62,10.46;2,90.00,496.56,423.01,10.46;2,90.00,508.52,423.01,10.46;2,90.01,520.47,247.10,10.46;2,174.10,327.75,238.04,93.92"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Senso Modules The Libs Module contains collections of text documents. These collections are seen as libraries that contain information needed for question answering. It had the five collections: Público and Folha de São Paulo from years 1994 and 1995, plus the Wikipedia documents.All the questions are firstly analyzed by the Query Module. The query group identifier determines if a query will be associated with the first from that group. This module will also select a set of relevant documents for each question, as explained later.</figDesc><graphic coords="2,174.10,327.75,238.04,93.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,203.54,238.65,195.93,10.46;3,131.80,117.55,322.56,105.98"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Senso Ontology: top-level concepts</figDesc><graphic coords="3,131.80,117.55,322.56,105.98" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="3,174.69,643.07,253.63,10.46;3,151.60,349.36,283.01,278.60"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Web Interface: options for intermediate analysis</figDesc><graphic coords="3,151.60,349.36,283.01,278.60" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,205.24,555.38,192.53,10.46"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Syntactical Parser: sample output</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="4,234.13,683.57,134.75,10.46;4,139.92,597.83,303.43,72.00"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: DRS for Question 12</figDesc><graphic coords="4,139.92,597.83,303.43,72.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="5,224.48,580.05,154.03,10.46;5,104.94,603.90,408.06,10.46;5,90.00,615.86,148.34,10.46;5,81.50,380.06,421.34,185.70"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Definition question resultThe search for plausible answers is done on the Lucene selected documents by two tools: the logic solver and the ad-hoc solver.</figDesc><graphic coords="5,81.50,380.06,421.34,185.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="6,207.24,485.84,188.52,10.46;6,81.83,245.64,420.32,225.92"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Numerical factoid question result</figDesc><graphic coords="6,81.83,245.64,420.32,225.92" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,97.23,155.32,408.38,111.28"><head>Table 1 :</head><label>1</label><figDesc>System accuracy results in QA@CLEF-2007</figDesc><table coords="7,97.23,155.32,408.38,79.55"><row><cell>Question Type</cell><cell>#</cell><cell cols="5">Right Wrong Unsupported Inexact Accuracy</cell></row><row><cell>Nil</cell><cell>111 returned</cell><cell>12</cell><cell>99</cell><cell>0</cell><cell>0</cell><cell>10.81%</cell></row><row><cell>Temporally Restricted</cell><cell>19</cell><cell>4</cell><cell>15</cell><cell>0</cell><cell>0</cell><cell>21.05%</cell></row><row><cell>Definition</cell><cell>31</cell><cell>19</cell><cell>5</cell><cell>0</cell><cell>0</cell><cell>61.29%</cell></row><row><cell>Lists</cell><cell>10</cell><cell>2</cell><cell>8</cell><cell>0</cell><cell>0</cell><cell>20.00%</cell></row><row><cell>Factoids</cell><cell>159</cell><cell>63</cell><cell>90</cell><cell>1</cell><cell>1</cell><cell>39.62%</cell></row><row><cell>All Questions</cell><cell>200</cell><cell>84</cell><cell>103</cell><cell>1</cell><cell>1</cell><cell>42.00%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,105.24,737.97,393.96,8.37"><p>For more information, see http://www.clef-campaign.org/ and http://clef-qa.itc.it/2007/CLEF-2007.html.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,105.24,717.13,407.88,8.37;2,90.00,726.59,423.08,8.37;2,90.00,736.05,423.12,8.37;2,90.01,745.51,23.53,8.37"><p>OWL<ref type="bibr" coords="2,119.88,717.13,14.64,8.37" target="#b8">[8]</ref> is the short name for Web Ontology Language and it is a language proposed by the W3C consortium to be used in the Semantic Web for the representation of ontologies. This language is based in the previous DAML+OIL (Darpa Agent Markup Language) language and it is defined using RDF (Resource Description Framework).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,105.24,736.35,253.40,8.37"><p>Apache Lucene is an open source project. http://lucene.apache.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,105.24,745.85,282.96,8.37"><p>Tool developed by Eckhard Bick. VISL Project: http://visl.hum.sdu.dk/visl</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,105.49,714.30,407.51,10.46;7,105.50,723.75,327.05,12.97" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,472.78,714.30,40.22,10.46;7,105.50,723.75,196.98,12.97">The University of Évora approach to QA@CLEF-2004</title>
		<author>
			<persName coords=""><forename type="first">Paulo</forename><surname>Quaresma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luis</forename><surname>Quintano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Irene</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">José</forename><surname>Saias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pedro</forename><surname>Salgueiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,311.68,726.26,116.30,10.46">CLEF 2004 Working Notes</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.49,110.53,407.51,10.46;8,105.50,122.49,151.57,10.46" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="8,271.43,110.53,241.57,10.46;8,105.50,122.49,22.82,10.46">A Logic Programming Based Approach To QA@CLEF05 Track</title>
		<author>
			<persName coords=""><forename type="first">Paulo</forename><surname>Quaresma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Irene</forename><surname>Rodrigues</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="report_type">CLEF</note>
	<note>Working Notes</note>
</biblStruct>

<biblStruct coords="8,105.49,142.41,407.51,10.46;8,105.50,154.37,407.50,10.46;8,105.50,166.33,407.51,10.46;8,105.50,178.28,335.76,10.46" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,245.12,142.41,267.89,10.46;8,105.50,154.37,62.35,10.46">A proposal for an ontology supported news reader and questionanswer system</title>
		<author>
			<persName coords=""><forename type="first">José</forename><surname>Saias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paulo</forename><surname>Quaresma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,361.91,154.37,151.09,10.46;8,105.50,166.33,407.51,10.46;8,105.50,178.28,104.90,10.46">2nd Workshop on Ontologies and their Applications (WONTO&apos;06) in the Proceedings of International Joint Conference, 10th IBERAMIA, ICMC-USP</title>
		<editor>
			<persName><forename type="first">Solange</forename><surname>Oliveira</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rezende</forename></persName>
		</editor>
		<meeting><address><addrLine>Ribeirão Preto, Brazil</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.49,198.21,407.52,10.46;8,105.50,210.16,407.52,10.46;8,105.50,222.12,407.50,10.46;8,105.50,234.07,233.95,10.46" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,250.35,198.21,262.67,10.46;8,105.50,210.16,31.64,10.46">A methodology to create ontology-based information retrieval systems</title>
		<author>
			<persName coords=""><forename type="first">José</forename><surname>Saias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paulo</forename><surname>Quaresma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,369.77,210.16,143.24,10.46;8,105.50,222.12,375.29,10.46">Progress in Artificial Intelligence -Proceedings of the 11th Protuguese Conference on Artificial Intelligence, EPIA&apos;03</title>
		<editor>
			<persName><forename type="first">Fernando</forename><surname>Moura</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Pires</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">Salvador</forename><surname>Abreu</surname></persName>
		</editor>
		<meeting><address><addrLine>Beja, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.49,253.99,407.51,10.46;8,105.50,265.96,339.66,10.46" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,177.32,253.99,136.64,10.46">The Parsing System &quot;Palavras</title>
		<author>
			<persName coords=""><forename type="first">Eckhard</forename><surname>Bick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,328.02,253.99,184.98,10.46;8,105.50,265.96,197.16,10.46">Automatic Grammatical Analysis of Portuguese in a Constraint Grammar Framework</title>
		<imprint>
			<publisher>Aarhus University Press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.49,285.88,407.52,10.46;8,105.50,297.84,210.20,10.46" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,390.43,285.88,118.15,10.46">Interpretation as abduction</title>
		<author>
			<persName coords=""><forename type="first">Jerry</forename><surname>Hobbs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Stickel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><surname>Appelt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Martin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,105.50,297.84,167.96,10.46">Technical Report SRI Technical Note</title>
		<imprint>
			<biblScope unit="volume">499</biblScope>
			<biblScope unit="page">333</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,320.33,297.84,192.67,10.46;8,105.50,309.79,22.69,10.46" xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Ravenswood</forename><surname>Ave</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990">94025. 1990</date>
			<pubPlace>Menlo Park, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.49,329.72,331.13,10.46" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Kamp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Reyle</surname></persName>
		</author>
		<title level="m" coord="8,216.04,329.72,105.13,10.46">From Discourse to Logic</title>
		<meeting><address><addrLine>Dordrecht</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.49,349.64,407.50,10.46;8,105.50,361.60,258.42,10.46" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="8,362.13,349.64,146.58,10.46">Owl web ontology language guide</title>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Welty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Deborah</forename><surname>Mcguinness</surname></persName>
		</author>
		<ptr target="http://www.w3.org/TR/owl-guide/" />
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
