<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,157.01,148.86,288.98,15.15">N-Gram Morphemes for Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,223.29,182.75,66.28,8.74"><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
							<email>paul.mcnamee@jhuapl.edu</email>
							<affiliation key="aff0">
								<orgName type="laboratory">JHU Applied Physics Laboratory</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,312.26,182.75,67.45,8.74"><forename type="first">James</forename><surname>Mayfield</surname></persName>
							<email>james.mayfield@jhuapl.edu</email>
							<affiliation key="aff0">
								<orgName type="laboratory">JHU Applied Physics Laboratory</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,157.01,148.86,288.98,15.15">N-Gram Morphemes for Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6A0507E5C8BACC3BB15FAAAC4FCAFBE6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing; H.3.3 Information Search and Retrieval Morphological Analysis</term>
					<term>Character N-gram Tokenization</term>
					<term>Text Retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Stemming, an approximation to morphological analysis, is a commonly used technique to improve performance in information retrieval systems. In the MorphoChallenge 2007 evaluation we applied a simple zero-knowledge technique that is based on frequency counts rather than machine learning. Our method is based on substituting a single fixed-length substring for each word that appears in documents or queries. We hope to discover whether this method, which has been used in previous IR evaluations with good effect, will be as effective for the information retrieval task as the unsupervised methods used by other participants. It should be emphasized that out submission was not a credible attempt to learn morphology and thus is not expected to perform well in the morphology induction task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Our aim in the MorphoChallenge 2007 evaluation was to explore how a simple method for approximating word stemming would compare against state of the art morphology induction on the Information Retrieval task. Our method is based on the use of character n-gram tokenization, which we have used successfully in the Cross Language Evaluation Forum (CLEF) competitions. N-grams have the advantages of simplicity and accuracy, but do incur penalties of increased disk space requirements and longer run times. In an attempt to achieve the benefits of n-gram indexing without incurring a substantial cost in run-time performance we devised a method of 'n-gram stemming' that replaces each word with a selected n-gram. The method only presumes the availability of text, which is clearly reasonable for IR applications.</p><p>In Section 2 we explain n-gram indexing and describe how synthetic morphemes are obtained. We evaluate the effectiveness of the technique in Section 3 using previous CLEF data sets. We summarize our findings in Section 4 and give a complete listing of our source code for producing morphemes as an appendix.</p><p>2 Character N-gramming</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">N-gram Indexing</head><p>Commonly IR systems adopt a bag-of-words model where words in a document are treated as the basic indexing units. Often the tokenization process additionally transforms words into stems or root forms so that words that differ only by inflectional or perhaps even derivational morphology are treated as the same. With character n-gram indexing, words are not considered the basic indexing unit; instead, character substrings are used, typically of a fixed length. For example, for the text 'Johns Hopkins' the character 4-grams generated are: #joh, john, ohns, hns#, ns#h, s#ho, #hop, hopk, opki, pkin, kins, and ins#<ref type="foot" coords="2,291.66,224.38,3.97,6.12" target="#foot_0">1</ref> . While short n-grams can have higher individual ambiguity (e.g., ins# could come from the words fins, skins, and dolphins, among others), this collection of twelve n-grams is not very likely to occur unless the phrase 'Johns Hopkins' was present in the original text. Storing 12 entries in an inverted file instead of just two (one for each word) is why n-gram indexing suffers from performance issues. However, this expense also enables flexible matching. Web log analysis shows that roughly 30% of users mistakenly<ref type="foot" coords="2,485.29,284.16,3.97,6.12" target="#foot_1">2</ref> type "john hopkins" and yet 8 out of the 12 n-grams still match this string.</p><p>N-grams have been used in many Asian languages because of inherent difficulties with word segmentation; however they have not been very popular in Western languages. Damashek <ref type="bibr" coords="2,502.48,321.60,10.52,8.74" target="#b0">[1]</ref> promoted their use at early TREC evaluations, but his claims generated controversy and were received with skepticism. McNamee and Mayfield <ref type="bibr" coords="2,309.33,345.51,10.52,8.74" target="#b2">[3]</ref> overwhelmingly demonstrated that n-grams are effective in European languages and presented compelling evidence using eight languages from the CLEF 2002 evaluation. They found that lengths of n=4 or n=5 worked about equally well and significantly outperformed unnormalized words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">N-gram Stemming</head><p>In their article on n-gram indexing, McNamee and Mayfield left unaddressed the question of whether n-grams achieved higher performance over stemmed words. But in other work they did a direct comparison of n-grams and stems and found that 4-grams performed on par with Porter's SNOWBALL stemmer and in three of eight CLEF 2002 languages performed significantly better. The tendency was that n-grams held an advantage in the more morphologically complex languages (i.e., Finnish, Swedish, German). Still, the question remained as to whether the advantage in accuracy was worth the degradation in run-time performance.</p><p>The key factor in increased disk space and run-times is the fact that each word generates multiple n-grams. If there were only some way to prune away most of the n-grams and yet preserve enough of the benefits of n-grams to still confer an advantage. The selection method for each word must be efficient as this is an operation that will be performed on every word in the corpusbillions of operations will be required. Mayfield and McNamee <ref type="bibr" coords="2,371.41,559.16,10.52,8.74" target="#b1">[2]</ref> introduced n-gram stemming where a single n-gram would be used to represent each word. The selected n-gram was chosen based on the relative document frequencies of the n-grams spanning the word under consideration. The least frequent n-gram was used; this makes sense if the hypothesis that frequent n-grams are more likely to be part of the morphologically variable part of a word, not the root form. As an example, consider the words jugglers and juggling. Using statistics from 110282 newspaper articles the constituent n-grams of each word are shown in Table <ref type="table" coords="2,341.19,630.89,3.87,8.74" target="#tab_0">1</ref>. It can be clearly seen that the rarest n-gram 'jugg' occurs much less often than the suffixes 'ers ' and 'ing '. And both words would get replaced with 'jugg' which intuitively seems like a good choice.</p><p>Other methods for selecting a single n-gram or a small number of n-grams are possible. For example, the examples we have given use n=4, but since three runs were permitted in this year's evaluation we also created lists using n=3 and n=5. One could consider variants such as using two disjoint 3-grams or never ending an n-gram on a vowel, or any number of other permutations that might have linguistic merit. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task 1: Morphology Induction</head><p>For Task 1 we simply reported, for each word, the 3, 4, or 5-gram with lowest collection frequency based on the training data provided for each language. We did not predict any attributes such as +PL or +3 PER. Since we did not set out to truly learn morphological rules, we are not really surprised by our results. Our runs had lower F-score than all other runs in each of the four languages. We note that our runs with 5-grams did have the highest precision in each of the four languages with with very low recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Prior Results in Information Retrieval</head><p>We have experimented with n-gram morphemes in previous CLEF datasets. In Table <ref type="table" coords="3,459.70,540.51,4.98,8.74" target="#tab_1">2</ref> we present results in five languages using data from CLEF 2002 (for English, German, and Finnish) and CLEF 2005 (Bulgarian and Hungarian) that illustrate the relative effectiveness of n-gram indexing and n-gram analysis compared to processing unnormalized words. We report performance using mean average precision. Comparisons should not be made across languages in Table <ref type="table" coords="3,437.30,588.33,3.87,8.74" target="#tab_1">2</ref>, but the results are meaningful for the different conditions in each language.</p><p>N-gram stemming usually helps, though performance was slightly worse for English. The largest gains are in the more complex languages and n-gram stemming does not perform as well as the use of ordinary n-gram indexing where the set of all n-grams is used instead of a select one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Task 2: Information Retrieval</head><p>In this competition the organizers took lists of normalized word forms and replaced words in the CLEF source documents with a canonical form. The test sets used were: CLEF-2005 (English), CLEF-2004 (Finnish), and CLEF-2003 (German). The Lemur retrieval engine was used with TF/IDF or Okapi BM25 term weighting. No automated relevance feedback was performed on queries. In Table <ref type="table" coords="4,144.74,326.59,4.98,8.74" target="#tab_2">3</ref> we compare our performance using 4-stems and 5-stems to several reference conditions. These figures are all based on the withnew condition, the scenario where all words in the IR collection were transformed, and with TF/IDF weighting.</p><p>The 4-Stems do not score as high as the 5-Stems. The 5-Stems outperform the dummy condition and the gold standard analysis in two out of three languages. The Morfessor baseline roundly beats 5-Stems in Finnish and German, though the two methods are comparable in English. The results in Table <ref type="table" coords="4,127.95,398.32,3.87,8.74" target="#tab_1">2</ref>, using CLEF-2002 data (which was not used in MorphoChallenge 2007), also show little difference between the dummy condition (labeled 'words' in Table <ref type="table" coords="4,391.49,410.28,4.43,8.74" target="#tab_1">2</ref>) and n-gram morphemes. However, in Table <ref type="table" coords="4,171.43,422.23,3.87,8.74" target="#tab_1">2</ref>, the use of all n-grams that span a word yields sizable improvements. This is also the case on the test sets used in this year's competition.</p><p>In Table <ref type="table" coords="4,143.13,446.14,4.98,8.74">4</ref> we list results obtained using the JHU/APL HAIRCUT retrieval engine in the CLEF evaluations in 2003-2005. These runs also made use of relevance feedback, and are not directly comparable to the results in Table <ref type="table" coords="4,248.98,470.05,3.87,8.74" target="#tab_2">3</ref>. Nonetheless these figures suggest the use of all n-grams yields better performance compared to a single selected one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Summary</head><p>We set out to participate in the information retrieval evaluation, not the morphology induction task. Our method for producing morphemes is unorthodox, but we believe that it is suitable for use in information retrieval. We provided results based on our own information retrieval experiments that support this claim, and that offer a means to obtain improvement with n-grams without a run-time penalty. The technique is also well motivated when working in a language with no available morphological toolkit. The results from the Task 2 evaluation suggest that n-gram morphemes perform better than unnormalized words and similarly to the gold standard analysis, but not as well as the Morfessor algorithm.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,182.15,118.94,237.82,118.87"><head>Table 1 :</head><label>1</label><figDesc>Frequency of n-grams in jugglers and juggling</figDesc><table coords="3,189.66,140.57,223.69,97.24"><row><cell cols="4">n-gram df(jugglers) n-gram df(juggling)</cell></row><row><cell>#jug</cell><cell>681</cell><cell>#jug</cell><cell>681</cell></row><row><cell>jugg</cell><cell>495</cell><cell>jugg</cell><cell>495</cell></row><row><cell>uggl</cell><cell>6775</cell><cell>uggl</cell><cell>6775</cell></row><row><cell>ggle</cell><cell>5377</cell><cell>ggli</cell><cell>3003</cell></row><row><cell>gler</cell><cell>890</cell><cell>glin</cell><cell>4567</cell></row><row><cell>lers</cell><cell>9650</cell><cell>ling</cell><cell>55210</cell></row><row><cell>ers#</cell><cell>89701</cell><cell>ing#</cell><cell>106463</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,140.06,272.41,322.88,84.75"><head>Table 2 :</head><label>2</label><figDesc>Efficacy of N-gram Stemming and Full N-gram Indexing (CLEF)</figDesc><table coords="3,173.57,284.63,255.85,72.53"><row><cell></cell><cell>words 4-stems</cell><cell>4-grams</cell></row><row><cell>Bulgarian</cell><cell cols="2">0.2096 0.2583 (+23.2%) 0.2928 (+39.7%)</cell></row><row><cell>English</cell><cell>0.3897 0.3796 (-2.6%)</cell><cell>0.4099 (+5.2%)</cell></row><row><cell>Finnish</cell><cell cols="2">0.2278 0.2532 (+11.1%) 0.3754 (+64.8%)</cell></row><row><cell>German</cell><cell>0.3335 0.3404 (+2.1%)</cell><cell>0.3994 (+19.8%)</cell></row><row><cell cols="3">Hungarian 0.1983 0.2939 (+48.2%) 0.3568 (+80.0%)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,142.91,118.94,317.17,174.72"><head>Table 3 :</head><label>3</label><figDesc>Task 2 Results for N-gram Stemming and Reference Conditions</figDesc><table coords="4,155.33,130.61,292.35,163.05"><row><cell></cell><cell cols="3">English-05 Finnish-04 German-03</cell></row><row><cell cols="2">No Analysis (dummy) 0.2783</cell><cell>0.3496</cell><cell>0.3559</cell></row><row><cell>Porter Stemmer</cell><cell>0.3052</cell><cell>0.3725</cell><cell>0.3566</cell></row><row><cell>4-Stems</cell><cell>0.2838</cell><cell>0.3049</cell><cell>0.3257</cell></row><row><cell>5-Stems</cell><cell>0.2885</cell><cell>0.3327</cell><cell>0.3618</cell></row><row><cell>Baseline Morfessor</cell><cell>0.2863</cell><cell>0.3874</cell><cell>0.4105</cell></row><row><cell>Gold Standard</cell><cell>0.2602</cell><cell>0.3128</cell><cell>0.3734</cell></row><row><cell cols="4">Table 4: Results from Prior CLEF evaluations</cell></row><row><cell></cell><cell cols="3">English-05 Finnish-04 German-03</cell></row><row><cell cols="2">All 4-grams 0.3692</cell><cell>0.5064</cell><cell>0.5056</cell></row><row><cell cols="2">All 5-grams 0.3873</cell><cell>0.5236</cell><cell>0.4869</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,105.24,733.50,164.14,6.99"><p>The # symbol is used to denote whitespace.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,105.24,743.01,355.26,6.99"><p>See http://en.wikipedia.org/wiki/Johns Hopkins for an explanation of this unusual given name.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Program Listing</head><p>#! / u s r / b i n / p e r l # Take c o r p u s o f t r a i n i n g d a t a and an i n p u t w o r d l i s t , compute n-gram f r e q u e n c i e s , # and o u t p u t t r a n s f o r m e d w o r d l i s t t h a t r e d u c e wordforms t o t h e l e a s t f r e q u e n t n-gram . $ l i n e = $ ; chomp( $ l i n e ) ; $ l i n e =˜s /\d+\s +//; # remove l e a d i n g j u n k ( i . e . , t h e f r e q u e n c y ) , k e e p t h e word my $ o r i g w o r d = $ l i n e ; $ l i n e =˜s /\ s+/ / g ; # r e p l a c e s p a c e w i t h u n d e r s c o r e s $ l i n e = " " . $ l i n e . " " ; # s p l i t l i n e ( r e a l l y word ) i n t o n-grams my $ l e n l i m = length ( $ l i n e ) -$ n l e n + 1 ; my $ b e s t t o k = " " ; my $ l o w e s t f r e q = 1 0 0 0 0 0 0 0 0 ; f o r (my $ i =0; $ i &lt;$ l e n l i m ; $ i ++) { my $tok = substr ( $ l i n e , $ i , $ n l e n ) ; i f ( e x i s t s ( $ c n t { $tok } ) &amp;&amp; $ c n t { $tok } &lt; $ l o w e s t f r e q ) { $ b e s t t o k = $tok ; $ l o w e s t f r e q = $ c n t { $tok } ; } } i f ( $ b e s t t o k eq " " ) { # Word wasn ' t i n corpus , or was &lt; 2 c h a r s i n l e n g t h . Use t h e o r i g i n a l word . </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="4,105.50,674.30,407.51,8.74;4,105.50,686.25,211.31,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,186.15,674.30,326.86,8.74;4,105.50,686.25,27.50,8.74">Gauging simularity with n-grams: Language-independent categororization of text</title>
		<author>
			<persName coords=""><forename type="first">Marc</forename><surname>Damashek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,141.46,686.25,30.49,8.74">Science</title>
		<imprint>
			<biblScope unit="volume">267</biblScope>
			<biblScope unit="page" from="843" to="848" />
			<date type="published" when="1995-02-10">10 February 1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,705.10,407.50,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,266.21,705.10,102.56,8.74">Single n-gram stemming</title>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,389.27,705.10,25.85,8.74">SIGIR</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="415" to="416" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,723.94,407.51,8.74;4,105.50,735.89,190.22,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,273.91,723.94,239.10,8.74;4,105.50,735.89,55.43,8.74">Character N-gram tokenization for european language text retrieval</title>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,169.19,735.89,36.41,8.74">Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="73" to="97" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
