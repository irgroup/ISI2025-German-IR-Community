<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,100.29,148.62,402.57,15.51;1,179.49,170.53,244.05,15.51">Brown at CL-SR&apos;07: Retrieving Conversational Speech in English and Czech</title>
				<funder ref="#_nn27GVt">
					<orgName type="full">DARPA</orgName>
				</funder>
				<funder ref="#_mp8Rgfz">
					<orgName type="full">National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder ref="#_4agsHJz #_qMEDHeU #_RnYA4NC #_95J7RSm #_835vYE9 #_XVuc3zP #_3k59Cud #_bNh7PQb #_dUJXNuE #_pBCcSBM #_46M4gvC #_D925vQz #_wNZbw2r #_j6tBGBF #_mRqHduU #_db5JHYM #_J9W8TUc #_RkmBZ4y #_ratvxGy #_jZASwyr #_XDjASJn #_3GZp59K #_yTEUduQ #_FQaQqUK #_kx9gMKU #_nNeaZNc #_t2hYCF2 #_ftrPWkX #_hwq6yYd #_ku8kXgB #_ed6dHDU #_7QrPA8D #_YeJ9uj8 #_cM2eaaz #_vW68jbm #_SPrjvS8">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,219.40,204.00,66.33,9.96"><forename type="first">Matthew</forename><surname>Lease</surname></persName>
							<email>mlease@cs.brown.edu</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Brown Laboratory for Linguistic Information Processing (BLLIP)</orgName>
								<orgName type="institution">Brown University Providence</orgName>
								<address>
									<region>RI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,308.43,204.00,75.17,9.96"><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Brown Laboratory for Linguistic Information Processing (BLLIP)</orgName>
								<orgName type="institution">Brown University Providence</orgName>
								<address>
									<region>RI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,100.29,148.62,402.57,15.51;1,179.49,170.53,244.05,15.51">Brown at CL-SR&apos;07: Retrieving Conversational Speech in English and Czech</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CE53AA744CA8C702F60380EF66A55A14</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Brown's entry to the Cross-Language Speech Retrieval (CL-SR) track at the 2007 Cross Language Evaluation Forum (CLEF) 1 was based on the language model (LM) paradigm for retrieval <ref type="bibr" coords="1,215.64,336.63,14.61,9.96" target="#b16">[17]</ref>. For English, our system introduced two minor enhancements to the basic unigram: we extended Dirichlet smoothing (popular with unigram modeling) to bigrams, and we smoothed the collection LM to compensate for the small collection size. For Czech, time-constraints restricted us to using a basic unigram model, though we did apply Czech-specific stemming. While our English system performed well in the evaluation and showed the utility of our enhancements, several aspects of it were rushed and need to be addressed in future work. Our Czech system did not perform competitively but did provide us with a useful first experience in non-English retrieval.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Our participation in the Cross-Language Speech Retrieval (CL-SR) track at the 2007 Cross Language Evaluation Forum (CLEF) represents our group's first effort in developing and applying an information retrieval (IR) system for human language. Our over-arching interest in this area is focused on two directions for future investigation <ref type="bibr" coords="1,312.29,522.91,9.96,9.96" target="#b8">[9]</ref>: <ref type="bibr" coords="1,331.53,522.91,12.72,9.96" target="#b0">(1)</ref> deeper syntactic/semantic analysis of queries and documents and (2) giving greater attention to speech-specific phenomena present in spontaneous speech. The system we developed for this year's CL-SR evaluation does not present new research in these areas but was intended to provide us with initial experience in retrieving conversational speech data and developing a competitive baseline model supporting future work.</p><p>Our retrieval system is based on the language model (LM) paradigm for retrieval in which a document's relevance is estimated as the probability of observing the query string as a random sample from the document's underlying LM <ref type="bibr" coords="1,310.47,606.59,15.50,9.96" target="#b16">[17,</ref><ref type="bibr" coords="1,329.78,606.59,11.62,9.96" target="#b24">25]</ref>. The unigram LM approach has been shown to have a strong theoretical connection to TF-IDF <ref type="bibr" coords="1,354.41,618.55,15.50,9.96" target="#b25">[26]</ref> and perform comparably <ref type="bibr" coords="1,489.10,618.55,10.52,9.96" target="#b2">[3]</ref> to other state-of-the-art approaches like vector similarity with pivot length normalization <ref type="bibr" coords="1,480.47,630.50,15.50,9.96" target="#b21">[22,</ref><ref type="bibr" coords="1,500.28,630.50,12.73,9.96" target="#b20">21]</ref> and the "probabilistic" approach <ref type="bibr" coords="1,241.30,642.45,15.51,9.96" target="#b18">[19,</ref><ref type="bibr" coords="1,261.32,642.45,11.62,9.96" target="#b23">24]</ref>. In addition to re-implementing the basic Dirichletsmoothed unigram model, we also added two simple extensions. First, given the bag-of-words independence assumption underlying unigram and most other approaches to retrieval, modeling some notion of how words relate to one another seems like a useful step toward better modeling queries and documents. Previous work has shown that use of phrases yields around 10% relative improvement <ref type="bibr" coords="1,150.38,702.23,9.96,9.96" target="#b0">[1]</ref>. In the LM paradigm, use of phrases has been largely restricted to word pairs modeled via a unigram-bigram mixture model <ref type="bibr" coords="1,299.23,714.19,14.61,9.96" target="#b22">[23]</ref>. Whereas previous work has linearly mixed bigram and unigram models using a fixed mixture weight over all documents, subsequent work has shown Dirichlet smoothing to outperform linear interpolation for unigram modeling by varying the mixture weight per-document according to document length. We extended document-collection unigram Dirichlet smoothing to include bigram mixing as well, as described in §3.</p><p>The second extension we added was collection smoothing. In the LM paradigm, the document LM is initially estimated by maximum likelihood, meaning any query word not observed in the document is assigned zero probability. This is problematic because there are likely many words related to the document yet which do not appear in it due to its brevity (i.e. chance). Assigning zero probability to a single term would zero-out the probability assigned to the entire query string, which is likely to be a poor estimate of document relevance. Consequently, it is common practice to smooth a document's LM with the collection LM (as a prior) to make the LM more robust. However, the collection LM is also estimated by maximum likelihood and so may also suffer from sparse data problems in the case of small collections. To investigate whether collection smoothing could help, we tried mixing the collection with larger corpora, and results show that collection smoothing substantially improved performance ( §4).</p><p>Retrieval experiments were conducted in English and Czech (i.e. English queries/documents and Czech queries/documents), but due to time constraints we gave much less attention to Czech, evaluating only a unigram model without the above extensions. While our English system performed well in the evaluation, our Czech system was not competitive. §2 describes the data used in our experiments. In §3, system methodology is presented. Results are presented in §4, with additional details given in the appendix ( §7). Concluding remarks appear in §5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data</head><p>This section introduces the English and Czech data used in our retrieval experiments. Our description is brief since this data has been previously described in detail <ref type="bibr" coords="2,410.12,405.22,15.51,9.96" target="#b15">[16,</ref><ref type="bibr" coords="2,429.53,405.22,11.62,9.96" target="#b14">15]</ref>. In addition to providing some factoid information about the collection, we also offer a few off-the-cuff reflections on our impressions of the broader significance of this task/dataset for IR.</p><p>The collection consists of interviews conducted by the Survivors of the Shoah Visual History Foundation (VHF) to record the memories of Holocaust survivors, rescuers, and witnesses. In terms of information management, cultural heritage archives like this one can be expected to become more frequent as recording and storage technology continues to become ever more widely accessible. Such archives are also just the tip of the iceberg in terms of the sorts of spontaneous speech being increasingly archived: debates, meetings, classroom discussion, talk shows, telephone conversations, online chat, etc.. In regard to information retrieval, previous work has considered broadcast news in detail <ref type="bibr" coords="2,202.62,524.77,10.52,9.96" target="#b4">[5]</ref> while spontaneous speech has garnered far less attention. Spontaneous speech also displays strikingly different phenomena than found in broadcast news or text with potentially interesting consequences for retrieval methodology. Word error rate is higher, topic segmentation is more problematic (potentially involving speaker identification and conversation untangling <ref type="bibr" coords="2,168.50,572.60,10.29,9.96" target="#b1">[2]</ref>), and indexing and use of retrieved content is complicated by back-channels, disfluency (filled pauses, explicit editing terms, self interruptions and corrections, etc.), and dramatically different sentential structure as speakers trail off, interrupt one another, and compose their utterances on-the-fly.</p><p>Compared to modern-sized retrieval collections, the VHF data set is quite small: the English collection consists of just 8,104 manually segmented interview passages to rank. However, whereas the size of the early text collections like Cranfield was limited by cost and human effort, a cultural heritage archive like this one may in fact be naturally small: in the case of VHF, there are only a limited number of people alive today with first-hand experience of the Holocaust. As for other forms of archived spontaneous speech, a particular individual may be interviewed only so many times, a course or talk shows series eventually terminates, etc. As such, we may increasingly see a practical need for effective search techniques on smaller collections such as this one; optimal methods and parameters on a terabyte collection may not yield the best performance here. Of course, one may have a broad information need and not care about which archived talkshow contained the relevant information. With regard to this scenario, the VHF collection does for spontaneous speech what early collections did for text, and likely larger collections of spontaneous speech are on the horizon.</p><p>Topics used were written in usual TREC style with three fields of increasing length: title, description, and narrative. These topics were based on actual information requests received by VHF from interested parties. Manual transcriptions of the interviews were not available in English or Czech, unfortunately, making it difficult to evaluate the impact of recognition errors on retrieval accuracy. Several variant one-best ASR transcripts were available for comparison. Both interviewer and interviewee were recorded on the same microphone/channel; while dialogue from the interviewee certainly dominates the interview, interviewer questions and comments are seen mixed into the same transcript.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">English</head><p>Each segment contained a two to three sentence manual summary as well as a set of manually assigned keywords following a careful ontology developed by VHF. It is worth noting that these "manual" segments are far shorter than text and spoken documents commonly retrieved today; they are perhaps most akin to scientific paper abstracts in terms of previous retrieval experiments. Each interviewee also filled out a pre-interview questionnaire with some additional information that could also be used in the "manual" retrieval condition. The ontology developed by VHF could also be exploited for synonym expansion, etc. To date, the interview data and ontology have rarely been used <ref type="bibr" coords="3,191.94,348.91,14.61,9.96" target="#b14">[15]</ref>. For the "automatic" retrieval condition, two sets of automatically recognized keywords were available in addition to the ASR transcripts <ref type="bibr" coords="3,399.88,360.87,14.61,9.96" target="#b14">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Czech</head><p>Czech interviews were not manually segmented as with English. Instead, track organizers supplied a set of scripts allowing the interviews to be automatically segmented for a fixed duration and overlap size with neighboring segments. They also supplied one such "quickstart" segmentation generated by their scripts, which had 11,377 segments of three-minute passages in which the first and last minute overlapped the neighboring segments. The idea of the scripts was to allow participants to explore the effects of various segmentations on retrieval accuracy. Unfortunately, problems with the scripts were found during the evaluation and led the organizers to suggest teams use the quickstart segments and avoid use of the scripts.</p><p>No manual summary or keywords available were available for the interviews. There also were no automatically recognized keywords; those used in the 2006 evaluation were removed for 2007 due to an unspecified problem with them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method</head><p>As described in the introduction, our retrieval system was based on the language model (LM) paradigm for retrieval <ref type="bibr" coords="3,186.15,593.42,14.61,9.96" target="#b16">[17]</ref>. In this paradigm, one assumes a unique language model (LM) underlies each observed document and estimates document relevance by the probability of observing the query as a random sample generated by the document's underlying LM. Usually one assumes bagof-words independence similar to that employed with the probabilistic and vector-space models: the probability of a string of words is computed as the product of the individual word probabilities (i.e. a unigram model).</p><formula xml:id="formula_0" coords="3,250.78,667.14,262.22,20.73">P (Q|D) = w∈Q P (w|D)<label>(1)</label></formula><p>One challenge of the LM paradigm is estimating the parameters of the underlying LMs given the brevity of the observed documents; if one simply takes the maximum likelihood estimate (MLE), a single query term unobserved in the document would zero-out the entire probability of observing the query given the document, making the entire framework exceedingly fragile.</p><p>Instead one commonly employs smoothing to discount the probability mass assigned to observed terms and reserve some probability mass for all unseen terms. Previous work has shown Dirichlet smoothing of the form below to be most effective in practice <ref type="bibr" coords="4,356.14,123.31,14.61,9.96" target="#b25">[26]</ref>. This form of smoothing adds a hyper-parameter number of pseudo-counts distributed fractionally according to the prior collection model. N is the total number of words in the document.</p><formula xml:id="formula_1" coords="4,235.95,165.65,277.04,23.53">P (w|D) = C D (w) + µP (w|C) N + µ<label>(2)</label></formula><p>The LM approach has been shown to have a strong theoretical connection to TF-IDF <ref type="bibr" coords="4,477.40,199.59,15.48,9.96" target="#b25">[26]</ref> and perform comparably to vector similarity and probabilistic approaches in practice <ref type="bibr" coords="4,445.57,211.54,9.96,9.96" target="#b2">[3]</ref>. A potential advantage of the LM approach lies in the pre-existing theoretical foundation and set of proven estimation techniques developed by earlier work in speech recognition.</p><p>A well-known improvement to the basic unigram LM is to model word pairs in a unigrambigram mixture model <ref type="bibr" coords="4,194.73,259.37,14.62,9.96" target="#b22">[23]</ref>. While previous work linearly mixed bigram and unigram models using a fixed mixture weight over all documents, this misses the key idea of Dirichlet smoothing that longer documents provide more evidence for MLE and so should require less smoothing. For this reason, we extended document-collection unigram Dirichlet smoothing equation above to include bigram mixing. The Dirichlet smoothed bigram is given by:</p><formula xml:id="formula_2" coords="4,191.53,327.55,321.47,23.89">P (w i |w i-1 , D) = C D (w i-1 , w i ) + µ 1 P (w i |w i-1 , C) C D (w i-1 ) + µ 1<label>(3)</label></formula><p>and can be mixed with the unigram by adding an additional hyper-parameter, µ 2 .</p><formula xml:id="formula_3" coords="4,163.10,381.87,349.90,23.89">P (w i |w i-1 , D) = C D (w i-1 , w i ) + µ 1 P (w i |w i-1 , C) + µ 2 P (w|D) C D (w i-1 ) + µ 1 + µ 2<label>(4)</label></formula><p>This leaves three hyper-parameters for tuning: µ, µ 1 , and µ 2 .</p><p>Our second extension to the basic LM approach was to incorporate collection smoothing. While it is common practice to smooth a document's LM with the collection LM (as a prior) to make the LM more robust, as shown above, the collection LM is also estimated by maximum likelihood and so may also suffer from sparse data problems in the case of small collections. To investigate whether collections smoothing could help, we tried linearly mixing the collection with two larger text corpora: 40,000 sentences from the Wall Street Journal as found in the Penn Treebank <ref type="bibr" coords="4,494.74,487.54,14.61,9.96" target="#b10">[11]</ref>, and 450,000 sentences (with automatically induced sentence boundaries) taken from the North American News Corpus (NANC) <ref type="bibr" coords="4,232.73,511.45,9.96,9.96" target="#b5">[6]</ref>. This introduced three additional hyper-parameters specifying integer mixing ratios between the collection, WSJ, and NANC corpora.</p><p>The importance of sentence boundaries is that bigram statistics were not collected across them, which also differs from previous work. Phrase-based statistics can be expected to perform best when not collected or applied across sentential boundaries, especially as phrase length increases. This issue has largely been ignored in previous work since sentences tend to be rather long in text (maybe around 30 words in a typical newspaper), and so error introduced for short phrase statistics by approximating the entire document as a single sentence is somewhat limited. Our attention to sentence boundaries stems primarily from the fact that we are eventually interested in comparing the efficacy of bigrams with syntactic bi-lexical dependencies induced from sentences, effectively revisiting previous work <ref type="bibr" coords="4,197.97,631.00,10.52,9.96" target="#b3">[4,</ref><ref type="bibr" coords="4,211.94,631.00,12.73,9.96" target="#b9">10,</ref><ref type="bibr" coords="4,228.11,631.00,12.73,9.96" target="#b13">14]</ref> with a more accurate parser <ref type="bibr" coords="4,370.74,631.00,14.61,9.96" target="#b11">[12]</ref>. It is also worth noting that the manual summary sentences were quite short on average, suggesting their boundaries are more important to recognize in order to collect accurate phrasal statistics. Manual summaries were automatically segmented into sentences using Ratnaparkhi's tool <ref type="bibr" coords="4,376.14,666.86,14.61,9.96" target="#b17">[18]</ref>. Keywords, which could be phrasal, were already delimited in the distributed collection, and we treated each keyword phrase as its own sentence. Noting multiple spaces in the ASR transcripts appeared to correlate with sentential boundaries, we inferred these spaces corresponded to recognizer segments and used them as sentence boundaries (there is no evidence for our inference in the track's documentation). The resulting "sentences" are much longer than typical sentence-like units (SUs) found in conversational speech <ref type="bibr" coords="4,122.54,738.59,10.52,9.96" target="#b7">[8]</ref> and probably have reasonable precision but poor recall, though it is not possible to measure this without reference transcripts. As such, we used them as an expedient and left application of more accurate SU-boundary detection for future work <ref type="bibr" coords="5,391.31,123.31,9.96,9.96" target="#b6">[7]</ref>.</p><p>We also applied pseudo-relevance feedback and found it significantly improved our results. Experimental parameters included the number of documents to use for feedback, and a multiplicative scaler for the original query counts. We never performed more than one iteration of feedback, nor did we try restricting term harvesting to a subset of terms rather than the entire document. This feedback scheme was developed in a short amount of time and leaves much room for improvement.</p><p>As indicated in the introduction, time constraints caused us to give far less attention to Czech than to English. We did not model bigrams or perform collection smoothing, and we used as the off-the-shelf Indri system as our model (with one minor change to its parsing code to not split tokens on accented characters). Indri actually implements a multi-Bernoulli model rather than a true unigram model, but results are roughly comparable <ref type="bibr" coords="5,371.37,242.86,14.62,9.96" target="#b12">[13]</ref>. Anecdotally comparing our unigram to Indri for the English manual data on development set topics ( §4), we saw a similar trend previously reported in which the unigram model scored about a half point higher MAP <ref type="bibr" coords="5,479.96,266.77,14.62,9.96" target="#b12">[13]</ref>. In terms of stemming Czech, we evaluated use of off-the-shelf "light" and "aggressive" stemmers <ref type="bibr" coords="5,494.72,278.73,14.61,9.96" target="#b19">[20]</ref>. We also evaluated use of Indri's pseudo-relevance feedback mechanism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation</head><p>This section describes our evaluation on English and Czech, including evaluation framework, parameter settings, and results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">English</head><p>The same 63 training topics and 33 evaluation topics used in 2006 were used again in 2007. Relevance assessments for the test set were distributed to participants following the 2006 evaluation, so some participants may have run error analysis experiments on the test data then without realizing it would be reused this year. Since relevant assessments for all queries were available, 2007 track organizers clearly indicated which queries comprised the test set to help ensure no one accidentally tuned on it this year. In order to preserve the test set for future use, we have performed no error analysis of our results on it. While working on the development set, we found a small problem with the distributed relevance assessments (across all topics) that some documents marked as relevant were not actually in the distributed collection, but these cases were automatically filtered out without compromising the assessments.</p><p>For the "manual" case, we used the manual summaries and keywords; we made no use preinterview questionnaire information, or the VHF ontology. For "automatic" retrieval, we used the ASR2006B transcripts and both sets of automatic keywords. As with the manual case, we found use of the automatic keywords to improve retrieval, although we did not evaluate use of one set of keywords versus the other. We also did not evaluate other versions of the automatic transcripts, and this may be worth revisiting since some teams have reported better retrieval accuracy with the 2004 transcripts. Following previous work <ref type="bibr" coords="5,295.26,594.96,14.62,9.96" target="#b25">[26]</ref>, µ was fixed at 2000 for all runs, manual and automatic. In hindsight, it would have been interesting to explore alternative µ settings since the manual and automatic "documents" used here are rather different from one another, and both differ significantly from previous retrieval experiments which varied µ on text collections. For both manual and automatic runs, best performance was almost always seen with µ 1 set to 1, and so this parameter was also largely fixed. Additional detail on parameter settings used and corresponding results on the development set can be found in the appendix ( §7).</p><p>Results in Table <ref type="table" coords="5,178.64,678.65,4.98,9.96" target="#tab_0">1</ref> show performance of our five submitted runs on development and test sets; queries used were: title-only (T), title and description (TD), and title, description, and narrative (TDN). Representative strong results achieved the CL-SR tracks are also shown, though it should be noted that our results on the development set correspond to optimal tuning on those queries whereas the CL-SR'05 numbers do not. Retrieval accuracy was measured using mean-average  <ref type="bibr" coords="6,105.63,226.22,14.61,9.96" target="#b14">[15]</ref>. Statistical significance analysis between participant submissions is not possible here due to unavailability of participants' document rankings; refer to the CL-SR'07 track report for such analysis.</p><p>precision (MAP) as reported by the trec_eval tool version 8.1<ref type="foot" coords="6,366.62,281.18,3.97,4.77" target="#foot_1">2</ref> . After submitting our official runs, we discovered a system bug which caused some query topic fields to be prematurely truncated. The bug did not affect the development set but did affect the narrative field of three test queries. After fixing the bug, we re-ran our two submissions affected by it (one manual, one automatic). We then made our only use of the test set relevance assessments to evaluate the resulting retrieval accuracy with the bug fix. The difference was substantial, and results given in the body of Table <ref type="table" coords="6,240.96,353.69,4.98,9.96" target="#tab_0">1</ref> show system performance with the bug fix. Without the fix, Manual-TDN on the test set was .2577 and Auto-TDN was .0831.</p><p>Regarding the impact of our enhancements to the basic unigram (bigram mixing and collections smoothing), we refer the reader to results on the development set shown in the appendix ( §7). To broadly summarize, while the best unigram result was often not too far below the best bigram result, bigram results were more robust across parameter settings. Bigram statistics also appeared to have greater impact with pseudo-relevance feedback than without. As for collection smoothing, it clearly provided a substantial improvement. WSJ smoothing always helped, and NANC smoothing almost always helped, though less so in the case of pseudo-relevance feedback.</p><p>Overall, we are fairly pleased with our system's relative performance in the evaluation, but room is certainly left for improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Czech</head><p>Czech retrieval accuracy was measured using the mGAP metric and tool, which mapped retrieved segments to replay times <ref type="bibr" coords="6,198.43,531.48,14.62,9.96" target="#b14">[15]</ref>. We used the distributed quickstart segments and made no use of the segmentation scripts. 29 topics used for evaluation in 2006 comprised our development set. The evaluation was blind, with a test set of 42 topics. Results are given in Table <ref type="table" coords="6,418.40,555.38,3.87,9.96" target="#tab_1">2</ref>. Preliminary results for 2007 indicate our performance was relatively poor. While this is of course disappointing, it is not too surprising given our focus on developing a strong English baseline system. As for last year's scores, it is difficult to compare this year's results to them because they apparently suffered from a bug in the 2006 distributed quickstart segments. For the same topics, the absolute value of all teams' (preliminary) results this year far surpassed 2006 scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>Brown's participation in the Cross-Language Speech Retrieval (CL-SR) track at the 2007 Cross Language Evaluation Forum (CLEF) represented our group's first effort in developing and applying an information retrieval (IR) system for human language. Our goal was to develop a strong baseline system which we could build on and compare to in future research. Our English system applied a novel form of Dirichlet bigram smoothing and showed the importance of collection smoothing with a small collection. This system performed well, though we expect there is still room for improvement through more tuning of existing methodology. Our Czech system applied a simple unigram model under two forms of stemming and provided us with initial experience in non-English retrieval.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,90.00,110.28,423.00,125.90"><head>Table 1 :</head><label>1</label><figDesc>Collection Queries Dev MAP CL-SR'05 Test MAP CL-SR'06 CL-SR'07 Mean-average precision (MAP) retrieval accuracy of English submitted runs. CL-SR columns indicate representative strongs result achieved in that year's track on the same query set</figDesc><table coords="6,96.74,122.11,396.56,58.18"><row><cell>Manual</cell><cell>TDN</cell><cell>.3829</cell><cell>-</cell><cell>.2870</cell><cell>.2902</cell><cell>?</cell></row><row><cell></cell><cell>TD</cell><cell>.3443</cell><cell>.3129</cell><cell>.2366</cell><cell>.2710</cell><cell>?</cell></row><row><cell></cell><cell>T</cell><cell>.3161</cell><cell>-</cell><cell>.2348</cell><cell>.2489</cell><cell>?</cell></row><row><cell>Auto</cell><cell>TDN</cell><cell>.1623</cell><cell>.2176</cell><cell>.0910</cell><cell>.0768</cell><cell>?</cell></row><row><cell></cell><cell>TD</cell><cell>.1397</cell><cell>.1653</cell><cell>.0785</cell><cell>.0754</cell><cell>.0855</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,90.00,110.28,423.01,149.82"><head>Table 2 :</head><label>2</label><figDesc>Mean Generalized Average Precision (mGAP) retrieval accuracy on Czech for the development and test sets. All runs were on the quickstart ASR transcripts using TD queries. Runs using feedback comprised our official submissions. No statistical significance testing was performed. Preliminary results for 2007 indicate the top-performing TD run achieved .0228 mGAP.</figDesc><table coords="7,178.53,110.28,245.92,81.97"><row><cell cols="4">Stemmer Feedback Dev mGAP Test mGAP</cell></row><row><cell>none</cell><cell>no</cell><cell>.0134</cell><cell>-</cell></row><row><cell>aggressive</cell><cell></cell><cell>.0140</cell><cell>-</cell></row><row><cell>light</cell><cell></cell><cell>.0144</cell><cell>-</cell></row><row><cell>none</cell><cell>yes</cell><cell>.0135</cell><cell>.0052</cell></row><row><cell>aggressive</cell><cell></cell><cell>.0146</cell><cell>.0106</cell></row><row><cell>light</cell><cell></cell><cell>.0161</cell><cell>.0114</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,105.25,745.21,111.92,7.97"><p>http://www.clef-campaign.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="6,105.25,736.81,114.07,7.97"><p>http://trec.nist.gov/trec_eval</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="7,105.25,712.74,82.52,7.97"><p>http://ufal.mff.cuni.cz</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6">Acknowledgments</head><p>This work was initiated at the <rs type="institution">Institute of Formal and Applied Linguistics ( ÚFAL) 3 at Charles University in Prague</rs>, where the first author was graciously hosted for the first half of 2007. Support for this work was provided by <rs type="funder">NSF</rs> <rs type="grantName">PIRE</rs> Grant No <rs type="grantNumber">OISE-0530118</rs> and <rs type="funder">DARPA</rs> <rs type="projectName">GALE</rs> contract <rs type="grantNumber">HR0011-06-2-0001</rs>. Any opinions, findings, and conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the supporting agencies.</p></div>
			</div>
			<div type="funding">
<div><p><rs type="grantNumber">0</rs>.<rs type="grantNumber">1396 TDN.1.750</rs>.coll+akw-1.wsj-16.nanc<rs type="grantNumber">-0 0.1395 TDN.1</rs>.750.coll+akw-1.wsj-8.nanc-0 0.1393 TDN.1.750.coll+akw-1.wsj-8.nanc-1 0.1393 TDN.1.500.coll+akw-1.wsj-8.nanc-0 0.1393 TDN.1.1250.coll+akw-1.wsj-16.nanc-0 0.1392 TDN.1.1500.coll+akw-1.wsj-16.nanc-0 0.1391 TDN.1.1000.coll+akw-1.wsj-8.nanc-0 0.1391 TDN.1.1000.coll+akw-1.wsj-16.nanc-0 0.1390 TDN.1.1250.coll+akw-1.wsj-8.nanc-0 0.1389 TDN.1.750.coll+akw-1.wsj-4.nanc-1 ... 0.1240 TD.1.1500.coll+akw-2.wsj-1.nanc-1 0.1237 TD.1.1250.coll+akw-2.wsj-1.nanc-1 0.1232 TD.1.2000.coll+akw-1.wsj-1.nanc-1 0.1231 TD.1.1500.coll+akw-1.wsj-1.nanc-1 0.1231 TD.1.1250.coll+akw-1.wsj-2.nanc<rs type="grantNumber">-1 0</rs>.1230 TD.1.2000.coll+akw-1.wsj-2.nanc<rs type="grantNumber">-1 0</rs>.1230 TD.1.1250.coll+akw-1.wsj-1.nanc<rs type="grantNumber">-1 0</rs>.1229 TD.1.1500.coll+akw-1.wsj-2.nanc<rs type="grantNumber">-1 0.1229 TD.1</rs>.1000.coll+akw-1.wsj-4.nanc<rs type="grantNumber">-1 0.1229 TD.1</rs>.1000.coll+akw-1.wsj-2.nanc-1 ... 0.1103 T.1.5000.coll+akw-2.wsj-1.nanc<rs type="grantNumber">-1 0</rs>.1103 T.1.2000.coll+akw-2.wsj-1.nanc<rs type="grantNumber">-1 0.1102 T.1</rs>.5000.coll+akw-1.wsj-2.nanc<rs type="grantNumber">-1 0.1102 T.1</rs>.5000.coll+akw-1.wsj-1.nanc<rs type="grantNumber">-1 0.1099 T.1</rs>.5000.coll+akw-1.wsj-4.nanc<rs type="grantNumber">-1 0.1099 T.1</rs>.2000.coll+akw-1.wsj-4.nanc<rs type="grantNumber">-0 0.1099 T.1</rs>.1500.coll+akw-2.wsj-1.nanc<rs type="grantNumber">-1 0.1099 T.1</rs>.<rs type="grantNumber">10000</rs>.coll+akw-1.wsj-1.nanc<rs type="grantNumber">-1 0.1097 T.5.5000</rs>.coll+akw-2.wsj-1.nanc<rs type="grantNumber">-1 0.1097 T.1</rs>.2000.coll+akw-1.wsj-1.nanc<rs type="grantNumber">-1 0.1611 TDN.2000.10.20</rs>.coll<rs type="grantNumber">-akw-1</rs>.wsj-1.nanc-1 ... 0.1397 TD.<rs type="grantNumber">2000.10.20</rs>.coll<rs type="grantNumber">-akw-2</rs>.wsj-1.nanc<rs type="grantNumber">-1 0</rs>.<rs type="grantNumber">1396 TD.2000.10.20</rs>.coll<rs type="grantNumber">-akw-1</rs>.wsj-1.nanc<rs type="grantNumber">-1 0.1394 TD.2000.10.20</rs>.coll<rs type="grantNumber">-akw-1</rs>.wsj-8.nanc<rs type="grantNumber">-0 0.1394 TD.1250.10.20</rs>.coll<rs type="grantNumber">-akw-2</rs>.wsj-1.nanc<rs type="grantNumber">-1 0</rs>.1394 TD.<rs type="grantNumber">100000.15.20</rs>.coll<rs type="grantNumber">-akw-1</rs>.wsj-16.nanc<rs type="grantNumber">-1 0.1393 TD.2000.10.20</rs>.coll<rs type="grantNumber">-akw-1</rs>.wsj-2.nanc<rs type="grantNumber">-1 0</rs>.1393 TD.<rs type="grantNumber">1500.10.20</rs>.coll-akw-2.wsj-1.nanc-1 0.1393 TD.100000.15.20.coll-akw-1.wsj-16.nanc-0 0.1390 TD.1500.10.20.coll-akw-1.wsj-4.nanc-0 0.1389 TD.2000.10.20.coll-akw-4.wsj-1.nanc-1 ... 0.1242 T.100000.10.20.coll-akw-1.wsj-16.nanc-0 0.1240 T.2000.10.20.coll-akw-1.wsj-2.nanc-0 0.1240 T.2000.10.20.coll-akw-1.wsj-1.nanc-0 0.1237 T.100000.10.20.coll-akw-1.wsj-8.nanc-0 0.1236 T.2000.10.15.coll-akw-1.wsj-1.nanc-0 0.1235 T.1500.10.20.coll-akw-4.wsj-1.nanc-0 0.1234 T.2000.10.15.coll-akw-2.wsj-1.nanc-0 0.1233 T.2000.10.20.coll-akw-4.wsj-1.nanc-1 0.1233 T.1500.10.20.coll-akw-1.wsj-1.nanc-0 0.1233 T.100000.10.20.coll-akw-1.wsj-8.nanc-1</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_mp8Rgfz">
					<idno type="grant-number">OISE-0530118</idno>
					<orgName type="grant-name">PIRE</orgName>
				</org>
				<org type="funded-project" xml:id="_nn27GVt">
					<idno type="grant-number">HR0011-06-2-0001</idno>
					<orgName type="project" subtype="full">GALE</orgName>
				</org>
				<org type="funding" xml:id="_4agsHJz">
					<idno type="grant-number">0</idno>
				</org>
				<org type="funding" xml:id="_qMEDHeU">
					<idno type="grant-number">1396 TDN.1.750</idno>
				</org>
				<org type="funding" xml:id="_RnYA4NC">
					<idno type="grant-number">-0 0.1395 TDN.1</idno>
				</org>
				<org type="funding" xml:id="_95J7RSm">
					<idno type="grant-number">-1 0</idno>
				</org>
				<org type="funding" xml:id="_835vYE9">
					<idno type="grant-number">-1 0</idno>
				</org>
				<org type="funding" xml:id="_XVuc3zP">
					<idno type="grant-number">-1 0</idno>
				</org>
				<org type="funding" xml:id="_3k59Cud">
					<idno type="grant-number">-1 0.1229 TD.1</idno>
				</org>
				<org type="funding" xml:id="_bNh7PQb">
					<idno type="grant-number">-1 0.1229 TD.1</idno>
				</org>
				<org type="funding" xml:id="_dUJXNuE">
					<idno type="grant-number">-1 0</idno>
				</org>
				<org type="funding" xml:id="_pBCcSBM">
					<idno type="grant-number">-1 0.1102 T.1</idno>
				</org>
				<org type="funding" xml:id="_46M4gvC">
					<idno type="grant-number">-1 0.1102 T.1</idno>
				</org>
				<org type="funding" xml:id="_D925vQz">
					<idno type="grant-number">-1 0.1099 T.1</idno>
				</org>
				<org type="funding" xml:id="_wNZbw2r">
					<idno type="grant-number">-1 0.1099 T.1</idno>
				</org>
				<org type="funding" xml:id="_j6tBGBF">
					<idno type="grant-number">-0 0.1099 T.1</idno>
				</org>
				<org type="funding" xml:id="_mRqHduU">
					<idno type="grant-number">-1 0.1099 T.1</idno>
				</org>
				<org type="funding" xml:id="_db5JHYM">
					<idno type="grant-number">10000</idno>
				</org>
				<org type="funding" xml:id="_J9W8TUc">
					<idno type="grant-number">-1 0.1097 T.5.5000</idno>
				</org>
				<org type="funding" xml:id="_RkmBZ4y">
					<idno type="grant-number">-1 0.1097 T.1</idno>
				</org>
				<org type="funding" xml:id="_ratvxGy">
					<idno type="grant-number">-1 0.1611 TDN.2000.10.20</idno>
				</org>
				<org type="funding" xml:id="_jZASwyr">
					<idno type="grant-number">-akw-1</idno>
				</org>
				<org type="funding" xml:id="_XDjASJn">
					<idno type="grant-number">2000.10.20</idno>
				</org>
				<org type="funding" xml:id="_3GZp59K">
					<idno type="grant-number">-akw-2</idno>
				</org>
				<org type="funding" xml:id="_yTEUduQ">
					<idno type="grant-number">-1 0</idno>
				</org>
				<org type="funding" xml:id="_FQaQqUK">
					<idno type="grant-number">1396 TD.2000.10.20</idno>
				</org>
				<org type="funding" xml:id="_kx9gMKU">
					<idno type="grant-number">-akw-1</idno>
				</org>
				<org type="funding" xml:id="_nNeaZNc">
					<idno type="grant-number">-1 0.1394 TD.2000.10.20</idno>
				</org>
				<org type="funding" xml:id="_t2hYCF2">
					<idno type="grant-number">-akw-1</idno>
				</org>
				<org type="funding" xml:id="_ftrPWkX">
					<idno type="grant-number">-0 0.1394 TD.1250.10.20</idno>
				</org>
				<org type="funding" xml:id="_hwq6yYd">
					<idno type="grant-number">-akw-2</idno>
				</org>
				<org type="funding" xml:id="_ku8kXgB">
					<idno type="grant-number">-1 0</idno>
				</org>
				<org type="funding" xml:id="_ed6dHDU">
					<idno type="grant-number">100000.15.20</idno>
				</org>
				<org type="funding" xml:id="_7QrPA8D">
					<idno type="grant-number">-akw-1</idno>
				</org>
				<org type="funding" xml:id="_YeJ9uj8">
					<idno type="grant-number">-1 0.1393 TD.2000.10.20</idno>
				</org>
				<org type="funding" xml:id="_cM2eaaz">
					<idno type="grant-number">-akw-1</idno>
				</org>
				<org type="funding" xml:id="_vW68jbm">
					<idno type="grant-number">-1 0</idno>
				</org>
				<org type="funding" xml:id="_SPrjvS8">
					<idno type="grant-number">1500.10.20</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Appendix</head><p>This section provides some additional detail on English retrieval experiments, including parameter settings and results on the development set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Manual without pseudo-relevance feedback</head><p>MAP retrieval accuracy on development corpus for top 10 manual runs without pseudo-relevance feedback. µ 2 unigram weight was either 500 or 100000 (the latter effectively nullifying bigram statistics). Use of manual key words in addition to manual summaries was varied. Collection smoothing was varied between: none, WSJ, and WSJ+NANC (simple concatenation). Overall, use of manual keywords is seen to help though not dramatically. Collection smoothing, in contrast, appears to be much more important. 0.3369 TDN 500 with-manual-keywords.wsj+nanc 0.3312 TDN 500 wsj 0.3269 TDN 500 wsj+nanc 0.3260 TDN 500 with-manual-keywords.wsj 0.3236 TDN 100000 with-manual-keywords.wsj+nanc 0.3218 TDN 100000 wsj 0.3149 TDN 100000 with-manual-keywords.wsj 0.3116 TDN 100000 wsj+nanc 0.2967 TDN 500 no-collection-smoothing 0.2914 TDN 500 with-manual-keywords.no-collection-smoothing ... 0.3091 TD 500 with-manual-keywords.wsj+nanc 0.3058 TD 500 wsj 0.3033 TD 500 with-manual-keywords.wsj 0.3021 TD 100000 wsj 0.3016 TD 500 wsj+nanc 0.2992 TD 100000 with-manual-keywords.wsj+nanc 0.2965 TD 100000 with-manual-keywords.wsj 0.2945 TD 100000 wsj+nanc 0.2852 TD 500 with-manual-keywords.no-collection-smoothing 0.2825 TD 500 no-collection-smoothing ... 0.2721 T 500 with-manual-keywords.wsj+nanc 0.2716 T 100000 with-manual-keywords.wsj+nanc 0.2689 T 100000 wsj 0.2663 T 500 with-manual-keywords.wsj 0.2662 T 500 wsj+nanc 0.2661 T 100000 wsj+nanc 0.2656 T 500 wsj 0.2646 T 100000 with-manual-keywords.wsj 0.2611 T 500 no-collection-smoothing 0.2605 T 100000 no-collection-smoothing </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="7,110.48,488.40,402.53,9.96;7,110.48,500.35,315.25,9.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,191.08,488.40,237.39,9.96">Natural Language Processing in Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Thorsten</forename><surname>Brants</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,451.24,488.40,61.76,9.96;7,110.48,500.35,284.74,9.96">Proceedings of the 14th Meeting of Computational Linguistics in the Netherlands</title>
		<meeting>the 14th Meeting of Computational Linguistics in the Netherlands</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,520.28,402.53,9.96;7,110.47,532.23,402.53,9.96;7,110.47,544.19,328.29,9.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,497.65,520.28,15.36,9.96;7,110.47,532.23,301.95,9.96">Detecting conversing groups of chatters: a model, algorithms, and tests</title>
		<author>
			<persName coords=""><forename type="first">Seyit</forename><surname>Ahmet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>¸amtepe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><forename type="middle">K</forename><surname>Goldberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Malik</forename><surname>Magdon-Ismail</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mukkai</forename><surname>Krishn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,434.45,532.23,78.55,9.96;7,110.47,544.19,239.11,9.96">Proceedings of the IADIS International Conference on Applied Computing</title>
		<meeting>the IADIS International Conference on Applied Computing</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="89" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,564.12,402.52,9.96;7,110.47,576.07,402.53,9.96;7,110.48,588.02,307.30,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,306.54,564.12,206.47,9.96;7,110.47,576.07,14.21,9.96">A formal study of information retrieval heuristics</title>
		<author>
			<persName coords=""><forename type="first">Hui</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tao</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,145.44,576.07,367.57,9.96;7,110.48,588.02,219.29,9.96">SIGIR &apos;04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="49" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,607.95,402.61,9.96;7,110.48,619.91,402.52,9.96;7,110.48,631.86,365.26,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,390.99,607.95,122.10,9.96;7,110.48,619.91,104.65,9.96">Dependence language model for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Jianfeng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jian-Yun</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guangyuan</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guihong</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,237.26,619.91,275.74,9.96;7,110.48,631.86,267.29,9.96">Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 27th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="170" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,651.79,402.53,9.96;7,110.48,663.74,309.39,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,310.95,651.79,202.05,9.96;7,110.48,663.74,53.81,9.96">The trec spoken document retrieval track: A success story</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Garofolo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Auzanne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,185.16,663.74,203.40,9.96">the Ninth Text Retrieval Conference (TREC-9)</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,683.67,402.52,9.96;7,110.47,695.63,50.90,9.96" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="7,178.54,683.67,160.20,9.96;7,383.73,683.67,124.38,9.96">North American News Text Corpus</title>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Graff</surname></persName>
		</author>
		<idno>LDC95T21</idno>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
	<note>Linguistic Data Consortium</note>
</biblStruct>

<biblStruct coords="8,110.48,111.36,402.51,9.96;8,110.48,123.31,402.51,9.96;8,110.48,135.26,402.52,9.96" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="8,487.90,123.31,25.09,9.96;8,110.48,135.26,398.13,9.96">Johns Hopkins Summer Workshop Final Report on Parsing and Spoken Structural Event Detection</title>
		<author>
			<persName coords=""><forename type="first">Mary</forename><surname>Harper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Hale</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Brian</forename><surname>Roark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Izhak</forename><surname>Shafran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthew</forename><surname>Lease</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yang</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthew</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lisa</forename><surname>Yung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anna</forename><surname>Krasnyanskaya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robin</forename><surname>Stewart</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,155.19,257.79,9.96" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="8,138.70,155.19,221.82,9.96">Simple metadata annotation specification version 6</title>
		<author>
			<persName coords=""><surname>Ldc</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,175.11,402.51,9.96;8,110.48,187.07,402.54,9.96;8,110.48,199.02,196.61,9.96" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,181.09,175.11,327.68,9.96">Natural language processing for information retrieval: the time is ripe (again)</title>
		<author>
			<persName coords=""><forename type="first">Matthew</forename><surname>Lease</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,122.09,187.07,390.93,9.96;8,110.48,199.02,113.67,9.96">Proceedings of the 1st Ph.D. Workshop at the ACM Conference on Information and Knowledge Management (PIKM)</title>
		<meeting>the 1st Ph.D. Workshop at the ACM Conference on Information and Knowledge Management (PIKM)</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>To appear</note>
</biblStruct>

<biblStruct coords="8,110.48,218.95,402.59,9.96;8,110.48,230.90,340.72,9.96" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,367.46,218.95,145.61,9.96;8,110.48,230.90,188.36,9.96">Dependency structure applied to language modeling for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Changki</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gary</forename><forename type="middle">Geunbae</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Myung</forename><forename type="middle">Gil</forename><surname>Jang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,307.06,230.90,59.96,9.96">ETRI Journal</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="337" to="346" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,250.83,402.53,9.96;8,110.48,262.79,142.18,9.96" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,187.50,250.83,287.74,9.96">Building a large annotated corpus of English: The Penn Treebank</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Marcus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,484.49,250.83,28.52,9.96;8,110.48,262.79,45.60,9.96">Comp. Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,282.71,402.56,9.96;8,110.48,294.67,402.50,9.96;8,110.48,306.62,90.81,9.96" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,355.48,282.71,140.25,9.96">Effective self-training for parsing</title>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Mcclosky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,110.48,294.67,397.89,9.96">Proceedings of the Human Language Technology Conference of the NAACL, Main Conference</title>
		<meeting>the Human Language Technology Conference of the NAACL, Main Conference</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="152" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,326.55,402.53,9.96;8,110.48,338.50,402.53,9.96;8,110.48,350.46,380.03,9.96" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,353.58,326.55,159.43,9.96;8,110.48,338.50,78.96,9.96">Formal multiple-bernoulli models for language modeling</title>
		<author>
			<persName coords=""><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Victor</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,210.53,338.50,302.47,9.96;8,110.48,350.46,282.05,9.96">SIGIR &apos;04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="540" to="541" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,370.38,402.52,9.96;8,110.48,382.34,402.50,9.96;8,110.48,394.29,287.74,9.96" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,275.88,370.38,237.11,9.96;8,110.48,382.34,101.58,9.96">Capturing term dependencies using a language model based on sentence trees</title>
		<author>
			<persName coords=""><forename type="first">Ramesh</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,234.09,382.34,278.88,9.96;8,110.48,394.29,188.38,9.96">CIKM &apos;02: Proceedings of the eleventh international conference on Information and knowledge management</title>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="383" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,414.21,402.53,9.96;8,110.48,426.18,310.31,9.96" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,174.75,414.21,280.99,9.96">Overview of the CLEF-2006 cross-language speech retrieval track</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Oard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,475.94,414.21,37.07,9.96;8,110.48,426.18,279.22,9.96">Working Notes for the Cross Language Evaluation Forum 2006 Workshop</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,446.10,402.54,9.96;8,110.48,458.05,402.52,9.96;8,110.48,470.01,402.54,9.96;8,110.48,481.97,402.52,9.96;8,110.48,493.92,402.50,9.96;8,110.48,505.87,22.68,9.96" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="8,266.94,470.01,246.07,9.96;8,110.48,481.97,129.46,9.96">Building an information retrieval test collection for spontaneous conversational speech</title>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dagobert</forename><surname>Soergel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Doermann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaoli</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">Craig</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianqiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bhuvana</forename><surname>Ramabhadran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Samuel</forename><surname>Gustman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Liliya</forename><surname>Kharevych</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stephanie</forename><surname>Strassel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,263.50,481.97,249.49,9.96;8,110.48,493.92,340.53,9.96">SIGIR &apos;04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,525.80,402.53,9.96;8,110.48,537.76,402.51,9.96" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="8,268.96,525.80,240.20,9.96">A language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Jay</forename><forename type="middle">M</forename><surname>Ponte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,122.43,537.76,293.38,9.96">Proceedings of the 21st annual international ACM SIGIR conference</title>
		<meeting>the 21st annual international ACM SIGIR conference</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="275" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,557.68,402.52,9.96;8,110.48,569.64,402.53,9.96;8,110.48,581.59,116.98,9.96" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="8,313.83,557.68,199.17,9.96;8,110.48,569.64,85.43,9.96">A maximum entropy approach to identifying sentence boundaries</title>
		<author>
			<persName coords=""><forename type="first">Jeffrey</forename><forename type="middle">C</forename><surname>Reynar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adwait</forename><surname>Ratnaparkhi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,218.05,569.64,294.95,9.96;8,110.48,581.59,28.70,9.96">Proceedings of the fifth conference on Applied natural language processing</title>
		<meeting>the fifth conference on Applied natural language processing</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="16" to="19" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,601.51,402.54,9.96;8,110.48,613.47,307.75,9.96" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="8,307.00,601.51,202.14,9.96">Experimentation as a way of life: Okapi at trec</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beaulieu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,110.48,613.47,176.63,9.96">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="95" to="108" />
			<date type="published" when="2000-01">January 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,633.39,402.54,9.96;8,110.48,645.35,402.54,9.96;8,110.48,657.30,63.56,9.96" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="8,224.32,633.39,288.71,9.96;8,110.48,645.35,153.67,9.96">Unine at clef-2006: experiments with monolingual, bilingual and domain-specific and robust retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Abdou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,283.50,645.35,229.52,9.96;8,110.48,657.30,32.20,9.96">Proceedings of the Cross-Language Evaluation Forum (CLEF)</title>
		<meeting>the Cross-Language Evaluation Forum (CLEF)</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,677.23,402.53,9.96;8,110.48,689.18,221.86,9.96" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="8,172.97,677.23,199.43,9.96">Modern information retrieval: A brief overview</title>
		<author>
			<persName coords=""><forename type="first">Amit</forename><surname>Singhal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,379.67,677.23,133.35,9.96;8,110.48,689.18,30.54,9.96">Bulletin of the IEEE Computer Society</title>
		<imprint/>
		<respStmt>
			<orgName>Technical Committee on Data Engineering</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,709.11,402.50,9.96;8,110.48,721.07,399.11,9.96" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="8,335.52,709.11,172.99,9.96">Pivoted document length normalization</title>
		<author>
			<persName coords=""><forename type="first">Amit</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mandar</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,122.93,721.07,298.13,9.96">Proceedings of the 19th annual international ACM SIGIR conference</title>
		<meeting>the 19th annual international ACM SIGIR conference</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,111.36,402.52,9.96;9,110.47,123.31,402.50,9.96;9,110.47,135.26,132.61,9.96" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="9,248.91,111.36,222.62,9.96">A general language model for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Fei</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,493.89,111.36,19.11,9.96;9,110.47,123.31,402.50,9.96;9,110.47,135.26,32.99,9.96">Proceedings of the eighth international conference on Information and knowledge management (CIKM)</title>
		<meeting>the eighth international conference on Information and knowledge management (CIKM)</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="316" to="321" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,154.94,402.52,9.96;9,110.47,166.90,402.53,9.96;9,110.47,178.86,157.34,9.96" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="9,335.10,154.94,177.90,9.96;9,110.47,166.90,292.46,9.96">A probabilistic model of information retrieval: development and comparative experiments (parts i and ii)</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">Sparck</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,411.82,166.90,101.18,9.96;9,110.47,178.86,72.34,9.96">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="779" to="840" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,198.54,402.53,9.96;9,110.47,210.50,339.51,9.96" xml:id="b24">
	<monogr>
		<title level="m" type="main" coord="9,192.52,198.54,199.23,9.96">A brief review of information retrieval models</title>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>Department of Computer Science, University of Illinois at Urbana-Champaign</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="9,110.48,230.18,402.50,9.96;9,110.47,242.13,337.39,9.96" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="9,279.97,230.18,233.02,9.96;9,110.47,242.13,135.75,9.96">A study of smoothing methods for language models applied to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,254.46,242.13,97.04,9.96">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="214" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
