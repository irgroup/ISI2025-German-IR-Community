<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,113.52,148.63,376.16,15.51;1,183.72,170.59,235.71,15.51">Amharic-English Information Retrieval with Pseudo Relevance Feedback</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,253.44,203.97,96.23,9.96"><forename type="first">Atelach</forename><forename type="middle">Alemu</forename><surname>Argaw</surname></persName>
							<email>atelach@dsv.su.se</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and System Sciences</orgName>
								<orgName type="institution">Stockholm University/KTH</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,113.52,148.63,376.16,15.51;1,183.72,170.59,235.71,15.51">Amharic-English Information Retrieval with Pseudo Relevance Feedback</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C2C74F5F50037822FCF937568EE3B5B0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries Measurement, Performance, Experimentation Cross Language Information Retrieval, Amharic, Query Analysis</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe cross language retrieval experiments using Amharic queries and English language document collection from our participation in the bilingual ad hoc track at the CLEF 2007. Two monolingual and eight bilingual runs were submitted. The bilingual experiments designed varied in terms of usage of long and short queries, presence of pseudo relevance feedback (PRF), and three approaches (maximal expansion, first-translation-given, manual) for word sense disambiguation. We used an Amharic-English machine readable dictionary (MRD) and an online Amharic-English dictionary in order to do the lookup translation of query terms. In utilizing both resources, matching query term bigrams were always given precedence over unigrams. Out of dictionary Amharic query terms were taken to be possible named entities in the language, and further filtering was attained through restricted fuzzy matching based on edit distance. The fuzzy matching was performed for each of these terms against automatically extracted English proper names. The Lemur toolkit for language modeling and information retrieval was used for indexing and retrieval. Although the experiments are too limited to draw conclusions from, the obtained results indicate that longer queries tend to perform similar to short ones, PRF improves performance considerably, and that queries tend to fare better when we use the first translation given in the MRD rather than using maximal expansion of terms by taking all the translations given in the MRD.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Amharic is a Semitic language that is spoken in Ethiopia by an approximated 20-30 million people. It is a syllabic language, and uses a script which originated from the Ge'ez alphabet (the liturgical language of the Ethiopian Orthodox Church). The language has 33 basic characters with each having 7 forms for each consonant-vowel combination, and extra characters that are consonantvowel-vowel combinations for some of the basic consonants and vowels. It also has a unique set of punctuation marks and digits. Unlike other related Semitic languages such as Arabic, Hebrew or Syrian, Amharic is written from left to right. Amharic alphabets are one of a kind and unique to Ethiopia.</p><p>Manuscripts in Amharic are known from the 14th century and the language has been used as a general medium for literature, journalism, education, national business and cross-communication. A wide variety of literature including religious writings, fiction, poetry, plays, and magazines are available in the language.</p><p>Amharic has a complex but fairly structured morphological properties. To give some highlights: Amhaic has a rich verb morphology which is based on triconsonantal roots with vowel variants describing modifications to, or supplementary detail and variants of the root form. A significantly large part of the vocabulary consists of verbs, which exhibit different morphosyntactic properties based on the arrangement of the consonant-vowel patterns. Amharic nouns can be inflected for gender, number, definiteness, and case, although gender is usually neutral. Adjectives behave in the same way as nouns, taking similar inflections, while prepositions are mostly bound morphemes prefixed to nouns. The definite article in Amharic is also a bound morpheme, and attaches to the end of a noun.</p><p>The Amharic topic set for CLEF 2007 was constructed by manually translating the English topics by translators who are not involved in the retrieval tasks. The Amharic topic set which was written using the Ethiopic script (fidel ), the writing system for Amharic, was then transliterated to an ASCII representation.</p><p>The two monolingual English retrieval experiments were conducted for comparison purposes. One used short queries containing the title and description fields of the English topic sets, while the other used long queries that contained title, description, and narrative fields of the topics. Two of the eight bilingual retrieval experiments conducted used short Amharic queries while the remaining six used long ones. The experiments also differed from one another in terms of the WSD method used and the use of pseudo relevance feedback in order to expand query terms. For indexing and retrieval, the Lemur toolkit for language modeling and information retrieval<ref type="foot" coords="2,488.76,445.30,3.97,4.84" target="#foot_0">1</ref> was used.</p><p>The paper is organized as follows; Section 1 gives an introduction of the language under consideration and the overall experimental setup. Section 2 deals with the different steps taken in the query analysis. Section 3 describes how out of dictionary terms were handled, followed by approaches for word sense disambiguation in section 4. Section 5 discusses pseudo relevance feedback, and section 6 presents details about the designed experiments and the obtained results. These results are discussed and future directives are given in the last section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Query Analysis</head><p>The query analysis starts with transliterating the Amharic script into an ASCII format. Stemming of the terms was then performed in order to handle morphological variations and insure that we find matches with the citation forms in the dictionaries for as many of the query terms as possible. Term bigrams were then looked up in the dictionaries and stop words were removed from the remaining Amharic query words based on corpus statistics. Remaining unigrams were then looked up in the dictionaries, giving a list of translation equivalents in English and unmatched terms to be considered for fuzzy matching. English stop words were also removed after the lookup translation using a publicly available stop words list for English. Each of these processes are described in more detail in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Transliteration</head><p>The Amharic queries were written in fidel. For ease of use and compatibility purposes, the text was transliterated to an ASCII representation using SERA<ref type="foot" coords="3,349.08,140.86,3.97,4.84" target="#foot_1">2</ref> . The transliteration was done using a file conversion utility called g2<ref type="foot" coords="3,231.12,152.86,3.97,4.84" target="#foot_2">3</ref> which is available in the LibEth<ref type="foot" coords="3,377.76,152.86,3.97,4.84" target="#foot_3">4</ref> package.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Stemming</head><p>We used an in-house developed software for stemming the Amharic query terms. The stemmer is designed to reduce morphological variants of words to their citation forms as found in the MRD. It finds all possible segmentations of a given word according to inflectional morphological rules of the language. Derivational variants are not handled since they tend to have separate entries in dictionaries. The most likely segmentation for the words is then selected based on occurrence statistics in a list of citation forms compiled from three dictionaries (Amharic-English, Amharic-Amharic, Amahric-French) and a 3.1 million words Amharic news corpus. The process is to strip off allowed prefixes and suffixes and look up the remaining stem (or alternatively, some morphologically motivated variants of it) in the list of citation forms to verify that it is a possible segmentation. Stem length is also taken into consideration when further disambiguation is needed. In the cases where stems cannot be verified using the dictionary lists, frequency of occurrence in the news corpus is used to decide which segmentation to pick. See <ref type="bibr" coords="3,386.27,331.41,10.45,9.96" target="#b1">[2]</ref> for a detailed information about the stemming process.</p><p>Bigrams are handled in the same manner, but the segmentation works in such a way that prefixes are removed from the first word and suffixes from the second one only. Compound words in Amharic are usually written as two words, but there is no inflection present as the suffix of the first word and prefix of the second word in the bigram.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Lookup Translation</head><p>The query translation was done through term-lookup in an Amharic-English MRD <ref type="bibr" coords="3,467.05,437.49,10.57,9.96" target="#b0">[1]</ref> and an online dictionary<ref type="foot" coords="3,164.40,448.66,3.97,4.84" target="#foot_4">5</ref> . The machine readable dictionary contains 15,000 Amharic words and their corresponding English translations while the online dictionary contains about 18,000 entries. The lookup is done in such a way that the MRD translations are given precedence over the online dictionary translations, which are entered by users of the system and come with no guarantee as to their quality or correctness. Although this is the case, it should be noted that we have found the online dictionary to be quite useful and with good standard translations.</p><p>The lookup translation is done in the order that bigrams were looked up in the MRD, followed by bigram lookup in the online dictionary for those bigrams where no match is found in the MRD. In the next step, stop words were removed from the remaining terms (see following section) and unigrams were looked up in the MRD followed by a lookup of unigrams in the online dictionary if no match is found in the MRD. In all cases, when a match is found, all senses and synonyms of the term translations as given in the dictionaries were taken.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Stop Word Removal</head><p>Non content bearing words (stop words) were removed both before and after the lookup translation. First, all bigrams were extracted and looked up. The stop words were removed after excluding the bigrams for which matches were found in the dictionaries. This was done to ensure that we are not missing any possible bigrams due to removed stop words that are part of a meaningful unit. Before translation, Amharic stop words were removed based on global and local occurrence statistics. Each word's occurrence frequency was collected from the 3.1 million words news text, and words with frequencies above 5,000 were considered to be stop words and are removed from the terms list. The remaining words were further checked by looking at their occurrence frequency in the 50 queries used. If they occur more than 15 times, they were also removed. The later stop word removal handled non content bearing words that are present in queries such as 'find', 'document', 'relevant' etc, which tend to have low occurrence frequencies in the news corpus.</p><p>English stop words were removed after the lookup translation. We used an English stop words list that comes with the Lemur toolkit, which is also used during the indexing of the English document collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Fuzzy Matching for Out of Dictionary Terms</head><p>Amharic query terms that are most likely to be named entities were selected automatically for fuzzy matching. Such words are query words that are not removed as stop words but for which no bigram or unigram match is found in both dictionaries. The unsegmented word form was retained for fuzzy matching and very commonly occurring noun prefixes and suffixes are stripped off. Prefixes such as 'be','ye','ke', and 'le', were removed when they are attached preceding a word and suffixes 'oc', 'oc-n', 'oc-na', 'oc-n-na' when they appear as the word endings.</p><p>Automatically extracting named entities for Amharic is difficult compared to that of English. Proper names in Amharic scripts are not capitalized. The absence of syntactic analyzer, a list of named entities, or a manually tagged text also makes it difficult (or time consuming if the resources are to be constructed from scratch) to train or base automatic named entity extraction with. Hence, in these experiments we opted for making use of features in the target language. We implemented a very simple and straight forward proper name extraction utility for English. We made use of the English document collection to extract these proper names, which included names of persons, organizations, places, awards, historical events, etc that begin with capital letters in the English document collection. Proper names that appear at the beginning of a sentence were not extracted since the capitalization at the beginning of a sentence is not always indicative of a proper name. We ensure that there isn't much 'noise' by discarding all sentence beginning words and although we might be missing out on some proper names, our assumption is that, if they occur ones, they tend to reappear elsewhere in the same text.</p><p>The extracted English proper names were then used for the subsequent process of fuzzy matching. An edit distance based fuzzy matching was done for the Amharic out of dictionary query terms that were selected to be possible named entities. Restricting the fuzzy matching to the extracted English proper names only rather than the entire document collection is believed to increase precision of the matches, while it lowers recall. We further restricted the fuzzy matching to contain terms with very high similarity levels only by setting the maximum allowed edit distance to be 2. Amharic terms for which no fuzzy match is found were removed while the shortest edit distance or preferred match is taken to be the English equivalent proper name for those words for which matches are found through the fuzzy matching. The preferred match is the match for which a predefined character in the Amharic word as given by the transliteration system <ref type="bibr" coords="4,448.07,584.61,10.57,9.96" target="#b5">[6]</ref> corresponds to a specific one in English. For example the Amharic transliteration 'marc' would have a 0 edit distance with the English proper name 'Marc' since we use lower cases for the fuzzy matching. But the English word 'March' which has an edit distance of 1 with the Amharic word 'marc' would be preferred since the Amharic 'c' in SERA corresponds to the sound 'ch' in English.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Word Sense Disambiguation</head><p>During the lookup translation using both dictionaries, all the senses given in the dictionaries for each term's translation were taken. In such a case, where there is no sense disambiguation and every term is taken as a keyword, we consider the queries to be 'maximally expanded' with all available senses and synonyms. The sense disambiguation in this case is left to be implicitly handled by the retrieval process. Some of the experiments discussed in the section below used the 'maximally expanded' set of translated keywords. Another set of experiments made use of only the first translation given in the dictionaries. Such an approach is an attempt to a very simplified and 'blind' word sense disambiguation, with the assumption that the most common sense of a word tends to be first one on the list of possible translations given in dictionaries. A manual sense disambiguation was also done for comparative purposes, to determine the effect of optimal WSD in the case of MRD based CLIR. Two of the reported experiments made use of the manually disambiguated set of keywords .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Pseudo Relevance Feedback</head><p>Pseudo Relevance Feedback (PRF) is a method of automatic local analysis where retrieval performance is expected to improve through query expansion by adding terms from top ranking documents. An initial retrieval is conducted returning a set of documents. The top n retrieved documents from this set are then assumed to be the most relevant documents, and the query is reformulated by expanding it using words that are found to be of importance (high weights) in these documents. PRF has shown improved IR performance, but it should also be noted that there is a risk of query drift in applying PRF <ref type="bibr" coords="5,281.32,309.57,14.51,9.96" target="#b3">[4]</ref>. Four of the experiments used PRF by including the highest weight 20 terms from the top ranking 20 documents, with a positive coefficient<ref type="foot" coords="5,479.28,320.74,3.97,4.84" target="#foot_5">6</ref> of 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments and Results</head><p>For indexing and retrieval, the Lemur toolkit for language modeling and information retrieval was used. The selection of this tool was primarily to try out language modeling approaches in Amharic-English cross language IR. We found that it was difficult to find optimal settings for the required smoothing parameters in the time frame allocated for this project, hence we reverted to the vector space models. Stop words were removed, and the Porter stemmer was used for stemming during indexing. Both features are available through the toolkit.</p><p>In information retrieval overall performance is affected by a number of factors, implicitly and explicitly. To try and determine the effect of all factors and tune parameters universally is a very complicated task. In attempting to design a reasonably well tuned retrieval system for Amharic queries and English document collections, our efforts lie in optimizing available resources, using language specific heuristics, and performing univariate sensitivity tests aimed at optimizing a specific single parameter while keeping the others fixed at reasonable values. In these experiments, we tried to see the effects of short queries vs. long queries, the use of PRF, and the effect of taking the first translation given versus maximally expanding query terms with all translations given in dictionaries.</p><p>What we refer to as long queries consisted of the title, description, and narrative fields of the topics, while short queries consisted of title and description fields. In the long queries, we filtered out the irrelevant info from the narrative fields, using cue words for Amharic. Amharic has the property that the last word in any sentence is always a verb, and Amharic verbs have negation markers as bound morphemes that attach themselves as prefixes onto the verbs. This property of Amharic has helped us in automatically determining whether or not a sentence in the narrative field of the topics is relevant to the query. Some of the sentences in the narrative fields of the topics describe what shouldn't be included or is not relevant for the query at hand. If we include all the sentences in the narrative fields, such information could possibly hurt performance rather than boost it. Therefore we looked at the last word in each Amharic sentence in the narrative field and removed those that have ending verbs marked for negation. Examples of such words used include 'ayfelegum', 'aydelum', 'aynoracewm' representing negations of words like 'needed', 'necessary', etc. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Designed Experiments</head><p>The experiments designed are:</p><p>• Run 1: Maximally expanded long queries (Title + Description + Filtered Narrative) were used.</p><p>• Run 2: Maximally expanded long queries, supplemented by PRF.</p><p>• Run 3: Maximally expanded short queries (Title + Description) were used.</p><p>• Run 4: Maximally expanded short queries, supplemented by PRF.</p><p>• Run 5: Long queries with word sense disambiguation using the first-translation-given approach.</p><p>• Run 6: Long queries with word sense disambiguation using the first-translation-given approach, supplemented by PRF.</p><p>• Run 7: Long queries with manual word sense disambiguation.</p><p>• Run 8: Long queries with manual word sense disambiguation, supplemented by PRF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Results</head><p>The results obtained for the experiments discussed above are given in tables 1, 2 and 3. Table <ref type="table" coords="6,507.97,570.69,4.98,9.96" target="#tab_0">1</ref> presents precision values at different recall levels for the eight bilingual runs. Table <ref type="table" coords="6,454.35,582.69,4.98,9.96" target="#tab_1">2</ref> summarizes the results for these runs by presenting the number of relevant documents, the retrieved relevant documents, the non-interpolated average precision as well as the precision after R (where R is the number of relevant documents for each query) documents retrieved (R-Precision). Table <ref type="table" coords="6,483.24,618.57,4.98,9.96" target="#tab_2">3</ref> gives a summary similar to that of Table <ref type="table" coords="6,250.09,630.57,4.98,9.96" target="#tab_1">2</ref> for the monolingual English runs that were performed for comparison purposes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion and Future Directives</head><p>As can be seen in the results presented above, the best performance obtained was from the manually disambiguated word senses, followed by the first-translation-given approach, while the maximal expansion comes last. Long queries, that are believed to carry more information since they have a lot more keywords, were expected to perform much better than the shorter queries, but the results show that they have comparable performance. The automatic filtering of sentences Although that is the case, most of the additional information gained by using the long queries was a repetition to what is already been available in the short ones, except for a few additions. Using the narrative field also boosts negative impact through wrong segmentation and lookup. In depth analysis of a larger set of queries might shade some light into the positive and negative impact, although we believe that it still would be hard to draw conclusions from. The use of PRF in all cases showed a substantial increase in performance. Given that the original retrieval precision is very low, it is very encouraging to see that PRF helps in boosting performance even in such cases. We plan to further pursue using PRF, and tuning parameters pertaining to PRF.</p><p>Amharic terms that have no match in the dictionaries were assumed to be named entities. Since the amount of entries in the two dictionaries utilized is 15,000 and 18,000 with possible overlaps, all out of dictionary entries would not possibly be named entities. In order to handle this issue, the fuzzy matching is restricted to English proper names only and a very high similarity requirement was set for the fuzzy matching supplemented by language specific heuristics. We intend to investigate this further by looking at ways of bootstrapping a named entity recognizer for Amharic, especially following the approaches discussed for Arabic by <ref type="bibr" coords="7,400.70,554.49,9.91,9.96" target="#b4">[5]</ref>, as well as using a more sophisticated named entity recognizer for English to extract as many named entities as possible, rather than restrict it to proper names only.</p><p>The fact that manual WSD gave the best results and that blindly picking the first translation given has better performance than maximal MRD expansion of query terms motivates us to put more effort in investigating approaches to automatic WSD. Given the resource limitations, the best approach is most likely to use target language document collection and contextual collocation measures for sense disambiguation. We intend to investigate further approaches presented in <ref type="bibr" coords="7,502.45,638.13,10.57,9.96" target="#b2">[3]</ref> as well as experiment with a few more collocation measures.</p><p>Stemming plays a crucial role in MRD based CLIR since whether we would find the correct match in the dictionary depends on how well the stemmer does. We will pursue further attempts made so far to optimize the performance of the stemmer.</p><p>Although the results obtained are indicative of the facts presented above, the experiments are too limited to draw any conclusions. Large scale experiments using a larger set of queries and data set including those from previous years of CLEF ad hoc tasks will be designed in order to give the results more statistical significance. The relatively low precision levels are also issues we plan to investigate further by taking a closer look at the indexing and retrieval experiments.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,142.08,118.29,315.54,153.12"><head>Table 1 :</head><label>1</label><figDesc>Recall-Precision tables for the eight bilingual runs Recall Run 1 Run 2 Run 3 Run 4 Run 5 Run 6 Run 7 Run 8</figDesc><table coords="6,146.52,141.93,309.56,129.48"><row><cell>0.00</cell><cell cols="8">17.89 23.54 22.15 26.74 21.79 26.08 25.94 33.01</cell></row><row><cell>0.10</cell><cell cols="8">15.61 20.06 14.33 19.32 17.24 22.18 20.14 23.40</cell></row><row><cell>0.20</cell><cell cols="8">13.07 16.18 12.49 16.45 13.90 18.57 14.47 18.54</cell></row><row><cell>0.30</cell><cell cols="8">11.08 13.85 10.00 13.97 11.24 15.43 12.62 16.76</cell></row><row><cell>0.40</cell><cell>9.33</cell><cell>11.85</cell><cell>8.32</cell><cell>11.79</cell><cell>9.28</cell><cell cols="3">13.38 10.67 14.48</cell></row><row><cell>0.50</cell><cell>7.68</cell><cell>10.68</cell><cell>7.30</cell><cell>10.59</cell><cell>7.80</cell><cell>11.66</cell><cell>9.74</cell><cell>13.42</cell></row><row><cell>0.60</cell><cell>6.01</cell><cell>7.83</cell><cell>6.26</cell><cell>9.08</cell><cell>6.44</cell><cell>8.66</cell><cell>7.99</cell><cell>9.81</cell></row><row><cell>0.70</cell><cell>5.02</cell><cell>6.60</cell><cell>5.61</cell><cell>8.15</cell><cell>5.05</cell><cell>7.94</cell><cell>6.65</cell><cell>8.51</cell></row><row><cell>0.80</cell><cell>3.58</cell><cell>5.59</cell><cell>4.40</cell><cell>6.54</cell><cell>4.16</cell><cell>6.67</cell><cell>5.20</cell><cell>7.19</cell></row><row><cell>0.90</cell><cell>2.54</cell><cell>4.35</cell><cell>3.10</cell><cell>4.78</cell><cell>3.15</cell><cell>4.97</cell><cell>3.42</cell><cell>5.26</cell></row><row><cell>1.00</cell><cell>2.16</cell><cell>2.74</cell><cell>2.30</cell><cell>3.03</cell><cell>2.65</cell><cell>3.56</cell><cell>2.76</cell><cell>3.38</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,140.76,118.29,317.36,120.48"><head>Table 2 :</head><label>2</label><figDesc>Summary of results for the bilingual runs Relevant-tot Relevant-retrieved Avg Precision R-Precision</figDesc><table coords="7,140.76,142.29,303.90,96.48"><row><cell>Run 1</cell><cell>2247</cell><cell>880</cell><cell>7.77</cell><cell>8.78</cell></row><row><cell>Run 2</cell><cell>2247</cell><cell>951</cell><cell>10.5</cell><cell>10.44</cell></row><row><cell>Run 3</cell><cell>2247</cell><cell>873</cell><cell>7.71</cell><cell>8.21</cell></row><row><cell>Run 4</cell><cell>2247</cell><cell>943</cell><cell>10.97</cell><cell>10.57</cell></row><row><cell>Run 5</cell><cell>2247</cell><cell>868</cell><cell>8.29</cell><cell>10.17</cell></row><row><cell>Run 6</cell><cell>2247</cell><cell>1030</cell><cell>11.75</cell><cell>12.87</cell></row><row><cell>Run 7</cell><cell>2247</cell><cell>1002</cell><cell>9.75</cell><cell>10.85</cell></row><row><cell>Run 8</cell><cell>2247</cell><cell>1104</cell><cell>12.92</cell><cell>13.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,90.00,277.29,423.13,95.88"><head>Table 3 :</head><label>3</label><figDesc>Summary of results for the monolingual English runs</figDesc><table coords="7,140.76,289.27,317.36,34.34"><row><cell></cell><cell cols="4">Relevant-tot Relevant-retrieved Avg Precision R-Precision</cell></row><row><cell>Run 0</cell><cell>2247</cell><cell>1399</cell><cell>22.84</cell><cell>24.47</cell></row><row><cell>Run L</cell><cell>2247</cell><cell>1435</cell><cell>24.05</cell><cell>25.49</cell></row></table><note coords="7,90.00,363.21,423.13,9.96"><p>in the narrative fields for long queries performed very well, removing all non-relevant sentences.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,105.24,697.34,112.55,7.97"><p>http://www.lemurproject.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,105.24,706.10,415.06,7.97;3,90.00,715.58,30.79,7.97"><p>SERA stands for System for Ethiopic Representation in ASCII, http://www.abyssiniacybergateway.net/fidel/serafaq.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,101.04,724.13,3.65,4.16;3,105.24,725.06,399.60,7.97"><p>3 g2 was made available to us through Daniel Yacob of the Ge'ez Frontier Foundation (http://www.ethiopic.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="3,504.84,725.06,7.77,7.97;3,101.04,733.73,3.65,4.16;3,105.24,734.54,344.05,7.97"><p>/)<ref type="bibr" coords="3,101.04,733.73,3.65,4.16" target="#b3">4</ref> LibEth is a library for Ethiopic text processing written in ANSI C http://libeth.sourceforge.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="3,449.29,734.54,14.61,7.97;3,101.04,743.21,3.65,4.16;3,105.24,744.02,134.98,7.97"><p>net/ 5 http://www.amharicdictionary.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="5,105.24,718.10,238.62,7.97"><p>The coefficient for positive terms in (positive) Rocchio feedback.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,105.48,166.17,393.30,9.96" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="8,175.56,166.51,120.72,9.18">Amharic English Dictionary</title>
		<author>
			<persName coords=""><forename type="first">Amsalu</forename><surname>Aklilu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1981">1981</date>
			<publisher>Mega Publishing Enterprise</publisher>
			<pubPlace>Ethiopia</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.48,186.09,407.55,9.96;8,105.48,197.97,407.48,9.96;8,105.48,209.97,407.78,9.96;8,105.48,221.97,186.75,9.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,274.09,186.09,238.94,9.96;8,105.48,197.97,22.51,9.96">An amharic stemmer : Reducing words to their citation forms</title>
		<author>
			<persName coords=""><forename type="first">Atelach</forename><surname>Alemu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Argaw</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lars</forename><surname>Asker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,152.04,198.31,360.92,9.18;8,105.48,210.31,170.58,9.18">Proceedings of the 2007 Workshop on Computational Approaches to Semitic Languages: Common Issues and Resources</title>
		<meeting>the 2007 Workshop on Computational Approaches to Semitic Languages: Common Issues and Resources<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007-06">June 2007</date>
			<biblScope unit="page" from="104" to="110" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.48,241.89,407.68,9.96;8,105.48,253.77,407.60,9.96;8,105.48,265.77,407.70,9.96;8,105.48,277.65,407.76,9.96;8,105.48,289.65,65.67,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,105.48,253.77,234.50,9.96">Dictionary-based amharic-french information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Alemu</forename><surname>Atelach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lars</forename><surname>Argaw</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rickard</forename><surname>Asker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jussi</forename><surname>Cster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Magnus</forename><surname>Karlgren</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Sahlgren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="8,292.32,277.99,155.86,9.18">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Fredric</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Henning</forename><surname>Mller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Gareth</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Bernardo</forename><surname>Kluck</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Maarten</forename><surname>Magnini</surname></persName>
		</editor>
		<editor>
			<persName><surname>De Rijke</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">4022</biblScope>
			<biblScope unit="page" from="83" to="92" />
			<date type="published" when="2005">2005</date>
			<publisher>Springer</publisher>
		</imprint>
		<respStmt>
			<orgName>CLEF</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.48,309.57,407.37,9.96;8,105.48,321.57,217.22,9.96" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Prabhakar</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hinrich</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Schtze</surname></persName>
		</author>
		<title level="m" coord="8,405.84,309.91,107.01,9.18;8,105.48,321.91,57.91,9.18">Introduction to Information Retrieval</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.48,341.49,407.45,9.96;8,105.48,353.71,407.46,9.18;8,105.48,365.37,407.67,9.96;8,105.48,377.37,49.57,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,252.51,341.49,178.78,9.96">Person name entity recognition for arabic</title>
		<author>
			<persName coords=""><forename type="first">Khaled</forename><surname>Shaalan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hafsa</forename><surname>Raza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,451.79,341.83,61.14,9.18;8,105.48,353.71,407.46,9.18;8,105.48,365.71,40.62,9.18">Proceedings of the 2007 Workshop on Computational Approaches to Semitic Languages: Common Issues and Resources</title>
		<meeting>the 2007 Workshop on Computational Approaches to Semitic Languages: Common Issues and Resources<address><addrLine>Prague, Czech Republic</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2007-06">June 2007</date>
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.48,397.29,10.33,9.96;8,133.81,397.29,29.41,9.96;8,211.09,397.29,31.34,9.96;8,260.41,397.29,11.95,9.96;8,290.17,397.29,34.31,9.96;8,342.50,397.29,62.06,9.96;8,422.18,397.29,8.30,9.96;8,448.47,397.29,18.96,9.96;8,485.31,397.29,27.82,9.96;8,105.48,409.17,227.07,9.96" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="8,211.09,397.29,31.34,9.96;8,260.41,397.29,11.95,9.96;8,290.17,397.29,34.31,9.96;8,342.50,397.29,62.06,9.96;8,422.18,397.29,8.30,9.96;8,448.47,397.29,18.96,9.96;8,485.31,397.29,23.85,9.96">System for ethiopic representation in ascii (sera)</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Yacob</surname></persName>
		</author>
		<ptr target="http://www.abyssiniacybergateway.net/fidel/" />
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
