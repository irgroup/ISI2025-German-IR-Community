<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,155.09,146.21,292.81,18.08;1,143.51,168.13,315.97,18.08">Sampling Precision to Depth 10000: Evaluation Experiments at CLEF 2007</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2007-08-20">August 20, 2007</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,259.83,203.18,83.34,10.46"><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
							<email>stomlins@opentext.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Open Text Corporation Ottawa</orgName>
								<address>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,155.09,146.21,292.81,18.08;1,143.51,168.13,315.97,18.08">Sampling Precision to Depth 10000: Evaluation Experiments at CLEF 2007</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2007-08-20">August 20, 2007</date>
						</imprint>
					</monogr>
					<idno type="MD5">E8A379F547F05DB428CA89F89838CA45</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing; H.3.3 Information Search and Retrieval Measurement</term>
					<term>Performance</term>
					<term>Experimentation Bulgarian Retrieval</term>
					<term>Czech Retrieval</term>
					<term>Hungarian Retrieval</term>
					<term>Robust Retrieval</term>
					<term>Sampling</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe evaluation experiments conducted by submitting retrieval runs for the monolingual Bulgarian, Czech and Hungarian information retrieval tasks of the Ad-Hoc Track of the Cross-Language Evaluation Forum (CLEF) 2007. In the ad hoc retrieval tasks, the system was given 50 natural language queries, and the goal was to find all of the relevant documents (with high precision) in a particular document set. We conducted diagnostic experiments with different techniques for matching word variations and handling stopwords, comparing the performance on the robust Generalized Success@10 measure and the non-robust mean average precision measure. The measures generally agreed on the mean benefits of morphological techniques such as stemming, but generally disagreed on the blind feedback technique, though not all of the mean differences were statistically significant. Also, for each language, we submitted a sample of the first 10000 retrieved items to investigate the frequency of relevant items at deeper ranks than the official judging depth (of 60 for Czech and 80 for Bulgarian and Hungarian). The results suggest that, on average, the percentage of relevant items assessed was less than 60% for Czech, 70% for Bulgarian and 85% for Hungarian.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Livelink ECM -eDOCS SearchServer TM (formerly known as Hummingbird SearchServer TM ) is a toolkit for developing enterprise search and retrieval applications. The SearchServer kernel is also embedded in other components of the Livelink ECM -eDOCS Suite SearchServer works in Unicode internally <ref type="bibr" coords="2,292.67,216.28,10.51,10.46" target="#b3">[4]</ref> and supports most of the world's major character sets and languages. The major conferences in text retrieval experimentation (CLEF <ref type="bibr" coords="2,499.71,228.24,9.96,10.46" target="#b2">[3]</ref>,</p><p>NTCIR <ref type="bibr" coords="2,127.10,240.19,10.51,10.46" target="#b4">[5]</ref> and TREC <ref type="bibr" coords="2,195.14,240.19,10.79,10.46" target="#b7">[8]</ref>) have provided judged test collections for objective experimentation with SearchServer in more than a dozen languages.</p><p>This paper describes experimental work with SearchServer for the task of finding relevant documents for natural language queries in various European languages using the CLEF 2007 Ad-Hoc Track test collections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data</head><p>The CLEF 2007 Ad-Hoc Track document sets consisted of tagged (SGML-formatted) news articles in 3 different languages: Bulgarian, Czech and Hungarian. Table <ref type="table" coords="2,375.80,375.11,4.98,10.46" target="#tab_0">1</ref> gives the sizes.</p><p>The CLEF organizers created 50 natural language "topics" (numbered 401-450) and translated them into many languages. Sometimes topics are discarded for some languages because of a lack of relevant documents. Table <ref type="table" coords="2,209.08,410.98,4.98,10.46" target="#tab_0">1</ref> gives the final number of topics for each language and their average number of relevant documents (along with the lowest and highest number of relevant documents of any topic). For more information on the CLEF test collections, see the track overview paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Indexing</head><p>Our indexing approach was mostly the same as last year <ref type="bibr" coords="2,347.61,481.16,9.96,10.46" target="#b8">[9]</ref>. Accents were not indexed except for the combining breve in Bulgarian. The apostrophe was treated as a word separator for the investigated languages. The custom text reader, cTREC, was updated to maintain support for the CLEF guidelines of only indexing specifically tagged fields.</p><p>For some experiments, some stop words were excluded from indexing (e.g. words like "the", "by" and "of" in English). For these experiments, the stop word lists for Bulgarian, Czech and Hungarian were based on Savoy's lists <ref type="bibr" coords="2,259.31,552.89,9.96,10.46" target="#b6">[7]</ref>.</p><p>By default, the SearchServer index supports both exact matching (after some Unicode-based normalizations, such as decompositions and conversion to upper-case) and morphological matching (e.g. inflections, derivations and compounds, depending on the linguistic component used).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Searching</head><p>We experimented with the SearchServer CONTAINS predicate. Our test application specified SearchSQL to perform a boolean-OR of the query words. For example, for Czech topic 405 whose Title was "Astma u dětství" (Childhood Asthma), a corresponding SearchSQL query would be:</p><formula xml:id="formula_0" coords="2,90.00,682.85,230.11,46.32">SELECT RELEVANCE('2:4') AS REL, DOCNO FROM CLEF07CS WHERE FT_TEXT CONTAINS 'Astma'|'u'|'dětství' ORDER BY REL DESC;</formula><p>Most aspects of the SearchServer relevance value calculation are the same as described last year <ref type="bibr" coords="3,111.66,122.49,9.96,10.46" target="#b8">[9]</ref>. Briefly, SearchServer dampens the term frequency and adjusts for document length in a manner similar to Okapi <ref type="bibr" coords="3,198.04,134.45,10.51,10.46" target="#b5">[6]</ref> and dampens the inverse document frequency using an approximation of the logarithm. These calculations are based on the stems of the terms (roughly speaking) when doing morphological searching (i.e. when SET TERM_GENERATOR 'word!ftelp/inflect' was previously specified). The SearchServer RELEVANCE_METHOD setting was set to '2:4' and RELEVANCE_DLEN_IMP was set to 750 for all experiments in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Diagnostic Runs</head><p>For the diagnostic runs listed in Tables 2, the run names consist of a language code ("BG" for Bulgarian, "CS" for Czech and "HU" for Hungarian) followed by one of the following labels:</p><p>• "none": No linguistic variations from stemming were matched. Just the surface forms were searched on (after case-normalization).</p><p>• "stem": Same as "none" except that linguistic variations from stemming were matched. We thank Jacques Savoy for providing experimental algorithmic stemmers <ref type="bibr" coords="3,419.58,306.25,10.51,10.46" target="#b6">[7]</ref> for all 3 languages. For Czech, our port of the stemmer was accent-insensitive.</p><p>• "all": Same as "stem" except that a separate index was used which did not stop any words from being indexed.</p><p>• "4gram": Same as "all" except that the run used a different index which primarily consisted of the 4-grams of terms, e.g. the word 'search' would produce index terms of 'sear', 'earc' and 'arch'. No stemming was done; searching used the IS_ABOUT predicate (instead of the CONTAINS predicate) with morphological options disabled to search for the 4-grams of the query terms. For Bulgarian, we did not index the breve accent for the 4-gram runs (unlike 2 years ago <ref type="bibr" coords="3,167.00,429.78,14.76,10.46" target="#b11">[12]</ref>).</p><p>• "fuse": Fusion run based on adding together the rsv scores of the "stem" and "4gram" runs.</p><p>Note that all diagnostic runs just used the Title field of the topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Retrieval Measures</head><p>Traditionally, different retrieval measures have been used for "ad hoc" tasks, which seek relevant items for a topic, than for "known-item" tasks, which seek a particular known document. However, we argue that the known-item measures are not only applicable to ad hoc tasks, but that they are often preferable. For many ad hoc tasks, e.g. finding answer documents for questions, just one relevant item is needed. Also, the traditional ad hoc measures encourage retrieval of duplicate relevants, which does not correspond to user benefit. The traditional known-item measures are very coarse, e.g. Success@10 is 1 or 0 for each topic, while reciprocal rank cannot produce a value between 1.0 and 0.5. Two years ago, we began investigating a new measure, Generalized Success@10 (GS10) (introduced as "First Relevant Score" (FRS) in <ref type="bibr" coords="3,134.36,625.50,14.76,10.46" target="#b11">[12]</ref>), which is defined below. This investigation led to the discovery that the blind feedback technique (a commonly used technique at CLEF, NTCIR and TREC, but not known to be popular in real systems) had the downside of pushing down the first relevant item (on average), as has now been verified not just for our own blind feedback approach, but for the 7 blind feedback systems of the 2003 RIA Workshop <ref type="bibr" coords="3,310.31,673.32,15.49,10.46" target="#b9">[10]</ref> and for the Neuchâtel system using French data from CLEF <ref type="bibr" coords="3,166.76,685.28,9.96,10.46" target="#b0">[1]</ref>. <ref type="bibr" coords="3,184.98,685.28,10.51,10.46" target="#b1">[2]</ref> provides a theoretical explanation for why positive feedback approaches are detrimental to the rank of the first relevant item.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.1">Primary Recall Measures</head><p>"Primary recall" is retrieval of the first relevant item for a topic. Primary recall measures include the following:</p><p>• Generalized Success@30 (GS30): For a topic, GS30 is 1.024 1-r where r is the rank of the first row for which a desired page is found, or zero if a desired page was not found.</p><p>• Generalized Success@10 (GS10): For a topic, GS10 is 1.08 1-r where r is the rank of the first row for which a desired page is found, or zero if a desired page was not found.</p><p>• Success@n (S@n): For a topic, Success@n is 1 if a desired page is found in the first n rows, 0 otherwise. This paper lists Success@1 (S1) and Success@10 (S10) for all runs.</p><p>• Reciprocal Rank (RR): For a topic, RR is 1 r where r is the rank of the first row for which a desired page is found, or zero if a desired page was not found. "Mean Reciprocal Rank" (MRR) is the mean of the reciprocal ranks over all the topics.</p><p>Interpretation of Generalized Success@n: GS30 and GS10 are estimates of the percentage of potential result list reading the system saved the user to get to the first relevant item, assuming that users are less and less likely to continue reading as they get deeper into the result list.</p><p>Comparison of GS10 and Reciprocal Rank : Both GS10 and RR are 1.0 if a desired page is found at rank 1. At rank 2, GS10 is just 7 points lower (0.93), whereas RR is 50 points lower (0.50). At rank 3, GS10 is another 7 points lower (0.86), whereas RR is 17 points lower (0.33). At rank 10, GS10 is 0.50, whereas RR is 0.10. GS10 is greater than RR for ranks 2 to 52 and lower for ranks 53 and beyond.</p><p>Connection of GS10 to Success@10 : GS10 is considered a generalization of Success@10 because it rounds to 1 for r≤10 and to 0 for r&gt;10. (Similarly, GS30 is considered a generalization of Success@30 because it rounds to 1 for r≤30 and to 0 for r&gt;30.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.2">Secondary Recall Measures</head><p>"Secondary recall" is retrieval of the additional relevant items for a topic (after the first one). Secondary recall measures place most of their weight on these additional relevant items.</p><p>• Precision@n: For a topic, "precision" is the percentage of retrieved documents which are relevant. "Precision@n" is the precision after n documents have been retrieved. This paper lists Precision@10 (P10) for all runs.</p><p>• Average Precision (AP): For a topic, AP is the average of the precision after each relevant document is retrieved (using zero as the precision for relevant documents which are not retrieved). By convention, AP is based on the first 1000 retrieved documents for the topic. The score ranges from 0.0 (no relevants found) to 1.0 (all relevants found at the top of the list). "Mean Average Precision" (MAP) is the mean of the average precision scores over all of the topics (i.e. all topics are weighted equally).</p><p>• Geometric MAP (GMAP): GMAP (introduced in <ref type="bibr" coords="4,335.19,661.38,15.49,10.46" target="#b13">[14]</ref>) is based on "Log Average Precision" which for a topic is the natural log of the max of 0.00001 and the average precision. GMAP is the exponential of the mean log average precision. (We argue in <ref type="bibr" coords="4,410.69,685.29,15.49,10.46" target="#b9">[10]</ref> that primary recall measures better reflect robustness than GMAP.) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Statistical Significance Tables</head><p>For tables comparing 2 diagnostic runs (such as Table <ref type="table" coords="5,328.99,392.16,3.87,10.46" target="#tab_2">3</ref>), the columns are as follows:</p><p>• "Expt" specifies the experiment. The language code is given, followed by the labels of the 2 runs being compared. The difference is the first run minus the second run. For example, "BG-stem-none" specifies the difference of subtracting the scores of the Bulgarian 'none' run from the Bulgarian 'stem' run (of Table <ref type="table" coords="5,291.69,447.31,3.87,10.46" target="#tab_1">2</ref>).</p><p>• "∆GS10" is the difference of the mean GS10 scores of the two runs being compared (and "∆MAP" is the difference of the mean average precision scores).</p><p>• "95% Conf" is an approximate 95% confidence interval for the difference (calculated from plus/minus twice the standard error of the mean difference). If zero is not in the interval, the result is "statistically significant" (at the 5% level), i.e. the feature is unlikely to be of neutral impact (on average), though if the average difference is small (e.g. &lt;0.020) it may still be too minor to be considered "significant" in the magnitude sense.</p><p>• "vs." is the number of topics on which the first run scored higher, lower and tied (respectively) compared to the second run. These numbers should always add to the number of topics.</p><p>• "3 Extreme Diffs (Topic)" lists 3 of the individual topic differences, each followed by the topic number in brackets. The first difference is the largest one of any topic (based on the absolute value). The third difference is the largest difference in the other direction (so the first and third differences give the range of differences observed in this experiment). The middle difference is the largest of the remaining differences (based on the absolute value).</p><p>3 Results of Morphological Experiments</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Impact of Stemming</head><p>Table <ref type="table" coords="5,117.21,720.26,4.98,10.46" target="#tab_2">3</ref> shows the impact of stemming for the 3 languages. The mean increases in GenS@10 were statistically significant for Czech and Hungarian. For example, Table <ref type="table" coords="5,392.88,732.21,4.98,10.46" target="#tab_2">3</ref> shows that the biggest increase in GenS@10 for Czech was for topic 431 (Francouzští prezidenští kandidáti (French Presiden- tial Candidates)), for which the stemmer found apparently helpful matches such as Francouzský, francouzskou, francouzským and kandidátů. (However, we notice it did not match prezident nor prezidentem.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Impact of Indexing All Words</head><p>Table <ref type="table" coords="6,117.54,490.53,4.98,10.46" target="#tab_3">4</ref> shows the impact of not discarding stopwords at index time for all 3 languages. None of the mean differences in GenS@10 were statistically significant, and few of the topics were affected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Comparison to 4-grams</head><p>Table <ref type="table" coords="6,117.80,548.76,4.98,10.46" target="#tab_4">5</ref> compares the 4-gram results to stemming results for all 3 languages. None of the mean differences in GenS@10 were statistically significant, but there were large impacts on some topics in each direction. For example, for Czech topic 439 (Nehody v zaměstnání (Accidents at Work)), the 4-gram method found a relevant document with terms such as Zaměstnanci and zaměstnance that the stemmer apparently did not match. For Hungarian, the increase in mean average precision from using 4-grams was statistically significant, presumably because Hungarian has a lot of compound words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Submitted Runs</head><p>For each language, we submitted 4 experimental runs in May 2007 for official assessment. In the identifiers (e.g. "otBG07tde"), 't', 'd' and 'n' indicate that the Title, Description and Narrative field of the topic were used (respectively), and 'e' indicates that query expansion from blind feedback on the first 3 rows was used (weight of one-half on the original query, and one-sixth each on the 3 expanded rows). The 'z' code indicates that special sampling was done, as described below. From the Description and Narrative fields for most languages, instruction words such as "find", "relevant" and "document" were automatically removed (based on looking at some older topic lists, not this year's topics; this step was skipped for Czech because we did not have an old list of Czech topics). Details of the submitted approaches:</p><p>• "t": Just the Title field of the topic was used. Same as the "fuse" runs of Section 2.4, i.e. fusion of stemming and 4-gram runs.</p><p>• "td": Same as "t" except that the Description field was additionally used for both the stemming and 4-gram inputs.</p><p>• "tde": Same as "td" except that blind feedback (based on the first 3 rows of the "td" query) was used to expand the query. The feedback queries just used stemming, not 4-grams.</p><p>• "tdn": Same as "td" except that the Narrative field was additionally used for the stemming input (but the Narrative was still not used for the 4-gram input). (This run was not submitted.)</p><p>• "tdnz": Depth-10000 sampling run based on the "tdn" run as described below.</p><p>Table <ref type="table" coords="7,132.33,732.58,4.98,10.46">6</ref> lists the mean scores for the submitted runs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Impact of Blind Feedback</head><p>Table <ref type="table" coords="8,117.22,287.81,4.98,10.46" target="#tab_5">7</ref> shows the impact of blind feedback on the GenS@10 and MAP measures. The results are generally consistent with our past findings that blind feedback is detrimental to GenS@10 even when it boosts MAP, though the the mean differences for GenS@10 here were not statistically significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Depth-10000 Sampling</head><p>The submitted tdnz run for each language was actually a depth probe run from sampling the tdn run for the language (the tdn run was not itself submitted). The base tdn run was retrieved to depth 10000 for each topic. The first 100 rows of the submitted tdnz run contained the following rows of the base tdn run in the following order: 1, 2, ..., 10, 20, 30, ..., 100, 200, 300, ..., 1000, 2000, 3000, ..., 10000, 15, 25, ..., 95, 150, 250, ..., 950, 1500, 2500, ..., 9500, 125, 175, ..., 975, 1250, 1750, ..., 9750.</p><p>The remainder of the tdnz run was the leftover rows from the base tdn run until 1000 had been retrieved (rows 11, 12, 13, 14, 16, ..., 962).</p><p>This ordering (e.g. depth 10000 before depth 15) was chosen because of uncertainty of how deep the judging would be. As long as the top-37 were judged, we would have sampling to depth 10000. The extra sample points would just improve the accuracy. The tdnz run was given highest precedence for judging. It turned out the top-60 were judged for each topic for Czech, and the top-80 were judged for each topic for Bulgarian and Hungarian.</p><p>Tables 8, 9 and 10 show the results of the sampling for each language. The columns are as follows:</p><p>• "Depth Range": The range of depths being sampled. The 11 depth ranges cover from 1 to 10000.</p><p>• "Samples": The depths of the sample points from the depth range. The samples are always uniformly spaced. They always end at the last point of the depth range. The total number of sample points (over the 11 rows of the table) adds to 60 for Czech and 80 for Bulgarian and Hungarian. • "# Rel": The number of each type of item retrieved from the sample points over the 50 topics. The item type codes are R (relevant), N (non-relevant) and U (unjudged, of which there are always 0). The sum of the item type counts is always 50 times the number of sample points for the depth range (because there are 50 topics for each language).</p><p>• "Precision": Estimated precision of the depth range (R/(R+N+U)).</p><p>• "Wgt": The weight of each sample point. The weight is equal to the difference in ranks between sample points, i.e. each sample point can be thought of as representing this number of rows, which is itself plus the preceding unsampled rows. The weights are higher in some cases for Czech than for Bulgarian and Hungarian because we have fewer sample points for Czech (60 instead of 80).</p><p>• "EstRel/Topic": Estimated number of relevant items retrieved per topic for this depth range. This is the Precision multiplied by the size of the depth range. Or equivalently, it is (R * Wgt) / 50.</p><p>Because each sample point is at the deep end of the range of rows it represents, the sampling should tend to underestimate precision for each depth range (assuming that precision tends to fall with depth, which appears to be the case for all 3 languages).</p><p>Table <ref type="table" coords="9,132.85,732.21,9.96,10.46" target="#tab_9">11</ref> shows the sums of the estimated number of relevant items per topic over all depth ranges in its first row. The official number of relevant items per topic for each language is listed in the second row. The final row of the table just divides the official number of relevant items by the estimated number in the first 10000 retrieved (e.g. for Bulgarian, 20.2/29.3=69%). This number should tend to be an overestimate of the percentage of all relevant items that are judged (on average per topic) because there may be relevant items that were not matched by the query in the first 10000 rows. However, the sampling was very coarse at the deeper ranks, e.g. for Czech, 1 relevant item out of 300 samples in the 3001-6000 range led to an estimate of 10 relevant items per topic in this range. If the sampling had turned up 0 or 2 relevant items, a minor difference, the estimate would have been 0 or 20 relevant items per topic in this range, leading to a substantially different sum (17.4 or 37.4 instead of 27.4). We should compute confidence intervals for these estimates, but have not yet done so. Also, there is a lot of variance across topics, which we have not yet analyzed.</p><p>These preliminary estimates of judging coverage for the CLEF 2007 collections (55% for Czech, 69% for Bulgarian, 83% for Hungarian) are much higher than the estimates we produced for the TREC 2006 Legal and Terabyte collections using a similar approach (18% for TREC Legal and 36% for TREC Terabyte) <ref type="bibr" coords="10,205.76,580.95,14.61,10.46" target="#b10">[11]</ref>. They are similar to the estimates we produced for the NTCIR-6 collections (58% for Chinese, 78% for Japanese, 100% for Korean) <ref type="bibr" coords="10,380.92,592.90,14.61,10.46" target="#b12">[13]</ref>.</p><p>These incompleteness results are similar to what <ref type="bibr" coords="10,322.44,604.85,15.49,10.46" target="#b14">[15]</ref> found for depth-100 pooling on the old TREC collections of approximately 500,000 documents: "it is likely that at best 50%-70% of the relevant documents have been found; most of these unjudged relevant documents are for the 10 or so queries that already have the most known answers."</p><p>Fortunately, <ref type="bibr" coords="10,160.49,652.68,15.49,10.46" target="#b14">[15]</ref> also found for such test collections that "overall they do indeed lead to reliable results." (We can also confirm that we have gained a lot of insights from the CLEF test collections over the years, such as from the topic analyses in <ref type="bibr" coords="10,307.81,676.59,14.76,10.46" target="#b11">[12]</ref>.)</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="1,387.09,698.16,7.24,11.54"><head>Table 1 :</head><label>1</label><figDesc>1 . Sizes of CLEF 2007 Ad-Hoc Track Test Collections</figDesc><table coords="2,119.81,130.20,363.37,52.70"><row><cell>Language</cell><cell>Text Size (uncompressed)</cell><cell>Documents</cell><cell>Topics</cell><cell>Rel/Topic</cell></row><row><cell>Bulgarian</cell><cell>265,368,055 bytes</cell><cell>87,281</cell><cell>50</cell><cell>20 (lo 2, hi 62)</cell></row><row><cell>Czech</cell><cell>151,914,429 bytes</cell><cell>81,735</cell><cell>50</cell><cell>15 (lo 2, hi 47)</cell></row><row><cell>Hungarian</cell><cell>106,631,823 bytes</cell><cell>49,530</cell><cell>50</cell><cell>18 (lo 1, hi 66)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,108.86,117.46,382.30,223.60"><head>Table 2 :</head><label>2</label><figDesc>Mean Scores of Diagnostic Monolingual Ad Hoc Runs</figDesc><table coords="5,108.86,132.14,382.30,208.92"><row><cell>Run</cell><cell>GS30</cell><cell>GS10</cell><cell>S10</cell><cell>MRR</cell><cell>S1</cell><cell>P10</cell><cell cols="2">GMAP MAP</cell></row><row><cell>BG-4gram</cell><cell>0.863</cell><cell>0.739</cell><cell>38/50</cell><cell>0.526</cell><cell>20/50</cell><cell>0.354</cell><cell>0.164</cell><cell>0.282</cell></row><row><cell>BG-fuse</cell><cell>0.859</cell><cell>0.725</cell><cell>36/50</cell><cell>0.538</cell><cell>22/50</cell><cell>0.326</cell><cell>0.170</cell><cell>0.295</cell></row><row><cell>BG-stem</cell><cell>0.840</cell><cell>0.723</cell><cell>39/50</cell><cell>0.542</cell><cell>22/50</cell><cell>0.316</cell><cell>0.147</cell><cell>0.281</cell></row><row><cell>BG-all</cell><cell>0.837</cell><cell>0.716</cell><cell>38/50</cell><cell>0.521</cell><cell>20/50</cell><cell>0.312</cell><cell>0.146</cell><cell>0.282</cell></row><row><cell>BG-none</cell><cell>0.840</cell><cell>0.694</cell><cell>35/50</cell><cell>0.474</cell><cell>18/50</cell><cell>0.272</cell><cell>0.095</cell><cell>0.209</cell></row><row><cell>CS-all</cell><cell>0.907</cell><cell>0.826</cell><cell>44/50</cell><cell>0.631</cell><cell>25/50</cell><cell>0.294</cell><cell>0.135</cell><cell>0.288</cell></row><row><cell>CS-stem</cell><cell>0.905</cell><cell>0.823</cell><cell>44/50</cell><cell>0.633</cell><cell>25/50</cell><cell>0.294</cell><cell>0.135</cell><cell>0.289</cell></row><row><cell>CS-fuse</cell><cell>0.867</cell><cell>0.806</cell><cell>42/50</cell><cell>0.610</cell><cell>22/50</cell><cell>0.298</cell><cell>0.144</cell><cell>0.315</cell></row><row><cell>CS-4gram</cell><cell>0.846</cell><cell>0.790</cell><cell>42/50</cell><cell>0.625</cell><cell>25/50</cell><cell>0.312</cell><cell>0.123</cell><cell>0.310</cell></row><row><cell>CS-none</cell><cell>0.805</cell><cell>0.719</cell><cell>39/50</cell><cell>0.537</cell><cell>21/50</cell><cell>0.228</cell><cell>0.063</cell><cell>0.215</cell></row><row><cell>HU-fuse</cell><cell>0.895</cell><cell>0.833</cell><cell>44/50</cell><cell>0.652</cell><cell>26/50</cell><cell>0.358</cell><cell>0.158</cell><cell>0.329</cell></row><row><cell>HU-4gram</cell><cell>0.882</cell><cell>0.820</cell><cell>44/50</cell><cell>0.639</cell><cell>26/50</cell><cell>0.374</cell><cell>0.145</cell><cell>0.328</cell></row><row><cell>HU-all</cell><cell>0.868</cell><cell>0.803</cell><cell>42/50</cell><cell>0.608</cell><cell>23/50</cell><cell>0.300</cell><cell>0.103</cell><cell>0.263</cell></row><row><cell>HU-stem</cell><cell>0.866</cell><cell>0.801</cell><cell>42/50</cell><cell>0.608</cell><cell>23/50</cell><cell>0.300</cell><cell>0.103</cell><cell>0.263</cell></row><row><cell>HU-none</cell><cell>0.705</cell><cell>0.610</cell><cell>33/50</cell><cell>0.443</cell><cell>17/50</cell><cell>0.230</cell><cell>0.021</cell><cell>0.181</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,98.76,117.46,405.49,118.59"><head>Table 3 :</head><label>3</label><figDesc>Impact of Stemming on GenS@10 and Average Precision</figDesc><table coords="6,98.76,132.14,405.49,103.91"><row><cell>Expt</cell><cell>∆GS10</cell><cell>95% Conf</cell><cell>vs.</cell><cell>3 Extreme Diffs (Topic)</cell></row><row><cell>BG-stm-none</cell><cell>0.029</cell><cell>(-0.045, 0.103)</cell><cell>19-15-16</cell><cell>-0.71 (436), 0.66 (448), 0.66 (450)</cell></row><row><cell>CS-stm-none</cell><cell>0.105</cell><cell>( 0.032, 0.177)</cell><cell>21-10-19</cell><cell>0.87 (431), 0.77 (422), -0.50 (403)</cell></row><row><cell>HU-stm-none</cell><cell>0.191</cell><cell>( 0.088, 0.293)</cell><cell>22-10-18</cell><cell>1.00 (414), 1.00 (404), -0.20 (446)</cell></row><row><cell></cell><cell>∆MAP</cell><cell></cell><cell></cell><cell></cell></row><row><cell>BG-stm-none</cell><cell>0.072</cell><cell>( 0.021, 0.123)</cell><cell>31-19-0</cell><cell>0.93 (448), 0.52 (441), -0.15 (409)</cell></row><row><cell>CS-stm-none</cell><cell>0.074</cell><cell>( 0.034, 0.114)</cell><cell>38-11-1</cell><cell>0.39 (418), 0.35 (432), -0.30 (413)</cell></row><row><cell>HU-stm-none</cell><cell>0.083</cell><cell>( 0.027, 0.138)</cell><cell>35-15-0</cell><cell>0.79 (441), 0.75 (414), -0.27 (421)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,97.16,268.38,408.68,118.59"><head>Table 4 :</head><label>4</label><figDesc>Impact of Indexing All Words on GenS@10 and Average Precision</figDesc><table coords="6,97.16,283.06,408.68,103.91"><row><cell>Expt</cell><cell>∆GS10</cell><cell>95% Conf</cell><cell>vs.</cell><cell>3 Extreme Diffs (Topic)</cell></row><row><cell>BG-all-stm</cell><cell>-0.007</cell><cell>(-0.017, 0.003)</cell><cell>5-7-38</cell><cell>-0.18 (412), -0.07 (434), 0.07 (420)</cell></row><row><cell>CS-all-stm</cell><cell>0.002</cell><cell>(-0.004, 0.009)</cell><cell>2-1-47</cell><cell>0.10 (446), 0.09 (411), -0.07 (448)</cell></row><row><cell>HU-all-stm</cell><cell>0.002</cell><cell>(-0.009, 0.012)</cell><cell>2-1-47</cell><cell>0.21 (427), 0.00 (446), -0.12 (409)</cell></row><row><cell></cell><cell>∆MAP</cell><cell></cell><cell></cell><cell></cell></row><row><cell>BG-all-stm</cell><cell>0.001</cell><cell>(-0.002, 0.004)</cell><cell>20-18-12</cell><cell>-0.03 (444), 0.02 (434), 0.03 (420)</cell></row><row><cell>CS-all-stm</cell><cell>-0.002</cell><cell>(-0.006, 0.002)</cell><cell>3-3-44</cell><cell>-0.09 (442), -0.01 (448), 0.01 (411)</cell></row><row><cell>HU-all-stm</cell><cell>-0.001</cell><cell>(-0.003, 0.001)</cell><cell>8-6-36</cell><cell>-0.03 (409), -0.01 (421), 0.00 (413)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,98.28,117.46,406.44,374.52"><head>Table 5 :</head><label>5</label><figDesc>4-grams vs. Stems in GenS@10 and Average Precision</figDesc><table coords="7,98.28,132.14,406.44,359.84"><row><cell>Expt</cell><cell>∆GS10</cell><cell cols="2">95% Conf</cell><cell>vs.</cell><cell></cell><cell cols="3">3 Extreme Diffs (Topic)</cell></row><row><cell>BG-4gr-all</cell><cell>0.023</cell><cell cols="2">(-0.050, 0.095)</cell><cell>17-16-17</cell><cell cols="4">0.97 (414), 0.86 (415), -0.54 (411)</cell></row><row><cell>CS-4gr-all</cell><cell>-0.036</cell><cell cols="2">(-0.104, 0.032)</cell><cell>12-16-22</cell><cell cols="4">1.00 (439), -0.50 (409), -0.57 (429)</cell></row><row><cell>HU-4gr-all</cell><cell>0.018</cell><cell cols="2">(-0.055, 0.090)</cell><cell>14-14-22</cell><cell cols="4">1.00 (424), 0.63 (446), -0.94 (403)</cell></row><row><cell></cell><cell>∆MAP</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>BG-4gr-all</cell><cell>0.001</cell><cell cols="2">(-0.044, 0.045)</cell><cell>26-24-0</cell><cell cols="4">-0.61 (445), 0.37 (417), 0.51 (414)</cell></row><row><cell>CS-4gr-all</cell><cell>0.022</cell><cell cols="2">(-0.015, 0.060)</cell><cell>29-20-1</cell><cell cols="4">0.40 (441), 0.37 (431), -0.34 (405)</cell></row><row><cell>HU-4gr-all</cell><cell>0.065</cell><cell cols="2">( 0.019, 0.112)</cell><cell>35-15-0</cell><cell cols="4">0.66 (408), 0.49 (424), -0.22 (412)</cell></row><row><cell></cell><cell cols="7">Table 6: Mean Scores of Submitted Monolingual Ad Hoc Runs</cell><cell></cell></row><row><cell>Run</cell><cell>GS30</cell><cell>GS10</cell><cell>S10</cell><cell>MRR</cell><cell>S1</cell><cell>P10</cell><cell cols="2">GMAP MAP</cell></row><row><cell>otBG07t</cell><cell>0.859</cell><cell>0.725</cell><cell>36/50</cell><cell>0.538</cell><cell>22/50</cell><cell>0.326</cell><cell>0.170</cell><cell>0.295</cell></row><row><cell>otBG07td</cell><cell>0.928</cell><cell>0.843</cell><cell>46/50</cell><cell>0.677</cell><cell>30/50</cell><cell>0.378</cell><cell>0.238</cell><cell>0.331</cell></row><row><cell>otBG07tde</cell><cell>0.921</cell><cell>0.833</cell><cell>44/50</cell><cell>0.642</cell><cell>27/50</cell><cell>0.386</cell><cell>0.240</cell><cell>0.350</cell></row><row><cell>(otBG07tdn)</cell><cell>0.937</cell><cell>0.858</cell><cell>46/50</cell><cell>0.680</cell><cell>29/50</cell><cell>0.398</cell><cell>0.257</cell><cell>0.351</cell></row><row><cell>otBG07tdnz</cell><cell>0.917</cell><cell>0.850</cell><cell>46/50</cell><cell>0.679</cell><cell>29/50</cell><cell>0.398</cell><cell>0.170</cell><cell>0.253</cell></row><row><cell>otCS07t</cell><cell>0.867</cell><cell>0.806</cell><cell>42/50</cell><cell>0.610</cell><cell>22/50</cell><cell>0.298</cell><cell>0.144</cell><cell>0.315</cell></row><row><cell>otCS07td</cell><cell>0.906</cell><cell>0.816</cell><cell>43/50</cell><cell>0.594</cell><cell>22/50</cell><cell>0.338</cell><cell>0.197</cell><cell>0.327</cell></row><row><cell>otCS07tde</cell><cell>0.894</cell><cell>0.805</cell><cell>43/50</cell><cell>0.623</cell><cell>25/50</cell><cell>0.356</cell><cell>0.191</cell><cell>0.348</cell></row><row><cell>(otCS07tdn)</cell><cell>0.908</cell><cell>0.823</cell><cell>43/50</cell><cell>0.589</cell><cell>20/50</cell><cell>0.362</cell><cell>0.217</cell><cell>0.344</cell></row><row><cell>otCS07tdnz</cell><cell>0.881</cell><cell>0.813</cell><cell>43/50</cell><cell>0.587</cell><cell>20/50</cell><cell>0.362</cell><cell>0.153</cell><cell>0.266</cell></row><row><cell>otHU07t</cell><cell>0.895</cell><cell>0.833</cell><cell>44/50</cell><cell>0.652</cell><cell>26/50</cell><cell>0.358</cell><cell>0.158</cell><cell>0.329</cell></row><row><cell>otHU07td</cell><cell>0.925</cell><cell>0.869</cell><cell>45/50</cell><cell>0.688</cell><cell>27/50</cell><cell>0.428</cell><cell>0.244</cell><cell>0.385</cell></row><row><cell>otHU07tde</cell><cell>0.932</cell><cell>0.871</cell><cell>45/50</cell><cell>0.719</cell><cell>30/50</cell><cell>0.466</cell><cell>0.288</cell><cell>0.433</cell></row><row><cell>(otHU07tdn)</cell><cell>0.939</cell><cell>0.887</cell><cell>47/50</cell><cell>0.712</cell><cell>29/50</cell><cell>0.444</cell><cell>0.281</cell><cell>0.411</cell></row><row><cell>otHU07tdnz</cell><cell>0.928</cell><cell>0.879</cell><cell>47/50</cell><cell>0.710</cell><cell>29/50</cell><cell>0.444</cell><cell>0.208</cell><cell>0.305</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,98.85,117.46,405.31,118.59"><head>Table 7 :</head><label>7</label><figDesc>Impact of Blind Feedback on GenS@10 and Average Precision</figDesc><table coords="8,98.85,132.14,405.31,103.91"><row><cell>Expt</cell><cell>∆GS10</cell><cell>95% Conf</cell><cell>vs.</cell><cell>3 Extreme Diffs (Topic)</cell></row><row><cell>BG-tde-td</cell><cell>-0.010</cell><cell>(-0.054, 0.034)</cell><cell>7-13-30</cell><cell>0.59 (407), 0.41 (411), -0.49 (428)</cell></row><row><cell>CS-tde-td</cell><cell>-0.011</cell><cell>(-0.045, 0.024)</cell><cell>13-13-24</cell><cell>-0.45 (428), -0.33 (430), 0.26 (409)</cell></row><row><cell>HU-tde-td</cell><cell>0.001</cell><cell>(-0.024, 0.027)</cell><cell>10-10-30</cell><cell>0.38 (426), -0.16 (417), -0.33 (446)</cell></row><row><cell></cell><cell>∆MAP</cell><cell></cell><cell></cell><cell></cell></row><row><cell>BG-tde-td</cell><cell>0.019</cell><cell>(-0.009, 0.047)</cell><cell>28-22-0</cell><cell>0.33 (445), 0.20 (415), -0.16 (405)</cell></row><row><cell>CS-tde-td</cell><cell>0.022</cell><cell>(-0.007, 0.051)</cell><cell>26-24-0</cell><cell>0.53 (433), 0.28 (431), -0.15 (441)</cell></row><row><cell>HU-tde-td</cell><cell>0.049</cell><cell>( 0.020, 0.077)</cell><cell>32-17-1</cell><cell>0.36 (408), 0.27 (431), -0.17 (445)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="9,99.59,117.46,403.83,163.03"><head>Table 8 :</head><label>8</label><figDesc>Marginal Precision of Bulgarian Base-TDN Run at Various Depths</figDesc><table coords="9,99.59,132.14,403.83,148.35"><row><cell>Depth Range</cell><cell>Samples</cell><cell># Rel</cell><cell cols="3">Precision Wgt EstRel/Topic</cell></row><row><cell>1-5</cell><cell>1, 2, ..., 5</cell><cell>107R, 143N, 0U</cell><cell>0.428</cell><cell>1</cell><cell>2.1</cell></row><row><cell>6-10</cell><cell>6, 7, ..., 10</cell><cell>92R, 158N, 0U</cell><cell>0.368</cell><cell>1</cell><cell>1.8</cell></row><row><cell>11-50</cell><cell>15, 20, ..., 50</cell><cell>70R, 330N, 0U</cell><cell>0.175</cell><cell>5</cell><cell>7.0</cell></row><row><cell>51-100</cell><cell>55, 60, ..., 100</cell><cell>28R, 472N, 0U</cell><cell>0.056</cell><cell>5</cell><cell>2.8</cell></row><row><cell>101-200</cell><cell>125, 150, ..., 200</cell><cell>5R, 195N, 0U</cell><cell>0.025</cell><cell>25</cell><cell>2.5</cell></row><row><cell>201-500</cell><cell>225, 250, ..., 500</cell><cell>2R, 598N, 0U</cell><cell>0.003</cell><cell>25</cell><cell>1.0</cell></row><row><cell>501-900</cell><cell>525, 550, ..., 900</cell><cell>2R, 798N, 0U</cell><cell>0.003</cell><cell>25</cell><cell>1.0</cell></row><row><cell>901-1000</cell><cell>950, 1000</cell><cell>1R, 99N, 0U</cell><cell>0.010</cell><cell>50</cell><cell>1.0</cell></row><row><cell>1001-3000</cell><cell>1500, 2000, ..., 3000</cell><cell>1R, 199N, 0U</cell><cell>0.005</cell><cell>500</cell><cell>10.0</cell></row><row><cell>3001-6000</cell><cell>3500, 4000, ..., 6000</cell><cell>0R, 300N, 0U</cell><cell>0.000</cell><cell>500</cell><cell>0.0</cell></row><row><cell>6001-10000</cell><cell>6500, 7000, ..., 10000</cell><cell>0R, 400N, 0U</cell><cell>0.000</cell><cell>500</cell><cell>0.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="9,97.10,312.55,408.81,163.03"><head>Table 9 :</head><label>9</label><figDesc>Marginal Precision of Czech Base-TDN Run at Various Depths</figDesc><table coords="9,97.10,327.25,408.81,148.34"><row><cell>Depth Range</cell><cell>Samples</cell><cell># Rel</cell><cell>Precision</cell><cell>Wgt</cell><cell>EstRel/Topic</cell></row><row><cell>1-5</cell><cell>1, 2, ..., 5</cell><cell>110R, 140N, 0U</cell><cell>0.440</cell><cell>1</cell><cell>2.2</cell></row><row><cell>6-10</cell><cell>6, 7, ..., 10</cell><cell>71R, 179N, 0U</cell><cell>0.284</cell><cell>1</cell><cell>1.4</cell></row><row><cell>11-50</cell><cell>15, 20, ..., 50</cell><cell>48R, 352N, 0U</cell><cell>0.120</cell><cell>5</cell><cell>4.8</cell></row><row><cell>51-100</cell><cell>55, 60, ..., 100</cell><cell>10R, 490N, 0U</cell><cell>0.020</cell><cell>5</cell><cell>1.0</cell></row><row><cell>101-200</cell><cell>150, 200</cell><cell>3R, 97N, 0U</cell><cell>0.030</cell><cell>50</cell><cell>3.0</cell></row><row><cell>201-500</cell><cell>250, 300, ..., 500</cell><cell>1R, 299N, 0U</cell><cell>0.003</cell><cell>50</cell><cell>1.0</cell></row><row><cell>501-900</cell><cell>550, 600, ..., 900</cell><cell>3R, 397N, 0U</cell><cell>0.007</cell><cell>50</cell><cell>3.0</cell></row><row><cell>901-1000</cell><cell>950, 1000</cell><cell>1R, 99N, 0U</cell><cell>0.010</cell><cell>50</cell><cell>1.0</cell></row><row><cell>1001-3000</cell><cell>1500, 2000, ..., 3000</cell><cell>0R, 200N, 0U</cell><cell>0.000</cell><cell>500</cell><cell>0.0</cell></row><row><cell>3001-6000</cell><cell>3500, 4000, ..., 6000</cell><cell>1R, 299N, 0U</cell><cell>0.003</cell><cell>500</cell><cell>10.0</cell></row><row><cell>6001-10000</cell><cell>7000, 8000, ..., 10000</cell><cell>0R, 200N, 0U</cell><cell>0.000</cell><cell>1000</cell><cell>0.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="10,99.59,117.46,403.83,163.03"><head>Table 10 :</head><label>10</label><figDesc>Marginal Precision of Hungarian Base-TDN Run at Various Depths</figDesc><table coords="10,99.59,132.14,403.83,148.35"><row><cell>Depth Range</cell><cell>Samples</cell><cell># Rel</cell><cell cols="3">Precision Wgt EstRel/Topic</cell></row><row><cell>1-5</cell><cell>1, 2, ..., 5</cell><cell>133R, 117N, 0U</cell><cell>0.532</cell><cell>1</cell><cell>2.7</cell></row><row><cell>6-10</cell><cell>6, 7, ..., 10</cell><cell>89R, 161N, 0U</cell><cell>0.356</cell><cell>1</cell><cell>1.8</cell></row><row><cell>11-50</cell><cell>15, 20, ..., 50</cell><cell>55R, 345N, 0U</cell><cell>0.138</cell><cell>5</cell><cell>5.5</cell></row><row><cell>51-100</cell><cell>55, 60, ..., 100</cell><cell>25R, 475N, 0U</cell><cell>0.050</cell><cell>5</cell><cell>2.5</cell></row><row><cell>101-200</cell><cell>125, 150, ..., 200</cell><cell>3R, 197N, 0U</cell><cell>0.015</cell><cell>25</cell><cell>1.5</cell></row><row><cell>201-500</cell><cell>225, 250, ..., 500</cell><cell>12R, 588N, 0U</cell><cell>0.020</cell><cell>25</cell><cell>6.0</cell></row><row><cell>501-900</cell><cell>525, 550, ..., 900</cell><cell>2R, 798N, 0U</cell><cell>0.003</cell><cell>25</cell><cell>1.0</cell></row><row><cell>901-1000</cell><cell>950, 1000</cell><cell>1R, 99N, 0U</cell><cell>0.010</cell><cell>50</cell><cell>1.0</cell></row><row><cell>1001-3000</cell><cell>1500, 2000, ..., 3000</cell><cell>0R, 200N, 0U</cell><cell>0.000</cell><cell>500</cell><cell>0.0</cell></row><row><cell>3001-6000</cell><cell>3500, 4000, ..., 6000</cell><cell>0R, 300N, 0U</cell><cell>0.000</cell><cell>500</cell><cell>0.0</cell></row><row><cell>6001-10000</cell><cell>6500, 7000, ..., 10000</cell><cell>0R, 400N, 0U</cell><cell>0.000</cell><cell>500</cell><cell>0.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="10,131.32,312.81,340.37,67.39"><head>Table 11 :</head><label>11</label><figDesc>Estimated Percentage of Relevant Items that are Judged, Per Topic BG CS HU Estimated Rel@10000 29.3 27.4 21.9 Official Rel/Topic 20.2 15.2 18.2 Percentage Judged 69% 55% 83%</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,105.24,716.34,407.82,9.49;1,90.00,726.93,423.11,8.37;1,90.01,736.39,423.10,8.37;1,90.00,745.85,340.60,8.37"><p>Livelink, Open Text TM and SearchServer TM are trademarks or registered trademarks of Open Text Corporation in the United States of America, Canada, the European Union and/or other countries. This list of trademarks is not exhaustive. Other trademarks, registered trademarks, product names, company names, brands and service names mentioned herein are property of Open Text Corporation or other respective owners.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,105.49,731.35,407.52,10.46;10,100.52,743.30,125.01,10.46" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,251.93,731.35,261.07,10.46;10,100.52,743.30,57.32,10.46">Considérations sur l&apos;évaluation de la robustesse en recherche d&apos;information</title>
		<author>
			<persName coords=""><forename type="first">Samir</forename><surname>Abdou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,165.56,743.30,33.27,10.46">CORIA</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,105.49,110.53,407.51,10.46;11,100.52,122.49,207.17,10.46" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,260.18,110.53,252.82,10.46;11,100.52,122.49,87.32,10.46">Less is More: Probabilistic Models for Retrieving Fewer Relevant Documents</title>
		<author>
			<persName coords=""><forename type="first">Harr</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">R</forename><surname>Karger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,196.29,122.49,50.32,10.46">SIGIR 2006</title>
		<imprint>
			<biblScope unit="page" from="429" to="436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,105.49,142.41,332.13,10.46" xml:id="b2">
	<monogr>
		<ptr target="http://www.clef-campaign.org/" />
		<title level="m" coord="11,105.49,142.41,188.54,10.46">Cross-Language Evaluation Forum web site</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="11,105.49,162.34,407.50,10.46;11,100.52,174.29,114.70,10.46" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,186.64,162.34,218.56,10.46">Converting the Fulcrum Search Engine to Unicode</title>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Hodgson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,413.30,162.34,99.70,10.46;11,100.52,174.29,84.08,10.46">Sixteenth International Unicode Conference</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,105.49,194.22,32.78,10.46;11,156.14,194.22,58.66,10.46;11,232.65,194.22,18.60,10.46;11,269.11,194.22,43.71,10.46;11,330.70,194.22,11.93,10.46;11,360.50,194.22,10.93,10.46;11,389.29,194.22,39.12,10.46;11,446.28,194.22,25.18,10.46;11,489.33,194.22,23.67,10.46;11,100.52,206.18,213.71,10.46" xml:id="b4">
	<monogr>
		<ptr target="http://research.nii.ac.jp/∼ntcadm/index-en.html" />
		<title level="m" coord="11,105.49,194.22,32.78,10.46;11,156.14,194.22,58.66,10.46;11,232.65,194.22,18.60,10.46;11,269.11,194.22,43.71,10.46;11,330.70,194.22,11.93,10.46;11,360.50,194.22,10.93,10.46;11,389.29,194.22,39.12,10.46;11,446.28,194.22,25.18,10.46;11,489.33,194.22,18.94,10.46">NTCIR (NII-NACSIS Test Collection for IR Systems) Home Page</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="11,105.49,226.11,407.51,10.46;11,100.52,238.06,173.50,10.46" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,473.43,226.11,39.57,10.46;11,100.52,238.06,33.91,10.46">Okapi at TREC-3</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,143.40,238.06,98.94,10.46">Proceedings of TREC-3</title>
		<meeting>TREC-3</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,105.49,257.99,407.51,10.46;11,100.52,269.94,137.79,10.46" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
		</author>
		<ptr target="http://www.unine.ch/info/clef/" />
		<title level="m" coord="11,192.77,257.99,315.69,10.46">CLEF and Multilingual information retrieval resource page</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="11,105.49,289.86,303.79,10.46" xml:id="b7">
	<monogr>
		<ptr target="http://trec.nist.gov/" />
		<title level="m" coord="11,105.49,289.86,206.29,10.46">Text REtrieval Conference (TREC) Home Page</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="11,105.49,309.79,407.50,10.46;11,100.52,321.74,227.43,10.46" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,195.36,309.79,317.63,10.46;11,100.52,321.74,20.40,10.46">Comparing the Robustness of Expansion Techniques and Retrieval Measures</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,128.32,321.74,194.61,10.46">Working Notes for the CLEF 2006 Workshop</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="11,110.47,341.67,402.53,10.46;11,100.52,353.62,137.39,10.46" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,198.29,341.67,314.71,10.46;11,100.52,353.62,18.15,10.46">Early Precision Measures: Implications from the Downside of Blind Feedback</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,126.53,353.62,50.31,10.46">SIGIR 2006</title>
		<imprint>
			<biblScope unit="page" from="705" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,110.47,373.55,402.52,10.46;11,100.52,385.50,222.64,10.46" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,201.70,373.55,311.29,10.46;11,100.52,385.50,94.86,10.46">Experiments with the Negotiated Boolean Queries of the TREC 2006 Legal Discovery Track</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,203.27,385.50,93.20,10.46">Proceedings of TREC</title>
		<meeting>TREC</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,110.47,405.43,402.52,10.46;11,100.52,417.39,55.70,10.46;11,156.21,416.31,12.85,7.32;11,172.88,417.39,267.82,10.46" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,211.75,405.43,301.24,10.46;11,100.52,417.39,55.70,10.46;11,156.21,416.31,12.85,7.32;11,172.88,417.39,38.87,10.46">European Ad Hoc Retrieval Experiments with Hummingbird SearchServer TM at CLEF</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,241.08,417.39,194.60,10.46">Working Notes for the CLEF 2005 Workshop</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,110.47,437.32,402.52,10.46;11,100.52,449.27,135.10,10.46" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,198.35,437.32,309.16,10.46">Sampling Precision to Depth 9000: Evaluation Experiments at NTCIR-6</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Tomlinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,100.52,449.27,103.57,10.46">Proceedings of NTCIR-6</title>
		<meeting>NTCIR-6</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,110.47,469.20,402.53,10.46;11,100.52,481.15,23.12,10.46" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,193.67,469.20,220.90,10.46">Overview of the TREC 2004 Robust Retrieval Track</title>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,421.52,469.20,91.49,10.46">Proceedings of TREC</title>
		<meeting>TREC</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,110.47,501.07,402.53,10.46;11,100.52,513.03,100.69,10.46" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,169.08,501.07,338.98,10.46">How Reliable are the Results of Large-Scale Information Retrieval Experiments</title>
		<author>
			<persName coords=""><forename type="first">Justin</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,100.52,513.03,39.33,10.46">SIGIR&apos;98</title>
		<imprint>
			<biblScope unit="page" from="307" to="314" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
