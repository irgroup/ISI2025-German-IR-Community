<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
				<funder ref="#_T4PqxHa">
					<orgName type="full">Infosys Technologies Limited, India</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,105.43,204.67,116.58,8.74"><forename type="first">Manoj</forename><surname>Kumar Chinnakotla</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of CSE IIT Bombay</orgName>
								<address>
									<settlement>Mumbai</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,229.99,204.67,66.20,8.74"><forename type="first">Sagar</forename><surname>Ranadive</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of CSE IIT Bombay</orgName>
								<address>
									<settlement>Mumbai</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,304.32,204.67,104.97,8.74"><forename type="first">Pushpak</forename><surname>Bhattacharyya</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of CSE IIT Bombay</orgName>
								<address>
									<settlement>Mumbai</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,431.98,204.67,65.59,8.74"><forename type="first">Om</forename><forename type="middle">P</forename><surname>Damani</surname></persName>
							<email>damani@cse.iitb.ac.in</email>
							<affiliation key="aff0">
								<orgName type="department">Department of CSE IIT Bombay</orgName>
								<address>
									<settlement>Mumbai</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A989B5052D456B6A58462E68B6BDC569</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.7 Digital Libraries Measurement, Performance, Experimentation Hindi-to-English, Marathi-to-English, Cross Language Information Retrieval, Query Translation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we present our Hindi→English and Marathi→English CLIR systems developed as part of our participation in the CLEF 2007 Ad-Hoc Bilingual task. We take a query translation based approach using bi-lingual dictionaries. Query words not found in the dictionary are transliterated using a simple rule based approach which utilizes the corpus to return the 'k' closest English transliterations of the given Hindi/Marathi word. The resulting multiple translation/transliteration choices for each query word are disambiguated using an iterative page-rank style algorithm which, based on term-term co-occurrence statistics, produces the final translated query. Using the above approach, for Hindi, we achieve a Mean Average Precision (MAP) of 0.2366 in title which is 61.36% of monolingual performance and a MAP of 0.2952 in title and description which is 67.06% of monolingual performance. For Marathi, we achieve a MAP of 0.2163 in title which is 56.09% of monolingual performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The World Wide Web (WWW), a rich source of information, is growing at an enormous rate with an estimate of more than 11.5 billion pages by January 2005 [ <ref type="bibr" coords="1,352.85,639.46,11.34,8.77" target="#b3">[4]</ref> ]. According to a survey conducted by Online Computer Library Center (OCLC) 1 , English is still the dominant language on the web. However, global internet usage statistics 2 reveal that the number of non-English internet users is steadily on the rise. Making this huge repository of information on the web, which is available in English, accessible to non-English internet users worldwide has become an important challenge in recent times.  Cross-Lingual Information Retrieval (CLIR) systems aim to solve the above problem by allowing users to pose the query in a language (source language) which is different from the language (target language) of the documents that are searched. This enables users to express their information need in their native language while the CLIR system takes care of matching it appropriately with the relevant documents in the target language. To help in identification of relevant documents, each result in the final ranked list of documents is usually accompanied by an automatically generated short summary snippet in the source language. Later, the relevant documents could be completely translated into the source language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query Translation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Monolingual</head><p>Hindi is the official language of India along with English and according to Ethnologue<ref type="foot" coords="2,495.96,547.37,3.97,6.12" target="#foot_0">3</ref> , a well-known source for language statistics, it is the fifth most spoken language in the world. It is mainly spoken in the northern and central parts of India. Marathi is also one of the widely spoken languages in India especially in the state of Maharashtra. Both Hindi and Marathi use the "Devanagari" script and draw their vocabulary mainly from Sanskrit.</p><p>In this paper, we describe our Hindi→English and Marathi→English CLIR approaches for the CLEF 2007 Ad-Hoc Bilingual task. We also present our approach for the English→English Ad-Hoc Monolingual task. The organization of the paper is as follows: Section 2, explains the architecture of our CLIR system. Section 3 describes the algorithm used for English→English monolingual retrieval. Section 4 presents the approach used for Query Transliteration. Section 5 explains the Translation Disambiguation module. Section 6 describes the experiments and discusses the results. Finally, Section 7 concludes the paper highlighting some potential directions for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Query Translation Approach</head><p>1: Remove all the stop words from query 2: Stem the query words to find the root words 3: for stem i ∈ stems of query words do</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4:</head><p>Retrieve all the possible translations from bilingual dictionary 5:</p><p>if list is empty then 6:</p><p>Transliterate the word using to produce candidate transliterations 7:</p><p>end if 8: end for 9: Disambiguate the various translation/transliteration candidates for each word 10: Submit the final translated English query to English→English Monolingual IR Engine</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Architecture</head><p>The architecture of our CLIR system is shown in Figure <ref type="figure" coords="3,344.99,290.63,3.88,8.74" target="#fig_0">1</ref>. We use a Query Translation based approach in our system since it is efficient to translate the query vis-a-vis documents. It also offers the flexibility of adding cross-lingual capability to an existing monolingual IR engine by just adding the query translation module. We use machine-readable bi-lingual Hindi→English and Marathi→English dictionaries created by Center for Indian Language Technologies (CFILT) <ref type="foot" coords="3,505.76,336.88,3.97,6.12" target="#foot_1">4</ref> , IIT Bombay for query translation. The Hindi→English bi-lingual dictionary has around 1,15,571 entries and is also available online<ref type="foot" coords="3,238.65,360.79,3.97,6.12" target="#foot_2">5</ref> . The Marathi→English bi-lingual has relatively less coverage and has around 6110 entries.</p><p>Hindi and Marathi, like other Indian languages, are morphologically rich. Therefore, we stem the query words before looking up their entries in the bi-lingual dictionary. In case of a match, all possible translations from the dictionary are returned. In case a match is not found, the word is assumed to be a proper noun and therefore transliterated by the Devanagari→English transliteration module. The above module, based on a simple lookup table and corpus, returns the best three English transliterations for a given query word. Finally, the translation disambiguation module disambiguates the multiple translations/transliterations returned for each word and returns the most probable English translation of the entire query to the monolingual IR engine. Algorithm 1 clearly depicts the entire flow of our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">English→English Monolingual</head><p>We used the standard Okapi BM25 Model [</p><p>[6] ] for English→English monolingual retrieval. Given a keyword query Q = {q 1 , q 2 , . . . , q n } and document D, the BM25 score of the document D is as follows:</p><formula xml:id="formula_0" coords="3,163.63,577.59,349.37,30.97">score(Q, D) = n i=1 IDF (q i ) • f (q i , D) • (k 1 + 1) f (q i , D) + k 1 • (1 -b + b • |D| avgdl )<label>(1)</label></formula><formula xml:id="formula_1" coords="3,178.44,613.22,334.56,23.23">IDF (q i ) = log N -n(q i ) + 0.5 n(q i ) + 0.5<label>(2)</label></formula><p>where f (q i , D) is the term frequency of q i in D, |D| is length of document D, k 1 &amp; b are free parameters to be set, avgdl is the average length of document in corpus, N is the total no. of documents in collection, n(q i ) is the number of documents containing q i . In our current experiments, we set the value of k 1 = 1.2 and b = 0.75. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Devanagari to English Transliteration</head><p>Many proper nouns of English like names of people, places and organizations, used as part of the Hindi or Marathi query, are not likely to be present in the Hindi→English and Marathi→English bi-lingual dictionaries. Table <ref type="table" coords="4,218.77,222.33,4.98,8.74" target="#tab_1">1</ref> presents an example Hindi topic from CLEF 2007.</p><p>In the above topic, the word "Eþ˚s h {rF" is "Prince Harry" written in Devanagari. Such words are to be transliterated to English. There are many standard formats possible for Devanagari-English transliteration viz. ITRANS, IAST, ISO 15919, etc. but they all use small and capital letters, and diacritic characters to distinguish letters uniquely and do not give the actual English word found in the corpus.</p><p>We use a simple rule based approach which utilizes the corpus to identify the closest possible transliterations for a given Hindi/Marathi word. We create a lookup table which gives the roman letter transliteration for each Devanagari letter. Since English is not a phonetic language, multiple transliterations are possible for each Devanagari letter. In our current work, we only use the most frequent transliteration. A Devanagari word is scanned from left to right replacing each letter with its corresponding entry from the lookup table. For e.g. a word g\go/F is transliterated as shown in Table <ref type="table" coords="4,159.24,365.80,3.88,8.74" target="#tab_2">2</ref>.</p><p>The above approach produces many transliterations which are not valid English words. For example, for the word "aA-V ~˜ElyAI" (Australian), the transliteration based on the above approach will be "astreliyai " which is not a valid word in English. Hence, instead of directly using the transliteration output, we compare it with the unique words in the corpus and choose 'k' words most similar to it in terms of string edit distance. For computing the string edit distance, we use the dynamic programming based implementation of Levenshtein Distance <ref type="bibr" coords="4,415.06,437.50,3.18,8.77;4,414.92,437.50,11.34,8.77">[ [5]</ref> ] metric which is the minimum number of operations required to transform the source string into the target string. The operations considered are insertion, deletion or substitution of a single character.</p><p>Using the above technique, the top 3 closest transliterations for "aA-V ~˜ElyAI" were "australian","australia" and "estrella". Note that we pick the top 3 choices even if our preliminary transliteration is a valid English word and found in the corpus. The exact choice of transliteration is decided by the translation disambiguation module based on the term-term co-occurrence statistics of a transliteration with translations/transliterations of other query terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Translation Disambiguation</head><p>Given the various translation and transliteration choices for each word in the query, the aim of the Translation Disambiguation module is to choose the most probable translation of the input query Q. In word sense disambiguation, the sense of a word is inferred based on the company it  keeps i.e based on the words with which it co-occurs. Similarly, the words in a query, although less in number, provide important clues for choosing the right translations/transliterations. For example, for a query "ndF jl", the translation for ndF is {river } and the translations for jl are {water, to burn}. Here, based on the context, we can see that the choice of translation for the second word is water since it is more likely to co-occur with river.</p><p>Assuming we have a query with three terms, s 1 , s 2 , s 3 , each with different possible translations/transliterations, the most probable translation of query is the combination which has the maximum number of occurrences in the corpus. However, this approach is not only computationally expensive but may also run into data sparsity problem. We use a page-rank style iterative disambiguation algorithm proposed by Christof Monz et. al. [</p><p>[?] ] which examines pairs of terms to gather partial evidence for the likelihood of a translation in a given context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Iterative Disambiguation Algorithm</head><p>Consider three words s i , s j , s k , as shown in Figure <ref type="figure" coords="5,313.64,500.24,3.88,8.74" target="#fig_1">2</ref>, with multiple translations. Let their translations be denoted as {{t i,1 }, {t j,1 , t j,2 , t j,3 }, {t k,1 , t k,2 }}. Given this, a co-occurrence network is constructed as follows: the translation candidates of different query terms are linked together. But, no links exist between different translation candidates of a query term. In the above graph, a weight w(t|s i ), is associated to each node t which denotes the probability of the candidate being the right translation choice for the input query Q. A weight, l(t, t ), is also associated to each edge (t, t ) which denotes the association measure between the words t and t .</p><p>Initially, all the translation candidates are assumed to be equally likely. Initialization step: After initialization, each node weight is iteratively updated using the weights of nodes linked to it and the weight of link connecting them.</p><formula xml:id="formula_2" coords="5,261.86,605.23,251.14,23.23">w 0 (t|s i ) = 1 |tr(s i )|<label>(3)</label></formula><p>Iteration step:</p><formula xml:id="formula_3" coords="6,186.86,233.67,321.89,22.60">w n (t|s i ) = w n-1 (t|s i ) + t ∈inlink(t) l(t, t ) * w n-1 (t |s) (<label>4</label></formula><formula xml:id="formula_4" coords="6,508.76,235.74,4.24,8.74">)</formula><p>where s is the corresponding source word for translation candidate t and inlink(t) is the set of translation candidates that are linked to t. After each node weight is updated, the weights are normalized to ensure they all sum to one. Normalization step:</p><formula xml:id="formula_5" coords="6,233.63,310.02,279.38,28.60">w n (t|s i ) = w n (t|s i ) |tr(si)| m=1 w n (t i,m |s i )<label>(5)</label></formula><p>Steps 4 and 5 are repeated iteratively till convergence. Finally, the two most probable translations for each source word are chosen as candidate translations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Link-weights computation</head><p>The link weight, which is meant to capture the association strength between the two words (nodes), could be measured using various functions. In our current work, we use two such functions: Dice Coefficient and Point-wise Mutual Information (PMI).</p><p>Point-wise Mutual Information(PMI) [ <ref type="bibr" coords="6,270.38,436.43,11.34,8.77" target="#b2">[3]</ref> ] is defined as follows:</p><formula xml:id="formula_6" coords="6,212.05,457.40,300.95,22.31">l(t, t ) = P M I(t, t ) = log 2 p(t, t ) p(t) * p(t )<label>(6)</label></formula><p>where p(t, t ) is the joint probability of t and t . p(t) and p(t ) are the marginal probabilities of t and t respectively. If the two terms are highly related then their joint probability will be higher when compared to the product of their marginals. Therefore, their PMI will in turn be higher. The joint probability p(t, t ) is computed by considering the co-occurrence of the terms t and t and dividing it with all possible term combinations. The marginal probability p(t) is the probability of finding the term independently in the entire corpus.</p><formula xml:id="formula_7" coords="6,246.75,572.07,266.25,49.28">p(t, t ) = f req(t, t ) avgdl × avgdl (7) p(t) = f req(t) N (<label>8</label></formula><formula xml:id="formula_8" coords="6,508.76,605.78,4.24,8.74">)</formula><p>where f req(t, t ) is the number of times t and t co-occur in the entire corpus, f req(t) is the number of times t occurs in the corpus, N is the number of words in the entire corpus, avgdl is the average document length. Dice Coefficient (DC) is defined as follows:</p><formula xml:id="formula_9" coords="6,216.09,687.87,296.91,22.31">l(t, t ) = DC(t, t ) = 2 * f req(t, t ) f req(t) + f req(t ) (9)</formula><p>As we can see, similar to PMI, Dice Coefficient also tries to capture the degree of relatedness between terms only using a different ratio. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experiments and Results</head><p>The CLEF 2007 document collection for Ad-Hoc Bilingual Task consisted of a collection of articles from LA Times that appeared in the year 2002. The details of the target document collection is given in Table <ref type="table" coords="7,168.20,304.35,3.88,8.74" target="#tab_4">4</ref>. We used Trec Terrier [ [8] ] as the monolingual English IR engine. We used the standard implementation of Okapi BM25 in Trec Terrier for our runs. The documents were indexed after stemming (using Porter Stemmer) and stop-word removal. The topic set consisted of 50 topics each in Hindi and Marathi. We used the Hindi and Marathi stemmers and morphological analyzers developed at CFILT, IIT Bombay for stemming the topic words. For each of the Title and Title + Description runs, we tried Dice Coefficient and PMI for calculating the link weight. This gave rise to four runs for Hindi. For Marathi, due to resource constraints, we could not submit the Title + Description run. The details of the runs which we submitted are given in Table <ref type="table" coords="7,117.40,399.99,3.88,8.74" target="#tab_5">5</ref>.</p><p>We use the following standard measures for evaluation [ [9] ]: Mean Average Precision (MAP), R-Precision, Precision at 5, 10 and 20 documents (P@5, P@10 and P@20) and Recall. Since different systems may be using different monolingual retrieval algorithms, to facilitate comparison, we also report the percentage with respect to monolingual retrieval for each performance figure. The overall results are tabulated in Table <ref type="table" coords="7,257.39,459.76,3.88,8.74" target="#tab_6">6</ref>. The corresponding precision-recall curves are shown in Figure <ref type="figure" coords="7,121.44,471.72,3.88,8.74" target="#fig_2">3</ref>.</p><p>For Hindi, we achieve a Mean Average Precision (MAP) of 0.2366 in title which is 61.36% of monolingual performance and a MAP of 0.2952 in title and description which is 67.06% of monolingual performance. For Marathi, we achieve a MAP of 0.2163 in title which is 56.09% of monolingual performance. The recall levels in Hindi are 72.58% for title runs which is 89.16% of monolingual and 76.55% for title and description run which is 87.32% of monolingual. The recall levels in Marathi are 62.44% in title run which is 76.70% of monolingual.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Discussion</head><p>In the title runs, we observe better performance in Hindi than Marathi. One of the reasons for the above is that the Marathi Morphological Analyzer (MA) is still under development. Hence, many words were not properly stemmed due to which the correct translations/transliterations could not be retrieved. Dice Coefficient consistently performs better than PMI. This result needs to be further investigated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>We presented our Hindi→English and Marathi→English CLIR systems developed for the CLEF 2007 Ad-Hoc Bilingual Task. Our approach is based on query translation using bi-lingual dictionaries. Transliteration of words which are not found in the dictionary is done using a simple rule based approach. It makes use of the corpus to return the 'k' closest possible English transliterations of a given Hindi/Marathi word. Disambiguating the various translations/transliterations is performed using an iterative page-rank style algorithm which is based on term-term co-occurrence statistics.</p><p>The bi-lingual dictionaries available with us also have Parts-Of-Speech (POS) information for each word. POS tagging the input query may help in reducing the ambiguity since translations of only matching POS will be retrieved. As part of future work, we plan to investigate the above idea in more detail. Besides, we plan to explore alternate string matching measures which are based on phonetic similarity for retrieving 'k' best transliterations from corpus. Finally, we would like to study the effect of varying 'k' on disambiguation. ] Dan Gusfield. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,189.52,421.47,223.96,8.74"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: System Architecture of our CLIR System</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,113.07,302.45,368.97,8.77;5,478.72,302.45,11.34,8.77"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Co-occurrence Network for Disambiguating Translations/Transliterations [ [7] ]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="9,123.67,316.29,355.66,8.74"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: CLEF 2007 Ad-Hoc Monolingual and Bilingual Precision-Recall Curves</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,203.93,110.82,195.14,42.69"><head>Table 1 :</head><label>1</label><figDesc>CLEF 2007 Topic Number 445</figDesc><table coords="4,203.93,110.82,195.14,20.83"><row><cell>&lt;num&gt;10.2452/445-AH&lt;/num&gt;</cell></row><row><cell>&lt;title&gt;Eþ˚s h {rF aOr nfFlF dvAe\&lt;/title&gt;</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,228.73,630.52,145.53,112.96"><head>Table 2 :</head><label>2</label><figDesc>Transliteration Example</figDesc><table coords="4,237.45,630.52,128.10,81.14"><row><cell cols="2">Input Letter Output String</cell></row><row><cell>g</cell><cell>ga</cell></row><row><cell>\</cell><cell>gan</cell></row><row><cell>g</cell><cell>ganga</cell></row><row><cell>ao</cell><cell>gango</cell></row><row><cell>/F</cell><cell>gangotri</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,147.37,649.60,308.26,102.85"><head>Table 3 :</head><label>3</label><figDesc>Mathematical symbols involved in translation disambiguation</figDesc><table coords="5,177.75,649.60,109.54,33.08"><row><cell cols="2">Symbol Explanation</cell></row><row><cell>s i</cell><cell>Source word</cell></row><row><cell>tr(s</cell><cell></cell></row></table><note coords="5,201.70,673.93,6.91,9.65;5,226.94,673.93,130.28,9.65;5,194.14,685.86,4.45,8.77;5,226.94,685.89,140.97,9.65;5,180.89,697.81,30.96,9.68;5,226.94,697.84,198.31,9.65;5,182.84,709.77,27.07,8.77;5,226.94,709.80,161.39,8.74;5,187.70,721.81,16.84,9.68;5,226.94,721.84,8.75,8.74;5,235.69,720.27,7.68,6.12;5,247.18,721.84,65.23,8.74;5,312.41,720.27,7.68,6.12;5,323.91,721.84,51.86,8.74"><p>i ) Set of translations for word s i t Translation candidate, t ∈ tr(s i ) w(t|s i ) Weight of node t, where s i is the source word l(t, t ) Weight of link between nodes t and t t i,m m th translation of i th source word</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,202.23,168.55,198.53,8.74"><head>Table 4 :</head><label>4</label><figDesc>Details of LA Times 2002 Collection</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,104.92,110.82,393.16,126.64"><head>Table 5 :</head><label>5</label><figDesc>Details of Runs Submitted</figDesc><table coords="7,104.92,110.82,85.24,8.74"><row><cell>S.No. Description</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,90.00,110.40,475.24,236.01"><head>Table 6 :</head><label>6</label><figDesc>CLEF 2007 Ad-Hoc Monolingual and Bilingual Overall Results (Percentage of monolingual performance given in brackets below the actual numbers)</figDesc><table coords="8,304.50,110.40,52.06,8.77"><row><cell>Title Only</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="9,89.86,348.11,423.15,196.04"><head></head><label></label><figDesc>Algorithms on Strings, Trees and Sequences: Computer Science and Computational Biology. Cambridge University Press, 1997. Karen Sparck Jones, Steve Walker, and Stephen E. Robertson. A probabilistic model of information retrieval: development and comparative experiments (parts 1&amp; 2). Information Processing and Management, 36(6):779-840, 2000. Christof Monz and Bonnie J. Dorr. Iterative translation disambiguation for cross-language information retrieval. In SIGIR '05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, pages 520-527, New York, NY, USA, 2005. ACM Press. Ounis, G. Amati, Plachouras V., B. He, C. Macdonald, and Johnson. Terrier Information Retrieval Platform. In Proceedings of the 27th European Conference on IR Research (ECIR 2005), volume 3408 of Lecture Notes in Computer Science, pages 517-519. Springer, 2005. Ricardo Baeza Yates and Berthier Ribeiro Neto. Modern Information Retrieval. Pearson Education, 2005.</figDesc><table coords="9,89.86,379.96,30.94,152.23"><row><cell>[ [ 6 ] ] [ [ 7 ] ] [ [ 8 ] ] I. [ [ 9 ] ]</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="2,105.24,699.95,105.85,6.64"><p>http://www.ethnologue.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="3,105.24,702.64,114.32,6.64"><p>http://www.cfilt.iitb.ac.in</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="3,105.24,712.14,307.89,6.64"><p>http://www.cfilt.iitb.ac.in/∼hdict/webinterface user/dict search user.php</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="8">Acknowledgements</head><p>The first author is supported by a <rs type="grantName">Fellowship Award</rs> from <rs type="funder">Infosys Technologies Limited, India</rs>. We would like to thank our project linguists <rs type="person">Jaya Madam</rs>, <rs type="person">Gajananji</rs>, <rs type="person">Gauri</rs>, <rs type="person">Sushant</rs> and <rs type="person">Subodh</rs> for their help. We would also like to thank <rs type="person">Manish Shrivastav</rs> for his help with Stemmer and Morphological Analyzer. ,</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_T4PqxHa">
					<orgName type="grant-name">Fellowship Award</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,114.44,611.09,398.56,8.74;8,114.44,623.05,226.51,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,296.78,611.09,216.22,8.74;8,114.44,623.05,88.66,8.74">Statistical models for monolingual and bilingual information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Nicola</forename><surname>Bertoldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marcello</forename><surname>Federico</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,211.37,623.05,39.68,8.74">Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="53" to="72" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,114.44,642.97,398.56,8.74;8,114.44,654.93,188.85,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,277.13,642.97,235.87,8.74;8,114.44,654.93,55.23,8.74">Cross-language evaluation forum: Objectives, results, achievements</title>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,178.68,654.93,39.68,8.74">Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="7" to="31" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,114.44,674.85,398.56,8.74;8,114.44,686.81,119.58,8.74" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="8,288.00,674.85,134.24,8.74">Elements of information theory</title>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joy</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Wiley-Interscience</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,114.44,706.73,398.57,8.74;8,114.44,718.69,398.57,8.74;8,114.44,730.64,243.62,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,229.57,706.73,213.85,8.74">The indexable web is more than 11.5 billion pages</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gulli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Signorini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,463.66,706.73,49.34,8.74;8,114.44,718.69,393.09,8.74">WWW &apos;05: Special interest tracks and posters of the 14th international conference on World Wide Web</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="902" to="903" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
