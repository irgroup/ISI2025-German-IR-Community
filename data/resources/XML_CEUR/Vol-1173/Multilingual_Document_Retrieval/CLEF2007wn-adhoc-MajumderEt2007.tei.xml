<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,110.88,99.10,381.54,15.20">Hungarian and Czech Stemming using YASS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,257.52,132.96,88.04,8.85;1,270.48,146.88,34.15,8.85"><forename type="first">Prasenjit</forename><forename type="middle">Majumder</forename><surname>Mandar</surname></persName>
							<email>prasenjitt@isical.ac.in</email>
							<affiliation key="aff0">
								<orgName type="laboratory">CVPR Unit</orgName>
								<orgName type="institution">Indian Statistical Institute</orgName>
								<address>
									<settlement>Kolkata</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,307.93,146.88,24.68,8.85;1,273.96,160.80,55.34,8.85"><forename type="first">Mitra</forename><surname>Dipasree Pal</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">CVPR Unit</orgName>
								<orgName type="institution">Indian Statistical Institute</orgName>
								<address>
									<settlement>Kolkata</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,110.88,99.10,381.54,15.20">Hungarian and Czech Stemming using YASS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F25753B6689AC2619D9B422610E64A50</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This is the second year in a row we are participating in CLEF. Our aim is to test the performance of a statistical stemmer on various languages. Last year, we tried the stemmer on French; this year, we opted for Hungarian, Bulgarian and Czech. We were unable to complete the Bulgarian task, but submitted official runs for the adhoc monolingual Hungarian and Czech tasks. We find that, for both languages, the performance of the statistical stemmer is comparable to that of an available rule-based stemmer.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Stemming is arguably a recall enhancing device in text retrieval. Most commonly used stemmers are rule-based and therefore language specific. Such stemmers are unlikely to be available for resource-poor languages. In earlier work, therefore, we proposed YASS, a statistical stemmer. As YASS does not assume any language-specific information, we expect the approach to work for multiple languages. The motivation behind our experiments at CLEF 2006 was to test this hypothesis. Since our hypothesis was supported by last year's experiments, this year, we planned on mono-lingual retrieval for three more languages which we know nothing about.</p><p>The main stumbling block in our experiments was the encoding issue. For all our experiments, we use the SMART system, which is not Unicode compatible. Our major task, therefore was to incorporate UTF-8 support in SMART.</p><p>We give a brief overview of YASS in the next section. Section 3 describes the training experiments of YASS which is followed by the results of all the runs (both official and unofficial) in for this year in the Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">YASS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">String Distance Measures</head><p>Distance functions map a pair of strings s and t to a real number r, where a smaller value of r indicates greater similarity between s and t. In the context of stemming, an appropriate distance measure would be one that assigns a low distance value to a pair of strings when they are morphologically similar, and assigns a high distance value to morphologically unrelated words. The languages that we have been experimenting with are primarily suffixing in nature, i.e. words are usually inflected by the addition of suffixes, and possible modifications to the tail-end of the word. Thus, for these languages, two strings are likely to be morphologically related if they share a long matching prefix. Based on this intuition, we define a string distance measure D which rewards long matching prefixes, and penalizes an early mismatch.</p><p>Given two strings X = x 0 x 1 . . . x n and Y = y 0 y 1 . . . y n , we first define a Boolean function p i (for penalty) as follows:</p><formula xml:id="formula_0" coords="2,213.12,85.35,170.56,21.42">p i = 0 if x i = y i 0 ≤ i ≤ min(n, n ) 1 otherwise</formula><p>Thus, p i is 1 if there is a mismatch in the i-th position of X and Y . If X and Y are of unequal length, we pad the shorter string with null characters to make the string lengths equal. Let the length of the strings be n + 1, and let m denote the position of the first mismatch between X and Y (i.e. x 0 = y 0 , x 1 = y 1 , . . . , x m-1 = y m-1 , but x m = y m ). We now define D as follows:</p><formula xml:id="formula_1" coords="2,170.40,181.79,342.63,31.09">D(X, Y ) = n -m + 1 m × n i=m 1 2 i-m if m &gt; 0, ∞ otherwise<label>(1)</label></formula><p>Note that D does not consider any match once the first mismatch occurs. The actual distance is obtained by multiplying the total penalty by a factor which is intended to reward a long matching prefix, and penalize significant mismatches. For example, for the pair astronomer, astronomically , m = 8, n = 13. Thus,</p><formula xml:id="formula_2" coords="2,259.44,252.83,165.01,14.29">D 3 = 6 8 × ( 1 2 0 + . . . + 1 2 13-8 ) = 1.4766.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Lexicon Clustering</head><p>Using the distance function defined above, we can cluster all the words in a document collection into groups. Each group, consisting of "similar" strings, is expected to represent an equivalence class consisting of morphological variants of a single root word. The words within a cluster can be stemmed to the 'central' word in that cluster. Since the number of natural clusters are unknown apriori, partitive clustering algorithms like k-means are not suitable for our task. Also, the clusters are likely to be of non-convex nature. Graph-theoretic clustering algorithms appear to be the natural choice in this situation because of their ability to detect natural and non-convex clusters in the data. Three variants of graph theoretic clustering are popular in literature, namely, single-linkage, average-linkage, and complete-linkage. Each of these algorithms are of hierarchical (agglomerative or divisive) nature. In the agglomerative form, the cluster tree (often referred to as a dendogram) consists of individual data points as leaves. The nearest (or most similar) pair(s) of points are merged to form groups, which in turn are successively merged to form progressively larger groups of points. Clustering stops when the similarity between the pair of closest groups falls below a pre-determined threshold. Alternatively, a threshold can be set on the distance value; when the distance between the pair of nearest points exceeds the threshold, clustering stops.</p><p>The three algorithms mentioned above differ in the way similarity between the groups is defined. We choose the compete-linkage algorithm for our experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments with Hungarian and Czech</head><p>We have mentioned earlier that YASS needs no linguistic input as it is a statistical stemmer. However, before running YASS on a new language we need to train it. For training we need a corpus of that language. In the following subsections, we will describe the training procedure of YASS in brief.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Training</head><p>A lexicon is extracted from a given language corpus and clustered. The clustering threshold is learned from the training data. For Hungarian we used 2006 CLEF data for training. For Czech we did not get previous years data and thus we did not train our stemmer for Czech.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Hungarian</head><p>The same Hungarian corpus is used for the 2005, 2006, and 2007 tasks. The lexicon extracted from the corpus has 536678 surface words. The lexicon was clustered using various threshold settings, and the number of clusters versus threshold curve is shown in Figure <ref type="figure" coords="3,406.35,104.52,3.90,8.85" target="#fig_0">1</ref>. The step like regions around 0.8, 1.1, 1.5, 2.0 suggest that the number of clusters is stable around these threshold values. These values may thus be chosen as candidate thresholds for clustering.</p><p>After clustering the lexicon using these four threshold values, the lexicon size gets reduced to 225489, 169619, 130278, 76782 classes respectively. The stemmers thus prepared are used in four different runs. The official topics for the Hungarian monolingual run at CLEF-2006 were topic numbers 301 to 325 and 351 to 375. We find that YASS performs best at the threshold 1.1. A mean average precision (MAP) versus threshold curve for the runs are plotted and given in Table <ref type="table" coords="3,470.39,480.00,3.90,8.85" target="#tab_0">1</ref> We tested these stemmers on CLEF queries 251 to 300. These queries were used in the CLEF 2005 monolingual Hungarian task. The highest MAP obtained here was again at θ = 1.1. We tried to compare our results with that of Tordai et al.[3], but could not compile the stemmer used by them. We have therefore reproduced the same experiments using YASS. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Czech</head><p>For Czech no training data was available. The threshold for the Czech stemmer was set to 1.5 based on our experience with English and French.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results of CLEF 2007</head><p>Unfortunately, we could not complete the training experiments described above, before the official submission. Thus for both the languages, we have submitted three runs, untrained.</p><p>In the first Hungarian run ISI.YASSTDHUN, we indexed only the &lt;title&gt; and &lt;desc&gt; fields of the queries. For the second run, ISI.YASSHUN we indexed the &lt;title&gt;, &lt;desc&gt;, and &lt;narr&gt; fields of the queries. In both cases the clustering threshold was set to 1.5. For the third run, ISI.ISIDWLDHSTEMGZ, we made use of the Hungarian stemmer available from the web <ref type="bibr" coords="4,484.68,456.71,3.97,6.97" target="#b0">1</ref> .</p><p>The Czech runs are analogous: the first run uses only the &lt;title&gt; and &lt;desc&gt; fields; the second and third runs use the complete query. The second run makes use of an existing stemmer 2 instead of YASS. The final run was a baseline run where no stemming was used.</p><p>After the relevance judgments for the data sets were distributed, we performed some additional experiments for both the languages. The results obtained for all the official and unofficial runs are given in Table <ref type="table" coords="4,155.77,530.52,4.98,8.85" target="#tab_2">3</ref> and 4. These results confirms our hypothesis that YASS will work for a variety of languages, provided the languages are primarily suffixing in nature.</p><p>Our ignorance of the languages prevents us from doing a detailed post-mortem on these results. For the benefit of those who understand Hungarian / Czech, we provide some examples of words and their roots (as obtained using YASS) in the following table. These words were selected from queries on which the stemmed run did significantly better than the unstemmed run.</p><p>[2] Gerard Salton, editor. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,188.76,430.20,225.66,8.85;3,131.40,183.31,340.07,231.71"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Threshold vs. no of cluster for Hungarian</figDesc><graphic coords="3,131.40,183.31,340.07,231.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,206.16,480.00,272.02,103.29"><head>Table 1 :</head><label>1</label><figDesc>. Threshold vs. MAP for Hungarian</figDesc><table coords="3,259.80,503.16,83.70,58.29"><row><cell cols="2">Threshold MAP</cell></row><row><cell>0.8</cell><cell>0.2692</cell></row><row><cell>1.1</cell><cell>0.2835</cell></row><row><cell>1.5</cell><cell>0.2777</cell></row><row><cell>2</cell><cell>0.2735</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,90.00,633.72,423.12,32.73"><head>Table 2 :</head><label>2</label><figDesc>Table 2 compares our results with those reported by Tordai et al. Tordai et. al report the results of 8 runs in their paper, out of which we listed the best three runs (4-Gram, Heavy minus hyphen and 5-Gram). Results of previous Hungarian runs</figDesc><table coords="4,136.32,60.96,330.38,209.37"><row><cell></cell><cell></cell><cell>YASS</cell><cell></cell></row><row><cell>Run Name</cell><cell>MAP</cell><cell>R-prec</cell><cell>% Rel Ret</cell></row><row><cell>noStem(T+D+N)</cell><cell>0.2472</cell><cell>0.2531</cell><cell>72.8434</cell></row><row><cell>θ = 0.8(T+D+N)</cell><cell>0.3211</cell><cell>0.3231</cell><cell>83.8125</cell></row><row><cell>θ =1.1(T+D+N)</cell><cell>0.3246</cell><cell>0.3247</cell><cell>86.0489</cell></row><row><cell>θ =1.5(T+D+N)</cell><cell>0.3246</cell><cell>0.3190</cell><cell>86.6879</cell></row><row><cell>θ =2.0(T+D+N)</cell><cell>0.3246</cell><cell>0.3068</cell><cell>83.8125</cell></row><row><cell>noStem(T+D)</cell><cell>0.2170</cell><cell>0.2285</cell><cell>69.1160</cell></row><row><cell>θ =0.8(T+D)</cell><cell>0.3121</cell><cell>0.3162</cell><cell>81.0436</cell></row><row><cell>θ =1.1(T+D)</cell><cell>0.3241</cell><cell>0.3270</cell><cell>84.2385</cell></row><row><cell>θ =1.5(T+D)</cell><cell>0.3268</cell><cell>0.3309</cell><cell>85.6230</cell></row><row><cell>θ =2.0(T+D)</cell><cell>0.3048</cell><cell>0.3074</cell><cell>84.1320</cell></row><row><cell></cell><cell></cell><cell>TORDAI et. al</cell><cell></cell></row><row><cell>Run Name</cell><cell>MAP</cell><cell cols="2">R-prec % Relevant Docs Retrieved</cell></row><row><cell cols="2">Heavy minus hyphen 0.3099</cell><cell>0.3048</cell><cell>83.1</cell></row><row><cell>4-Gram</cell><cell>0.3303</cell><cell>0.338</cell><cell>83.6</cell></row><row><cell>5-Gram</cell><cell>0.3002</cell><cell>0.3057</cell><cell>82.4</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,90.00,62.16,423.13,52.77"><head>Table 3 :</head><label>3</label><figDesc>The SMART Retrieval System-Experiments in Automatic Document Retrieval. Prentice Hall Inc., Englewood Cliffs, NJ, 1971. [3] Anna Tordai and Maarten de Rijke. Four stemmers and a funeral: Stemming in hungarian at clef 2005. In CLEF, pages 179-186, 2005. All Hungarian runs on 2007 CLEF data</figDesc><table coords="6,135.00,84.96,333.14,414.57"><row><cell cols="4">Hungarian Runs Submitted (nnn.ltn)</cell></row><row><cell>Run Name</cell><cell>MAP</cell><cell cols="3">R-prec % Rel Ret</cell></row><row><cell>ISI.YASSHUN</cell><cell>0.1712</cell><cell>0.1974</cell><cell>72.22</cell></row><row><cell>ISI.YASSTDHUN</cell><cell>0.1695</cell><cell>0.1943</cell><cell>72.88</cell></row><row><cell cols="2">ISI.ISIDWLDHSTEMGZ 0.1605</cell><cell>0.1858</cell><cell>66.84</cell></row><row><cell cols="4">Other Hungarian Runs (Lnu.ltn)</cell></row><row><cell>Run Name</cell><cell>MAP</cell><cell cols="3">R-prec % Rel Ret</cell></row><row><cell>noStem(T+D+N)</cell><cell>0.2647</cell><cell>0.2849</cell><cell>71.59</cell></row><row><cell>hun.d6-0.8(T+D+N)</cell><cell>0.3276</cell><cell>0.3316</cell><cell>81.11</cell></row><row><cell>hun.d6-1.1(T+D+N)</cell><cell>0.3459</cell><cell>0.3437</cell><cell>84.19</cell></row><row><cell>hun.d6-1.5(T+D+N)</cell><cell>0.3600</cell><cell>0.3565</cell><cell>84.96</cell></row><row><cell>hun.d6-2.0(T+D+N)</cell><cell>0.3638</cell><cell>0.3747</cell><cell>83.42</cell></row><row><cell>noStem(T+D)</cell><cell>0.2320</cell><cell>0.2571</cell><cell>65.53</cell></row><row><cell>hun.d6-0.8(T+D)</cell><cell>0.2982</cell><cell>0.3084</cell><cell>76.83</cell></row><row><cell>hun.d6-1.1(T+D)</cell><cell>0.3094</cell><cell>0.3095</cell><cell>79.91</cell></row><row><cell>hun.d6-1.5(T+D)</cell><cell>0.3203</cell><cell>0.3274</cell><cell>81.22</cell></row><row><cell>hun.d6-2.0(T+D)</cell><cell>0.3638</cell><cell>0.3747</cell><cell>75.08</cell></row><row><cell cols="3">Runs Submitted (Lnu.ltn)</cell><cell></cell></row><row><cell>Run Name</cell><cell></cell><cell>MAP</cell><cell cols="2">R-prec % Rel Ret</cell></row><row><cell>ISI.CZTD [YASS] (T+D)</cell><cell></cell><cell>0.3224</cell><cell>0.3102</cell><cell>87.13</cell></row><row><cell>ISI.ISICL [dnlded] (T+D+N)</cell><cell></cell><cell>0.3362</cell><cell>0.3326</cell><cell>89.37</cell></row><row><cell cols="2">ISI.ISICZNS [nostem] (T+D+N)</cell><cell>0.2473</cell><cell>0.2540</cell><cell>76.64</cell></row><row><cell cols="3">Other runs (Lnu.ltn)</cell><cell></cell></row><row><cell>Run Name</cell><cell></cell><cell>MAP</cell><cell cols="2">R-prec % Rel Ret</cell></row><row><cell cols="2">CzeTDN.cze.d6-1.1.Lnu (T+D+N)</cell><cell>0.3305</cell><cell>0.3208</cell><cell>89.63</cell></row><row><cell cols="2">CzeTDN.cze.d6-1.5.Lnu (T+D+N)</cell><cell>0.3390</cell><cell>0.3264</cell><cell>89.23</cell></row><row><cell cols="3">CzeTDN.cze.d6-2.0.Lnu (T+D+N)(Lnu) 0.3381</cell><cell>0.3213</cell><cell>89.89</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,97.20,512.52,408.64,142.29"><head>Table 4 :</head><label>4</label><figDesc>All Czech runs on 2007 CLEF data</figDesc><table coords="6,97.20,577.20,408.64,77.61"><row><cell>Hungarian</cell><cell></cell><cell>Czech</cell><cell></cell></row><row><cell>politikusokról, politikai</cell><cell>politi</cell><cell>Kostelicových, Kostelicovi</cell><cell>Kostelic</cell></row><row><cell>atomhulladékot</cell><cell cols="3">atomhulladék prezidenstí, prezidenta, prezidentského preziden</cell></row><row><cell>megszűnése</cell><cell>megsz</cell><cell>kandidáti, kandidáta</cell><cell>kandidát</cell></row><row><cell cols="2">elnökjelöltek, elnökjelölt elnökjelöl</cell><cell>vesmírní, vesmírných, vesmíru</cell><cell>vesmír</cell></row><row><cell>királynő, királyságbeli</cell><cell>kir / király</cell><cell>turistech, turisté</cell><cell>turist</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,212.04,669.96,178.83,8.85"><head>Table 5 :</head><label>5</label><figDesc>Word stems generated by YASS</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,105.48,644.76,407.54,8.85;4,105.48,656.76,407.44,8.85;4,105.48,668.76,326.53,8.85" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,278.82,644.76,234.20,8.85;4,105.48,656.76,30.28,8.85">Using Query Zoning and Correlation within SMART: TREC5</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,346.08,656.76,166.84,8.84;4,105.48,668.76,214.04,8.85">Proceedings of the Fifth Text REtrieval Conference (TREC-5). NIST Special Publication</title>
		<editor>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting>the Fifth Text REtrieval Conference (TREC-5). NIST Special Publication</meeting>
		<imprint>
			<date type="published" when="1997-11">November 1997</date>
			<biblScope unit="page" from="500" to="238" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
