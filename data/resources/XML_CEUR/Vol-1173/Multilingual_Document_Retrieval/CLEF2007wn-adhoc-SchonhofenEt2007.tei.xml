<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,127.71,151.38,347.56,12.38;1,256.75,173.29,83.32,12.38;1,346.25,168.17,5.98,10.48">Performing Cross-Language Retrieval with Wikipedia *</title>
				<funder ref="#_MNy3ee5 #_Zmcgf48">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,145.79,204.00,75.70,9.96"><forename type="first">Péter</forename><surname>Schönhofen</surname></persName>
							<email>schonhofen@ilab.sztaki.hu</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,234.76,204.00,69.98,9.96"><forename type="first">András</forename><surname>Benczúr</surname></persName>
							<email>benczur@ilab.sztaki.hu</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,318.02,204.00,48.63,9.96"><forename type="first">István</forename><surname>Bíró</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,379.93,204.00,77.28,9.96"><forename type="first">Károly</forename><surname>Csalogány</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,127.71,151.38,347.56,12.38;1,256.75,173.29,83.32,12.38;1,346.25,168.17,5.98,10.48">Performing Cross-Language Retrieval with Wikipedia *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">34D9F80E532B86F45A6A2341A60B6896</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.3 [Information Search and Retrieval]: [Query Formulation] Design</term>
					<term>Experimentation</term>
					<term>Performance Cross-language information retrieval</term>
					<term>Wikipedia</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe a method which is able to translate queries extended by narrative information from one language to another, with help of an appropriate machine readable dictionary and the Wikipedia on-line encyclopedia. Processing occurs in three steps: rst, we look up possible translations phrase by phrase using both the dictionary and the cross-lingual links provided by Wikipedia; second, improbable translations, detected by a simple language model computed over a large corpus of documents written in the target language, are eliminated; and nally, further ltering is applied by matching Wikipedia concepts against the query narrative and removing translations not related to the overall query topic. Experiments performed on the Los Angeles Times 2002 corpus, translating from Hungarian to English showed that while queries generated at end of the second step were roughly only half as eective as original queries, primarily due to the limitations of our tools, after the third step precision improved signicantly, reaching 60% of the native English level.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Although the overwhelming majority of documents available on the Internet are written in English (as of 2002 roughly 72%, according to statistics presented in <ref type="bibr" coords="1,365.30,657.69,14.61,9.96" target="#b22">[23]</ref>, merely a fraction of users is procient in this language and as a consequence are most probably unable to formulate eective queries for traditional search engines. However, because they might be interested in various nontextual content stored in these documents, like diagrams, images, numeric data, hyperlinks etc., there should be a way to translate queries from any language to English. In the paper we introduce a relatively simple method which, when given a short description of the topic in Hungarian, tries to nd the English keywords most accurately representing it. Experiments performed on the Los Angeles Times 2002 news article collection showed that precision of translated queries (computed for the top 5 retrieved documents) were roughly 60% of the original ones. This value is rather abismal, but when considering the small size of the English-Hungarian dictionary at our disposal and also the naive technique applied for raw translation, is in fact acceptible.</p><p>Our main goal was not to develop a highly accurate machine translation system, but rather to prove that employing an ontology mined from Wikipedia, quality of translations can be significantly improved. The fundamental idea is: if we score candidate English terms based on to how many other terms they are semantically related and exactly how strongly, we can reliably decide whether to retain it or not. For instance when encountering word "ég", which could be interpreted as either "sky" or "burn", and by examining the overall topic suggested by other words we found that the query is about reghting, we can safely prefer the latter meaning. In addition, because many Wikipedia articles exist in more than one language, Hungarian and English titles of such parallel articles can yield term translations not included in a traditional dictionary.</p><p>The proposed algorithm consists of four stages. First of all, we pre-process source documents, carrying out the usual steps, such as stemming and stopword removal; in addition, we extract both phrase translations and a basic ontology from the English Wikipedia. Next, we generate a raw translation of the query narrative, utilizing a simple machine readable dictionary (SZTAKI Szótár <ref type="bibr" coords="2,90.00,326.55,15.49,9.96" target="#b9">[10]</ref>) by looking up English versions of Hungarian terms, naively word for word, then we perform disambiguation where necessary relying on a bigram language model computed over the textual contents of English Wikipedia articles but of course any large corpus with a wide coverage would do. In the third stage, resulting terms are aligned with Wikipedia articles (in fact representing concepts), which in turn are scored primarily according to how many other recognized articles they refer to. Finally, we construct a query from titles of the few highest ranked Wikipedia articles, submitting it to a search engine, which retrieves relevant documents.</p><p>Let us examine the basic idea behind the second and third step more closely. During raw translation the dictionary often gives multiple translations for a specic Hungarian words, each valid, but only one of them is correct in the current context. Context can be represented either by simply the set of words present inside the same sentence (or paragraph), or by the set of Wikipedia concepts recognized through them. In the former case, a bigram language model might predict how "compatible" are words with each other, while in the latter case semantic connections between concepts (extracted from references between Wikipedia articles, each representing a concept described by their titles) may help us pinpoint erroneous translations.</p><p>The search engine is the Hungarian Academy of Sciences search engine <ref type="bibr" coords="2,416.67,505.88,10.51,9.96" target="#b1">[2]</ref> which uses a TF × IDF -based ranking; it was slightly modied in order to work with the Los Angeles Times 2002 corpus and to be able to inuence its ranking function in more aspects than was originally possible.</p><p>There are four research areas strongly relevant to the proposed algorithm, of course the most crucial of whose is machine translation (for an overview see for instance <ref type="bibr" coords="2,400.17,553.70,14.76,9.96" target="#b15">[16]</ref>). Machine translation is usually performed in three dierent ways. In the rst approach, source text is converted to some kind of internal representation, typically with the help of natural language understanding, then converted to the target language (see <ref type="bibr" coords="2,248.79,589.56,14.61,9.96" target="#b20">[21]</ref>, among others). In the second, a dictionary is used, and in case of ambiguous translations, the correct one is selected by determining the precise grammatical role of the source phrase (e. g. <ref type="bibr" coords="2,234.08,613.47,10.29,9.96" target="#b8">[9]</ref>). Finally, in the third, word correlation data collected from statistical analysis of parallel corpora are utilized to select the most appropriate translation (as described for example in <ref type="bibr" coords="2,200.84,637.38,10.29,9.96" target="#b2">[3]</ref>). Our algorithm adopts a simplistic solution, where neither training data acquired from parallel corpora, nor part of speech information are exploited; however, it perfectly ts our declared purpose to demonstrate how Wikipedia can improve translation quality.</p><p>Another related eld is language modeling (an excellent overview is provided by <ref type="bibr" coords="2,470.19,673.25,14.76,9.96" target="#b11">[12]</ref>), and applying language modeling to machine translation <ref type="bibr" coords="2,318.69,685.20,10.51,9.96" target="#b3">[4,</ref><ref type="bibr" coords="2,332.86,685.20,7.75,9.96" target="#b5">6]</ref> or information retrieval <ref type="bibr" coords="2,450.51,685.20,10.51,9.96" target="#b6">[7]</ref> is not new. Though we utilize bigrams to help disambiguate English translations, we do not exploit all possibilities inherent in this technology, such as smoothing or larger n-grams, neither do we employ it as extensively as would be possible, for instance deciding whether a Wikipedia concept is rightly aligned to an English word sequence based on the similarity between its immediate context in the query text and content of the corresponding article body or not.</p><p>Several researcher utilized ontologies to support disambiguation in machine translation <ref type="bibr" coords="3,482.90,111.35,14.61,9.96" target="#b16">[17]</ref>, or as a base for internal representation bridging the source and target languages <ref type="bibr" coords="3,435.61,123.31,14.61,9.96" target="#b19">[20]</ref>; <ref type="bibr" coords="3,457.76,123.31,15.49,9.96" target="#b18">[19]</ref> provides an extensive theoretical discussion on this topic. However, due to a dearth of ontologies which have a suciently wide coverage and at the same time are available in multiple languages, these methods typically construct their own ontologies through some machine learning technique run over parallel corpora. Though the idea of taking advantage of Wikipedia has already emerged, either as an ontology <ref type="bibr" coords="3,185.25,183.09,10.51,9.96" target="#b7">[8]</ref> or as a parallel corpus <ref type="bibr" coords="3,299.70,183.09,9.96,9.96" target="#b0">[1]</ref>, to our best knowledge, so far it has not been used for dictionary construction or to improve translation accuracy.</p><p>The last related area is cross-language information retrieval itself (see for instance <ref type="bibr" coords="3,468.12,207.00,15.49,9.96" target="#b21">[22]</ref> for an overview). There are several papers dealing with the various problematic points of the task, like acquisition of the dictionary <ref type="bibr" coords="3,213.03,230.91,14.61,9.96" target="#b13">[14]</ref>, mapping terms (or concepts) from source to target languages <ref type="bibr" coords="3,497.50,230.91,15.49,9.96" target="#b10">[11,</ref><ref type="bibr" coords="3,90.00,242.86,11.62,9.96" target="#b17">18]</ref>, or disambiguation between multiple possible translations <ref type="bibr" coords="3,357.83,242.86,14.61,9.96" target="#b14">[15]</ref>. Though our approach contains a rather simple disambiguation strategy, the main focus is on the improvement of translation accuracy via the discovery of semantic relations between recognized concepts, which is (at least presently) a quite unexplored research direction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Preparations</head><p>Several preparational steps are necessary before we can carry out actual query translation. First of all, we have to construct a machine readable dictionary which will provide us possible English variants of individual Hungarian words or phrases. Next, a concept network should be extracted from Wikipedia, which will help us discover semantic relationships between candidate English terms, and therefore decide whether they are compatible with the query topic or not. Finally, texts of queries and documents themselves which have to be searched are pre-processed in traditional fashion, to facilitate ecient matching of its contents against dictionary entries. The next three subsection describe each above mentioned activity in detail.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.1</head><p>Constructing the dictionary It goes without saying that the most crucial component for every translation program is a machine readable dictionary, which ideally is accurate, covers a wide range of subjects, and in case of words with many possible translations also contains information about contexts characteristic to each translation. We took advantage of the collaboratively edited SZTAKI Szótár dictionary, a simple textual database of English-Hungarian word pairs behind the popular and freely available on-line service of the same name. It has two components: an ocial and an unocial sub-dictionary (the main dierence between them is that the former is more closely supervised), comprising of roughly 131,000 and 53,000 entries, respectively. Its structure is fairly straightforward, as can be seen from the short extracted fragment below: aeronautical repülési aeronomy fels®légkör tudománya aeroplane repül®gép aesthete esztéta</p><p>Obviously, the rst line of each entry contains an English term, the second its Hungarian variant, while the third remains empty, serving as a very easy to detect delimiter. Unfortunately, some entries specify more than one English or Hungarian terms (typically for words having an irregular plural form, like "adman") separated by commas or semicolons; certain entries refer to idioms (for instance "blow high, blow low"), often complete with punctuations; and a small number of entries represent prexes or postxes, not regular phrases (e. g. "-able", "thermo-" etc). While these special dictionary items usually do not facilitate better translation accuracy, they do make our pre-processing mechanism more complex.</p><p>So when going through the original dictionary entries, we remove text inside parentheses or after a slash; discard question marks, exclamation marks and double quotes; ignore prex or sux references (characterized by an initial or ending hyphen); in addition, English stopwords and dictionary abbreviations (like "sb" representing a person object or subject) are deleted. When an entry contains multiple terms, it is exploded to as many entries as necessary to represent all possible English-Hungarian term pairs. For example, a compound translation from "A, B" to "C, D" will yield four entries, namely A to C, A to D, B to C and B to D.</p><p>Note that at this point we do not perform stemming neither on English, nor on Hungarian words the former will be carried out in a subsequent processing step, and the latter is not strictly required, because terms already appear in their base forms in the dictionary. However, English words not present in any Wikipedia article bodies are deleted, partly as they are totally useless when we attach Wikipedia concepts to translated queries, partly since probably they are misspelled or extremely infrequent in common English, therefore it is very unlikely that submitting them as a query to a search engine would retrieve even a small number of documents.</p><p>Compared to professional dictionaries SZTAKI Szótár is relatively small, thus it was perfectly natural that we attempted to extend it by all available means. Luckily, articles in the English Wikipedia contain links to articles on the same subject in the Hungarian version (if present), so titles connected in this fashion can be considered valid translation pairs and added to the basic dictionary. However, there are at least two problems with the above mentioned approach: First, the number of articles in Hungarian Wikipedia is rather low, around 60,000 as of early 2007 (less than one tenth of the size of its English counterpart), a signicant percentage of which is specic to the Hungarian culture, and consequently is not part of English Wikipedia. Second, Wikipedia covers mostly technical terms, geographical locations, historical events and persons, phrases either not requiring translation or rarely occurring inside common texts.</p><p>We converted cross-language references extracted from Wikipedia to dictionary entries in the following way. Similarly to the processing performed on SZTAKI Szótár, text inside parentheses or written after a comma, semicolon, slash is deleted, both in Hungarian and English titles. In addition, English titles are stemmed and from them stopwords (using a list originally developed for the Smart search engine) are removed. Note that now there is no need to break up English-Hungarian pairs, because overwhelming majority of Wikipedia articles discuss only a single concept, the rest being disambiguation pages, where the various concepts are represented by the same term, for example "Java" or "acid test", and either are translated to the same Hungarian term, or do not have a corresponding article in Hungarian Wikipedia.</p><p>After dictionary entries have been collected from both SZTAKI Szótár and Wikipedia, we merge them to produce the machine readable dictionary utilized during query translation later. As we consider entries derived from Wikipedia less reliable than those extracted from SZTAKI Szótár (which is perfectly understandable since Wikipedia originally was not intended to be employed as a dictionary), we ignore Wikipedia pairs already present among SZTAKI Szótár entries even if they would provide additional English translations for an already known Hungarian term. It is now that Hungarian titles are stemmed and stopwords are removed (with the help of a manually constructed stopword list), making Hungarian terms of several dictionary entries the same (e. g. "futott" and "futó" are both converted to "fut"), which therefore should be merged. The resulting dictionary contains 100,510 Hungarian terms, in average composed of 1.6211 words and referring to 2.0695 English terms, each one representing a dierent possible sense.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2.2</head><p>Converting Wikipedia to a concept network</p><p>In its original form, Wikipedia consists of articles of various types. Regular articles have a title, body, enumeration of Wikipedia categories they pertain to, and possibly links to the same article written in other languages. Article bodies might contain supplementary tables, images, messages for contributors (such as that the article has to be reviewed or cannot be modied temporarily due to recent acts of vandalism), references to related Wikipedia articles, hyperlinks to external websites. Longer articles are usually partitioned into sections, even subsections, and consequently after a short introduction, they typically embed a table of contents. Figure <ref type="figure" coords="5,420.98,509.84,4.98,9.96" target="#fig_0">1</ref> shows a sample. Besides regular articles, there are two additional article types redirects and category pages. Redirects are merely "placeholders" for alternate titles of a given article (e. g. "Eugene Paul Wigner" to "Eugene Wigner"), they have only a title without any body, category assignment list or links to versions in other languages. As their name suggests, when a user retrieves them through the ocial Wikipedia web interface, he or she immediately gets redirected to the appropriate regular article. Category pages describe Wikipedia categories by giving a brief overview about their exact meaning, enumerating their sub-and supercategories (if exist), nally listing all pages pertaining to them. Note that although categories are organized into a hierarchy, unfortunately it is not a tree, because categories might have multiple supercategories.</p><p>Of course, in its original form, Wikipedia cannot be used to help us recognize concepts in the English queries, then detect and discard those which are not consistent with the dominant query subject, since they have been inserted due to some erroneous judgment made by the raw translator. In fact we need only a concept network, or more precisely, an undirected graph where nodes represent concepts and edges the various relationships between them: concept names can be easily extracted from Wikipedia article titles, and if an article refers to another article, it is a fairly reliable indicator that they are semantically connected. As opposed to WordNet, OpenCyc and other proper ontologies, here we do not record the type of relations, because this information is not present in the Wikipedia corpus in explicit form (however, several researchers worked out techniques to rectify this omission, for instance <ref type="bibr" coords="5,298.67,736.99,14.76,9.96" target="#b26">[27]</ref>). To carry out the required transformations, rst of all we convert bodies of regular Wikipedia articles from Wiki markup to XML, omitting embedded images, tables of contents, footnotes and other supplementary elements not strictly pertaining to the core textual content. Category pages are deleted, redirects are regarded as additional titles of articles they point to. Disambiguation pages, which list the dierent possible interpretations of the same term, are broken up to smaller fragments bearing the same title, otherwise our algorithm would falsely believe that articles referenced from the page all belong to a single domain, derailing the second stage of translation.</p><p>Next, titles of redirect articles are added as additional titles to the target articles, and references between articles are collected from article bodies. We apply the same pre-processing to Wikipedia article titles to which English terms inside the dictionary were subjected, in order to make future matching between query terms and Wikipedia concepts as accurate as possible. Namely we remove text between parentheses or after a comma, slash, semicolon; replace letters outside the Latin alphabet with their Latin equivalent if possible (for instance "é" with "e"); delete stopwords; and nally do stemming using TreeTagger <ref type="bibr" coords="6,257.55,574.44,14.61,9.96" target="#b24">[25]</ref>.</p><p>Before we would discard Wikipedia article bodies, we split them to paragraphs and compute occurrence counts of bigrams (it goes without saying that bigrams cannot span paragraph boundaries), so that probability of word w followed by word v can be estimated with the formula:</p><formula xml:id="formula_0" coords="6,250.94,630.73,262.06,23.23">P w,v = P (v|w) = C w,v f w<label>(1)</label></formula><p>Here C w,v denotes the number of occurrences of w where it was followed by v, and f w shows the frequency of w both calculated over the entire Wikipedia corpus. Of course, this language model could have been derived from any suciently large corpus; we used Wikipedia simply because it has been already converted to a format on which bigram statistics was easy to generate. Queries for which relevant documents had to be found in the CLEF Ad-hoc task contain three parts: title, description and narrative. While titles consist of only a few words, descriptions are whole sentences and narratives are usually even longer, sometimes being composed from two or three sentences. Though we will search in the document collection utilizing only the words captured from query titles, we translate all three query parts, otherwise there would not be a sucient amount of context (enough recognized concept) for reliably detect query subjects. As a consequence, pre-processing of course should extend to the whole query, not just to their titles. The pre-processing steps applied to queries do not contain any novel elements, we employ almost the same technique as for Wikipedia titles. More precisely, we perform stemming, remove stopwords (again relying on a slightly modied stopword list originally developed for the Smart search engine), if possible, convert accented characters to their equivalent in the Latin alphabet, and in addition split both query descriptions and narratives to paragraphs. Words not present in Wikipedia article bodies are ignored, because it is guaranteed that they cannot be used to recognize Wikipedia concepts and so improve translation quality.</p><p>For documents in the Los Angeles Times 2002 corpus, from which we want later to retrieve items relevant to queries, exactly the same steps are carried out, otherwise alignment between query and document content would not be as precise as would be possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Raw translation</head><p>As was already mentioned in the introduction of this paper, translation is carried out in two stages: rst, we make a raw translation relying only on the machine readable dictionary built from SZTAKI Szótár and Wikipedia cross-language links; second, we rene the raw translation by removing terms whose meaning is not compatible with the detected subject of our query. Raw translation again consists of two stages after we gathered possible English versions of Hungarian words, we select those seeming the most probable based on the bigram language model computed on Wikipedia article bodies, as has been described in the previous section.</p><p>So we start by examining word sequences present in the Hungarian query which we want to translate; sequences obviously have to be continuous, cannot cross paragraph or query part boundaries, and in addition their length cannot exceed 5 words. If a word sequence exactly matches some Hungarian term in our machine readable vocabulary, we attach the corresponding English term (or maybe terms) to text positions occupied by the Hungarian term. For instance, encountering "Kémiai Nobel-díj" (Nobel Prize in chemistry) as title of query No. 448 yields would yield the English terms shown in Table <ref type="table" coords="7,300.81,689.64,3.87,9.96" target="#tab_0">1</ref>. Note that because "nobel díj" was correctly recognized as a multiword Hungarian phrase, its various English translations (the stranger ones, like "nobelprize" coming from Wikipedia) were registered for text positions 2 and 3 as they are competing with translations assigned to individual words present at the same places.</p><p>As we can see from this example, the dictionary typically gives a relatively large number of Table <ref type="table" coords="8,180.44,118.22,3.87,9.96">2</ref>: Scores assigned to terms in query title "Kémiai Nobel-díj".</p><p>Term Score Term Score 0.2500 chemistry 0.0014 nobel prise mathematics 0.2500 nobelprizeorg 0.0012 premium 0.0314 award 0.0009 trophy 0.0157 nobel prise 0.0005 prize 0.0157 noble prise 0.0004 blue ribbon 0.0041 nobel 0.0002 stake 0.0026 charge 0.0000 awards 0.0020 due 0.0000 nobelprize 0.0020 nobel award 0.0000 nobelist 0.0020 nobel price 0.0000 remuneration possible translations, whose majority is evidently wrong, and can be easily ltered out if we are able to detect that they are not present inside their typical context. Fortunately, language modeling provide a simple yet very ecient tool to help us in this respect, namely bigram statistics. The P w,v values computed during pre-processing species the probability that word w is followed by word v, based on the analysis of a large corpus (roughly 1,600,000 Wikipedia article bodies). Let us now assume that query text contains words A and B, which can be translated to A 1 or A 2 , and B 1 or B 2 , respectively. If probability of A 1 and B 2 appearing as a bigram is signicantly higher than those of the other three combinations, of course they should be chosen as the most probably valid translation. However, since terms being immediately near each other in the Hungarian version may be far apart in the corresponding English sentence, we have to tread carefully. Our technique is the following. We pair each English terms present in the same sentence with each other in every imaginable combination (but naturally a term is never aligned with itself), and assign scores to them computed according to the formula:</p><formula xml:id="formula_1" coords="8,207.13,461.07,305.88,15.33">S t = max u∈S∧u =t max P t last ,u f irst , P t f irst ,u last<label>(2)</label></formula><p>where t f irst denotes the rst word of term t, while t last stands for its last word. To put it more intuitively, we characterize term t with the P value corresponding to the most probable bigram it participates in. This approach works well here since sentences are fairly short, obviously, if we would be dealing with longer ones, we should specify a maximal distance between t and u, otherwise the greatly increased amount of examined term pairs would surely introduce an unacceptably strong noise. Terms in the query title discussed above receive the scores shown in Table <ref type="table" coords="8,471.63,543.54,3.87,9.96">2</ref>. As can be seen, highest ranked translations were "chemistry" and "nobelprizeorg" (derived from the web address nobelprize.org), while "awards", "nobelprize", "nobelist", "remuneration" did not form any meaningful pair with other terms, at least not according to Wikipedia articles.</p><p>After candidate English translations have been retrieved and scored, we can go through all text locations examining the terms attached to them, retaining only the highest ranked ones. It should be stressed that since several terms may get exactly the same score, ambiguous translations will be not necessarily resolved at this time (our goal now is merely to produce a raw translation).</p><p>Finally, let us answer the question what happens if a Hungarian words is not in the dictionary, since it is a proper name, technical term or a particular form of a verb or noun which was not properly reduced by the Hungarian stemmer <ref type="bibr" coords="8,293.42,663.09,14.61,9.96" target="#b12">[13]</ref>. There are two cases. If the word occurs in Wikipedia article bodies, it does not need any translation (the probability of a Hungarian word accidentally being the same to an English word, letter by letter, is extremely low). However, if it does not, we ignore it, as documents in the collection we will search using the current query will surely not contain it remember that during pre-processing (see Section 2.3) we deleted words from documents which we did not encountered in Wikipedia. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Improving translation quality with Wikipedia</head><p>The quality of raw translation of a query title is often too low to directly submit it to the search engine for two main reasons: (1) there are still words whose English variants was not selected unambiguously, because their score was equal; and (2) it might happen that the concept most appropriate for retrieval is not present among concepts recognized in the query title, but rather it can be found among those connected to the query description or narrative. Thus we rst map words and word sequences inside the English translation to Wikipedia concepts; score these concepts mainly based on how strongly they are related semantically to other concepts also recognized in the nally compose a new query extracting words from concepts having the highest scores. Outline of our algorithm is shown in Figure <ref type="figure" coords="9,323.96,436.48,3.87,9.96">3</ref>. It should be emphasized, however, that introducing mapping has also a few drawbacks besides its many advantages Wikipedia deals primarily with complex concepts, basic nouns and verbs (e. g. "read", "day") are missing from it; and an additional conversion layer naturally introduces more noise into the processing. Let us see now the various steps in more detail. In the rst step, we look for Wikipedia article titles (representing concepts) exactly matching a word sequences in the English translation, again requiring that these sequences be continuous and do not span paragraph boundaries. Because CLEF-2007 queries rarely mention multiword terms and if they do, the terms are mostly phrases from everyday English which are present in the machine readable dictionary , Wikipedia concepts typically do not encompass more than one term. However, it may happen that due to the limitations of the dictionary a name of some person (for instance Richard Nixon) or company (e. g. Nestlé Foods) is translated in a word by word fashion, while Wikipedia contains an appropriate article. So we should allow that Wikipedia article titles cover many terms, but at the same time also demand that these terms immediately follow each other. This way "John Smith" will be correctly recognized as John Smith, but our algorithm will not retrieve it for "John met Smith".</p><p>Next, we collect actual Wikipedia articles, in other words concepts, behind the Wikipedia article titles discovered previously. Note that as a consequence of redirects, stemming, stopword removal and deletion of auxiliary descriptors (between parentheses or after a comma, slash, semicolon), a given title often points to several concepts for example "power" to "Political Power", "Power (electricity)", "Power (physics)" etc). So besides ambiguity originating from raw translation, we are now saddled with ambiguity arising from title-concept mapping. Still, results discussed in Section 6 will prove that the scoring formula soon introduced is able to relatively eectively select the best candidate, no matter how high their number is.</p><p>In the third step, for each candidate concept c we determine the R c set of other candidate concepts related to it, now not necessarily from the same paragraph. Remember that two concepts are considered semantically related if the body of either one contains a hyperlink reference to the other. However, if the two concepts have the same title, they are alternative (and competing) interpretations of the same word sequence, and obviously cannot support each other during later analysis, so this sort of connection is ignored. Concepts without any connections are discarded, as they probably do not pertain to the query subject. Still, this is not necessarily true in the reverse direction: just because a concept has at least one connection does not automatically mean that it is about the query topic, as it may be easily related to a similarly inappropriate concept.</p><p>In the fourth step, we assign scores to candidate concepts according to the following simple formula to estimate their relevance to the query subject:</p><formula xml:id="formula_2" coords="10,250.31,409.38,262.69,23.22">S c = L c × 1 1 + M c × F c<label>(3)</label></formula><p>In order to simplify explanation of the above calculation, lets introduce the term "c is attached to text position p", meaning that p is occupied by a word being part of a word sequence through which c has been recognized in the rst step. L c denotes the number of text locations to which concepts related to c are attached; M c is the number of concepts c competes with (some concept is a competitor if it is attached to at least one text location to which c is also attached); and nally F c species the amount of text locations to which c is attached.</p><p>To put it more informally, L c measures how strongly concept c correlates to the whole query description the reason we deal with text positions and not with candidate concepts is that we would like to avoid Wikipedia titles attracting a high number of concepts to gain undeservedly large inuence over the disambiguation process. M c estimates reliability of c: if c has no competitors (the words it covers do not have alternative interpretations), it is almost surely correct, but if it conicts with many other candidates, the probability that it will be chosen as the best translation is lower. F c corresponds to the popular and widely used TF term frequency value, and thus emphasizes (or suppresses) the relevance of c not in relation to its competitors, like L c , but rather to concepts attached to dierent word sequences. Table <ref type="table" coords="10,342.13,604.99,4.98,9.96" target="#tab_1">3</ref> shows scores of concepts attached to the content of query No. 448 about the Nobel Prize in Chemistry.</p><p>After we ranked candidate concepts, we are ready to map them back to English words in step ve. However, instead of simply choosing the few highest ranked concepts and pasting their titles one after the other to form a new query, we follow a slightly more sophisticated approach, and introduce another layer of decision by scoring words according to the formula below:</p><formula xml:id="formula_3" coords="10,261.68,688.68,251.32,20.80">S w = l∈Pw∧l∈Qc S c<label>(4)</label></formula><p>where P w represents the set of text locations occupied by word w, and similarly, Q c stands for the set of text locations to which concept c is attached. Thus in the above formula we add up scores of concepts recognized through titles containing w, as many times as the recognition took place, so more frequent words will automatically receive higher scores. Although members of multiword terms might get dierent scores, since they do not necessarily serve as base for exactly the same concepts throughout the query text, this is not always a bad thing, because more signicant words (like "programming" in "programming language", assuming a query about computers) will be emphasized. Table <ref type="table" coords="11,174.44,341.52,4.98,9.96" target="#tab_2">4</ref> shows scores of words, assuming concepts scores shown in Table <ref type="table" coords="11,464.81,341.52,3.87,9.96" target="#tab_1">3</ref>. The query to be submitted for the search engine is formed in the nal, sixth step. Remember that although we translated and analyzed the entire query (its title, description and narrative), we intend to select only a few words, since unfortunately our search engine presently do not cope well with long queries: individual query words cannot be supplemented with weights indicating their relative importance, thus insignicant words can easily distort the hit list. The applied selection heuristic is fairly simple: we retain words which occur in raw translation of the query title or have scores putting them among the top 3 words. In addition, words which appear in the original Hungarian query title but were not translated (since they were present neither in the machine readable dictionary nor in Wikipedia) are also kept.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Search engine</head><p>We use the Hungarian Academy of Sciences search engine <ref type="bibr" coords="11,344.16,503.88,10.51,9.96" target="#b1">[2]</ref> as our information retrieval system. Its ranking algorithm was developed originally for HTML pages; it uses a TF × IDF -based ranking with increased weights for query words within URLs, anchor texts, the title and additional signicant HTML elements. More precisely, the relevance score is computed from the weighted combination of the following factors:</p><p>• traditional TF × IDF -based ranking which takes into account how close are the query terms to each other in documents <ref type="bibr" coords="11,238.14,585.57,15.49,9.96" target="#b23">[24,</ref><ref type="bibr" coords="11,257.18,585.57,7.01,9.96" target="#b4">5]</ref>, utilizes document length normalization <ref type="bibr" coords="11,445.48,585.57,14.61,9.96" target="#b25">[26]</ref>, and places stronger emphasis on query terms found in the document title than those appearing in the document body.</p><p>• Number of dierent query terms in the document.</p><p>• The coverage of the rst and the last query term occurrence. This is the proportion of the document between the rst and last query term. It is almost 1 if the document contains query terms at the beginning and at the end, and 1 / size if there is only one query term.</p><p>In contrast to the original version, here we do not require that a document contain all the query words in order to include it in the resulting hit list.</p><p>This ranking method had several parameters: weights of the TF × IDF score and the number of query words and the query term coverage, weights of the title and body. After several runs with dierent settings, we have found that we get the best result if the weight of the number of query terms is much higher than the TF × IDF score. In other words, we rank documents with respect to the number of query terms found inside their text, then use the TF × IDF -based measurement to dierentiate between documents carrying the same number of query terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>After the detailed description of our proposed algorithm let us see how well it performed in practice.</p><p>For the experiments, we used the Wikipedia snapshot taken in August of 2006; as the result of various pre-processing procedures, it contained 1,728,641 concepts reachable through 2,184,226 dierent titles. The target corpus, the Los Angeles Times 2002 collection comprised of 86,002 news articles, in which documents relevant to 50 queries had to be retrieved. Each query was submitted to our search engine in three dierent versions:</p><p>• using words in the ocial English translation of query titles;</p><p>• using words in the raw translation of original Hungarian query titles;</p><p>• using words selected by our algorithm.</p><p>The rst batch of queries served as a baseline; the second helped us estimate how well (or badly) raw translation worked; and the last demonstrated how much improvement could be achieved by the concept mapping and remapping utilizing Wikipedia. Table <ref type="table" coords="12,371.62,357.40,4.98,9.96" target="#tab_3">5</ref> shows exact texts of queries in the three batches in order to keep the presentation as possible, in cases where a query contained more than four words, only the rst four is shown, rest is represented by an ellipsis. As we can see, even the raw translation managed to provide a perfect translation for several queries, however, in the majority of cases it made mistakes, which can be classied in ve main groups:</p><p>• translated words are the same but are in a dierent grammatical form (see for example "human cloning" vs. "human clone" in query No. 408);</p><p>• translated words are synonyms of the original ones (e. g. "Australian" vs. the more informal "Aussie" in the immediately preceding query, No. 407);</p><p>• bigram statistics derived from the Wikipedia corpus was not enough to properly disambiguate possible translations (see query No. 433);</p><p>• the Hungarian stemmer failed to determine the root form of a word (as happened in the case of "drogoz", "drug" in English, in query No. 415);</p><p>• the dictionary failed to provide any translation for a given word (see for instance "weapon" inside query No. 410, which should have been recognized indirectly from "atomsorompó").</p><p>Translations aligned with Wikipedia concepts are usually more verbose than raw translations, and frequently introduce synonyms (like in query No. 412) or sometimes even downright strange words (such as in query No. 414), probably because the query text does not provide a suciently large textual body to reliably determine the dominant topic. However, these query versions often bring back important keywords lost during raw translation see for instance "cancer" in query No. 438, or "priest" in query No. 433). As a result, though precision at 5 retrieved documents were only 14.66% for raw translations, a fraction of the 33.31% observed when using ocial English translations, Wikipedia post-processing managed to increase precision to 16.45% (the values reect the search engine setting which yielded the best accuracy). Figure <ref type="figure" coords="12,452.94,684.17,4.98,9.96" target="#fig_3">4</ref> shows more detailed information about the performance.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion and future work</head><p>In this paper we have demonstrated that a concept network extracted from the Wikipedia online encyclopedia can be used to improve the quality of machine translation of CLEF queries supplemented by narratives thus making accurate cross-lingual information retrieval feasible.</p><p>As experiments performed on the Los Angeles Times 2002 corpus have shown, our proposed algorithm works well only if it is supported by a reliable stemmer, suciently rich dictionary, and a relatively long text describing the purpose of the query. However, when these conditions are met, adequate precision can be achieved even with a very simple machine translation approach. Obviously, there are several points where our method can be (and should be) improved. First of all, we plan to test it against language pairs other than Hungarian-English German-English translation is particularly promising, as for this combination an extremely rich concept mapping is available inside Wikipedia. Second, we have to make disambiguation during raw translation more aggressive, and less dependent on the quality of stemmer which is used for the source or target language. Third, semantic relationships between Wikipedia articles could be derived from additional sources, not only from hyperlinks, such as category assignments and similarity of text of actual article bodies. Finally, we may easily re-order query results by detecting Wikipedia concepts in their text and comparing them to the concepts recognized in the query.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,208.63,430.20,185.74,9.96;5,101.34,112.25,397.00,304.50"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Fragment of a Wikipedia article.</figDesc><graphic coords="5,101.34,112.25,397.00,304.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,192.17,387.20,218.65,9.96;6,101.59,112.25,396.50,260.50"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Fragment of a Wikipedia category page.</figDesc><graphic coords="6,101.59,112.25,396.50,260.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="9,212.41,287.20,178.17,9.96"><head>1 .Figure 3 :</head><label>13</label><figDesc>Figure 3: Outline of proposed algorithm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="14,90.00,376.91,423.00,9.96;14,90.00,388.87,264.94,9.96"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Interpolated recall vs. average precision when using ocial English translations, raw translations or Wikipedia-enhanced translations as queries. .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,90.00,118.22,407.33,161.29"><head>Table 1 :</head><label>1</label><figDesc>English terms attached to query title "Kémiai Nobel-díj".</figDesc><table coords="7,90.00,139.88,407.33,139.62"><row><cell cols="3">Text position Hungarian word Attached translations</cell></row><row><cell></cell><cell>1 kémia</cell><cell>chemistry</cell></row><row><cell></cell><cell>2 nobel</cell><cell>nobel; nobel award, nobel price, nobel prise, nobel prise,</cell></row><row><cell></cell><cell></cell><cell>mathematics, noble prise, nobelprize, nobelprizeorg,</cell></row><row><cell></cell><cell></cell><cell>nobelist</cell></row><row><cell></cell><cell>3 díj</cell><cell>award, blue ribbon, charge, due, premium, prize,</cell></row><row><cell></cell><cell></cell><cell>remuneration, stake, trophy; nobel award, nobel price,</cell></row><row><cell></cell><cell></cell><cell>nobel prise, nobel prise mathematics, noble prise,</cell></row><row><cell></cell><cell></cell><cell>nobelprize, nobelprizeorg, nobelist</cell></row><row><cell>2.3</cell><cell cols="2">Pre-processing queries and documents</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="10,161.21,118.22,280.57,163.53"><head>Table 3 :</head><label>3</label><figDesc>Scores assigned to concepts mined from query No. 448.</figDesc><table coords="10,209.92,139.88,179.83,141.86"><row><cell>Score Concept</cell></row><row><cell>3.3333 Nobel Prize</cell></row><row><cell>3.0000 Ludvig Nobel</cell></row><row><cell>3.0000 Alfred Nobel</cell></row><row><cell>3.0000 Academia</cell></row><row><cell>2.0000 Chemistry</cell></row><row><cell>1.6667 Nobel Prize in Literature</cell></row><row><cell>1.0000 Fundraising</cell></row><row><cell>1.0000 Work (thermodynamics)</cell></row><row><cell>1.0000 Employment</cell></row><row><cell>0.6667 Award 1002</cell></row><row><cell>0.4000 Miguel de Espriella -"Noble"</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="11,186.14,118.22,230.72,151.57"><head>Table 4 :</head><label>4</label><figDesc>Scores of words occurring in query No. 448.</figDesc><table coords="11,248.18,139.88,99.99,129.91"><row><cell>Score Word</cell></row><row><cell>31.3333 nobel</cell></row><row><cell>13.3333 prise</cell></row><row><cell>7.0667 noble</cell></row><row><cell>4.0000 chemistry</cell></row><row><cell>3.3333 mathematics</cell></row><row><cell>3.0000 scholarly</cell></row><row><cell>3.0000 academic</cell></row><row><cell>2.0000 work</cell></row><row><cell>1.0000 contribution</cell></row><row><cell>0.6667 award</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="13,95.98,215.81,434.97,437.52"><head>Table 5 :</head><label>5</label><figDesc>Queries submitted to the search engine.</figDesc><table coords="13,95.98,245.40,434.97,407.92"><row><cell>Qry Ocial translation 401 euro ination 402 renewable energy source 403 act cop 404 nato summit security 405 childhood asthma 406 animate cartoon 407 australian prime minister 408 human cloning 409 bali car bombing 410 north korea nuclear weapon ... 411 best picture oscar 412 book politician 413 reduce diabetes risk 414 beer festival 415 drug abuse 416 moscow theatre hostage crisis 417 airplane hijacking 418 bulent ecevit statement 419 nuclear waste repository 420 obesity ill health 421 kostelic olympic medal 422 industrial business closure 423 alternative u shot 424 internet banking increase 425 endangered species 426 9/11 counterterrorism measure 427 testimony milosevic 428 ecological tourism 429 water health risk 430 cosmetic procedure 431 french presidential candidate 432 zimbabwe presidential election 433 child abuse priest 434 political instability venezuela 435 cause air pollution 436 vip divorce 437 enron auditing irregularity 438 cancer research 439 accident work 440 winter olympics doping scandal dopping scandal winter olympics Raw translation euro rise prices power well actor police role nato summit security childhood asthma animated cartoon aussie prime minister premier human clone bali car bomb north korea dpr republic ... lm oscar politic book diabetes hazard mitigation beer festival drogoz hostage crisis moscow theatre air plane hijacking diversion ... bulent ecevit protestation statement ... bulent ecevit revelation turkish ... Improved translation euro rise continental power energy owe actor police role sleuth actress nato summit security north childhood infancy development animated cartoon festival aussie minister premier prime 2002 clone human embryo medical ... bali car bomb indonesian north people korea democratic ... lm oscar movie politic book political hazard mitigation play form ... beer festival john space drug dependence consumerism hostage crisis moscow theatre send ... plane aeroplane hijacking diversion ... atom feed cutting cemetery atom cemetery waste prevailing hygienic problem hygienic problem disease number kostelic pendent pendant olympics win event kostelic ivica factory business cessation factory business mill shutdown u immunization alternative alternative method detail give international network bank network international bank information endangered species illegal person activity 11th sept 2001 aftermath ... 11 sept 2001 terrorism ... milosevics testimony deposition testimony deposition witness beloved blank safari park park safari tourism polluted water hazard polluted water sanitary cosmetic procedures cosmetic surgical intervention french president nominee french president nominee party zimbabwean presidential zimbabwean presidential 2002 latvian divine sexually child divine sexually child priest ... politics doubt venezuelan politics doubt venezuelan president air pollution ground air pollution ground smog vip breakup break divorce vip break divorce actor ... accounting irregularity irregularity accounting enron auditor oncology oncology cancer treatment workplace accident scandal winter jock 441 space tourist russian expedition candidate russian expedition person cosmonaut 442 queen mother funeral mother queen funeral mother queen funeral 443 world swimming record oat all time high oat cork sport meter 444 brazil world soccer champion brasil footballer world champion ... brasil footballer champion world ... 445 prince harry drug harry prince drug prince drug controversy 446 ood damage cultural heritage ood damage cultural heritage damage ood cultural heritage 447 pim fortuyn politics archimedes constant fortuyn policy constant archimedes fortuyn political ... 448 nobel prize chemistry chemistry nobel award nobelprizeorg ... chemistry nobel prise award ... 449 civil war africa africa civil war africa war civil african ... 450 failed assassination attempt abortive attempt abortive person target</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0" coords="14,110.48,743.41,258.19,11.20"><p>Proceedings of the 12th World Wide Web Conference, 2003.</p></note>
		</body>
		<back>

			<div type="funding">
<div><p>* This work was supported by a <rs type="grantName">Yahoo! Faculty Research Grant</rs> and by grants <rs type="grantNumber">MOLINGV NKFP-2/0024/2005</rs>, <rs type="grantNumber">NKFP-2004</rs> project Language Miner http://nyelvbanyasz.sztaki.hu.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_MNy3ee5">
					<idno type="grant-number">MOLINGV NKFP-2/0024/2005</idno>
					<orgName type="grant-name">Yahoo! Faculty Research Grant</orgName>
				</org>
				<org type="funding" xml:id="_Zmcgf48">
					<idno type="grant-number">NKFP-2004</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="14,110.48,676.60,402.53,9.96;14,110.48,687.62,402.53,11.20;14,110.48,699.58,310.58,11.20" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="14,311.90,676.60,201.10,9.96;14,110.48,688.55,84.25,9.96">Finding similar sentences across multiple languages in wikipedia</title>
		<author>
			<persName coords=""><forename type="first">Sisay</forename><surname>Fissaha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adafre</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,217.29,687.62,295.71,11.20;14,110.48,699.58,280.43,11.20">Proceedings of the New Text Workshop, 11th Conference of the European Chapter of the Association for Computational Linguistics</title>
		<meeting>the New Text Workshop, 11th Conference of the European Chapter of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,110.48,720.43,402.52,9.96;14,110.48,732.39,402.52,9.96" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="14,247.38,732.39,245.73,9.96">Searching a small national domain preliminary report</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>András</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Károly</forename><surname>Benczúr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eszter</forename><surname>Csalogány</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dániel</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tamás</forename><surname>Fogaras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Máté</forename><surname>Sarlós</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eszter</forename><surname>Uher</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Windhager</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.48,111.35,402.53,9.96;15,110.48,123.31,402.52,9.96;15,110.48,134.33,292.95,11.20" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="15,404.39,123.31,108.61,9.96;15,110.48,135.27,84.74,9.96">A statistical approach to machine translation</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><forename type="middle">A</forename><surname>Cocke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vincent</forename><forename type="middle">J</forename><surname>Della Pietra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fredrick</forename><surname>Della Pietra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><forename type="middle">D</forename><surname>Jelinek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Laerty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><forename type="middle">S</forename><surname>Mercer</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Roossin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,203.79,134.33,113.05,11.20">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">7985</biblScope>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.48,155.19,402.53,9.96;15,110.48,166.21,402.52,11.20;15,110.48,178.17,314.71,11.20" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="15,272.11,155.19,240.90,9.96;15,110.48,167.15,108.84,9.96">Applying statistical english language modeling to symbolic machine translation</title>
		<author>
			<persName coords=""><forename type="first">Ralf</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><surname>Frederking</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,240.39,166.21,272.60,11.20;15,110.48,178.17,216.23,11.20">Proceedings of the 6th International Conference on Theoretical and Methodological Issues in Machine Translation</title>
		<meeting>the 6th International Conference on Theoretical and Methodological Issues in Machine Translation</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page">221239</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.48,199.03,402.53,9.96;15,110.48,210.05,402.52,11.20;15,110.48,222.01,402.52,11.20;15,110.48,234.89,126.47,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="15,366.20,199.03,146.80,9.96;15,110.48,210.98,163.11,9.96">Term proximity scoring for ad-hoc retrieval on very large text collections</title>
		<author>
			<persName coords=""><forename type="first">Stefan</forename><surname>Büttcher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Brad</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Lushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,294.18,210.05,218.82,11.20;15,110.48,222.01,309.63,11.20">Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 29th annual international ACM SIGIR conference on Research and development in information retrieval<address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page">621622</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.48,254.82,402.53,9.96;15,110.48,265.84,402.53,11.20;15,110.48,277.80,118.77,11.20" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="15,298.06,254.82,214.94,9.96;15,110.48,266.77,73.11,9.96">Syntax-based language models for statistical machine translation</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Charniak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Yamada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,211.16,265.84,301.84,11.20;15,110.48,277.80,88.41,11.20">Proceedings of the 9th Summit if the International Association for Machine Translation</title>
		<meeting>the 9th Summit if the International Association for Machine Translation</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.48,297.72,402.52,11.20;15,110.48,310.61,181.25,9.96" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="15,272.54,297.72,198.51,11.20">Language Modeling for Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">W</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Laerty</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>Norwell, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.48,329.60,402.53,11.20;15,110.48,342.49,38.73,9.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="15,286.26,330.53,111.33,9.96">The wikipedia xml corpus</title>
		<author>
			<persName coords=""><forename type="first">Ludovic</forename><surname>Denoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Patrick</forename><surname>Gallinari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,406.32,329.60,57.81,11.20">SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="64" to="69" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.48,361.48,402.52,11.20;15,110.48,373.44,139.70,11.20" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="15,186.13,362.41,279.42,9.96">The use of lexical semantics in interlingual machine translation</title>
		<author>
			<persName coords=""><forename type="first">Bonnie</forename><forename type="middle">J</forename><surname>Dorr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,476.07,361.48,36.93,11.20;15,110.48,373.44,47.92,11.20">Machine Translation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">135193</biblScope>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.47,394.29,245.23,9.96;15,372.65,394.29,63.22,9.96;15,452.80,394.29,60.20,9.96;15,110.48,406.25,101.67,9.96" xml:id="b9">
	<monogr>
		<ptr target="http://szotar.sztaki.hu" />
		<title level="m" coord="15,110.47,394.29,245.23,9.96;15,372.65,394.29,59.09,9.96">Számítástechnikai és Automatizálási Kutató Intézet. Sztaki szótár</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.47,426.17,402.52,9.96;15,110.48,437.20,402.52,11.20;15,110.48,449.15,265.04,11.20" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="15,303.21,426.17,209.78,9.96;15,110.48,438.13,219.24,9.96">An approach to conceptual text retrieval using the EuroWordNet multilingual semantic database</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gilarranz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Verdejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,355.77,437.20,157.23,11.20;15,110.48,449.15,234.89,11.20">Proceedings of the AAAI-96 Spring Symposium Cross-Language Text and Speech Retrieval</title>
		<meeting>the AAAI-96 Spring Symposium Cross-Language Text and Speech Retrieval</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.47,469.08,402.53,11.20;15,110.48,481.97,89.09,9.96" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="15,190.54,470.01,174.16,9.96">A bit of progress in language modeling</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">T</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,377.24,469.08,130.94,11.20">Computer Speech &amp; Language</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">403434</biblScope>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.47,501.89,402.52,9.96;15,110.48,512.91,402.53,11.20;15,110.48,524.87,76.75,11.20" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="15,139.02,513.85,89.48,9.96">A szószablya projekt</title>
		<author>
			<persName coords=""><forename type="first">Péter</forename><surname>Halácsy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">András</forename><surname>Kornai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">László</forename><surname>Németh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">András</forename><surname>Rung</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">István</forename><surname>Szakadát</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Viktor</forename><surname>Trón</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,250.45,512.91,262.55,11.20;15,110.48,524.87,46.13,11.20">Proceedings of the 1st Hungarian Computational Linguistics Conference</title>
		<meeting>the 1st Hungarian Computational Linguistics Conference</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.47,545.73,402.52,9.96;15,110.48,556.75,402.53,11.20;15,110.48,568.71,246.73,11.20" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="15,290.52,545.73,222.47,9.96;15,110.48,557.68,128.94,9.96">A domain specic lexicon acquisition tool for crosslanguage information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Jong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,258.55,556.75,254.45,11.20;15,110.48,568.71,148.41,11.20">Proceedings of the RIAO Conference on Computer Assisted Information Searching on Internet</title>
		<meeting>the RIAO Conference on Computer Assisted Information Searching on Internet</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page">255270</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.47,589.56,402.53,9.96;15,110.48,600.59,402.52,11.20;15,110.48,612.54,295.18,11.20" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="15,291.89,589.56,221.11,9.96;15,110.48,601.52,67.86,9.96">Disambiguation strategies for cross-language information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Djoerd</forename><surname>Hiemstra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Franciska</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jong</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,197.59,600.59,315.41,11.20;15,110.48,612.54,136.74,11.20">Proceedings of the Third European Conference on Research and Advanced Technology for Digital Libraries</title>
		<meeting>the Third European Conference on Research and Advanced Technology for Digital Libraries<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page">274293</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.47,632.47,402.52,11.20;15,110.48,645.35,51.73,9.96" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="15,291.89,632.47,171.23,11.20">An Introduction to Machine Translation</title>
		<author>
			<persName coords=""><forename type="first">W</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Hutchins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Harold</forename><forename type="middle">L</forename><surname>Somers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.47,665.28,402.53,9.96;15,110.48,676.30,402.52,11.20;15,110.48,689.19,63.64,9.96" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="15,261.83,665.28,251.17,9.96;15,110.48,677.23,23.72,9.96">Building a large-scale knowledge base for machine translation</title>
		<author>
			<persName coords=""><forename type="first">Kevin</forename><surname>Knight</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steve</forename><forename type="middle">K</forename><surname>Luk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,160.20,676.30,319.99,11.20">Proceedings of the twelfth National Conference on Articial Intelligence</title>
		<meeting>the twelfth National Conference on Articial Intelligence</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page">773778</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.47,709.11,402.53,9.96;15,110.48,720.14,402.52,11.20;15,110.48,733.02,89.09,9.96" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="15,346.72,709.11,166.28,9.96;15,110.48,721.07,199.00,9.96">Transitive dictionary translation challenges direct dictionary translation in CLIR</title>
		<author>
			<persName coords=""><forename type="first">Raija</forename><surname>Lehtokangas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eija</forename><surname>Airio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kalervo</forename><surname>Järvelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,325.44,720.14,182.27,11.20">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">973988</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,110.47,111.35,402.53,9.96;16,110.48,123.31,402.52,9.96;16,110.48,135.27,22.69,9.96" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="16,163.35,111.35,317.65,9.96">Ontology development for machine translation: Ideology and methodology</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mahesh</surname></persName>
		</author>
		<idno>MCCS 96-292</idno>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
		<respStmt>
			<orgName>Computing Research Laboratory, New Mexico State University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="16,110.47,155.19,402.53,9.96;16,110.48,166.21,354.31,11.20" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="16,338.84,155.19,174.17,9.96;16,110.48,167.15,150.62,9.96">Ontology learning and its application to automated terminology translation</title>
		<author>
			<persName coords=""><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paola</forename><surname>Velardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aldo</forename><surname>Gangemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,269.66,166.21,108.00,11.20">IEEE Intelligent Systems</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">2231</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,110.47,187.07,402.53,9.96;16,110.48,198.10,402.53,11.20;16,110.48,210.98,231.27,9.96" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="16,333.65,187.07,175.19,9.96">On knowledge-based machine translation</title>
		<author>
			<persName coords=""><forename type="first">Sergei</forename><surname>Nirenburg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Allen</forename><surname>Victor Raskin</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,122.10,198.10,265.09,11.20">Proceedings of the 11th coference on Computational linguistics</title>
		<meeting>the 11th coference on Computational linguistics<address><addrLine>Morristown, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page">627632</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,110.47,230.91,402.53,9.96;16,110.48,242.86,325.39,9.96" xml:id="b21">
	<monogr>
		<title level="m" type="main" coord="16,291.22,230.91,169.56,9.96">A survey of multilingual text retrieval</title>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bonnie</forename><forename type="middle">J</forename><surname>Dorr</surname></persName>
		</author>
		<idno>UMIACS-TR-96-19</idno>
		<imprint>
			<date type="published" when="1996">1996</date>
		</imprint>
		<respStmt>
			<orgName>University of Maryland at College Park</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="16,110.47,261.86,402.52,11.20;16,110.48,273.81,93.57,11.20" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="16,304.21,262.79,175.17,9.96">Trends in the evolution of the public web</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">T</forename><surname>O'neill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">F</forename><surname>Lavoie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Bennett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="16,488.03,261.86,24.97,11.20;16,110.48,273.81,38.91,11.20">D-Lib Magazine</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,110.47,294.67,402.53,9.96;16,110.48,305.69,402.53,11.20;16,110.48,318.58,63.64,9.96" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="16,256.02,294.67,252.43,9.96">Term proximity scoring for keyword-based retrieval systems</title>
		<author>
			<persName coords=""><forename type="first">Yves</forename><surname>Rasolofo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,123.98,305.69,356.01,11.20">Proceedings of the 25th European Conference on Information Retrieval Research</title>
		<meeting>the 25th European Conference on Information Retrieval Research</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page">207218</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,110.47,337.57,402.53,11.20;16,110.48,349.53,334.43,11.20" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="16,186.19,338.50,243.09,9.96">Probabilistic part-of-speech tagging using decision trees</title>
		<author>
			<persName coords=""><forename type="first">Helmut</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,451.34,337.57,61.66,11.20;16,110.48,349.53,304.08,11.20">Proceedings of the International Conference on New Methods in Language Processing</title>
		<meeting>the International Conference on New Methods in Language Processing</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="16,110.47,370.38,402.52,9.96;16,110.48,382.34,360.66,9.96" xml:id="b25">
	<monogr>
		<title level="m" type="main" coord="16,402.37,370.38,110.63,9.96;16,110.48,382.34,58.09,9.96">Pivoted document length normalization</title>
		<author>
			<persName coords=""><forename type="first">Amit</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mandar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gerard</forename><surname>Salton</surname></persName>
		</author>
		<idno>TR95-1560</idno>
		<imprint>
			<date type="published" when="1995">1995</date>
			<pubPlace>Ithaca, NY</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Cornell University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="16,110.47,402.26,402.53,9.96;16,110.48,413.29,402.53,11.20;16,110.48,426.17,63.64,9.96" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="16,473.43,402.26,39.57,9.96;16,110.48,414.22,39.84,9.96">Semantic wikipedia</title>
		<author>
			<persName coords=""><forename type="first">Max</forename><surname>Völkel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Markus</forename><surname>Krötzsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Denny</forename><surname>Vrandecic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Heiko</forename><surname>Haller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rudi</forename><surname>Studer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="16,174.89,413.29,304.63,11.20">Proceedings of the 15th international conference on World Wide Web</title>
		<meeting>the 15th international conference on World Wide Web</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page">585594</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
