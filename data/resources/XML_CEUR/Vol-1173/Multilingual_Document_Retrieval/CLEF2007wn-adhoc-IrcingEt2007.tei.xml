<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,98.02,148.86,406.96,15.15;1,107.30,170.78,388.40,15.15;1,116.37,192.69,370.26,15.15">Czech Monolingual Information Retrieval Using Off-The-Shelf Components -the University of West Bohemia at CLEF 2007 Ad-Hoc track</title>
				<funder ref="#_64mDpwU">
					<orgName type="full">Ministry of Education of the Czech Republic</orgName>
				</funder>
				<funder ref="#_hxEN3dR">
					<orgName type="full">Grant Agency of the Czech Academy of Sciences</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,234.78,226.59,51.92,8.74"><forename type="first">Pavel</forename><surname>Ircing</surname></persName>
							<email>ircing@kky.zcu.cz</email>
							<affiliation key="aff0">
								<orgName type="institution">University of West Bohemia</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,309.39,226.59,58.83,8.74"><forename type="first">Luděk</forename><surname>Müller</surname></persName>
							<email>muller@kky.zcu.cz</email>
							<affiliation key="aff0">
								<orgName type="institution">University of West Bohemia</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,98.02,148.86,406.96,15.15;1,107.30,170.78,388.40,15.15;1,116.37,192.69,370.26,15.15">Czech Monolingual Information Retrieval Using Off-The-Shelf Components -the University of West Bohemia at CLEF 2007 Ad-Hoc track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A763CA91EB493C806B882E294434CD56</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H</term>
					<term>3 [Information Storage and Retrieval]: H</term>
					<term>3</term>
					<term>1 Content Analysis and Indexing; H</term>
					<term>3</term>
					<term>3 Information Search and Retrieval Monolingual Ad-Hoc Information Retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The paper provides a brief description of the system assembled for the CLEF 2007 Ad-Hoc track by the University of West Bohemia. We have performed only monolingual experiments (Czech documents -Czech queries) using two incarnations of the tf.idf model -one with raw term frequency and the other with the BM25 term frequency weighting -as implemented in the Lemur toolkit. The effect of the blind relevance feedback was also explored. Czech morphological analyser and tagger were used for lemmatization and stop word removal. The results achieved seem to be quite reasonable, with MAP ranging from 0.11. to 0.30.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Although our group is mainly interested in the CL-SR track in the CLEF campaign, we could not resist participating in Ad-Hoc once our native language was introduced to the track. Our runs were generated essentially just by putting together off-the-shelf components available either for Czech NLP or general IR. Such seemingly unambitious approach has, however, proven to be quite successful in the past CLEF campaigns. We have performed monolingual Czech experiments only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System description 2.1 Linguistic preprocessing</head><p>Stemming (or lemmatization) is considered to be vital for good IR performance. This assumption was experimentally proven by our group also for the Czech language IR in the last year's CLEF CL-SR track <ref type="bibr" coords="1,147.07,743.53,9.96,8.74" target="#b2">[3]</ref>. Thus we have used the same method of linguistic preprocessing, that is, the serial combination of Czech morphological analyser and tagger <ref type="bibr" coords="2,339.97,112.02,9.96,8.74" target="#b1">[2]</ref>, which provides both the lemma and stem for each input word form, together with a detailed morphological tag. This tag (namely its first position) is used for stop-word removal -we removed from indexing all the words that were tagged as prepositions, conjunctions, particles and interjections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Retrieval</head><p>All our retrieval experiments were performed using the Lemur toolkit <ref type="bibr" coords="2,393.54,194.16,9.96,8.74" target="#b0">[1]</ref>, which offers a variety of retrieval models. We have decided to stick to the tf.idf model where both documents and queries are represented as weighted term vectors</p><formula xml:id="formula_0" coords="2,268.09,218.07,244.92,9.65">d i = (w i,1 , w i,2 , • • • , w i,n ) and q k = (w k,1 , w k,2 , • • • , w k,n ),</formula><p>respectively (n denotes the total number of distinct terms in the collection). The inner-product of such weighted term vectors then determines the similarity between individual documents and queries. There are many different formulas for computation of the weights w i,j , we have tested two of them, varying in the tf component:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Raw term frequency</head><formula xml:id="formula_1" coords="2,259.31,308.08,253.69,23.22">w i,j = tf i,j • log d df j<label>(1)</label></formula><p>where tf i,j denotes the number of occurrences of the term t j in the document d i (term frequency), d is the total number of documents in the collection and finally df j denotes the number of documents that contain t j .</p><p>BM25 term frequency</p><formula xml:id="formula_2" coords="2,219.03,405.04,293.97,26.84">w i,j = k 1 • tf i,j tf i,j + k 1 (1 -b + b l d l C ) • log d df j<label>(2)</label></formula><p>where tf i,j , d and df j have the same meaning as in (1), l d denotes the length of the document, l C the average length of a document in the collection and finally k 1 and b are the parameters to be set.</p><p>The tf components for queries are defined analogously, except for the average length of a query, which obviously cannot be determined as the system is not aware of the full query set and processes one query at a time. The Lemur documentation is however not clear about the exact way of handling the l C value for queries.</p><p>The values of k 1 and b were set according to the suggestions made by <ref type="bibr" coords="2,399.95,522.24,10.52,8.74" target="#b4">[5]</ref> and <ref type="bibr" coords="2,431.48,522.24,9.96,8.74" target="#b3">[4]</ref>, that is k 1 = 1.2 and b = 0.75 for computing document weights and k 1 = 1 and b = 0<ref type="foot" coords="2,386.41,532.62,3.97,6.12" target="#foot_0">1</ref> for query weights.</p><p>We have also tested the influence of the blind relevance feedback. The simplified version of the Rocchio's relevance feedback implemented in Lemur <ref type="bibr" coords="2,321.72,558.11,10.52,8.74" target="#b4">[5]</ref> was used for this purposes. The original Rocchio's algorithm is defined by the formula</p><formula xml:id="formula_3" coords="2,239.88,593.92,122.70,9.65">q new = q old + α • d R -β • d R</formula><p>where R and R denote the set of relevant and non-relevant documents, respectively, and d R and d R denote the corresponding centroid vectors of those sets. In other words, the basic idea behind this algorithm is to move the query vector closer to the relevant documents and away from the non-relevant ones. In the case of blind feedback, the top M documents from the first-pass run are simply considered to be relevant. The Lemur modification of this algorithm sets the β = 0 and keeps only the K top-weighted terms in d R .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Evaluation</head><p>There were 50 topics defined for Ad-Hoc track, in a variety of languages. As we have already mentioned, we have used only the Czech topics for searching Czech documents. The document set consists of electronic versions of articles from two nationwide newspapers (Mladá Fronta Dnes, Lidové Noviny); following the track organisers' instructions, we have indexed only the &lt;TITLE&gt; and &lt;TEXT&gt; fields, in both the original (non-lemmatized) and the lemmatized version.</p><p>The results are summarized in Table <ref type="table" coords="3,272.00,193.62,3.87,8.74" target="#tab_0">1</ref>. The upper section shows the MAP for queries constructed by concatenating the tokens (either words or lemmas) from the &lt;title&gt; and &lt;desc&gt; fields of the topics (TD), the lower section then the results for queries made from all three topic fields, i.e. &lt;title&gt;, &lt;desc&gt; and &lt;narr&gt; (TDN). Both results with (BRF) and without (no FB) application of the blind relevance feedback are shown. The table reveals several findings. First of them is that the length normalization contained in the BM25 formula seems to have an immense effect on the performance -this is probably something not very surprising to an experienced IR researcher, it did however surprise us as we were dealing with documents of approximately uniform length in last year's CL-SR track (again see <ref type="bibr" coords="3,106.71,430.62,10.52,8.74" target="#b2">[3]</ref> for details). What is truly puzzling is the negligible effect of lemmatization for the runs using BM25 term frequency component and TDN queries; especially when you compare those runs with the other "quadrants" of the table.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Raw</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>Our participation in the Ad-Hoc track was motivated mainly by two factors -we wanted to enrich the diversity of the pool of results and we wanted to know how our quite strong experience of dealing with Czech language processing and a rather poor experience of designing IR systems will hold up in competition. While we have hopefully succeeded in the former, we still have no idea how we have done in the latter as the organisers did not publish any cross-site comparison. Thus we look forward to seeing such ranking in the track overview paper.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,118.88,264.10,365.24,103.53"><head>Table 1 :</head><label>1</label><figDesc>MAP of the individual runs -bold runs were submitted for official scoring.</figDesc><table coords="3,184.62,264.10,233.76,71.70"><row><cell></cell><cell></cell><cell></cell><cell>TF</cell><cell>BM25 TF</cell></row><row><cell></cell><cell></cell><cell>no FB</cell><cell>BRF</cell><cell>no FB</cell><cell>BRF</cell></row><row><cell>TD</cell><cell>words</cell><cell cols="3">0.1405 0.1101 0.2053 0.2500</cell></row><row><cell></cell><cell cols="4">lemmas 0.1765 0.1247 0.2569 0.3025</cell></row><row><cell>TDN</cell><cell>words</cell><cell cols="3">0.1491 0.1162 0.2219 0.2480</cell></row><row><cell></cell><cell cols="4">lemmas 0.1869 0.1415 0.2277 0.2405</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,105.24,695.66,309.14,6.99"><p>This is actually not a choice, as the value of b is hard-set to 0 for queries in Lemur.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was supported by the <rs type="funder">Grant Agency of the Czech Academy of Sciences</rs> project No. <rs type="grantNumber">1ET101470416</rs> and the <rs type="funder">Ministry of Education of the Czech Republic</rs> project No. <rs type="grantNumber">LC536</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_hxEN3dR">
					<idno type="grant-number">1ET101470416</idno>
				</org>
				<org type="funding" xml:id="_64mDpwU">
					<idno type="grant-number">LC536</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="3,105.50,690.56,407.50,8.74;3,105.50,702.51,375.49,8.74" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="3,391.72,690.56,121.28,8.74;3,105.50,702.51,183.90,8.74">The Lemur Toolkit for Language Modeling and Information Retrieval</title>
		<ptr target="http://www.lemurproject.org/" />
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University and the University of Massachusetts</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="3,105.50,722.44,407.50,8.74;3,105.50,734.39,111.72,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="3,168.50,722.44,155.69,8.74">Disambiguation of Rich Inflection</title>
		<author>
			<persName coords=""><forename type="first">Jan</forename><surname>Hajič</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,339.75,722.44,168.71,8.74">Computational Morphology of Czech)</title>
		<meeting><address><addrLine>Karolinum, Prague</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,112.02,407.51,8.74;4,105.50,123.98,407.50,8.74;4,105.50,135.93,407.50,8.74;4,105.50,147.89,407.50,8.74;4,105.50,159.84,312.34,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,256.01,112.02,257.00,8.74;4,105.50,123.98,193.86,8.74">Benefit of Proper Language Processing for Czech Speech Retrieval in the CL-SR Task at CLEF 2006</title>
		<author>
			<persName coords=""><forename type="first">Pavel</forename><surname>Ircing</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luděk</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,382.41,135.93,130.59,8.74;4,105.50,147.89,407.50,8.74;4,105.50,159.84,48.71,8.74">Evaluation of Multilingual and Multi-modal Information Retrieval -7th Workshop of the Cross-Language Evaluation Forum, CLEF 2006</title>
		<title level="s" coord="4,162.15,159.84,152.88,8.74">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Gey</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Karlgren</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Magnini</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Oard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Stempfhuber</surname></persName>
		</editor>
		<meeting><address><addrLine>Alicante, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,179.77,407.51,8.74;4,105.50,191.72,156.35,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,279.21,179.77,120.80,8.74">Okapi/Keenbow at TREC-8</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steve</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,424.72,179.77,88.28,8.74;4,105.50,191.72,125.03,8.74">The Eight Text REtrieval Conference (TREC-8)</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,211.65,407.50,8.74;4,105.50,223.60,114.29,8.74" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="4,188.07,211.65,151.26,8.74">Notes on the Lemur TFIDF model</title>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>School of CS, CMU</orgName>
		</respStmt>
	</monogr>
	<note>Note with Lemur 1.9 documentation</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
