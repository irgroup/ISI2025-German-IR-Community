<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,90.87,146.21,421.24,18.08;1,130.68,168.13,341.62,18.08">Applying Query Expansion techniques to Ad Hoc Monolingual tasks with the IR-n system</title>
				<funder ref="#_8nMbyyQ">
					<orgName type="full">Valencia Government</orgName>
				</funder>
				<funder ref="#_DgDjXX3">
					<orgName type="full">Spanish Government</orgName>
				</funder>
				<funder ref="#_3wMtKXu">
					<orgName type="full">European Union</orgName>
					<orgName type="abbreviated">EU</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,224.69,203.19,60.83,10.46"><forename type="first">Elisa</forename><surname>Noguera</surname></persName>
						</author>
						<author role="corresp">
							<persName coords="1,308.21,203.19,70.10,10.46"><forename type="first">Fernando</forename><surname>Llopis</surname></persName>
							<email>llopis@dlsi.ua.es</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Información Departamento de Lenguajes y Sistemas</orgName>
								<orgName type="laboratory">Grupo de investigación en Procesamiento del Lenguaje Natural y Sistemas de</orgName>
								<orgName type="institution">Informáticos</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,90.87,146.21,421.24,18.08;1,130.68,168.13,341.62,18.08">Applying Query Expansion techniques to Ad Hoc Monolingual tasks with the IR-n system</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2AB5DCC840D57D1111798C5E3AC1F20E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.3 Information Search and Retrieval Experimentation</term>
					<term>Performance</term>
					<term>Query Expansion Information Retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The paper describes our participation in Monolingual tasks at CLEF 2007. We submitted results for the following languages: Hungarian, Bulgarian and Czech. We focused on studying different query expansion techniques: Probabilistic Relevance Feedback (PRF) and Mutual Information Relevance Feedback (MI-RF) to improve retrieval performance. After an analysis of our experiments and of the official results at CLEF 2007, we achieved considerably improved scores by using query expansion techniques for different languages (Hungarian, Bulgarian and Czech).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Query expansion (QE) is a technique commonly used in Information Retrieval (IR) <ref type="bibr" coords="1,458.37,577.24,10.52,10.46" target="#b4">[5]</ref> [2] to improve retrieval performance by reformulating the original query adding new terms or re-weighting the original terms. Query expansion terms can be automatically extracted from documents or taken from knowledge resources.</p><p>In our seventh participation at CLEF, we focused on comparing two different query expansion strategies: Probabilistic Relevance Feedback (PRF) and Mutual Information Relevance Feedback (MI-RF). Specifically, we participated in tasks for the following languages: Hungarian, Bulgarian and Czech.</p><p>We used the IR-n system <ref type="bibr" coords="1,218.49,672.88,9.96,10.46" target="#b2">[3]</ref>. It is a Passage Retrieval (PR) system which uses passages with a fixed number of sentences. This provides the passages with some syntactical content.</p><p>This paper is organized as follows: the next section describes the task developed by our system and the training carried out for CLEF 2007. The results obtained are then presented. Finally, we present the conclusions and the future work.</p><p>Query expansion techniques as Relevance Feedback (RF) can substantially improve retrieval effectiveness. Most of the IR systems commonly implemented query expansion techniques. RF is usually performed in the following way:</p><p>• A search using the original query is performed, selecting the n terms from top-ranked documents.</p><p>• The n terms are added to the original query to formulate a new query.</p><p>• The new query is performed to produce a new ranked list of documents.</p><p>An important factor is how to assign the weight to the selected terms with respect to the terms from the initial query. In this work, we compare two formulas in order to calculate this weight (w t ): Probabilistic and Mutual Information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Probabilistic Relevance Feedback (PRF)</head><p>This is the term relevance weighting formula proposed by Robertson and Sparck Jones in <ref type="bibr" coords="2,478.26,322.09,9.96,10.46" target="#b3">[4]</ref>. The relevance weight of term t is given by:</p><formula xml:id="formula_0" coords="2,209.46,354.47,303.54,24.94">w t = (m t + 0.5) • (n -n t -m + m t + 0.5) (m -m t + 0.5) • (n t -m t + 0.5)<label>(1)</label></formula><p>where n is the number of documents in the collection, m is the number of documents considered as relevants (in this case 10 documents), n t is the number of documents which the term t appears and m t is the number of relevant documents in which the term t appears. w t will be better for those terms which have a higher frecuency in the relevant documents than the whole collection. Our system allows two query expansion techniques based on this formula: (1) query expansion based on the most relevant passages or (2) the most relevant documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Mutual Information Relevance Feedback (MI-RF)</head><p>This is based on the idea the co-ocurrence between two terms can determine the semantic relation that exists between them <ref type="bibr" coords="2,202.93,502.44,9.96,10.46" target="#b0">[1]</ref>. The mutual information score grows with the increase in frequency of word co-occurrence. If two words co-occur mainly due to chance their mutual information score will be close to zero. If they occur predominantly individually, then their mutual information will be a negative number. The standard formula for calculating mutual information is:</p><formula xml:id="formula_1" coords="2,239.13,558.73,273.87,24.03">M I(x, y) = log( P (x, y) P (x) • P (y) )<label>(2)</label></formula><p>where P (x, y) is the probability that words x and y occur together; P (x) and P (y) are the probabilities that x and y occur individually. The relevance weight w t of each term t is calculated adding the MI between t and each term of the query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>This section describes the training process carried out in order to obtain the best features to improve the performance of the system. In CLEF 2007, our system participated in the following Monolingual tasks: Hungarian, Bulgarian and Czech.</p><p>The aim of the experimental phase was to set up the optimum value of the input parameters for each collection. CLEF 2005 and 2006 (Hungarian and Bulgarian) collections were used for training. Query expansion techniques were also evaluated for all languages. Here below, we describe the input parameter of the system:</p><p>• Size passage (sp): We established two passage sizes: 8 sentences (normal passage) or 30 sentences (big passage).</p><p>• Weighting model (wm): We use two weighting models: okapi and dfr.</p><p>• Dfr parameters: these are c and avg ld .</p><p>• Query expansion parameters: If exp has value 1, this denotes we use PRF based on passages. If exp has value 2, the PRF is based on documents. And, if exp has value 3, MI-RF query expansion is used. Moreover, np and nd denote the k terms (nd) extracted from the best ranked passages or documents (np) from the original query.</p><p>• Evaluation measure: Mean average precision (avgP) is the evaluation measure used in order to evaluate the experiments. This value was obtained with the 2006 collections.</p><p>Table <ref type="table" coords="3,132.34,271.93,4.98,10.46" target="#tab_0">1</ref> shows the best configuration for each language: The best weighting scheme for Hungarian and Bulgarian was dfr. For Hungarian, we used 30 as passage size. For Bulgarian, we set up 8 as passage size. Finally, the configuration used for Czech was the same as for Hungarian (dfr as weighting scheme and 30 as passage size).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results at CLEF 2007</head><p>We submitted four runs for each language in our participation at CLEF 2007. The best parameters, i.e. those that gave the best results in system training, were used in all cases. This is the description of the runs that we submitted at CLEF 2007:</p><p>• IRnxxyyyyN -xx is the language (BU, HU or CZ) -yyyy is the query expansion (nexp: not used, exp2 : PRF, exp3 : MI-RF).</p><p>-N means the tag narrative was used.</p><p>The official results for each run are showed in Table <ref type="table" coords="3,340.95,629.65,3.87,10.46" target="#tab_1">2</ref>. Like other systems which use query expansion techniques, these models also improve performance with respect to the base system. Our results are appreciably above baseline in all languages. The best percentage of improvement in AvgP is 40.09% for Hungarian.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future Work</head><p>In this eighth CLEF evaluation campaign, we compared different query expansion techniques in our system for Hungarian, Bulgarian and Czech (see Table <ref type="table" coords="3,346.59,732.24,3.87,10.46" target="#tab_0">1</ref>). Specifically, we compare two query The results of this evaluation indicate that for the Hungarian, Bulgarian and Czech our approach proved to be effective (see Table <ref type="table" coords="4,266.39,362.49,4.43,10.46" target="#tab_1">2</ref>) because the results are above baseline.</p><p>For all languages, the best results were obtained using MI-RF (see Table <ref type="table" coords="4,425.68,374.44,3.87,10.46" target="#tab_1">2</ref>).</p><p>In the future we intend to test this approach in other languages such as Spanish. We also intend to study ways of integrating NLP knowledge and procedures into our basic IR system and evaluating the impact.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,157.86,302.71,287.27,103.26"><head>Table 1 :</head><label>1</label><figDesc>Best results obtained with training data CLEF 2006</figDesc><table coords="3,157.86,317.39,287.27,88.57"><row><cell>language</cell><cell cols="3">sp wm C</cell><cell cols="3">avgld exp np nd avgP</cell></row><row><cell cols="2">Hungarian 8</cell><cell>dfr</cell><cell>2</cell><cell>300</cell><cell></cell><cell>0.3182</cell></row><row><cell cols="2">Hungarian 8</cell><cell>dfr</cell><cell>2</cell><cell>300</cell><cell>2</cell><cell>10 10 0.3602</cell></row><row><cell cols="2">Hungarian 8</cell><cell>dfr</cell><cell>2</cell><cell>300</cell><cell>3</cell><cell>10 10 0.3607</cell></row><row><cell>Bulgarian</cell><cell cols="2">30 dfr</cell><cell cols="2">1.5 300</cell><cell></cell><cell>0.1977</cell></row><row><cell>Bulgarian</cell><cell cols="2">30 dfr</cell><cell cols="2">1.5 300</cell><cell>2</cell><cell>10 10 0.2112</cell></row><row><cell>Bulgarian</cell><cell cols="2">30 dfr</cell><cell cols="2">1.5 300</cell><cell>3</cell><cell>10 10 0.2179</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,90.00,117.46,423.02,231.57"><head>Table 2 :</head><label>2</label><figDesc>CLEF 2007 official results. Monolingual tasks.</figDesc><table coords="4,90.00,132.14,423.02,216.89"><row><cell cols="2">Language Run</cell><cell cols="2">AvgP Dif</cell></row><row><cell cols="3">Hungarian IRnHUnexp (baseline) 33.90</cell></row><row><cell></cell><cell>IRnHUexp2</cell><cell>38.94</cell><cell>+14.88%</cell></row><row><cell></cell><cell>IRnHUexp3</cell><cell>39.42</cell><cell>+16.29%</cell></row><row><cell></cell><cell>IRnHUexp2N</cell><cell>40.09</cell><cell>+18.26%</cell></row><row><cell>Bulgarian</cell><cell cols="2">IRnBUnexp (baseline) 21.19</cell></row><row><cell></cell><cell>IRnBUexp2</cell><cell>25.97</cell><cell>+22.57%</cell></row><row><cell></cell><cell>IRnBUexp3</cell><cell>26.35</cell><cell>+24.36%</cell></row><row><cell></cell><cell>IRnBUexp2N</cell><cell>29.81</cell><cell>+40.09%</cell></row><row><cell>Czech</cell><cell cols="2">IRnCZnexp (baseline) 20.92</cell></row><row><cell></cell><cell>IRnCZexp2</cell><cell>24.81</cell><cell>+18.61%</cell></row><row><cell></cell><cell>IRnCZexp3</cell><cell>24.84</cell><cell>+18.76%</cell></row><row><cell></cell><cell>IRnCZexp2N</cell><cell>27.68</cell><cell>+32.36%</cell></row><row><cell cols="4">expansion techniques: Probabilistic Relevance Feedback (PRF) and Mutual Information Relevance</cell></row><row><cell>Feedback (MI-RF).</cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This research has been partially supported by the framework of the project <rs type="projectName">QALL-ME</rs> (<rs type="grantNumber">FP6-IST-033860</rs>), which is a 6th <rs type="programName">Framenwork Research Programme of</rs> the <rs type="funder">European Union (EU)</rs>, by the <rs type="funder">Spanish Government</rs>, project <rs type="projectName">TEXT-MESS</rs> (<rs type="grantNumber">TIN-2006-15265-C06-01</rs>) and by the <rs type="funder">Valencia Government</rs> under project number <rs type="grantNumber">GV06-161</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_3wMtKXu">
					<idno type="grant-number">FP6-IST-033860</idno>
					<orgName type="project" subtype="full">QALL-ME</orgName>
					<orgName type="program" subtype="full">Framenwork Research Programme of</orgName>
				</org>
				<org type="funded-project" xml:id="_DgDjXX3">
					<idno type="grant-number">TIN-2006-15265-C06-01</idno>
					<orgName type="project" subtype="full">TEXT-MESS</orgName>
				</org>
				<org type="funding" xml:id="_8nMbyyQ">
					<idno type="grant-number">GV06-161</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,105.49,555.70,407.51,10.46;4,105.50,567.65,407.50,10.46;4,105.50,579.62,313.91,10.46" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,296.47,555.70,212.52,10.46">Identifying word correspondence in parallel texts</title>
		<author>
			<persName coords=""><forename type="first">William</forename><forename type="middle">A</forename><surname>Gale</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenneth</forename><forename type="middle">W</forename><surname>Church</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,118.92,567.65,318.95,10.46">HLT &apos;91: Proceedings of the workshop on Speech and Natural Language</title>
		<meeting><address><addrLine>Morristown, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1991">1991</date>
			<biblScope unit="page" from="152" to="157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.49,599.54,407.50,10.46;4,105.50,611.50,407.50,10.46;4,105.50,623.45,228.67,10.46" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,180.79,599.54,123.22,10.46">Relevance feedback revisited</title>
		<author>
			<persName coords=""><forename type="first">Donna</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,325.82,599.54,187.18,10.46;4,105.50,611.50,403.66,10.46">SIGIR &apos;92: Proceedings of the 15th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.49,643.37,407.50,10.46;4,105.50,655.33,124.06,10.46" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Llopis</surname></persName>
		</author>
		<title level="m" coord="4,150.76,643.37,303.63,10.46">IR-n: Un Sistema de Recuperación de Información Basado en Pasajes</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>University of Alicante</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="4,105.49,675.25,407.50,10.46;4,105.50,687.21,37.64,10.46" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="4,323.64,675.25,156.86,10.46">Relevance weighting of search terms</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karen</forename><forename type="middle">Sparck</forename><surname>Jones</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="143" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.49,707.13,407.52,10.46;4,105.50,719.09,407.52,10.46;4,105.50,731.05,407.50,10.46" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,241.45,707.13,253.79,10.46">Query expansion using local and global document analysis</title>
		<author>
			<persName coords=""><forename type="first">Jinxi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,105.50,719.09,407.52,10.46;4,105.50,731.05,175.92,10.46">SIGIR &apos;96: Proceedings of the 19th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="4" to="11" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
