<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,90.30,76.47,48.63,12.57">Bengali</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,134.70,114.92,114.92,11.23"><forename type="first">Sivaji</forename><surname>Bandyopadhyay</surname></persName>
							<email>sbandyopadhyay@cse.jdvu.ac.in</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Jadavpur University</orgName>
								<address>
									<postCode>700032</postCode>
									<settlement>Kolkata</settlement>
									<country key="IN">INDIA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,259.36,114.92,94.56,11.23"><forename type="first">Tapabrata</forename><surname>Mondal</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Jadavpur University</orgName>
								<address>
									<postCode>700032</postCode>
									<settlement>Kolkata</settlement>
									<country key="IN">INDIA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,363.37,114.92,108.09,11.23"><forename type="first">Sudip</forename><surname>Kumar Naskar</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Jadavpur University</orgName>
								<address>
									<postCode>700032</postCode>
									<settlement>Kolkata</settlement>
									<country key="IN">INDIA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,157.02,131.78,51.11,11.23"><forename type="first">Asif</forename><surname>Ekbal</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Jadavpur University</orgName>
								<address>
									<postCode>700032</postCode>
									<settlement>Kolkata</settlement>
									<country key="IN">INDIA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,217.04,131.78,84.87,11.23"><forename type="first">Rejwanul</forename><surname>Haque</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Jadavpur University</orgName>
								<address>
									<postCode>700032</postCode>
									<settlement>Kolkata</settlement>
									<country key="IN">INDIA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,315.07,131.78,139.98,11.23"><forename type="first">Srinivasa</forename><forename type="middle">Rao</forename><surname>Godavarthy</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">Jadavpur University</orgName>
								<address>
									<postCode>700032</postCode>
									<settlement>Kolkata</settlement>
									<country key="IN">INDIA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,90.30,76.47,48.63,12.57">Bengali</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">13EDD023266155EA74EB9EA8D1407386</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.2.3 [Database Management]: Languages-Query Languages Languages, Performance, Experimentation Ad-hoc cross language information retrieval, Indian languages, Bengali, Hindi, Telugu</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the experiments carried out at Jadavpur University as part of participation in the CLEF 2007 ad-hoc bilingual task. This is our first participation in the CLEF evaluation task and we have considered Bengali, Hindi and Telugu as query languages for the retrieval from English document collection. We have discussed our Bengali, Hindi and Telugu to English CLIR system as part of the ad-hoc bilingual task, English IR system for the ad-hoc monolingual task and the associated experiments at CLEF. Query construction was manual for Telugu-English ad-hoc bilingual task, while it was automatic for all other tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Cross-language information retrieval (CLIR) research involves the study of systems that accept queries (or information needs) in one language and return objects of a different language. These objects could be text documents, passages, images, audio or video documents. Cross-language information retrieval focused on the cross-language issues from information retrieval (IR) perspective rather than machine translation perspective. Some of the key technical issues <ref type="bibr" coords="1,198.59,542.52,11.71,9.02" target="#b6">[7]</ref> for cross language information retrieval can be thought of as: (i). How can a query term in one language L 1 be expressed in another language L 2 ?</p><p>(ii). What mechanisms determine which of the possible translations of text from L 1 to L 2 should be retained? (iii). In cases where more than one translation is retained, how can different translation alternatives be weighed? Many different techniques were experimented in various CLIR systems in the past in order to address these issues. These techniques can be broadly classified <ref type="bibr" coords="1,210.17,625.02,11.71,9.02" target="#b2">[3]</ref> as controlled vocabulary based and free text based systems at very high level. However, it is very difficult to create, maintain and scale a controlled vocabulary for CLIR systems in a general domain for a large corpus. Researchers came up with models that can be built on the full text of the corpus. The free text based system research can be broadly classified on the corpus-based and knowledge-based aspects. Corpus-based systems may use parallel or comparable corpora, which are aligned at word level, sentence level or passage level to learn models automatically. Knowledge-based systems might use bilingual dictionaries or ontologies, which form the handcrafted knowledge readily available for the systems to use. Hybrid systems were also built combining the knowledge-based and corpus-based approaches. Apart from these approaches, the extension of monolingual IR techniques such as vector-based models, relevance modeling techniques <ref type="bibr" coords="2,180.69,86.28,16.74,9.02" target="#b13">[14]</ref> etc., to cross language IR were also explored.</p><p>In this work we have discussed our experiments on CLIR for Indian languages to English, where the queries are in Indian languages and the documents to be retrieved are in English. Experiments were carried out using queries in three Indian languages using the CLEF 2007 experimental setup. The three languages chosen were Bengali, Hindi and Telugu, which are predominantly spoken in the eastern India, northern India and the southern India respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>Very little work has been done in the past in the areas of IR and CLIR involving Indian languages. In the year 2003 a surprise language exercise <ref type="bibr" coords="2,162.81,199.08,11.71,9.02" target="#b3">[4]</ref> was conducted at ACM TALIP <ref type="foot" coords="2,303.00,196.99,3.24,5.83" target="#foot_0">1</ref> . The task was to build CLIR systems for English to Hindi and Cebuano, where the queries were in English and the documents were in Hindi and Cebuano. Five teams participated in this evaluation task at ACM TALIP providing some insights into the issues involved in processing Indian language content. A few other information access systems were built apart from this task such as cross language Hindi headline generation <ref type="bibr" coords="2,543.84,234.18,10.66,9.02" target="#b1">[2]</ref>, English to Hindi question answering system <ref type="bibr" coords="2,239.19,245.88,16.69,9.02" target="#b12">[13]</ref> etc. International Institute of Information Technology (IIIT), Hyderabad, built a monolingual web search engine for various Indian languages, which is capable of retrieving information from multiple character encodings <ref type="bibr" coords="2,172.52,269.28,15.37,9.02" target="#b9">[10]</ref>. In CLEF 2006 ad-hoc document retrieval task, Hindi and Telugu to English Cross Lingual Information Retrieval task <ref type="bibr" coords="2,162.37,280.98,16.72,9.02" target="#b10">[11]</ref> were reported by IIIT, Hyderabad. Some research was previously carried out in the areas of machine translation involving Indian languages <ref type="bibr" coords="2,505.85,298.68,10.64,9.02" target="#b0">[1]</ref>, <ref type="bibr" coords="2,523.59,298.68,16.74,9.02" target="#b12">[13]</ref> etc. Most of the Indian language MT efforts involve studies on translating various Indian languages amongst themselves or translating English to Indian language content. Hence most of the Indian language resources available for the works are largely biased to these tasks. Recently, Government of India has initiated a consortia project titled "Development of Cross-Lingual Information Access System", where the query would be in any of the six different Indian languages (Bengali, Hindi, Marathi, Telugu, Tamil, Punjabi) and the output would be also in the user's own language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Our Approach</head><p>The experiments carried out by us for CLEF 2007 are based on stemming, zonal indexing and TFIDF based ranking model with bilingual dictionary look up. There were no readily available bilingual dictionaries that could be used as databases for this work, so we had to develop bilingual dictionaries from the available resources in the Internet. The method of zonal indexing was applied on the English document collection after removing stop words and performing stemming operation. The keywords in the English document collection were indexed using the n-gram indexing methodology. The query terms were extracted from the topic files using bilingual dictionaries. The Information Retrieval system was working on a TFIDF based ranking model. Query construction was carried out manually for the Telugu-English bilingual task due to the unavailability of the machine-readable Telugu-English bilingual dictionary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Zonal Indexing and Query Construction</head><p>In zonal indexing, a particular document is divided into n number of zones/regions, say, w 1 , w 2 , …… ,w n . Then a weight is associated with each zone in such a way that the sum of all weights results in 1. Here, we divided each document into two zones, say, w 1 and w 2 . The zone 'w 1 ' contains the contents of ED, PT, DK, EI, KH, HD and AU tags and 'w 2 ' region contains the contents of ID and TE tags of the Los Angeles Times (LA TIMES, 2002) documents. The weights heuristically assigned to w1 and w2 were 0.3 and 0.7 respectively. The contents of these two zones for all the documents were checked for stop words and then stemmed. Relative term frequency of a content word in a document is then calculated in each of the w 1 and w 2 regions as the ratio of the number of occurrences of the content word in the region to the total number of content words present in that region. The relative term frequencies of any content word in the two regions are normalized and added together to get the relative term frequency of that content word in the entire document. These content words which could be multiwords were used as index keywords.</p><p>We have created a list of stop-words for each language, i.e., English, Bengali, Hindi and Telugu. We have also prepared a list of words/terms that identifies whether the index terms in the narration part provided with each topic talk about relevance/irrelevance of the index terms with respect to the topic. This list has been prepared for the languages studying the corresponding topic files. Stop words are first eliminated from the topic files. For every n-gram identified from the topic file all possible lower order (n-1) grams starting from unigrams were considred as query words. For example, for the trigram "Australian Prime Minister" identified from the topic file, the following were included in the query as query expansion: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Monograms</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Query Translation</head><p>The available Bengali-English dictionary<ref type="foot" coords="3,221.04,290.26,3.00,5.40" target="#foot_1">2</ref> was conveniently formatted for the machine-processing tasks. The Hindi-English dictionary was developed from the available English-Bengali and Bengali-Hindi machine readable dictionaries. Initially, the English-Hindi dictionary was constructed. This dictionary was then converted into a Hindi-English dictionary for further use. A Telugu -English human readable online dictionary was used for query construction from Telugu topic files. Related works on dictionary construction can be found in <ref type="bibr" coords="3,253.88,338.34,10.64,9.02" target="#b7">[8]</ref>.</p><p>The popular Porter Stemming <ref type="bibr" coords="3,188.88,356.04,16.74,9.02" target="#b11">[12]</ref> algorithm has been used in this work in order to remove the suffixes from the terms in the English topic file. Indian languages are inflectional / agglutinative in nature and thus demand good stemming algorithms. Due to the absence of good stemmers for Indian languages, the words in the Bengali, Hindi and Telugu topic files are subjected to suffix stripping using manually prepared suffix lists in the respective languages. The terms remaining after suffix removal are looked up in the corresponding bilingual Bengali / Hindi / Telugu to English dictionary. All English words/terms found in the Bengali / Hindi / Telugu to English dictionary for a word are considered, these may be synonyms or may correspond to different senses of the source language word. Many of the terms may not be found in the bilingual dictionary, as the term is a proper name or a word from a foreign language or a valid Indian language word, which did not occur in the dictionary. Dictionary look up may fail in some cases due to the errors involved in the process of stemming and/or suffix removal. For handling dictionary look up failure csases, a transliteration from Indian languages to English was attempted assuming the word to be most likely a proper name not to be found in the bilingual dictionaries. The transliteration engine is the modified joint source-channel model <ref type="bibr" coords="3,265.59,484.74,11.72,9.02" target="#b1">[2]</ref> based on the regular expression based alignment techniques. Three different bilingual training sets namely, Bengali-English, Hindi-English and Telugu-English were developed to train the transliteration engine. The Bengali-English training set contains approximately 25,000 bilingual examples of proper names, particularly person and location names. The Hindi-English and Telugu-English bilingual training sets were developed from the Bengali-English training set. The Hindi-English and Telugu-English training sets contain 5,000 bilingual training examples. The Indian language terms are thus translated and transliterated into the English terms accordingly. These translated/transliterated terms are then added together to form the English language query terms as part of query expansion. This algorithm for query translation and transliteration addresses the first issue of representing query in one language (L 1 ) to another language (L 2 ). The query translation process considers all the alternative translations / transliterations with equal weight.</p><p>Once the translations for the words of the Bengali, Hindi and Telugu topic files were obtained, all possible n-grams (n=1 to no. of query words in the title) were extracted for the title of each topic as explained in Section 3.1. We considered consecutive words as an n-gram, if no stop-word appears in between. For the English topic file, n-grams were extracted from title, description and narration part. For Bengali, Hindi and Telegu topic files, ngrams and all possible monograms were considered for the description and narration parts of each topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Experiments</head><p>The evaluation document set consists of 135,917 documents from Los Angeles Times of 2002. Among these, a large number of documents were containing no element. A set of 50 topics representing the information need was given for each of the languages, Bengali, Hindi, Telugu and English. A set of human relevance judgments for these topics was generated by assessors at CLEF. These relevance judgements are binary relevance judgements and are decided by a human assessor after reviewing a set of pooled documents using the relevant document pooling technique. The system evaluation framework is similar to the Cranfield style system evaluations and the measures are similar to those used in TREC<ref type="foot" coords="4,472.38,167.56,3.00,5.40" target="#foot_2">3</ref>  <ref type="bibr" coords="4,478.86,168.84,10.62,9.02" target="#b5">[6]</ref>. Three different runs were submitted related to the three Indian languages, one for each of the three languages, Bengali, Hindi and Telugu as our task in the ad-hoc bilingual track. Another run was submitted for English as a part of the ad-hoc monolingual task. Three runs were performed using the title, description and narration parts of the topic files for Bengali, Hindi and English. Only title and description parts of the topic file were considered for the bilingual Telugu-English run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">CLEF 2007 Evaluation for Bengali-English, Hindi-English, Telugu-English Bilingual Ad-hoc Task and English Monolingual Ad-hoc Task</head><p>The run statistics for the 4 runs submitted to CLEF 2007 are described in Table <ref type="table" coords="4,384.95,296.58,3.76,9.02" target="#tab_1">1</ref>. Clearly the geometric average precision metrics and its difference from mean average precision metrics suggests the lack of robustness in our system. There were certain topics that performed very well across the language pairs as well as for English also, but there were many topics where the performance was very low. The values of the evaluation metrics of Table <ref type="table" coords="4,393.16,331.68,5.01,9.02" target="#tab_1">1</ref> show that our system performs the best for the monolingual English task. As part of the bilingual ad-hoc tasks, the system performs best for the Telugu followed by Hindi and Bengali. The key to these higher values of the evaluation metrics in the Telugu-English bilingual run compared to other two bilingual runs (Hindi-English and Telugu-English) may be the manual tasks that were carried out during indexing. But it is also evident that the automatic runs for Hindi-English and Bengali-English tasks achieved a performance comparable to the manual run of Telugu-English. The overall relatively low performance of the system particularly with Indian language queries is the indicative of the fact that simple techniques such as dictionary lookup with minimal lemmatization such as suffix removal may not be sufficient for the morphologically rich Indian language CLIR. Relatively low performance of Bengali/Hindi suggests the need for broader coverage of dictionary and good morphological analyzer is inevitable for Bengali/Hindi CLIR in order to achieve a reasonable performance. The mean precision with retrieved documents graphs are shown in figures 1.(a) -(d) for the Bengali-English, Hindi-English, Telugu-English and the monolingual English tasks. The interpolated precision with standard recall graphs is shown in figures 2.(a) -(d) for the four different runs. The figures 2.(a) -(d) suggest that the effect of ranking has not been much in the system. The sloping of curve seems to be consistent all across, as opposed to a rapid sloping for the first few recall points in all the runs. A good ranking algorithm would consistently push relevant documents to the top ranks; thereby resulting in a rapid sloping of the curve for the first few recall points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and Future Work</head><p>Our experiments suggest that simple TFIDF based ranking algorithms may not result in effective CLIR systems for Indian language queries. Any additional information added from corpora either resulting in source language query expansion or the target language query expansion or both could help. Machine readable bilingual dictionaries with more coverage would have improved the results. An aligned bilingual parallel corpus would be an ideal resource to have in order to apply certain machine learning approaches. Application of word sense disambiguation methods on the translated query words would have a positive effect on the result. A robust stemmer is required for the highly inflective Indian languages. We would like to automate the query construction task of Telugu in future. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,126.90,561.24,358.14,9.02;6,274.44,349.56,202.05,152.04"><head>Figure 2 :</head><label>2</label><figDesc>Figure 1: PRECISION VS RETRIEVED DOCUMENT (LOGARITHMIC SCALE)</figDesc><graphic coords="6,274.44,349.56,202.05,152.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,54.00,469.59,491.33,97.98"><head>Table 1 : Run Statistics</head><label>1</label><figDesc></figDesc><table coords="4,54.00,469.59,491.33,68.16"><row><cell>Run</cell><cell>MAP</cell><cell>R-Prec</cell><cell>GAP</cell><cell>B-Pref</cell></row><row><cell>Bengali Title + Description + Narration</cell><cell>10.18%</cell><cell>12.48%</cell><cell>2.81%</cell><cell>12.72%</cell></row><row><cell>Hindi Title + Description + Narration</cell><cell>10.86%</cell><cell>13.70%</cell><cell>2.78%</cell><cell>13.43%</cell></row><row><cell>Telugu Title + Description</cell><cell>11.28%</cell><cell>13.92%</cell><cell>2.76%</cell><cell>12.95%</cell></row><row><cell>English Title + Description + Narration</cell><cell>12.32%</cell><cell>14.40%</cell><cell>4.63%</cell><cell>13.68%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,57.00,707.67,343.12,8.10"><p>ACM Transactions on Asian Language Information Processing, http://www.acm.org/pubs/talip</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,59.28,707.67,187.52,8.10"><p>http://dsal.uchicago.edu/dictionaries/biswas-bengali</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,59.28,707.67,170.16,8.10"><p>Text Retrieval Conferences, http://trec.nist.gov</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,72.02,208.83,485.96,8.10;5,72.00,219.39,426.12,8.10" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,343.41,208.83,185.57,8.10">Machine Translation Activities in India: A Survey</title>
		<author>
			<persName coords=""><forename type="first">Akshar</forename><surname>Bharati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rajeev</forename><surname>Sangal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dipti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Amba P</forename><surname>Sharma</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Kulkarni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,546.97,208.83,11.01,8.10;5,72.00,219.39,399.76,8.10">the Proceedings of Workshop on Survey on Research and Development of Machine Translation in Asian Countries</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.02,233.97,485.99,8.10;5,72.00,244.53,194.15,8.10" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,272.05,233.97,216.30,8.10">A Modified Joint Source-Channel Model for Transliteration</title>
		<author>
			<persName coords=""><forename type="first">Asif</forename><surname>Ekbal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sudip</forename><surname>Naskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sivaji</forename><surname>Bandyopadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,504.14,233.97,53.87,8.10;5,72.00,244.53,62.60,8.10">Proceedings of the COLING/ACL</title>
		<meeting>the COLING/ACL<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="191" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.01,259.11,486.00,8.10;5,72.00,269.67,232.71,8.10" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,265.88,259.11,175.59,8.10">Cross-language Headline Generation for Hindi</title>
		<author>
			<persName coords=""><forename type="first">Bonnie</forename><surname>Dorr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Zajic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,449.52,259.11,108.49,8.10;5,72.00,269.67,154.00,8.10">ACM Transactions on Asian Language Information Processing (TALIP)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="270" to="289" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,74.29,284.25,483.68,8.10;5,72.00,294.81,83.97,8.10" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,129.65,284.25,213.66,8.10">Alternative Approaches for Cross Language Text Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><surname>Orad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,359.40,284.25,198.57,8.10;5,72.00,294.81,35.32,8.10">AAAI Symposium on Cross Language Text and Speech Rretrieval</title>
		<meeting><address><addrLine>USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.01,309.39,486.00,8.10;5,72.00,319.95,45.86,8.10" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,141.97,309.39,121.53,8.10">The Surprise Language Exercises</title>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><forename type="middle">W</forename><surname>Orad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,270.13,309.39,263.36,8.10">ACM Transactions on Asian Language Information Processing (TALIP)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="79" to="84" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.01,334.53,486.00,8.10;5,72.00,345.09,306.76,8.10" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,237.52,334.53,229.20,8.10">Overview of the Sixth Text Retrieval Conferences (TTREC)</title>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorchees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Donna</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,487.12,334.53,70.89,8.10;5,72.00,345.09,161.47,8.10">Proceedings of the Workshop of Sixth Text Retrieval Conference</title>
		<meeting>the Workshop of Sixth Text Retrieval Conference<address><addrLine>Morristown, NJ, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="241" to="273" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.01,359.67,485.97,8.10;5,72.00,370.23,20.28,8.10" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="5,227.71,359.67,139.28,8.10">Cross-Language Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Gregory</forename><surname>Grefenstette</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Grefenstette</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>Norwell, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.01,384.81,485.98,8.10;5,72.00,395.37,98.10,8.10;5,170.10,393.40,4.68,5.40;5,177.36,395.37,380.61,8.10;5,72.00,405.93,183.44,8.10" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,214.86,384.81,343.13,8.10;5,72.00,395.37,15.78,8.10">Converting On-line Bilingual Dictionaries from Human-readable form to Machine-readable form</title>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,104.42,395.37,65.69,8.10;5,170.10,393.40,4.68,5.40;5,177.36,395.37,377.08,8.10">Proceedings of 25 th Annual International ACM SIGIR Conference on Research and Development in Informational Retrieval</title>
		<meeting>25 th Annual International ACM SIGIR Conference on Research and Development in Informational Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="405" to="406" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.02,420.51,486.01,8.10;5,72.00,431.07,77.96,8.10;5,149.94,429.10,4.68,5.40;5,156.90,431.07,354.69,8.10" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,299.76,420.51,243.78,8.10">Webkhoj: Indian Language IR from Multiple Character Encodings</title>
		<author>
			<persName coords=""><forename type="first">Prasad</forename><surname>Pingali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jagadeesh</forename><surname>Jagarlamudi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,72.00,431.07,77.96,8.10;5,149.94,429.10,4.68,5.40;5,156.90,431.07,164.33,8.10">Proceedings of the 15 th International Conference on World Wide Web</title>
		<meeting>the 15 th International Conference on World Wide Web<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="801" to="809" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.00,445.65,486.00,8.10;5,72.00,456.21,367.36,8.10" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="5,199.97,445.65,288.96,8.10">Hindi and Telugu to English Cross Language Information Retrieval at CLEF</title>
		<author>
			<persName coords=""><forename type="first">Prasad</forename><surname>Pingali</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vasudeva</forename><surname>Varma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,526.98,445.65,31.02,8.10;5,72.00,456.21,237.02,8.10">Working Notes for the CLEF 2006 Wokshop (Cross Language Adhoc Task)</title>
		<meeting><address><addrLine>Alicante, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-09">2006. September</date>
			<biblScope unit="page" from="20" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.01,470.79,299.30,8.10" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="5,149.21,470.79,122.92,8.10">An Algorithm for Suffix Stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,277.92,470.79,30.37,8.10">Program</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.01,485.37,486.00,8.10;5,72.00,495.93,232.71,8.10" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="5,220.76,485.37,217.43,8.10">Hindi-English Cross-Lingual Question-Answering System</title>
		<author>
			<persName coords=""><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ralph</forename><surname>Grishman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,447.36,485.37,110.65,8.10;5,72.00,495.93,154.00,8.10">ACM Transactions on Asian Language Information Processing (TALIP)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="181" to="192" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.02,510.51,485.99,8.10;5,72.00,521.07,61.69,8.10" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="5,227.02,510.51,188.73,8.10">Use of Machine Translation in India: Current Status</title>
		<author>
			<persName coords=""><forename type="first">Sudip</forename><surname>Naskar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sivaji</forename><surname>Bandyopadhyay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,431.91,510.51,86.23,8.10">Proc. of MT SUMMIT-X</title>
		<meeting>of MT SUMMIT-X<address><addrLine>Phuket, Thailand</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="465" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,72.02,535.65,450.94,8.10;5,522.96,533.68,4.68,5.40;5,531.96,535.65,26.04,8.10;5,72.00,546.21,486.00,8.10;5,72.00,556.77,66.50,8.10" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="5,295.11,535.65,123.01,8.10">Cross-Lingual Relevance Models</title>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Victor Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Choquette</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,438.47,535.65,84.49,8.10;5,522.96,533.68,4.68,5.40;5,531.96,535.65,26.04,8.10;5,72.00,546.21,341.39,8.10">Proceedings of the 25 th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 25 th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="175" to="182" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
