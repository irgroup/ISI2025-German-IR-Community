<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,163.54,146.21,275.94,18.08;1,225.07,168.13,152.84,18.08">GIR experiements with Forostar at GeoCLEF 2007</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,183.50,203.19,61.47,10.46"><forename type="first">Simon</forename><surname>Overell</surname></persName>
							<email>simon.overell01@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Multimedia &amp; Information Systems Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<postCode>SW7 2AZ</postCode>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,255.52,203.19,69.11,10.46"><forename type="first">João</forename><surname>Magalhães</surname></persName>
							<email>j.magalhaes@imperial.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Multimedia &amp; Information Systems Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<postCode>SW7 2AZ</postCode>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,351.79,203.19,56.91,10.46"><forename type="first">Stefan</forename><surname>Rüger</surname></persName>
							<email>s.rueger@open.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Multimedia &amp; Information Systems Department of Computing</orgName>
								<orgName type="institution">Imperial College London</orgName>
								<address>
									<postCode>SW7 2AZ</postCode>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Knowledge Media Institute The Open University</orgName>
								<address>
									<addrLine>Milton Keynes</addrLine>
									<postCode>MK7 6AA</postCode>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,163.54,146.21,275.94,18.08;1,225.07,168.13,152.84,18.08">GIR experiements with Forostar at GeoCLEF 2007</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0B46337563EB72B8FA3702F050061E0E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software Measurement, Performance, Experimentation Geographic Information Retrieval, Relevance Ranking, Disambiguation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe our Geographic Information Retrieval experiments with Forostar, our GIR application on the GeoCLEF 2007 corpus and query set. We compare the results from orthogonal text with no geographic entities and only geographic entities with standard text retrieval and combined text and geographic relevance methods. The text and named entity analysis and retrieval methods of Forostar are described in detail. We also detail our placename disambiguation and geographic relevance ranking methods.</p><p>The paper concludes with an analysis of our results including significance testing where we show our baseline method, in fact, to be best. Finally we identify weaknesses in our approach and ways in which the system could be optimised and improved.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper describes the experiments performed by the Multimedia and Information Systems group at GeoCLEF 2007 with our GIR application: Forostar. We compare the results from orthogonal text with no geographic entities and only geographic entities with standard text retrieval and combined text and geographic relevance methods.</p><p>In Section 2 we outline how we index the GeoCLEF corpus and the three field types: Text, Named Entity and Geographic. We then describe how the manually constructed queries are expanded and submitted to the query engine. Section 3 describes and justifies the placename disambiguation methods and geographic relevance ranking methods in more detail. In Section 4 we describe our experiments followed by the results in Section 5. Finally Section 6 analyses the weaknesses of our system and identifies areas for improvement. Forostar is our ad-hoc Geographic Information Retrieval system. At indexing time, documents are analysed and named entities extracted. Named entities tagged as locations are then disambiguated using our co-occurrence model. The free-text fields, named entities and disambiguated locations are then indexed by Lucene. In the querying stage we combine the relevance scores assigned to the Geographic fields and Textual fields using the vector space model. Fields designated as containing more information (i.e. The Headline) have a boost value assigned to them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Indexing</head><p>The indexing stage of Forostar begins by extracting named entities from text using ANNIE, the Information Extraction engine bundled with GATE. GATE is Sheffield University's General Architecture for Text Engineering <ref type="bibr" coords="2,241.97,599.46,9.96,10.46" target="#b1">[2]</ref>. Of the series of tasks ANNIE is able to perform, the only one we use is named entity recognition. We consider ANNIE a "black box" where text goes in, and categorised named entities are returned; because of this, we will not discuss the workings of ANNIE further here but rather refer you to the GATE manual <ref type="bibr" coords="2,367.56,635.33,9.96,10.46" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Named Entity fields</head><p>We index all the named entities categorised by GATE in a "Named Entity" field in Lucene (e.g. "Police," "City Council," or "President Clinton"). The named entities tagged as Locations by ANNIE we index as "Named Entity -Location" (e.g. "Los Angeles," "Scotland" or "California") and as a Geographic Location (described in Section 2.1.3). The body of the GeoCLEF articles and the article titles are indexed as text fields. This process is described in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Text fields</head><p>Text fields are pre-processed by a customised analyser similar to Lucene's default analyser <ref type="bibr" coords="3,499.71,128.93,9.96,10.46" target="#b0">[1]</ref>.</p><p>Text is split at white space into tokens, the tokens are then converted to lower case, stop words discarded and stemmed with the "Snowball Stemmer". The processed tokens are held in Lucene's inverted index.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Geographic fields</head><p>The locations tagged by the named entity recogniser are passed to the disambiguation system. We have implemented a simple disambiguation method based on heuristic rules. For each placename being classified we build a list of candidate locations, if the placename being classified is followed by a referent location this can often cut down the candidate locations enough to make the placename unambiguous. If the placename is not followed by a referent location or is still ambiguous we disambiguate it as the most commonly occurring location with that name.</p><p>Topological relationships between locations are looked up in the Getty Thesaurus of Geographical Names (TGN) <ref type="bibr" coords="3,171.88,292.77,9.96,10.46" target="#b3">[4]</ref>. Statistics on how commonly different placenames refer to different locations and a set of synonyms for each location are harvested from our Geographic Co-occurrence model, which in turn is built by crawling Wikipedia <ref type="bibr" coords="3,287.43,316.67,9.96,10.46" target="#b7">[8]</ref>.</p><p>Once placenames have been mapped to unique locations in the TGN, they need to be converted into Geographic fields to be stored in Lucene. We store locations in two fields:</p><p>• Coordinates. The coordinate field is simply the latitude and longitude as read from the TGN.</p><p>• Unique strings. The unique string is the unique id of this location, preceded with the unique id of all the parent locations, separated with slashes. Thus the unique string for the location "London, UK" is the unique id for London (7011781), preceded by its parent, Greater London (7008136), preceded by its parent, Britain (7002445). . . until the root location, the World (1000000) is reached. Giving the unique string for London as 1000000\1000003\7008591\7002445\7008136\7011781.</p><p>Note the text, named entity and geographic fields are not orthogonal. This has the effect of multiplying the impact of terms occurring in multiple fields. For example if the term "London" appears in text, the token "london" will be indexed in the text field. "London" will be recognised by ANNIE as a Named Entity and tagged as a location (and indexed as Location Entity, "London"). The Location Entity will then be disambiguated as location "7011781" and corresponding geographic fields will be added.</p><p>Previous experiments conducted on the GeoCLEF data set in <ref type="bibr" coords="3,371.82,543.83,10.52,10.46" target="#b6">[7]</ref> showed improved results from having overlapping fields. We concluded from these experiments that the increased weighting given to locations caused these improvements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Querying</head><p>The querying stage of Forostar is a two step process. First manually constructed queries are expanded and converted into Lucene's bespoke querying language; then we query the Lucene index with these expanded queries and perform blind relevance feedback on the result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Manually constructed query</head><p>The queries are manually constructed in a similar structure to the Lucene index. Queries have the following parts: a text field, a Named Entity field and a location field. The text field contains the query with no alteration. The named entity field contains a list of named entities referred to in the query (manually extracted). The location field contains a list of location -relationship pairs. These are the locations contained in the query and their relationship to the location being searched for. A location can be specified either with a placename (optionally disambiguated with a referent placename), a bounding box, a bounding circle (centre and radius), or a geographic feature type (such as "lake" or "city"). A relationship can either be "exact match," "contained in (vertical topology)," "contained in (geographic area)," or "same parent (vertical topology)". The negation of relationships can also be expressed i.e. "excluding," "outside," etc.</p><p>We believe such a manually constructed query could be automated with relative ease in a similar fashion to the processing that documents go through when indexed. This was not implemented due to time constraints.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Expanding the geographic query</head><p>The geographic queries are expanded in a pipeline. The location -relation pairs are expanded in turn. The relation governs at which stage the location enters the pipeline. At each stage in the pipeline the geographic query is added to. At the first stage an exact match for this location's unique string is added: for "London" this would be 1000000\1000003\7008591\7002445\7008136\ 7011781. Then places within the location are added, this is done using Lucene's wild-card character notation: for locations in "London" this becomes 1000000\1000003\7008591\7002445\7008136\ 7011781\*. Then places sharing the same parent location are added, again using Lucene's wildcard character notation. For "London" this becomes all places within "Greater London," 1000000\ 1000003\7008591\7002445\7008136\*. Finally the coordinates of all the locations falling close to this location are added. A closeness value can manually be set in the location field, however default values are based on feature type (default values were chosen by the authors). The feature listed in the Getty TGN for "London" is "Administrative Capital," the default value of closeness for this feature is 100km.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.3">Combining using the VSM</head><p>A Lucene query is built using the text fields, named entity fields and expanded geographic fields. The text field is processed by the same analyzer as at indexing time and compared to both the text and headline fields in the Lucene index. We define a separate boost factor for each field. These boost values were set by the authors during initial iterative tests (they are comparable to similar weighting in past GeoCLEF papers <ref type="bibr" coords="4,249.64,729.97,10.52,10.46" target="#b5">[6,</ref><ref type="bibr" coords="4,263.95,729.97,7.20,10.46" target="#b8">9]</ref>). The headline had a boost of 10, the text a boost of 7, named entities a boost of 5, geographic unique string a boost of 5 and geographic coordinates a boost of 3. The geographic, text and named entity relevance are then combined using Lucene's Vector Space Model.</p><p>We perform blind relevance feedback on the text fields only. To do this the whole expanded query is submitted to the Lucene query engine, and the top 10 documents considered relevant. The top occurring terms in these documents with more than 5 occurrences are added to the text parts of the query. A maximum of 10 terms are added. The final expanded query is re-submitted to the query engine and our final results are returned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Geographic retrieval</head><p>Forostar allows us to perform experiments on placename disambiguation and geographic relevance ranking. Our geographic model represents locations as points. We choose a point representation over a more accurate polygon representation for several reasons: It makes minimal appreciable difference for queries at the small (city or county) scale; Eigenhofer and Mark's topology matters metrics refine premise <ref type="bibr" coords="5,190.29,284.85,9.96,10.46" target="#b2">[3]</ref>, suggests that for queries of a larger scale than city or county topology is of greater importance than distance; and far more point data is available. We represent each location referred to in a document with a single point rather than constructing an encompassing footprint because, we argue, if several locations are referred to in a document does, it does not imply locations occurring between the referenced locations are relevant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Placename disambiguation</head><p>As discussed in Section 2.1.3 our placename disambiguation is performed using simple heuristic rules. A key part of the disambiguation is our default gazetteer, the generation of which is explained in this section. The default gazetteer is used to disambiguate placenames that are not immediately followed by a referent placename. The default gazetteer is a many-to-one mapping of Placenames to locations (i.e. for every placename there is a single location). We extract our default gazetteer from a co-occurrence model built from Wikipedia.</p><p>Our Geographic co-occurrence model contains a mapping of Wikipedia articles to locations in the TGN. It also contains the placenames used to refer to every article describing a location (extracted from anchor texts). In total we crawled 2.3 million links from Wikipedia to articles describing locations. This gave us a mapping of 75,322 placenames to 53,643 locations. The default gazetteer contains these 75,322 placenames mapped to a subset of the TGN. A full description and analysis of the co-occurrence model can be found in <ref type="bibr" coords="5,338.68,510.46,9.96,10.46" target="#b7">[8]</ref>.</p><p>The motivation of this disambiguation method is to provide a baseline of placename disambiguation achievable with our co-occurrence model. Analysis of the co-occurrence model suggests its application should recognise ∼ 75% of locations with an accuracy of between ∼ 80% and ∼ 90%. The unrecognised ∼ 25% of locations will only be indexed as "Named Entity -Location."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Geographic relevance</head><p>In Section 2.1.3 our geographic relevance strategy is described. In this section we provide a justification for the methods used. We have 4 types of geographic relations each expanded differently:</p><p>• 'Exact Match,' the motivation behind this is the most relevant documents to a query will mention the location being searched for;</p><p>• 'Contained in (Vertical Topology)' assumes locations within a location being searched for are relevant, for example 'London' will be relevant to queries which search for 'England';</p><p>• Locations that share the same parent, these locations are topologically close. For example a query for 'Wales' would have 'Scotland', 'England' and 'Northern Ireland' added;</p><p>• The final method of geographic relevance is defining a viewing area, all locations within a certain radius are considered relevant. Each geographic relation is considered of greater importance than the following one. This follows Egenhofer and Mark's 'Topology Matters, Metrics Refine' premise. The methods of greater importance are expanded in a pipeline as illustrated in Figure <ref type="figure" coords="6,368.17,222.81,3.87,10.46" target="#fig_1">2</ref>. The expanded query is finally combined in Lucene using the Vector space model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>We compared four methods of query construction. All methods query the same index.</p><p>• Standard Text (Text). This method only used the standard text retrieval part of the system. The motivation for this method was to evaluate our text retrieval engine and provide a baseline.</p><p>• Text with geographic entities removed (TextNoGeo). For this method we manually removed the geographic entities from the text queries to quantify the importance of ambiguous geographic entities. The results produced by this method should be othogornal to the results produced by the Geo method.</p><p>• Geographic Entities (Geo). The Geo method uses only the geographic entities contained in a query, these are matched ambiguously against the named entity index and unambiguously against the geographic index. Ranking is performed using the geographic relevance methods described in Section 3.2.</p><p>• Text and geographic entities (Text + Geo). Our combined method combines elements of textual relevance with geographic relevance using the vector space model. It is a combination of the Text and Geo methods. Our hypothesis is that it will show an improvement over the other tested methods.</p><p>Our hypothesis is that a combination of Text and Geographic relevance will give the best results as it uses the most information to discover documents relevant to the query. The Standard Text method should provide a good baseline to compare this hypothesis against and the orthogonal Geo and TextNoGeo entries should help us interpret where the majority of the information is held.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>The experimental results are displayed in Table <ref type="table" coords="6,300.83,611.29,3.87,10.46" target="#tab_0">1</ref>. Surprisingly the Text result is the best with a confidence greater than 99.95% using the Wilcoxon signed rank test <ref type="bibr" coords="6,392.92,623.25,9.96,10.46" target="#b4">[5]</ref>. The Text+Geo method is better than the TextNoGeo method with a confidence greater than 95%. The Geo results are the worst with a confidence greater than 99.5%. 74.9% of named entities tagged by ANNIE as locations were mapped to locations in the default gazetteer. This is consistent with the prediction of ∼ 75% made in Section 3.1. Some brief observations of the per query results shows that the Text+Geo results are better than Geo in all except 1 case, while the Text results are better in all except 2 cases. The largest variation in results (and smallest significant difference) is the Text+Geo and the TextNoGeo results. Surprisingly the Text method achieved significantly better results than the combination of textual and geographic relevance. We attribute the relatively poor results of the Text+Geo method to the way the textual and geographic relevance were combined.</p><p>The separate types of geographic relevance and the textual relevance were all combined within Lucene's vector space model with no normalisation. The motivation behind this was that using Lucene's term boosting we should be able to give greater weighting to text terms. The difference in information between the Text+Geo method and Text method are captured in the Geo method. Observations of the per query results shows that in cases where the Geo method performed poorly and the Text method performed well the Text+Geo method performed poorly. The intention of combining the two methods was to produce synergy, however, in reality the Geo method undermined the Text results.</p><p>The geo method alone performed poorly compared to the other methods. However, when considering the only information provided in these queries is geographic information (generally a list of placenames), the results are very promising. The highest per query result achieved by the geo method had an average precision of 0.097. Further work is needed to evaluate the accuracy of the placename disambiguation. Currently we have only quantified that 74.9% of locations recognised by ANNIE are disambiguated. We have not yet evaluated the disambiguation accuracy or the proportion of locations that are missed by ANNIE.</p><p>In future work we would like to repeat the combination experiment detailed in this paper however separating the geographic relevance and textual relevance into two separate indexes. Similarity values with respect to a query could be calculated for both indexes, normalised and combined in a weighted sum. A similar approach to this was taken in GeoCLEF 2006 by Martins et al. <ref type="bibr" coords="7,115.46,395.37,9.96,10.46" target="#b5">[6]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,221.85,415.85,159.30,10.46;2,123.07,109.08,356.80,283.36"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Building the Lucene Index</figDesc><graphic coords="2,123.07,109.08,356.80,283.36" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,205.96,334.61,191.09,10.46;4,98.38,109.06,406.20,202.13"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Expanding the geographic queries</figDesc><graphic coords="4,98.38,109.06,406.20,202.13" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,183.98,117.46,235.04,58.02"><head>Table 1 :</head><label>1</label><figDesc>Mean Average Precision of our four methods</figDesc><table coords="6,257.71,129.16,84.26,46.32"><row><cell>Text 0.185</cell></row><row><cell>TextNoGeo 0.099</cell></row><row><cell>Geo 0.011</cell></row><row><cell>Text+Geo 0.107</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,105.49,450.14,407.51,10.46;7,105.50,462.09,22.69,10.46" xml:id="b0">
	<monogr>
		<ptr target="http://lucene.apache.org/java/docs/" />
		<title level="m" coord="7,105.49,450.14,99.96,10.46">Apache Lucene Project</title>
		<imprint>
			<date type="published" when="2007-08-01">1 August 2007, 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.49,482.02,407.52,10.46;7,105.50,493.97,363.06,10.46" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="7,422.93,482.02,90.08,10.46;7,105.50,493.97,150.52,10.46">Developing language processing components with GATE</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Maynard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Tablan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Ursu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Bontcheva</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>University of Sheffield</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="7,105.49,513.90,407.51,10.46;7,105.50,525.85,68.26,10.46" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,243.44,513.90,71.34,10.46">Naive geography</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Egenhofer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,343.26,513.90,169.75,10.46;7,105.50,525.85,36.97,10.46">the 1st Conference on Spatial Theory (COSIT)</title>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.49,545.78,407.51,10.46;7,105.50,557.74,58.67,10.46" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,162.97,545.78,177.72,10.46">User&apos;s Guide to the TGN Data Releases</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Harping</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,351.69,545.78,139.22,10.46">The Getty Vocabulary Program</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>0 edition</note>
</biblStruct>

<biblStruct coords="7,105.49,577.67,407.51,10.46;7,105.50,589.62,242.46,10.46" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,145.76,577.67,285.54,10.46">Using statistical testing in the evaluation of retrieval experiments</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hull</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,453.59,577.67,59.42,10.46;7,105.50,589.62,143.69,10.46">Annual international ACM SIGIR Conference</title>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="329" to="338" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.49,609.54,407.51,10.46;7,105.50,621.50,290.09,10.46" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,390.15,609.54,122.85,10.46;7,105.50,621.50,43.93,10.46">The University of Lisbon at GeoCLEF</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Cardoso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chaves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Andrade</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,192.31,621.50,172.16,10.46">Working Notes for the CLEF Workshop</title>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.49,641.42,407.51,10.46;7,105.50,653.38,271.21,10.46" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="7,285.05,641.42,120.46,10.46">Forostar: A system for GIR</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Overell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Magalhães</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Rüger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>to appear) Lecture Notes from the Cross Language Evaluation Forum 2006</note>
</biblStruct>

<biblStruct coords="7,105.49,673.30,407.51,10.46;7,105.50,685.26,235.26,10.46" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,218.95,673.30,189.82,10.46">Geographic co-occurrence as a tool for GIR</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Overell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Rüger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,485.44,673.30,27.57,10.46;7,105.50,685.26,205.10,10.46">CIKM Workshop on Geographic Information Retrieval</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct coords="7,105.49,705.18,407.51,10.46;7,105.50,717.13,162.65,10.46" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,362.27,705.18,72.83,10.46">UB at GeoCLEF</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Abbas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Southwick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,475.93,705.18,37.07,10.46;7,105.50,717.13,131.53,10.46">Working Notes for the CLEF Workshop</title>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
