<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,160.20,80.45,274.86,12.58;1,124.20,96.53,350.24,12.58">MIRACLE at GeoCLEF Query Parsing 2007: Extraction and Classification of Geographical Information</title>
				<funder ref="#_S52Q5xY">
					<orgName type="full">Spanish R&amp;D National Plan</orgName>
				</funder>
				<funder ref="#_a2hGBwq">
					<orgName type="full">Madrid&apos;s R&amp;D Regional Plan</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,149.94,123.42,74.76,9.02"><forename type="first">Sara</forename><surname>Lana-Serrano</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universidad Politécnica de Madrid</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">DAEDALUS -Data, Decisions and Language</orgName>
								<address>
									<country>S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,237.78,123.42,83.57,9.02"><forename type="first">Julio</forename><surname>Villena-Román</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Universidad Carlos III de Madrid</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">DAEDALUS -Data, Decisions and Language</orgName>
								<address>
									<country>S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,334.50,123.42,107.74,9.02"><forename type="first">José</forename><forename type="middle">Miguel</forename><surname>Goñi-Menoyo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universidad Politécnica de Madrid</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,160.20,80.45,274.86,12.58;1,124.20,96.53,350.24,12.58">MIRACLE at GeoCLEF Query Parsing 2007: Extraction and Classification of Geographical Information</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B17D6FB582F0AC00D8823C968DB564DA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.2 Information Storage</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital libraries. H.2 [Database Management]: H.2.5 Heterogeneous Databases</term>
					<term>H.2.8 Database Applications -Spatial databases and GIS Linguistic Engineering, classification, geographical IR, geographic entity recognition, gazetteer, semantic expansion, Wordnet</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the participation of MIRACLE research consortium at the Query Parsing task of GeoCLEF 2007. Our system is composed of three main modules. First, the Named Geo-entity Identifier, whose objective is to perform the geo-entity identification and tagging, i.e., to extract the "where" component of the geographical query, should there be any. This module is based on a gazetteer built up from the Geonames geographical database and carries out a sequential process in three steps that consist on geo-entity recognition, geo-entity selection and query tagging. Then, the Query Analyzer parses this tagged query to identify the "what" and "geo-relation" components by means of a rule-based grammar. Finally, a two-level multiclassifier first decides whether the query is indeed a geographical query and, should it be positive, then determines the query type according to the type of information that the user is supposed to be looking for: map, yellow page or information. According to a strict evaluation criterion where a match should have all fields correct, our system reaches a precision value of 42.8% and a recall of 56.6% and our submission is ranked 1 st out of 6 participants in the task. A detailed evaluation of the confusion matrixes reveal that some extra effort must be invested in "user-oriented" disambiguation techniques to improve the first level binary classifier for detecting geographical queries, as it is a key component to eliminate many false-positives.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The goal of Geographical Information Retrieval (GIR) is to deal with those information retrieval problems that contain some kind of spatial awareness, i.e., that include geographical references (georeferences) which are essential for the meaning of the query, for example: "find me nice and cheap hotels near Madrid". It is a complex task because of its strong dependence on geographical information resources, which tend to be incomplete and inexact. Moreover, geographical information is mainly arranged in a tree-like hierarchy, therefore queries usually imply a multilevel search (for example: "give me documents about villages in Northern Spain"). Finally, additional translation problems arise when dealing with multiple languages, due to the lack of specific and specialized translation resources in a worldwide domain.</p><p>GeoCLEF is the cross-language geographic retrieval track that runs as part of the Cross Language Evaluation Forum (CLEF) campaign, whose aim is to provide with the necessary framework in which to evaluate GIR systems for search tasks involving both spatial and multilingual aspects. This year, apart from the traditional task, GeoCLEF 2007 offered the Query Parsing task.</p><p>A geographic query is usually composed of three components, "what", "geo-relation" and "where". The keywords in "what" indicate what users want to find; "where" refers to their geographic area of interest; and "geo-relation" stands for the relationship between "what" and "where". For instance, in the first example, "what" would be "nice and cheap hotels", "where" would be "Madrid", and "geo-relation" would be "NEAR". Note that "Madrid" is itself ambiguous and can refer not only to the capital of Spain or the autonomous region where the city of Madrid is located, but also other cities or administrative divisions in United States, Philippines, Mexico, Argentina, Equatorial Guinea, Colombia, Dominican Republic, Sweden…</p><p>The key problem for GIR is to understand how to parse and extract those key components from the queries. This is the objective of the Query Parsing task. Participants where given a set of 800,000 untagged queries and had to detect whether each query was a geographic query or not, and, should the result be positive, had to extract the three components: "where" (with its corresponding latitude/longitude), "geo-relation" (normalized into a predefined relation type such as IN, NEAR, FROM, TO, NORTH_OF…) and "what" (categorized into a type of request: "map", "yellow page" or "information").</p><p>The MIRACLE team is a research consortium formed by research groups of three different universities in Madrid (Universidad Politécnica de Madrid, Universidad Autónoma de Madrid and Universidad Carlos III de Madrid) along with DAEDALUS, a small/medium size enterprise (SME) founded in 1998 as a spin-off of two of these groups and a leading company in the field of linguistic technologies in Spain. MIRACLE has taken part in CLEF since 2003 in many different tracks and tasks, including the main bilingual, monolingual and cross lingual tasks <ref type="bibr" coords="2,93.43,269.22,11.69,9.02" target="#b3">[4]</ref> as well as in ImageCLEF, Question Answering,WebCLEF and GeoCLEF <ref type="bibr" coords="2,405.08,269.22,25.57,9.02">[5] [6]</ref>tracks. This paper describes the MIRACLE participation at the Query Parsing task of GeoCLEF 2007. In the following sections, we will first give an overview of the architecture of our system. Afterwards we will elaborate on the different modules. Finally, the results will be presented and analyzed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">System Description</head><p>Figure <ref type="figure" coords="2,102.24,359.04,5.01,9.02" target="#fig_1">1</ref> presents the system architecture. Observe that the approach consists of three sequential tasks executed by independent modules: Named Geo-entity Identifier: performs geo-entity identification and query expansion.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Named Geo-entity Identifier</head><p>The objective of this module is to perform the geo-entity identification and tagging, i.e., to extract the "where" component of the query, should there be any. It is composed of two main components: a geo-entity parser based on a gazetteer, i.e. a database with geographical resources that constitutes the knowledge base of the system.</p><p>Our gazetteer is built up from the Geonames geographical database <ref type="bibr" coords="3,352.00,73.26,10.64,9.02" target="#b1">[2]</ref>, available free of charge for download under a creative commons attribution license. It contains over 8 million geographical names with more than 6.5 million unique features about 2.2 million populated places and 1.8 million alternate names. Those features include a unique identifier, the resource name, alternative names (in other languages), county/region, administrative divisions, country, continent, longitude, latitude, population, elevation and timezone. All features are categorized into one out of 9 feature classes and further subcategorized into one out of 645 feature codes.</p><p>Geonames integrates geographical data (such as names of places in various languages, elevation or population) from various sources, mainly the Geonet Names Server (GNS) [9] gazetteer of the National Geospatial Intelligence Agency (NGA), the Geographic Names Information System (GNIS) <ref type="bibr" coords="3,418.62,171.24,11.67,9.02" target="#b7">[8]</ref> gazetteer of the U.S. Geographic Survey, the GTOPO30 <ref type="bibr" coords="3,224.69,182.76,11.68,9.02" target="#b2">[3]</ref> digital elevation model for the world developed by United States Geological Survey (USGS) and Wikipedia, among others.</p><p>For our purposes, all data was loaded and indexed in a MySQL database, although not all fields (such as time zone or elevation) were to be used: the relevant fields are UFI (unique identifier), NAME_ASCII (name), NAME_ALTERNATE (alternate names), COUNTRY, ADM1 and ADM2 (administrative region where the entity is located), FEATURE_CLASS, FEATURE_TYPE, POPULATION, LATITUDE and LONGITUDE. To simplify the queries, each row is complemented with the expansion of country codes (ES Spain) and/or state codes (NC North Carolina) -when applicable. The final database uses 865KB.</p><p>The geo-entity parser carries out the following tasks:</p><p>Geo-entity recognition: identifies named geo-entities <ref type="bibr" coords="3,327.04,304.20,11.68,9.02" target="#b5">[6]</ref> using the information stored in the gazetteer, looking for candidate named entities matching any substring of one or more words <ref type="bibr" coords="3,448.41,315.72,11.64,9.02" target="#b0">[1]</ref> included in the query and not included in a stopword (or stop-phrase) list <ref type="bibr" coords="3,337.13,327.24,10.63,9.02" target="#b6">[7]</ref>.</p><p>The stopword list is mainly automatically built by extracting those words that are both common nouns and also georeference entities, assuming that the user is asking for the common noun sense (for example, "Aguilera" -for Christina Aguilera-or "tanga" -thong). Specifically we have used lexicons for English, Spanish, French, Italian, Portuguese and German, and have selected words that appear at least with a certain frequency in the query collection. The final stopword list contains 1712 entries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Geo-entity selection:</head><p>The selected named geo-entity will be the one with the longest number of words and, if the same, the one with higher score. The score is computed according to the type of geographic resource (country, region, county, city…) and its population, as shown in the following table. Those values where arbitrarily chosen after different manual executions and subsequent analysis.</p><p>Query tagging: expands the query with information about the selected entity: name, country, longitude, latitude, and type of geographic resource.</p><p>The output of this module is the list of queries in which a possible named geo-entity has been detected, along with its complete tagging. For example: Observe that the geo-entity is specifically marked in the original query, enclosed between double curly brackets, to help the following module to identify the rest of the components of the geographical query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Query Analyzer</head><p>This module parses each previously tagged query to identify the "what" and "geo-relation" components of a geographical query, sorting out the named geo-entity detected by the previous module, enclosed between curly brackets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>It consists of two subsystems:</head><p>Geo-relation identifier: identifies and qualifies spatial relationships supported by a regular expression rules based. Its output is the input list of queries expanded with information related to the identified "geo-relation".</p><p>For instance, continuing with the previous examples, the output would be the following:</p><p>Query|geo-relation|entity|state|country|country (code)|latitude|longitude|feature_class|feature_type airport {{alicante}} car rental week|NONE|Alicante||Spain|ES|38.5|-0.5|A|ADM2 bedroom apartments for sale #@#IN#@# {{bulgaria}}|IN|Bulgaria||Bulgaria|BG |43.0|25.0|A|PCLI hotels #@#IN#@# {{south lake tahoe}}|IN|South Lake Tahoe|California|United States|US|38.93|-119.98|P|PPL helicopter flight training in #@#SOUTH_WEST_OF#@# {{florida}}|SOUTH_WEST_OF|Florida| Indiana|United States|US|40.16|-85.71|P|PPL</p><p>Observe that the geo-relation is also marked in the original query.</p><p>Concept identifier: analyses the output of the previous step and extracts the "what" component of a geographical query applying manually defined grammar rules based on the identified "where" and "georelation" components.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Query Type Classifier</head><p>Finally, the last step is to decide whether the query is indeed a geographical query and, should it be positive, to determine the type of query, according to the type of information that the user is supposed to be looking for:</p><p>Map type: users are looking for natural points of interest, like rivers, beaches, mountains, monuments… Yellow page type: businesses or organizations, like hotels, restaurants, hospitals, etc.</p><p>Information type: users are looking for text information, like news, articles, blogs, and so on.</p><p>The process is carried out by a two level classifier:</p><p>1. First level: a binary classifier to determine whether a query is a geographical or a non-geographical query. This simple classifier is based on the assumption that a query is geographical if the "where" component is not empty.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Second level: a multi-classification rule-based classifier to determine the type of geographical query.</head><p>The multi-classifier treats the tagged queries as a lexicon of semantically related terms (words, multiwords and query parts).</p><p>The classification algorithm applies a knowledge base that consists on a set of manually defined grammar rules, including nouns and grammatically related part-of-speech categories as well as the type of geographical resource. The different valid lemmas are unified using Wordnet synsets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Results</head><p>For the evaluation, multiple human editors labeled 500 queries that were chosen to represent the whole query set. Then all the submitted results were manually compared to those queries following a strict criterion where a match should have all fields correct.</p><p>Table <ref type="table" coords="4,98.16,733.08,5.01,9.02" target="#tab_2">2</ref> shows the evaluation results of our submission, using the well-known evaluation measures of precision, recall and F1-score. According to the task organizers, our submission achieved the best performance out of the 8 submissions of this year, which was a good reward for our hard work.</p><p>As participants in the task were provided with the evaluation data set, we have further evaluated our submission to separately study the results for each component of the geographical queries and also the performance level-bylevel of the final classifier.</p><p>Table <ref type="table" coords="5,98.16,290.76,5.01,9.02" target="#tab_3">3</ref> shows the individual analysis of the classifier per each extracted field. The first-level classifier achieves a precision of 75.40%. However, the second-level classifier reduces this value to 56.20% for the WHAT-TYPE feature. According to a strict evaluation criterion, this would be the precision of the overall experiment. If evaluated only over well-classified (geographical/non geographical) queries, the precision arises to 74.53%. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusions and Future Work</head><p>We have however some disagreements with the evaluation data provided by the organizers. Although some of them may be actual errors, most are due to the complexity and ambiguity of the queries. Table <ref type="table" coords="6,466.74,473.76,5.01,9.02" target="#tab_13">7</ref> shows some examples of queries that have been classified as geographical by our system but have been evaluated as falsepositives. In fact, we think that it would be almost impossible to reach a complete agreement in the parsing or classification for every case among different human editors. The conclusion to be drawn from this is that the task to analyze and classify queries is very hard without a previous contact and without the possibility of interaction and feedback with the user. The analysis of the confusion matrixes for the multiclassifier that are calculated over the topics correctly classified by the first level classifier shows that the probability that a geographical query is classified as "Yellow Page" is very high. This could be related to the uneven distribution of topics (almost 50% of the geographical queries belong to this class). In addition, "Information" type queries have a very low recall. These combined facts point out that the classification rules have not been able to establish a difference between both classes. We will focus on this issue in future participations. Moreover, we will try to incorporate some "user-oriented" disambiguation techniques to improve the first level binary classifier, as it is a key component to eliminate many false-positives.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,104.94,405.54,383.85,9.02;2,104.94,423.00,270.81,9.02"><head>Query</head><label></label><figDesc>Analyzer: identifies the "what" and "geo-relation" components of a geographical query. Query Type Classifier: determines the type of geographical query.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,228.36,670.20,138.53,9.02;2,77.10,450.12,441.19,211.68"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Overview of the system.</figDesc><graphic coords="2,77.10,450.12,441.19,211.68" type="vector_box" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,82.56,448.73,425.18,117.98"><head>Table 1 .</head><label>1</label><figDesc>Entity score.</figDesc><table coords="3,82.56,468.29,425.18,98.42"><row><cell>Feature type</cell><cell>Code</cell><cell>Score</cell></row><row><cell>Capital and other big cities</cell><cell>PPLA, PPLC, PPLG</cell><cell>Population+100,000,000</cell></row><row><cell>Political entities</cell><cell>PCL, PCLD, PCLF, PCLI, PCLIX, PCLS</cell><cell>Population+10,000,000</cell></row><row><cell>Countries</cell><cell>A</cell><cell>Population+1,000,000</cell></row><row><cell>Other cities</cell><cell>PP, STLMT</cell><cell>Population+100,000</cell></row><row><cell>Other</cell><cell>*</cell><cell>Population</cell></row><row><cell>For all cities, if country/state</cell><cell>PP, STLMT</cell><cell>Score += 100,000,000</cell></row><row><cell>name/code is also in the query</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,213.30,73.26,167.34,131.73"><head>Table 2 .</head><label>2</label><figDesc>Overall results.</figDesc><table coords="5,213.30,90.01,167.34,114.97"><row><cell cols="6">Precision (1)</cell><cell></cell><cell cols="2">Recall (2)</cell><cell>F1-score (3)</cell></row><row><cell></cell><cell cols="3">0.428</cell><cell></cell><cell></cell><cell></cell><cell cols="2">0.566</cell><cell>0.488</cell></row><row><cell>(1)</cell><cell cols="5">precision =</cell><cell cols="3">_queries ries tagged_que all_tagged correctly_</cell></row><row><cell>(2)</cell><cell cols="3">recall =</cell><cell cols="5">nt_queries all_releva ries tagged_que correctly_</cell></row><row><cell>(3)</cell><cell>F1</cell><cell>-</cell><cell cols="2">score</cell><cell>=</cell><cell>2</cell><cell>precision precision * +</cell><cell>recall recall *</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,70.92,348.72,442.16,95.06"><head>Table 3 .</head><label>3</label><figDesc>Individual analysis per component.</figDesc><table coords="5,70.92,367.38,442.16,76.40"><row><cell></cell><cell cols="2">LOCAL</cell><cell cols="2">WHAT</cell><cell cols="2">WHAT-TYPE</cell><cell cols="2">WHERE</cell><cell cols="2">ALL</cell></row><row><cell></cell><cell>Total</cell><cell>%</cell><cell>Total</cell><cell>%</cell><cell>Total</cell><cell>%</cell><cell>Total</cell><cell>%</cell><cell>Total</cell><cell>%</cell></row><row><cell>All topics</cell><cell>377</cell><cell>75.40</cell><cell>323</cell><cell>64.60</cell><cell>281</cell><cell>56.20</cell><cell>321</cell><cell>64.20</cell><cell>259</cell><cell>51.80</cell></row><row><cell>Well-classified</cell><cell>377</cell><cell>100.00</cell><cell>323</cell><cell>85.67</cell><cell>281</cell><cell>74.53</cell><cell>321</cell><cell>85.15</cell><cell>259</cell><cell>68.70</cell></row><row><cell cols="7">The confusion matrix for the first-level classifier is shown in Table 4.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,94.68,458.22,403.14,84.42"><head>Table 4 .</head><label>4</label><figDesc>Confusion matrix for the binary classifier.</figDesc><table coords="5,94.68,477.12,403.14,65.51"><row><cell cols="2">ASSIGNED YES ASSIGNED NO</cell><cell cols="7">LOCAL YES LOCAL NO 297 111 12 80</cell><cell cols="3">Precision (1) 0.73</cell><cell></cell><cell cols="4">Recall (2) 0.96</cell><cell></cell><cell>Accuracy (3) 0.75</cell></row><row><cell>(1)</cell><cell cols="2">precision</cell><cell>=</cell><cell>FP TP TP +</cell><cell>(2)</cell><cell>recall</cell><cell>=</cell><cell>FN TP TP +</cell><cell>(3)</cell><cell>accuracy</cell><cell>=</cell><cell>TP</cell><cell>+</cell><cell>TN TP</cell><cell>+ +</cell><cell>FP TN</cell><cell>+</cell><cell>FN</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="5,70.92,575.34,453.62,20.54"><head>Table 5 (</head><label>5</label><figDesc>a, b, c) presents the confusion matrixes for the multiclassifier, individualized per class and calculated over all topics.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="5,76.92,604.32,434.82,60.56"><head>Table 5a .</head><label>5a</label><figDesc>Confusion matrix for the multiclassifier, "Yellow Page" class.</figDesc><table coords="5,76.92,628.86,434.82,36.02"><row><cell>ASSIGNED YES ASSIGNED NO</cell><cell>Yellow-Page YES Yellow-Page NO 142 190 7 161</cell><cell>Precision 0.43</cell><cell>Recall 0.95</cell><cell>Accuracy 0.61</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="5,110.28,686.40,368.16,60.56"><head>Table 5b .</head><label>5b</label><figDesc>Confusion matrix for the multiclassifier, "Map" class.</figDesc><table coords="5,110.28,710.94,368.16,36.02"><row><cell>ASSIGNED YES ASSIGNED NO</cell><cell>Map YES Map NO 45 16 41 398</cell><cell>Precision 0.74</cell><cell>Recall 0.52</cell><cell>Accuracy 0.89</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="6,78.06,73.26,432.60,60.56"><head>Table 5c .</head><label>5c</label><figDesc>Confusion matrix for the multiclassifier, "Information" class.</figDesc><table coords="6,78.06,97.80,432.60,36.02"><row><cell>ASSIGNED YES ASSIGNED NO</cell><cell>Information YES Information NO 14 1 57 428</cell><cell>Precision 0.93</cell><cell>Recall 0.20</cell><cell>Accuracy 0.88</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="6,70.92,155.28,453.60,20.54"><head>Table 6</head><label>6</label><figDesc>(a, b, c) presents the same confusion matrixes per class, but calculated only over topics which are correctly classified by the first level binary classifier.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="6,81.60,190.26,425.46,60.56"><head>Table 6a .</head><label>6a</label><figDesc>Confusion matrix for the multiclassifier, "Yellow Page" class.</figDesc><table coords="6,81.60,214.80,425.46,36.02"><row><cell>ASSIGNED YES ASSIGNED NO</cell><cell>Yellow-Page YES Yellow-Page NO 142 92 2 141</cell><cell>Precision 0.61</cell><cell>Recall 0.99</cell><cell>Accuracy 0.75</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" coords="6,110.28,272.34,368.16,60.56"><head>Table 6b .</head><label>6b</label><figDesc>Confusion matrix for the multiclassifier, "Map" class.</figDesc><table coords="6,110.28,296.88,368.16,36.02"><row><cell>ASSIGNED YES ASSIGNED NO</cell><cell>Map YES Map NO 14 0 54 309</cell><cell>Precision 0.92</cell><cell>Recall 0.55</cell><cell>Accuracy 0.89</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" coords="6,78.06,354.36,432.60,60.56"><head>Table 6c .</head><label>6c</label><figDesc>Confusion matrix for the multiclassifier, "Information" class.</figDesc><table coords="6,78.06,378.90,432.60,36.02"><row><cell>ASSIGNED YES ASSIGNED NO</cell><cell>Information YES Information NO 14 0 54 309</cell><cell>Precision 1.00</cell><cell>Recall 0.21</cell><cell>Accuracy 0.86</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13" coords="6,84.36,554.70,426.64,112.52"><head>Table 7 .</head><label>7</label><figDesc>Some examples of ambiguities.</figDesc><table coords="6,84.36,573.36,426.64,93.86"><row><cell>QueryNo</cell><cell>Query</cell><cell>Extracted "where"</cell><cell>Why not?</cell></row><row><cell>113501</cell><cell>calabria chat</cell><cell>calabria, Italy</cell><cell>chat rooms about the region of</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Calabria?</cell></row><row><cell>443245</cell><cell>Machida</cell><cell>machida, Japan</cell><cell>Hiroko Machida (actress), Kumi</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Machida (artist) or the city of</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Machida?</cell></row><row><cell>486273</cell><cell>montserrat reporter</cell><cell>montserrat, Montserrat</cell><cell>online newspaper or reporters in</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Montserrat?</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work has been partially supported by the <rs type="funder">Spanish R&amp;D National Plan</rs>, by means of the project <rs type="projectName">RIMMEL (Multilingual and Multimedia Information Retrieval, and its Evaluation</rs>), <rs type="grantNumber">TIN2004-07588-C03-01</rs>; and by the <rs type="funder">Madrid's R&amp;D Regional Plan</rs>, by means of the project <rs type="projectName">MAVIR (Enhancing the Access and the Visibility of Networked Multilingual Information for the Community of Madrid</rs>), <rs type="grantNumber">S-0505/TIC/000267</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_S52Q5xY">
					<idno type="grant-number">TIN2004-07588-C03-01</idno>
					<orgName type="project" subtype="full">RIMMEL (Multilingual and Multimedia Information Retrieval, and its Evaluation</orgName>
				</org>
				<org type="funded-project" xml:id="_a2hGBwq">
					<idno type="grant-number">S-0505/TIC/000267</idno>
					<orgName type="project" subtype="full">MAVIR (Enhancing the Access and the Visibility of Networked Multilingual Information for the Community of Madrid</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,97.92,205.86,392.98,9.02" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,177.09,205.86,149.16,9.02">A Maximum-Entropy-Inspired Parser</title>
		<author>
			<persName coords=""><forename type="first">Eugene</forename><surname>Charniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,343.49,205.86,116.93,9.02">Proceedings of NAACL-2000</title>
		<meeting>NAACL-2000</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,97.92,223.32,365.62,9.02" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="7,97.92,223.32,131.77,9.02">Geonames geographical database</title>
		<ptr target="http://www.geonames.org[Visited14/08/2007" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,97.92,240.84,426.52,9.02;7,97.92,252.30,86.10,9.02" xml:id="b2">
	<monogr>
		<ptr target="http://eros.usgs.gov/products/elevation/gtopo30.html[Visited14/08/2007" />
		<title level="m" coord="7,97.92,240.84,172.70,9.02">Global 30 Arc-Second Elevation Data Set</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,97.92,269.82,426.63,9.02;7,97.92,281.34,426.52,9.02;7,97.92,292.80,426.74,9.02;7,97.92,304.32,426.65,9.02;7,97.92,315.84,22.53,9.02" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,381.37,269.82,143.19,9.02;7,97.92,281.34,262.81,9.02">MIRACLE at Ad-Hoc CLEF 2005: Merging and Combining without Using a Single Approach</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Goñi-Menoyo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>González-Cristóbal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Villena-Román</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,372.10,281.34,152.35,9.02;7,97.92,292.80,353.76,9.02">Accessing Multilingual Information Repositories: 6th Workshop of the Cross Language Evaluation Forum 2005</title>
		<title level="s" coord="7,295.11,304.32,142.19,9.02">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">4022</biblScope>
		</imprint>
	</monogr>
	<note>CLEF 2005. Revised Selected Papers</note>
</biblStruct>

<biblStruct coords="7,97.92,333.30,426.62,9.02;7,97.92,344.82,426.55,9.02;7,97.92,356.34,426.67,9.02;7,97.92,367.80,367.82,9.02" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,506.25,333.30,18.29,9.02;7,97.92,344.82,131.58,9.02">First Experiments in Geographical IR</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lana-Serrano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Goñi-Menoyo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>González-Cristóbal</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Miracle</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Geoclef</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,233.97,344.82,290.50,9.02;7,97.92,356.34,216.45,9.02">Accessing Multilingual Information Repositories: 6th Workshop of the Cross Language Evaluation Forum 2005</title>
		<title level="s" coord="7,159.95,367.80,141.13,9.02">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005. 2006</date>
			<biblScope unit="volume">4022</biblScope>
			<biblScope unit="page" from="920" to="923" />
		</imprint>
	</monogr>
	<note>CLEF 2005. Revised Selected Papers</note>
</biblStruct>

<biblStruct coords="7,97.92,385.32,426.58,9.02;7,97.92,396.84,426.55,9.02;7,97.92,408.30,426.51,9.02;7,97.92,419.82,86.34,9.02" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,453.87,385.32,70.63,9.02;7,97.92,396.84,426.55,9.02;7,97.92,408.30,26.74,9.02">MIRACLE&apos;s Ad-Hoc and Geographic IR approaches for CLEF 2006: 7th Workshop of the Cross Language Evaluation Forum</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Goñi-Menoyo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>González-Cristóbal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lana-Serrano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Martínez-González</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,152.40,408.30,45.13,9.02">CLEF 2006</title>
		<title level="s" coord="7,467.83,408.30,56.60,9.02;7,97.92,419.82,82.14,9.02">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Alicante, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>Revised Selected Papers</note>
</biblStruct>

<biblStruct coords="7,97.92,437.34,426.57,9.02;7,97.92,448.79,207.51,9.02" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="7,201.47,437.34,269.96,9.02">Page of resources for CLEF (Stopwords, transliteration, stemmers</title>
		<ptr target="http://www.unine.ch/info/clef[Visited18/07/2006" />
		<imprint/>
		<respStmt>
			<orgName>University of Neuchatel</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="7,97.92,466.31,304.09,9.02" xml:id="b7">
	<analytic>
		<title/>
		<ptr target="http://www.usgs.gov[Visited14/08/2007" />
	</analytic>
	<monogr>
		<title level="j" coord="7,97.92,466.31,93.02,9.02">U.S. Geological Survey</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
