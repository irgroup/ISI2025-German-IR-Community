<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,198.80,74.14,214.38,12.64">MSRA Columbus at GeoCLEF2007</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,194.72,95.27,48.49,9.02"><forename type="first">Zhisheng</forename><surname>Li</surname></persName>
							<email>zsli@mail.ustc.edu.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Sci. &amp; Tech. of China</orgName>
								<address>
									<postCode>230026</postCode>
									<settlement>Hefei</settlement>
									<region>Anhui</region>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,251.48,95.27,53.10,9.02"><forename type="first">Chong</forename><surname>Wang</surname></persName>
							<email>chwang@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="department">Microsoft Research Asia</orgName>
								<orgName type="institution">Sigma</orgName>
								<address>
									<addrLine>4F, Center, No.49, Zhichun Road</addrLine>
									<postCode>100080</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,312.92,95.27,36.82,9.02"><forename type="first">Xing</forename><surname>Xie</surname></persName>
							<email>xingx@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="department">Microsoft Research Asia</orgName>
								<orgName type="institution">Sigma</orgName>
								<address>
									<addrLine>4F, Center, No.49, Zhichun Road</addrLine>
									<postCode>100080</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,358.04,95.27,55.78,9.02"><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
							<email>wyma@microsoft.com</email>
							<affiliation key="aff1">
								<orgName type="department">Microsoft Research Asia</orgName>
								<orgName type="institution">Sigma</orgName>
								<address>
									<addrLine>4F, Center, No.49, Zhichun Road</addrLine>
									<postCode>100080</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">P.R. China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,198.80,74.14,214.38,12.64">MSRA Columbus at GeoCLEF2007</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">AEAA9AA3C82A2E956B03F7D53BF63115</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.2.3 [Database Management]: Languages -Query Languages Measurement, Performance, Experimentation Geographic information retrieval, System design, Latent Dirichlet Allocation, Evaluation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the participation of Columbus Project of Microsoft Research Asia (MSRA) in GeoCLEF2007 (a cross-language geographical retrieval track which is part of Cross Language Evaluation Forum). This is the second time we participate in this event. Since the queries in GeoCLEF2007 are similar to those in GeoCLEF2006, we leverage most of the methods that we used in GeoCLEF2006, including MSRAWhitelist, MSRAExpansion, MSRALocation and MSRAText approaches. The difference is that MSRAManual approach is not included in GeoCLEF2007 this time, and we use MSRALDA instead. In MSRALDA, we combine the Latent Dirichlet Allocation (LDA) model with the text retrieval model. The results show that the application of LDA model in GeoCLEF monolingual English task needs to be further explored.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In general web search and mining, location information is usually discarded. However, people need to deal with locations all the time, such as dining, traveling and shopping. GeoCLEF <ref type="bibr" coords="1,360.68,457.79,11.72,9.02" target="#b6">[7]</ref> aims at providing necessary platform for evaluating the geographic information retrieval. We also participated in GeoCLEF2006, and this is second time we participate this GeoCLEF event. The same to GeoCLEF2006, we only participated in the Monolingual GeoCLEF evaluation (EN-EN) and submitted five runs based on different methods. Offline-Phase</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Geographic Information Retrieval System</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Online-Phase</head><p>Figure <ref type="figure" coords="2,99.80,73.07,4.98,9.02" target="#fig_0">1</ref> is the system flow of our GIR system used in GeoCLEF2007. Our geographic information retrieval system is mainly composed of geo-knowledge base, location extraction module, geo-focus detection module, queryprocessing module, geo-indexing module and geo-ranking module. We will describe these modules in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Geographic Knowledge Base</head><p>The Geographic Knowledge Base (GKB) we use is the same as that used in the last year. We use an internal geographic database as our basic gazetteer. This gazetteer contains basic information about locations all over the world, including location name, location type, location importance and hierarchical relationship between locations. We utilize this gazetteer to extract locations, to disambiguate locations and detect focuses of documents. Besides this gazetteer, we also use some other resources to improve the performance, including stop word list, person name list, white list and location indicator list. The method to generate the stop word list can be found in our report last year <ref type="bibr" coords="2,521.96,194.39,15.34,9.02" target="#b11">[12]</ref>.</p><p>The white list and location indicator list is maintained manually, while the person name list is downloaded from the Internet. Finally we integrated all these resources as a GKB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Location Extraction Module</head><p>Location Extraction module aims to extract locations and also disambiguate them from unstructured text. It is used in the query processing module and geo-indexing module. We manually composed the rules to address this task. It includes several parts: text parsing, geo-parsing, geo-disambiguating and geo-coding. For more details, please see our reports last year <ref type="bibr" coords="2,137.12,281.27,15.43,9.02" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Geographic Focus Detection Module</head><p>When the locations' exact positions are determined, we want to get the focus of the documents. We adopted the algorithm described in <ref type="bibr" coords="2,147.80,321.95,10.69,9.02" target="#b4">[5]</ref>. Its main idea is to accumulate the score of each node in the hierarchical tree from bottom to up, and to sort all the nodes whose score are not equal to zero. Then we can get a list of focuses about the documents.</p><p>The location with the biggest score is the most possible focus. For example, a document, mainly talking about Redmond economics, also has mentioned Seattle economics and the focus of the document is Redmond.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Query Processing Module</head><p>GeoCLEF2007 topics are structured topics, in which they contain topic numbers, topic-titles, topic-descriptions and topic-narratives. They don't provide explicit locations and relationships, so we need to parse the queries first and identify the geographic references, e.g. the textual terms, spatial relationships and the locations, from the different parts of the topics. But some topics are hard to be parsed. For example, "Lakes with monsters", "Rivers with floods", they don't contain explicit locations in the topics. For other examples, "Sport events in the French speaking part of Switzerland", "F1 circuits where Ayrton Senna competed in 1994", these human-language style queries are too difficult for machines to understand. Therefore, we designed three schemes to process the topics: automatic extraction, pseudo feedback and man-made whitelist.</p><p>1. Automatic extraction. We use the location extraction module to extract locations and get coordinates. To identify the relationships, e.g. "in", "near", we design a simple relationship matching program by adopting a rulebased approach. Except locations and relationships, we regard the left parts in the query-title as the text keyword.</p><p>In such a way, we can handle topics containing explicit locations, e.g. "Damage from acid rain in northern Europe", "OSCE meetings in Eastern Europe". 2. Pseudo Feedback. For topics which don't contain explicit locations, we use pseudo feedback technique to expand the queries. We do this in the following steps. First, we search the topic title in our search engine to get the top-N documents (here we set N = 100), then we use the location extraction module to extract the locations from these documents and select the most frequent ones (the top 10 ones in our experiments). Finally, we use the selected ones as the locations for the queries. 3. Manual expansion. For the topics like "Whisky making in the Scottish Islands", "Water quality along coastlines of the Mediterranean Sea", though they contain location names in the titles, it is still difficult to identify the precise locations from these imprecise names, e.g. the coastlines of the Mediterranean Sea, the Scottish Islands. We expand them to exact locations manually by looking up in our geographic base as the location whitelist.</p><p>After processing the topics, we obtain the textual terms, spatial relationship and locations of the topics and send them to our GIR system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Geo-Indexing Module</head><p>We use a hybrid indexing schema in our GIR system, which contains two parts: text index and geo-index. In our system, explicit locations and implicit locations <ref type="bibr" coords="3,259.04,98.39,11.72,9.02" target="#b8">[9]</ref> are indexed together and different geo-confidence scores are assigned to them. The advantage of this mechanism is that no query expansion is necessary and implicit location information can be computed offline for fast retrieval. In our system, we adopt two types of geo-indexes: one is called focus-index, which utilizes the inverted index to store all the explicit, and implicit locations of documents; the other is called grid-index, which divides the surface of the Earth into 1000 × 2000 grids. The documents will be indexed by these grids according to their focuses. For more details, please see our reports last year <ref type="bibr" coords="3,435.08,155.99,15.43,9.02" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Geo-Ranking module</head><p>For the ranking module, we adopt IREngine, developed by MSRA, as our basic search engine. Then we integrated the geo-ranking module into it. To test the effectiveness of different methods, we totally designed three kinds of ranking algorithms: 1) pure textual ranking. Its basic ranking function is BM25; 2) linearly combining the text relevance and the geo-relevance; 3) linearly combing the text relevance and the LDA relevance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.1">Geo-based Model</head><p>In the second scheme, we retrieve a document list with geo-relevance from the geo-index by looking up the geographic terms. That is, for the focus-index, the matched docID list can be retrieved by looking up the locationID in the inverted index. For the grid-index, we can get the docID list by looking up the grids that the query location covers. We first retrieve two lists of documents relevant to the textual terms and the geographical terms respectively, and then merge them to get the final results. For re-ranking, we used a combined ranking function , where is the textual relevance score and is the geo-relevance score. Experiments show that textual relevance scores should be weighted higher than geo-relevance scores (</p><p>In our experiments).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.2">LDA-based Model</head><p>For the third scheme, we explored the Latent Dirichlet Allocation model in our GeoCLEF2007 experiments. Latent Dirichlet Allocation (LDA) model <ref type="bibr" coords="3,212.24,358.31,16.64,9.02" target="#b9">[10]</ref> is a semantically consistent topic model. In LDA, the topic mixture is drawn from a conjugate Dirichlet prior that remains the same for all documents. The graphical model of LDA is shown in Figure <ref type="figure" coords="3,99.44,381.47,3.77,9.02" target="#fig_1">2</ref>. The generative process for LDA can be stated as follows:</p><p>For each text document 1. Choose . 2. For each word in document a. Choose a topic . b. Choose a word , which is a topic-specific multinomial probability distribution.</p><p>Thus, the likelihood of generating a corpus is:</p><p>The LDA model is represented as a probabilistic graphical model. Compared to the probabilistic Latent Semantic Indexing model (pLSI) <ref type="bibr" coords="3,167.36,695.75,15.34,9.02" target="#b10">[11]</ref>, LDA processes fully consistent generative semantics by treating the topic mixture dis-</p><formula xml:id="formula_0" coords="3,229.40,399.80,132.96,100.68">α θ D z w N β</formula><p>tribution as a -parameter hidden variable rather than a large set of individual parameters which are explicitly linked to the training set. Thus LDA overcomes the overfitting problem and has the fully generative process for new documents.</p><p>In <ref type="bibr" coords="4,82.40,111.83,15.43,9.02" target="#b12">[13]</ref>, Xing et al. discussed the application of LDA in ad hoc retrieval. We use the similar approach for our geographic information retrieval task in GeoCLEF2007, which allows us to compute a probability a query given a document using LDA model. That is each document is scored by the likelihood of its model generating a query ,</p><p>where is a document model, is the query and q is a query term in . is the likelihood of the document model generating the query terms under the "bag-of-words" assumption that terms are independent given the documents. In our experiment, we use LDA model as the document model.</p><p>After we computed the , we selected the top 1000 documents with the highest for each query. We also use our text search engine to retrieve top 1000 documents respectively. Then we merged these two document-lists. If one document in both of the list, we used a combined score function , where is the textual relevance score and is the LDA model probability (here we set = 0.5). Both scores are normalized. Otherwise, we computed a new score for the document by multiplying a decay factor 0.5. Finally we re-ranked all these documents by the new scores and selected the top 1000 ones as result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Monolingual GeoCLEF Experiments (English -English)</head><p>In Table <ref type="table" coords="4,108.80,308.63,3.77,9.02">1</ref>, we show all the five runs submitted to GeoCLEF. When the topic field is "Title", we just use the title element of the topic to generate the query of the run. When the topic field is "Title + Description", this means that the title and desc are both used in the run. When the topic field is "Title + Description + Narrative", this means that title, desc and narr are all used. And the "Description" field in Table <ref type="table" coords="4,358.88,343.07,4.98,9.02">1</ref> gives a simple explanation of the methods used in the runs. Priorities are assigned by us, where priority 1 is the highest and 5 the lowest. In MSRALDA, we used the title elements to generate the queries. Then we used the LDA-based model described in section 2.6.2 to select 1000 documents for each query. In MSRAWhiteList, we used the Title and Desc elements of the topics to generate the queries. For some special queries, e.g. "Scottish Islands", "coastlines of the Mediterranean Sea", we cannot get the exact locations directly from our gazetteer, so we utilized the GKB to get the corresponding geo-entities. Then we can make a whitelist manually for the geo-terms of these queries. In MSRAExpansion, we generated the queries with title and desc elements of the topics. Different from MSRAWhiteList, the queries were automatically expanded based on the pseudo-feedback technique. First we used the original queries to search the corpus. Then we extracted the locations from the returned documents and calculated the times each location appears in the documents. Finally we got the top 10 most frequent location names and combined them with the original geoterms in the queries. In MSRALocation, we used the title elements of the topics to generate the queries. And we do not use geo knowledge base or query expansion method to expand the query locations. We just utilize our location extraction module to extract the locations automatically from the queries. In MSRAText, we generated the queries with title, desc and narr elements of the topics. We just utilized our pure text search engine "IREngine" to process the queries.  <ref type="table" coords="5,151.04,657.35,4.98,9.02" target="#tab_0">2</ref> show the results of MSRA Columbus on the GeoCLEF monolingual English task. MSRAText run achieves the best precision in our results. The precision of MSRALDA run decreases after combing the LDA model with the pure text model. As the same as GeoCLEF2006, the performance of MSRAExpansion is the lowest among the five runs, because many unrelated locations are added to new topics after pseudo feedback for some topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1. Run information</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results and Discussion</head><p>From </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="1,217.76,691.01,176.42,8.96"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Architecture of our GIR system</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,198.68,513.05,214.29,8.96"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Graphical representation of LDA model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,82.04,386.75,15.24,9.02;4,154.52,386.75,50.31,9.02;4,290.12,386.75,46.62,9.02;4,511.88,386.75,30.66,9.02;4,66.80,402.23,48.83,9.02;4,154.52,402.23,18.94,9.02;4,290.12,402.23,96.61,9.02;4,511.88,402.23,4.98,9.02;4,66.80,420.83,68.29,9.02;4,154.52,420.83,76.26,9.02;4,290.12,420.71,210.92,9.02;4,290.12,432.23,34.98,9.02;4,511.88,420.83,4.98,9.02;4,66.80,447.83,70.50,9.02;4,154.52,447.83,76.26,9.02;4,290.12,447.83,89.94,9.02;4,511.88,447.83,4.98,9.02;4,66.80,463.31,63.78,9.02;4,154.52,463.31,18.94,9.02;4,290.12,463.31,199.38,9.02;4,511.88,463.31,4.98,9.02;4,66.80,484.07,46.57,9.02;4,154.52,484.07,194.89,9.02;4,511.88,484.07,4.98,9.02"><head></head><label></label><figDesc>+ Narrative using pure text 5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,138.56,642.05,334.71,8.96;5,70.88,657.35,470.17,9.02;5,70.88,668.75,470.15,9.02;5,70.88,680.27,470.05,9.02;5,184.64,456.48,228.24,179.04"><head>Figure 3 .Figure 3</head><label>33</label><figDesc>Figure 3. Standard recall levels vs mean interpolated precision for all five runsFigure 3 and Table2show the results of MSRA Columbus on the GeoCLEF monolingual English task. MSRAText run achieves the best precision in our results. The precision of MSRALDA run decreases after combing the LDA model with the pure text model. As the same as GeoCLEF2006, the performance of MSRAExpansion is the lowest</figDesc><graphic coords="5,184.64,456.48,228.24,179.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,70.88,100.07,470.34,155.06"><head>Table 2 ,</head><label>2</label><figDesc>we can see that MSRALDA drops the performance significantly compared with MSRAText by about 7.6% in MAP. This indicates that linearly combining LDA model with text model does not work well. The reason may be that we haven't tune the parameter to be the best or linear combination is not a good choice.Though the MAP of MSRALDA is lower than MSRAText, it still outperforms the latter one in some cases. For example, for the 10.2452/53-GC "Scientific research at east coast Scottish Universities", MSRAText just retrieves 39 relevant documents, while MSRALDA retrieves 43 relevant ones (The number of relevant documents is 64). For 10.2452/65-GC "Free elections in Africa", MSRAText retrieves 59 relevant documents and MSRALDA retrieves 74 (The number of relevant documents is 93). And we can see that the standard deviation of MSRALDA is just 0.09, lower than MSRAText. This indicates that MSRAText performs badly in some cases while MSRALDA performs more stably.MSRAWhiteList and MSRALocation achieve similar MAP with each other, about 8.6%. Their MAPs are much lower than MSRAText by about 6.5% and just a little better than MSRAExpansion. Different from the results of GeoC-LEF2006, automatic location extraction and manual expansion don't bring improvements.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,163.88,261.89,274.14,102.80"><head>Table 2 . MAP &amp; Standard Deviation for five runs</head><label>2</label><figDesc></figDesc><table coords="6,163.88,278.15,274.14,86.54"><row><cell>RUN-ID</cell><cell>MAP</cell><cell>Standard Deviation</cell></row><row><cell>MSRALDA</cell><cell>7.51%</cell><cell>0.090</cell></row><row><cell>MSRAWhiteList</cell><cell>8.61%</cell><cell>0.145</cell></row><row><cell>MSRAExpansion</cell><cell>7.01%</cell><cell>0.134</cell></row><row><cell>MSRALocation</cell><cell>8.61%</cell><cell>0.145</cell></row><row><cell>MSRAText</cell><cell>15.19%</cell><cell>0.197</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="5.">Conclusions</head><p>We conclude that the application of LDA model in GeoCLEF monolingual English task needs to be further explored. Another conclusion is that automatic location extraction from the topics does not improve the retrieval performance, even decrease it sometimes. The third conclusion is the same as last year. That is automatic query expansion by pseudo feedback weakens the performance because the topics are too hard to be handled and many unrelated locations are added to new topics. Obviously, we still need to improve the system in many aspects, such as query processing, geo-indexing and geo-ranking.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="6,88.88,474.71,403.17,9.02" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,273.92,474.71,160.11,9.02">Web-a-where: Geotagging Web Content</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amitay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Har'el</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sivan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Soffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,440.84,474.71,46.68,9.02">SIGIR 2004</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.88,490.07,442.52,9.02;6,88.88,501.71,116.85,9.02" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,246.32,490.07,258.80,9.02">Efficient Query Processing in Geographical Web Search Engines</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Suel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Markowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,512.00,490.07,19.40,9.02;6,88.88,501.71,33.51,9.02">SIG-MOD&apos;06</title>
		<meeting><address><addrLine>Chicago, IL, USA</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.88,517.19,445.41,9.02" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,250.04,517.19,165.30,9.02">Indexing and Ranking in Geo-IR Systems</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Silva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Andrade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,422.36,517.19,28.47,9.02">GIR&apos;05</title>
		<meeting><address><addrLine>Bremen, Germany</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.88,532.67,436.65,9.02;6,88.88,544.19,59.49,9.02" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,135.80,532.67,194.30,9.02">Cross-Language Retrieval Experiments at CLEF</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">T</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="6,357.80,532.67,142.54,9.02">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">2785</biblScope>
			<date type="published" when="2002">2002. 2003</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.88,559.67,432.09,9.02;6,88.88,571.19,111.81,9.02" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,294.44,559.67,222.19,9.02">Detecting Geographical Locations from Web Resources</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,88.88,571.19,28.26,9.02">GIR&apos;05</title>
		<meeting><address><addrLine>Bremen, Germany</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.88,586.79,347.25,9.02" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,205.52,586.79,129.81,9.02">Analyzing Geographical Queries</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kohler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,342.08,586.79,28.36,9.02">GIR&apos;04</title>
		<meeting><address><addrLine>Sheffield, UK</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.88,602.27,174.01,9.02" xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Geoclef</surname></persName>
		</author>
		<ptr target="http://ir.shef.ac.uk/geoclef/" />
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.88,617.63,448.52,9.02;6,88.88,629.27,314.73,9.02" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,322.28,617.63,215.12,9.02;6,88.88,629.27,115.03,9.02">The SPIRIT Spatial Search Engine: Architecture, Ontologies and Spatial Indexing</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">B</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">I</forename><surname>Abdelmoty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Finch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vaid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="6,210.80,629.27,142.66,9.02">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="volume">3234</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.88,644.63,437.46,9.02;6,88.88,656.27,128.49,9.02" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,307.88,644.63,218.46,9.02;6,88.88,656.27,32.16,9.02">Indexing implicit locations for geographic information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><forename type="middle">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,127.16,656.27,28.36,9.02">GIR&apos;06</title>
		<meeting><address><addrLine>Seattle, USA</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.88,671.63,434.00,9.02;6,88.88,683.27,122.61,9.02" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,279.20,671.63,103.93,9.02">Latent Dirichlet allocation</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,389.48,671.63,133.40,9.02;6,88.88,683.27,23.94,9.02">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003-01">2003. Jan. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,88.88,73.07,435.25,9.02;7,88.88,84.71,102.33,9.02" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,142.76,73.07,148.93,9.02">Probabilistic latent semantic indexing</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,298.40,73.07,225.73,9.02;7,88.88,84.71,72.71,9.02">Proceedings of the Twenty-Second Annual International SIGIR Conference</title>
		<meeting>the Twenty-Second Annual International SIGIR Conference</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,88.88,100.07,439.29,9.02;7,88.88,111.71,106.74,9.02" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Y</forename><surname>Ma</surname></persName>
		</author>
		<title level="m" coord="7,251.24,100.07,145.80,9.02">MSRA Columbus at GeoCLEF 2006</title>
		<meeting><address><addrLine>GeoCLEF; Alicante, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-09">2006. Sep. 2006</date>
		</imprint>
	</monogr>
	<note>working note</note>
</biblStruct>

<biblStruct coords="7,88.88,127.07,445.29,9.02;7,88.88,138.71,60.93,9.02" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,189.56,127.07,207.38,9.02">LDA-based Document Models for Ad-hoc Retrieval</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,414.20,127.07,116.41,9.02">the Proceedings of SIGIR &apos;06</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="178" to="185" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
