<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
				<funder ref="#_vRHD4er">
					<orgName type="full">European Commission</orgName>
				</funder>
				<funder ref="#_c8KVPEJ #_Bv5FDqB">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder>
					<orgName type="full">Tampere Graduate School of Information Science and Engineering</orgName>
					<orgName type="abbreviated">TISE</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,118.99,183.47,59.12,8.74"><forename type="first">Anni</forename><surname>JÃ¤rvelin</surname></persName>
							<email>anni.jarvelin@uta.fi</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Tampere</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,188.66,183.47,59.72,8.74"><forename type="first">Peter</forename><surname>Wilkins</surname></persName>
							<email>pwilkins@computing.dcu.ie</email>
							<affiliation key="aff1">
								<orgName type="institution">University</orgName>
								<address>
									<settlement>Dublin City</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,258.94,183.47,72.29,8.74"><forename type="first">Tomasz</forename><surname>Adamek</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University</orgName>
								<address>
									<settlement>Dublin City</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,341.78,183.47,42.79,8.74"><forename type="first">Eija</forename><surname>Airio</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Tampere</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,395.12,183.47,81.65,8.74"><forename type="first">Gareth</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University</orgName>
								<address>
									<settlement>Dublin City</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,219.24,197.70,74.31,8.74"><forename type="first">Alan</forename><forename type="middle">F</forename><surname>Smeaton</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University</orgName>
								<address>
									<settlement>Dublin City</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,312.40,197.70,66.89,8.74"><forename type="first">Eero</forename><surname>Sormunen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Tampere</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Dublin City University (DCU)</orgName>
								<orgName type="institution" key="instit2">University of Tampere</orgName>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">65EED10E67517EDAD5A9E325051E559D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.3 Information Search and Retrieval Measurement</term>
					<term>Performance</term>
					<term>Experimentation Fuzzy matching</term>
					<term>Content-Based Image Retrieval</term>
					<term>Data Fusion</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>UTA) participated in the ImageCLEF 2007 photographic ad-hoc retrieval task with several monolingual and bilingual runs. Our approach was language independent: text retrieval based on fuzzy s-gram query translation was combined with visual retrieval. Data fusion between text and image content was performed using unsupervised query-time weight generation approaches. Our baseline was a combination of dictionary-based query translation and visual retrieval, which achieved the best result. The best mixed modality runs using fuzzy s-gram translation achieved on average around 83% of the performance of the baseline. Performance was more similar when only top rank precision levels of P10 and P20 were considered. This suggests that fuzzy sgram query translation combined with visual retrieval is a cheap alternative for cross-lingual image retrieval where only a small number of relevant items are required. Both sets of results emphasize the merit of our query-time weight generation schemes for data fusion, with the fused runs exhibiting marked performance increases over single modalities, this is achieved without the use of any prior training data.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In earlier ImageCLEF campaigns combined text and visual retrieval approaches have performed better than text or image retrieval alone. Also, text retrieval alone has clearly outperformed visual-only retrieval approaches <ref type="bibr" coords="1,230.52,643.84,14.61,8.74" target="#b14">[15]</ref>. In this year's campaign, text retrieval was faced with a new challenge of retrieval of lightly annotated photographs <ref type="bibr" coords="1,328.36,656.04,9.96,8.74" target="#b5">[6]</ref>. A negative impact on the performance of the text retrieval techniques was to be expected. When the textual context available for image retrieval is sparse, visual retrieval gains more significance and thus effective fusion of text and visual features becomes important. Therefore one of our main research interests in the ImageCLEF photo 2007 task was to study different techniques for fusion of text and visual retrieval results.</p><p>Retrieving images by their associated text is a common approach in image retrieval <ref type="bibr" coords="1,464.77,717.01,14.62,8.74" target="#b14">[15]</ref>. When cross-language image retrieval is considered, this approach requires language dependent linguistic resources for query translation. Machine-readable dictionaries, machine translation tools or corpus-based translation tools are expensive, and are not available for all the language pairs. However, there are alternative approaches which may be used to compensate for poor or absent linguistic translation tools, for example the approximate string matching techniques of n-gramming and its generalization s-gramming. An aspect that speaks for the use of approximate string matching in image retrieval is that proper names are very common query terms when searching image databases <ref type="bibr" coords="2,135.82,172.99,14.61,8.74" target="#b12">[13]</ref>. Machine readable bilingual dictionaries typically do not cover proper names and thus they often remain untranslatable in queries. Proper names in related languages are nevertheless often spelling variants of each other and can thus be recognized and translated using approximate string matching techniques. Generally, when approximate string matching techniques are used, the query words need to have somewhat close cognates in the target language for the translation to succeed.</p><p>We participated in ImageCLEF 2007 photographic ad-hoc retrieval task in order to test a language independent image retrieval approach. The s-gram-based query translation was fused with visual retrieval. To study the relatedness of the source and target languages on the translation quality we selected language pairs where source/target languages were related to each other at different levels. The Scandinavian languages Danish, Norwegian and Swedish are quite closely related to German, while French was the language closest to English available. German and English instead are not very closely related languages and therefore translation between them should be hard. Thus, we had six language pairs: French-English, German-English, Danish-German, Norwegian-German, Swedish-German and English-German. To have a strong baseline, the performance of the language independent approach was compared to a state-of-the-art technique, a combination of dictionary-based query translation and visual retrieval. A total of 138 runs were submitted. Reporting the results for all of these would be impractical and therefore only the results for the best and most interesting runs are presented here.</p><p>Our exploration of data fusion continued within our work in query-time coefficient generation for retrieval expert combination. Within our ImageCLEF work we experimented primarily with altering the stages at which we fuse various experts together. For instance we experimented with fusing all the visual experts into a single expert, then fusing with text, as opposed to treating all experts equally.</p><p>The structure of the paper is following. The text and visual retrieval approaches are presented in more detail in Section 2. In Section 3 our retrieval systems and runs are presented in detail. The results are reported in section 4 and Section 5 finally concludes with a short discussion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">s-gram-based query translation</head><p>Approximate string matching techniques enable target database index words most similar to a query word to be recognized as its translations, and can be used for fuzzy query translation. sgram matching is a technique like this. In s-gram matching the text strings to be compared are decomposed into substrings (s-grams) and the similarity between the strings is calculated as the overlap of their common substrings. s-gram matching is a generalization of the well known ngram technique, which is quite commonly used for matching cognates in CLIR. While the n-gram substrings consist of adjacent characters of the original strings, skipping some characters is allowed when forming the s-grams. In classified s-gram matching <ref type="bibr" coords="2,337.14,651.43,15.50,8.74" target="#b17">[18]</ref> different types of s-grams are formed by skipping different number of characters. The s-grams are then classified into sets based on the number of characters skipped, and only the s-grams belonging to the same set are compared to each other when calculating the similarity. Character combination index (CCI) indicates the set of all the s-gram types to be formed from a string. CCI {{0}, {1, 2}} for example means that three types of s-grams are formed and classified into two sets: one set of conventional n-grams formed of adjacent characters ({0}) and one of s-grams formed both by skipping one and two characters ({1, 2}). For an extensive description of the s-gram matching technique see <ref type="bibr" coords="2,421.34,736.79,15.49,8.74" target="#b17">[18,</ref><ref type="bibr" coords="2,440.15,736.79,11.63,8.74" target="#b9">10]</ref>. n-gram matching has been used for fuzzy translation in a few studies, e.g., by <ref type="bibr" coords="3,455.38,112.02,10.52,8.74" target="#b6">[7]</ref> and <ref type="bibr" coords="3,489.70,112.02,10.52,8.74" target="#b7">[8]</ref> as a complement to the dictionary-based translation and by <ref type="bibr" coords="3,350.58,124.21,15.50,8.74" target="#b13">[14]</ref> for the whole query translation. <ref type="bibr" coords="3,90.00,136.41,106.35,8.74">JÃ¤rvelin et al. 2007 [9]</ref> used s-gram matching in fuzzy query translation between the closely related languages Swedish and Norwegian. Other approaches to fuzzy query translation have been developed by <ref type="bibr" coords="3,148.03,160.80,14.61,8.74" target="#b18">[19]</ref>, who translated out-of-vocabulary words based on statistical transformation rules for character changes between the source and target languages, and by <ref type="bibr" coords="3,409.47,172.99,10.52,8.74" target="#b3">[4]</ref> who treated English query words as misspelled French and attempted to translate them using a spelling correction program.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Visual Retrieval</head><p>To facilitate visual retrieval we made use of six 'low-level' global visual experts. Our visual features are MPEG7 features and were extracted using the aceToolBox, developed as part DCU's collaboration in the aceMedia project <ref type="bibr" coords="3,261.74,268.56,9.96,8.74" target="#b0">[1]</ref>. These six features included: Colour Layout, Colour Structure, Colour Moments, Scalable Colour, Edge Histogram and Homogenous Texture. Further details on these descriptors can be found in <ref type="bibr" coords="3,292.75,292.95,15.50,8.74" target="#b15">[16]</ref> and <ref type="bibr" coords="3,333.41,292.95,14.62,8.74" target="#b10">[11]</ref>. Distance metrics for each of these features were implementations of those specified in the MPEG7 specification <ref type="bibr" coords="3,427.47,305.15,14.61,8.74" target="#b10">[11]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Query-Time Fusion</head><p>The combination of retrieval experts for a given information need can be expressed as a data fusion problem <ref type="bibr" coords="3,128.90,364.14,9.96,8.74" target="#b2">[3]</ref>. Given that for any given information need different retrieval experts perform differently, we require some form of weighting scheme in order to combine experts. Typical approaches to weight generation include the use of query-independent weights, learnt through experimentation on a training collection or query-class experts weights <ref type="bibr" coords="3,348.03,400.72,14.61,8.74" target="#b21">[22]</ref>. A query is categorized into some pre-determined class, and the weights for each class are again learnt through experimentation on a training collection. These approaches however require that both a training collection, and a representative set of training queries for that collection so as to avoid problems of over-fitting expert weights.</p><p>Our approach to weight generation differs in that it is a query-dependant weighting scheme for expert combination which requires no training data <ref type="bibr" coords="3,311.08,473.89,14.62,8.74" target="#b20">[21]</ref>. This work was based upon an observation, that if we plot the normalized scores of an expert, against that of scores of other experts used for a particular query, the expert who's scores exhibited the greatest initial change in scores correlated with that expert being the best performer for this query. An example of this observation is presented in Figure <ref type="figure" coords="3,177.70,522.66,4.98,8.74" target="#fig_0">1</ref> and Table <ref type="table" coords="3,232.77,522.66,3.88,8.74" target="#tab_0">1</ref>.  From the graph it can be observed that the greatest initial change in score is exhibited by the Colour Structure expert, which correlates to the table of performance where Colour Structure is the best performing of the experts. However, this observation is informing us that the Colour Structure expert is likely to be the better performing expert relative to the other experts used for this query. This observation is not giving us any absolute indication of expert performance, which would be the case in techniques such as those employed by Manmathma et al. <ref type="bibr" coords="4,429.79,262.70,14.61,8.74" target="#b11">[12]</ref>, or Arampatzis et al. <ref type="bibr" coords="4,116.57,274.90,9.96,8.74" target="#b1">[2]</ref>.</p><p>At this stage we should note that this observation is not universal, and that there are failure cases where this observation will not hold. If we assume though that in a majority of queries this observation does hold, then we can employ techniques that leverage this approach to create query-time expert coefficients for data fusion.</p><p>Our initial method of exploiting these observations is designed to assign a higher weight to the expert which undergoes the greatest initial change in score. For a given expert, we can measure the average change in score through Equation <ref type="formula" coords="4,299.90,360.26,3.88,8.74" target="#formula_0">1</ref>, which we refer to as Mean Average Distance (MAD):</p><formula xml:id="formula_0" coords="4,210.66,392.45,302.34,25.41">M AD = N -1 n=1 (score(n) -score(n + 1)) N -1<label>(1)</label></formula><p>This value alone though does not provide sufficient information for deriving the rate of change in score of an expert. To achieve this, we define a ratio which measures MAD for a top subset of an expert's document scores over a larger set of document scores, given in Equation <ref type="formula" coords="4,445.69,448.24,3.88,8.74" target="#formula_1">2</ref>:</p><formula xml:id="formula_1" coords="4,248.84,468.90,264.16,22.31">SC = M AD(subset) M AD(largerset)<label>(2)</label></formula><p>This ratio provides us with a single measure of the degree of change in an expert's document scores. With this we can simply divide each ratio value by the sum of all expert's ratio values to arrive at the coefficient for the given expert, formally given in Equation <ref type="formula" coords="4,406.31,523.25,3.88,8.74" target="#formula_2">3</ref>:</p><formula xml:id="formula_2" coords="4,218.13,543.24,294.88,22.31">Expert W eight = F eature SC Score Î£All SC Scores<label>(3)</label></formula><p>The crux of this approach lies in the determination of the values to be used for 'subset' and 'larger set' in Equation <ref type="formula" coords="4,161.06,582.90,3.88,8.74" target="#formula_1">2</ref>. We have previously experimented with fixed sizes for these variables, but found that using a percentage of the size of the expert's returned result list works best, which in practise is the top 5% of an expert's results over the top 95% of the expert's results. As this data fusion technique only requires the results that an expert provides, it can be used to combine multi-modal experts together. Furthermore, it allows us to combine single experts for a given query image into a single result list for that given query image. Once this is performed, we are left with a single result list per query image, meaning we can reapply the same technique to generate weights that can be applied to the query image. This allows us to weight query images differently, as for various queries, each query image may perform better or worse than other query images for a given query. A more complete explanation of this process can be found in <ref type="bibr" coords="4,471.68,692.65,14.62,8.74" target="#b20">[21]</ref>.</p><p>3 Resources, Methods and Runs</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Text Retrieval and Indexing</head><p>We utilized the Lemur toolkit (Indri engine) for indexing and retrieval (www.lemurproject.org, <ref type="bibr" coords="5,90.00,166.94,14.76,8.74" target="#b19">[20]</ref>). Indri combines language modeling to inference nets and allows structured queries to be evaluated using language modeling estimates rather than tf*idf estimates. The word tokenization rules used in indexing were the following. First, punctuation marks were converted into spaces, and capitals were converted into lower case. Next, strings broken down by the space character were decoded to be individual words. Different indices were created for the s-gram-based and dictionary-based query translation. For the dictionary-based translation, lemmatized English and German indices were created. The words of the image annotations were lemmatized with English and German lemmatizers and lemmas were stored into the indices. Words not recognized by the lemmatizers were indexed as such. Compound words were split and both the original compound and the constituents were indexed. With the s-gram-based translation we used inflected indices, where the words were stored in the inflected word forms in which they appeared in the image annotations. Stop words were removed.</p><p>Topic words were not morphologically processed prior to the s-gram-based query translation. Stop words were removed and the remaining words were translated into the target language with s-gram matching. The CCI was set to be 0,1,2 and the Jaccard coefficient <ref type="bibr" coords="5,436.39,337.66,15.50,8.74" target="#b9">[10]</ref> was used for calculating the s-gram proximity. Three best matching index words were selected as translations for each topic word. A similarity threshold value of 0.3 was set to discard bad translations: only the index words exceeding this threshold with respect to a source word were accepted as its translation equivalents. As a consequence, some of the query words could not be translated. Queries were structured utilizing a synonym operator: target words derived from the same source word were grouped into the same synonym group. This kind of structure balances the queries and down-weights the ambiguous words with many possible translations (the Pirkola method, <ref type="bibr" coords="5,490.86,423.02,14.76,8.74" target="#b16">[17]</ref>). We used Indri's Pseudo-Relevance Feedback (PRF) with 10 keys taken from 10 highest ranked documents in the original result list.</p><p>The UTACLIR query translation tool developed at UTA was used for the dictionary-based query translation. UTACLIR was originally developed for the CLEF 2000 and 2001 campaigns <ref type="bibr" coords="5,90.00,483.99,9.97,8.74" target="#b6">[7]</ref>. The system utilizes external language resources, such as translation dictionaries, stemmers and lemmatizers. Word processing in UTACLIR proceeds in the following way. First, topic words are lemmatized in order to match them with dictionary words (our translation dictionaries include source words only in their basic forms). The lemmatizer produces one or more basic forms for a token. After normalization, stop words are removed, and non-stop words are translated. Untranslatable compound words are split and the constituents are translated. Translation equivalents are normalized utilizing a target language lemmatizer. Untranslatable words are matched against the database index with the s-gram matching technique and three best matches are chosen as translations. Queries were structured according to the Pirkola method utilizing a synonym operator. Since there was no French morphological analyzer available to us, the French topics were analyzed manually. This might result in a slightly better quality of lemmatization than automatic analysis, even though we strived for equal quality. In this case we performed PRF with 20 expansion keys from the 15 top ranked documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Data Fusion</head><p>The query-time data fusion approach described in Section 2.3 was adopted as our basic approach to expert combination. However, one set of parameters that was not specified was the order in which experts will be combined. This is the focus of our experimental work in this section.</p><p>One commonality between all the combination approaches we try in this work is the fusion of the low-level visual experts. For each query image we fuse the six low-level visual experts into a single result for each image, where their combination uses the aforementioned technique.</p><p>Therefore for each query, the visual component was then represented by three result sets, one for each query image. Additionally for a subset of our runs we introduce a seventh visual expert, the FIRE baseline <ref type="bibr" coords="6,172.40,136.41,9.96,8.74" target="#b4">[5]</ref>. In cases where FIRE was used, because it was a single result for the three visual query images, we first combined our MPEG7 visual features into a single result for each image, then these were combined into a overall image result, which was then combined with the FIRE baseline. This combination made use of the query-time weighting scheme.</p><p>We explored four variants in our combination work as follows:</p><p>â¢ dyn-equal: Query-time weighting method with text and individual image results combined at the same level, i.e. we have three image results and one text result which are to be combined.</p><p>â¢ dyn-top: As above, except the results for each query image were fused into a single image result, which was then combined with the text result, i.e. image results combined into a single result, which is then combined with the single text result.</p><p>â¢ stat-eventop: Query-time weighting to produce single image result list, image and text fused together with equal static weighting (0.5 coefficient).</p><p>â¢ stat-imgHigh: As above, except with the image result assigned a static weight of 0.8 and text a static weight of 0.2.</p><p>Additionally, any of our runs which ended in 'fire' incorporated the FIRE baseline into the set of visual experts used for combination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>Our tables of results are organized as follows. Table <ref type="table" coords="6,321.85,430.72,4.98,8.74" target="#tab_1">2</ref> presents our baseline runs, both text-only monolingual and visual-only. Table <ref type="table" coords="6,244.77,442.91,4.98,8.74" target="#tab_3">3</ref> presents our baseline fusion results, mixing monolingual text with visual experts. Table <ref type="table" coords="6,209.54,455.11,4.98,8.74" target="#tab_4">4</ref> presents our central cross-lingual results with mixed modalities. In all tables where data fusion is utilized, we present only the best performing data fusion approach. With the exception of Two different indexing approaches were used for the monolingual text runs: The runs marked dict in Table <ref type="table" coords="6,149.35,690.67,4.98,8.74" target="#tab_1">2</ref> used lemmatized indices and topic words. The s-gram runs used inflected indices and the topic words were matched against the index words with s-gram matching. The runs with morphological analysis performed slightly better than the s-gram runs, but for the English runs the difference is very small. For German runs the difference is greater, which is understandable as German has much more complex inflectional morphology than English. Our text-only and visual-only retrieval techniques were almost equal, which is notable in the context of ImageCLEF results in previous years. Our best visual-only run performed well being the overall second best visual approach in terms of Mean Average Precision (MAP). Its MAP value 0.1340 is comparable to our best English-English text-only run scoring 0.1305. We believe that the comparative low performance of the text expert (when compared to the dominance of text in previous years) was due to the reduced length of the annotations for 2007. Table <ref type="table" coords="7,133.29,323.20,4.98,8.74" target="#tab_3">3</ref> presents our fused text and visual retrieval runs, which performed best among our submissions, being clearly better than any of the text or visual runs alone. Of interest is that in each data fusion case, the increase in MAP was 65%-67%. Whilst this is too small a sample to infer any conclusions, it is nonetheless interesting that such a consistent gain was achieved and is worthy of further investigation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language</head><p>From a data fusion perspective, no single approach of the four we tried consistently performed the best. Whilst our results presented here show the "dyn-equal" fusion as being superior, this is because it was the only fusion type attempted with visual data which incorporated the FIRE baseline. For runs where FIRE was not used, the best performing fusion type varied depending on the text type (dictionary or sgram) or language pair used. In the majority of cases all fusion types performed similarly, deeper investigation with significance testing will be required in order to infer any meaningful interpretations. However, we can conclude that as all four fusion types made use of our query-time weight generation method at some level, that this technique is capable of producing weights which lead to performance improvements when combining results. What is unknown is how far from the optimal query-dependant combination we achieved, and knowing this would give one of the ultimate measures of the success of this approach.</p><p>Table <ref type="table" coords="7,132.50,518.31,4.98,8.74" target="#tab_4">4</ref> presents our central cross-lingual results. Dictionary-based query translation was the best query translation approach. The best mixed modality runs using the s-gram-based query translation reached on average around 84% of the MAP of the best mixed modality runs using dictionary-based translation. These approaches were more similar when the top rank precision values at P10 and P20 were considered: the best s-gram runs reached on average around 91% of the best dictionary-based runs performance at P10 and around 89% at P20. If the high ranks of the result list are considered to be important from the user perspective, the s-gram translation could be seen as almost equal with the dictionary-based translation in mixed modality runs. The results for the two text query translation techniques varied depending on the language pair. Generally the s-gram-based translation and the dictionary-based translation were quite equal for the more closely related language pairs, while the dictionary-based translation was clearly better for the more distant language pairs. The s-gram translation reached its best results with Norwegian and Danish topics and German annotations -over 90% of the dictionary translation's MAP, and the worst ones between German and English -less than 80% of the dictionary translation's MAP. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this paper we have presented results for the joint DCU and UTA participation in the ImageCLEF 2007 Photo task. In our work we experimented with two major variables, that of cross-lingual text retrieval utilizing minimal translation resources, and query-time weight generation for expert combination. Our results are encouraging and support further investigation into both approaches. Further work is now required to conduct a more thorough analysis of contributing factors to performance emphasized by each approach. Of particular interest will be the degree to which each of these approaches introduced new information, or re-ordered existing information presented by the systems. For instance, we do not know yet if the s-gram retrieval found relevant documents that were missed by the dictionary based approach. Likewise for data fusion, we do not know yet if we promoted into the final result set relevant results which were only present in some and not all of the experts used.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,188.29,709.91,226.43,8.74;3,193.50,543.36,216.00,151.20"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: ImageCLEF Topic 35 Single Image Query</figDesc><graphic coords="3,193.50,543.36,216.00,151.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,288.22,709.91,126.50,8.74"><head>Table 1 :</head><label>1</label><figDesc>Topic 35 Single Image Query ImageCLEF Topic 35 Single Image Results</figDesc><table coords="4,190.10,110.99,222.80,45.72"><row><cell>Name</cell><cell>AP</cell><cell cols="3">P@5 P@10 Recall</cell></row><row><cell>Edge Hist.</cell><cell>0.0130</cell><cell>0.2</cell><cell>0.1</cell><cell>10%</cell></row><row><cell>Colour Layout</cell><cell>0.0260</cell><cell>0.4</cell><cell>0.3</cell><cell>16%</cell></row><row><cell cols="3">Colour Struct. 0.0643 0.6</cell><cell>0.4</cell><cell>43%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,90.00,479.50,423.00,139.48"><head>Table 2 ,</head><label>2</label><figDesc>all visual results used in data fusion presented here incorporated the FIRE baseline. Visual data which included the FIRE baseline with our global MPEG7 features consistently outperformed global MPEG7 by themselves.</figDesc><table coords="6,103.75,536.67,395.49,82.30"><row><cell>Language Pair</cell><cell>Modality</cell><cell>Text</cell><cell>Fusion</cell><cell>FB MAP</cell><cell>P@10</cell><cell>P@20</cell></row><row><cell>EN-EN</cell><cell>Text</cell><cell>dict</cell><cell>n/a</cell><cell cols="3">no 0.1305 0.1550 0.1408</cell></row><row><cell>EN-EN</cell><cell>Text</cell><cell>s-gram</cell><cell>n/a</cell><cell cols="3">yes 0.1245 0.1133 0.1242</cell></row><row><cell>DE-DE</cell><cell>Text</cell><cell>dict</cell><cell>n/a</cell><cell cols="3">yes 0.1269 0.1717 0.1533</cell></row><row><cell>DE-DE</cell><cell>Text</cell><cell>s-gram</cell><cell>n/a</cell><cell cols="3">yes 0.1067 0.1233 0.1125</cell></row><row><cell>MPEG7 With FIRE</cell><cell>Visual</cell><cell>na</cell><cell cols="4">dyn-equal no 0.1340 0.3600 0.2658</cell></row><row><cell>MPEG7 Without FIRE</cell><cell>Visual</cell><cell>na</cell><cell cols="4">dyn-equal no 0.1000 0.2700 0.1958</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,218.05,632.17,166.89,8.74"><head>Table 2 :</head><label>2</label><figDesc>ImageCLEF Baseline Results</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,139.28,205.78,341.61,79.85"><head>Table 3 :</head><label>3</label><figDesc>ImageCLEF Monolingual Fusion Results</figDesc><table coords="7,139.28,205.78,341.61,57.91"><row><cell cols="2">Pair Modality</cell><cell>Text</cell><cell>Fusion</cell><cell>FB MAP</cell><cell>P@10</cell><cell>P@20</cell></row><row><cell>EN-EN</cell><cell>Mixed</cell><cell>dict</cell><cell cols="4">dyn-equal yes 0.1951 0.3967 0.3150</cell></row><row><cell>EN-EN</cell><cell>Mixed</cell><cell cols="5">s-gram dyn-equal yes 0.1833 0.3833 0.3092</cell></row><row><cell>DE-DE</cell><cell>Mixed</cell><cell>dict</cell><cell cols="4">dyn-equal yes 0.1940 0.4033 0.3300</cell></row><row><cell>DE-DE</cell><cell>Mixed</cell><cell cols="5">s-gram dyn-equal yes 0.1628 0.3350 0.2792</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,125.43,110.99,355.46,177.80"><head>Table 4 :</head><label>4</label><figDesc>ImageCLEF CLIR Fusion Results</figDesc><table coords="8,125.43,110.99,355.46,155.87"><row><cell cols="2">Language Pair Modality</cell><cell>Text</cell><cell>Fusion</cell><cell>FB MAP</cell><cell>P@10</cell><cell>P@20</cell></row><row><cell>FR-EN</cell><cell>Mixed</cell><cell>dict</cell><cell cols="4">dyn-equal yes 0.1819 0.3583 0.2967</cell></row><row><cell>FR-EN</cell><cell>Mixed</cell><cell cols="5">s-gram dyn-equal no 0.1468 0.3483 0.2667</cell></row><row><cell>DE-EN</cell><cell>Mixed</cell><cell>dict</cell><cell cols="4">dyn-equal yes 0.1910 0.3483 0.3042</cell></row><row><cell>DE-EN</cell><cell>Mixed</cell><cell cols="5">s-gram dyn-equal yes 0.1468 0.3233 0.2533</cell></row><row><cell>DA-DE</cell><cell>Mixed</cell><cell>dict</cell><cell cols="4">dyn-equal yes 0.1730 0.3467 0.2942</cell></row><row><cell>DA-DE</cell><cell>Mixed</cell><cell cols="5">s-gram dyn-equal yes 0.1572 0.3350 0.2717</cell></row><row><cell>NO-DE</cell><cell>Mixed</cell><cell>dict</cell><cell cols="4">dyn-equal yes 0.1667 0.3517 0.2700</cell></row><row><cell>NO-DE</cell><cell>Mixed</cell><cell cols="5">s-gram dyn-equal yes 0.1536 0.3167 0.2667</cell></row><row><cell>SV-DE</cell><cell>Mixed</cell><cell>dict</cell><cell cols="4">dyn-equal yes 0.1788 0.3817 0.2942</cell></row><row><cell>SV-DE</cell><cell>Mixed</cell><cell cols="5">s-gram dyn-equal yes 0.1472 0.3050 0.2500</cell></row><row><cell>EN-DE</cell><cell>Mixed</cell><cell>dict</cell><cell cols="4">dyn-equal yes 0.1828 0.3633 0.3008</cell></row><row><cell>EN-DE</cell><cell>Mixed</cell><cell cols="5">s-gram dyn-equal yes 0.1446 0.3350 0.2667</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6">Acknowledgments</head><p>We are grateful to the <rs type="projectName">AceMedia</rs> project (<rs type="grantNumber">FP6-001765</rs>) which provided us with output from the AceToolbox image analysis tooklit.</p><p>The research leading to this paper was supported by the <rs type="funder">European Commission</rs> under contract <rs type="grantNumber">FP6-027026</rs> (<rs type="grantNumber">K-Space</rs>).</p><p>The work of the first author is funded by <rs type="funder">Tampere Graduate School of Information Science and Engineering (TISE)</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_c8KVPEJ">
					<idno type="grant-number">FP6-001765</idno>
					<orgName type="project" subtype="full">AceMedia</orgName>
				</org>
				<org type="funding" xml:id="_vRHD4er">
					<idno type="grant-number">FP6-027026</idno>
				</org>
				<org type="funding" xml:id="_Bv5FDqB">
					<idno type="grant-number">K-Space</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,110.48,627.58,273.05,8.74" xml:id="b0">
	<monogr>
		<ptr target="http://www.acemedia.org" />
		<title level="m" coord="8,110.48,627.58,97.38,8.74">The AceMedia Project</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,647.75,402.52,8.74;8,110.48,659.94,402.52,8.74;8,110.48,672.14,402.52,8.74;8,110.48,684.33,243.62,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,304.35,647.75,208.66,8.74;8,110.48,659.94,168.80,8.74">The score-distributional threshold optimization for adaptive binary classification tasks</title>
		<author>
			<persName coords=""><forename type="first">Avi</forename><surname>Arampatzis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">AndrÃ©</forename><surname>Van Hameran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,303.25,659.94,209.75,8.74;8,110.48,672.14,398.38,8.74">SIGIR &apos;01: Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="285" to="293" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,704.50,402.51,8.74;8,110.48,716.69,402.52,8.74;8,110.48,728.88,89.12,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,354.28,704.50,158.71,8.74;8,110.48,716.69,205.46,8.74">Combining the evidence of multiple query representations for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">J</forename><surname>Belkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Kantor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Shaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,327.77,716.69,179.93,8.74">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="431" to="448" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,112.02,402.51,8.74;9,110.48,124.21,402.53,8.74;9,110.48,136.41,22.69,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,394.37,112.02,118.62,8.74;9,110.48,124.21,147.69,8.74">Using clustering and superconcepts within SMART: TREC 6</title>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mandar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Janet</forename><forename type="middle">A</forename><surname>Walz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Claire</forename><surname>Cardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,265.89,124.21,175.68,8.74">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="109" to="131" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,156.57,402.52,8.74;9,110.48,168.77,402.53,8.74;9,110.48,180.96,178.95,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,110.48,168.77,402.53,8.74;9,110.48,180.96,34.67,8.74">FIRE in ImageCLEF 2005: Combining content-based image retrieval with textual information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tobias</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wolfgang</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,165.87,180.96,23.53,8.74">CLEF</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="652" to="661" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,201.13,402.51,8.74;9,110.48,213.32,402.52,8.74;9,110.48,225.51,211.41,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,440.75,201.13,72.24,8.74;9,110.48,213.32,224.83,8.74">Overview of the ImageCLEFphoto 2007 photographic retrieval task</title>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>MÃ¼ller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,360.59,213.32,152.41,8.74;9,110.48,225.51,40.84,8.74">Working Notes of the 2007 CLEF Workshop</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">September 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,245.68,402.52,8.74;9,110.48,257.87,402.52,8.74;9,110.48,270.07,402.53,8.74;9,110.48,282.26,402.52,8.74;9,110.48,294.46,30.48,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,471.45,245.68,41.55,8.74;9,110.48,257.87,293.19,8.74">Utaclir @ CLEF 2001 -effects of compound splitting and n-gram techniques</title>
		<author>
			<persName coords=""><forename type="first">Turid</forename><surname>Hedlund</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Heikki</forename><surname>Keskustalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ari</forename><surname>Pirkola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eija</forename><surname>Airio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kalervo</forename><surname>JÃ¤rvelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,427.74,257.87,85.25,8.74;9,110.48,270.07,402.53,8.74;9,110.48,282.26,201.72,8.74">CLEF &apos;01: Revised Papers from the Second Workshop of the Cross-Language Evaluation Forum on Evaluation of Cross-Language Information Retrieval Systems</title>
		<meeting><address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="118" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,314.62,402.51,8.74;9,110.48,326.82,167.00,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,279.99,314.62,233.01,8.74;9,110.48,326.82,20.78,8.74">Twenty-One at TREC7: Ad-hoc and cross-language track</title>
		<author>
			<persName coords=""><forename type="first">Djoerd</forename><surname>Hiemstra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wessel</forename><surname>Kraaij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,152.28,326.82,24.84,8.74">TREC</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="174" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,346.98,402.51,8.74;9,110.48,359.17,396.51,8.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,344.71,346.98,168.28,8.74;9,110.48,359.17,103.91,8.74">s-grams: Defining generalized n-grams for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Anni</forename><surname>JÃ¤rvelin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antti</forename><surname>JÃ¤rvelin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kalervo</forename><surname>JÃ¤rvelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,222.66,359.17,176.64,8.74">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1005" to="1019" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,379.34,402.51,8.74;9,110.48,391.53,402.52,8.74;9,110.48,403.73,43.73,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,491.69,379.34,21.30,8.74;9,110.48,391.53,297.51,8.74">Nonadjacent digrams improve matching of cross-lingual spelling variants</title>
		<author>
			<persName coords=""><forename type="first">Heikki</forename><surname>Keskustalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ari</forename><surname>Pirkola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kari</forename><surname>Visala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Erkka</forename><surname>LeppÃ¤nen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kalervo</forename><surname>JÃ¤rvelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,429.38,391.53,27.50,8.74">SPIRE</title>
		<imprint>
			<biblScope unit="page" from="252" to="265" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,423.89,402.52,8.74;9,110.48,436.09,193.13,8.74" xml:id="b10">
	<monogr>
		<title level="m" coord="9,349.24,423.89,163.77,8.74;9,110.48,436.09,130.49,8.74">Introduction to MPEG-7: Multimedia Content Description Language</title>
		<editor>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Manjunath</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Salembier</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Sikora</surname></persName>
		</editor>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,456.25,402.51,8.74;9,110.48,468.44,402.52,8.74;9,110.48,480.64,402.53,8.74;9,110.48,492.83,126.20,8.74" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,275.07,456.25,237.93,8.74;9,110.48,468.44,72.06,8.74">Modeling score distributions for combining the outputs of search engines</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Manmatha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Rath</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,204.47,468.44,308.53,8.74;9,110.48,480.64,284.59,8.74">SIGIR &apos;01: Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="267" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,513.00,402.51,8.74;9,110.48,525.19,330.80,8.74" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,277.55,513.00,235.45,8.74;9,110.48,525.19,137.62,8.74">End-user searching challenges indexing practices inthe digital newspaper photo archive</title>
		<author>
			<persName coords=""><forename type="first">Marjo</forename><surname>Markkula</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eero</forename><surname>Sormunen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,256.70,525.19,92.98,8.74">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="259" to="285" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,545.36,402.51,8.74;9,110.48,557.55,246.61,8.74" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,276.31,545.36,236.68,8.74;9,110.48,557.55,55.42,8.74">Character n-gram tokenization for european language text retrieval</title>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Mayfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,174.17,557.55,92.98,8.74">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="73" to="97" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,577.72,402.52,8.74;9,110.48,589.91,402.52,8.74;9,110.48,602.10,402.52,8.74;9,110.48,614.30,402.53,8.74;9,110.48,626.49,402.52,8.74;9,110.48,638.69,71.98,8.74" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,110.48,589.91,337.67,8.74">Overview of the ImageCLEFmed 2006 medical retrieval and annotation tasks</title>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>MÃ¼ller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,146.47,614.30,366.53,8.74;9,110.48,626.49,255.33,8.74">Evaluation of Multilingual and Multi-modal Information Retrieval -Seventh Workshop of the Cross-Language Evaluation Forum, CLEF 2006</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Gey</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Karlgren</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Magnini</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Stempfhuber</surname></persName>
		</editor>
		<meeting><address><addrLine>Alicante, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">September 2007</date>
		</imprint>
	</monogr>
	<note>page to appear</note>
</biblStruct>

<biblStruct coords="9,110.48,658.85,402.51,8.74;9,110.48,671.05,402.53,8.74;9,110.48,683.24,402.52,8.74;9,110.48,695.43,83.01,8.74" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,495.85,658.85,17.15,8.74;9,110.48,671.05,383.77,8.74">The AceToolbox: Low-Level Audiovisual Feature Extraction for Retrieval and Classification</title>
		<author>
			<persName coords=""><forename type="first">O'</forename><surname>Noel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Edward</forename><surname>Connor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Herve</forename><surname>Cooke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Le Borgne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tomasz</forename><surname>Blighe</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Adamek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,110.48,683.24,270.93,8.74">2nd IEE European Workshop on the Integration of Knowledge</title>
		<imprint>
			<publisher>Semantic and Digital Media Technologies</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,715.60,402.51,8.74;9,110.48,727.79,402.51,8.74;9,110.48,739.99,379.42,8.74" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,167.93,715.60,345.07,8.74;9,110.48,727.79,131.07,8.74">The effects of query structure and dictionary setups in dictionary-based crosslanguage information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Ari</forename><surname>Pirkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,264.05,727.79,248.94,8.74;9,110.48,739.99,291.08,8.74">SIGIR &apos;98: Proceedings of the 21st Annual ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="55" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,112.02,402.52,8.74;10,110.48,124.21,402.52,8.74;10,110.48,136.41,235.97,8.74" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="10,110.48,124.21,402.52,8.74;10,110.48,136.41,81.25,8.74">Targeted s-gram matching: a novel n-gram matching technique for cross-and mono-lingual word form variants</title>
		<author>
			<persName coords=""><forename type="first">Ari</forename><surname>Pirkola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Heikki</forename><surname>Keskustalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Erkka</forename><surname>LeppÃ¤nen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antti-Pekka</forename><surname>KÃ¤nsÃ¤lÃ¤</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kalervo</forename><surname>JÃ¤rvelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,200.27,136.41,91.84,8.74">Information Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,156.57,402.52,8.74;10,110.48,168.77,402.53,8.74;10,110.48,180.96,402.52,8.74;10,110.48,193.16,243.62,8.74" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="10,487.68,156.57,25.32,8.74;10,110.48,168.77,190.40,8.74">Fuzzy translation of cross-lingual spelling variants</title>
		<author>
			<persName coords=""><forename type="first">Ari</forename><surname>Pirkola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jarmo</forename><surname>Toivonen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Heikki</forename><surname>Keskustalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kari</forename><surname>Visala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kalervo</forename><surname>JÃ¤rvelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,323.99,168.77,189.02,8.74;10,110.48,180.96,398.68,8.74">SIGIR &apos;03: Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="345" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,213.32,402.51,8.74;10,110.48,225.51,366.72,8.74" xml:id="b19">
	<monogr>
		<title level="m" type="main" coord="10,431.60,213.32,81.39,8.74;10,110.48,225.51,281.54,8.74">Indri: A languagemodel based search engine for complex queries (extended version</title>
		<author>
			<persName coords=""><forename type="first">Trevor</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Donald</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Howard</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="2005" to="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,245.68,402.51,8.74;10,110.48,257.87,402.52,8.74;10,110.48,270.07,175.36,8.74" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="10,343.59,245.68,169.40,8.74;10,110.48,257.87,127.50,8.74">Using score distributions for querytime fusion in multimedia retrieval</title>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Wilkins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Ferguson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alan</forename><forename type="middle">F</forename><surname>Smeaton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,258.51,257.87,254.48,8.74;10,110.48,270.07,145.20,8.74">MIR 2006 -8th ACM SIGMM International Workshop on Multimedia Information Retrieval</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,290.23,402.51,8.74;10,110.48,302.43,402.53,8.74;10,110.48,314.62,402.52,8.74;10,110.48,326.82,25.74,8.74" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="10,341.95,290.23,171.04,8.74;10,110.48,302.43,121.89,8.74">Learning query-class dependent weights in automatic video retrieval</title>
		<author>
			<persName coords=""><forename type="first">Rong</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jun</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><forename type="middle">G</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,256.08,302.43,256.92,8.74;10,110.48,314.62,171.79,8.74">MULTIMEDIA &apos;04: Proceedings of the 12th annual ACM international conference on Multimedia</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="548" to="555" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
