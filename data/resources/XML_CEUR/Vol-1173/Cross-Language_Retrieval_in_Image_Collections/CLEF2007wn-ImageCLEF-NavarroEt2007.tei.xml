<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,98.52,148.62,406.10,15.51;1,170.70,170.53,261.65,15.51">Information retrieval of visual descriptions with IR-n system based on passages</title>
				<funder ref="#_cX6XJHs">
					<orgName type="full">European Union</orgName>
					<orgName type="abbreviated">EU</orgName>
				</funder>
				<funder ref="#_9KQUYcV">
					<orgName type="full">Spanish Government</orgName>
				</funder>
				<funder ref="#_JFv4sPu">
					<orgName type="full">Valencia Government</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,144.43,204.00,62.66,9.96"><forename type="first">Sergio</forename><surname>Navarro</surname></persName>
							<email>snavarro@dlsi.ua.es</email>
						</author>
						<author>
							<persName coords="1,215.10,204.00,68.74,9.96"><forename type="first">Fernando</forename><surname>Llopis</surname></persName>
							<email>llopis@dlsi.ua.es</email>
						</author>
						<author>
							<persName coords="1,291.30,204.00,98.79,9.96"><forename type="first">Rafael</forename><forename type="middle">Muñoz</forename><surname>Guillena</surname></persName>
							<email>rafael@dlsi.ua.es</email>
						</author>
						<author>
							<persName coords="1,397.80,204.00,60.82,9.96"><forename type="first">Elisa</forename><surname>Noguera</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Lenguajes y Sistemas</orgName>
								<orgName type="laboratory">Grupo de Investigación en Procesamiento del Lenguaje Natural y Sistemas de Información</orgName>
								<orgName type="institution">Informáticos</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,98.52,148.62,406.10,15.51;1,170.70,170.53,261.65,15.51">Information retrieval of visual descriptions with IR-n system based on passages</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">880A43B7F305E01148424F9FB91C56FC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Managment]: Languages-Query Languages Measurement, Performance, Experimentation Question answering, Questions beyond factoids</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes an approach made to the development of a textual image retrieval system, by the university of Alicante using IR-n, a Information Retrieval (IR) textbased system. With only a minimal quantity of adaptations to the features of this task, our system has obtained precision results over the mean average of participants at ImageCLEF07: for English (0.1604 vs 0.1388) and for Spanish (0.1482 vs 0.1450). For German, our results were under the mean (0.0991 vs 0.1331), it could be due to our system does not incorporate a splitter for the treatment of this agglutinative language. We obtain these results, without incorporate specific adaptations of the dominion of the recovery of images. This leads us to believe that we start from a good base point from which to work to obtain better results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Nowadays the amount of information documents that society produces is huge. All sort of documents are generated: text-planes, images, videos, source codes, etc. This amount of documents requires the use of automatic techniques for its access.</p><p>In order to take up this challenge, systems of information retrieval are used (IR). The primary target of these systems, is to locate the relevant documents from a user query in a document collection.</p><p>In order to attend and to stimulate the development of systems of IR based on the different European languages, the campaigns CLEF have been created. These are annual competitions where different systems from IR compete. Specifically, within the scope of the CLEF [2], an area specialized in the images retrieval exists, wich is the ImageCLEF [1] <ref type="bibr" coords="1,390.72,744.97,9.97,9.96" target="#b2">[5]</ref>.</p><p>For our task of the ImageCLEF we have used the IR, IR-n <ref type="bibr" coords="2,374.27,111.36,9.96,9.96" target="#b4">[7]</ref>. It's a information retraival system that using statistical techniques, has given good results in flat text based tasks. The objective to use a system of these characteristics is to contrast, in the scope of the recovery of images, the results of a statistical system, with others which includes NLP techniques.</p><p>This paper is structured as follows: Firstly, presents the main characteristics of the IR-n system; the following section explains the task with which we have evaluated the system and the carried out training; finally, in the last section we present the results and the conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">IR-n System</head><p>For this approach we have used IR-n, that is a IR based on passages. The RP systems, consider each document like a set of passages, where a passage defines as a portion or contiguous text block. This kind of systems opposite to those that are based on documents, allow to consider the proximity of appearance of the words in a document, to value their relevance <ref type="bibr" coords="2,429.51,273.71,9.96,9.96" target="#b4">[7]</ref>.</p><p>IR-n like RP system difference of other systems pertaining to the same category, in the method proposed for the definition of the passages. The unit that uses the IR-n system to define the passages is the phrase. Thus, the passages are defined by a number of consecutive phrases of the document. <ref type="bibr" coords="2,139.82,321.53,9.96,9.96" target="#b4">[7]</ref>.</p><p>In this section the main characteristics of the IR-n system are described, and the techniques used for ImageCLEF 2007 are detailed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Resources: stemmers and stopword list</head><p>Stemmers and stopword list are used with the objective to discriminate the information that is going to be used for retrieval. Thus, the stopword list of each language contains those words that, in spite of appearing in the query, does not consider important its appearance in the document to determine if this one is relevant or no. As far as stemers, these, obtain the root of a word eliminating the suffixes and prefixes of the same ones, for their indexing and search.</p><p>IR-n uses stemmers and the stopword list available in the web www.unine.ch/info/clef.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Weighting models</head><p>The weighting models allow to quantify the similarity between a text (a complete document or a passage) and the query. These measures are based fundamentally on the terms that share the text and the query, as well as on the discriminatory importance of each term. IR-n uses several weighting models. For this competition we have used dfr <ref type="bibr" coords="2,338.15,533.64,10.52,9.96" target="#b0">[3]</ref> and okapi <ref type="bibr" coords="2,396.70,533.64,9.96,9.96" target="#b3">[6]</ref>. The document ranking produced by each weighting model is obtained using the same general expression, this one is defined as the product of the weight of a term in the document by the weight of the term in the query.</p><formula xml:id="formula_0" coords="2,243.04,593.42,269.96,20.28">sim(q, d) = t∈q∧p w t,p • w t,q<label>(1)</label></formula><p>Variables List Here is described the list of variables used in the following formulas. 2, 3:</p><p>• f t,p is the frequency of the term t on the passage p,</p><p>• f t,q is the frequency of the term t on the query q,</p><p>• n is the number of documents in the collection,</p><p>• n t is the number of documents in which it appears t,</p><p>• c, k 1 , b and k 3 are constant values,</p><p>• ld is the length of the document,</p><p>• avg ld is the average of the length of the documents</p><p>Okapi Using the okapi model, the weight of a passage p for a query q is given by:</p><formula xml:id="formula_1" coords="3,238.12,187.56,274.88,104.58">w t,p = (k 1 + 1) • f t,p K • f t,p w t,q = (k 3 + 1) • f t,q k 3 • f t,q • w t K = (1 -b) + b • ld avr l d w t = log 2 n -n t + 0.5 n t + 0.5<label>(2)</label></formula><p>DFR Using this model, the weight of a passage p for query q is given by:</p><formula xml:id="formula_2" coords="3,166.11,339.04,346.88,87.11">w t,q = f t,q w t,p = (log 2 (1 + w t ) + w ′ t,p • log 2 ( 1 + w t w t )) • f t + 1 n t • (w ′ t,p + 1) w ′ t,p = f t,p • log 2 (1 + c • avr ld ld ) w t = f t n<label>(3)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Query expansion</head><p>Most IR systems use query expansion techniques <ref type="bibr" coords="3,313.14,458.27,10.52,9.96" target="#b1">[4]</ref> based on adding the most frequent terms contained in the most relevant documents to the original query. The IR-n architecture allows us to use query expansion based on either the most relevant passages or the most relevant documents.</p><p>In previous researches, we obtained better results using the most relevant passages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Training</head><p>IR-n is a parametrizable system, that allows to adapt it to the concrete characteristics of the task to make. The parameters for his configuration are: the number of phrases that form a passage, the weighting model to use, the type of expansion, the number of documents/passages on which the expansion is based, and the average number of words by document. This section describes the training process which has been carried out in order to obtain the best features to improve the performance of the system. Firstly, the collections and resources are described, and in following section, the specific experiments carried out.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Collections</head><p>We have participated in the following monolingual tasks of ImageCLEF 2007: English, German and Spanish. For its training with English and German we have been based on corpus of previous years. Table <ref type="table" coords="3,146.81,690.82,4.24,9.96" target="#tab_2">3</ref>.1 shows the characteristics of the language collections.</p><p>• WDAvg: is the average of words by document.</p><p>• NrQue: is the number of queries that are used in the experiments on each collection. To the Spanish we did not have previous corpus, that's the reason why we have used as guide the results obtained for the English and German.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language</head><p>As we can see at Table, the difference between corpus of the year 2004 and corpus of the year 2006 is substantial, since the one of the 2004 presents greater amount of information (greater number of documents and greater average of words by document). Furthermore, at corpus of 2006 only a 70% of the documents has all the information, the 10% hasn't description, another 10% has only location and date, and finally last 10% hasn't any annotation. All of this, increases the possibilities of success in a task of textual information retrieval over the corpus of 2004.</p><p>The collections of data has a semi structured format. We took advantage of it selecting the information used as input of the IR-n system.</p><p>The information that is not interesting for a textual recovery is rejected. Thus, we used as input for IR-n only the fields that correspond with the title (TITLE), the description (DESCRIPTION), notes (NOTES), the place (LOCATION) and the date of the photo (DATES).</p><p>The queries associated to each corpus (60 queries by corpus) also has a semi structured format as is possible to see in Figure <ref type="figure" coords="4,219.97,378.30,3.87,9.96" target="#fig_0">1</ref>, and in addition the text contains images with similar contents to the target to retrieve. Furthermore from a set of 60 queries in ImageCLEF 2006, only 30 were responded with textual information, 10 with visual information and 20 indifferently with textual or visual information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experiments</head><p>The aim of the experiment phase is set up the optimum value of the input parameters for each collection. Next, we describe the input parameter of the system:</p><p>• Size of the Passage (sp): Number of phrases that form the passage.</p><p>• Weight model (wm): We used two weighting models : okapi y dfr.</p><p>• Opaki parameters: k 1 , b and avg ld (k 3 is fixed as 1000).</p><p>• Dfr parameters: c and avg ld .</p><p>• Query expansion parameters: If exp has value 1, this denotes we use relevance feedback based on passages in this experiment. But, if exp has value 2, the relevance feedback is based on documents. Moreover, num denote the number of passages or documents that the expansion will use, and term indicates the k terms extracted from the best ranked passages or documents from the original query</p><p>• Evaluation Measure: MAP Mean average precision (avgP) is the evaluation measure used in order to evaluate the experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">English</head><p>As we can see for corpus of 2004 at For 2006 English corpus we can see that the precision is reduced considerably. This is justified by the fact that corpus has minor amount of textual information that in the edition of the 2004, as reflects Table <ref type="table" coords="5,165.36,432.89,3.87,9.96" target="#tab_2">3</ref>.1. And too because corpus of the 2005 has a 30% of incomplete documents. Also we observed, that the best results are obtained with dfr and techniques of expansion based on documents. For this corpus we see that the average length by document, has been standardized, corresponding with numbers nearer the real ones. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">German</head><p>The results in German are lower as we can see at Table <ref type="table" coords="5,335.56,643.24,3.87,9.96" target="#tab_3">4</ref>.</p><p>It could be a combination of two causes: on the one hand the fact that IR-n does not incorporate a mechanism for the treatment of compound words (in spite of being very common in this language), on the other hand the circumstance that the queries in German do not contain narrative, which reduce the success possibilities.</p><p>For German the weighting model that better results gives back is okapi, with expansion by documents. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Experiments Summary</head><p>The obtained training results and the results obtained by the participants of the respective Im-ageCLEFs, are compared at These results were obtained with the best configuration for each corpus and language. For our participation at ImageCLEF07 we used the same configuration than the best one used with ImageCLEF06 corpus. The decission is justified by the fact that the corpus for ImageCLEF07 is the same that we used at ImageCLEF06, and it will improve our success rate. Despite the fact that we have discarded the 2004 results for the training process, they have helped us to meassure how the features of the corpus can affect the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results at ImageCLEFPhoto-2007</head><p>Table <ref type="table" coords="6,117.23,485.61,4.98,9.96" target="#tab_6">6</ref> shows the configurations used for ImageCLEF 2007, and the comparative of the obtained results with the average of all participants by language at monolingual task. For English and German, we used the configurations which obtain the best rsults at training phase using the ImageCLEF06 corpus. For Spanish, we used the same configuration than for English. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and future work</head><p>In our first ImageCLEF participation, we used an IR text-based system. We used it with a minimal quantity of adaptations to the features of this task. We highlight that its precision results are above average for English and Spanish. The lower results in German could be due to IR-n not incorporate a mechanism for the treatment of compound words (in spite of being very common in this language). We will work to solve this in future projects.</p><p>In addition, analysing the results of training with the corpus of previous years, makes us meassure how the no completeness of the corpus and the absence of theme tags (like in 2004 corpus) result in decrease of precision values, and moreover the reduction of the length of the corpus has a direct effect over the passage size.</p><p>Finally, the fact to obtain these results, without to have incorporated specific adaptations of the dominion of the recovery of images, makes us to think, that we start from a good base point, from which work, to obtain better results.</p><p>To continue improving the system there are several ways that can be taken in account. One of them is to consider to do an approach to the resolution of a multilingual corpus using the calculation of the documentary relevance in two steps <ref type="bibr" coords="7,340.28,242.86,9.96,9.96" target="#b5">[8]</ref>. Another work to be developed is to improve the system with the incorporation of a system CBIR, that complements the textual information retrieval that IR-n carries out. Therefore, as future work we will explore the possibility of shape extraction from images, establishing a relationship between them and associated terms. And finally, we will try to add NLP techniques to the local query expansion.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,175.86,550.54,251.27,9.96;4,104.94,574.45,408.04,9.96;4,90.00,586.40,423.00,9.96;4,90.00,598.36,269.19,9.96;4,104.94,610.31,408.05,9.96;4,90.00,622.27,414.53,9.96"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Queries from set of queries of ImageCLEF 2006 Only the queries in English of ImageCLEF 2006 and ImageCLEF 2004 contain narrative (NARR) that accompanies the query, the rest of sets of queries of ImageCLEF 2006 in other languages only contains title (TITLE) as textual information.Furthermore from a set of 60 queries in ImageCLEF 2006, only 30 were responded with textual information, 10 with visual information and 20 indifferently with textual or visual information.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,135.91,110.16,339.09,70.87"><head>Table 1 :</head><label>1</label><figDesc>Data Collections</figDesc><table coords="4,135.91,110.16,339.09,49.01"><row><cell></cell><cell>Colection</cell><cell cols="3">NDocs WDAvg NrQue</cell></row><row><cell>English</cell><cell>St Andrews(ImageCLEF2004)</cell><cell>28.133</cell><cell>48</cell><cell>25</cell></row><row><cell>English</cell><cell cols="2">IAPR TC-12 (ImageCLEF2006) 20.000</cell><cell>40,29</cell><cell>60</cell></row><row><cell>German</cell><cell cols="2">IAPR TC-12 (ImageCLEF2006) 20.000</cell><cell>34,61</cell><cell>60</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,90.00,255.27,422.99,130.36"><head>Table 2 :</head><label>2</label><figDesc>Table 2, expansion based on passages and dfr obtains better results. It is important to stand out that, better results are obtained establishing the average length (in bytes) by document to values greater than corpus has. English 2004 Best Results</figDesc><table coords="5,150.21,302.39,302.56,61.37"><row><cell cols="2">sp wm</cell><cell>c</cell><cell cols="2">avgld k1</cell><cell>b</cell><cell cols="3">exp num term</cell><cell>avgP</cell></row><row><cell>5</cell><cell>dfr</cell><cell>4</cell><cell>1600</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.4752</cell></row><row><cell>5</cell><cell>dfr</cell><cell cols="2">9.5 1700</cell><cell></cell><cell></cell><cell>1</cell><cell>10</cell><cell>5</cell><cell>0.5128</cell></row><row><cell cols="2">5 okapi</cell><cell></cell><cell>50</cell><cell>1</cell><cell>0.2</cell><cell></cell><cell></cell><cell>0.4752</cell></row><row><cell cols="2">5 okapi</cell><cell></cell><cell>350</cell><cell>3</cell><cell>0.2</cell><cell>1</cell><cell>5</cell><cell>5</cell><cell>0.5086</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,151.16,491.42,300.65,95.58"><head>Table 3 :</head><label>3</label><figDesc>English 2006 Best Results</figDesc><table coords="5,151.16,491.42,300.65,73.72"><row><cell cols="2">sp wm</cell><cell>c</cell><cell cols="2">avgld k1</cell><cell>b</cell><cell cols="3">exp num term</cell><cell>avgP</cell></row><row><cell>2</cell><cell>dfr</cell><cell>5.5</cell><cell>85</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.1926</cell></row><row><cell>3</cell><cell>dfr</cell><cell>8</cell><cell>85</cell><cell></cell><cell></cell><cell>2</cell><cell>5</cell><cell>5</cell><cell>0.2059</cell></row><row><cell cols="2">2 okapi</cell><cell></cell><cell>90</cell><cell>4</cell><cell>0.8</cell><cell></cell><cell></cell><cell>0.1799</cell></row><row><cell cols="2">2 okapi</cell><cell></cell><cell>1900</cell><cell>4</cell><cell>0.8</cell><cell></cell><cell></cell><cell>0.1800</cell></row><row><cell cols="2">5 okapi</cell><cell></cell><cell>90</cell><cell>2</cell><cell>0.8</cell><cell>1</cell><cell>10</cell><cell>10</cell><cell>0.1992</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,152.38,110.16,298.22,83.23"><head>Table 4 :</head><label>4</label><figDesc>German 2006 Best Results</figDesc><table coords="6,152.38,110.16,298.22,61.36"><row><cell>sp</cell><cell>wm</cell><cell cols="3">c avgld k1</cell><cell>b</cell><cell cols="3">exp num term</cell><cell>avgP</cell></row><row><cell>3</cell><cell>dfr</cell><cell>2</cell><cell>90</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.1487</cell></row><row><cell>3</cell><cell>dfr</cell><cell>2</cell><cell>85</cell><cell></cell><cell></cell><cell>1</cell><cell>5</cell><cell>5</cell><cell>0.1742</cell></row><row><cell>3</cell><cell>okapi</cell><cell></cell><cell>85</cell><cell>2</cell><cell>0.8</cell><cell></cell><cell></cell><cell>0.1492</cell></row><row><cell cols="2">3 okapi</cell><cell></cell><cell>85</cell><cell>2</cell><cell>0.8</cell><cell>2</cell><cell>5</cell><cell>5</cell><cell>0.1857</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,137.01,253.62,328.98,71.68"><head>Table 5</head><label>5</label><figDesc></figDesc><table coords="6,137.01,276.28,328.98,49.01"><row><cell>Competition</cell><cell cols="3">avgP IR-n avgP ImageCLEF avgP Best</cell></row><row><cell>ImageCLEF04 English</cell><cell>0.5128</cell><cell>0.4155</cell><cell>0.58</cell></row><row><cell>ImageCLEF06 English</cell><cell>0.2059</cell><cell>0.152</cell><cell>0.385</cell></row><row><cell>ImageCLEF06 German</cell><cell>0.1857</cell><cell>0.121</cell><cell>0.311</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,241.72,337.20,119.55,9.96"><head>Table 5 :</head><label>5</label><figDesc>Compared Results</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="6,104.11,544.14,394.78,106.74"><head>Table 6 :</head><label>6</label><figDesc>ImageCLEFPhoto 2007 official average results. Monolingual tasks.</figDesc><table coords="6,104.11,544.14,394.78,84.88"><row><cell cols="6">lang sp wm c avgld k1</cell><cell>b</cell><cell cols="3">exp num term avgP ImgCLEF07</cell></row><row><cell>Eng</cell><cell>3</cell><cell>dfr</cell><cell>8</cell><cell>85</cell><cell></cell><cell></cell><cell>2</cell><cell>5</cell><cell>5</cell><cell>0.1604</cell></row><row><cell></cell><cell>3</cell><cell>dfr</cell><cell>8</cell><cell>85</cell><cell></cell><cell></cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0.1453</cell><cell>0.1388</cell></row><row><cell>Spa</cell><cell>3</cell><cell>dfr</cell><cell>8</cell><cell>85</cell><cell></cell><cell></cell><cell>2</cell><cell>5</cell><cell>5</cell><cell>0.1482</cell></row><row><cell></cell><cell>3</cell><cell>dfr</cell><cell>8</cell><cell>85</cell><cell></cell><cell></cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0.1367</cell><cell>0.1450</cell></row><row><cell>Ger</cell><cell cols="2">3 okapi</cell><cell></cell><cell>85</cell><cell>2</cell><cell>0.8</cell><cell>2</cell><cell>5</cell><cell>5</cell><cell>0.0991</cell></row><row><cell></cell><cell cols="2">3 okapi</cell><cell></cell><cell>85</cell><cell>2</cell><cell>0.8</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0.0911</cell><cell>0.1331</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6">Acknowledgements</head><p>This research has been partially funded by the <rs type="funder">Spanish Government</rs> under project <rs type="projectName">TEXT-MESS</rs> (<rs type="grantNumber">TIN-2006-15265-C06-01</rs>), and by <rs type="funder">European Union (EU)</rs> under <rs type="projectName">QALL-ME</rs> project (<rs type="grantNumber">FP6-IST-033860</rs>), and by the <rs type="funder">Valencia Government</rs> under project number <rs type="grantNumber">GV06-161</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_9KQUYcV">
					<idno type="grant-number">TIN-2006-15265-C06-01</idno>
					<orgName type="project" subtype="full">TEXT-MESS</orgName>
				</org>
				<org type="funded-project" xml:id="_cX6XJHs">
					<idno type="grant-number">FP6-IST-033860</idno>
					<orgName type="project" subtype="full">QALL-ME</orgName>
				</org>
				<org type="funding" xml:id="_JFv4sPu">
					<idno type="grant-number">GV06-161</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,105.50,463.97,407.51,9.96;7,105.50,475.93,341.54,9.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,273.73,463.97,239.28,9.96;7,105.50,475.93,186.06,9.96">Probabilistic Models of information retrieval based on measuring the divergence from randomness</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,300.86,476.27,48.37,9.18">ACM TOIS</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="357" to="389" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.50,495.85,407.48,9.96;7,105.50,507.81,407.49,9.96;7,105.50,519.77,407.49,9.96;7,105.50,531.72,407.53,9.96;7,105.50,543.68,30.46,9.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,257.30,495.85,255.69,9.96;7,105.50,507.81,123.49,9.96">Combining Query Translation and Document Translation in Cross-Language Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Aitao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fredric</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,140.70,520.10,238.14,9.18">4th Workshop of the Cross-Language Evaluation Forum</title>
		<title level="s" coord="7,443.92,520.10,69.07,9.18;7,105.50,531.72,239.22,9.96">Lecture notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</editor>
		<meeting><address><addrLine>CLEF; Trondheim, Norway</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
	<note>Lecture notes in Computer Science</note>
</biblStruct>

<biblStruct coords="7,105.50,563.60,407.47,9.96;7,105.50,575.56,407.51,9.96;7,105.50,587.51,162.14,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,412.74,563.60,100.23,9.96;7,105.50,575.56,192.71,9.96">Overview of the Image-CLEFphoto 2007 photographic retrieval task</title>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,318.17,575.90,189.73,9.18">Working Notes of the 2007 CLEF Workshop</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">September 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.50,607.43,407.50,9.96;7,105.50,619.40,407.49,9.96;7,105.50,631.35,407.50,9.96;7,105.50,643.30,70.38,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,146.75,607.43,287.65,9.96">Fusion of Probabilistic Models for Effective Monolingual Retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,347.54,619.73,165.45,9.18;7,105.50,631.69,131.93,9.18">4th Workshop of the Cross-Language Evaluation Forum, CLEF 2003</title>
		<title level="s" coord="7,244.75,631.35,147.85,9.96">Lecture notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</editor>
		<meeting><address><addrLine>Trondheim, Norway</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.50,663.23,407.49,9.96;7,105.50,675.18,75.89,9.96" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Llopis</surname></persName>
		</author>
		<title level="m" coord="7,184.96,663.23,308.46,9.96">IR-n: Un Sistema de Recuperación de Información Basado en Pasajes</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="7,105.50,695.10,407.49,9.96;7,105.50,707.06,407.50,9.96;7,105.50,719.02,75.89,9.96" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="7,239.71,695.10,273.29,9.96;7,105.50,707.06,387.69,9.96">El problema de la fusión de colecciones en la recuperación de información multilingüe y distribuida: cálculo de la relevancia documental en dos pasos</title>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Santiago</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
