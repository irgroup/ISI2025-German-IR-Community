<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,186.30,80.45,222.73,12.58;1,71.58,96.53,452.14,12.58">MIRACLE at ImageCLEFmed 2007: Merging Textual and Visual Strategies to Improve Medical Image Retrieval</title>
				<funder ref="#_gQ5W3wW">
					<orgName type="full">Madrid&apos;s R+D Regional Plan</orgName>
				</funder>
				<funder ref="#_dsybDAu">
					<orgName type="full">Spanish R+D National Plan</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,138.30,123.42,83.56,9.02"><forename type="first">Julio</forename><surname>Villena-Román</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universidad Carlos III de Madrid</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Decisions and Language</orgName>
								<orgName type="institution">DAEDALUS -Data</orgName>
								<address>
									<country>S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,235.01,123.42,74.75,9.02"><forename type="first">Sara</forename><surname>Lana-Serrano</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Universidad Politécnica de Madrid</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Decisions and Language</orgName>
								<orgName type="institution">DAEDALUS -Data</orgName>
								<address>
									<country>S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,322.85,123.42,126.17,9.02"><forename type="first">José</forename><forename type="middle">Carlos</forename><surname>González-Cristóbal</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Universidad Politécnica de Madrid</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Decisions and Language</orgName>
								<orgName type="institution">DAEDALUS -Data</orgName>
								<address>
									<country>S.A</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,186.30,80.45,222.73,12.58;1,71.58,96.53,452.14,12.58">MIRACLE at ImageCLEFmed 2007: Merging Textual and Visual Strategies to Improve Medical Image Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DFBB0BC115EC14A12952F6C22BBBD02B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.2 Information Storage</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital libraries. H.2 [Database Management]: H.2.5 Heterogeneous Databases</term>
					<term>E.2 [Data Storage Representations] Image retrieval, domain-specific vocabulary, thesaurus, linguistic engineering, information retrieval, indexing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the participation of MIRACLE research consortium at the ImageCLEF Medical Image Retrieval task of ImageCLEF 2007. For this campaign, our challenge was to research on different merging strategies, i.e. methods of combination of textual and visual retrieval techniques. We have focused on the idea of performing all possible combinations of well-known textual and visual techniques in order to find which ones offer the best results in terms of MAP and analyze if the combined results may improve the individual ones. Our system consists of three different modules: the textual (text-based) retrieval module, which indexes the case descriptions to look for those descriptions which are more relevant to the text of the topic; the visual (contentbased) retrieval component, which provides the list of case images that are more similar to the topic images; and, finally, the merging module, which offers different operators (AND, OR, LEFT, RIGHT) and metrics (max, min, avg, max-min) to combine and rerank the outputs of the two previous subsystems. These modules are built up from a set of basics components organized in four categories: (i) resources and tools for both general-domain and medical-specific vocabulary analysis, (ii) linguistic tools for text-based information retrieval, (iii) tools for image analysis and retrieval, and (iv) ad-hoc tools for result merging and reranking. We finally submitted 50 runs. The highest MAP was obtained with the baseline text-based experiment in English where only stemming plus stopword removal is performed. Neither tagging with UMLS medical concepts nor merging of textual and visual results proved to be of value to improve the precision with regards to the baseline experiment. However, the most interesting conclusion is that experiments that use the OR operator obtain higher MAP values than those with the AND operator.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The MIRACLE team is a research consortium formed by research groups of three different universities in Madrid (Universidad Politécnica de Madrid, Universidad Autónoma de Madrid and Universidad Carlos III de Madrid) along with DAEDALUS, a small/medium size enterprise (SME) founded in 1998 as a spin-off of two of these groups and a leading company in the field of linguistic technologies in Spain. MIRACLE has taken part in CLEF since 2003 in many different tracks and tasks, including the main bilingual, monolingual and cross lingual tasks as well as in ImageCLEF <ref type="bibr" coords="1,199.46,680.10,11.69,9.02" target="#b6">[7]</ref>  <ref type="bibr" coords="1,213.65,680.10,10.64,9.02" target="#b7">[8]</ref>, Question Answering, WebCLEF and GeoCLEF tracks. This paper describes our participation in the ImageCLEFmed task of ImageCLEF 2007. The goal of this task (fully described in <ref type="bibr" coords="1,152.89,709.08,11.27,9.02" target="#b9">[9]</ref>) is to improve the retrieval of medical images from heterogeneous and multilingual document collections containing images as well as text. The task organizers provide a list of topic statements (a short textual description explaining the research goal) in English, French and German, and a collection of images (from one to three) for each topic. The objective is to retrieve as many relevant images as possible from the given visual and multilingual topics. ImageCLEFmed 2007 extends the experiments of past editions with a larger database and even more complex queries.</p><p>Although this task certainly requires the use of image retrieval techniques and our areas of expertise do not include image analysis research, we do take part to promote and encourage multidisciplinary participation in all aspects of information retrieval, no matter whether it is text or content based.</p><p>All experiments are fully automatic, thus avoiding any manual intervention. We submitted runs using only text (text-based retrieval) or only visual features (content-based retrieval) and also mixed runs using a combination of both.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">System Description</head><p>Our system is logically built up from three different modules: the textual (text-based) retrieval module, which indexes case descriptions in order to look for the most relevant ones to the text of the topic; the visual (contentbased) retrieval component, which provides the list of case images that are more similar to the topic ones; and, finally, the result combination module, which uses different operators to combine the results of the two previous subsystems. Figure <ref type="figure" coords="2,152.36,261.00,5.01,9.02" target="#fig_0">1</ref> gives an overview of the system architecture. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Textual Retrieval</head><p>The system consists of a set of different basic components organized in two categories:</p><p>• Resources and tools for medical-specific vocabulary analysis</p><p>• Linguistic tools for textual analysis and retrieval.</p><p>Instead of using raw terms, the textual information of both topics and documents is parsed and tagged to unify all terms into concepts of medical entities. This is similar to a stemming or a lemma extraction process, but the output, instead of the stem or lemma, is the medical entity to which the term relates. The consequence of this process is that concept identifiers <ref type="bibr" coords="2,207.87,744.96,11.69,9.02" target="#b4">[5]</ref> are used instead of terms in the text-based process of information retrieval.</p><p>For this purpose, a terminological dictionary was created by using a subset of the Unified Medical Language System (UMLS) metathesaurus (US National Library of Medicine) <ref type="bibr" coords="3,355.45,84.72,16.65,9.02" target="#b12">[12]</ref> and incorporating terms in English, Spanish, French and German (the four different languages involved in the ImageCLEFmed task <ref type="bibr" coords="3,484.58,96.24,10.49,9.02" target="#b9">[9]</ref>). This dictionary contains 4,327,255 entries matching 1,215,749 medical concepts. Table <ref type="table" coords="3,430.20,107.76,5.01,9.02" target="#tab_0">1</ref> shows the language coverage of terms (the same as UML). The baseline approach to process the document collection is based on the following steps which are executed in sequence:</p><p>1. Text Extraction: Ad-hoc scripts are run on the files that contain information about the medical cases in order to extract the annotations and metadata enclosed between XML tags. Table <ref type="table" coords="3,437.28,433.20,5.01,9.02" target="#tab_1">2</ref> shows the metadata which was considered from each collection.  <ref type="bibr" coords="3,283.83,676.68,16.73,9.02" target="#b12">[12]</ref> to identify and disambiguate medical terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Tokenization:</head><p>This process extracts basic text components, detecting and isolating punctuation symbols. Some basic entities are also treated, such as numbers, initials, abbreviations, and years. So far, compounds, proper nouns, acronyms or other entities are not specifically considered. The outcomes of this process are only single words, years in numbers (e.g. 1995, 2004, etc.) and tagged entities.</p><p>4. Lowercase words: All document words are normalized by changing all uppercase letters to lowercase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5.</head><p>Filtering: All words recognized as stopwords are filtered out. Stopwords in the target languages were initially obtained from <ref type="bibr" coords="4,197.53,84.72,16.74,9.02" target="#b11">[11]</ref> and afterwards extended using several other sources <ref type="bibr" coords="4,432.58,84.72,11.70,9.02" target="#b1">[2]</ref> as well as our own knowledge and resources <ref type="bibr" coords="4,206.72,96.24,10.62,9.02" target="#b7">[8]</ref>.</p><p>6. Stemming: This process is applied to each one of the words to be indexed or used for retrieval. Standard stemmers from Porter <ref type="bibr" coords="4,192.82,125.22,16.69,9.02" target="#b10">[10]</ref> have been used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>7.</head><p>Indexing and retrieval: The information retrieval engine applied for all textual indexing and retrieval task was Lucene <ref type="bibr" coords="4,171.64,154.26,10.63,9.02" target="#b0">[1]</ref>.</p><p>No feedback or any other kind of expansion was used.</p><p>Because the textual retrieval module is completely based on information about medical cases, the last step of module is to obtain the images that correspond to each case (block labeled as AnnotationToImage at Figure <ref type="figure" coords="4,505.49,200.76,3.62,9.02">2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Visual Retrieval</head><p>For this part of the system, we resorted to two publicly and freely available Content-Based Information Retrieval systems: GIFT (GNU Image Finding Tool) <ref type="bibr" coords="4,252.56,255.54,11.72,9.02" target="#b3">[4]</ref> and FIRE (Flexible Image Retrieval Engine) <ref type="bibr" coords="4,455.03,255.54,25.88,9.02">[3] [6]</ref>. They are both developed under the GNU license and allow to perform query by example on images, using an image as the starting point for the search process and relying entirely on the image contents.</p><p>In the case of GIFT, the complete image database was indexed in a single collection, down-scaling each image to 32x32 pixels. For each ImageCLEFmed query, a visual query is made up of all the images contained in the query. Next, this visual query is used in GIFT to obtain the list of the most relevant images (i.e., images which are more similar to those included in the visual query), along with the corresponding relevance values. Although different search algorithms could be integrated as plug-ins in GIFT, only the provided separate normalization algorithm has been used in our experiments.</p><p>On the other hand, we directly used the results of the FIRE system kindly provided by the organizers, with no further processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Merging</head><p>The textual and image result lists are then merged by applying different techniques, which are characterized by an operator and a metric for computing the relevance (score) of the result. Table <ref type="table" coords="4,400.74,437.34,5.01,9.02">3</ref> shows the defined operators: union (OR), intersection (AND), difference (AND NOT), and external join (LEFT JOIN, RIGHT JOIN). Each of these operators selects which images are part of the final result set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 3. Combination operators.</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Operators OR</head><formula xml:id="formula_0" coords="4,231.90,511.92,131.52,53.88">A ∪ B AND A ∩ B LEFT (A ∪ B ) ∪ (A -B) RIGHT (A ∪ B ) ∪ (B -A)</formula><p>Then, results are reranked by computing a new relevance measure value based on their corresponding input results by using different metrics shown in Table <ref type="table" coords="4,270.84,587.22,3.77,9.02">4</ref>. Table <ref type="table" coords="4,254.88,610.74,3.77,9.02">4</ref>. Score computing metrics. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Metrics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiment Set</head><p>Experiments are defined by the choice of different combinations of the previously described modules, operators and score computation metrics. A wide set of experiments was submitted: 8 text-based runs covering the 3 different topic languages, 9 content-based runs (built with the combination of results from GIFT and FIRE), and also 33 mixed runs (built with the combination of textual and visual experiments).   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head><p>Results are presented in the following tables. Each of them shows the run identifier, the number of relevant documents retrieved, the mean average precision (MAP), the R-precision and the precision at 10, 30 and 100 first results.</p><p>Table <ref type="table" coords="6,100.74,73.26,5.01,9.02" target="#tab_5">8</ref> shows the results of the text-based experiments. The highest MAP is obtained by the baseline experiment in English where only stemming plus stopword removal is performed. Surprisingly for us, tagging with UMLS thesaurus has proved to be of no use with regards to the simplest strategy. This issue has to be further investigated in case that there is some problem with the generation of the result sets. Experiments using French and German languages achieve a very low precision (respectively, a decrease to 31% and 28% with regards to English). This result is similar to other experiments carried out in other CLEF tracks and may be attributed to deficient stemming modules.</p><p>The evaluation for the content-based experiments is shown in Table <ref type="table" coords="6,346.38,324.96,3.77,9.02" target="#tab_6">9</ref>. In general, MAP values are very low, which reflects the complexity and difficulty of the visual-only retrieval for this task. The best value (5% of the top ranked textual experiment) is obtained with the baseline visual experiment, which just uses GIFT. However, probably due to an oversight by the task organizers, the evaluations for the experiments with the OR operator (4 runs) are missing in the Excel files provided. Thus, no definitive conclusion can be extracted about the usage of any merging strategy, as the restrictive AND operator filters out many images (165 instead of 532 relevant images retrieved).</p><p>Finally, Table <ref type="table" coords="6,132.64,552.54,10.05,9.02" target="#tab_7">10</ref> in next page shows the evaluation for the mixed runs. Although the MAP of the best ranked mixed experiment is lower than the MAP of the best textual one (77%), we cannot conclude that the combination of textual and visual results with any kind of merging strategy fails to improve the precision because. The same as before, some experiments with OR operator (11 runs) are missing from the table, thus, it is impossible to extract any valuable conclusion on this issue.</p><p>However, observe that the best ranked runs are those with the RIGHT operator, which implicitly includes an OR (see definition in Table <ref type="table" coords="6,168.90,627.54,3.62,9.02">4</ref>). In addition, the use of this operator (visual RIGHT textual) shows that textual results are preferred over visual results (RIGHT prioritizes the second result list).</p><p>Another conclusion that can be drawn from these results is that the textual retrieval is the best strategy for this task. We think that this is because many queries include semantic aspects such as medical diagnoses or specific details present in the image, which a purely visual retrieval cannot tackle. This issue will be considered for future participations.</p><p>The best experiment at ImageCLEFmed 2007 reaches a MAP value of 0.3962, 112% better than ours. Despite this difference, MIRACLE participation is ranked 3 rd out of over 12 groups, which is indeed considered to be a very good position. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions and Future Work</head><p>The highest MAP is obtained with the baseline text-based experiment in English where only stemming plus stopword removal is performed. Neither tagging with UMLS medical concepts nor merging of textual and visual results have proved to be of value to improve the precision with regards to the baseline experiment. However, evaluations for some of our experiments were missing, so this issue cannot be confirmed and has to be further investigated. In addition, experiments using French and German languages get a very low precision. This result is similar to other experiment carried out in other CLEF tracks and may be attributed to deficient stemming modules. We will invest more effort in these languages in future participations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,228.36,613.20,138.53,9.02;2,88.86,276.18,417.86,328.68"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Overview of the system.</figDesc><graphic coords="2,88.86,276.18,417.86,328.68" type="vector_box" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,70.92,136.74,427.00,240.02"><head>Table 1 .</head><label>1</label><figDesc>Language distribution of terms.</figDesc><table coords="3,261.12,156.36,73.11,60.44"><row><cell cols="2">Lang #Terms</cell></row><row><cell>EN</cell><cell>3,207,890</cell></row><row><cell>ES</cell><cell>1,116,086</cell></row><row><cell>FR</cell><cell>2,556</cell></row><row><cell>DE</cell><cell>723</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,85.14,468.24,439.52,217.46"><head>Table 2 .</head><label>2</label><figDesc>Metadata extracted from XML annotation files. All case descriptions and topics are parsed and tagged using a subset of Unified Medical Language metathesaurus</figDesc><table coords="3,85.14,487.80,401.01,186.44"><row><cell>Collection</cell><cell cols="2">Lang Metadata</cell></row><row><cell>CASImage</cell><cell>FR</cell><cell>Description, Diagnosis, Clinical Presentation, Keywords, Anatomy,</cell></row><row><cell></cell><cell></cell><cell>Chapter, Title, Age</cell></row><row><cell>Endoscopy</cell><cell>EN</cell><cell>Title, Subject, Description</cell></row><row><cell>myPACS</cell><cell>EN</cell><cell>Title, Abstract, Keywords, Text-Caption, Discussion, Document-Type,</cell></row><row><cell></cell><cell></cell><cell>Pathology, Anatomy, Pt-Sex, Months, Years, Days</cell></row><row><cell>PathoPICS</cell><cell>DE</cell><cell>Diagnose, Synonyme, Beschreibung, Zusatzbefund, Klinik,</cell></row><row><cell></cell><cell></cell><cell>Kommentar</cell></row><row><cell></cell><cell>EN</cell><cell>Diagnosis, Synonyms, Description, AddtlFindings, ClinicalFindings,</cell></row><row><cell></cell><cell></cell><cell>Comment</cell></row><row><cell>Peir</cell><cell>EN</cell><cell>Title, Description, RadiographType, DiseaseProcess, ClinicalHistory</cell></row><row><cell>MIR</cell><cell>EN</cell><cell>Diagnosis, Brief_History, Images, Full_History, Radiopharm,</cell></row><row><cell></cell><cell></cell><cell>Findings, Discussion, Followup, Teaching</cell></row><row><cell cols="3">2. Medical-vocabulary Recognition:</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,127.62,157.02,366.68,147.76"><head>Table 5 .</head><label>5</label><figDesc>Textual experiments.</figDesc><table coords="5,130.62,174.55,334.13,112.62"><row><cell cols="2">Run Identifier Language (1) Method</cell></row><row><cell>TxtENN EN&gt;all</cell><cell>stem + stopwords</cell></row><row><cell>TxtENT EN&gt;all</cell><cell>stem + stopwords + tagged with UMLS thesaurus</cell></row><row><cell>TxtFRN FR&gt;all</cell><cell>stem + stopwords</cell></row><row><cell>TxtFRT FR&gt;all</cell><cell>stem + stopwords + tagged with UMLS thesaurus</cell></row><row><cell>TxtDEN DE&gt;all</cell><cell>stem + stopwords</cell></row><row><cell>TxtDET DE&gt;all</cell><cell>stem + stopwords + tagged with UMLS thesaurus</cell></row><row><cell>TxtXN all&gt;all</cell><cell>stem + stopwords</cell></row><row><cell>TxtXT all&gt;all</cell><cell>stem + stopwords + tagged with UMLS thesaurus</cell></row></table><note coords="5,127.62,294.70,6.98,5.40;5,136.86,296.67,357.44,8.10"><p><p>(1) </p>[Query language] &gt; [Annotation language]; "all" refers to the concatenation of text in all languages</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,205.62,325.38,207.60,160.24"><head>Table 6 .</head><label>6</label><figDesc>Visual experiments.</figDesc><table coords="5,214.44,342.91,166.41,125.10"><row><cell>Run Identifier Method (1)</cell></row><row><cell>VisG GIFT</cell></row><row><cell>VisGFANDavg GIFT ANDavg FIRE</cell></row><row><cell>VisGFANDmax GIFT ANDmax FIRE</cell></row><row><cell>VisGFANDmin GIFT ANDmin FIRE</cell></row><row><cell>VisGFANDmm GIFT ANDmm FIRE</cell></row><row><cell>VisGFORavg GIFT ORavg FIRE</cell></row><row><cell>VisGFORmax GIFT ORmax FIRE</cell></row><row><cell>VisGFORmin GIFT ORmin FIRE</cell></row><row><cell>VisGFORmm GIFT ORmm FIRE</cell></row></table><note coords="5,205.62,475.54,6.98,5.40;5,214.86,477.51,198.36,8.10"><p><p><p>(1) </p>The merging strategy is defined by [Operator]</p>[Metric]    </p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,87.42,506.22,418.56,173.00"><head>Table 7 .</head><label>7</label><figDesc>Mixed textual and visual retrieval experiments.</figDesc><table coords="5,87.42,525.84,418.56,153.38"><row><cell>Run Identifier Method</cell><cell>Merging strategy</cell></row><row><cell>MixGENT[Merging] VisG+TxtENT</cell><cell>ANDmax, ANDmin, ANDavg, ORmax,</cell></row><row><cell></cell><cell>ORmin, ORavg, ORmm, LEFTmax,</cell></row><row><cell></cell><cell>LEFTmin, LEFTmm, RIGHTmax,</cell></row><row><cell></cell><cell>RIGHTmin, RIGHTmm</cell></row><row><cell>MixGFRT[Merging] VisG+TxtFRT</cell><cell>ORmax, ORmm, LEFTmax, LEFTmm,</cell></row><row><cell></cell><cell>ANDmin</cell></row><row><cell>MixGDET[Merging] VisG+TxtDET</cell><cell>ORmax, ORmm, LEFTmax, LEFTmm,</cell></row><row><cell></cell><cell>ANDmin</cell></row><row><cell cols="2">MixGFANDminENT[Merging] VisGFANDmin+TxtENT ORmax, ORmm, LEFTmax, LEFTmm,</cell></row><row><cell></cell><cell>ANDmin</cell></row><row><cell>MixGFORmaxENT[Merging] VisGFORmax+TxtENT</cell><cell>ORmax, ORmm, LEFTmax, LEFTmm,</cell></row><row><cell></cell><cell>ANDmin</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,175.02,131.22,245.33,137.24"><head>Table 8 .</head><label>8</label><figDesc>Results for textual experiments.</figDesc><table coords="6,175.02,150.12,245.33,118.34"><row><cell></cell><cell cols="2">RelRet MAP R-prec P10</cell><cell>P30</cell><cell>P100</cell></row><row><cell cols="2">TxtENN 2,294 0.3518 0.389</cell><cell cols="2">0.58 0.4556 0.36</cell></row><row><cell>TxtXN</cell><cell cols="3">2,252 0.299 0.354 0.4067 0.3756 0.2943</cell></row><row><cell cols="4">TxtENT 2,002 0.274 0.2876 0.45 0.3822 0.2697</cell></row><row><cell>TxtXT</cell><cell cols="3">1,739 0.2005 0.2118 0.3267 0.2889 0.2263</cell></row><row><cell>TxtFRN</cell><cell cols="3">898 0.1107 0.1429 0.2733 0.1989 0.133</cell></row><row><cell>TxtFRT</cell><cell cols="3">970 0.1082 0.1138 0.2533 0.1911 0.1297</cell></row><row><cell>TxtDET</cell><cell cols="3">694 0.0991 0.0991 0.23 0.1222 0.0837</cell></row><row><cell cols="4">TxtDEN 724 0.0932 0.1096 0.18 0.1356 0.097</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="6,156.00,346.39,279.95,116.60"><head>Table 9 .</head><label>9</label><figDesc>Results for visual experiments(1) .</figDesc><table coords="6,159.42,367.32,276.53,77.90"><row><cell></cell><cell>RelRet MAP R-prec P10</cell><cell>P30</cell><cell>P100</cell></row><row><cell>VisG</cell><cell cols="3">532 0.0186 0.0396 0.0833 0.0833 0.047</cell></row><row><cell>VisGFANDmm</cell><cell cols="3">165 0.0102 0.0255 0.0667 0.05 0.0347</cell></row><row><cell cols="4">VisGFANDmax 165 0.0099 0.0251 0.06 0.0511 0.0343</cell></row><row><cell>VisGFANDavg</cell><cell cols="3">165 0.0087 0.0214 0.0467 0.0556 0.0343</cell></row><row><cell>VisGFANDmin</cell><cell cols="3">165 0.0081 0.0225 0.0367 0.0478 0.0333</cell></row></table><note coords="6,156.00,452.92,6.98,5.40;6,165.24,454.89,231.66,8.10"><p><p>(1) </p>Evaluations for some experiments with OR operator are missing</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="7,127.62,106.15,339.16,344.06"><head>Table 10 .</head><label>10</label><figDesc>Results for mixed textual and visual retrieval experiments(1) . Evaluations for some experiments with OR operator are missing</figDesc><table coords="7,127.62,125.10,339.16,320.45"><row><cell></cell><cell cols="3">RelRet MAP R-prec P10</cell><cell>P30</cell><cell>P100</cell></row><row><cell>MixGENTRIGHTmin</cell><cell cols="5">2002 0.274 0.2876 0.45 0.3822 0.2697</cell></row><row><cell>MixGENTRIGHTmax</cell><cell cols="4">2045 0.2502 0.2821 0.3767 0.35</cell><cell>0.29</cell></row><row><cell>MixGENTRIGHTmm</cell><cell cols="5">2045 0.2486 0.2817 0.3733 0.3578 0.289</cell></row><row><cell>MixGFANDminENTORmm</cell><cell cols="3">1972 0.1427 0.1439 0.22</cell><cell cols="2">0.2 0.1793</cell></row><row><cell>MixGFANDminENTORmaxt</cell><cell cols="5">1972 0.1419 0.1424 0.2067 0.1911 0.177</cell></row><row><cell>MixGFRTORmm</cell><cell cols="5">697 0.0372 0.064 0.1433 0.1244 0.084</cell></row><row><cell>MixGFRTORmax</cell><cell cols="5">693 0.0322 0.0611 0.14 0.1233 0.0747</cell></row><row><cell>MixGENTLEFTmm</cell><cell cols="5">532 0.0279 0.0485 0.12 0.0944 0.0643</cell></row><row><cell>MixGDETLEFTmm</cell><cell>532</cell><cell>0.024 0.043</cell><cell>0.1</cell><cell cols="2">0.09 0.0577</cell></row><row><cell>MixGFRTLEFTmm</cell><cell cols="5">532 0.0236 0.0416 0.09 0.0889 0.058</cell></row><row><cell>MixGENTANDavg</cell><cell cols="5">162 0.0234 0.0341 0.17 0.1056 0.047</cell></row><row><cell>MixGENTANDmin</cell><cell cols="5">162 0.0229 0.0341 0.17 0.1056 0.047</cell></row><row><cell>MixGDETANDmin</cell><cell cols="5">247 0.0213 0.0415 0.12 0.0989 0.0447</cell></row><row><cell>MixGFRTANDmin</cell><cell cols="5">176 0.0209 0.037 0.1167 0.1044 0.0487</cell></row><row><cell>MixGFRTLEFTmax</cell><cell cols="5">532 0.0191 0.0398 0.0833 0.0856 0.0487</cell></row><row><cell>MixGDETLEFTmax</cell><cell cols="5">532 0.0189 0.0408 0.0867 0.0844 0.048</cell></row><row><cell>MixGENTLEFTmax</cell><cell cols="5">532 0.0186 0.0397 0.0833 0.0833 0.0473</cell></row><row><cell>MixGENTANDmax</cell><cell cols="5">162 0.0175 0.0332 0.1533 0.1044 0.047</cell></row><row><cell>MixGENTLEFTmin</cell><cell cols="5">532 0.0155 0.0339 0.0767 0.0822 0.0433</cell></row><row><cell>MixGFANDminENTANDmin</cell><cell>67</cell><cell cols="4">0.0114 0.0152 0.1233 0.0622 0.0207</cell></row><row><cell>MixGFANDminENTLEFTmm</cell><cell cols="5">165 0.0099 0.024 0.0533 0.0544 0.0363</cell></row><row><cell cols="6">MixGFANDminENTLEFTmax 165 0.0081 0.0225 0.0367 0.0478 0.0333</cell></row><row><cell>(1)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work has been partially supported by the <rs type="funder">Spanish R+D National Plan</rs>, by means of the project <rs type="projectName">RIMMEL (Multilingual and Multimedia Information Retrieval, and its Evaluation</rs>), <rs type="grantNumber">TIN2004-07588-C03-01</rs>; and by the <rs type="funder">Madrid's R+D Regional Plan</rs>, by means of the project <rs type="projectName">MAVIR (Enhancing the Access and the Visibility of Networked Multilingual Information for the Community of Madrid</rs>), <rs type="grantNumber">S-0505/TIC/000267</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_dsybDAu">
					<idno type="grant-number">TIN2004-07588-C03-01</idno>
					<orgName type="project" subtype="full">RIMMEL (Multilingual and Multimedia Information Retrieval, and its Evaluation</orgName>
				</org>
				<org type="funded-project" xml:id="_gQ5W3wW">
					<idno type="grant-number">S-0505/TIC/000267</idno>
					<orgName type="project" subtype="full">MAVIR (Enhancing the Access and the Visibility of Networked Multilingual Information for the Community of Madrid</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,97.92,692.70,314.66,9.02" xml:id="b0">
	<monogr>
		<ptr target="http://lucene.apache.org[Visited10/08/2007" />
		<title level="m" coord="7,97.92,692.70,91.47,9.02">Apache Lucene project</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,97.92,710.22,426.64,9.02;7,97.92,721.68,203.44,9.02" xml:id="b1">
	<monogr>
		<ptr target="http://www.computing.dcu.ie/~gjones/CLEF2005/Multi-8/[Visited10/08/2007" />
		<title level="m" coord="7,97.92,710.22,261.15,9.02">CLEF 2005 Multilingual Information Retrieval resources page</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,97.92,73.26,426.60,9.02;8,97.92,84.72,326.20,9.02" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,262.84,73.26,261.68,9.02;8,97.92,84.72,41.73,9.02">FIRE -Flexible Image Retrieval Engine: ImageCLEF 2004 Evaluation</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">;</forename><forename type="middle">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,157.08,84.72,45.02,9.02">CLEF 2004</title>
		<meeting><address><addrLine>Bath, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-09">September 2004</date>
			<biblScope unit="volume">3491</biblScope>
			<biblScope unit="page" from="688" to="698" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,97.92,102.24,411.85,9.02" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="8,125.43,102.24,121.21,9.02">The GNU Image-Finding Tool</title>
		<author>
			<persName coords=""><surname>Gift</surname></persName>
		</author>
		<ptr target="http://www.gnu.org/software/gift/[Visited10/08/2007" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,97.92,119.76,426.60,9.02;8,97.92,131.22,426.58,9.02;8,97.92,142.74,355.34,9.02" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,370.55,119.76,153.97,9.02;8,97.92,131.22,195.84,9.02">Semiautomatic Extraction of Thesauri and Semantic Search in a Digital Image Archive</title>
		<author>
			<persName coords=""><forename type="first">José</forename><forename type="middle">C</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julio</forename><forename type="middle">;</forename><surname>Villena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cristina</forename><forename type="middle">;</forename><surname>Moreno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Martínez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,301.21,131.22,223.29,9.02;8,97.92,142.74,204.79,9.02">Integrating Technology and Culture: 10th International Conference on Electronic Publishing, ELPUB 2006</title>
		<meeting><address><addrLine>Bansko, Bulgaria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-06-16">14-16 June 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,97.92,160.26,426.66,9.02;8,97.92,171.72,168.10,9.02" xml:id="b5">
	<monogr>
		<ptr target="http://www-i6.informatik.rwth-aachen.de/~deselaers/fire.html" />
		<title level="m" coord="8,97.92,160.26,192.30,9.02">FIRE: Flexible Image Retrieval System</title>
		<imprint>
			<date type="published" when="2007-08-10">10/08/2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,97.92,189.24,426.58,9.02;8,97.92,200.76,426.53,9.02;8,97.92,212.22,214.44,9.02" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,97.92,200.76,210.36,9.02">MIRACLE team report for ImageCLEF IR in CLEF</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Martínez-Fernández</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julio</forename><forename type="middle">;</forename><surname>Villena-Román</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ana</forename><forename type="middle">M</forename><surname>García-Serrano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paloma</forename><surname>Martínez-Fernández</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,336.07,200.76,188.38,9.02;8,97.92,212.22,26.75,9.02">Proceedings of the Cross Language Evaluation Forum</title>
		<meeting>the Cross Language Evaluation Forum<address><addrLine>Alicante, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-09-22">2006. 2006. 20-22 September 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,97.92,229.74,426.55,9.02;8,97.92,241.20,426.64,9.02;8,97.92,252.72,426.62,9.02;8,97.92,264.24,101.45,9.02" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,129.56,241.20,242.99,9.02">Combining Textual and Visual Features for Image Retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Martínez-Fernández</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julio</forename><forename type="middle">;</forename><surname>Villena-Román</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ana</forename><forename type="middle">M</forename><surname>García-Serrano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">José</forename><surname>González-Cristóbal</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Carlos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,379.46,241.20,145.09,9.02;8,97.92,252.72,349.65,9.02">Accessing Multilingual Information Repositories: 6th Workshop of the Cross-Language Evaluation Forum, CLEF 2005</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint/>
	</monogr>
	<note>Revised Selected Papers</note>
</biblStruct>

<biblStruct coords="8,202.42,264.24,322.01,9.02;8,97.92,275.70,72.81,9.02" xml:id="b8">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="s" coord="8,305.40,264.24,143.22,9.02">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<idno type="ISSN">0302-9743</idno>
		<imprint>
			<biblScope unit="volume">4022</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,97.92,293.22,426.58,9.02;8,97.92,304.74,426.57,9.02;8,97.92,316.19,363.71,9.02" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,224.42,304.74,300.07,9.02;8,97.92,316.19,21.51,9.02">Overview of the ImageCLEFmed 2007 Medical Retrieval and Annotation Tasks</title>
		<author>
			<persName coords=""><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">;</forename><surname>Henning; Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eugene</forename><forename type="middle">;</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jayashree</forename><forename type="middle">;</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">;</forename><surname>Deserno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><forename type="middle">;</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,126.16,316.19,178.23,9.02">Working Notes of the 2007 CLEF Workshop</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">September 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,97.92,333.71,426.47,9.02;8,97.92,345.23,51.41,9.02" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Porter</surname></persName>
		</author>
		<ptr target="http://www.snowball.tartarus.org" />
		<title level="m" coord="8,160.18,333.71,156.76,9.02">Snowball stemmers and resources page</title>
		<imprint>
			<date type="published" when="2007-08-10">10/08/2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,97.92,362.69,426.57,9.02;8,97.92,374.21,207.51,9.02" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="8,201.47,362.69,269.96,9.02">Page of resources for CLEF (Stopwords, transliteration, stemmers</title>
		<ptr target="http://www.unine.ch/info/clef[Visited10/08/2007" />
		<imprint/>
		<respStmt>
			<orgName>University of Neuchatel</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="8,97.92,391.73,17.78,9.02;8,131.65,391.73,34.47,9.02;8,182.12,391.73,30.06,9.02;8,228.19,391.73,8.33,9.02;8,252.53,391.73,40.30,9.02;8,308.78,391.73,34.41,9.02;8,359.19,391.73,36.67,9.02;8,411.86,391.73,8.33,9.02;8,436.13,391.73,29.15,9.02;8,481.29,391.73,12.23,9.02;8,509.51,391.73,15.02,9.02;8,97.92,403.19,246.11,9.02" xml:id="b12">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">U</forename><forename type="middle">S</forename></persName>
		</author>
		<ptr target="http://www.nlm.nih.gov/research/umls/[Visited10/08/2007" />
		<imprint>
			<publisher>National Institutes of Health</publisher>
		</imprint>
		<respStmt>
			<orgName>Library of Medicine</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
