<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,105.33,151.38,392.34,12.38;1,254.28,173.29,94.45,12.38;1,348.72,168.17,5.98,10.48">Cross-modal retrieval by text and image feature biclustering *</title>
				<funder ref="#_JeA6CEg #_By9JBab">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,194.64,204.00,69.97,9.96"><forename type="first">András</forename><surname>Benczúr</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences {benczur</orgName>
								<address>
									<settlement>ibiro</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,277.88,204.00,48.64,9.96"><forename type="first">István</forename><surname>Bíró</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences {benczur</orgName>
								<address>
									<settlement>ibiro</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,339.81,204.00,68.56,9.96"><forename type="first">Mátyás</forename><surname>Brendel</surname></persName>
							<email>mbrendel@ilab.sztaki.hu</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences {benczur</orgName>
								<address>
									<settlement>ibiro</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,188.05,217.95,77.28,9.96"><forename type="first">Károly</forename><surname>Csalogány</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences {benczur</orgName>
								<address>
									<settlement>ibiro</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,278.61,217.95,65.87,9.96"><forename type="first">Bálint</forename><surname>Daróczy</surname></persName>
							<email>daroczyb@ilab.sztaki.hu</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences {benczur</orgName>
								<address>
									<settlement>ibiro</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,357.76,217.95,57.18,9.96"><forename type="first">Dávid</forename><surname>Siklósi</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences {benczur</orgName>
								<address>
									<settlement>ibiro</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,105.33,151.38,392.34,12.38;1,254.28,173.29,94.45,12.38;1,348.72,168.17,5.98,10.48">Cross-modal retrieval by text and image feature biclustering *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">975C73DEC53BCF256E6A2A1A51166388</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Managment]: LanguagesQuery Languages Measurement, Performance, Experimentation Cross-modal retrieval, image annotation, biclustering, co-clustering</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe our approach to the ImageCLEF-Photo 2007 task. The novelty of our method consists of biclustering image segments and annotation words. Given the query words, we may select the image segment clusters that have strongest cooccurrence with the corresponding word clusters. These image segment clusters act as the selected segments relevant to a query. We rank text hits by our own tf.idf based information retrieval system and image similarities by using a 20-dimensional vector describing the visual content of image segments. Here relevant image segments were selected by the biclustering procedure. Images were segmented by a home developed segmenter. We used neither query expansion nor relevance feedback; queries were generated automatically from the title and the 0.1 weighted description words.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.275" lry="841.889"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.275" lry="841.889"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.275" lry="841.889"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.275" lry="841.889"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.275" lry="841.889"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.275" lry="841.889"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.275" lry="841.889"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.275" lry="841.889"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper we describe our approach to the ImageCLEF Photo 2007 evaluation campaign <ref type="bibr" coords="1,482.06,647.72,10.51,9.96" target="#b6">[7]</ref> over the IAPR TC-12 Benchmark <ref type="bibr" coords="1,219.06,659.68,10.51,9.96" target="#b7">[8]</ref> with reduced annotation text. The key feature of our solution is to combine text based image retrieval and content based image retrieval. Moreover, a biclustering algorithm to form interrelated clusters of image segments and annotation words.</p><p>Our CBIR method is based on segmentation of the image and on the comparison of features of the segments. The biclustering algorithm is used to lter relevant segments.</p><p>Many of the existing CBIR systems rely on so called blobs, regions, or segments, see <ref type="bibr" coords="2,459.73,181.51,10.51,9.96" target="#b4">[5,</ref><ref type="bibr" coords="2,473.43,181.51,12.73,9.96" target="#b10">11,</ref><ref type="bibr" coords="2,489.34,181.51,7.75,9.96" target="#b3">4,</ref><ref type="bibr" coords="2,500.28,181.51,12.73,9.96" target="#b9">10]</ref> for example. The specialty of our method is our special segmentation method and the combining of CBIR with biclustering and text based IR.</p><p>Biclustering is used in a wide variety of applications. For example documents-words clustering <ref type="bibr" coords="2,90.00,229.33,10.51,9.96" target="#b8">[9]</ref> or gene expression clustering <ref type="bibr" coords="2,232.18,229.33,9.96,9.96" target="#b0">[1]</ref>. <ref type="bibr" coords="2,90.00,257.89,7.89,15.78" target="#b1">2</ref> The base text search engine</p><p>We use the Hungarian Academy of Sciences search engine <ref type="bibr" coords="2,344.16,284.07,10.51,9.96" target="#b1">[2]</ref> as our information retrieval system. Its ranking algorithm was developed originally for HTML pages, it uses a tf.idf based ranking with increased weights for query words within URL, anchor text, title and additional HTML elements.</p><p>We created small HTML-like documents from the textual information of the images. These contain the title, description and the location part of the annotations. The ranking algorithm uses dierent weights depending on which part of the document contains the query term. As in the original HTML search engine we removed the stop words from the documents. We used a wider range of stop words than usually because words like "photo" and "image" are frequently used in annotations but does not have distinctive meaning in this task.</p><p>The queries which were submitted to the search engine were constructed from the the title and narrative parts of topics. We removed the stop words described above rst and sentences containing the phrase "not relevant" were also removed from the narrative. The resulting query is the concatenation of the remaining words of the title and the narrative parts. The words from the narrative part are marked, as the ranking algorithm uses dierent weights for the title and narrative query word hits.</p><p>The relevance score is computed by the weighted combination of the following:</p><p>• tf.idf based ranking which takes the proximity of query terms into account <ref type="bibr" coords="2,443.19,483.20,17.81,9.96" target="#b11">[12,</ref><ref type="bibr" coords="2,464.46,483.20,7.75,9.96" target="#b2">3]</ref> and uses document length normalization <ref type="bibr" coords="2,254.32,495.16,15.49,9.96" target="#b13">[14]</ref> and uses dierent weights depending on the location of the query terms inside the document (title, description or location).</p><p>• Number of dierent query terms in the document.</p><p>This ranking method had several parameters: weights of the tf.idf score and the number of query words, weights of the title, description and location hits and the weight of the title and narrative query terms. After several runs with dierent set-ups, we found that we get the bestlooking result if the weight of the number of query terms is much higher than the tf.idf score. In other words we rank the documents with respect to the number of query terms, then use the tf.idf score to rank those documents that have the same number of query terms.</p><p>Since many topics have location reference, we get the best results if the weight of hits inside the location is much higher than the weights of title and the description. The query terms from the topic title have ten times higher weight than the narrative terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The content based IR system</head><p>The task of the CBIR part was to help annotation based retrieval with a content based method. Query images had to be classied into query topics. For each topics 3 sample images were given. For each query image we had to compute a distance, which measures how similar the query image is to the 3 sample images in the topic. Segment, region or blob based image similarity is a common method in content based image retrieval, see for example <ref type="bibr" coords="2,348.42,744.98,10.51,9.96" target="#b4">[5,</ref><ref type="bibr" coords="2,362.95,744.98,12.73,9.96" target="#b10">11,</ref><ref type="bibr" coords="2,379.69,744.98,7.75,9.96" target="#b3">4,</ref><ref type="bibr" coords="2,391.45,744.98,11.62,9.96" target="#b9">10]</ref>. Respectively, the basis of our method is to nd segments on the query image, which are similar to the segments in the sample-images. Image segmentation in itself is a widely researched and open problem itself. We used an image segmenter developed by our group to extract segments from the query images. Similarity of complex objects is usually measured feature-based. This means the the similarity of the objects is dened by the similarity in a certain feature-space.</p><formula xml:id="formula_0" coords="3,187.02,181.09,325.98,10.32">dist(S i , S j ) = d(F (S i ), F (S j )) : S i ∈ S(Q), S j ∈ S(I)<label>(1)</label></formula><p>where S(q) is the set of segments of the query image Q, and S(I) is the set of segments of the sample image I, dist is the distance function of the segments, d is a distance function in the feature space (usually some of the conventional metrics in the n-dimensional real space), F is the function, which assigns features to objects and segments. We extracted features, like mean color, size, shape information, and histogram information. Our histograms had 5 bins in each channel. Altogether a 20-dimensional, real valued feature-vector was extracted for each of the segments. The same features were extracted for the segments of the sample-images. The features of the segments were written to a le. This way we obtained a data-base of the topic-samples, containing features of segments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Segmentation</head><p>Most of the traditional digital image segmentation methods were based on the fact that we have no further information aside the position of pixels and their color. Fifteen or less regions are usual considered enough for processing with a Content Based Image Retrieval(CBIR) system properly.</p><p>In computer graphics we use many color representations. The most common color space is RGB. Because the equivalence of components in this three dimensional space we can use the Euclidean distance to measure the similarity of pixels P 1 and P 2 :</p><formula xml:id="formula_1" coords="3,150.80,426.45,362.20,10.49">dif f RGB(P 1 , P 2 ) = (R P2 -R P1 ) 2 + (G P2 -G P1 ) 2 + (B P2 -B P1 ) 2<label>(2)</label></formula><p>We know that the human visual system (HVS) is more sensitive to the brightness of pixels than to the additional color. According to this we can use a dierent distance:</p><formula xml:id="formula_2" coords="3,131.23,482.41,381.77,10.32">dif f Y (P 1 , P 2 ) = 0.3 * | R P2 -R P1 | +0.59 * | G P2 -G P1 | +0.11 * | B P2 -B P1 |<label>(3)</label></formula><p>The basic idea is that we transform the image into a graph. Let G = (V, E) be an undirected graph where ∀v i ∈ V corresponds to a pixel in the image, and the edges in E connect certain pairs of neighboring pixels. The early graph-based representations contained only edges between neighboring pixels, recent works dene a full graph with a more complex distance function. This graph-based representation of the image reduces the original proposition into a graph cutting challenge.</p><p>The adequate cut is the normalized cut (Ncut developed by Shi and Malik <ref type="bibr" coords="3,421.87,576.06,17.10,9.96" target="#b12">[13]</ref>). Unfortunately Ncut is one of the NP-hard problems so they could only approach the optimal cut. The subjective quality of the minimal cut found by the early graph-based CBIR systems is far weaker than that of the result of nearly normalized cut-based CBIR systems. However, old normalized cut-based methods are too slow for real-time or practical utilization. Felzenszwalb and Huttenlocher made a very ecient and linear algorithm that yields a result near to the optimal normalized cut <ref type="bibr" coords="3,497.51,635.83,11.62,9.96" target="#b5">[6]</ref>. Notably, they did not limit the number of segments inside an image.</p><p>With our restrictions, the graph-based algorithms are not the only option. One of the wellknown methods is pyramid-based image segmentation. Using the Gaussian-Laplacian pyramid we can dene a connection between pixels on neighboring levels and inside a level. Generally the pyramid-based segmentation methods use six or more levels with typically small thresholds. Pyramid-based algorithms have advantages over graph-based methods, such as computation time, but they oer subjectively worse quality -they suer from the so-called blocking problem, and perform badly with complicated picture regions.</p><p>When we decided to develop our own segmentation method we wanted to achieve a relatively low running time, and to preserve a quality comparable to the graph-based algorithms used as reference. To improve the eciency of our implementation we used some functions from the OpenCV library (www.intel.com/technology/computing/opencv/) for resizing, smoothing the image and to calculate the Sobel gradient. We resized all images to a xed resolution to eliminate the downsides of dierent image resolutions. Gaussian-based smoothing helped us cut down high frequency noise. As pre-segmentation we built a three-level Gaussian-Laplacian pyramid to dene initial pixel groups. The original pyramid-based method which uses brightness distance was modied to eliminate the blocking problem. After these, we had groups of 16 pixels maximum. To detect complex segments, we implemented a modied Felzenszwalb and Huttenlocher <ref type="bibr" coords="4,408.16,218.95,13.45,9.96" target="#b5">[6]</ref> graph-based method with an adaptive threshold system using Euclidean distance to prefer larger regions instead of small, noise-like parts of the image.</p><p>Algorithm Segmentation (I src , τ 1 , τ 2 ) τ 1 and τ 2 are threshold functions. Let I 2 be the source image, I 1 and I 0 are the down-scaled images. Let P (x, y, i) be the pixel P (x, y) in the image on level i (I i ). Let G = (V, E) be an undirected weighted graph where ∀v i ∈ V corresponds to a pixel P (x, y). Each edge (v i , v j ) has a non-negative weight w(v i , v j ).</p><p>Gaussian-Laplacian Pyramid 1. For every P(x,y,1) Join(P (x, y, 1), P (x/2, y/2, 0)) if τ 1 &lt; dif f Y (P (x, y, 1), P (x/2, y/2, 0)) 2. For every P(x,y,2) Join(P (x, y, 2), P (x/2, y/2, 1)) if τ 1 &lt; dif f Y (P (x, y, 2), P (x/2, y/2, 1)) This algorithm sometimes does not nd relevant parts with low initial thresholds. To nd the relevant borders which would disappear with the graph-based method we calculated the gradient image to select important edges from remainders. Typically we detected a hundred or less segments in a regular image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph-based Segmentation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The distance function</head><p>We used euclidean distance to measure similarity of images. The distance of image Q to sample image I was computed as:</p><formula xml:id="formula_3" coords="5,144.34,161.68,364.42,26.65">dist(Q, I) = min I 1 n j min i dist(S i , S j ) : S i ∈ S(Q), S j ∈ S(I), n = |S(I)| (<label>4</label></formula><formula xml:id="formula_4" coords="5,508.76,167.75,4.24,9.96">)</formula><p>where n is the number of segments in the sample image, S(Q) is the set of segments of image Q, S(I) is the set of segments of the sample-image S. So, we took all the segments in the sample image, and searched for the closest segment in the query image. After this, we summed up all the distances for the sample image. Doing this in the other way would also be possible: for each segment in the query image we could search closest segments in the sample images. We choose our direction, because for each topic the sample images and its segments are xed, and this way, dist(Q) does not depend on the number of segments in the query image. To be sure, we are using a normalization by n, but found that this way the distances are better. From the 3 sample-images, we took the closest one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Image segment annotation word biclustering</head><p>Clustering is used to group together similar objects and has practical importance in a wide variety of applications such as web-log and market-basket data analysis. The data in this applications is arranged as a co-occurrence table. Most of the clustering algorithms clusters one dimension of the co-occurrence table based on the similarities along the second dimension. Biclustering is simultaneously clusters both dimensions of the table by exploiting the duality between rows and columns. We used the following biclustering algorithm <ref type="bibr" coords="5,296.31,422.42,9.96,9.96" target="#b8">[9]</ref>. Let X and Y be discrete random variables that take values in the sets {segments} and {words of annotations} respectively. Let p(X, Y ) denote the joint probability distribution between X and Y . Let the k clusters of X be written as: {x For brevity we write X = C X (X) and Ŷ = C Y (Y ) where X and Ŷ are random variables that are a deterministic function of X and Y , respectively. Finally let D(p q) denote the Kullback-Leibler divergence of probability distributions p and q.</p><p>Algorithm BiClustering p, k, l, C</p><p>X , C Y are some initial partition functions.</p><p>1. Compute segment (row) clusters: For each segment x , nd its new cluster index as</p><formula xml:id="formula_7" coords="6,181.57,196.85,251.82,24.06">C (t+1) X (x) = argmin x D p(x, Y ) p(x) p(Y ) • p (t) (x, ŷ) p (t) (x) • p (t) (ŷ)</formula><p>,</p><formula xml:id="formula_8" coords="6,157.21,232.89,187.02,14.22">resolving ties arbitrarily. Let C (t+1) Y = C (t)</formula><p>Y . 2. Compute word (column) clusters: For each word y, nd its new cluster index as</p><formula xml:id="formula_9" coords="6,171.28,286.14,272.38,24.06">C (t+2) Y (y) = argmin ŷ D p(X, y) p(y) p(X) • p (t+1) (x, ŷ) p (t+1) (x) • p (t+1) (ŷ)</formula><p>,</p><formula xml:id="formula_10" coords="6,157.21,322.19,203.69,14.22">resolving ties arbitrarily. Let C (t+2) X = C (t+1) X .</formula><p>3. set t = t + 2 and go to step 1.</p><p>We modied the above algorithm at the rst step by combining KL-divergence with euclideandistance on the segment features as follows. Let f 1 (x), ..., f s (x) denote the features of a segment x. Let c i (x) be the avarage of f i (x) (i = 1, ..., s) where x ∈ x. With this notations the modied rst step is</p><formula xml:id="formula_11" coords="6,90.00,447.25,430.12,65.65">C (t+1) X (x) = argmin x    D p(x, Y ) p(x) p(Y ) • p (t) ( x, ŷ)p (t) (x) • p (t) (ŷ) + s i=1 f i (x) -c (t) i (x) 2   <label>5</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Image distance with bicluster information</head><p>We extended the CBIR method by using the above described biclustering method. It was supposed that these biclusters indicate some semantical connection between the features and the text. This was used to rene the CBIR method. When the segments of the 3 sample-images were examined, we tried to lter them. All the segments were examined if there is a word in a corresponding textual bicluster, which occurs in the title of the topic. The title of the topic was a short description. If there is at least one word in common, then we assumed, that the segment is semantically connected to a word, which is relevant. Consequently, we included this segment in our computation. In the rare case, when all of the segments of a sample-image was excluded, we included them all again, since an empty set of segments would not do anything good. The distance measure was done the same way with the ltered segments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>Table <ref type="table" coords="6,116.70,685.20,4.98,9.96" target="#tab_1">1</ref> shows the results of the text based, content based and the mixed method. The results were evaluated by the ImageCLEF organizers using the following measures: Mean Average Precision (MAP), Precision at 10/20/30 (P10, P20, P30), Binary Preference (BPREF), Geometric Mean Average Precision (GMAP).</p><p>Results using only the visual information are very poor. However, when combined with the text-based ranking it yields signicant improvements in every measures. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion and future work</head><p>We have demonstrated that the biclustering of image segments and annotation words can improve the performance of an IR system.</p><p>Our future work to be done includes to improve the content based IR behind the results, to test various settings of the segmentation and the biclustering algorithm. And nally, to use query expansion and feedback in order to demonstrate whether the method can improve performance over the state of the art.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,144.48,500.19,326.22,10.62;4,157.21,512.15,261.39,9.96;4,144.48,532.07,326.22,10.32;4,157.21,544.03,87.57,9.96;4,144.48,563.95,326.22,10.32;4,157.21,575.91,313.49,10.32;4,157.21,588.53,11.53,9.65;4,172.56,587.86,30.90,10.32;4,144.48,607.79,229.14,9.96;4,373.62,608.46,20.43,9.65;4,394.56,607.79,76.14,9.96;4,157.21,619.75,67.31,9.96"><head>1 . 3 . 2 4.</head><label>132</label><figDesc>Compute M ax weight (R) = max e∈M ST (R,E) w(e) for every coherent group of points R where M ST (R, E) is the minimal spanning tree2. Compute Co(R) = τ 2 (R) + M ax weight (R) as the measure of coherence between points in R Join(R 1 , R 2 ) if e ∈ E exists so w(e) &lt; min(Co(R 1 ), Co(R 2 )) is true, where R 1 R 2 = ∅ and w(e)is the weight of the border edge e between R 1 and R Repeat steps 1,2,3 for every neighboring group (R 1 , R 2 ) until possible to join two groups</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,90.00,458.29,423.00,44.19"><head></head><label></label><figDesc>1 , x2 , ..., xk } , and let the l clusters of Y be written as: {ŷ 1 , ŷ2 , ..., ŷl } . We are interested in nding maps C X and C Y , C X : {x 1 , x 2 , ..., x k } → {x 1 , x2 , ..., xk }, C Y : {y 1 , y 2 , ..., y l } → {ŷ 1 , ŷ2 , ..., ŷl }.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,126.70,110.16,349.60,72.92"><head>Table 1 :</head><label>1</label><figDesc>Performance of the three basic method evaluated by dierent measures</figDesc><table coords="7,147.29,110.16,305.09,47.02"><row><cell></cell><cell>MAP</cell><cell>P10</cell><cell>P20</cell><cell>P30</cell><cell>BPREF GMAP</cell></row><row><cell cols="5">text + visual 0.2132 0.3267 0.2733 0.2478</cell><cell>0.1962</cell><cell>0.0441</cell></row><row><cell>text only</cell><cell cols="4">0.1880 0.2833 0.2350 0.2033</cell><cell>0.1675</cell><cell>0.0386</cell></row><row><cell>visual only</cell><cell cols="4">0.0138 0.0467 0.0433 0.0367</cell><cell>0.0240</cell><cell>0.0019</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div><p>* This work was supported by a <rs type="grantName">Yahoo! Faculty Research Grant</rs> and by grants <rs type="grantNumber">MOLINGV NKFP-2/0024/2005</rs>, <rs type="grantNumber">NKFP-2004</rs> project Language Miner http://nyelvbanyasz.sztaki.hu.</p><p>We use the <rs type="institution">Hungarian Academy of Sciences</rs> search engine [2] as our information retrieval system. Biclustering is used to extend our method so, that segments are ltered according to the estimated relevance-relation to the query-text.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_JeA6CEg">
					<idno type="grant-number">MOLINGV NKFP-2/0024/2005</idno>
					<orgName type="grant-name">Yahoo! Faculty Research Grant</orgName>
				</org>
				<org type="funding" xml:id="_By9JBab">
					<idno type="grant-number">NKFP-2004</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,110.48,340.71,402.52,9.96;7,110.48,352.66,51.73,9.96" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="7,299.90,340.71,147.28,9.96">Biclustering algorithms: A survey</title>
		<author>
			<persName coords=""><forename type="first">Ron</forename><surname>Shamir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Amos</forename><surname>Tanay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Roded</forename><surname>Sharan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>Oxford Univ Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,372.34,402.52,9.96;7,110.48,384.30,402.52,9.96;7,110.48,396.25,299.74,9.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,248.73,384.30,243.75,9.96">Searching a small national domainpreliminary report</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>András</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Károly</forename><surname>Benczúr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eszter</forename><surname>Csalogány</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dániel</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tamás</forename><surname>Fogaras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Máté</forename><surname>Sarlós</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eszter</forename><surname>Uher</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Windhager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,110.48,399.14,266.95,6.11">Proceedings of the 12th World Wide Web Conference (WWW)</title>
		<meeting>the 12th World Wide Web Conference (WWW)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,415.93,402.52,9.96;7,110.48,427.89,402.53,9.96;7,110.48,442.73,402.52,6.11;7,110.48,451.80,243.55,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,377.04,415.93,135.95,9.96;7,110.48,427.89,187.24,9.96">Term proximity scoring for adhoc retrieval on very large text collections</title>
		<author>
			<persName coords=""><forename type="first">Stefan</forename><surname>Büttcher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Brad</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Lushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,321.94,430.78,191.06,6.11;7,110.48,442.73,398.68,6.11">SIGIR &apos;06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page">621622</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,471.48,402.52,9.96;7,110.48,483.43,402.52,9.96;7,110.48,495.39,256.28,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,432.21,471.48,80.78,9.96;7,110.48,483.43,368.08,9.96">Blobworld: Image segmentation using expectation-maximization and its application to image querying</title>
		<author>
			<persName coords=""><forename type="first">Chad</forename><surname>Carson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hayit</forename><surname>Greenspan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,488.89,486.32,24.11,6.11;7,110.48,498.28,150.32,6.11">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">10261038</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,515.07,402.53,9.96;7,110.48,527.03,169.41,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,252.51,515.07,256.33,9.96">Image categorization by learning and reasoning with regions</title>
		<author>
			<persName coords=""><forename type="first">Yixin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,110.48,529.91,90.46,6.11">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">913939</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,546.71,402.52,9.96;7,110.48,558.66,228.40,9.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,331.43,546.71,176.95,9.96">Ecient graph-based image segmentation</title>
		<author>
			<persName coords=""><forename type="first">Pedro</forename><forename type="middle">F</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><forename type="middle">P</forename><surname>Huttenlocher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,110.48,561.55,181.91,6.11">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,578.34,402.52,9.96;7,110.48,590.30,402.52,9.96;7,110.48,602.25,210.59,9.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,440.75,578.34,72.25,9.96;7,110.48,590.30,224.48,9.96">Overview of the ImageCLEFphoto 2007 photographic retrieval task</title>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,360.77,593.19,152.22,6.11;7,110.48,605.14,40.15,6.11">Working Notes of the 2007 CLEF Workshop</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">September 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,621.93,402.52,9.96;7,110.48,633.89,402.52,9.96;7,110.48,648.73,402.52,6.11;7,110.48,657.80,203.16,9.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,445.05,621.93,67.95,9.96;7,110.48,633.89,321.93,9.96">The IAPR TC-12 benchmark -a new evaluation resource for visual information systems</title>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselears</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,456.09,636.78,56.91,6.11;7,110.48,648.73,402.52,6.11;7,110.48,660.69,113.57,6.11">International Workshop OntoImage 2006: Language Resources for Content-Based Image Retrieval, held in conjunction with LREC&apos;06</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page">1323</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,677.48,402.52,9.96;7,110.48,689.43,402.52,9.96;7,110.48,701.39,201.60,9.96" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,403.96,677.48,109.04,9.96;7,110.48,689.43,40.82,9.96">Information-theoretic coclustering</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dharmendra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Modha Inderjit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Subramanyam</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Mallela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,170.83,692.32,342.17,6.11;7,110.48,704.28,112.75,6.11">Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining</title>
		<meeting>the ninth ACM SIGKDD international conference on Knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2003">8998. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.47,721.07,402.53,9.96;7,110.48,733.02,402.52,9.96;7,110.48,744.98,370.54,9.96" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,276.73,721.07,232.08,9.96">Image similarity search with compact data structures</title>
		<author>
			<persName coords=""><forename type="first">Qin</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Moses</forename><surname>Charikar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,123.84,735.91,389.16,6.11;7,110.48,747.87,118.45,6.11">CIKM &apos;04: Proceedings of the thirteenth ACM international conference on Information and knowledge management</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">208217</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.47,111.36,402.52,9.96;8,110.48,123.31,378.34,9.96" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,314.79,111.36,198.20,9.96;8,110.48,123.31,137.08,9.96">Region-based image retrieval using integrated color, shape, and location index</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">G</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">K</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">K</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,256.35,126.20,127.30,6.11">Comput. Vis. Image Underst</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page">193233</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.47,143.24,402.53,9.96;8,110.48,155.19,402.53,9.96;8,110.48,167.15,133.46,9.96" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,256.02,143.24,252.43,9.96">Term proximity scoring for keyword-based retrieval systems</title>
		<author>
			<persName coords=""><forename type="first">Yves</forename><surname>Rasolofo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,248.19,158.08,22.20,6.11">ECIR</title>
		<title level="s" coord="8,352.55,158.08,156.10,6.11">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Fabrizio</forename><surname>Sebastiani</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">2633</biblScope>
			<biblScope unit="page">207218</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.47,187.07,402.53,9.96;8,110.48,199.03,242.35,9.96" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,247.22,187.07,175.05,9.96">Normalized cuts and image segmentation</title>
		<author>
			<persName coords=""><forename type="first">Jianbo</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,430.29,189.96,82.71,6.11;8,110.48,201.91,158.66,6.11">IEEE Transactions on Pattern and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page">888905</biblScope>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.47,218.95,402.52,9.96;8,110.48,230.91,247.97,9.96" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="8,402.37,218.95,110.63,9.96;8,110.48,230.91,58.09,9.96">Pivoted document length normalization</title>
		<author>
			<persName coords=""><forename type="first">Amit</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mandar</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gerard</forename><surname>Salton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<pubPlace>Ithaca, NY, USA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
