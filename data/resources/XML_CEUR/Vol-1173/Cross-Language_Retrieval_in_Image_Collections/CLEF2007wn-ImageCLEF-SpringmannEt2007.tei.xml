<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,136.57,148.86,329.85,15.15;1,222.88,170.78,157.23,15.15">Speeding up IDM without degradation of retrieval quality</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,223.31,204.67,87.43,8.74"><forename type="first">Michael</forename><surname>Springmann</surname></persName>
							<email>michael.springmann@unibas.ch</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Basel</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,319.09,204.67,60.60,8.74"><forename type="first">Heiko</forename><surname>Schuldt</surname></persName>
							<email>heiko.schuldt@unibas.ch</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Basel</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,136.57,148.86,329.85,15.15;1,222.88,170.78,157.23,15.15">Speeding up IDM without degradation of retrieval quality</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E01A867090DB3F21BBF1996753F7EF73</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>I.5 [Pattern Recognition]: I.5.4 Applications Algorithms, Measurement, Performance, Experimentation Content-Based Image Retrieval, Image Distortion Model, Medical Image Retrieval, Classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The Image Distortion Model (IDM) has shown good retrieval quality in previous runs of the medical automatic annotation task of previous ImageCLEF workshops. However, one of its limitations is computational complexity and the resulting long retrieval times. We applied several optimizations, in particular the use of an early termination strategy for the individual distance computations, the use of optimized data structures for the intermediate results, and the proper use of multithreading on state-of-the-art hardware.</p><p>With these extensions, we were able to perform the IDM P2DHMDM down to 1.5 second per query. Moreover, we extended the possible displacements to an area of 7x7 pixels, using a local context of either 5x5 or 7x7 pixels. We also introduced a classifier, that exploits the hierarchical structure of the IRMA code.</p><p>The results of the extendeded IDM P2DHMDM have been submitted to this year's medical automatic annotation task and achieved rank 19 to 25 out of 68. More importantly, the used techniques are not limited strictly to IDM but are also applicable to other expensive distance measures.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Image Distortion Model (IDM) has shown very good retrieval quality in the Medical Automatic Annotation Task at ImageCLEF 2005 <ref type="bibr" coords="1,300.25,658.42,10.52,8.74" target="#b5">[6]</ref> and was still ranked in the top 10 results of ImageCLEF 2006 <ref type="bibr" coords="1,168.55,670.38,14.61,8.74" target="#b11">[12]</ref>. It is used as a local feature, this means, the individual values of the feature are bound to a pixel or an area of the image rather the image as a whole. IDM performs a pixelby-pixel gray value comparison of downscaled versions of the image, in which some displacements of pixels are accepted. P2DHMDM extends IDM to consider not only a single pixel, but e.g. a 3x3 area for displacements -which improves the query results, but is at the same time associated with significantly higher complexity. In contrast to most of the successful techniques from the object recognition track that performed better in ImageCLF 2006, it is not strictly limited to the area of classification, but applicable to a wider range of image retrieval problems. A limiting factor of IDM as a similarity measure is the computational complexity and, consequently, its long retrieval times. According to <ref type="bibr" coords="2,220.60,135.93,14.62,8.74" target="#b14">[15]</ref>, the execution of a single query in a collection of 8'728 images took about 5 minutes on a standard Pentium PC with 2.4 GHz -which is clearly not even close to interactive response times. The authors therefore proposed to use a sieve function to reduce the number of expensive IDM computations to the nearest neighbors until a cutoff position c = 500 based on the less expensive Euclidean distance. By this, they reduced the time for a single query to 18.7 seconds, but this is only possible with some degradation in retrieval quality. Using such an approach therefore requires to find c that achieves a good tradeoff between speed an quality.</p><p>We propose an approach that increases the speed of IDM without any negative impact on the retrieval quality. In our experiments, we used the parameters for IDM as used in <ref type="bibr" coords="2,460.81,231.57,10.51,8.74" target="#b8">[9]</ref> with the Pseudo-2D Hidden Markov Distortion Model (P2DHMDM) <ref type="bibr" coords="2,354.80,243.53,14.62,8.74" target="#b9">[10]</ref>, but apply an early termination condition in the individual distance computation. By this, we can reduce the execution time for a single query on similar hardware to 4h 28m for the full run of 1'000 queries, therefore about 16 seconds per query. On modern hardware which is better suited for multithreading, we could further reduce this time to 1h 11m on a Core 2 Duo with 2.4 GHz (4.2 seconds per query) and only 24 minutes on a 8-way Xeon MP with 2.8 GHz enabled (1.5 seconds per query).</p><p>The main improvement in our approach is based on the following idea: As a result of the query, we want to retrieve a small set of reference images, that are the k nearest neighbors of the query image within a potentially big collection. This set is passed to a kNN classifier to determine the class of the query image. For this, we need the rank and the distance of the k nearest neighbors. It is important to notice that ranks and distances of images are not needed, as long as we can guarantee, that they do not belong to the set of those k nearest neighbors. Therefore we can terminate any individual distance computation of the query image and a reference image as soon as a certain threshold is exceeded. This threshold can be derived out of the best k images that have been found so far. This means, that only for the first k images of the collection we have to compute the exact distance. Then we can derive the threshold and can apply it to subsequent distance computations. We start processing the next feature vector of an image value-by-value. As soon as we find out, that it must exceed the threshold, we abort the computation for this image. If we processed the feature vector until its end and the image did not exceed the threshold, it also must have a distance that is smaller than some of the k best images we found before. By inserting its distance in a ordered list of the distances we found, we can decrease the value of the threshold to the k-th value in this list. We can now continue the query with a smaller threshold and therefore might be able to abort the following computations even earlier. We reapply this technique until we processed all images of the collection. Such a technique has already been used in the implementation of <ref type="bibr" coords="2,205.15,530.45,14.61,8.74" target="#b18">[19]</ref>, which is a part of ISIS <ref type="bibr" coords="2,335.17,530.45,15.50,8.74" target="#b10">[11,</ref><ref type="bibr" coords="2,354.96,530.45,7.75,8.74" target="#b2">3]</ref> Further improvements have been achieved by using specialized data structures and making excellent use of multi-threading.</p><p>For our runs in the ImageCLEF Medical Automatic Annotation Task, we extended the warp range of IDM to three pixels instead of only two and used a P2DHMDM with 5x5 and 7x7 pixel areas instead of only 3x3 as in <ref type="bibr" coords="2,224.75,578.27,14.61,8.74" target="#b9">[10]</ref>. When applied to the development data set, we have achieved better scores. Notice that extending the area results in significantly longer computation times. Therefore, the above mentioned optimizations we have applied are essential.</p><p>The remainder of this paper is organized as follows: Section 2 describes in depth the used distance measure and the chosen parameters. Section 3 describes the algorithmic optimizations, that achieved most of the performance improvements in the similarity computation. Section 4 adds more details about the implementation, that contributed in smaller performance improvements. Section 5 introduces the classifier that has been used to exploit to the hierarchical IRMA code. The results of all these modifications are presented in Section 6. Finally, Conclusion and outlook are given in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The IDM Distance Measure and Parameters of the Submitted Runs</head><p>The implementation used in the submitted runs is based on <ref type="bibr" coords="3,360.56,151.77,9.97,8.74" target="#b8">[9]</ref>. In contrast to FIRE<ref type="foot" coords="3,469.59,150.20,3.97,6.12" target="#foot_0">1</ref> , the implementation of used for the winning run of the medical automatic annotation task in 2005 <ref type="bibr" coords="3,499.71,163.73,9.97,8.74" target="#b6">[7]</ref>, which has been implemented in C++ and some Python for the UI, we used Java as the implementation language of choice. Due to the algorithmic nature of our proposed modifications, the implementation language has only little effect of the relative execution time of the unoptimized vs. the optimized solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Starting Point: IDM with P2DHMDM</head><p>The Image Distortion Model (IDM) is deformation model <ref type="bibr" coords="3,355.84,257.74,15.50,8.74" target="#b9">[10]</ref> which is used as a measure of distance or dissimilarity between two images. By using a k-Nearest Neighbor (kNN) classifier, it can be applied to the automatic annotation required in this task.</p><p>To determine the k nearest neighbors, each image of the collection needs to be compared to the query image using a distance function or distance measure. More formally, a distance function is a function that computes for Q, R ∈ I with I being the set of all images and Q being the query image and R being one reference image out of the collection: D :</p><formula xml:id="formula_0" coords="3,380.50,329.47,65.37,8.74">I × I → [0, ∞)</formula><p>The Euclidean distance is an example for an elementary distance measure that can be applied to two dimensional images.</p><formula xml:id="formula_1" coords="3,194.86,367.09,318.14,30.67">D euclid (Q, R) = height x=0 width y=0 (Q(x, y) -R(x, y)) 2<label>(1)</label></formula><p>with height and width being the height and width of the query image Q. R(x, y) and Q(x, y) denote the gray value of the pixel in row x and column y. The k nearest neighbors are the k images who have lowest distance to the query image. IDM then allows for some displacements of each individual pixel on both axes within the range of the warping distance w. Each displacement may get penalized with some costs that are associated with this displacement which are computed using the cost function C. Out of the possible displacements of a single pixel, always the one is chosen that results in the smallest distance.</p><formula xml:id="formula_2" coords="3,122.00,511.13,391.00,31.38">D IDM (Q, R) = height x=0 width y=0 min x ∈[x-w,x+w], y ∈[y-w,y+w] ((Q(x, y) -R(x , y )) 2 + C(x -x , y -y ))<label>(2)</label></formula><p>For means of clarity and generalization, we introduce the more generic model</p><formula xml:id="formula_3" coords="3,217.03,577.63,295.98,30.67">D(Q, R, p) = height x=0 width y=0 p(Q, R, x, y)<label>(3)</label></formula><p>with</p><formula xml:id="formula_4" coords="3,214.50,630.37,298.50,11.72">p euclid (Q, R, x, y) = (Q(x, y) -R(x, y)) 2<label>(4)</label></formula><p>and</p><formula xml:id="formula_5" coords="3,139.50,659.95,373.50,26.20">p IDM (Q, R, x, y) = min x ∈[x-w,x+w], y ∈[y-w,y+w] ((Q(x, y) -R(x , y )) 2 + C(x -x , y -y ))<label>(5)</label></formula><p>as pixel distance computation function. Every pixel distance computation function evaluates the distance<ref type="foot" coords="3,125.48,704.69,3.97,6.12" target="#foot_1">2</ref> of a single pixel (x, y) of the query image with its corresponding pixel in the reference image -and as for the distance function, the resulting values must be out of the interval [0, ∞).  Our experiments showed that it can improve the retrieval quality if the distance that can be achieved by any single pixel is limited by a threshold t. We introduced an intermediate function p pt , that can be applied on any pixel distance computation function:</p><formula xml:id="formula_6" coords="4,184.41,393.26,328.59,24.66">p pt (Q, R, x, y) = p(Q, R, x, y) for p(Q, R, x, y) &lt; t 2 t 2 for p(Q, R, x, y) ≥ t 2<label>(6)</label></formula><p>We use t 2 instead of t here in order to be in line with the square root that will be taken in Equation 3.</p><p>To improve IDM, we need a method that does not only take into account single pixels, but the local context which is defined by an area of pixels around the central pixel that differ in their row and column value by not more than the HMM range h. P2DHMDM computes the average distance between those pixels in the area with the corresponding pixels of the reference image.</p><formula xml:id="formula_7" coords="4,99.96,517.84,413.04,49.78">p P 2DHM DM (Q, R, x, y) = min x ∈[x-w,x+w], y ∈[y-w,y+w] h x=-h h ŷ=-h ((Q(x + x, y + ŷ) -R(x + x, y + ŷ)) 2 + C(x -x , y -y )) (2h + 1) 2<label>(7)</label></formula><p>The distortion model is commonly applied to grayscale images, which may have been scaled down to a common size that is sufficient for the task of finding nearest neighbors for classification. If images differ in size and/or aspect ratio, corresponding pixels need to be identified at the time of comparison. For pixels at the boundary, only deformations are allowed, where pixels remain inside the image boundary. For P2DHMDM the local context of such pixels consists only of the pixels inside the image. For instance at position x = 0, y = 7 with h = 1, the resulting 3x3 area is not entirely inside the image: Only six pixels can be inside the image since a row index of x = -1 is not allowed. In such a case, only the pixels inside the image will be considered and the average distance will get computed accordingly. The entire model may either be applied to the image directly or on the image after it has been processed by a Sobel filter to detect edges. It is also possible to treat both versions of the image as layers of the images and compute the pixel distance on either or both layers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Modifications of Parameters</head><p>In <ref type="bibr" coords="5,101.98,130.41,14.62,8.74" target="#b14">[15]</ref>, images have been scaled to a common height of 32 pixels while preserving the aspect ratio. This means, that images in portrait orientation contain significantly less pixels after scaling than images in landscape orientation. In order to reduce the effect of this with regard of the absolute value of the summed distance over all pixels as defined in Equation <ref type="formula" coords="5,396.96,166.27,3.88,8.74" target="#formula_3">3</ref>, we decided to scale the images to 32 pixels on the longer side.</p><p>The recommended parameters in <ref type="bibr" coords="5,248.50,190.19,15.50,8.74" target="#b9">[10]</ref> are: w ∈ {1, 2}, allowing a deformation in a warp range of 3x3 or 5x5 pixels and a HMM range h = 1, hence using another 3x3 pixel area for the P2DHMDM. For our runs, we used w = 3, therefore allowing displacements in an area of 7x7 pixels which showed better results on the development data set. Notice that we used only IDM with P2DHMDM, which is -even if allowing some deformations-still a local feature, whereas in other approaches might get combined with global features, like Tamura texture features and aspect ratio in <ref type="bibr" coords="5,446.76,249.96,14.62,8.74" target="#b14">[15]</ref>. Therefore the more relaxed displacement rule might be less important when combining IDM with features, that take into account the entire image already. However, also the winning run in 2005 was using IDM alone <ref type="bibr" coords="5,141.32,285.83,9.96,8.74" target="#b6">[7]</ref>, so they also did not combine it with any global feature. We increased also the HMM range to h = 2 for most runs, our best run used h = 3. We applied a cost function with two different sets of parameters, out of which the one with higher costs and therefore higher penalty for displacements achieved slightly better results.</p><p>We used both layers, the one with the gray values of down scaled images directly and one using the Sobel-filtered image. An implementation detail here is, that for generating the second layer, we filtered the original image and scaled this down separately, rather than applying the edge detection on the very small image where one would expect to find more or less only hard edges since areas of pixels of same color are less likely to be found in small images. We did not weight both layers equally; on the training dataset and generated cross validation sets, giving the gray values twice the importance of the Sobel-filtered version achieved better results.</p><p>Finally, we used a kNN classifier that takes not only the class of the nearest neighbors into account, but also weighs the class information based on the distance computed using IDM, with k ∈ {3, 5} and made further use knowledge about the IRMA code. In <ref type="bibr" coords="5,399.31,441.24,14.62,8.74" target="#b9">[10]</ref>, k = 1 has been used. In our experiments, k = 3 performed best, 4 slightly worse. 1 was preferable over 5 if distances were ignored; when the distances were taken into account and the IRMA code was exploited, it outperformed k = 1 in most cases, but couldn't outperform k = 3 with or without exploiting IRMA code.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Algorithmic Optimization</head><p>In the following, we report on the algorithms that have been designed to implement the model introduced in Section 2 in an efficient way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Maximum Sum</head><p>As a matter of fact, only the ordering and distance of the k nearest neighbors will be used in the classification step. Therefore the exact distance of any image with a rank &gt; k is unimportant and can safely be approximated. Since the rank of those images will not be important either, it is sufficient to approximate the distance to ∞. Let d(r) be the exact distance of the image with rank r, then we can rewrite equation 3 to a thresholded function similar to equation 6:</p><formula xml:id="formula_8" coords="5,104.17,672.38,408.83,27.51">D(Q, R, p) = height x=0 width y=0 p(Q, R, x, y) if height x=0 width y=0 p(Q, R, x, y) &lt; d(k) ∞ otherwise<label>(8)</label></formula><p>On first glance, this did not improve the performance yet. But due to the fact that we compute sums of potentially many non-negative values, we can safely abort this computation as soon as the sum we aggregated so far exceeds d(k). Since d(k) can only be known after all images in Distance(Q, R, p) </p><formula xml:id="formula_9" coords="6,94.98,135.70,309.33,23.10">1 sum ← 0 £ initialize to sum to 0 2 maxSum ← d(k) 2 £</formula><formula xml:id="formula_10" coords="6,106.09,371.55,406.91,27.51">D(Q, R, p) = height x=0 width y=0 p(Q, R, x, y) if height x=0 width y=0 p(Q, R, x, y) &lt; d(k) 2 ∞ otherwise<label>(9)</label></formula><p>A simple, yet efficient pseudo-code for this function is presented in figure <ref type="figure" coords="6,431.34,411.53,3.87,8.74">3</ref>.1. In worst case, where k is the size of the entire collection, every image in the collection is so similar that each of them achieves the same distance, or images in the collection are ordered in exactly the reverted order of there similarity with regard to Q, the only overhead generated by this approach is a couple of very cheap comparison and the assignment in line 2. The ordered list of all nearest neighbors seen so far, which is needed to implement d(k) would be required to some extend anyway for computing the final set of kNN. But in common cases, in particular when k is small like k ≤ 5 as for our classifier, this method is likely to terminate early for most of the images.</p><p>Since the algorithm is orthogonal to the used pixel distance computation function, it can be applied to IDM, P2DHMDM as well as the Euclidean distance that might be used in a sieve function. In our own implementation, we tried out also distance functions where there is no need to compute the square root. For our implementation, we did not separate the code of the generic distance function from the pixel distance computation function and therefore implemented this kind of behavior directly in every combined function, which also gave the chance to better use the locality of some variables.</p><p>In order to keep the amount of main memory occupied acceptable, d(k) is also used as a threshold to filter results: Only results with a distance less than d(k) will be kept and added to the list of results in main memory. Details on options how to implement this efficiently are presented in Section 4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Filter-and-Refinement</head><p>The sieve function as described in <ref type="bibr" coords="6,247.74,673.91,15.50,8.74" target="#b14">[15]</ref> is similar to a top operator in some database systems, that performs a simple cutoff at position c of the ascendingly ordered list. Finding a value c that makes a good tradeoff between the reduced running time and the reduced retrieval quality is very important in such a case. It looks appealing, that if the retrieval takes too long, c simply is reduced until retrieval times are acceptable again. Unfortunately, in order to validate if the retrieval quality is still close enough to the potential of the distance measure, it actually requires the full run for comparison.</p><p>We therefore explored possibilities to filter the candidates without any loss of retrieval quality. This is possible using a fiter-and-refinement algorithm using upper and lower bounds as used in <ref type="bibr" coords="7,90.00,135.93,15.50,8.74" target="#b16">[17,</ref><ref type="bibr" coords="7,109.46,135.93,11.63,8.74" target="#b13">14]</ref>. For finding a valid upper bound, we use the fact that our cost function C is designed such that C(0, 0) = 0 -or in other words: If the pixel has not been displaced, there is no penalty for that. Combining this with the minimality constraint in equation 5, one can easily conclude that if p euclid is a variant of p euclid that is using the same the scaling / mapping in case of images that differ in there number of pixel in width and/or hight as p IDM and also all layers with the same weights, then p euclid (Q, R, x, y) ≥ p IDM (Q, R, x, y) holds for every Q, R ∈ I and x ∈ [0, height], y ∈ [0, width] and therefore is a valid upper bound for the distance. For finding a upper bound for p P 2DHM DM with w = 3 as in our experiments, the straight forward choice is to use p P 2DHM DM with w = 0 and therefore also disallowing displacement.</p><p>As a safe lower bound, we can allow displacements all over the image without penalty. This is equal to retrieving the distance to the closest pixel value within the histogram of the reference image. We need only the gray value of such a pixel, therefore we did not compute a full histogram, but simply extracted all gray values that appear at least one time. We store the found gray values in an ordered list, such that binary search can be performed for finding the most similar value to each pixel in the query image. For 8-bit grayscale images, even a simple lookup table can be used to speed up this task. This histogram lookup can be used directly as the lower bound for p IDM ; for a very quick, but not very tight lower bound for p P 2DHM DM , we still need to divide this value by the number of pixels in the area defined by the HMM range h which is (2h + 1) 2 , since all surrounding pixels in this area of the query image might be exactly equal to the corresponding ones of the reference image and there contribution to the sum therefore 0.</p><p>The retrieved candidates are stored in a priority queue which is ordered ascendingly on minimal lower bound distance. For being a candidate, an image needs to achieve a lower bound similarity smaller than the smallest k upper bounds (or exact similarity values) seen so far. Unfortunately, the lower bound turned out to be close to zero for almost any two images, since the number of pixels and the type of images resulted in each gray value being present in almost any image. Therefore the filter stage was not selective enough and the run times did not improve, since basically all exact distances still needed to be computed. In other setups, this approach might achieve better results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Multithreading</head><p>Within the last years, multi-core CPUs became very popular and affordable. Therefore it becomes more and more important to design applications in a way that they can use multiple threads in order to utilize all the capabilities provided by current hardware.</p><p>In image retrieval tasks, there are commonly two distinct tasks that which might be CPUintinsive: a) the feature extraction of entire collections and b) the actual retrieval. For the first one, it is very common to separate this task not among several threads, but frequently also using many nodes in a network as in <ref type="bibr" coords="7,230.49,576.73,14.61,8.74" target="#b17">[18]</ref>. For the task of the actual search, parallel index structures <ref type="bibr" coords="7,90.00,588.68,15.50,8.74" target="#b15">[16]</ref> and the coordination <ref type="bibr" coords="7,205.09,588.68,15.50,8.74" target="#b12">[13]</ref> becomes more important since different execution speeds of parts of the query may limit the overall speed and prohibit in worst case interactive answering times.</p><p>Since communication between threads is much cheaper than the communication over network, we decided to not assign ranges as workloads to individual threads, but individual similarity computations. A dispatcher takes the computed result, updates the d as described in Section 3.1 and assigns the next task to the thread. Though this we could achieve almost linear speedup on multi-core CPUs, since IDM is much more CPU-bound than I/O-bound and accesses to the disk get serialized through the dispatcher and therefore the concurrent execution does not lead to slow concurrent disk accesses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Feature Storage</head><p>In order to keep the I/O costs as low as possible, in particular to avoid random seeks on disk, we store all extracted features in a single file. For the time being, we use the Java object serialization to store the individual feature vectors in this file. The resulting file for all 10'000 feature vectors occupies only about 60 MB for the image scaled down to 32 pixels on the longer side together with the Sobel-filtered version. Since this is not much comparing state-of-the-art hard disks with several Gigabytes up to Terabyte storage capacity, we generated separate files in case we want to use either just the gray values without the Sobel-filtered version or the other way round.</p><p>Notice that we use p euclid in case of sieve function or the filter-and-refinement algorithm presented in Section 3.2 and can use for this the same feature vectors as for IDM with or without P2DHMDM. This is possible since we adapted the Euclidean distance to perform the same scaling and therefore we i.) get better approximations since the filter uses a closer bound, ii.) do not need to store separate feature vectors for the 32x32 representation of images. The situation could be slightly different if we employed more features and corresponding distance functions. But even then it might be beneficial to perform a feature fusion on-the-fly to aggregate all features used in a multi-feature single-object query in main memory <ref type="bibr" coords="8,318.72,321.60,9.97,8.74" target="#b1">[2]</ref>.</p><p>The feature file gets sequentially read, either for each query performed or just a single time and then remains cached entirely in memory. This is easily possible for the current collection since 60 MB are not much compared to the RAM that current computers are equipped with. In any case, in order to reduce subsequent needs to re-read the features or meta-information about an image file during the execution of a query, we keep the entire feature vector in memory as long as the image remains a valid candidate of being among the k nearest neighbors. By this, we only need to keep and pass references rather than copying bytes in memory and can make excellent use of Java's garbage collection.</p><p>More sophisticated index structures like the VA-File <ref type="bibr" coords="8,337.41,429.19,14.62,8.74" target="#b18">[19]</ref>, M-Tree <ref type="bibr" coords="8,394.20,429.19,9.97,8.74" target="#b3">[4]</ref>, or R*-Tree <ref type="bibr" coords="8,461.53,429.19,10.52,8.74" target="#b0">[1]</ref> have not been used for several reasons: First of all, the dimensionality of the feature vectors is high (2 layers with up to 32 x 32 pixels = 2048 dimensions) and worse, are of variable length. Second, neither IDM, P2DHMDM, nor the modified Euclidean distance are metrics. This is due to the preservation of the aspect ratio, that results in varying width and height and therefore the feature vector length of each image may differ. Since the query image is determining the number of pixels used for distance computation, the symmetry condition D(X, Y ) = D(Y, X) does not hold for any of these distance functions. For similar reason, the triangle inequation D(X, Z) ≤ D(X, Y ) + D(Y, Z) may not be satisfied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Bounded Priority Queue</head><p>Most of the improvements achieved in Section 3 are based on the fact, that we can easily and inexpensively find or refer at any time to the k minimal distances that have been computed for this query up to this moment. This means that we need some ordering of distance scores. We also need an ordering of candidate images in a different context, but this has in detail two different requirements.</p><p>First, we need a priority queue to get the best candidate in the filter-and-refinement algorithm as presented in Section 3.2 and also to perform the sieve function more efficiently. In both cases, we add many (potentially all) images of the search collection to the queue, but intent to take out only a small fraction (the cutoff value c in case of the sieve function) from the top. We therefore do not have to entirely sort the queue. Sun provides in Java version 1.5 a very decent implementation of a priority queue based on a heap. But in addition, since we are only interested in keeping good candidates in the list, it would be ideal to be able to remove previously inserted items and thus reduce memory requirements and also speed up other operations that modify the priority queue. We are not interested which items get removed, as long as we do not accidentally remove one that would become one of the k nearest neighbors. For selecting victims for deletion, we can apply again the bound d(k) defined for computing the maximum sum in Section 3.1. Of course, such deletion should be cheap, because otherwise it would slow down the organization of the priority queue more than it improves it. We therefore used a binary minimum heap implementation of our own. Due to the heap property it is possible to delete any leaf node without violating the heap property and therefore can perform this efficiently. The binary heap is further organized such that it is either perfectly balanced or if the last level of the tree is not filled entirely, it is always filled from left to right. We implemented a fast yet simple heuristic in which, before each new insertion, we check if the right-most leave node still is better than d(k). If not, we will delete it and continue deleting until we find a better leaf node. We will place the new entry to the right of the this item. Of course, we will start this insertion only, if the new item is better than d(k). Although this does cannot guarantee that the heap is free of "bad candidates", it may reduce significantly the number of entries -depending on the value of d(k).</p><p>As a second requirement, in order to determine and maintain d(k) efficiently, we need a sorted list of a fixed size to which we can add new distance scores. In case the list is already full, the data structure does not need to grow, but simply drop the worst value and insert the new value at the appropriate position. This data structure is used to get the value that a distance may not exceed in order to become a candidate. It is checked frequently, in particular to decide whether an item should be added to the priority queue described in the first requirement. Therefore we actually need a list of the best values so far, hence a list of ascending distances, but need to be able to retrieve worst score very efficiently -not the best value as it is the property of priority queues. Common priority queues provide very efficient access to the best value, but less efficient or even no direct access to all other values. So we rather need a fully sorted data structure. In addition, we need the ability to store duplicate values since two different nearest neighbors may have exactly the same distance and -in contrast to range queries-the number of items is very important for nearest neighbors searches. These properties together cannot be easily met with e.g., SortedSet out of the Java Class Library or FixedSizeList of Jakarta Commons Collections. Therefore, we implemented our own data structure. This list is fixed in size and backed by a simple float array. Insertion points can be identified by a simple binary search and shifting of huge parts of the list in case of insertion close to the head can be performed by comparably cheap system calls.</p><p>For the filter-and-refinement algorithm, we need these two requirements at the same time, but on different lists -one priority queue for the images based on their lower bound distances and the sorted list of upper bound (or exact) distances. But for the sieve function as well as a plain sequential scan, those two requirements are actually always applied to the same elements. Therefore we extended the concept of the sorted list of fixed size to also act as a "priority list", which is bounded in size and automatically drops all elements with ranks greater than the fixed size. With this, we were able to reduce the minimal memory requirement to k elements in case of a plain sequential scan and k + c elements for the sieve function. <ref type="foot" coords="9,370.35,541.91,3.97,6.12" target="#foot_2">3</ref> The deletion heuristics to limit the size of a priority heap sketched above is no longer required here, since the work to erase "bad candidates" is performed already to be able to determine d(k).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">IRMA-Code-aware Classifier</head><p>Since the goal of this task is the automatic annotation of medical images by assigning them classes, the step following the generic retrieval is the classification. For this, we started with a weighted kNN classifier that uses the inverse square of the distance <ref type="bibr" coords="9,345.09,646.07,9.97,8.74" target="#b7">[8]</ref>. Let l be the ordered list of nearest neighbors and dl(l, i) be the distance of the i-th nearest neighbor in the list and cl(l, i) the class, respectively. For each class a ∈ l we compute the score s:</p><formula xml:id="formula_11" coords="9,224.15,690.76,288.85,30.32">s(a, l) = k i=0 1 dl(l,i) 2 if cl(l, i) = a 0 if cl(l, i) = a<label>(10)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Testing Infrastructure</head><p>For our experiments, we used a couple of machines in order to be able to verify the expected performance improvements on different CPUs and operating systems. The used machines are listed in Figure <ref type="figure" coords="11,159.68,178.13,3.88,8.74">4</ref>. Due to time limitations, not all experiments could be performed on all machines. P4 has a single 32-bit processor, the other machines have multiple CPUs / cores, and therefore require multiple threads to fully utilize all CPUs. The number of parallel threads used in an experiment are written behind the used machine as an exponent, e.g. Xeon 8 means that 8 worker threads were used -in this case this would use all 8 CPUs, whereas Xeon 16  HT would fully use all CPUs in case HyperThreading is enabled, for which each CPU appears to the OS as two separate ones. The Core 2 Duo processors is a 64-bit architecture, therefore a 64-bit software environment (OS, Java) has been installed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>P4</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Submitted Runs</head><p>For the runs submitted, we used an image distortion model with a warp range of w = 3 and two different cost matrices, 4812 and 369, where the one assigning higher costs (4812) performed a little better when using only a 5x5 pixel area (h = 2) in the P2DHMDM. For h = 3 we submitted only a single run using the 369 matrix -which turned out to be the best of our runs. A "c" appended to the number of k nearest neighbors indicates that the IRMA-code aware classifier shown in Equation <ref type="formula" coords="11,175.79,521.45,9.96,8.74">11</ref>was used with a threshold of 1.0 on the normalized distance and that the two nearest neighbors will be used to generate the code. We used a per-pixel threshold of t = 96 in Equation 6 in all cases. As mentioned in Section 5, whenever there were a couple of runs that differ only in the in the used classifier, we performed the nearest neighbor search only once with the biggest k and passed the result to all appropriate classifiers. This is the reason why several runs took exactly the same time -even when k was different.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rank</head><p>Run id -UNIBAS-DBIS-.  Features were cached in main memory, execution time is for the entire run on 1'000 images. Each image has been processed one after another by first extracting the features of the image, then performing the nearest neighbor search and finally wait until all classifiers (if more than one) have finished. We did not apply further optimizations for the throughput of the entire run, e.g. extracting the features of the next image while the classifier for the last image is still running. Therefore one can simply divide the runtime of the entire run by 1'000 to get the average execution time per query. This means for h = 2, a single query took on average less than 8.6 seconds with HyperThreading enabled, less than 9.5 seconds without HyperThreading, and 13.3 seconds when h = 3. For comparison: Our best run with w = 3 and h = 3 took 16h 18m on Xeon 16  HT when no early termination based on the maximum sum and no checking on insertion to the priority queue was used. This long duration even increased to entire 5 days, 17h and 32m on the same machine when we limited the number of used threads to a single one -as it was the case in our starting point of the implementation. This means that our optimizations achieved a speedup of 4.42 and 37.34, respectively.</p><p>We also performed runs with the parameters proposed in <ref type="bibr" coords="12,354.78,279.39,14.62,8.74" target="#b9">[10]</ref>: IDM with a deformation in 5x5 pixels (w = 2) and a P2DHMDM of a local context of 3x3 pixels (h = 1) and the nearest neighbor decision rule (k = 1). On the standard Pentium 4 PC, this run finished within 4 hours and 28 minutes (16.0 seconds per query) -without any sieve function. The same run was finished on the 64-bit Core 2 Duo machine in 1 hour and 11 minutes (4.2 seconds per query) and on the 8-way Xeon 16  HT with HyperThreading enabled within 24 minutes and 45 seconds (1.5 seconds per query). When we turned off just the early termination, the durations increased to 19 hours 21 minutes on P4 (69.77 seconds per query, factor 4.33), 4 hours 14 minutes on C2D (15.0 seconds per query, factor 3.58), and 1 hour 59 minutes on Xeon 16 HT (7.1 seconds per query, factor 4.86).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Short summary of other experiments</head><p>• More experiments need to be performed to verify the benefit o the IRMA-code aware classifier. The official runs did not achieve the same clear picture as we would have expected from the results on the development set.</p><p>• Filter-and-refinement could be implemented, but did not improve the speed because the lower bound was not tight enough.</p><p>• The sieve function as proposed in <ref type="bibr" coords="12,264.20,493.50,15.50,8.74" target="#b14">[15]</ref> can also reduce the execution times significantly, but only at the cost of loss of retrieval quality. In our experiements, the loss was smaller if the Euclidean distance has been replaced by the Manhattan distance. The Manhattan distance as a pixel distance computation function is p manhattan (Q, R, x, y) = |Q(x, y) -R(x, y)|, but requires that D(Q, R, p) may not take the square root of the sum if p = p manhattan .</p><p>• We could speedup also the sieve function. Since the cutoff position c = 500 is much bigger than k ∈ 1, 3, 5, the early termination strategy could not achieve a speedup of approximately 4, but at least more than half of the pixel distance computations could be omitted. The more computationally intensive part occurs after the sieve function performed the cutoffand here the smaller k is used to compute the exact distance out of the c candidates. Also for this stage the early termination strategy paid off.</p><p>• Not caching the entire feature file in memory results in additional work to (re-)read sequentially 60 MB of features for each query. The required time for this depends heavily on the hard disk I/O speed of the system and varied in our case between ≤ 1 second on the server hardware and 2 to at most 5 seconds for the old hard disk of the standard PC. Iterating over the feature vectors is integrated in the retrieval process. How much this slows down the query execution depends on the complexity of the distance measure. For features that are fast to compute like the Euclidean distance, the I/O speed determines the overall performance. For P2DHMDM, the overhead is rather small, e.g. on C2D 2 , the additional time spend for reading the features from disk for an entire run of 1'000 was only about 2.5 -5 minutes.</p><p>In this paper, we propose an early termination strategy, which has proven to successfully speed up the expensive Image Distortion Model with Pseudo-2D Hidden Markov Distorion Model by factors in the range of 3.5 to 4.9 in our experiments. Using appropriate data structures for storing intermediate sets of candidates and ordered lists of best distances achieved so far, we could reduce the computation time to perform a single query in the collection with 10'000 reference images to approximately 16 seconds on a standard Pentium 4 PC. Making proper use of multithreading, we could even perform a single query within 1.5 seconds on a 8-way Xeon MP server. This improved speed opened enough resources, to allow for local displacements of IDM in an area of 7x7 pixels instead of 5x5 and also increase local context of the HMM range from a 3x3 area to 5x5 or 7x7. Even with these parameters that cause significantly more computations, we could perform this on the Xeon server in maximum 13.3 seconds per query.</p><p>By this we were able to achieve rank 19 -25 among 68 runs that have been submitted to the Medical Automatic Annotation Task of ImageCLEF 2007. Further experiments shall provide an in-depth analysis of the applied optimizations. So far, some parameters like the cost function and the chosen classifier have been set manually. IDM suffered until now from the lack of support for setting those values automatically by means of machine learning and automated verification through cross-validation since the runtimes were simply too long. With our optimizations we expect to be able to perform those within a reasonable time.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,199.74,314.65,203.51,8.74"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overview of frequently used symbols</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="11,203.98,718.07,195.04,8.74"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Execution times of performed runs</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,105.24,736.80,407.76,7.91"><p>FIRE -Flexible Image Retrieval Engine, http://www-i6.informatik.rwth-aachen.de/ ∼ deselaers/fire.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,105.24,747.00,362.14,6.99"><p>Actually, this does not return the distance value since the square root still needs to be computed.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="9,105.24,730.91,407.75,6.99;9,90.00,740.38,240.44,6.99"><p>For the sieve function, we need to store in addition to the result also temporarily the top-c results of the less expensive distance used for filtering in a separate data structure.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>Part of the implementation are based on the work performed by <rs type="person">Andreas Dander</rs> for his BSc project at <rs type="institution">UMIT, Hall i.T., Austria</rs>. Based on his idea we tried out the Manhatten distance instead of Euclidean distance in the sieve function, which performed significantly better in all our experiments. He also adapted the Filter-and-Refinement Algorithm for the use in this context.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The IRMA code is hierarchical and uncertainty / a "don't know" character is allowed at any level in the hierarchy in submission. Therefore it can be better to express uncertainty at some level which will receive an error of 0.5 at this level rather then submitting a false guess, which will receive an error of 1.0. We implemented a function scode(l) that given a set of classes generates the code containing the "don't know" symbol * at any position the codes of the classes differ. Example as shown in Fig. <ref type="figure" coords="10,207.09,384.82,3.88,8.74">3</ref>: Image number 372250 (Fig. <ref type="figure" coords="10,344.15,384.82,4.32,8.74">3</ref> Using only scode(l) will frequently result in codes with high uncertainty, even if the kN N (l) would give very good guesses. This is particularly true for big k. So we limit scode(l, i) to use only the i nearest neighbors for generating the IRMA code, with i = 2 being the best choice we found so far. As a rule of thumb, kN N (l) gives good results if the nearest neighbors are close enough to the query image. As pointed out in Section 4.1, P2DHMDM is not symmetric, because its values depend on the number of pixels in the query image. This makes it harder to determine when the nearest neighbors are close enough to rely on kN N (l). As a simple way to normalize the distance, we divided it by the number of pixels of the query image. In experiments we tried several values as thresholds and it turned out that the best value would be around 1. So we came up with the following classifier:</p><p>width * height &lt; 1.0 scode(l, 2) otherwise <ref type="bibr" coords="10,495.29,606.43,17.71,8.74" target="#b10">(11)</ref> In order to directly compare many classifiers using different parameter sets, we wrote a small program to perform the nearest neighbor search with the biggest k required by any of the classifiers and then feeding all of them with only the number of top-k results that are needed for the classifier. By this, we avoided to repeat the costly nearest neighbor search for each classifier individually.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="13,110.48,482.48,402.52,8.74;13,110.48,494.43,402.52,8.74;13,110.48,506.39,402.52,8.74;13,110.48,518.34,175.48,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,460.54,482.48,52.45,8.74;13,110.48,494.43,268.30,8.74">The r*-tree: an efficient and robust access method for points and rectangles</title>
		<author>
			<persName coords=""><forename type="first">Norbert</forename><surname>Beckmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hans-Peter</forename><surname>Kriegel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ralf</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bernhard</forename><surname>Seeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,398.41,494.43,114.59,8.74;13,110.48,506.39,330.78,8.74">SIGMOD &apos;90: Proceedings of the 1990 ACM SIGMOD international conference on Management of data</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1990">1990</date>
			<biblScope unit="page" from="322" to="331" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,110.48,538.27,402.53,8.74;13,110.48,550.22,322.38,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,445.34,538.27,67.67,8.74;13,110.48,550.22,176.29,8.74">Fast evaluation techniques for complex similarity queries</title>
		<author>
			<persName coords=""><forename type="first">Klemens</forename><surname>Böhm</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Mlivoncic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hans-Jörg</forename><surname>Schek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Roger</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,307.76,550.22,24.77,8.74">VLDB</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="211" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,110.48,570.15,402.52,8.74;13,110.48,582.10,402.52,8.74;13,110.48,594.06,249.78,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,110.48,582.10,402.52,8.74;13,110.48,594.06,47.58,8.74">Isis &amp; osiris: a process-based digital library application on top of a distributed process support middleware</title>
		<author>
			<persName coords=""><forename type="first">Gert</forename><surname>Brettlecker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paola</forename><surname>Ranaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hans-Jörg</forename><surname>Schek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Heiko</forename><surname>Schuldt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Springmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,179.68,594.06,107.40,8.74">DELOS Conference 2007</title>
		<imprint>
			<date type="published" when="2007-02">February 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,110.48,613.98,402.53,8.74;13,110.48,625.94,289.23,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,337.56,613.98,175.45,8.74;13,110.48,625.94,142.97,8.74">M-tree: An efficient access method for similarity search in metric spaces</title>
		<author>
			<persName coords=""><forename type="first">Paolo</forename><surname>Ciaccia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marco</forename><surname>Patella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pavel</forename><surname>Zezula</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,274.60,625.94,24.77,8.74">VLDB</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="426" to="435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,110.48,645.87,402.52,8.74;13,110.48,657.82,336.72,8.74" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="13,110.48,657.82,306.17,8.74">Hierarchical classification for imageclef 2007 medical image annotation</title>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jayashree</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">M</forename><surname>Deserno</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,110.48,677.75,402.52,8.74;13,110.48,689.70,402.52,8.74;13,110.48,701.66,148.17,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="13,110.48,689.70,241.69,8.74">The clef 2005 automatic medical image annotation task</title>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clogh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">M</forename><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,360.99,689.70,152.01,8.74;13,110.48,701.66,26.62,8.74">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="58" />
			<date type="published" when="2007-08">August 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,110.48,721.58,402.52,8.74;13,110.48,733.54,402.53,8.74;13,110.48,745.49,178.95,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,110.48,733.54,402.53,8.74;13,110.48,745.49,34.67,8.74">Fire in imageclef 2005: Combining content-based image retrieval with textual information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tobias</forename><surname>Weyand</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wolfgang</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,165.87,745.49,23.53,8.74">CLEF</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="652" to="661" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,110.48,112.02,398.19,8.74" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="14,252.93,112.02,148.84,8.74">Knowledge Discovery in Databases</title>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Esters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jörg</forename><surname>Sander</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,110.48,131.95,402.53,8.74;14,110.48,143.90,59.00,8.74" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="14,261.76,131.95,251.25,8.74;14,110.48,143.90,28.27,8.74">Classification of medical images using non-linear distortion models</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gollan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,110.48,163.83,402.52,8.74;14,110.48,175.78,402.52,8.74;14,110.48,187.74,133.73,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="14,425.69,163.83,87.31,8.74;14,110.48,175.78,93.11,8.74">Deformation models for image recognition</title>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christian</forename><surname>Gollan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,215.78,175.78,293.21,8.74">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1422" to="1435" />
			<date type="published" when="2007-08">August 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,110.48,207.66,402.53,8.74;14,110.48,219.62,402.52,8.74;14,110.48,231.57,143.50,8.74" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="14,367.50,207.66,145.50,8.74;14,110.48,219.62,220.78,8.74">Hyperdatabase infrastructure for management and search of multimedia collections</title>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Mlivoncic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christoph</forename><surname>Schuler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Can</forename><surname>Türker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,356.42,219.62,156.58,8.74;14,110.48,231.57,55.08,8.74">DELOS Workshop: Digital Library Architectures</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="25" to="36" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,110.48,251.50,402.52,8.74;14,110.48,263.45,402.52,8.74;14,110.48,275.41,402.52,8.74;14,110.48,287.36,402.53,8.74;14,110.48,299.32,402.52,8.74;14,110.48,311.27,63.65,8.74" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="14,110.48,263.45,333.08,8.74">Overview of the imageclefmed 2006 medical retrieval and annotation tasks</title>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,146.47,287.36,366.53,8.74;14,110.48,299.32,204.15,8.74">Evaluation of Multilingual and Multi-modal Information Retrieval -Seventh Workshop of the Cross-Language Evaluation Forum</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Gey</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Karlgren</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Magnini</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Stempfhuber</surname></persName>
		</editor>
		<meeting><address><addrLine>CLEF</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006. 2007</date>
			<biblScope unit="volume">4730</biblScope>
			<biblScope unit="page" from="595" to="608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,110.48,331.20,402.53,8.74;14,110.48,343.15,335.03,8.74" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="14,270.03,331.20,224.85,8.74">Higher order databases and multimedia information</title>
		<author>
			<persName coords=""><forename type="first">Hans-Jörg</forename><surname>Schek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Roger</forename><surname>Weber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,110.48,343.15,261.80,8.74">Swiss/Japan Seminar Advances in Database and Multimedia</title>
		<imprint>
			<date type="published" when="2000-02">February 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,110.48,363.08,402.53,8.74;14,110.48,375.03,300.03,8.74" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="14,209.10,363.08,229.83,8.74">A novel approach for compound document matching</title>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Springmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,449.42,363.08,63.58,8.74;14,110.48,375.03,244.65,8.74">Bulletin of the IEEE Technical Committee on Digital Libraries (TCDL)</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,110.48,394.96,402.52,8.74;14,110.48,406.91,402.52,8.74;14,110.48,418.87,402.53,8.74;14,110.48,430.82,402.52,8.74;14,110.48,442.78,402.53,8.74" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="14,474.81,394.96,38.19,8.74;14,110.48,406.91,354.89,8.74">Contentbased queries on the casimage database within the irma framework: A field report</title>
		<author>
			<persName coords=""><forename type="first">Christian</forename><surname>Thies</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Oliver Güld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benedikt</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">M</forename><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,461.04,418.87,51.96,8.74;14,110.48,430.82,402.52,8.74;14,110.48,442.78,56.67,8.74">Multilingual Information Access for Text, Speech and Images: 5th Workshop of the Cross-Language Evaluation Forum</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Kuck</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Magnini</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="volume">3491</biblScope>
			<biblScope unit="page" from="781" to="792" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,110.48,462.70,402.53,8.74;14,110.48,474.66,310.51,8.74" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="14,351.76,462.70,161.24,8.74;14,110.48,474.66,191.72,8.74">Interactive-time similarity search for large image collections using parallel va-files</title>
		<author>
			<persName coords=""><forename type="first">Roger</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Klemens</forename><surname>Böhm</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hans-Jörg</forename><surname>Schek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,322.67,474.66,22.42,8.74">ICDE</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page">197</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,110.48,494.59,402.53,8.74;14,110.48,506.54,402.52,8.74;14,110.48,518.50,164.49,8.74" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="14,280.11,494.59,161.96,8.74">Efficient region-based image retrieval</title>
		<author>
			<persName coords=""><forename type="first">Roger</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Mlivoncic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,465.06,494.59,47.95,8.74;14,110.48,506.54,402.52,8.74;14,110.48,518.50,19.53,8.74">CIKM &apos;03: Proceedings of the twelfth International Conference on Information and Knowledge Management</title>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="69" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,110.48,538.42,402.52,8.74;14,110.48,550.38,345.25,8.74" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="14,273.97,538.42,239.03,8.74;14,110.48,550.38,95.09,8.74">A distributed image-database architecture for efficient insertion and retrieval</title>
		<author>
			<persName coords=""><forename type="first">Roger</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hans-Jörg</forename><surname>Schek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,226.28,550.38,140.59,8.74">Multimedia Information Systems</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="48" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,110.48,570.30,402.52,8.74;14,110.48,582.26,402.52,8.74;14,110.48,594.21,315.17,8.74" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="14,337.01,570.30,175.99,8.74;14,110.48,582.26,271.89,8.74">A quantitative analysis and performance study for similarity-search methods in high-dimensional spaces</title>
		<author>
			<persName coords=""><forename type="first">Roger</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hans-Jörg</forename><surname>Schek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Blott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,403.56,582.26,109.44,8.74;14,110.48,594.21,243.54,8.74">VLDB&apos;98, Proceedings of 24rd International Conference on Very Large Data Bases</title>
		<imprint>
			<biblScope unit="page" from="194" to="205" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,428.35,594.21,84.65,8.74;14,110.48,606.17,22.69,8.74" xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Morgan</forename><surname>Kaufmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
