<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,93.84,148.63,415.60,15.51;1,233.76,170.59,135.66,15.51">Content-based Image Retrieval Using Shape-Size Pattern Spectra</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,196.32,203.97,76.79,9.96"><forename type="first">Florence</forename><surname>Tushabe</surname></persName>
							<email>florence@cs.rug.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Groningen</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,295.81,203.97,111.04,9.96"><forename type="first">Michael</forename><forename type="middle">H F</forename><surname>Wilkinson</surname></persName>
							<email>m.h.f.wilkinson@cs.rug.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Groningen</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,93.84,148.63,415.60,15.51;1,233.76,170.59,135.66,15.51">Content-based Image Retrieval Using Shape-Size Pattern Spectra</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6BB5F2F8CCB904B7050BB34577409A64</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>I.5 [Pattern Recognition]: I.5.3 Clustering-Similarity Measures</term>
					<term>G.2 [Discrete Mathematics]: G.2.2 Graph Theory Measurement, Performance, Experimentation Max-tree, pattern spectrum, shape-size pattern spectra, granulometry, attribute filtering, shape representation, IAPR TC-12</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the results of using the shape, size and color features of an image for content-based image retrieval. The use of granulometries has been applied to model the size and shape of the connected components of the image. Granulometry are computed by successively sieving an image using filters of increasing size parameter so that information can be obtained about the components that filter through. A shape-size granulometry using sieves of increasing shape and sizeparameters represents the shape and size distributions of an image. The results of granulometry are stored in a 2-D pattern spectrum that is implemented using attribute thinnings and openings. Additionally, the pattern spectra is extracted from the red, green and blue color bands of the images, concatenated and compared using the L1 Norm and the Jensen-Shannon divergence (JSD). Our results show that incorporating color information improves the performance by 23% and L1 Norm outperforms JSD by 20%.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The most recent advances in image retrieval show that text-based methods still outperform content-based ones by approximately 30% <ref type="bibr" coords="1,275.17,646.77,9.91,9.96" target="#b2">[3]</ref>. Yet the question: " What sentence can describe an image" is still being researched by linguists, computer scientists and other academicians. This is because different people will describe an image quite differently, depending on their interests and prior knowledge. Some users look at an image in terms of the shape of its components, others the size, color, texture, orientation or spatial location etcetera . In theory, using the features of an image as its signature presents the users with a precise and focussed way of describing an image according to their interests. User satisfaction is enhanced when one is presented with a variety of ways to define his need. This is because the retrieval engine is customised according to the selected choice / requirement. This study retrieves images based upon the shape of its components by using mathematical morphology techniques. Attribute filtering is used to identify subsets of the image that satisfy the requirements of a particular property or attribute. Forexample, attributes like moments and length (or width / volume) are useful for spatial and size information respectively <ref type="bibr" coords="2,118.32,147.21,14.60,9.96" target="#b9">[10]</ref>. The selected components are then used for further analysis like the formation of a pattern spectrum. Pattern spectrum has been used to obtain information about the contents and distribution of an image including it's spatial location <ref type="bibr" coords="2,330.54,171.09,15.43,9.96" target="#b9">[10,</ref><ref type="bibr" coords="2,349.56,171.09,7.81,9.96" target="#b8">9,</ref><ref type="bibr" coords="2,360.96,171.09,7.05,9.96" target="#b4">5]</ref>. We present the results of using pattern spectra for content-based image retrieval in large-scale databases. It is an extension of the method proposed by Urbach et al <ref type="bibr" coords="2,255.50,195.09,10.45,9.96" target="#b7">[8]</ref> but combined with color information and applied within the image retrieval context. The objective was to identify the 1000 most similar images from the 20,000 IAPR TC-12 database by using a purely visual, fully automated modality <ref type="bibr" coords="2,446.64,218.97,10.00,9.96" target="#b1">[2]</ref>.</p><p>Section 2 briefly describes the theory of our method, the experiments and results are contained in Section 3 and 4 and Section 5 has the concluding remarks and on-going work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">2-D Shape-Size Pattern Spectra</head><p>Pattern spectrum is a quantitative description of the contents of an image after the application of a granulometric operation <ref type="bibr" coords="2,222.62,309.57,9.91,9.96" target="#b4">[5]</ref>. Granulometry is when an image is successively sieved using filters of increasing diameters, r, so that information can be obtained about its components that satisfy the properties of r. A size granulometry obtains the size distribution of an image by using sieves of increasing sizes herein represented by area. Let X , Y represent an image then the size granulometry (Γ r ) is a set of filters {Γ r } with r from some totally ordered set Λ (usually Λ ⊂ R or Z ) satisfying the properties:</p><formula xml:id="formula_0" coords="2,276.60,381.33,236.44,10.26">Γ r (X) ⊆ X<label>(1)</label></formula><formula xml:id="formula_1" coords="2,245.04,399.21,268.00,10.26">X ⊆ Y ⇒ Γ r (X) ⊆ Γ r (Y )<label>(2)</label></formula><formula xml:id="formula_2" coords="2,243.00,417.21,270.03,10.62">Γ s (Γ r (X)) = Γ max(r,s) (X),<label>(3)</label></formula><p>for all r, s ∈ Λ. Equations (1),( <ref type="formula" coords="2,240.86,435.09,4.03,9.96" target="#formula_1">2</ref>) and (3) define Γ r as being anti-extensive, increasing and idempotent respectively. Attribute openings are size granulometries since they share the same properties <ref type="bibr" coords="2,138.00,458.97,10.45,9.96" target="#b0">[1,</ref><ref type="bibr" coords="2,152.89,458.97,11.62,9.96" target="#b9">10]</ref>. The pattern spectrum, s Γ (X), obtained by applying the size granulometry, {Γτ }, to a binary image X is defined by <ref type="bibr" coords="2,268.81,470.97,10.57,9.96" target="#b4">[5]</ref> as:</p><formula xml:id="formula_3" coords="2,231.12,491.61,281.92,25.50">(s Γ (X))(u) = - dA(Γ r (X)) dr r=u<label>(4)</label></formula><p>where A(X) is the area of X.</p><p>Similarly, shape granulometry filters image contents using sieves of different shapes <ref type="bibr" coords="2,452.98,534.69,10.57,9.96" target="#b7">[8,</ref><ref type="bibr" coords="2,466.55,534.69,7.05,9.96" target="#b8">9]</ref>. Urbach and Wilkinson <ref type="bibr" coords="2,159.26,546.69,10.57,9.96" target="#b8">[9]</ref> defined shape granulometry, of X, as a family of filters, {Φ r }, with shape parameter, r, from some totally ordered set Λ (usually Λ ⊂ R or Z) with the following properties:</p><formula xml:id="formula_4" coords="2,257.64,582.57,255.40,28.14">Φ r (X) ⊆ X (5) Φ r (tX) = t(Φ r (X)),<label>(6)</label></formula><p>in which tC stands for a scaling of set C by a factor t, and,</p><formula xml:id="formula_5" coords="2,241.56,640.29,271.48,10.62">Φ s (Φ r (X)) = Φ max(r,s) (X),<label>(7)</label></formula><p>for all r, s ∈ Λ and t &gt; 0. Equations ( <ref type="formula" coords="2,261.69,662.25,4.03,9.96">5</ref>),( <ref type="formula" coords="2,277.82,662.25,4.03,9.96" target="#formula_4">6</ref>) and ( <ref type="formula" coords="2,313.88,662.25,4.25,9.96" target="#formula_5">7</ref>) define Φ r as anti-extensive, scale invariant and idempotent respectively. Therefore, attribute thinnings are shape granulometries since they share the same properties including the non-increasing criterion <ref type="bibr" coords="2,366.14,686.13,11.52,9.96" target="#b7">[8]</ref>. The shape pattern spectrum, s Φ (X), is obtained by applying the shape granulometry, {Φτ }, to a binary image X and defined as <ref type="bibr" coords="2,102.24,710.13,10.00,9.96" target="#b7">[8]</ref>:</p><formula xml:id="formula_6" coords="2,230.28,730.77,278.50,25.50">(s Φ (X))(u) = - dA(Φ r (X)) dr r=u (<label>8</label></formula><formula xml:id="formula_7" coords="2,508.78,737.49,4.25,9.96">) P 0 3 P 0 2 P 1 3 P 1 1 P 0 1 P 0 0 2, 4 3, 1 2, 3 2, 5 8, 2 13, 1 C 0 3 c C 0 2 d d C 1 3 ¡ ¡ ¡ ¡ C 0 1 d d C 1 1 © C 0 0 3 8 2 2 4 peak components node members max-Tree 2-D spectrum Figure 1: Peak components(P k h ), corresponding (C k h )</formula><p>, the resultant max-tree and the corresponding pattern spectrum (right) as above. In our case we use a shape granulometry based on the ratio I(C)/A 2 (C), with I(C) the moment of inertia of C. This shape parameter is equivalent to Hu's first moment invariant <ref type="bibr" coords="3,499.69,291.57,10.00,9.96" target="#b7">[8]</ref>. The final feature vector resulting from the combination of size and shape granulometries formed the 2-D shape-size pattern spectrum as a shape descriptor that we used. Further details about this are found in <ref type="bibr" coords="3,165.63,327.45,10.00,9.96" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.0.1">Computing the shape-size pattern spectra</head><p>The same method as was used in <ref type="bibr" coords="3,234.94,371.73,10.45,9.96" target="#b7">[8]</ref> has been adopted for application within CBIR. The max-tree approach <ref type="bibr" coords="3,133.57,383.73,10.45,9.96" target="#b5">[6,</ref><ref type="bibr" coords="3,147.98,383.73,7.81,9.96" target="#b6">7]</ref> was used to implement the attribute thinnings and openings in grey-scale. The subsets (connected components) of the image are arranged into a tree structure and filtered by removing the nodes which do not satisfy a given criterion. A max tree is a rooted tree in which each of its nodes, C k h , at gray-level h corresponds to a peak component, P k h <ref type="bibr" coords="3,430.44,419.49,9.91,9.96" target="#b5">[6]</ref>. An example is shown in Figure <ref type="figure" coords="3,163.58,431.49,4.98,9.96">1</ref> which illustrates the peak components, P k h , of a 1-D signal, the corresponding C k h at levels h = 0, 1, 2, 3, the resultant max-tree and corresponding spectrum. Let {Γ r } be a size distribution with r from some finite set Λ r and {Φ s } a shape distribution with s from some index set Λ s . If S is the 2-D array that stores the final 2-D spectrum, then each cell, S(r, s), contains the sum of gray levels of C k h that falls within size class r-and r and shape class s-and s. The 2-D pattern spectrum is then computed from the max-tree as follows:</p><p>• Set all elements of the array S to zero.</p><p>• Compute the max-tree according to the algorithm in <ref type="bibr" coords="3,348.25,531.09,10.00,9.96" target="#b6">[7]</ref>.</p><p>• As the max-tree is built, compute the area A(P k h ) and moment of inertia I(P k h ) of each node. • For each node C k h : -Compute the size class r from the area A(P k h ); -Compute the shape class s from I(P k h ) / A 2 (P k h ); -Compute the gray level difference δ h , between the current node and its parent; -Add the product of δ h and A(P k h ) to S(r, s).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>The objective of our experiments was: given a sample image, find as many relevant images as possible from the IAPR TC-12 photographic collection <ref type="bibr" coords="3,330.50,705.45,9.91,9.96" target="#b2">[3]</ref>. The procedure that was undertaken is as follows: Images are first pre-processed by filtering off all components whose area is less than 30% of the total image size. This was after comparisons with other size ranges indicated that the discriminative power lies in the large particles. Figure <ref type="figure" coords="4,362.54,335.37,4.98,9.96" target="#fig_0">2</ref> illustrates detailed MAP results after using different class sizes. It is observed that the smaller particles performed poorer than the larger ones and that using all particles without any filtering performs worse than using particles over 30% or 75% of total area.</p><p>2. The shape-size pattern spectrum is then extracted from all images including the query images. The size and shape ranges were between 50, 000 -172, 800 and 1 -53 respectively. A 20 by 15 bin histogram which translates into a 1 × 600 array representation per image was chosen. Additionally, conversion of the images into XYZ and YUV color spaces as well as grayscale (PGM) was performed. This was to test whether additional information is captured from the color matrices. Visual analysis showed that unlike YUV and XYZ which performed worse than the grayscale images, RGB representation improved the results.</p><p>3. One of the three topic images was selected as the query image according to what the authors thought provided the most meaningful retrievals. The list of the chosen topic images is provided in the appendix.</p><p>4. The similarity measure used is the reciprocal of the L1 Norm.</p><formula xml:id="formula_8" coords="4,258.48,545.97,254.55,23.82">Sim(X, Y ) = 1 (x i -y i ) (9)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Submitted Runs</head><p>Four runs were submitted:</p><p>1. PGM2007 -the shape-size pattern spectrum of the grayscale images are compared.</p><p>2. Max2007 -the maximum of red, green and blue bands of the images are compared.</p><p>3. Concatenate2007 -the concatenated red, green and blue bands of the images are compared (a 1 × 1800 array).</p><p>4. JSD2007 -same as (3) above but comparison with the Jensen-Shannon divergence <ref type="bibr" coords="4,477.26,695.37,10.00,9.96" target="#b3">[4]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>We observed that most queries returned images based on their shapes. For example an image of a hill returns images of hills / mountains. So is the case with images of people, beaches, skies, buildings etcetera. An image with more buildings than people returns more results of buildings (some of them without people) than people. A group of people standing in front of a mountain landscape returns a group of people in front of buildings, mountains or in a city square or anywhere else. But if the mountains cover a larger percentage of the picture, then the returned results are more of mountains than people. Similarly, a duck swimming in water returns many images of birds flying in the sky and hens eating on a road. This is because the shapes of ducks, birds and hens are similar. The texture of the image also affects the performance of this method. For example, the image of a bird flying in a clear sky returns many images of birds or aeroplanes flying in the sky. But the one with a bird flying in a cloudy sky returns pictures of beds, clouds without birds, mountains covered in snow and some beach pictures. One of the poorest performances was the meat dishes which returned buildings, landscapes, beds, and people with no food and without food.</p><p>The overall performance of the submitted runs is shown in Table <ref type="table" coords="5,391.31,421.05,3.90,9.96" target="#tab_0">1</ref>. The RGB concatenated version using L1 Norm produces the best results and improves performance by 23%. As expected, all methods that incorporate color information perform better than the one without (PGM). This shows that more information has been obtained from the color matrices and so images with similar colors are grouped closer together. For example, images taken at night return more black pictures just as the ones taken in deserts return more brown ones. Interestingly, the images with two dominant colors seemed to outperform those with only one dominant color or many colors. Table <ref type="table" coords="5,155.04,504.69,4.98,9.96" target="#tab_0">1</ref> also gives surprising results that show how the maximum of the RGB bands using L1 norm outperformed the concatenated version using JSD. This could be due to the loss of information during normalization. This clearly shows that the use of an appropriate similarity measure significantly contributes to the performance of our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>This paper uses the shape-size pattern spectrum as the fundamental image signature for contentbased image retrieval. The pattern spectrum is obtained from the red, green and blue color bands of the image and compared using the L1-Norm. Our experiments have shown that this results in very logical and interesting performance although the MAP scores remain low. We believe that one of the ways of improving the MAP scores is to represent a single topic by the combination of the three provided sample images. This can be achieved by using relevance learning techniques already in place. Secondly, the results have shown that textural information, especially within the background, affects the performance of this system. We intend to incorporate both textural and spatial information into the pattern spectrum. Other works in progress include identifying the most appropriate shape parameters, attributes and similarity measures. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix -Selected topic images and corresponding MAP</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,210.00,279.69,183.09,9.96;4,159.72,108.88,283.40,156.32"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Performance of component sizes</figDesc><graphic coords="4,159.72,108.88,283.40,156.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,160.68,118.29,281.76,79.68"><head>Table 1 :</head><label>1</label><figDesc>performance of submitted runs</figDesc><table coords="5,160.68,138.57,281.76,59.40"><row><cell>Run</cell><cell>MAP</cell><cell>P20</cell><cell cols="2">Relevant % improvement</cell></row><row><cell cols="3">Concatenate 0.0337 0.1050</cell><cell>724</cell><cell>23</cell></row><row><cell>M ax</cell><cell cols="2">0.0288 0.0933</cell><cell>699</cell><cell>5.5</cell></row><row><cell>JSD</cell><cell cols="2">0.0281 0.0925</cell><cell>701</cell><cell>2.9</cell></row><row><cell>P GM</cell><cell cols="2">0.0273 0.0925</cell><cell>693</cell><cell>-</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,110.52,133.17,402.48,9.96;6,110.52,145.17,220.34,9.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,237.37,133.17,220.05,9.96">Attribute openings, thinnings and granulometries</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">J</forename><surname>Breens</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,470.15,133.17,42.85,9.96;6,110.52,145.17,122.85,9.96">Computer Vision Image Understanding</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="377" to="389" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.52,165.09,402.64,9.96;6,110.52,176.97,193.58,9.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,301.13,165.09,212.04,9.96;6,110.52,176.97,25.62,9.96">The iapr tc-12 benchmark for visual information search</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Clement</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,144.60,176.97,72.44,9.96">IAPR Newsletter</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="10" to="12" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.52,196.89,402.64,9.96;6,110.52,208.89,402.49,9.96;6,110.52,220.89,84.63,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,360.69,196.89,152.48,9.96;6,110.52,208.89,119.46,9.96">Overview of the ImageCLEF 2007 photographic retrieval task</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Henning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,257.52,208.89,200.85,9.96">Working Notes of the 2007 CLEF Workshop</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">Sep 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.52,240.81,402.31,9.96;6,110.52,252.69,125.78,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,138.25,240.81,216.91,9.96">Divergence measures based on the shannon entropy</title>
		<author>
			<persName coords=""><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,362.27,240.81,150.56,9.96;6,110.52,252.69,28.29,9.96">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="145" to="151" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.52,272.61,402.43,9.96;6,110.52,284.61,178.70,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,168.49,272.61,239.40,9.96">Pattern spectrum and multiscale shape representation</title>
		<author>
			<persName coords=""><surname>Maragos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,419.27,272.61,93.68,9.96;6,110.52,284.61,82.34,9.96">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="701" to="715" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.52,304.53,402.56,9.96;6,110.52,316.53,334.09,9.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,272.80,304.53,240.28,9.96;6,110.52,316.53,51.55,9.96">A comparison of algorithms for connected set openings and closings</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">H F</forename><surname>Meijster</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Wilkinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,170.40,316.53,177.98,9.96">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="484" to="494" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.52,336.45,402.50,9.96;6,110.52,348.33,295.21,9.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,297.04,336.45,215.98,9.96;6,110.52,348.33,84.58,9.96">Antiextensive connected operators for image and sequence processing</title>
		<author>
			<persName coords=""><surname>Salembier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Oliveras</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Garrido</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,203.64,348.33,110.03,9.96">IEEE Trans. Image Proc</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="555" to="570" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.52,368.25,402.42,9.96;6,110.52,380.25,402.53,9.96;6,110.52,392.25,215.18,9.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,397.27,368.25,115.67,9.96;6,110.52,380.25,337.86,9.96">Connected shape-size pattern spectra for rotation and scale-invariant classification of gray-scale images</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">R</forename><surname>Urbach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">B T M</forename><surname>Roerdink</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">H F</forename><surname>Wilkinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,457.43,380.25,55.62,9.96;6,110.52,392.25,118.82,9.96">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="272" to="285" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.52,412.17,402.47,9.96;6,110.52,424.05,368.33,9.96" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,277.37,412.17,232.22,9.96">Shape-only granulometries and grey-scale shape filters</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">R</forename><surname>Urbach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">H F</forename><surname>Wilkinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,122.88,424.05,215.99,9.96">Proc. Int. Symp. Math. Morphology (ISMM) 2002</title>
		<meeting>Int. Symp. Math. Morphology (ISMM) 2002<address><addrLine>Sydney, Australia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-04">April 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.52,443.97,402.44,9.96;6,110.52,455.97,402.84,9.96;6,110.52,467.97,156.62,9.96" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,196.71,443.97,258.58,9.96">Generalized pattern spectra sensitive to spatial information</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">H F</forename><surname>Wilkinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,477.11,443.97,35.85,9.96;6,110.52,455.97,282.06,9.96">Proceeding of the 16th International Conference on Pattern Recognition</title>
		<meeting>eeding of the 16th International Conference on Pattern Recognition<address><addrLine>Quebec City, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-08">August 2002</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="701" to="715" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
