<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,165.52,113.60,284.35,15.06;1,190.12,131.54,235.16,15.06;1,249.12,149.47,117.15,15.06">Cross-Language and Cross-Media Image Retrieval: An Empirical Study at ImageCLEF2007</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,270.60,187.83,74.17,10.46"><forename type="first">Steven</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
							<email>chhoi@ntu.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Engineering</orgName>
								<orgName type="institution">Nanyang Technological University Singapore</orgName>
								<address>
									<postCode>639798</postCode>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,165.52,113.60,284.35,15.06;1,190.12,131.54,235.16,15.06;1,249.12,149.47,117.15,15.06">Cross-Language and Cross-Media Image Retrieval: An Empirical Study at ImageCLEF2007</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5EEDC382AD54E878C9B4219C94BFF67F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper summarizes our empirical study of cross-language and cross-media image retrieval at the CLEF image retrieval track (Im-ageCLEF2007). In this year, we participated in the ImageCLEF photo retrieval task, in which the goal of the retrieval task is to search natural photos by some query with both textual and visual information. In this paper, we study the empirical evaluations of our solutions for the image retrieval tasks in three aspects. First of all, we study the application of language models and smoothing strategies for text-based image retrieval, particularly addressing the short text query issue. Secondly, we study the cross-media image retrieval problem using some simple combination strategy. Lastly, we study the cross-language image retrieval problem between English and Chinese. Finally, we summarize our empirical experiences and indicate some future directions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Digital image retrieval has attracted a surge of research interests in recent years due to the rapid growth of digital media contents overwhelming over the World Wide Web (WWW). Most existing search engines usually employ text based retrieval methods to search the digital images from WWW. They have yet to solve the retrieval tasks very effectively. Until now, general image retrieval is still a challenging research problem. There are several major obstacles for image retrieval. First of all, Web images may be associated with textual descriptions in different languages. When searching the images with different languages, the retrieval tasks will be suffered critically without further translation processing. Moreover, many Web image may not associate with textual descriptions, which makes the traditional text based retrieval difficult to reach some Web images without text annotations. Finally, even some images are associated with keywords, it can still be difficult for a short text query due to some challenges, such as word ambiguity. In this paper, we study some methodology to attack some of these challenges for a benchmark image retrieval evaluation campaign.</p><p>ImageCLEF is the cross-language image retrieval track which is run as part of the Cross Language Evaluation Forum (CLEF) campaign. The goal of this track is to evaluate retrieval of images described by text captions based on queries in a different language; both text and image based retrieval techniques can be explored. The ImageCLEF provides an annual benchmark evaluation for image retrieval research from 2003 <ref type="bibr" coords="2,263.57,153.20,9.97,10.46" target="#b1">[1]</ref>. In this year, there are two types of retrieval tasks in the ImageCLEF, including general photographs retrieval and medical image retreival. In this paper, we discuss our participation in the photo retrieval tasks at ImageCLEF2007.</p><p>In this participation, we offer the major contributions in three aspects. First of all, we study an empirical evaluation of language models and smoothing strategies for cross-language image retrieval. Secondly, we conduct an evaluation of cross-media image retrieval, i.e., combining text and visual contents for image retrieval. The last contribution is the empirical evaluation of a methodology for bilingual image retrieval spanning English and Chinese sources.</p><p>The rest of this paper is organized as follows. Section 2 reviews some methodology of the TF-IDF retrieval model and the language model for information retrieval. Section 3 presents our implementation for this participation, and outlines our empirical study on the cross-language and cross-media image retrieval. Section 4 set out our conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Review of Language Models and Smoothing Techniques</head><p>In this section, we review several existing language models and smoothing techniques to be studied in our experiments. In our participation, we have performed an extensive set of experiments to evaluate the performance of several state-ofthe-art language models in application to text-based image retrieval and also examine the influence of several popular smoothing techniques.</p><p>More specifically, two kinds of retrieval models are studied: <ref type="bibr" coords="2,424.21,436.78,12.73,10.46" target="#b1">(1)</ref> The TF-IDF (Term Frequency-Inverse Document Frequency) retrieval model, and <ref type="bibr" coords="2,467.89,448.73,12.73,10.46" target="#b2">(2)</ref> The KL-divergence language model based methods. Three smoothing strategies for Language Models evaluated in our experiments <ref type="bibr" coords="2,361.46,472.64,10.52,10.46" target="#b2">[2]</ref> include: (1) the Jelinek-Mercer (JM) method, (2) Bayesian smoothing with Dirichlet priors (DIR), and (3) Absolute discounting (ABS).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">TF-IDF Information Retrieval Model</head><p>We study the TF-IDF retrieval model, which is a well-known information retrieval model for text-based retrieval tasks <ref type="bibr" coords="2,324.22,558.81,9.97,10.46" target="#b3">[3]</ref>. In general, one can assume that each document and each query can be represented as a term frequency vector d = (x 1 , x 2 , . . . , x n ) and q = (y 1 , y 2 , . . . , y n ) respectively, where n is the number of total terms, x i and y i are the frequency (counts) of term t i in the document vector d and query vector q, respectively. In a retrieval task, given a document collection C, the inverse-document-frequency (IDF) of a term t is defined by log(N/n t ), where N is the total number of documents in C, and n t is the number of documents that contain the term t. For the TF-IDF representation, all terms in the query and documents vectors are weighted by the TF-IDF weighting formula, i.e., d = (tf d (x 1 )idf (t 1 ), tf d (x 2 )idf (t 2 ), . . . , tf d (x n )idf (t n )) and q = (tf q (y 1 )idf (t 1 ), tf q (y 2 )idf (t 2 ), . . . , tf q (y n )idf (t n )). For a simple TF-IDF retrieval model, one simply takes tf d (x i ) = x i . One can also define some other heuristic formula for the TF function. For example, the Okapi retrieval approach is a special case of TF-IDF model by defining the document TF formula as <ref type="bibr" coords="3,146.99,177.11,9.97,10.46" target="#b4">[4]</ref>:</p><formula xml:id="formula_0" coords="3,245.23,188.72,235.36,28.53">tf d (x) = k 1 x x + k 1 (1 -b + b l d l C )<label>(1)</label></formula><p>where k 1 and b are two parameters for the document TF function, l d and l C are the lengths of the given document and collection, respectively. Similarly, a query TF function can be defined with parameters k 1 and b as well as l q representing the average length of queries. For similarity measure of the TF-IDF retrieval model, cosine similarity function is often adopted, which a measure of similarity between two vectors of n dimensions by finding the angle between them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Language Modeling for Information Retrieval</head><p>Language model, or the statistical language model, employs a probabilistic mechanism to generate text. The earliest serious approach for a statistical language model may be tracked to Claude Shannon <ref type="bibr" coords="3,325.25,360.40,9.97,10.46" target="#b5">[5]</ref>. To apply his newly founded information theory to human language applications, Shannon evaluated how well simple n-gram models did at predicting or compressing natural text. In the past, there has been considerable attention paid to using the language modeling techniques for text document retrieval and natural language processing tasks <ref type="bibr" coords="3,455.69,408.23,9.97,10.46" target="#b6">[6]</ref>.</p><p>The KL-divergence Measure. Given two probability mass functions p(x) and q(x), D(p||q), the Kullback-Leibler (KL) divergence (or relative entropy) between p and q is defined as</p><formula xml:id="formula_1" coords="3,250.99,485.21,229.60,28.06">D(p||q) = x p(x)log p(x) q(x)<label>(2)</label></formula><p>One can show that D(p||q) is always non-negative and is zero if and only if p = q. Even though it is not a true distance between distributions (because it is not symmetric and does not satisfy the triangle inequality), it is often still useful to think of the KL-divergence as a "distance" between distributions <ref type="bibr" coords="3,433.81,559.90,9.97,10.46" target="#b7">[7]</ref>.</p><p>The KL-divergence based Retrieval Model. In the language modeling approach, we assume a query q is generated by a generative model p(q|θ Q ), where θ Q denotes the parameters of the query unigram language model. Similarly, we assume a document d is generated by a generative model p(q|θ D ), where θ Q denotes the parameters of the document unigram language model. Let θQ and θD be the estimated query and document models, respectively. The relevance of d with respect to q can be measured by the negative KL-divergence function <ref type="bibr" coords="4,467.33,117.33,9.97,10.46" target="#b6">[6]</ref>:</p><formula xml:id="formula_2" coords="4,158.98,136.41,321.61,23.95">-D( θQ || θD ) = w p(w| θQ )logp(w| θD ) + (- w p(w| θQ )logp(w| θQ ))<label>(3)</label></formula><p>In the above formula, the second term on the right-hand side of the formula is a query-dependent constant, i.e., the entropy of the query model θQ . It can be ignored for the ranking purpose. In general, we consider the smoothing scheme for the estimated document model as follows:</p><formula xml:id="formula_3" coords="4,208.39,220.16,272.20,23.31">p(w| θD ) = p s (w|d) if word w is present α d p(w|C) otherwise<label>(4)</label></formula><p>where p s (w|d) is the smoothed probability of a word present in the document, p(w|C) is the collection language model, and α d is a coefficient controlling the probability mass assigned to unseen words, so that all probabilities sum to one <ref type="bibr" coords="4,153.03,287.80,9.97,10.46" target="#b6">[6]</ref>. We discuss several smoothing techniques in detail below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Three Smoothing Techniques</head><p>In the context of language modeling study, the term "smoothing" can be defined as the adjustment of the maximum likelihood estimator of a language model so that it will be more accurate <ref type="bibr" coords="4,259.73,358.00,9.97,10.46" target="#b2">[2]</ref>. As we know that a language modeling approach usually estimates p(w|d), a unigram language model based on a given document d, one of the simplest methods for smoothing is based on the maximum likelihood estimate as follows:</p><formula xml:id="formula_4" coords="4,256.87,402.34,223.72,26.43">p ml (w|d) = c(w; d) w c(w; d) (5)</formula><p>Unfortunately, the maximum likelihood estimator will often underestimate the probabilities of unseen words in the given document. Hence, it is important to employ smoothing methods that usually discount the probabilities of the words seen in the text and assign the extra probability mass to the unseen words according to some model <ref type="bibr" coords="4,246.37,479.29,9.97,10.46" target="#b2">[2]</ref>. Some comprehensive evaluation of smoothing techniques for traditional text retrieval can be found in literature <ref type="bibr" coords="4,296.82,503.20,10.52,10.46" target="#b8">[8,</ref><ref type="bibr" coords="4,309.01,503.20,7.01,10.46" target="#b2">2]</ref>. They have been an important tool to improve the performance of language models in traditional text retrieval. To achieve efficient implementations for large-scale tasks, three representative methods are selected in our scheme, which are popular and relatively efficient. They are discussed in turn below.</p><p>The Jelinek-Mercer (JM) Method. This method simply employs a linear interpolation of the maximum likelihood model with the collection model, using a coefficient λ to control the influence:</p><formula xml:id="formula_5" coords="4,227.78,622.78,252.82,11.36">p λ (ω|d) = (1 -λ)p ml (ω|d) + λp(ω|C) (6)</formula><p>It is a simple mixture model. A more general Jelinek-Mercer method can be found in <ref type="bibr" coords="4,174.36,654.45,9.97,10.46" target="#b9">[9]</ref>.</p><p>Bayesian Smoothing with Dirichlet Priors (DIR). In general, a language model can be considered as a multinomial distribution, in which the conjugate prior for Bayesian analysis is the Dirichlet distribution with parameters <ref type="bibr" coords="5,470.13,141.24,10.52,10.46" target="#b2">[2]</ref> (µp(ω 1 |C), µp(ω 2 |C), . . . , µp(ω n |C)). Thus, the smoothing model can be given as:</p><formula xml:id="formula_6" coords="5,246.37,174.36,234.22,26.43">p µ (ω|d) = c(ω; d) + µp(ω|C) ω c(ω; d) + µ (7)</formula><p>Note that µ in the above formula is a DIR parameter that is usually estimated empirically from training sets.</p><p>Absolute Discounting Smoothing (ABS). The absolute discounting method subtracts a constant from the counts of seen words for reducing the probabilities of the seen words, meanwhile it increases the probabilities of unseen words by including the collection language model. More specifically, the model can be represented as follows:</p><formula xml:id="formula_7" coords="5,220.77,319.92,255.58,26.43">p δ (ω|d) = max(c(ω; d) -δ, 0) ω c(ω; d) + σp(ω|C) (<label>8</label></formula><formula xml:id="formula_8" coords="5,476.35,326.66,4.24,10.46">)</formula><p>where δ ∈ [0, 1] is a discount constant and σ = δ|d| µ /|d|, so that all probabilities sum to one. Here |d| µ is the number of unique terms in document d, and |d| is the total count of words in the document, i.e., |d| = ω c(ω; d).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Cross-Language and Cross-Media Image Retrieval</head><p>The goal of the photographic retrieval task is to find as many relevant images as possible from an image collection given a multilingual statement describing a user information need. This task intends to simulate the text-based retrieval from photographs with multilingual captions, meanwhile queries for contentbased image retrieval will also be offered. In this section, we study techniques to address several open challenges in this retrieval task, including (1) short text query problem, (2) cross-media image retrieval, and (3) cross-language retrieval. In the following part, we first describe the experimental testbed and setup at the ImageCLEF 2007, in which we have participated in the photo retrieval task. We will then conduct the empirical evaluations to address the above challenges and summarize our empirical experiences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Testbed and Setup</head><p>The experimental testbed contains 20,000 color photographs with semi-structured captions in English, German and Spanish. For performance evaluations, there are 60 queries, each of them describes the user's information needs by short text in a range of languages including English, Italian, Spanish, French, German, Chinese, Japanese and Russian, and sample images.</p><p>For the photographic retrieval task, we have studied the query tasks in English and Chinese (simplified). Both text and visual information are used in our experiments. To evaluate the language models correctly, we employ the Lemur toolkit<ref type="foot" coords="6,166.87,152.12,3.97,7.32" target="#foot_0">1</ref> . A list of standard stopwords is used in the parsing step.</p><p>To evaluate the influence on the performance of using the different schemes, we have evaluated the methods by trying a variety of different configurations in order to examine every aspects of the solutions. In particular, there groups of performance evaluations will be studied in the subsequent parts. "TF-IDF" and "OKAPI" are two typical retrieval methods, "KL" denotes Kullback-Leibler divergence based model, "DIR" denotes the smoothing technique using the Dirichlet priors, "ABS" denotes the smoothing using the absolute discounting, and "JM" denotes the Jelinek-Mercer smoothing approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation of Language Models and Smoothing Techniques.</head><p>In our experiments, we study several retrieval methods by language models with different smoothing techniques for the text-based image retrieval tasks. Table <ref type="table" coords="6,475.63,479.04,4.98,10.46" target="#tab_0">1</ref> shows the results of a number of our submissions with respect to the text based retrieval approaches by Language Models. The listed methods are ranked by the MAP (mean average precision) score. From the results, we can observe that the best approach is the "Eng-kl-dir-fb2" solution, which is based on the KLdivergence language model with the Dirichlet priors smoothing technique. We also found that the retrieval methods by KL-divergence language models do not always outperform the traditional TF-IDF and Okapi approaches, while the language models tend to outperform the TF-IDF and Okapi approaches on average. Further, we found that the retrieval methods with pseudo-relevance feedback (FB) consistently outperform the ones without any feedback. For example, the "Eng-kl-dir" approach is the KL-divergence language model approach using the Dirichlet priors smoothing technique without feedback, which achieved only a MAP score of 0.1419. However, by engaging the relevance feedback, the MAP performance will be importantly improved, such as the "Eng-kl-dir-fb2" solution, which achieved a MAP score of 0.1660. Finally, comparing several different smoothing techniques, there is no a clear evidence that which smoothing technique significantly outperform the others, though the Dirichlet priors smoothing approach achieved the best MAP performance among all runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Cross-Language Image Retrieval</head><p>In this part, we study the bilingual image retrieval using Chinese queries and English sources. To this purpose, the first step is to translate the Chinese queries into English. In our experiment, we simply test an online translation tool offered by Google inc<ref type="foot" coords="7,194.89,259.54,3.97,7.32" target="#foot_1">2</ref> . Fig. <ref type="figure" coords="7,225.79,260.61,4.98,10.46" target="#fig_0">1</ref> shows some examples of the translation results. Given the translated results, we conducted the experimental evaluations to examine the retrieval performance. Table <ref type="table" coords="7,322.27,548.28,4.98,10.46" target="#tab_1">2</ref> shows the experimental results of cross-language retrieval evaluation. From the experimental results, we found that the average retrieval performance of the bilingual retrieval tasks is less than the results of the single language image retrieval as shown in Table <ref type="table" coords="7,454.93,584.15,3.88,10.46" target="#tab_0">1</ref>. For example, for a same retrieval method by the KL-divergence language model with the Dirichlet priors smoothing technique, the scheme "Chn-kl-dir-fb3" achieved only the MAP of 0.1429 in the bilingual retrieval task, while the same approach "Eng-kl-dir-fd3" can achieve the MAP of 0.1571 in the single langauge retrieval tasks. Nonetheless, the overall performance of the bilingual approach is quite impressive. In the future work, we will study more advanced translation techniques to improve the results <ref type="bibr" coords="8,233.73,141.24,14.62,10.46" target="#b10">[10]</ref>. "TF-IDF" and "OKAPI" are two typical retrieval methods, "KL" denotes Kullback-Leibler divergence based model, "DIR" denotes the smoothing technique using the Dirichlet priors, "ABS" denotes the smoothing using the absolute discounting, and "JM" denotes the Jelinek-Mercer smoothing approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Cross-Media Image Retrieval</head><p>In this task we study the combination of text and visual information for crossmedia image retrieval. We consider a simple combination scheme to combine the information from both the textual and visual modalities. Specifically, for a given query, we first rank the images using the language modeling techniques.</p><p>We then measure the similarity of the top ranked images with respect to the sample images of the query. Finally, we combine the similarity values from both textual and visual modalities and re-rank the retrieval results based on the overall similarity scores. In our experiment, three types of low-level visual features are engaged: color, shape, and texture <ref type="bibr" coords="8,222.24,522.95,15.50,10.46" target="#b11">[11,</ref><ref type="bibr" coords="8,239.40,522.95,11.63,10.46" target="#b12">12]</ref>. For color features, we use the grid color moment. Each image is partitioned into 3 × 3 grids and three types of color moments are extracted for representing color content of each grid. Thus, an 81-dimensional color moment is adopted for the color feature. For shape features, we employ the edge direction histogram. A Canny edge detector is used to acquire the edge images and then the edge direction histogram is computed from the edges. Each histogram is quantized into 36 bins of 10 degrees each. An additional bin is used to count the number of pixels without edge information. Hence, a 37dimensional edge direction histogram is used for the shape feature. For texture features, we adopt the Gabor feature <ref type="bibr" coords="8,295.44,630.54,14.62,10.46" target="#b13">[13]</ref>. Each image is scaled to 64×64. Gabor wavelet transformation is applied on the scaled image with 5 scale levels and 8 orientations, which results in 40 subimages. For each subimage, three moments are computed: mean, variance, and skewness. Thus, a 120-dimensional feature vector is adopted for the texture feature. In total, a 238-dimensional feature vector is employed to represent each of images in the testbed.</p><p>Table <ref type="table" coords="9,176.98,153.36,4.98,10.46">3</ref> shows the cross-media retrieval results. Before examining the experimental results, we potentially expect that the cross-media retrieval approaches are very likely to improve the text-based retrieval approaches. Unfortunately, the observations from the empirical results are somewhat surprising, which are not consistent with our intuition. Two possible reasons may explain this conflict results. One reason may be the wrong results reported from the official evaluations. Another possible reason may be due to some mistake engaged when combining the visual and textual similarity values. (We will examine all of the reasons since our similar approach in ImageCLEF2005 achieved much better results <ref type="bibr" coords="9,444.08,249.00,14.77,10.46" target="#b14">[14]</ref>.)</p><p>In fact, in our current implementation, we do not engage other advanced combination methods. In future work, we will try some nonlinear combination methods. For example, we can train an SVM classifier with the sample images and then apply the classifier to re-rank the top images from the text retrieval results. We will consider this in our future work and expect it will importantly improve current results.</p><p>Table <ref type="table" coords="9,160.35,341.89,3.52,7.32">3</ref>. The performance evaluation for cross-media image retrieval tasks with queries of both textual and visual information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>In this paper we reported our empirical study of cross-language and cross-media image retrieval in the ImaegCLEF 2007 campaign. We have conducted three parts of empirical evaluations for three different purposes. One is to evaluate the techniques of language models and smoothing techniques with applications to text-based image retrieval. In this year, we found that the language models approaches did not achieve significantly promising results as we achieved in the ImageCLEF2005 campaign. The main reason is that the testbed in this year is totally different from the one in 2005. In this year, images are only associated with very short text captions, which makes the text retrieval models difficult to achieve excellent performance. The second major evaluation is the cross-media image retrieval by combining both textual and visual information. In the evaluation, some strange observations were found. We will study the problem in more details in our future work. Finally, we also examined a commercial language translation tool for the cross-language retrieval tasks and found good retrieval results. In future work, we will study more effective techniques to overcome the limitation of current approaches.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="7,140.28,514.24,334.70,9.41;7,137.60,284.35,340.10,216.59"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Some examples of Chinese to English query translation in our experiments.</figDesc><graphic coords="7,137.60,284.35,340.10,216.59" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,139.22,222.74,339.98,185.42"><head>Table 1 .</head><label>1</label><figDesc>The performance evaluation of Language Models for text-based image retrieval tasks</figDesc><table coords="6,139.22,241.03,339.98,167.12"><row><cell>Run ID</cell><cell cols="4">Method Query Source Modality RunType QE/RF MAP P10 REL RET REL</cell></row><row><cell cols="2">Eng-kl-dir-fb2 KL-DIR English English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1660 0.2217 1827 3416</cell></row><row><cell cols="2">Eng-kl-jm-fb1 KL-JM English English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1641 0.2017 1788 3416</cell></row><row><cell cols="2">Eng-tf-idf-fb3 TF-IDF English English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1641 0.2150 1955 3416</cell></row><row><cell cols="2">Eng-kl-jm-fb2 KL-JM English English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1640 0.2033 1870 3416</cell></row><row><cell cols="2">Eng-kl-abs-fb2 KL-ABS English English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1635 0.2017 1757 3416</cell></row><row><cell cols="2">Eng-okapi-fb2 OKAPI English English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1612 0.2333 1674 3416</cell></row><row><cell cols="2">Eng-kl-abs-fb1 KL-ABS English English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1611 0.1950 1700 3416</cell></row><row><cell cols="2">Eng-kl-dir-fb1 KL-DIR English English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1603 0.2117 1682 3416</cell></row><row><cell cols="2">Eng-kl-abs-fb3 KL-ABS English English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1593 0.2000 1797 3416</cell></row><row><cell cols="2">Eng-kl-dir-fb3 KL-DIR English English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1571 0.1867 1823 3416</cell></row><row><cell cols="2">Eng-kl-jm-fb3 KL-JM English English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1566 0.1917 1860 3416</cell></row><row><cell cols="2">Eng-tf-idf-fb2 TF-IDF English English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1560 0.2117 1842 3416</cell></row><row><cell cols="2">Eng-okapi-fb3 OKAPI English English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1540 0.1950 1733 3416</cell></row><row><cell cols="2">Eng-tf-idf-fb1 TF-IDF English English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1540 0.2133 1750 3416</cell></row><row><cell cols="2">Eng-okapi-fb1 OKAPI English English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1492 0.2000 1726 3416</cell></row><row><cell>Eng-kl-abs</cell><cell>KL-ABS English English TEXT</cell><cell cols="3">AUTO NOFB 0.1455 0.1883 1570 3416</cell></row><row><cell>Eng-okapi</cell><cell>OKAPI English English TEXT</cell><cell cols="3">AUTO NOFB 0.1437 0.1850 1556 3416</cell></row><row><cell>Eng-kl-jm</cell><cell>KL-JM English English TEXT</cell><cell cols="3">AUTO NOFB 0.1428 0.1850 1547 3416</cell></row><row><cell>Eng-kl-dir</cell><cell>KL-DIR English English TEXT</cell><cell cols="3">AUTO NOFB 0.1419 0.1850 1554 3416</cell></row><row><cell>Eng-tf-idf</cell><cell>TF-IDF English English TEXT</cell><cell cols="3">AUTO NOFB 0.1341 0.1900 1539 3416</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,134.77,163.12,352.23,193.77"><head>Table 2 .</head><label>2</label><figDesc>The performance evaluation for cross-language image retrieval tasks between Chinese (simplified) queries and English sources.</figDesc><table coords="8,137.99,189.77,349.01,167.12"><row><cell>Run ID</cell><cell>Method</cell><cell>Query</cell><cell cols="2">Source Modality RunType QE/RF MAP P10 REL RET REL</cell></row><row><cell cols="4">Chn-tf-idf-fb3 TF-IDF Chinese S English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1574 0.2000 1874 3416</cell></row><row><cell cols="4">Chn-kl-dir-fb3 KL-DIR Chinese S English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1429 0.1650 1709 3416</cell></row><row><cell cols="4">Chn-tf-idf-fb2 TF-IDF Chinese S English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1413 0.1783 1790 3416</cell></row><row><cell cols="4">Chn-kl-abs-fb3 KL-ABS Chinese S English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1406 0.1667 1713 3416</cell></row><row><cell cols="4">Chn-kl-abs-fb2 KL-ABS Chinese S English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1385 0.1500 1732 3416</cell></row><row><cell cols="4">Chn-kl-dir-fb2 KL-DIR Chinese S English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1382 0.1600 1763 3416</cell></row><row><cell cols="4">Chn-kl-jm-fb2 KL-JM Chinese S English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1380 0.1533 1801 3416</cell></row><row><cell cols="4">Chn-kl-jm-fb3 KL-JM Chinese S English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1378 0.1600 1748 3416</cell></row><row><cell cols="4">Chn-kl-jm-fb1 KL-JM Chinese S English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1345 0.1533 1696 3416</cell></row><row><cell cols="4">Chn-kl-dir-fb1 KL-DIR Chinese S English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1333 0.1650 1672 3416</cell></row><row><cell cols="4">Chn-okapi-fb3 OKAPI Chinese S English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1312 0.1517 1646 3416</cell></row><row><cell cols="4">Chn-kl-abs-fb1 KL-ABS Chinese S English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1309 0.1417 1675 3416</cell></row><row><cell cols="4">Chn-tf-idf-fb1 TF-IDF Chinese S English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1286 0.1767 1553 3416</cell></row><row><cell>Chn-okapi</cell><cell cols="3">OKAPI Chinese S English TEXT</cell><cell>AUTO NOFB 0.1268 0.1417 1404 3416</cell></row><row><cell>Chn-kl-dir</cell><cell cols="3">KL-DIR Chinese S English TEXT</cell><cell>AUTO NOFB 0.1265 0.1467 1410 3416</cell></row><row><cell>Chn-kl-abs</cell><cell cols="3">KL-ABS Chinese S English TEXT</cell><cell>AUTO NOFB 0.1264 0.1483 1411 3416</cell></row><row><cell>Chn-kl-jm</cell><cell cols="3">KL-JM Chinese S English TEXT</cell><cell>AUTO NOFB 0.1252 0.1450 1415 3416</cell></row><row><cell cols="4">Chn-okapi-fb1 OKAPI Chinese S English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1237 0.1350 1654 3416</cell></row><row><cell>Chn-tf-idf</cell><cell cols="3">TF-IDF Chinese S English TEXT</cell><cell>AUTO NOFB 0.1223 0.1567 1388 3416</cell></row><row><cell cols="4">Chn-okapi-fb2 OKAPI Chinese S English TEXT</cell><cell>AUTO</cell><cell>FB</cell><cell>0.1177 0.1383 1540 3416</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="6,144.73,655.30,125.22,9.41"><p>http://www.lemurproject.org/.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="7,144.73,655.30,158.24,9.41"><p>http://www.google.com/language tools</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,137.99,366.40,26.14,7.32;9,205.32,366.40,21.35,7.32;9,242.23,366.40,246.05,7.32;9,137.99,374.77,21.91,7.32;9,205.32,374.77,282.86,7.32;9,137.99,382.74,350.20,7.32;9,137.99,390.71,350.20,7.32;9,137.99,398.68,350.20,7.32;9,137.99,406.65,350.20,7.32;9,137.99,414.62,350.20,7.32;9,137.99,422.59,350.20,7.32;9,137.99,430.56,350.20,7.32;9,137.99,438.53,350.20,7.32;9,137.99,446.50,350.20,7.32;9,137.99,454.47,350.20,7.32;9,137.99,462.44,350.20,7.32;9,137.99,470.41,350.20,7.32;9,137.99,478.38,350.20,7.32;9,137.99,486.35,350.20,7.32;9,137.99,494.32,350.20,7.32;9,137.99,502.29,350.20,7.32;9,137.99,510.26,350.20,7.32;9,137.99,518.23,350.20,7.32;9,137.99,526.20,350.20,7.32;9,137.99,534.17,350.20,7.32;9,137.99,542.14,350.20,7.32;9,134.77,553.60,345.84,5.23;9,134.77,559.58,345.86,5.23;9,134.77,565.55,271.62,5.23;10,134.77,252.60,62.92,12.55" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,137.99,366.40,26.14,7.32;9,205.32,366.40,21.35,7.32;9,242.23,366.40,246.05,7.32;9,137.99,374.77,21.91,7.32;9,205.32,374.77,154.57,7.32">Run ID Query Method Source Modality RunType QE/RF MAP P10 REL RET REL Visual Euclidean Visual Visual VISUAL AUTO</title>
		<idno>AUTO FB 0.0098 0.0083 802 3416 Eng-</idno>
	</analytic>
	<monogr>
		<title level="m" coord="9,189.23,414.62,170.67,7.32">tv2 OKAPI English English MIXED AUTO</title>
		<imprint>
			<publisher>-IDF English English MIXED AUTO</publisher>
			<date type="published" when="2067">2067. 0093</date>
			<biblScope unit="page" from="883" to="3416" />
		</imprint>
	</monogr>
	<note>Eng-kl-abs-fb1-tv3 KL-ABS English English MIXED. -ABS English English MIXED. -ABS English English MIXED. TF-IDF English English MIXED. -ABS English English MIXED. -ABS English English MIXED. -ABS English English MIXED. Eng-okapi-fb3-tv2 OKAPI English English MIXED AUTO. -JM English English MIXED. okapi-fb2-tv2 OKAPI English English MIXED AUTO FB 0</note>
</biblStruct>

<biblStruct coords="10,142.95,274.13,337.53,9.42;10,151.52,285.09,329.07,9.41;10,151.52,296.05,329.04,9.41;10,151.52,307.01,54.31,9.41" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,198.82,285.09,206.11,9.41">The CLEF 2005 cross language image retrieval track</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müeller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,424.77,285.09,55.82,9.41;10,151.52,296.05,152.28,9.41">Proceedings of the Cross Language Evaluation Forum</title>
		<title level="s" coord="10,335.25,296.05,145.31,9.41;10,151.52,307.01,26.47,9.41">Springer Lecture Notes in Computer science</title>
		<meeting>the Cross Language Evaluation Forum</meeting>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.95,317.19,337.57,9.41;10,151.52,328.15,329.07,9.41;10,151.52,339.10,126.23,9.41" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,262.84,317.19,217.69,9.41;10,151.52,328.15,154.89,9.41">A study of smoothing methods for language models applied to ad hoc information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,327.01,328.15,153.59,9.41;10,151.52,339.10,44.02,9.41">ACM International SIGIR Conference (SIGIR&apos;01)</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="334" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.95,349.28,337.62,9.41;10,151.52,360.24,53.79,9.41" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="10,309.31,349.28,121.76,9.41">Modern Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ribeiro-Neto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Addison Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.95,370.41,337.56,9.41;10,151.52,381.37,319.02,9.41" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,156.26,381.37,60.68,9.41">Okapi at trec-3</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gatford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,238.32,381.37,193.53,9.41">The Third Text REtrieval Conference (TREC-3)</title>
		<imprint>
			<publisher>NIST</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.95,391.55,337.63,9.41;10,151.52,402.51,97.76,9.41" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,218.67,391.55,165.45,9.41">Prediction and entropy of printed English</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,394.97,391.55,81.66,9.41">Bell Sys. Tech. Jour</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="51" to="64" />
			<date type="published" when="1951">1951</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.95,412.68,337.57,9.41;10,151.52,423.64,329.08,9.41;10,151.52,434.60,186.77,9.41" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,264.00,412.68,216.53,9.41;10,151.52,423.64,22.48,9.41">Model-based feedback in the kl-divergence retrieval model</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,197.87,423.64,282.73,9.41;10,151.52,434.60,104.02,9.41">Proc. Tenth International Conference on Information and Knowledge Management (CIKM2001)</title>
		<meeting>Tenth International Conference on Information and Knowledge Management (CIKM2001)</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="403" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.95,444.78,331.46,9.41" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<title level="m" coord="10,283.04,444.78,128.40,9.41">Elements of Information Theory</title>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.95,454.95,337.58,9.41;10,151.52,465.91,329.07,9.41;10,151.52,476.87,142.06,9.41" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,213.35,454.95,267.19,9.41;10,151.52,465.91,214.94,9.41">Term-specific smoothing for the language modeling approach to information retrieval: the importance of a query term</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,389.29,465.91,91.31,9.41;10,151.52,476.87,69.47,9.41">Proceedings 25th ACM SIGIR conference</title>
		<meeting>25th ACM SIGIR conference</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="35" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.95,487.04,337.57,9.41;10,151.52,498.00,284.77,9.41" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,266.25,487.04,214.27,9.41;10,151.52,498.00,66.26,9.41">Interpolated estimation of markov sourceparameters from sparse data</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Jelinek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mercer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,229.23,498.00,125.36,9.41">Pattern Recognition in Practice</title>
		<imprint>
			<date type="published" when="1980">1980</date>
			<biblScope unit="page" from="381" to="402" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,508.18,337.99,9.41;10,151.52,519.14,112.28,9.41" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
		<title level="m" coord="10,268.83,508.18,211.78,9.41;10,151.52,519.14,11.09,9.41">Foundations of Statistical Natural Language Processing</title>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,529.31,337.90,9.41;10,151.52,540.27,329.07,9.41;10,151.52,551.23,248.85,9.41" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,272.96,529.31,207.55,9.41;10,151.52,540.27,116.75,9.41">A novel log-based relevance feedback technique in content-based image retrieval</title>
		<author>
			<persName coords=""><forename type="first">C.-H</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,288.21,540.27,192.38,9.41;10,151.52,551.23,105.92,9.41">Proceedings 12th ACM International Conference on Multimedia (MM 2004)</title>
		<meeting>12th ACM International Conference on Multimedia (MM 2004)<address><addrLine>New York, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="24" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,561.41,337.90,9.41;10,151.52,572.37,329.06,9.41;10,151.52,583.32,167.48,9.41" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,321.58,561.41,158.93,9.41;10,151.52,572.37,108.81,9.41">A unified log-based relevance feedback scheme for image retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,271.97,572.37,208.61,9.41;10,151.52,583.32,27.86,9.41">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="509" to="524" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,593.50,337.91,9.41;10,151.52,604.46,329.07,9.41;10,151.52,615.42,329.00,9.41;10,151.52,626.38,202.21,9.41" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,391.37,593.50,89.15,9.41;10,151.52,604.46,158.16,9.41">A texture descriptor for browsing and similarity retrieval</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Manjunath</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Newsam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Shin</surname></persName>
		</author>
		<ptr target="http://vision.ece.ucsb.edu/publications/00ICJ.pdf" />
	</analytic>
	<monogr>
		<title level="j" coord="10,323.49,604.46,157.09,9.41;10,151.52,615.42,61.35,9.41">Journal of Signal Processing: Image Communication</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="33" to="43" />
			<date type="published" when="2000-09">Sep 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,636.55,337.89,9.41;10,151.52,647.51,116.62,9.41" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="10,300.42,636.55,180.08,9.41;10,151.52,647.51,109.31,9.41">Cuhk at imageclef 2005: Cross-language and cross-media image retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
