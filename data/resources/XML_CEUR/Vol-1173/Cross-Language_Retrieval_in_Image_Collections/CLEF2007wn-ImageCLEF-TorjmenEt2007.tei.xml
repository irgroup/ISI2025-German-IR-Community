<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,114.16,148.62,374.33,15.51;1,207.30,170.53,188.22,15.51">Using pseudo-relevance feedback to improve image retrieval results</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,164.90,204.00,67.82,9.96"><forename type="first">Mouna</forename><surname>Torjmen</surname></persName>
							<email>torjmen@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">Boughanem IRIT</orgName>
								<address>
									<addrLine>118 Route Narbonne</addrLine>
									<postCode>31062</postCode>
									<settlement>Toulouse Cedex 4</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,240.96,204.00,142.27,9.96"><roleName>Mohand</roleName><forename type="first">Karen</forename><surname>Pinel-Sauvagnat</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Boughanem IRIT</orgName>
								<address>
									<addrLine>118 Route Narbonne</addrLine>
									<postCode>31062</postCode>
									<settlement>Toulouse Cedex 4</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,114.16,148.62,374.33,15.51;1,207.30,170.53,188.22,15.51">Using pseudo-relevance feedback to improve image retrieval results</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0466A942AF209A8D6A5A8646E6662E06</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Managment]: Languages-Query Languages Image retrieval, pseudo-relevance feedback</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we propose a pseudo-relevance feedback method to deal with the photographic retrieval and medical retrieval tasks of ImageCLEF 2007. The aim of our participation to ImageCLEF is to evaluate a combination method using both english textual queries and image queries to answer to topics. The approach processes image queries and merges them with textual queries in order to improve results. We do not obtain good results using only textual information and queries. To process image queries, we used the Fire system to sort similar images using low level features, and we then used associated textual information of the top images to construct a new textual query. Results showed the interest of low level features to process image queries, as performance increased compared to textual queries processing. Finally, best results were obtained combining the results lists of textual queries processing and image queries processing with a linear function .</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In Image Retrieval, one can distinguish two main approaches <ref type="bibr" coords="1,369.92,599.52,15.48,9.96" target="#b15">[16]</ref> : <ref type="bibr" coords="1,399.43,599.52,12.70,9.96" target="#b0">(1)</ref> Context Based Image Retrieval and (2) Content Based Image Retrieval:</p><p>1. The context of an image is all information about the image coming from others sources than the image itself. For the time being, only textual information is used as context. The main problem of this approach is that documents can use different words to describe the same image or can use the same words to describe different concepts. Moreover image queries can't be processed.</p><p>2. Content Based Image Retrieval (CBIR) systems use low-level image features to return images similar to an example image. The main problem of this approach is that visual similarity does not always correspond to semantic similarity (for example a CBIR system can return a picture of blue sky when the example image is a blue car).</p><p>Most of the image retrieval systems combine nowadays content and context retrieval, in order to take advantages of both methods. Indeed, it has been proved that combining text-and contentbased methods for images retrieval always improves performance <ref type="bibr" coords="2,375.48,135.26,9.94,9.96" target="#b3">[4]</ref>.</p><p>Images and textual information can be considered as independent and content and contextual information of queries can be combined in different ways:</p><p>• Image queries and textual queries can be processed separately and the two results lists are then merged using a linear function <ref type="bibr" coords="2,273.44,203.01,9.94,9.96" target="#b0">[1]</ref>, <ref type="bibr" coords="2,290.03,203.01,9.94,9.96" target="#b6">[7]</ref>.</p><p>• One can also use a pipeline approach: a first search is done using textual information or content information, and a filtering step is then processed using the other information type to exclude non-relevant images <ref type="bibr" coords="2,252.40,246.84,14.58,9.96" target="#b11">[12]</ref>.</p><p>• Other methods use Latent Semantic Analysis (LSA) techniques to combine visual and textual information, but are not efficient <ref type="bibr" coords="2,260.95,278.73,33.39,9.96">[16] [17]</ref>.</p><p>Some other works propose translation-based methods, in which content and context information are complementary. The main idea is to extract relations between images and text, and to use them to translate textual information to visual one and vice versa <ref type="bibr" coords="2,381.10,322.56,9.94,9.96" target="#b8">[9]</ref>:</p><p>• In <ref type="bibr" coords="2,127.35,342.48,9.94,9.96" target="#b7">[8]</ref>, authors translate textual queries to visual ones.</p><p>• authors of <ref type="bibr" coords="2,162.01,362.41,10.50,9.96" target="#b1">[2]</ref> propose to translate image queries to textual ones, and to process them using textual methods. Results are then merged with those obtained with textual queries. Authors in <ref type="bibr" coords="2,125.70,386.32,15.48,9.96" target="#b9">[10]</ref> also propose to expand the initial textual query by terms extracted thanks to an image query.</p><p>For the latter methods, the main problem to construct a new textual query or expand an initial textual query is term extraction. To do this, the main solution is pseudo-relevance feedback. Using pseudo-relevance feedback in context based image retrieval to process image queries is slightly different from classic pseudo-relevance feedback. The first step is to use a visual system to process image queries. Images obtained as results are considered as relevant and the associated textual information is then used to select terms in order to express a new textual query. The work presented in this paper also propose to combine context and content information to answer to the photographic retrieval and medical retrieval tasks. More precisely, we present a method to transform image queries to textual ones. We use XFIRM <ref type="bibr" coords="2,385.28,513.84,14.58,9.96" target="#b13">[14]</ref>, a structured information retrieval system to process english textual queries, and the Fire system <ref type="bibr" coords="2,393.59,525.80,10.50,9.96" target="#b2">[3]</ref> to process image queries. Documents corresponding to the images returned by Fire are used to extract terms that will form a new textual query.</p><p>The paper is organized as follows. In Section 2, we describe textual queries processing using the XFIRM system. In Section 3, we describe the image queries processing using in a first step, the Fire system, and in a second step a pseudo-relevance feedback method. In Section 4, we present our combination method, which uses both results of the XFIRM and FIRE systems. Experiments and results for the two tasks (medical retrieval and photographic retrieval <ref type="bibr" coords="2,412.00,609.49,14.58,9.96" target="#b12">[13]</ref>, <ref type="bibr" coords="2,433.30,609.49,10.77,9.96" target="#b5">[6]</ref>) are exposed in section 5. Finally we conclude in Section 6 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Textual queries processing</head><p>Textual information of collections used for the photographic and medical retrieval tasks <ref type="bibr" coords="2,490.81,676.20,10.50,9.96" target="#b5">[6]</ref> is organised using the XML language. In the indexing phase, we decided to only use documents elements containing positive information: ≺ description , ≺ title , ≺ notes and ≺ location . We then used the XFIRM system <ref type="bibr" coords="2,237.81,712.07,15.48,9.96" target="#b13">[14]</ref> to process queries. XFIRM (XML Flexible Information Retrieval Model ) uses a relevance propagation method to process textual queries in XML documents. Relevance values are first computed on leaf nodes (which contain textual information) and scores are then propagated along the document tree to evaluate inner nodes relevance values.</p><p>Let q = t 1 , . . . , t n be a textual query composed of n terms. Relevance values of leaf nodes ln are computed thanks to a similarity function RSV (q, ln).</p><p>RSV (q, ln) = n i=1 w q i * w ln i , where w q i = tf q i and w</p><formula xml:id="formula_0" coords="3,386.06,175.18,126.91,12.91">ln i = tf ln i * idf i * ief i<label>(1)</label></formula><p>w q i and w ln i are the weights of term i in query q and leaf node ln respectively. tf q i and tf ln i are the frequency of i in q and ln, idf i = log(|D|/(|di| + 1)) + 1, with |D| the total number of documents in the collection, and |di| the number of documents containing i, and ief i is the inverse element frequency of term i, i.e. log(|N |/|nf i | + 1) + 1, where |nf i | is the number of leaf nodes containing i and |N | is the total number of leaf nodes in the collection. idf i allows to model the importance of term i in the collection of documents, while ief i allows to model it in the collection of elements.</p><p>Each node n in the document tree is then assigned a relevance score r n which is function of the relevance scores of the leaf nodes it contains and of the relevance value of the whole document.</p><formula xml:id="formula_1" coords="3,161.72,335.76,351.26,23.41">r n = ρ * |L r n |. ln k ∈Ln α dist(n,ln k )-1 * RSV (q, ln k ) + (1 -ρ) * r root (2)</formula><p>dist(n, ln k ) is the distance between node n and leaf node ln k in the document tree, i.e. the number of arcs that are necessary to join n and ln k , and α ∈]0..1] allows to adapt the importance of the dist parameter. In all the experiments presented in the paper, α is set to 0.6. L n is the set of leaf nodes being descendant of n, and |L r n | is the number of leaf nodes in L n having a non-zero relevance value (according to equation 1). ρ ∈]0..1], inspired from work presented in <ref type="bibr" coords="3,90.00,429.49,14.58,9.96" target="#b10">[11]</ref>, allows the introduction of document relevance in inner nodes relevance evaluation, and r root is the relevance score of the root element, i.e. the relevance score of the whole document, evaluated with equation 2 with ρ = 1.</p><p>Finally, the documents d j containing relevant nodes are retrieved with the following relevance score:</p><formula xml:id="formula_2" coords="3,248.16,501.23,264.82,10.39">r xf irm (d j ) = max n∈dj r n<label>(3)</label></formula><p>Images associated to the documents are lastly returned by the system to answer to the retrieval tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Image queries processing</head><p>To process image queries, we used a third-steps method: (1) a first step processes images using the Fire System <ref type="bibr" coords="3,162.53,609.49,9.94,9.96" target="#b2">[3]</ref>, (2) we then use pseudo-relevance feedback to construct new textual queries , (3) the new textual queries are processed with the XFIRM system.</p><p>We first used the Fire system to get the top K similar images to the image query. We then get the N associated textual documents (with N ≤ K, because some images do not have associated textual information) and extracted the top L terms from them. To select the top L terms, we evaluated two formula to express the weight w i of term t i .</p><p>The first formula uses the frequency of term t i in the N documents.</p><formula xml:id="formula_3" coords="3,274.73,725.96,238.24,30.53">w i = N j=1 tf j i (4)</formula><p>where tf j i is the frequency of term t i in document d j . The second formula uses terms frequency in the N selected documents, the number of documents in the N selected containing the term, and a normalized idf of the term in the whole collection.</p><formula xml:id="formula_4" coords="4,221.24,156.54,291.74,30.53">w i = [1 + log( N j=1 tf j i )] * n i N * log( D di ) log(D)<label>(5)</label></formula><p>where n i is the number of documents in the N associated documents containing the term t i , D is the number of all documents in the collection and d i is the number of documents in the collection containing t i . The use of the ni N parameter is based on the following idea: a term occuring one time in n documents is more important and must be more relevant than a term occuring n times in one document. The log function is used on N j=1 tf j i because without it results with or without the ni N parameter were almost the same.</p><p>We then construct a new textual query with the top L terms selected according to formula 4 or 5 and we process it using the XFIRM system (as explained in section 2).</p><p>In the photographic retrieval task, we obtained the following queries for topic Q48, with K = 5 and L &lt;= 5: Textual query using equation 4: "south korea river" Textual query using equation 5: "south korea night forklift australia"</p><p>The original textual query in english was: "vehicle in South Korea". As we can see, the query using equation 5 is more similar to the original query than the one using equation 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Combination function</head><p>To evaluate the interest of using both content and context information, we combined results of image queries and textual queries processing and we evaluated new relevance scores r(d j ) for documents d j :</p><formula xml:id="formula_5" coords="4,199.62,476.34,313.35,10.39">r(d j ) = λ * (r xf irm (d j )) + (1 -λ) * (r P RF (d j ))<label>(6)</label></formula><p>where r xf irm (d j ) is the relevance score of document d j according to the XFIRM system (equation 3) and r P RF (d j ) is the relevance score of d j according to the XFIRM system after image queries processing (see section 3).</p><p>In order to answer to both retrieval tasks, we then return all images associated to the top ranked documents.</p><p>Figure <ref type="figure" coords="4,136.36,566.01,4.97,9.96">1</ref> illustrates our approach. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Final documents results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Documents and their associated relevance scores</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Images associated to documents</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Final images results</head><p>Figure <ref type="figure" coords="5,208.34,504.00,3.87,9.96">1</ref>: Query processing with the combinate approach 5 Evaluation and results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Photographic Retrieval Task</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1">Evaluation of textual queries</head><p>We evaluated english textual queries using the XFIRM system with parameters ρ = 0.9 and ρ = 1. Results, which are almost the same, are presented in table We notice that the use of term frequency in selected documents is not enough, and that the importance of the term in the collection need to be used in the term weighted function (results are better with equation 5 than with equation 4).</p><p>If we now compare table 1 and table 2, we see that processing image queries with the Fire system and our pseudo-relevance feedback system gives better results than using only the XFIRM system on textual queries. It shows the importance of visual features to retrieve images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3">Combination of textual and image queries results</head><p>Table <ref type="table" coords="6,117.37,304.17,4.97,9.96">3</ref> shows our results for the combination approach.</p><p>Run-id K λ ρ Eq. MAP P10 P20 P30 BPREF GMAP Runcomb1 6 0.9 1 eq. 4 0.1039 0.1500 0.1242 0.1189 0.0915 0.0311 Runcomb2 15 0.9 0.9 eq. 5 0.1091 0.1433 0.1292 0.1267 0.0969 0.0291 Runcomb3 15 0.5 1 eq. 5 0.1354 0.2217 0.1983 0.1839 0.1402 0.0351 Runcomb4 15 0.9 1 eq. 5 0.1308 0.2100 0.1983 0.1867 0.1454 0.0264 Table <ref type="table" coords="6,223.69,396.91,3.87,9.96">3</ref>: Results using the combination function Let us first compare runs Runcomb1 and Runcomb4, which use eq. 4 and K=6, and eq. 5 and K=15. For both, we use ρ = 1, L=5 and λ = 0.9 for the combination. Results show that using eq. 5 with K=15 is more efficient that eq. 4 with K=6, which confirms results obtained using only image queries..</p><p>In order to evaluate the combination function, we then use eq. 5, and fix ρ = 1, K=15 and L=5. We test λ = 0.5 and λ = 0.9 (runs Runcomb3 and Runcomb4). Results are almost the same but combining equally the two sources of evidence gives slightly better results.</p><p>Finally, we vary ρ = 0, 9 and ρ = 1, and fix equation 5, λ = 0.9 in equation 6, K =15, L=5 (runs Runcomb4 and Runcomb2). Better results are obtained with ρ = 1, which means that the document relevance should not be taken into account in the evaluation of inner nodes relevance values (equation 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Medical Retrieval Task</head><p>For this task, we only evaluated the combination method described in section 4. RunComb09 uses equation 5 with ρ = 1, K=15, L=10 and λ = 0.9. RunComb05 uses equation 4 with ρ=1, K=6, L=5 and λ = 0.5. Results are significantly better for run RunComb09. However, as many parameters are involved (K, L, λ and the equation used to select terms) it is difficult to conclude on which parameters impact the results. Further experiments are thus needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>Increasing the number of textual information resources to construct new textual queries from image queries improves results: the K number of selected images from FIRE results has a great impact on results. Increasing K improves thus results by introducing relevant information. Another factor of influence on results is the number of new query terms L. In our experiments, when K and L increase, the MAP metric also increases. Moreover, processing textual queries or images separately does not allow to obtain the best results: combining the two sources of evidence clearly improves results.</p><p>Finally, we'd like to conclude with the type of textual information used. In the Medical and Photographic Retrieval Tasks, textual information is encoded using the XML language, and as a consequence, we decided to use an XML-oriented information retrieval system to process textual queries (XFIRM). However, elements are not organized in a hierarchic way as in can be the case in XML documents (no ancestor-descendant relationships between nodes), and the functions used by the XFIRM system to evaluate nodes relevance may not be appropriate in that case. Other experiments are consequently needed with a plain-text information retrieval system. Combining the XFIRM system with the FIRE system may be however interesting with fully encoded-XML collections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion and future work</head><p>We participated in the Photographic and Medical Retrieval Tasks of ImageCLEF 2007 in order to evaluate a method using a content-and context-based approach to answer to topics. We proposed a new pseudo-relevance feedback approach to process image queries and we tested an XML oriented system to process textual queries. Results showed the interest of combining the two sources of evidence (content and context) to answer to image retrieval.</p><p>In future work, we plan to:</p><p>• Add low level features results extracted from FIRE to the combination function in the Medical Retrieval Task, as visual features are very important in the medical domain.</p><p>• Sort images using concepts level features <ref type="bibr" coords="7,296.26,490.80,15.48,9.96" target="#b14">[15]</ref> instead of low level features to construct new textual queries in the Photographic Retrieval Task.</p><p>• Use a specific domain ontology to expand textual queries (original textual queries and queries obtained with our pseudo-relevance feedback approach).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,117.78,155.14,9.21,24.92;5,117.78,130.25,9.21,22.35;5,214.01,142.44,47.86,9.21;5,139.24,273.45,54.22,7.64;5,181.33,230.95,9.21,28.90;5,206.28,242.02,9.21,18.36;5,206.28,225.04,9.21,14.43;5,273.42,258.91,48.42,7.64;5,311.48,135.30,16.04,6.17;5,311.48,142.48,19.34,6.17;5,343.34,171.85,67.05,7.64;5,421.96,132.66,46.87,9.21;5,416.22,143.43,60.88,9.21;5,418.82,186.48,50.09,7.64;5,121.19,339.17,9.21,29.46;5,121.19,311.81,9.21,22.35;5,219.12,331.52,50.09,7.64;5,410.92,241.31,52.16,7.64;5,410.92,250.29,52.16,7.64;5,410.92,259.26,56.32,7.64;5,397.46,287.54,50.74,42.20;5,418.46,304.95,21.03,20.57"><head></head><label></label><figDesc>e a r c o m b in a t io n f u n c t io n</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,90.00,620.88,395.79,134.05"><head>Table 1 :</head><label>1</label><figDesc>1. Textual queries results using the XFIRM system5.1.2 Evaluation of image queriesTable2shows results using the two formula described in section 3.</figDesc><table coords="5,114.44,643.14,371.35,34.27"><row><cell>Run-id</cell><cell>ρ</cell><cell>MAP</cell><cell>P10</cell><cell>P20</cell><cell>P30</cell><cell cols="2">BPREF GMAP</cell></row><row><cell>RunText0609</cell><cell>0.9</cell><cell>0.0634</cell><cell>0.1400</cell><cell>0.1175</cell><cell>0.1133</cell><cell>0.0719</cell><cell>0.0039</cell></row><row><cell>RunText061</cell><cell>1</cell><cell>0.0633</cell><cell>0.1400</cell><cell>0.1175</cell><cell>0.1128</cell><cell>0.0719</cell><cell>0.0039</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,90.00,168.28,422.59,9.96"><head>Table 2 :</head><label>2</label><figDesc>Image queries results using pseudo-relevance feedback with the FIRE and XFIRM systems</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,96.37,633.22,413.54,56.13"><head>Table 4 :</head><label>4</label><figDesc>Results of the Medical retrieval task</figDesc><table coords="6,96.37,633.22,413.54,34.27"><row><cell>-id</cell><cell>Eq.</cell><cell>L</cell><cell>K</cell><cell>λ</cell><cell>MAP</cell><cell>R-prec</cell><cell>P10</cell><cell>P30</cell><cell>P100</cell></row><row><cell>RunComb09</cell><cell>eq. 5</cell><cell>10</cell><cell>15</cell><cell>0.9</cell><cell cols="2">0.1297 0.1687</cell><cell>0.2100</cell><cell>0.2122</cell><cell>0.1893</cell></row><row><cell>RunComb05</cell><cell>eq. 4</cell><cell>5</cell><cell>6</cell><cell>0.5</cell><cell>0.066</cell><cell cols="2">0.0.0996 0.0833</cell><cell>0.11</cell><cell>0.1023</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,110.46,589.41,402.16,9.96;7,110.47,601.36,308.25,9.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,343.61,589.41,169.02,9.96;7,110.47,601.36,108.07,9.96">A cross-media adaptation strategy for multimedia presentations</title>
		<author>
			<persName coords=""><forename type="first">Susanne</forename><surname>Boll</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wolfgang</forename><surname>Klas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jochen</forename><surname>Wandel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,239.71,601.36,75.38,9.96">ACM Multimedia</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="37" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.46,621.29,402.14,9.96;7,110.47,633.24,328.49,9.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,360.25,621.29,152.35,9.96;7,110.47,633.24,184.36,9.96">A corpus-based relevance feedback approach to cross-language image retrieval</title>
		<author>
			<persName coords=""><forename type="first">Yih-Chen</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wen-Cheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hsin-Hsi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,315.56,633.24,23.50,9.96">CLEF</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="592" to="601" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.46,653.16,402.18,9.96;7,110.47,665.13,221.48,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,281.27,653.16,231.37,9.96;7,110.47,665.13,66.17,9.96">FIRE -flexible image retrieval engine: ImageCLEF 2004 evaluation</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,197.83,665.13,73.34,9.96">CLEF Workshop</title>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.46,685.05,402.15,9.96;7,110.47,697.00,402.10,9.96;7,110.47,708.96,148.00,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,110.47,697.00,241.43,9.96">The clef 2005 automatic medical image annotation task</title>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Mller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clogh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">M</forename><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,360.74,697.00,151.84,9.96;7,110.47,708.96,26.58,9.96">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="58" />
			<date type="published" when="2007-08">August 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.46,728.88,397.18,9.96" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Fuhr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mounia Lalmas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Malik</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Kazai</surname></persName>
		</author>
		<title level="m" coord="7,332.08,728.88,145.14,9.96">INEX 2005 workshop proceedings</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.46,111.36,402.18,9.96;8,110.47,123.31,402.19,9.96;8,110.47,135.26,161.97,9.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,440.45,111.36,72.19,9.96;8,110.47,123.31,191.79,9.96">Overview of the ImageCLEF 2007 photographic retrieval task</title>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,320.87,123.31,186.69,9.96">Working Notes of the 2007 CLEF Workshop</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">September 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.46,155.19,402.17,9.96;8,110.47,167.15,402.13,9.96;8,110.47,179.10,253.68,9.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,190.18,167.15,322.42,9.96;8,110.47,179.10,109.55,9.96">Dublin city university at clef 2004: Experiments in monolingual, bilingual and multilingual retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Gareth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anna</forename><surname>Judge</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Khasin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Adenike</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joachim</forename><surname>Lam-Adesina</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,240.74,179.10,23.50,9.96">CLEF</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="207" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.46,199.02,402.15,9.96;8,110.47,210.98,402.12,9.96;8,110.47,222.94,187.87,9.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,363.53,199.02,149.08,9.96;8,110.47,210.98,190.70,9.96">Integrating textual and visual information for cross-language image retrieval</title>
		<author>
			<persName coords=""><forename type="first">Wen-Cheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yih-Chen</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hsin-Hsi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,322.38,210.98,190.21,9.96;8,110.47,222.94,88.66,9.96">Proceedings of the Second Asia Information Retrieval Symposium</title>
		<meeting>the Second Asia Information Retrieval Symposium</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="454" to="466" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.46,242.86,402.13,9.96;8,110.47,254.82,402.12,9.96;8,110.47,266.77,131.98,9.96" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,355.14,242.86,157.45,9.96;8,110.47,254.82,338.46,9.96">Integrating textual and visual information for cross-language image retrieval: A trans-media dictionary approach</title>
		<author>
			<persName coords=""><forename type="first">Wen-Cheng</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yih-Chen</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hsin-Hsi</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,458.52,254.82,54.07,9.96;8,110.47,266.77,34.70,9.96">Inf. Process. Manage</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="488" to="502" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.46,286.69,402.15,9.96;8,110.47,298.65,402.14,9.96;8,110.47,310.61,296.79,9.96" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,441.62,286.69,70.99,9.96;8,110.47,298.65,300.79,9.96">Ipal inter-media pseudo-relevance feedback approach to imageclef 2006 photo retrieval</title>
		<author>
			<persName coords=""><forename type="first">Nicolas</forename><surname>Maillot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean-Pierre</forename><surname>Chevallet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vlad</forename><surname>Valea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joo Hwee</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,431.81,298.65,80.81,9.96;8,110.47,310.61,111.71,9.96">Working Notes for the CLEF 2006 Workshop</title>
		<meeting><address><addrLine>Alicante, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-09-22">20-22 September. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.46,330.53,402.14,9.96;8,110.47,342.48,39.93,9.96" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="8,266.08,330.53,229.74,9.96">Experimenting various user models for XML retrieval</title>
		<author>
			<persName coords=""><forename type="first">Yosi</forename><surname>Mass</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matan</forename><surname>Mandelbrod</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.46,362.41,402.15,9.96;8,110.47,374.36,187.86,9.96" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="8,278.66,362.41,233.94,9.96;8,110.47,374.36,157.22,9.96">Image-to-word transformation based on dividing and vector quantizing images with words</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Takahashi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Oka</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.46,394.29,402.14,9.96;8,110.47,406.25,402.16,9.96;8,110.47,418.20,402.17,9.96;8,110.47,430.15,114.77,9.96" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,306.25,406.25,206.38,9.96;8,110.47,418.20,131.01,9.96">Overview of the ImageCLEFmed 2007 medical retrieval and annotation tasks</title>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eugene</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jayashree</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">M</forename><surname>Deserno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,264.75,418.20,194.90,9.96">Working Notes of the 2007 CLEF Workshop</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">September 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.46,450.08,402.13,9.96;8,110.48,462.04,335.83,9.96" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Karen</forename><surname>Sauvagnat</surname></persName>
		</author>
		<title level="m" coord="8,195.01,450.08,317.58,9.96;8,110.48,462.04,89.51,9.96">Modle flexible pour la recherche d&apos;information dans des corpus de documents semi-structurs</title>
		<meeting><address><addrLine>Toulouse</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>Paul Sabatier University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="8,110.46,481.97,402.19,9.96;8,110.48,493.92,402.13,9.96;8,110.48,505.87,402.16,9.96;8,110.48,517.83,360.75,9.96" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,193.87,493.92,318.74,9.96;8,110.48,505.87,59.43,9.96">The challenge problem for automated detection of 101 semantic concepts in multimedia</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">M</forename><surname>Cees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marcel</forename><surname>Snoek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jan</forename><forename type="middle">C</forename><surname>Worring</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jan-Mark</forename><surname>Van Gemert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Arnold</forename><forename type="middle">W M</forename><surname>Geusebroek</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Smeulders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,194.85,505.87,317.79,9.96;8,110.48,517.83,109.37,9.96">MULTIMEDIA &apos;06: Proceedings of the 14th annual ACM international conference on Multimedia</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="421" to="430" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.46,537.76,402.14,9.96;8,110.48,549.71,366.93,9.96" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="8,194.95,537.76,176.00,9.96">Image retrieval: Content versus context</title>
		<author>
			<persName coords=""><forename type="first">Thijs</forename><surname>Westerveld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,396.08,537.76,116.52,9.96;8,110.48,549.71,242.77,9.96">Content-Based Multimedia Information Access</title>
		<imprint>
			<date type="published" when="2000-04">April 2000</date>
			<biblScope unit="page" from="276" to="284" />
		</imprint>
	</monogr>
	<note>RIAO 2000 Conference Proceedings</note>
</biblStruct>

<biblStruct coords="8,110.46,569.64,402.16,9.96;8,110.47,581.59,156.43,9.96" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="8,223.56,569.64,289.05,9.96;8,110.47,581.59,126.36,9.96">Narrowing the semantic gap -improved text-based web document retrieval using visual features</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Grosky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
