<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,146.01,146.21,310.96,18.08;1,207.64,168.13,187.72,18.08">XRCE&apos;s Participation to CLEF 2007 Domain-specific Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,202.25,203.19,85.24,10.46"><forename type="first">Stephane</forename><surname>Clinchant</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xerox Research Centre Europe</orgName>
								<address>
									<addrLine>6 ch. de Maupertuis</addrLine>
									<postCode>38240</postCode>
									<settlement>Meylan</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,310.18,203.19,90.58,10.46"><forename type="first">Jean-Michel</forename><surname>Renders</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Xerox Research Centre Europe</orgName>
								<address>
									<addrLine>6 ch. de Maupertuis</addrLine>
									<postCode>38240</postCode>
									<settlement>Meylan</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,146.01,146.21,310.96,18.08;1,207.64,168.13,187.72,18.08">XRCE&apos;s Participation to CLEF 2007 Domain-specific Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C7CFEC3428FE18419D2165BCF2EFF697</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Managment]: Languages-Query Languages Measurement, Performance, Experimentation Domain-specific IR, Lexicon Extraction, Query Translation and Disambiguation, Dictionary Adaptation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Our participation to CLEF07 (Domain-specific Track)  was motivated this year by assessing several query translation and expansion strategies that we recently designed and developed. One line of research and development was to use our own Statistical Machine Translation system (called Matrax) and its intermediate outputs to perform query translation and disambiguation. Our idea was to benefit from Matrax' flexibility to output more than one plausible translations and to train its Language Model component on the CLEF07 target corpora. The second line of research consisted in designing algorithms to adapt an initial, general probabilistic dictionary to a particular pair (query, target corpus); this constitutes some extreme viewpoint on the "bilingual lexicon extraction and adaptation" topic that we are investigating since now more than 6 years. For this strategy, our main contributions lie in a pseudo-feedback algorithm and an EM-like optimisation algorithm that realize this adaptation. A third axis was to evaluate the potential impact of "Lexical Entailment" models in a cross-lingual framework, as they were only used in a monolingual setting up to now. Experimental results on CLEF-2007 corpora (domain-specific track)  show that the dictionary adaptation mechanisms appear quite effective in the CLIR framework, exceeding in certain cases the performance of much more complex Machine Translation systems and even the performance of the monolingual baseline. In most cases also, Lexical Entailment models, used as query expansion mechanisms, turned out to be beneficial.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction : Query Translation and Disambiguation</head><p>We can distinguish at least two families to perform query translation. The first one is to use Machine Translation systems (such as Babylon, Systran, etc.); the second one is to rely on multilingual dictionaries or lexicons. Machine Translations systems aims at translating a source sentence into a target sentence. MT systems are built to produce well formed grammatical sentences. However, most information retrieval models (or user's queries) do not rely today on proper syntax: this is the bag of words hypothesis. A query is a set of terms and no use is made about the order or the syntax in the query, if it exists. One need not translate properly the query into a correct sentence, a rough term-to-term translation can be sufficient to capture the concept of a query. Hence, termto-term translations rely on bilingual dictionaries and cross-lingual information retrieval has been concerned with the extraction of bilingual dictionaries on the one hand, and with algorithms to obtain the best translation of a query from a dictionary on the other hand.</p><p>The first and naive use of a dictionary, is to use all translations -possibly weighted -of a query word. Albeit simple, this approach does not address the polysemy of words. A classical example is the translation of the english word bank. Bank can refer either to a financial institution or to the edge of a river. Choosing the right translation of a query term can be obvious with the context of the complete query. If one was to translate the word bank in a query and also observe the word account, then the translation is no longer ambiguous. Note though that the retrieval process is a disambiguating process in itself, in that spurious translations are generally filtered out simply by the fact that it is very unlikely that they co-occur with other translations. Several approaches <ref type="bibr" coords="2,142.33,313.77,15.50,10.46" target="#b14">[15,</ref><ref type="bibr" coords="2,162.21,313.77,12.73,10.46" target="#b11">12,</ref><ref type="bibr" coords="2,179.31,313.77,7.75,10.46" target="#b7">8,</ref><ref type="bibr" coords="2,191.44,313.77,12.73,10.46" target="#b12">13,</ref><ref type="bibr" coords="2,208.54,313.77,12.73,10.46" target="#b13">14,</ref><ref type="bibr" coords="2,225.65,313.77,7.75,10.46" target="#b8">9]</ref> resolve the translation of query with the notion of coherence. Each query term has candidate translation terms and a co-occurrence statistics can be computed between all the candidate translation terms; then an optimisation algorithm is used to solve some maximum coherence problem. The idea is that the query defines a lexical field. The more likely a candidate belongs to the lexical field, the better it is for translation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Cross-lingual Information Retrieval and Language Modelling</head><p>We will first introduce the standard monolingual language modeling approach to information retrieval. Then, we will present the classical extensions to cross-lingual information retrieval.</p><p>The core idea of language models is to determine the probability P (q|d) -the probability that the query would be generated from a particular document. Formally, given a query q, the language model approach to IR <ref type="bibr" coords="2,188.95,482.12,15.50,10.46" target="#b16">[17]</ref> scores documents d by estimating P (q|d), the probability of the query according to some language model of the document. Using some independence assumption, for a query q = {q 1 , . . . q }, we get:</p><formula xml:id="formula_0" coords="2,256.42,527.80,90.15,21.63">P (q|d) = i=1 P (q i |d).</formula><p>(</p><p>We assume that for each document there exists some parameter θ d , which is a probability distribution over words -a language model. Abusively we note P (q|d) ≡ P (q|θ d ). Standard language models in information retrieval are multinomial distributions : the language model of a document is defined by its parameter vector θ d , whose dimension is the size of the vocabulary. As this multinomial parameter is normalized (the sum of its components sums up to one), another notation is used : θ dw = P (w|d).</p><p>For each document d, a simple language model could be obtained by considering the frequency of words in d, P M L (w|d) ∝ #(w, d) (this is the Maximum Likelihood, or ML, estimator). The probabilities are smoothed by the corpus language model P M L (w|C) ∝ d #(w, d). The resulting language model is:</p><formula xml:id="formula_2" coords="2,207.89,674.00,300.87,11.35">P (w|d) = λ P M L (w|d) + (1 -λ) P M L (w|C). (<label>2</label></formula><formula xml:id="formula_3" coords="2,508.76,674.00,4.24,10.46">)</formula><p>The reasons of smoothing are twofold: first a word can be present in a query but absent in a document. However this fact does not make it impossible and the document should give it a probability. The second reason is to play a role like the Inverse Document Frequency. Smoothing enables implicitly to renormalize the frequency of one word in a document with respect to its occurrence in the corpus. Others smoothing methods could be applied (Dirichlet smoothing, Absolute Discounting, ...) and can be found in <ref type="bibr" coords="3,313.15,110.53,14.61,10.46" target="#b19">[20]</ref>. The Query Likelihood approach above gives an intuitive view of how language models works in information retrieval. Others equivalent ranking functions can be considered and lead to the same ranking function as the Query Likelihood formulation. For example the KL-divergence and the Cross-Entropy functions can also be used in information retrieval. Let θ q be a multinomial parameter for the language model of a query q, θ d the language model for a document d, the cross-entropy function between these two objects is:</p><formula xml:id="formula_4" coords="3,181.71,192.79,331.29,21.32">CE(θ q |θ d ) = w P (w|q) log(P (w|d)) = w θ qw log(θ dw )<label>(3)</label></formula><p>As far as cross-lingual IR is concerned, the core idea remains the same: modeling the probability of the query given the document. Let q s be the query in some source language, w s a word in the source language, d t a document in the target language, w t a word in the target language, P (w t |w s ) the probability that word w s is translated into w t . We can distinguish two methods:</p><p>The first method, we will refer as CL LM1, translates the query into a query language model in the target language <ref type="bibr" coords="3,192.60,282.01,14.61,10.46" target="#b11">[12]</ref>. Then a monolingual search is performed, using a ranking criterion such as the Cross-Entropy:</p><formula xml:id="formula_5" coords="3,181.64,326.96,331.36,91.87">CE(q s |d t ) = w t P (w t |q s ) log P (w t |d t ) = w t ,w s P (w t |w s , q s )P (w s |q s ) log P (w t |d t ) ∼ = wt,ws P (w t |w s )P (w s |q s ) log P (w t |d t )<label>(4)</label></formula><p>The second model, we will refer as CL LM2 <ref type="bibr" coords="3,292.19,429.40,17.00,10.46" target="#b1">[2,</ref><ref type="bibr" coords="3,312.10,429.40,11.62,10.46" target="#b10">11]</ref>, models the translation from the document side : a language model of the document is built in the source language and compared to the query:</p><formula xml:id="formula_6" coords="3,180.46,475.79,332.53,49.82">CE(q s |d t ) = ws P (w s |q s ) log P (w s |d t ) ∼ = w s P (w s |q s ) log( w t P (w s |w t )P (w t |d t ))<label>(5)</label></formula><p>Both models are based on probabilistic dictionaries, but the first model uses a dictionary from source language to target language, whereas the second model uses a dictionary from target to source. In CL LM1, the translation process in independent of the document, whereas, in CL LM2, one tries to model the probability that a particular document is translated and "distilled" into the original query.</p><p>In the following part of this report, we will adopt the viewpoint of model CL LM1 for two reasons: first it is simpler to use because it just requires a monolingual retrieval system, unlike CL LM2 which need a devoted cross-lingual system. The second reason is a benchmarking one : we wanted to compare our results with Machine Translation tools, which operate in that direction (translate the query from source to target) for obvious practical reasons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Dictionary Adaptation</head><p>The main idea of dictionary adaptation is to be able to adapt the entries of a dictionary to a query and a target corpus. Formally, let q s = (w s1 , . . . , w sl ) be the query in source language. Ideally, we are looking for P (w t |q s ), the probability of a target term given the source query. As we adopt the CL LM1 model, this leads us to focus on P (w t |w s , q), which is the probability that source term w s tranlates to w t , given the context of the query. Computing this probability would need to clearly define the context of a query, or its associated "concept". The next question is how can we find the context of the query in the target language? We argue that relevant documents in target language contain such an information. In other words, the coherence is implicitly present in relevant documents. Even if relevant documents are obviously not known in advance, they can be found by active relevance feedback or pseudo-relevance feedback (PRF). Hence, our algorithm will adapt the probabilities in the dictionary based on the set of (pseudo) relevant documents. Before going into the details of this adaptation mechanism, let us first review monolingual PRF techniques in the framework of Language Modelling-based retrieval. Their extension to the cross-lingual case will provide us with the adaptation method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Monolingual PRF within the language modeling framework</head><p>Traditional methods, such as Rocchio's algorithm, extract terms from feedback documents and add them to the query. The language modeling approach to information retrieval goes beyond this approach: it extracts a probability distribution over words from the feedback documents. We shall first present the general setting for pseudo-feedback with monolingual language models.</p><p>• Let C be a corpus, d k a document of the corpus.</p><p>• Let n the number of top documents selected after a first retrieval.</p><p>• F = (d 1 , . . . , d n ) the feedback documents.</p><p>• Let θ F , a multinomial parameter, standing for the distribution of relevant terms in F: in other words θ F is a probability distribution over words peaked on relevant terms.</p><p>Feedback methods have two aspects: first extracting relevant information (identification of θ F ) and, secondly, enriching the query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Estimation of θ F</head><p>To estimate θ F from feedback documents F, we present as an example the method of Zhai and Lafferty <ref type="bibr" coords="4,127.53,480.06,14.61,10.46" target="#b20">[21]</ref>. They propose the following generative process for F:</p><p>• For i from 1 to n, draw document d i following the distribution:</p><formula xml:id="formula_7" coords="4,126.12,519.91,197.65,11.96">-d i ∼ M ultinomial(l d i , λθ F + (1 -λ)p(.|C))</formula><p>so that we have the following global likelihood:</p><formula xml:id="formula_8" coords="4,199.91,561.61,313.09,23.43">P (F|θ) = k w (λθ F w + (1 -λ)P (w|C)) c(w,d k )<label>(6)</label></formula><p>P (w|C) is word probability built upon the corpus, λ is a fixed parameter, which can be understood as a noise parameter for the distribution of terms. c(w, d k ) is the number of occurence of term w in document d k . Finally θ F is learned by optimising the data loglikelihood with an Expectation Maximization algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Updating the original query</head><p>Now suppose the relevant language model θ F has been estimated; how can we add the information from the feedback to the query? Within the language model approach to IR, a query is represented as a probability distribution over words (in practice a multinomial distribution which is estimated from maximum likelihood). If θ Q is the multinomial parameter for a query Q, then the MLestimation of θ Qw is equal to the proportion of words w in the query Q. To come back with the initial question of how to combine information from the initial query and feedback documents, a simple method is to simply mix the parameters of their distributions:</p><formula xml:id="formula_9" coords="5,222.25,144.41,290.75,11.35">θ new query = αθ old query + (1 -α)θ F (7)</formula><p>In practice, we restrict θ F to their top N words, by considering all other values of this vector as null.</p><p>We can note that more elaborated techniques exists in <ref type="bibr" coords="5,353.72,190.24,14.61,10.46" target="#b17">[18]</ref>. Setting the value of α is done experimentally and adapted to collections. The robustness of the estimation of θ F has a significant impact on the value of α. Lastly, the value of α could be understood as a trade off between precision and recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Extension to the Cross-lingual case: Dictionary Adaptation</head><p>We generalize the monolingual mixture model for feedback to the case of CLIR: the input data are an initial source query language model p(w s |q s ) and a first dictionary p(w t |w s ). The monolingual mixture model can be interpreted as follows: for each term in a document, first choose between the relevant topic model or the corpus language model. Then generate the frequency of the term from the chosen mixture component. We extend this process, by choosing either a source query term w s (instead of the relevant topic model), or the target corpus (C) language model, for each term in a feedback document. If a query term w s has been chosen, then a target term w t is generated with some unkown (ideal) probabilistic dictionary. Mathematically, this gives:</p><p>• For i from 1 to n, draw document d i with:</p><formula xml:id="formula_10" coords="5,126.12,397.92,254.85,13.45">-d i ∼ M ultinomial(l d i , λ w s θ s p(w s |q s ) + (1 -λ)p(.|C))</formula><p>where</p><formula xml:id="formula_11" coords="5,118.81,419.83,140.27,11.96">l d i is the length of document d i .</formula><p>In this framework, θ s can be interpreted as an adapted probability of translation : θ st ≡ p(w t |w s , q s ). But is can be interpreted too as a probability distribution (multinomial parameter) over the vocabulary of target terms; it is like a language model, but associated to a specific word w s . To understand the connections between the monolingual model and the bilingual model, we can make an analogy of this form : θ F ≡ w s θ s p(w s |q s ). Note that the same algorithm realizes both the query enrichment and the dictionary adaptation. Note also that the translation/adaptation is limited to the words of the query (w s ) if we adopt a simple maximum likelihood language model for the query (what is assumed in the following). Lastly, but importantly, the role of the initial (probabilistic), non-adapted dictionary relies in providing the algorithm with a good starting candidate solution for θ s .</p><p>From this generative process, it remains to solve the problems of estimating the parameters (θ s ) w s ∈Q and of generating the new query language model (on the target side).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Estimation of adapted translation probabilities</head><p>We now proceed to the estimation of the parameters (θ s ) ws∈Q with maximum likelihood approach using an EM-like algorithm. Recall that, as in the monolingual setting, λ is a fixed parameter and p(w s |q s ) is also known since it represents the distribution of words in a particular query.</p><p>First, the model likelihood can be written in the equivalent form:</p><formula xml:id="formula_12" coords="5,167.80,664.11,345.20,25.31">P (F|θ) = k wt λ( ws θ st p(w s |q s ) + (1 -λ)P (w t |C) c(w t ,d k )<label>(8)</label></formula><p>We can maximize the log-likelihood with an EM algorithm. Let t wd the hidden random variable whose value is 1 if word w in document d has been generated by p(.|C). Let r ws be the indicator for which query word has been chosen. Let θ ts = p(w t |w s , q s ) be the unknown parameter of this model.</p><p>The E-step gives:</p><formula xml:id="formula_13" coords="6,174.45,130.90,338.55,51.69">p(t wd = 1|F, θ (i) ) = (1 -λ)p(w t |C) λ( ws θ (i) ts p(w s |q s ) + (1 -λ)P (w t |C) (9) p(t wd = 0|F, θ (i) ) = 1 -p(t wd = 1|F, θ (i) )<label>(10)</label></formula><p>Then, r ws is only defined for t wd = 0:</p><formula xml:id="formula_14" coords="6,204.39,209.84,308.61,14.94">p(r ws = k|F, θ (i) , t wd = 0) ∝ p(w s = k|q s )θ (i) ts (11)</formula><p>As usual, in the M-step, we try to optimize a lower bound of the expected log-likelihood :</p><formula xml:id="formula_15" coords="6,132.63,257.18,375.94,53.27">Q(θ (i+1) , θ (i) ) = d,w c(w, d) p(t wd = 1|θ (i) ) log((1 -λ)p(w|C)) + p(t wd = 0|θ (i) ) w s p(r ws = k|θ (i) ) log(p(w s = k|q s )θ (i+1) ts ) (<label>12</label></formula><formula xml:id="formula_16" coords="6,508.57,288.52,4.43,10.46">)</formula><p>Differentiating w.r.t. θ (i+1) and adding Lagrange multiplier (for w t θ ts = 1) gives the M-step:</p><formula xml:id="formula_17" coords="6,165.31,344.55,347.69,24.48">θ (i+1) ts ∝ d c(w t , d)p(t wd = 0|F, θ (i) )p(r ws = k|F, θ (i) , t wd = 0)<label>(13)</label></formula><p>As already mentioned, θ (0) is given by the corresponding part of an initial (probabilistic), non-adapted dictionary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Query Update</head><p>When the algorithm converges giving some optimal θ (adapted) parameters, a new query can be generated by using all entries in the adapted dictionary ((θ adapted s ) ws∈Q ), so no selection method, nor threshold is required to compute the new query. To make the analogy with monolingual IR we do not use a parameter like α or, in a sense, we use α = 1, since we only use the dictionary learnt by feedback. The new query language model becomes:</p><formula xml:id="formula_18" coords="6,232.17,505.14,280.82,24.17">P (w t |q s ) = w s θ adapted st P (w s |q s )<label>(14)</label></formula><p>In others words, model CL LM1 with p(w t |w s ) = θ adapted st is used to perform the retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Remarks</head><p>The initial dictionary is used as the starting point for the EM algorithm. As a consequence, only non zero entries are used in this algorithm. During the iterations of the EM, the dictionary weights are adapted to fit the feedback documents and hence to choose the correct translations for a query.</p><p>In the introduction to dictionary adaptation we argued that one should model the probability P (w t |w s , q). In the model represented by equation 4, we made an independence assumptions which discard the query q from this latter probability. However, the query q is implicitly present in the feedback documents, which enables to learn translation probabilities from the context of the query. <ref type="bibr" coords="6,90.01,671.39,15.50,10.46" target="#b10">[11]</ref> propose a feedback method for CL LM2 relying also on dictionary adaptation. Our method is an extension of the classical monolingual mixture model for feedback to the cross-lingual case, which is also a natural feedback method for CL LM1. However, Hiemstra and al. <ref type="bibr" coords="6,442.34,695.30,15.50,10.46" target="#b10">[11]</ref> experiments show that their model were unable to perform pseudo-relevance feedback, but was very good with active relevance feedback.</p><p>Lexical Entailment (LE) <ref type="bibr" coords="7,203.72,132.36,10.52,10.46" target="#b2">[3,</ref><ref type="bibr" coords="7,218.84,132.36,12.73,10.46" target="#b9">10,</ref><ref type="bibr" coords="7,236.18,132.36,7.75,10.46" target="#b4">5]</ref> models the probability that one term entails another, in a monolingual framework. It can be understood as a probabilistic term similarity or as a unigram language model associated to a word (rather than to a document or a query). Let u be a term in the corpus, then lexical entailment models compute a probability distribution over terms v of the corpus P (v|u). These probabilities can be used in information retrieval models to enrich queries and/or documents and to give a similar effect than the use of a semantic thesaurus. However, lexical entailment is purely automatic, by extracting statistical relationships from the considered corpus. In practice, a sparse representation of P (v|u) is adopted, where we restrict v to be one of the N max terms that are the closest from u using an Information Gain metric <ref type="foot" coords="7,432.43,226.93,3.97,7.32" target="#foot_0">1</ref> .</p><p>We refer to <ref type="bibr" coords="7,157.52,239.95,10.52,10.46" target="#b2">[3]</ref> for all technical and practical details of the method. Still one important thing to be mentioned is that the LE models P (v|u) are used as if this was a cross-lingual framework (for instance one of the CL LM1 or CL LM2 models), i.e. as if P (v|u) was a probabilitic translation matrix. If q = (q 1 , ..., q l ) and if CL LM2 is chosen, this gives using the CE criterion:</p><formula xml:id="formula_19" coords="7,201.93,296.76,311.07,21.92">CE(q|d) = q i P (q i |q) log( w P (q i |w)P (w|d))<label>(15)</label></formula><p>P (q i |w) is the result of the Lexical Entailment model, and P (w|d) is given by equation 2. We also used a slighty modified formula, introducing a background query-language smoothing P (q i |D). Instead of eq. 15, the document score is now computed as:</p><formula xml:id="formula_20" coords="7,159.38,370.31,349.19,21.92">CE(q|d) = q i P (q i |q) log(β w P (q i |w)P (w|d) + (1 -β)P (q i |D)) (<label>16</label></formula><formula xml:id="formula_21" coords="7,508.57,370.31,4.43,10.46">)</formula><p>5 Experiments on <ref type="bibr" coords="7,230.92,405.85,89.02,15.06">GIRT -2004</ref><ref type="bibr" coords="7,345.04,405.85,32.27,15.06">GIRT - to 2006</ref> We refer to the overview paper <ref type="bibr" coords="7,230.91,431.39,10.52,10.46" target="#b0">[1]</ref> for the description of the task, the corpora and the available resources (see aldo http://www.gesis.org/en/research/information technology/girt4.htm for specific information).</p><p>In order to do some preliminary tunings and validations, we used the domain-specific corpus GIRT as available in 2006 from the CLEF Evaluation Forum, as well as the 75 queries and their relevance assessments collected from the years 2004, 2005 and 2006. In the next section, we will present the results on the test data, namely the new GIRT corpus (extended on the english side, by additional documents coming from the CSA corpus) and the corresponding new queries. We used Mean Average Precision (MAP) as retrieval performance measure.</p><p>For the whole collection and the queries, we used our home-made lemmatiser and wordsegmenter (decompounder) for German. Classical stopword removal was performed. We used only the title and the description of the queries.</p><p>As multilingual resources, we used on the one hand the English-German GIRT Thesaurus (considered as domain-specific, but very narrow) and, on the other hand, a probabilistic one, called EL-RAC, that is a combination of a very standard one (ELRA) and a lexicon automatically extracted from the parallel JRC-AC (Acquis Communautaire) Corpus (see URL: langtech.jrc.it/JRC-Acquis.html) using the Giza++ word alignment algorithm.</p><p>As already mentioned, one goal of the experiments was to compare the query translation approach using dictionary adaptation with the use of our Statistical Machine Translation system (MATRAX). The latter needs two kinds of corpus: a parallel corpus for the alignment models, and a corpus in the target language to learn a "language model". We fed MATRAX with the JRC-AC (Acquis Communautaire) Corpus for the alignment models, and with out GIRT / CSA corpora (in the target language) for the language models. In this way, we can expect to introduce some bias or adaptation to our target corpus in the translation process, as the Language Model component of Matrax will favour translation and disambiguation consistent with this corpus. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Monolingual Experiments</head><p>Monolingual results enable to evaluate the performance of the cross-lingual results, being a reference to compete with. Table <ref type="table" coords="8,215.26,380.36,4.98,10.46" target="#tab_0">1</ref> shows the results of the monolingual experiments. A Dirichlet prior smoothing was used with a value of 200, and PRF was applied, using the TOP15 documents with the mixture model algorithm described in 3.1. We observe a significative difference between the behavior of the english corpus and the german one. English documents are sparser than german ones, which explains the retrieval deficiency. Table <ref type="table" coords="8,133.52,440.14,4.98,10.46">2</ref> shows monolingual experiments using lexical entailment models. We used the top 20 entailed terms (N max = 20) , for each german term, and the top 10 terms for english term (N max = 10) since the english corpus is sparser than the german one. We applied LE first on the basic query (results are given in column 2). Then the mixture model algorithm for pseudofeedback described in 3.1 is applied on the top15 documents, which provides a new query and once again the lexical entailment model is applied. The lexical entailment model using pseudo-relevance feedback will also be called PRF+Lexical Entailment, or Double Lexical Entailment (as actually the top15 documents are retrieved using a first lexical entailment step). Performance of this model is given in Column 3 of Table <ref type="table" coords="8,222.60,535.77,3.87,10.46" target="#tab_0">1</ref>. One can see that lexical entailment models perform better than the baseline monolingual models without feedback and that lexical entailment techniques provide improvment comparable (and better than) to those obtain by pseudo-relevance feedback.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Cross-lingual Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1">Baseline</head><p>Table <ref type="table" coords="8,118.78,624.36,4.98,10.46">3</ref> (column 3 -without adaptation) shows the experimental results using the dictionary adaptation algorithm. We tested the algorithm both for the English-to-German and Germanto-English translations. We also used different initial dictionaries : the first one based on the GIRT thesaurus and the second one based on ELRAC. We used model CL LM1 (cf. eq 4) for the retrieval. Recall that in model CL LM1, the query words are translated with the dictionary and then some monolingual search is performed.</p><p>This baseline used all translation candidates: this makes the queries noisy and has the consequence that any traditional monolingual relevance feedback algorithm we tried did not boost the performance of the retrieval. As the query is already noisy, it is likely that expanding it make it unstable since feedback terms are mixed with irrelevant terms issued by the naive translation.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2">Dictionary Adaptation</head><p>Then, we perform a dictionary adaptation with parameters λ = 0.5 (in equation <ref type="formula" coords="9,433.82,420.65,4.43,10.46" target="#formula_12">8</ref>) and the number of feedback documents is set to 50 ( Table <ref type="table" coords="9,276.55,432.60,3.87,10.46">3</ref>). The results show that, with dictionary adaptation, we gain in performance for every dictionary and translation sense. We obtain a global improvement ranging from 3% to 10% , and a relative improvement from 10% to 50% and an average gain of 6% for both directions and both dictionaries.</p><p>The thesaurus used is the one provided by GIRT and already performs well since it is adapted to the corpus of GIRT: there is less ambiguity in this dictionary than in the standard ELRAC dictionary. Still, the method is able to gain in precision. The interesting fact is the improvement obtained by the ELRAC dictionary after adaptation. ELRAC is a general dictionary not at all adapted to social science corpus of GIRT. The initial performance of ELRAC is worst than using the GIRT thesaurus. However, the dictionary adaptation improves a lot the query translation process( 8% avg increase in map on both direction). This shows that a general dictionary with the adequate adaptation mechanism can be used for a specialized corpus, without a huge loss compared to a domain specific dictionary. Of course, domain specific dictionaries work better but they require external resources, or comparable corpora to be extracted from, whereas general dictionaries are always more easily available. Beyond the feature of giving a more accurate translation, a second reason of these improvements is that dictionary often encodes some semantic enrichment. For example the word area can be translated in french into region, or zone.</p><p>Figure <ref type="figure" coords="9,136.38,635.84,4.98,10.46" target="#fig_1">1</ref> shows the evolution of mean average precision with an increasing number of pseudofeedback documents. This graph indicates that the algorithm seems to be very stable and robust to a large set of feedback documents. One can also notice , that much of the gain can be obtained using only the top 10 documents. We believe the stability is due to the initialization of algorithm with the previous dictionary, which make only non zeros entries serves as training data.</p><p>Figure <ref type="figure" coords="9,136.14,695.62,4.98,10.46">2</ref> shows the influence of the λ parameter. This parameter can be interpreted as a noise parameter in the feedback documents. Since, we restrain ourself to non-zero entries, a better interpretation would be as a noise parameter in the dictionary. The conclusion we can draw from this graph, is that modeling the noise is useless when only non-zero entries are used. So, the algorithm should be used with λ = 1. This parameter could have more influence if we extend the number of feedback documents to a larger value. Then, the data would be noisier. The results around the influence of the number of top documents show that they are sufficient to disambiguate the query. However, if we were to "smooth" zero entries of the dictionary (and then allow new translation candidates that were not present in the initial dictionary), this noise parameter would influence much more the performance. There are two problems acting at the same time : query translation and query enrichment. Enriching the query amounts to smoothing non zeros entries in the dictionary. We believe it is more important to solve the query translation problem first and enrich the query later (possibly with another monolingual mechanism). Hence, the λ parameter can be set to 1 without loss of performance. Table <ref type="table" coords="10,131.80,577.05,4.98,10.46" target="#tab_1">4</ref> shows the results of lexical entailment model after a first step of dictionary adaptation. To sum up, the original query is first roughly translated with an initial dictionary, then a first retrieval is done and the dictionary is adapted to the query: a new translation of the query is obtained. The baseline model is the model CL LM1 using the new translated query. Instead of using CL LM1, the others models rely on a Lexical Entailment model. As before, Simple Lex Entailment names the model CL LM2 with the lexical entailment model based on the information gain. PRF Lex Ent denotes the same model, but with a step a pseudo-feedback with the mixture model introduced previously. Once again, the lexical entailment model outperforms the baseline. One can argue that, both models CL LM1 and CL LM2 are alternatively use in the same retrieval process. This comes from historical reasons : we first developped lexical entailment model a few years ago, and dictionary adaptation model later on (for CLEF07). These two models were combined afterwards. Theoretically, it could be interesting to develop a single model tackling the multilinguality and the use of monolingual thesaurus in a single framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Experimental results on GIRT 07</head><p>We now proceed to our participation to the Domain Specific Task in CLEF 2007, on the GIRT and CSA corpora. Once again, we refer to <ref type="bibr" coords="11,279.64,144.31,15.50,10.46" target="#b15">[16]</ref> for a precise description of the task, the corpora, and the available resources. We submitted monolingual runs as well as bilingual runs, restricted to English and German. Our monolingual runs mainly rely on lexical entailment models. The bilingual runs are issued from two techniques: either query translation with our home-developed Statistical Machine Translation System called Matrax, or query translation through dictionary adaptation. Tables <ref type="table" coords="11,136.71,521.44,4.98,10.46" target="#tab_2">5</ref> and<ref type="table" coords="11,165.30,521.44,4.98,10.46">6</ref> show the main parameters of our system. If a run contains prf (respectively le), in its name then it used parameters described in table 5 (respectively table <ref type="table" coords="11,440.05,533.39,3.87,10.46">6</ref>). The item list below describes the nomenclature of our retrieval models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Parameters, Nomenclature and Monolingual Runs</head><p>• Language Model+ PRF: The standard query likelihood (or equivalently cross-entropy) approach, with the mixture model for pseudo-feedback (as explained in section 3.1);</p><p>• Lexical Entailment : the lexical model with Information Gain used in conjunction with the CL LM2 model</p><p>• Language Model + PRF + Lexical Entailment : After a first retrieval with Language Model and PRF (as in bullet 1), the enriched query is scored with a Lexical Entailment model</p><p>• PRF Lexical Entailment : this is the Double Lexical Entailment model explained before, where a first lexical entailment model is used to provide the system with an initial set of TOPn documents, from which a mixture model for pseudo-feedback is built, and a second retrieval is performed based once again on the lexical entailment model applied to the enriched query.</p><p>Table <ref type="table" coords="11,132.01,732.21,4.98,10.46" target="#tab_3">7</ref> shows our official runs with their result in mean average precision and their associated information retrieval model. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Bilingual Runs</head><p>The bilingual retrieval model adopts the same nomenclature as in previous sections.</p><p>As allready explained, all our bilingual runs follow the same schema "query translation" followed by a monolingual search (most often with PRF or query expansion in the target language). For the first step -query translation -, we used either our Statistical Machine Translation system (MATRAX), either one (initial standard) dictionary adapted following the strategy described in this paper. The monolingual search component obeys the same nomenclature as in the previous section.</p><p>In order to increase the recall of what can be obtained with MATRAX, we intentionally kept the TOP5 most plausible translations given by MATRAX and concatenated them to obtain the new query in the target language (this indeed significantly increased the performance of the retrieval).</p><p>In order to perform lexicon adaptation, the choice of the initial dictionary is crucial to the task. We used two initial dictionaries that were at our disposal: the first one, CsaGirt, has been extracted from the concatenation of the GIRT and CSA thesauri. The second dictionary was ELRAC, composed as described before. Hence, to benefit from both sources, the dictionaries were merged hierarchically : an entry of the dictionary is added to the other one, if this entry is not already present in the master dictionary. The dictionary named Hier-CsaGirtElrac (abbreviation: hcge) is the dictionary obtained by giving priority to the dictionary CsaGirt and then adding any Elrac entry not already present in CsaGirt. The dictionary named Hier-ElracCsaGirt (abbreviation: hecg) is the dictionary obtained by giving priority to the dictionary Elrac and then adding the dictionary CsaGirt.</p><p>Table <ref type="table" coords="12,131.92,551.63,4.98,10.46" target="#tab_4">8</ref> shows the result of our bilingual runs with their mean average precision and the model used for translation and retrieval. If no other query expansion (in the target language) is done beyond the lexical entailment model, Matrax offers the best results (but recall that Matrax is significantly harder and more time-consuming to train than our simple dictionary extraction and adaptation). However, it seems that, once we want to adopt more complex PRF techniques after translation, there is a substantial advantage to use our dictionary adaptation method that, presumably, gives less noisy translations. Consequently, the best absolute performance are obtained by combining (1) the hierarchical building of the inital dictionary (the order in the hierarchy is dependent of the source and target languages, (2) adapting this initial dictionary with the proposed algorithm and (3) performing a rather sophisticated (PRF+Lexical Entailment) query expansion/enrichment in the target language. Note that, when English is the target language, bilingual performances are even better than monolingual ones.</p><p>Table <ref type="table" coords="12,133.68,695.09,4.98,10.46" target="#tab_5">9</ref> shows the results of some experiments that we performed after the submission to CLEF, but using the CLEF 2007 queries and relevance assessments. The table intent is to better understand the individual effect of the basic components of our official runs. We can observe that the monolingual pseudo-relevance feedback algorithm improves a lot the results: for German, it boosted the mean average precision form 0.30 to 0.44. We can also see that the dictionary adaptation also works for queries of this year. Finally, there is still a deficiency when the target corpus is the english corpus: we still believe this is due to the unbalanced nature of the documents (german documents are longer in average and, consequently, more reliable, because they most often contain the abstract field).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion to GIRT Participation</head><p>Our main goal this year was to validate two query translation and disambiguation strategies. The first one relies on the use of our Statistical Machine Translation tool, especially taking benefit from its flexibility to output more than one plausible translations and to train its Language Model component on the CLEF07 target corpora. The second one relies on a pseudo-feedback adaptation mechanism that performs simultaneously dictionary adaptation and query expansion. Experimental results on CLEF-2007 corpora (domain-specific track) show that the dictionary adaptation mechanisms appear quite effective in the CLIR framework, exceeding in certain cases the performance of much more complex Machine Translation systems and even the performance of the monolingual baseline. The pseudo-feedback adaptation method turns out to be robust to the number of feedback documents and relatively efficient since we do not need to extract co-occurence statistics. It is also robust to the noise in feedback documents, contrary to several traditional monolingual feedback methods that decreased their performances in our experiments. Lastly, it enables to use general dictionaries in domain specific context with almost as good performance as domain specific dictionaries.</p><p>We believe that the concept of adaptation of lexicon has other applications in cross-lingual information access tasks. For instance, if there is some underlying class or category system (built in a supervised or unsupervised way), lexicons could be adapted to a particular category/cluster. Moreover, the adaptation model could be useful to adapt a dictionary to a user profile: from feedback sessions, one can learn an bilingual lexicon adapted to a particular user, which has significant applications. Our further works will focus on such aspects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Aknowledgments</head><p>This work was partly supported by the IST Programme of the European Community, under the SMART project, FP6-IST-2005-033917. The authors also want to thank Francois Pacull for his greatly appreciated help in applying the MATRAX tools in CLEF07 experiments.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="9,158.74,332.81,3.91,6.50;9,198.95,332.81,7.81,6.50;9,241.15,332.81,7.81,6.50;9,283.36,332.81,7.81,6.50;9,325.50,332.81,7.81,6.50;9,367.70,332.81,7.81,6.50;9,409.91,332.81,7.81,6.50;9,452.11,332.81,7.81,6.50;9,148.90,326.89,9.76,6.50;9,144.98,301.67,13.67,6.50;9,144.98,276.44,13.67,6.50;9,144.98,251.21,13.67,6.50;9,144.98,225.98,13.67,6.50;9,148.90,200.75,9.76,6.50;9,144.98,175.53,13.67,6.50;9,144.98,150.30,13.67,6.50;9,144.98,125.13,13.67,6.50;9,256.90,341.18,103.06,6.50;9,135.14,248.23,6.50,17.57;9,135.14,220.90,6.50,25.38;9,135.14,190.84,6.50,28.10;9,201.53,116.99,214.32,6.50;9,383.27,292.01,69.87,6.50;9,383.27,300.67,60.11,6.50;9,383.27,309.39,60.11,6.50;9,383.27,318.06,69.87,6.50"><head></head><label></label><figDesc>Mean average precision with varying number of feedback documents GER to EN Thesaurus GER to EN ELRAC EN to GER ELRAC EN to GER Thesaurus</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="9,160.21,370.44,282.59,10.46"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Influence of the number of pseudo-feedback documents</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="8,104.87,117.46,393.27,209.15"><head>Table 1 :</head><label>1</label><figDesc>Monolingual Experimental Results in MAP</figDesc><table coords="8,104.87,129.16,393.27,197.44"><row><cell></cell><cell cols="3">Language Before feedback After Feedback</cell><cell></cell></row><row><cell></cell><cell>EN</cell><cell>0.33</cell><cell>0.37</cell><cell></cell></row><row><cell></cell><cell>GER</cell><cell>0.41</cell><cell>0.48</cell><cell></cell></row><row><cell cols="5">Table 2: Monolingual Lexical Entailment (LE) Experimental Results in map</cell></row><row><cell cols="5">Language Simple LE Double LE Standard approach with PRF (baseline)</cell></row><row><cell>EN</cell><cell>0.38</cell><cell>0.41</cell><cell>0.38</cell><cell></cell></row><row><cell>GER</cell><cell>0.45</cell><cell>0.51</cell><cell>0.49</cell><cell></cell></row><row><cell></cell><cell cols="3">Table 3: Dictionary Adaptation Experimental Results in MAP</cell><cell></cell></row><row><cell>Translation</cell><cell cols="4">Initial Dictionary Without adaptation After adaptation Rel. Improv.</cell></row><row><cell>EN to GER</cell><cell>Thesaurus</cell><cell>0.3054</cell><cell>0.3385</cell><cell>10%</cell></row><row><cell>EN to GER</cell><cell>ELRAC</cell><cell>0.2751</cell><cell>0.3502</cell><cell>29%</cell></row><row><cell>GER to EN</cell><cell>Thesaurus</cell><cell>0.3068</cell><cell>0.3516</cell><cell>16%</cell></row><row><cell>GER to EN</cell><cell>ELRAC</cell><cell>0.2089</cell><cell>0.3027</cell><cell>50%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="10,131.94,116.10,339.14,329.93"><head>Table 4 :</head><label>4</label><figDesc>CLIR Results with Lexical Entailment in map</figDesc><table coords="10,131.94,116.10,339.14,329.93"><row><cell></cell><cell></cell><cell></cell><cell cols="6">Influence of lambda on mean average precision</cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.37</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">GER-&gt;EN TH</cell></row><row><cell></cell><cell>0.36</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">GER-&gt;EN ELRAC</cell></row><row><cell></cell><cell>0.35</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>mean average precision</cell><cell>0.31 0.32 0.33 0.34</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.29</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>0.1</cell><cell>0.2</cell><cell>0.3</cell><cell>0.4</cell><cell>0.5</cell><cell>0.6</cell><cell>0.7</cell><cell>0.8</cell><cell>0.9</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>lambda</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Figure 2: Influence of λ</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Translation</cell><cell></cell><cell>Method</cell><cell></cell><cell cols="7">baseline Simple Lex. Ent. PRF Lex. Ent.</cell></row><row><cell cols="5">EN to GER DA Thesaurus</cell><cell cols="2">0.3385</cell><cell cols="2">0.36</cell><cell></cell><cell cols="2">0.39</cell></row><row><cell cols="2">EN to GER</cell><cell cols="3">DA ELRAC</cell><cell cols="2">0.3502</cell><cell cols="2">0.38</cell><cell></cell><cell cols="2">0.41</cell></row><row><cell cols="5">GER to EN DA Thesaurus</cell><cell cols="2">0.3516</cell><cell cols="2">0.37</cell><cell></cell><cell cols="2">0.39</cell></row><row><cell cols="2">GER to EN</cell><cell cols="3">DA ELRAC</cell><cell cols="2">0.3027</cell><cell cols="2">0.33</cell><cell></cell><cell cols="2">0.36</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="11,178.15,267.85,246.70,229.72"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table coords="11,178.15,267.85,246.70,229.72"><row><cell></cell><cell cols="3">Monolingual pseudo-feedback Parameters</cell></row><row><cell>Value</cell><cell></cell><cell cols="2">Notation in this report</cell></row><row><cell></cell><cell></cell><cell cols="2">GERMAN</cell></row><row><cell>15</cell><cell></cell><cell cols="2">n of section 3.1</cell></row><row><cell>0.85</cell><cell></cell><cell cols="2">α in eq. 7</cell></row><row><cell>20</cell><cell cols="3">Take the top N words from θ F (cf section 3.1.2)</cell></row><row><cell>0.6</cell><cell></cell><cell cols="2">λ in eq. 6</cell></row><row><cell></cell><cell></cell><cell cols="2">ENGLISH</cell></row><row><cell>10</cell><cell></cell><cell cols="2">n cf section3.1</cell></row><row><cell>0.8</cell><cell></cell><cell cols="2">α in eq. 7</cell></row><row><cell>20</cell><cell cols="3">Take the top N words from θ F (cf section 3.1.2)</cell></row><row><cell>0.6</cell><cell></cell><cell cols="2">λ in eq. 6</cell></row><row><cell cols="4">Table 6: Lexical Entailment IR Model Parameters Name Value Reference</cell></row><row><cell></cell><cell>λ</cell><cell>0.9</cell><cell>eq. 2</cell></row><row><cell></cell><cell>β</cell><cell>0.125</cell><cell>eq. 16</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="12,117.20,117.46,368.60,143.31"><head>Table 7 :</head><label>7</label><figDesc>Official Monolingual Runs with their underlying model and results in MAP</figDesc><table coords="12,149.90,129.16,303.20,131.60"><row><cell>Model</cell><cell cols="2">MAP Run Name</cell></row><row><cell>GERMAN</cell><cell></cell><cell></cell></row><row><cell>Lexical Entailment Simple</cell><cell>0.3475</cell><cell>xrcelede</cell></row><row><cell>Language Model + PRF</cell><cell>0.4465</cell><cell>xrceprfde</cell></row><row><cell cols="3">Language Model + PRF + Lexical Entailment 0.5014 xrceprfdele</cell></row><row><cell>PRF Lexical Entailment</cell><cell cols="2">0.5051 xrceprflede</cell></row><row><cell>ENGLISH</cell><cell></cell><cell></cell></row><row><cell>Lexical Entailment Simple</cell><cell>0.2722</cell><cell>xrceleen</cell></row><row><cell>Language Model + PRF</cell><cell>0.2934</cell><cell>xrceprfde</cell></row><row><cell cols="3">Language Model + PRF + Lexical Entailment 0.3237 xrceprfenle</cell></row><row><cell>PRF Lexical Entailment</cell><cell cols="2">0.3051 xrceprfleen</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="13,106.96,117.46,389.09,191.12"><head>Table 8 :</head><label>8</label><figDesc>Official Bilingual Runs with their underlying model and results in MAP</figDesc><table coords="13,106.96,129.16,389.09,179.42"><row><cell>Bilingual Model</cell><cell>MAP</cell><cell>Run Name</cell></row><row><cell>ENGLISH to GERMAN</cell><cell></cell><cell></cell></row><row><cell>Matrax + Language Model + PRF</cell><cell>0.4</cell><cell>xrcee2dmatrax</cell></row><row><cell>Matrax+Lexical Entailment Simple</cell><cell>0.43</cell><cell>xrcee2dmatraxle</cell></row><row><cell>Matrax+ PRF Lexical Entailment</cell><cell cols="2">0.4298 xrcee2dmatraxprfle</cell></row><row><cell>Adapt Dico Hier-CsaGirtElrac + Lexical Entailment</cell><cell>0.3905</cell><cell>xrcee2dhcgele</cell></row><row><cell cols="2">Adapt Dico Hier-CsaGirtElrac + PRF Lexical Entailment 0.4447</cell><cell>xrcee2dhcgeprfle</cell></row><row><cell cols="2">Adapt Dico Hier-ElracCsaGirt + PRF Lexical Entailment 0.4568</cell><cell>xrcee2dhecgprfle</cell></row><row><cell>GERMAN to ENGLISH</cell><cell></cell><cell></cell></row><row><cell>Matrax + Language Model + PRF</cell><cell>0.2468</cell><cell>xrced2ematrax</cell></row><row><cell>Matrax+Lexical Entailment Simple</cell><cell>0.2757</cell><cell>xrced2ematraxle</cell></row><row><cell>Matrax+ PRF Lexical Entailment</cell><cell cols="2">0.2873 xrced2ematraxprfle</cell></row><row><cell>Adapt Dico Hier-ElracCsaGirt + Lexical Entailment</cell><cell>0.2338</cell><cell>xrced2ehecgle</cell></row><row><cell cols="2">Adapt Dico Hier-CsaGirtElrac + PRF Lexical Entailment 0.3341</cell><cell>xrced2ehcgeprfle</cell></row><row><cell cols="2">Adapt Dico Hier-ElracCsaGirt + PRF Lexical Entailment 0.2923</cell><cell>xrced2ehecgprfle</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="13,142.44,340.91,318.12,155.66"><head>Table 9 :</head><label>9</label><figDesc>Unofficial runs with their underlying model and results in MAP</figDesc><table coords="13,177.51,352.60,247.99,143.97"><row><cell>Model Description</cell><cell>MAP</cell><cell>MAP</cell></row><row><cell>Matrax Language Model without PRF</cell><cell></cell><cell></cell></row><row><cell>english to german</cell><cell>0.2911</cell><cell></cell></row><row><cell>german to english</cell><cell>0.2083</cell><cell></cell></row><row><cell>Adaptation of Dictionary</cell><cell cols="2">Before After</cell></row><row><cell cols="3">english to german : Hier-CsaGirtElrac 0.2768 0.3541</cell></row><row><cell cols="3">english to german : Hier-ElracCsaGirt 0.2127 0.3050</cell></row><row><cell cols="3">german to english : Hier-CsaGirtElrac 0.2072 0.2454</cell></row><row><cell>german to english : Hier-ElracCsaGirt</cell><cell>0.154</cell><cell>0.207</cell></row><row><cell>Monolingual</cell><cell></cell><cell></cell></row><row><cell>english Language Model</cell><cell>0.2511</cell><cell></cell></row><row><cell>german Language Model</cell><cell>0.3016</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="7,105.24,736.39,407.87,8.37;7,90.00,745.85,201.52,8.37"><p>The Information Gain, aka Generalised (or average) Mutual Information<ref type="bibr" coords="7,381.79,736.39,8.47,8.37" target="#b3">[4]</ref>, is used for selecting features in text categorisation<ref type="bibr" coords="7,161.81,745.85,13.18,8.37" target="#b18">[19,</ref><ref type="bibr" coords="7,177.82,745.85,6.59,8.37" target="#b6">7]</ref> or detecting collocations<ref type="bibr" coords="7,280.22,745.85,8.47,8.37" target="#b5">[6]</ref>.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="14,110.47,339.62,402.53,10.46;14,110.48,351.58,402.54,10.46;14,110.48,363.54,208.08,10.46" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="14,255.83,339.62,240.82,10.46">Domain-specific track clef 2006 : Overview of the results</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Baerisch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Stempfhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,110.48,351.58,355.83,10.46">CLEF 2006: Proceedings of the Workshop of the Cross-Language Evaluation Forum</title>
		<meeting><address><addrLine>Alicante, Spain</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">September 20 -22, 2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,110.47,383.46,402.53,10.46;14,110.48,395.41,402.53,10.46;14,110.48,407.37,220.88,10.46" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="14,248.79,383.46,195.05,10.46">Information retrieval as statistical translation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">L</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,463.34,383.46,49.66,10.46;14,110.48,395.41,402.53,10.46;14,110.48,407.37,92.98,10.46">Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="222" to="229" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,110.47,424.77,402.53,12.98;14,110.48,439.25,402.52,10.46;14,110.48,451.20,393.26,10.46" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="14,303.42,427.29,190.13,10.46">Lexical entailment for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clinchant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Goutte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">É</forename><surname>Gaussier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,110.48,451.20,22.21,10.46">ECIR</title>
		<title level="s" coord="14,210.47,451.20,152.09,10.46">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Lalmas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Macfarlane</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Rüger</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Tombros</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Yavlinsky</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">3936</biblScope>
			<biblScope unit="page" from="217" to="228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,110.47,471.13,402.52,10.46;14,110.48,483.09,38.74,10.46" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="14,152.72,471.13,149.34,10.46">Information et analyse des données</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Colin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,310.29,471.13,92.99,10.46">Pub. Inst. Stat. Univ</title>
		<imprint>
			<biblScope unit="volume">XXXVII</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="43" to="60" />
			<date type="published" when="1993">1993</date>
			<pubPlace>Paris</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,110.47,503.01,402.54,10.46;14,110.48,514.97,334.16,10.46" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="14,287.78,503.01,221.00,10.46">The pascal recognising textual entailment challenge</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Glickman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,122.93,514.97,291.09,10.46">PASCAL Challenges Workshop for Recognizing Textual Entailment</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,110.47,534.89,402.53,10.46;14,110.48,546.85,132.22,10.46" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="14,168.36,534.89,272.05,10.46">Accurate methods for the statistics of surprise and coincidence</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Dunning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,449.10,534.89,63.91,10.46;14,110.48,546.85,45.60,10.46">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="74" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,110.47,566.77,402.53,10.46;14,110.48,578.73,255.79,10.46" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="14,166.13,566.77,343.02,10.46">An extensive empirical study of feature selection metrics for text classification</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Forman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,110.48,578.73,166.59,10.46">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1289" to="1305" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,110.47,598.65,402.54,10.46;14,110.48,610.60,402.53,10.46;14,110.48,622.56,402.52,10.46;14,110.48,634.52,335.23,10.46" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="14,389.67,598.65,123.34,10.46;14,110.48,610.60,276.24,10.46">Improving query translation for cross-language information retrieval using statistical models</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Xun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,409.68,610.60,103.32,10.46;14,110.48,622.56,402.52,10.46;14,110.48,634.52,89.43,10.46">SIGIR &apos;01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="96" to="104" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,110.47,654.45,402.53,10.46;14,110.48,666.40,402.52,10.46;14,110.48,678.35,84.13,10.46" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="14,251.94,654.45,261.06,10.46;14,110.48,666.40,69.09,10.46">Statistical query translation models for cross-language information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,189.77,666.40,318.04,10.46">ACM Transactions on Asian Language Information Processing (TALIP)</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="323" to="359" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,110.47,698.28,402.53,10.46;14,110.48,710.23,402.52,10.46;14,110.48,722.19,22.69,10.46" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="14,297.03,698.28,215.97,10.46;14,110.48,710.23,78.67,10.46">A probabilistic classification approach for lexical textual entailment</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Glickman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Dagan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,211.82,710.23,296.11,10.46">Twentieth National Conference on Artificial Intelligence (AAAI-05)</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.47,110.53,402.53,10.46;15,110.48,122.49,402.53,10.46;15,110.48,134.45,402.52,10.46;15,110.48,146.40,22.69,10.46" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="15,378.22,110.53,134.78,10.46;15,110.48,122.49,331.11,10.46">Translation resources, merging strategies, and relevance feedback for cross-language information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Pohlmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Westerveld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="15,244.58,134.45,152.71,10.46">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="page" from="102" to="115" />
			<date type="published" when="2000">2069. 2000</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.47,166.33,402.53,10.46;15,110.48,178.28,337.19,10.46" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="15,276.23,166.33,236.77,10.46;15,110.48,178.28,154.67,10.46">Embedding web-based statistical translation models in cross-language information retrieval</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Simard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="15,273.42,178.28,77.72,10.46">Comput. Linguist</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="381" to="419" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.47,198.21,402.53,10.46;15,110.48,210.16,402.52,10.46;15,110.48,222.12,402.52,10.46;15,110.48,234.07,175.48,10.46" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="15,259.88,198.21,253.13,10.46;15,110.48,210.16,131.12,10.46">A maximum coherence model for dictionary-based crosslanguage information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">Y</forename><surname>Chai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,264.20,210.16,248.80,10.46;15,110.48,222.12,332.35,10.46">SIGIR &apos;05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="536" to="543" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.47,253.99,402.54,10.46;15,110.48,265.96,402.53,10.46;15,110.48,277.91,402.52,10.46;15,110.48,289.86,78.59,10.46" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="15,221.61,253.99,291.40,10.46;15,110.48,265.96,34.68,10.46">Iterative translation disambiguation for cross-language information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">J</forename><surname>Dorr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,164.65,265.96,348.36,10.46;15,110.48,277.91,233.60,10.46">SIGIR &apos;05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="520" to="527" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.47,309.79,402.53,10.46;15,110.48,321.74,402.52,10.46;15,110.48,333.70,402.52,10.46;15,110.48,345.65,96.39,10.46" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="15,234.40,309.79,227.18,10.46">Using statistical translation models for bilingual ir</title>
		<author>
			<persName coords=""><forename type="first">J.-Y</forename><surname>Nie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Simard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,486.37,309.79,26.64,10.46;15,110.48,321.74,402.52,10.46;15,110.48,333.70,266.82,10.46">CLEF &apos;01: Revised Papers from the Second Workshop of the Cross-Language Evaluation Forum on Evaluation of Cross-Language Information Retrieval Systems</title>
		<meeting><address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="137" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.47,365.58,402.53,10.46;15,110.48,377.54,402.53,10.46;15,110.48,389.49,287.29,10.46" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="15,305.24,365.58,161.32,10.46">The domain-specific track at clef 2007</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Petras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Baerisch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Stempfhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,486.37,365.58,26.64,10.46;15,110.48,377.54,327.12,10.46">CLEF 2007: Proceedings of the Workshop of the Cross-Language Evaluation Forum</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">September 19 -21, 2007. 2007</date>
		</imprint>
	</monogr>
	<note>page forthcoming</note>
</biblStruct>

<biblStruct coords="15,110.47,409.42,402.53,10.46;15,110.48,421.37,402.52,10.46;15,110.48,433.33,220.88,10.46" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="15,209.99,409.42,235.42,10.46">A language modelling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ponte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,463.34,409.42,49.66,10.46;15,110.48,421.37,402.52,10.46;15,110.48,433.33,92.98,10.46">Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="275" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.47,453.25,402.54,10.46;15,110.48,465.20,402.53,10.46;15,110.48,477.16,360.29,10.46" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="15,205.49,453.25,307.53,10.46;15,110.48,465.20,35.68,10.46">Regularized estimation of mixture models for robust pseudo-relevance feedback</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,165.89,465.20,347.13,10.46;15,110.48,477.16,233.55,10.46">SIGIR &apos;06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.47,497.08,402.53,10.46;15,110.48,509.05,402.51,10.46;15,110.48,521.00,43.72,10.46" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="15,237.35,497.08,271.41,10.46">A comparative study on feature selection in text categorization</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">O</forename><surname>Pedersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,122.78,509.05,335.54,10.46">Proceedings of ICML-97, 14th International Conference on Machine Learning</title>
		<meeting>ICML-97, 14th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="412" to="420" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.47,540.93,402.53,10.46;15,110.48,552.88,350.62,10.46" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="15,212.18,540.93,300.83,10.46;15,110.48,552.88,96.94,10.46">A study of smoothing methods for language models applied to ad hoc to information etrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,228.13,552.88,104.29,10.46">Proceedings of SIGIR&apos;01</title>
		<meeting>SIGIR&apos;01</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="334" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="15,110.47,572.80,402.53,10.46;15,110.48,584.76,263.47,10.46" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="15,240.83,572.80,272.18,10.46;15,110.48,584.76,88.67,10.46">Model-based feedback in the language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="15,219.86,584.76,24.27,10.46">CIKM</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="403" to="410" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
