<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,102.66,98.15,389.59,12.58">Domain-Specific IR for German, English and Russian Languages</title>
				<funder ref="#_BDyY6Zc">
					<orgName type="full">Swiss National Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,177.66,121.83,56.48,8.74"><forename type="first">Claire</forename><surname>Fautsch</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Neuchatel</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,240.89,121.83,66.01,8.74"><forename type="first">Ljiljana</forename><surname>Dolamic</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Neuchatel</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,314.04,121.83,51.22,8.74"><forename type="first">Samir</forename><surname>Abdou</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Neuchatel</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Neuchatel</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,372.77,121.83,58.86,8.74"><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
							<email>jacques.savoy@unine.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Neuchatel</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,102.66,98.15,389.59,12.58">Domain-Specific IR for German, English and Russian Languages</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">72BC1C529C2CE9D1AB79F6CD8B66E1BC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:14+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.1 [Content Analysis and Indexing]: Indexing methods</term>
					<term>Linguistic processing. I.2.7 [Natural Language Processing]: Language models. H.3.3 [Information Storage and Retrieval]: Retrieval models. H.3.4 [Systems and Software]: Performance evaluation Experimentation</term>
					<term>Performance</term>
					<term>Measurement</term>
					<term>Algorithms Natural Language Processing with European Languages</term>
					<term>Manual Indexing</term>
					<term>Digital Libraries</term>
					<term>German Language</term>
					<term>Russian Language</term>
					<term>Thesaurus</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In participating in this CLEF evaluation campaign, our first objective is to propose and evaluate various indexing and search strategies for the Russian language, in order to obtain better retrieval effectiveness than that provided by the language-independent approach (n-gram). Our second objective is to more effectively measure the relative merit of various search engines when used for the German and to a lesser extent the English language. To do so we evaluate the GIRT-4 test-collection using the Okapi, various IR models derived from the Divergence from Randomness (DFR) paradigm, the statistical language model (LM) together with the classical tf . idf vector-processing scheme. We also evaluated different pseudo-relevance feedback approaches. For the Russian language, we find that word-based indexing with our light stemming procedure results in better retrieval effectiveness than does 4-gram indexing strategy (relative difference around 30%). Using the GIRT corpora (available in German and English), we examine certain variations in retrieval effectiveness that result from applying the specialized thesaurus to automatically enlarge topic descriptions. In this case, the performance variations were relatively small and usually non significant.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In our domain-specific retrieval task we access the GIRT (German Indexing and Retrieval Test database) corpus, composed of bibliographic records. These are mainly extracted from two social science sources: SOLIS (social science literature) and FORIS 1 (current research in social science fields), covering Europe's German speaking countries <ref type="bibr" coords="1,148.49,607.41,146.87,8.74">(Germany, Austria, and Switzerland)</ref>. This collection has grown from 13,000 documents in 1996 to more than 150,000 in 2005, and we are making a continuous effort to enhance the number of documents available, see <ref type="bibr" coords="1,127.50,629.97,53.84,8.74" target="#b5">Kluck (2004)</ref> for a more complete description of this corpus.</p><p>The fact that scientific documents may contain manually assigned keywords is of particular interest to us in our work. They are usually extracted from a controlled vocabulary by librarians who are knowledgeable of the domain to which the indexed articles belong. These descriptors should be helpful in improving document surrogates and thus the extraction of more pertinent information, and at the same time discarding irrelevant abstracts. Access to the underlying thesaurus would also improve the retrieval performance.</p><p>1 See the Web sites http://www.gesis.org/Information/SOLIS/ and http://www.gesis.org/Information/FORIS/ The rest of this paper is organized as follows: Section 2 describes the main characteristics of the GIRT-4 and ISISS test-collections. Section 3 outlines the main aspects of our stopword lists and light stemming procedures. Section 4 analyses the principal features of various indexing and search strategies, and evaluates their use with the available corpora. Section 5 presents our official runs and results. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Overview of Test-Collections</head><p>In the domain-specific retrieval task (called GIRT), the two available corpora are composed of bibliographic records extracted from various sources in the social sciences domain. Typical records (see Figure <ref type="figure" coords="2,463.51,713.91,5.01,8.74">1</ref> for a German example) in this corpus consist of a title (tag &lt;TITLE-DE&gt;), author name (tag &lt;AUTHOR&gt;), document language (tag &lt;TITLE-DE&gt;), publication date (tag &lt;PUBLICATION-YEAR&gt;) and abstract (tag &lt;ABSTRACT-DE&gt;). Manually assigned descriptors and classifiers are provided for all documents. An inspection of this German corpus reveals that all bibliographic notices have a title, and that 96.4% of them have an abstract. In addition to this information provided by the author, a typical record contains on average 10.15 descriptors ("&lt;CONTROLLED-TERM-DE&gt;"), 2.02 classification terms ("&lt;CLASSIFICATION-TEXT-DE&gt;"), and 2.42 methodological terms ("&lt;METHOD-TEXT-DE&gt;" or "&lt;METHOD-TERM-DE&gt;"). The manually assigned descriptors are extracted from the controlled list which is the "Thesaurus for the Social Sciences" (or GIRT Thesaurus). Finally, associated with each record is a unique identifier ("&lt;DOCNO&gt;"). <ref type="bibr" coords="3,421.25,129.75,53.85,8.74" target="#b5">Kluck (2004)</ref> provides a more complete description of this corpus.</p><p>The above-mentioned German collection was translated into British English, mainly by professional translators who are native English speakers. Included in all English records is a translated title (listed under "&lt;TITLE-EN&gt;" in Figure <ref type="figure" coords="3,173.13,180.87,3.63,8.74">2</ref>), manually assigned descriptors ("&lt;CONTROLLED-TERM-EN&gt;"), classification terms ("&lt;CLASSIFICATION-TEXT-EN&gt;") and methodological terms ("&lt;METHOD-TEXT-EN&gt;"). Abstracts however were not always translated (in fact they are available for only around 15% of the English records).</p><p>In addition to this bilingual corpus, we also have access to the GIRT thesaurus. Figure <ref type="figure" coords="3,428.97,220.71,5.01,8.74">3</ref> shows some examples of four typical entries in this thesaurus. Each main entry includes the tag &lt;GERMAN&gt; followed by the descriptor written in the German language. Its corresponding uppercase form without diacritics or "ß" appears under the tag &lt;GERMAN-CAPS&gt;. The British English translation follows the label &lt;ENGLISH-TRANSLATION&gt;. The hierarchical relationships between the different descriptors are shown under the labels &lt;BROADER-TERM&gt; (a term having a broader semantic coverage) and &lt;NARROWER-TERM&gt; (a more specific term). The relationship &lt;RELATED-TERM&gt; is used to provide additional pertinent descriptors (similar to the relationship "see also …" often found in many controlled vocabularies). The tag &lt;USE-INSTEAD&gt; is used to redirected readers to another entry (usually a synonym of an existing entry or to indicate that an acronym exists). The tag &lt;USE-COMBINATION&gt; is sometimes used to indicate a possible decompounded or simplified term variant, or more generally a similar term. Usually however, the &lt;USE-COMBINATION&gt; is used like &lt;USE-INSTEAD&gt; to refer from a non-descriptor to a descriptor but having usually more than one descriptor that should be used in combination.</p><p>In the GIRT thesaurus are found 10,623 entries (all with both the tag &lt;GERMAN&gt; and &lt;GERMAN-CAPS&gt;) together with 9,705 English translations. Also found are 2,947 &lt;BROADER-TERM&gt; relationships and 2,853 &lt;NARROWER-TERM&gt; links. The synonym relationship between terms can be expressed through the &lt;USE-INSTEAD&gt; (2,153 links), &lt;RELATED-TERM&gt; <ref type="bibr" coords="3,283.23,407.19,12.57,8.74">(1,</ref><ref type="bibr" coords="3,295.80,407.19,16.76,8.74">528)</ref>   <ref type="table" coords="3,110.46,653.07,5.01,8.74" target="#tab_1">1</ref> below lists a few statistics from these collections, showing that the German corpus has the largest size (326 MB), the English ranks second and the Russian third, both in size (12 MB) and in number of documents <ref type="bibr" coords="3,70.92,675.63,20.94,8.74">(145,</ref><ref type="bibr" coords="3,91.86,675.63,16.75,8.74">802)</ref>. The German corpus has the larger mean size (89.71 indexing terms/article), compared to the English collection (54.86), while for the Russian corpus the mean value is smaller (38.4). For the English corpus, we do not include the CSA Sociological Abstracts (20,000 documents, 38.5 MB) in our evaluation. The fact that the relevance assessments contain 1,032 items extracted from this sub-collection implies that our retrieval effectiveness measures for the English corpus are lower than expected.</p><p>During the indexing process, we retained all pertinent sections in order to build document representatives. Additional information such as author name, publication date and the language in which the bibliographic notice was written are of less importance, particularly from an IR perspective, and in our experiments they will be ignored.</p><p>As shown in Appendix 2, the available topics cover various subjects (e.g., Topic #176: "Sibling relations," Topic #178: "German-French relations after 1945," Topic #196: "Tourism industry in Germany," or Topic #199: "European climate policy"), and some of them may cover a relative large domain (e.g. Topic #187: "Migration pressure"). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>German</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Stopword Lists and Stemming Procedures</head><p>During this evaluation campaign, we used the same stopword lists and stemmers that we selected for our previous English and German language CLEF participation <ref type="bibr" coords="4,310.66,528.75,59.45,8.74">(Savoy, 2004a)</ref>. Thus for English it was the SMART stemmer and stopword list (containing 571 items), while for the German we applied our light stemmer (available at http://www.unine.ch/info/clef/) and stopword list (603 words). For all our German experiments we applied our decompounding algorithm <ref type="bibr" coords="4,179.52,562.59,60.09,8.74" target="#b10">(Savoy, 2004b)</ref>.</p><p>For the Russian language, we designed and implemented a new light stemmer that removes only inflectional suffixes attached to nouns or adjectives. This stemmer applies 53 rules to remove the final suffix representing gender (masculine, feminine, and neutral), number (singular, plural) and the six Russian grammatical cases (nominative, accusative, genitive, dative, instrumental, and locative). The stemmer also applied three normalization rules in order to correct certain variations that occur when a particular suffix is attached to a noun or adjective. See Appendix 3 for a list all this new stemmer's rules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">IR Models and Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Indexing and Search Strategies</head><p>In order to obtain a broader view of the relative merit of various retrieval models, we may first adopt the classical tf idf indexing scheme. In this case, the weight attached to each indexing term in a document surrogate (or in a query) is composed by the term occurrence frequency (denoted tf ij for indexing term t j in document D i ) and the inverse document frequency (denoted idf j ).</p><p>In addition to this vector-processing model, we may also consider probabilistic models such as the Okapi model (or BM25) <ref type="bibr" coords="5,144.17,112.92,93.84,9.02" target="#b8">(Robertson et al., 2000)</ref>. As a second probabilistic approach, we may implement four variants of the DFR (Divergence from Randomness) family suggested by <ref type="bibr" coords="5,332.09,124.47,125.99,8.74" target="#b1">Amati &amp; van Rijsbergen (2002)</ref>. In this framework, the indexing weight w ij attached to term t j in document D i combines two information measures as follows:</p><formula xml:id="formula_0" coords="5,126.90,162.13,218.38,11.65">w ij = Inf 1 ij • Inf 2 ij = -log 2 [Prob 1 ij (tf)] • (1 -Prob 2 ij (tf))</formula><p>The first model called GL2 was based on the following equations:</p><formula xml:id="formula_1" coords="5,126.90,196.69,396.99,11.65">Prob 2 ij = tfn ij / (tfn ij + 1) with tfn ij = tf ij • log 2 [1 + ((c • mean dl) / l i )]<label>(1)</label></formula><p>Prob</p><formula xml:id="formula_2" coords="5,145.92,213.73,377.97,12.97">1 ij = [1 / (1+λ j )] • [λ j / (1+λ j )] tfn ij with λ j = tc j / n (2)</formula><p>where tc j represents the number of occurrences of term t j in the collection, df j the number of documents in which the term t j appears, and n the number of documents in the corpus. In our experiments, we fixed the constants values according to the values given in the Appendix 1.</p><p>For the second model called PL2, Prob 2 ij was obtained from Equation <ref type="formula" coords="5,366.81,276.33,3.77,8.74" target="#formula_1">1</ref>, and Prob 1 ij was modified as:</p><formula xml:id="formula_3" coords="5,126.90,291.19,396.99,12.97">Prob 1 ij = (e -λj • λ tfij ) / tf ij ! (3)</formula><p>For the third model called I(n)L2, we still used Equation 1 to compute Prob 2 ij but the implementation of Inf 1 ij was modified as:</p><formula xml:id="formula_4" coords="5,126.90,338.53,396.98,11.65">Inf 1 ij = tfn ij • log 2 [(n+1) / (df j +0.5)]<label>(4)</label></formula><p>For the fourth model called PB2, the implementation of Prob 1 ij was obtained by Equation <ref type="formula" coords="5,441.69,359.67,3.77,8.74">3</ref>, and for evaluating Prob 2 ij we used:</p><formula xml:id="formula_5" coords="5,126.90,386.05,396.98,11.65">Prob 2 ij = 1-[(tc j +1) / (df j • (tf ij +1))]<label>(5)</label></formula><p>For the fifth model called I(n)B2, the implementation of Inf 1 ij was obtained from Equation 4 while Prob 2 ij was provided by Equation <ref type="formula" coords="5,160.52,416.79,3.77,8.74" target="#formula_5">5</ref>.</p><p>Finally, we also considered an approach based on a statistical language model (LM) <ref type="bibr" coords="5,424.44,434.07,65.35,8.74" target="#b3">(Hiemstra 2000;</ref><ref type="bibr" coords="5,492.29,434.07,21.62,8.74" target="#b4">2002)</ref>, known as a non-parametric probabilistic model (both Okapi and DFR are viewed as parametric models). Thus probability estimates would not be based on any known distribution (as in Equations 2, or 3), but rather be estimated directly based on occurrence frequencies of document D or corpus C. Within this language model (LM) paradigm, various implementations and smoothing methods might be considered, and in this study we adopted a model proposed by <ref type="bibr" coords="5,150.31,490.46,65.97,8.74" target="#b4">Hiemstra (2002)</ref> as described in Equation <ref type="formula" coords="5,319.78,490.46,3.77,8.74">6</ref>, which combines an estimate based on document (P[t j | D i ]) and on corpus (P[t j | C]).</p><formula xml:id="formula_6" coords="5,126.90,517.93,396.99,24.91">P[D i | Q] = P[D i ] . ∏ t j ∈Q [λ j . P[t j | D i ] + (1-λ j ) . P[t j | C]] with P[t j | D i ] = tf ij /l i and P[t j | C] = df j /lc with lc = ∑ k df k (6)</formula><p>where λ j is a smoothing factor (constant for all indexing terms t j , and usually fixed at 0.35) and lc an estimate of the size of the corpus C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Overall Evaluation</head><p>To measure the retrieval performance, we adopted the mean average precision (MAP) (computed on the basis of 1,000 retrieved items per request by the new TREC-EVAL program). In the following tables, the best performance under the given conditions (with the same indexing scheme and the same collection) is listed in bold type. For the English corpus, our evaluation measures are lower than expected due to the fact that our IR system does not take account for the CSA collection.</p><p>Table <ref type="table" coords="5,110.45,666.03,5.01,8.74" target="#tab_3">2</ref> shows the MAP obtained by the seven probabilistic models and the classical tf idf vector-space model using the German or English collection and three different query formulations (title-only or T, TD, and TDN). In the bottom lines we reported the MAP average over the best 7 IR models (the average is computed without the tf idf scheme), and the percentage of change over the medium (TD) query formulation. The DFR I(n)B2 model for the German language or also the Okapi model when searching into the English corpus tends to produce the best retrieval performance.  <ref type="bibr" coords="6,118.19,84.63,72.46,8.74" target="#b7">&amp; Mayfield, 2004)</ref>). The last three lines in this table indicate the MAP average computed for the 4 IR models, the percentage of change compared to the medium (TD) query formulation, and the percentage of change when comparing word-based and 4-gram indexing approaches.</p><p>From this table, we can see that the best performing model when using word-based indexing strategy tends to be the DFR I(n)B2 or the DFR GL2 model. With the 4-gram indexing approach, we may also include the LM model in the set of the best performing schemes. The improvement over the medium query formulation (TD) is greater than 25%, a clear and important enhancement. As shown in the last line, when comparing word-based and 4-gram indexing system, we can see that the relative difference is rather large (around 30%) and favors the word-based approach. Using our evaluation approach, evaluation differences occur when comparing with values computed according to the official measure (the latter always takes 25 queries into account).  In an effort to improve search performance we examined pseudo-relevance feedback using Rocchio's formulation (denoted "Roc") <ref type="bibr" coords="7,189.06,195.60,87.80,9.02" target="#b2">(Buckley et al., 1996)</ref> with α = 0.75, β = 0.75, whereby the system was allowed to add m terms extracted from the k best ranked documents from the original query. For the German corpus (Table <ref type="table" coords="7,515.72,207.15,3.63,8.74" target="#tab_6">4</ref>), enhancement increased from +9.8% (Okapi, 0.2616 vs. 0.2872) to +21.8% (LM model, 0.2526 vs. 0.3076). For the English collection (Table <ref type="table" coords="7,188.54,229.71,3.63,8.74" target="#tab_7">5</ref>), Rocchio's blind query expansion improves the MAP from +3.6% (Okapi, 0.2549 vs. 0.2640) to +18.2% (LM model, 0.2603 vs. 0.3077). For the Russian language (Table <ref type="table" coords="7,422.91,240.99,3.63,8.74" target="#tab_8">6</ref>), blind query expansion may hurt the MAP (e.g., -21.3% with the DFR InB2 model, 0.1775 vs. 0.1397) or improve the retrieval effectiveness (e.g., +8.9% with the LM model, 0.1511 vs. 0.1645). As another pseudo-relevance feedback technique we applied our idf-based approach (denoted "idf" in Table <ref type="table" coords="7,349.06,274.83,4.18,8.74" target="#tab_12">8</ref>) <ref type="bibr" coords="7,359.96,274.83,95.33,8.74" target="#b0">(Abdou &amp; Savoy, 2007)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mean average precision</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mean average precision</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mean average precision</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Query Expansion Using a Specialized Thesaurus</head><p>The GIRT collection has certain interesting aspects from an IR perspective. Each record has manually assigned descriptors (see examples given in Figures <ref type="figure" coords="7,279.23,437.61,5.01,8.74">1</ref> and<ref type="figure" coords="7,303.08,437.61,4.18,8.74">2</ref>) in order to provide more information on the semantic contents of each bibliographic record. Additionally, descriptors from the specialized thesaurus are accessed (see entry examples depicted in Figure <ref type="figure" coords="7,209.89,460.17,3.62,8.74">3</ref>).  In an effort to improve the mean average precision, we used the GIRT thesaurus to automatically enlarge the query. To achieve this, we considered each entry in the thesaurus as a document and then indexed it. We then took each query in turn and used it to retrieve the thesaurus entries. Since the number of retrieved thesaurus entries was relatively small, we simply added all these thesaurus entries to the query, forming a new and enlarged one. Although certain terms occurring in the original query were repeated, in other cases this procedure added related terms. If for example the topic included the country name "Deutschland", our thesaurus-based query expansion procedure might add the related term "BDR" and "Bundesrepublik". Thus, these two terms would usually be helpful to retrieve more pertinent articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mean average precision</head><p>Using the TD query formulation, MAP differences were relatively small (around -3.1%, in average). We believe that one possible explanation for this relatively small difference was that a query might be expanded with frequently used terms that would not be really effective in discriminating between the relevant and irrelevant items.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Official Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run name</head><p>Language   <ref type="table" coords="8,110.53,693.21,5.01,8.74" target="#tab_12">8</ref> describes our 12 official runs in the monolingual GIRT task. In this case each run was built using a data fusion operator "Z-Score" (see <ref type="bibr" coords="8,197.06,704.49,94.54,8.74" target="#b11">(Savoy &amp; Berger, 2006)</ref>). For all runs, we automatically expanded the queries using a blind relevance feedback method, Rocchio (denoted "Roc") or our IDFQE approach (denoted "idf"). In order to obtain more relevant documents in the pool, we also submitted three runs using the TDN queries (UniNEde4, UniNEen4, and UniNEru4). For the English collection the runs retrieved only documents from the GIRT-4 collection and thus we have ignored the CSA corpus. The MAP values achieved for this language are therefore clearly below the expected performance. Finally for the Russian collection, Table <ref type="table" coords="9,444.14,84.63,5.01,8.74" target="#tab_12">8</ref> depicts the MAP achieved when considering 22 queries and in parenthesis, the official MAP computed with 25 queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>For our participation in this domain-specific evaluation campaign, we propose a new light stemmer for the Russian language. The resulting MAP (see Table <ref type="table" coords="9,273.08,162.03,4.18,8.74" target="#tab_2">3</ref>) shows that for this Slavic language our approach may produce better MAP than a 4-gram approach (relative difference around 30%). For the German corpus, we try to exploit the specialized thesaurus in order to improve the resulting MAP. The retrieval effectiveness difference is rather small and we still need to analyze the reasons for obtaining so little difference (see Table <ref type="table" coords="9,447.37,195.86,3.63,8.74" target="#tab_10">7</ref>). We believe that a more specific query enrichment procedure is needed, one able to take the various different term-term relationships into account, along with the occurrence frequencies of the potential new search terms.</p><p>When comparing the various IR models (see Table <ref type="table" coords="9,291.95,235.70,3.63,8.74" target="#tab_3">2</ref>), we found that the I(n)B2 model derived from the Divergence from Randomness (DFR) paradigm tends usually to result in the best performance. When analyzing blind query expansion approaches (see Tables <ref type="table" coords="9,258.42,258.26,21.50,8.74" target="#tab_8">4 to 6</ref>), we find that this type of automatic query expansion can enhance MAP but there is clearly larger improvement when using the LM model. Finally for the Russian corpus, this search strategy produces less improvement than for the English or German collections.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,206.22,407.22,182.54,9.02;2,78.00,428.79,30.25,8.74;2,78.00,440.79,126.13,8.74;2,78.00,452.79,437.76,8.74;2,78.00,464.79,113.57,8.74;2,78.00,476.79,120.91,8.74;2,78.00,488.79,121.70,8.74;2,78.00,500.79,104.93,8.74;2,78.00,512.79,130.33,8.74;2,78.00,524.79,211.98,8.74;2,78.00,536.79,190.56,8.74;2,78.00,548.79,200.82,8.74;2,78.00,560.79,222.98,8.74;2,78.00,572.79,170.22,8.74;2,78.00,584.79,219.26,8.74;2,78.00,596.79,223.16,8.74;2,78.00,608.79,325.44,8.74;2,78.00,620.79,293.14,8.74"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure 1: Record example written in German &lt;DOC&gt; &lt;DOCNO&gt; GIRT-EN19904041 &lt;TITLE-EN &gt; Impact of Information Technologies on Future Employment and Training Perspectives in the EC &lt;AUTHOR&gt; Riedel, Monika &lt;AUTHOR&gt; Wagner, Michael &lt;PUBLICATION-YEAR&gt; 1990 &lt;LANGUAGE-CODE&gt; EN &lt;CONTROLLED-TERM-EN&gt; EC &lt;CONTROLLED-TERM-EN&gt; information technology &lt;CONTROLLED-TERM-EN&gt; employment trend &lt;CONTROLLED-TERM-EN&gt; vocational education &lt;CONTROLLED-TERM-EN&gt; qualification requirements &lt;METHOD-TERM-EN&gt; document analysis &lt;CLASSIFICATION-TEXT-EN&gt; Employment Research &lt;CLASSIFICATION-TEXT-EN&gt; Labor Market Research &lt;CLASSIFICATION-TEXT-EN &gt; Occupational Research, Occupational Sociology &lt;CLASSIFICATION-TEXT-EN&gt; Vocational Training, Adult Education …</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,76.56,407.19,419.58,254.62"><head></head><label></label><figDesc>or263). Example on four different entries in the GIRT thesaurus Table</figDesc><table coords="3,76.56,430.17,419.58,214.37"><row><cell>&lt;ENTRY&gt;</cell><cell>&lt;ENTRY&gt;</cell></row><row><cell>&lt;GERMAN&gt; Raumwahrnehmung</cell><cell>&lt;GERMAN&gt; Volksstamm</cell></row><row><cell>&lt;GERMAN-CAPS&gt; RAUMWAHRNEHMUNG</cell><cell>&lt;GERMAN-CAPS&gt; VOLKSSTAMM</cell></row><row><cell>&lt;BROADER-TERM&gt; Wahrnehmung</cell><cell>&lt;USE-INSTEAD&gt; ethnische Gruppe</cell></row><row><cell>&lt;RELATED-TERM&gt; Perspektive</cell><cell>&lt;ENGLISH-TRANSLATION&gt; tribe</cell></row><row><cell>&lt;ENGLISH-TRANSLATION&gt; spatial orientation</cell><cell>&lt;/ENTRY&gt;</cell></row><row><cell>&lt;/ENTRY&gt;</cell><cell></cell></row><row><cell>&lt;ENTRY&gt;</cell><cell>&lt;ENTRY&gt;</cell></row><row><cell>&lt;GERMAN&gt; Volksabstimmung</cell><cell>&lt;GERMAN&gt; Wachstumspolitik</cell></row><row><cell>&lt;GERMAN-CAPS&gt; VOLKSABSTIMMUNG</cell><cell>&lt;GERMAN-CAPS&gt; WACHSTUMSPOLITIK</cell></row><row><cell>&lt;BROADER-TERM&gt; direkte Demokratie</cell><cell>&lt;USE-COMBINATION&gt; Wirtschaftspolitik</cell></row><row><cell>&lt;NARROWER-TERM&gt; Volksbegehren</cell><cell>&lt;USE-COMBINATION&gt; Wirtschaftswachstum</cell></row><row><cell>&lt;NARROWER-TERM&gt; Volksentscheid</cell><cell>&lt;ENGLISH-TRANSLATION&gt; policy of economic</cell></row><row><cell>&lt;ENGLISH-TRANSLATION&gt; plebiscite</cell><cell>growth</cell></row><row><cell>&lt;/ENTRY&gt;</cell><cell>&lt;/ENTRY&gt;</cell></row><row><cell>…</cell><cell></cell></row><row><cell>Figure 3:</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,101.82,176.78,350.02,294.59"><head>Table 1 :</head><label>1</label><figDesc>CLEF GIRT-4 and ISISS test collection statistics</figDesc><table coords="4,324.96,176.78,116.25,8.74"><row><cell>English</cell><cell>Russian</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,70.92,73.08,432.00,20.29"><head>Table 3</head><label>3</label><figDesc>reports the evaluations done for the Russian language (word-based indexing &amp; n-gram indexing (McNamee</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,91.26,210.39,412.51,166.61"><head>Table 2 :</head><label>2</label><figDesc>Mean average precision of various single searching strategies (monolingual, GIRT-4 corpus)</figDesc><table coords="6,104.94,210.39,383.75,146.68"><row><cell></cell><cell>German</cell><cell>German</cell><cell>German</cell><cell>English</cell><cell>English</cell></row><row><cell>Query</cell><cell>T</cell><cell>TD</cell><cell>TDN</cell><cell>TD</cell><cell>TDN</cell></row><row><cell>Model \ # of queries</cell><cell>25 queries</cell><cell>25 queries</cell><cell>25 queries</cell><cell>25 queries</cell><cell>25 queries</cell></row><row><cell>DFR PB2</cell><cell>0.2375</cell><cell>0.2635</cell><cell>0.2820</cell><cell>0.3122</cell><cell>0.3329</cell></row><row><cell>DFR PL2</cell><cell>0.2288</cell><cell>0.2500</cell><cell>0.2885</cell><cell>0.2978</cell><cell>0.3114</cell></row><row><cell>DFR GL2</cell><cell>0.2363</cell><cell>0.2608</cell><cell>0.2905</cell><cell>0.2710</cell><cell>0.2852</cell></row><row><cell>DFR I(n)B2</cell><cell>0.2605</cell><cell>0.2898</cell><cell>0.2983</cell><cell>0.3130</cell><cell>0.3254</cell></row><row><cell>DFR I(n)L2</cell><cell>0.2469</cell><cell>0.2700</cell><cell>0.3015</cell><cell>0.2896</cell><cell>0.3254</cell></row><row><cell>LM (λ=0.35)</cell><cell>0.2271</cell><cell>0.2526</cell><cell>0.2993</cell><cell>0.2603</cell><cell>0.2929</cell></row><row><cell>Okapi</cell><cell>0.2432</cell><cell>0.2616</cell><cell>0.2927</cell><cell>0.2549</cell><cell>0.2501</cell></row><row><cell>tf idf</cell><cell>0.1704</cell><cell>0.1835</cell><cell>0.2019</cell><cell>0.1980</cell><cell>0.2091</cell></row><row><cell>Mean (top-7 best models)</cell><cell>0.2400</cell><cell>0.2640</cell><cell>0.2933</cell><cell>0.2855</cell><cell>0.3033</cell></row><row><cell cols="2">% change over TD queries -9.09%</cell><cell></cell><cell>+11.1%</cell><cell></cell><cell>+6.2%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,70.92,577.98,422.24,123.32"><head>Table 3 :</head><label>3</label><figDesc>Mean average precision of various single search strategies (monolingual, ISISS corpus)</figDesc><table coords="6,70.92,601.44,384.76,99.86"><row><cell>4.3. Blind-Query Expansion</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Mean average precision</cell><cell></cell></row><row><cell>Query TD</cell><cell>German</cell><cell>German</cell><cell>German</cell></row><row><cell>Rocchio' model</cell><cell>25 queries</cell><cell>25 queries</cell><cell>25 queries</cell></row><row><cell>IR Model / MAP</cell><cell>Okapi 0.2616</cell><cell>DFR I(n)B2 0.2898</cell><cell>LM 0.2526</cell></row><row><cell>k doc. / m terms</cell><cell>5/70 0.2872</cell><cell>5/70 0.3298</cell><cell>5/70 0.3014</cell></row><row><cell></cell><cell>10/100 0.3051</cell><cell>10/100 0.3349</cell><cell>10/100 0.2973</cell></row><row><cell></cell><cell>10/200 0.3107</cell><cell>10/200 0.3435</cell><cell>10/200 0.3076</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="6,112.32,712.20,370.38,9.02"><head>Table 4 :</head><label>4</label><figDesc>Mean average precision using blind-query expansion (German GIRT-4 collection)</figDesc><table coords="7,292.38,73.83,95.86,8.74"><row><cell>Mean average precision</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="7,113.10,165.96,368.85,9.02"><head>Table 5 :</head><label>5</label><figDesc>Mean precision using blind-query expansion (English GIRT-4 collection)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="7,107.76,305.79,365.43,88.67"><head>Table 6 :</head><label>6</label><figDesc>Mean average precision using blind-query expansion (Russian, ISISS corpus)</figDesc><table coords="7,107.76,305.79,345.40,68.75"><row><cell>Query TD</cell><cell>Russian</cell><cell>Russian</cell><cell>Russian</cell></row><row><cell>PRF Rocchio's model</cell><cell>22 queries</cell><cell>22 queries</cell><cell>22 queries</cell></row><row><cell>IR Model / MAP</cell><cell>Okapi 0.1630</cell><cell>DFR InB2 0.1775</cell><cell>LM 0.1511</cell></row><row><cell>k doc. / m terms</cell><cell>5/50 0.1709</cell><cell>5/50 0.1397</cell><cell>5/50 0.1515</cell></row><row><cell></cell><cell>10/20 0.1712</cell><cell>10/20 0.1462</cell><cell>10/20 0.1614</cell></row><row><cell></cell><cell>10/60 0.1709</cell><cell>10/60 0.1477</cell><cell>10/10 0.1645</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="7,87.66,661.92,419.69,20.29"><head>Table 7 :</head><label>7</label><figDesc>Mean average precision of various IR models with and without using the specialized thesaurus (monolingual, GIRT-4 corpus)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" coords="8,85.14,675.66,380.26,26.29"><head>Table 8 :</head><label>8</label><figDesc>Description and mean average precision (MAP) of our official GIRT runsTable</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>The authors would like to also thank the GIRT -CLEF-2007 task organizers for their efforts in developing domain-specific test-collections. This research was supported in part by the <rs type="funder">Swiss National Science Foundation</rs> under Grant #<rs type="grantNumber">200021-113273</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_BDyY6Zc">
					<idno type="grant-number">200021-113273</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>if (word ends with "-ь") then remove "-ь" return; if (word ends with "-и") then remove "-и"return; if (word ends with "-нн") then replace by "-н" return; return;</p><p>RemoveCase (word) { if (word ends with "-иями") then remove "-иями" return; if (word ends with "-оями") then remove "-оями" return; if (word ends with "-оиев") then remove "-оиев" return; if (word ends with "-иях") then remove "-иях" return; if (word ends with "-иям") then remove "-иям" return; if (word ends with "-ями") then remove "-ями" return; if (word ends with "-оям") then remove "-оям" return; if (word ends with "-оях") then remove "-оях" return; if (word ends with "-ами") then remove "-ами" return; if (word ends with "-его") then remove "-его" return; if (word ends with "-ему") then remove "-ему" return; if (word ends with "-ери") then remove "-ери" return; if (word ends with "-ими") then remove "-ими" return; if (word ends with "-иев") then remove "-иев" return; if (word ends with "-ого") then remove "-ого" return; if (word ends with "-ому") then remove "-ому" return; if (word ends with "-ыми") then remove "-ыми" return; if (word ends with "-оев") then remove "-оев" return; if (word ends with "-яя") then remove "-яя" return; if (word ends with "-ях") then remove "-ях" return; if (word ends with "-юю") then remove "-юю" return; if (word ends with "-ая") then remove "-ая" return; if (word ends with "-ах") then remove "-ах" return; if (word ends with "-ею") then remove "-ею" return; if (word ends with "-их") then remove "-их" return; if (word ends with "-ия") then remove "-ия" return; if (word ends with "-ию") then remove "-ию" return; if (word ends with "-ие") then remove "-ие" return; if (word ends with "-ий") then remove "-ий" return; if (word ends with "-им") then remove "-им" return; if (word ends with "-ое") then remove "-ое" return; if (word ends with "-ом") then remove "-ом" return; if (word ends with "-ой") then remove "-ой" return; if (word ends with "-ов") then remove "-ов" return; if (word ends with "-ые") then remove "-ые" return; if (word ends with "-ый") then remove "-ый" return; if (word ends with "-ым") then remove "-ым" return; if (word ends with "-ми") then remove "-ми" return; if (word ends with "-ою") then remove "-ою" return; if (word ends with "-ую") then remove "-ую" return; if (word ends with "-ям") then remove "-ям" return; if (word ends with "-ых") then remove "-ых" return; if (word ends with "-ея") then remove "-ея" return; if (word ends with "-ам") then remove "-ам" return; if (word ends with "-ее") then remove "-ее" return; if (word ends with "-ей") then remove "-ей" return; if (word ends with "-ем") then remove "-ем" return; if (word ends with "-ев") then remove "-ев" return; if (word ends with "-я") then remove "-я" return; if (word ends with "-ю") then remove "-ю" return; if(word ends with "-й") then remove "-й" return; if (word ends with "-ы") then remove "-ы" return; if (word ends with "-[аеиоу]") then remove "-[аеиоу]" return; } </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="9,70.92,388.77,424.87,8.74;9,92.16,400.05,252.93,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,200.27,388.77,295.52,8.74;9,92.16,400.05,40.26,8.74">Searching in Medline: Stemming, query expansion, and manual indexing evaluation</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Abdou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,141.50,400.05,156.46,8.74">Information Processing &amp; Management</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct coords="9,70.92,413.31,446.36,8.74;9,92.16,424.32,365.41,9.02" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,241.55,413.31,275.73,8.74;9,92.16,424.59,114.35,8.74">Probabilistic models of information retrieval based on measuring the divergence from randomness</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,216.12,424.32,171.68,9.02">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="357" to="389" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.92,437.58,453.18,9.02;9,92.16,448.86,246.33,9.02" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,298.05,437.85,155.60,8.74">New retrieval approaches using SMART</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<idno>#500-236</idno>
	</analytic>
	<monogr>
		<title level="m" coord="9,473.94,437.58,50.16,9.02;9,92.16,448.86,40.65,9.02">Proceedings of TREC-4</title>
		<meeting>TREC-4<address><addrLine>Gaithersburg</addrLine></address></meeting>
		<imprint>
			<publisher>NIST Publication</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="25" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.92,462.39,368.95,8.74" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="9,159.30,462.39,193.01,8.74">Using language models for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note type="report_type">CTIT Ph.D. Thesis</note>
</biblStruct>

<biblStruct coords="9,70.92,475.65,448.76,8.74;9,92.16,486.66,268.66,9.02" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,159.25,475.65,343.42,8.74">Term-specific smoothing for the language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,92.16,486.66,124.68,9.02">Proceedings of the ACM-SIGIR</title>
		<meeting>the ACM-SIGIR<address><addrLine>Tempere</addrLine></address></meeting>
		<imprint>
			<publisher>The ACM Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="35" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.92,500.19,374.94,8.74" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="9,148.77,500.19,271.98,8.74">The GIRT data in the evaluation of CLIR systems -from 1997 until</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kluck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2004. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,450.91,500.19,58.60,8.74;9,92.16,511.20,408.95,9.02;9,92.16,522.48,259.31,9.02" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,258.90,511.20,242.21,9.02;9,92.16,522.48,29.96,9.02">Comparative Evaluation of Multilingual Information Access Systems</title>
	</analytic>
	<monogr>
		<title level="m" coord="9,128.95,522.75,51.21,8.74">LNCS #3237</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Kluck</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="376" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.92,535.74,439.61,9.02;9,92.16,547.02,92.54,9.02" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,223.51,535.74,268.98,9.02">Character n-gram tokenization for European language text retrieval</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mayfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,501.06,535.74,9.47,9.02;9,92.16,547.02,29.54,9.02">IR Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="73" to="97" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.92,560.55,410.74,8.74;9,92.16,571.56,223.16,9.02" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,283.51,560.55,193.05,8.74">Experimentation as a way of life: Okapi at TREC</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beaulieu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,92.16,571.56,157.71,9.02">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="95" to="108" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.92,584.82,428.39,9.02;9,92.16,596.10,102.61,9.02" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,148.75,585.09,332.44,8.74">Combining multiple strategies for effective monolingual and cross-lingual retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,489.84,584.82,9.47,9.02;9,92.16,596.10,29.54,9.02">IR Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="121" to="148" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,70.92,609.63,430.57,8.74;9,92.16,620.64,431.21,9.02;9,92.16,631.92,392.21,9.02" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,149.38,609.63,352.12,8.74;9,92.16,620.91,85.41,8.74">Report on CLEF-2003 monolingual tracks: Fusion of probabilistic models for effective monolingual retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,414.06,620.64,109.31,9.02;9,92.16,631.92,220.89,9.02">Comparative Evaluation of Multilingual Information Access Systems</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Kluck</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2004">2004b. 2004</date>
			<biblScope unit="page" from="322" to="336" />
		</imprint>
	</monogr>
	<note>LNCS #3237</note>
</biblStruct>

<biblStruct coords="9,70.92,645.45,426.06,8.74" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="9,208.33,645.45,263.56,8.74">Monolingual, Bilingual and GIRT Information Retrieval at CLEF</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P.-Y</forename><surname>Berger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2006. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,502.02,645.45,20.07,8.74;9,92.16,656.46,431.96,9.02;9,92.16,667.73,286.85,9.02" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="9,394.20,656.46,129.92,9.02;9,92.16,667.73,112.13,9.02">Multilingual Information Access for Text, Speech and Images</title>
		<editor>C. Peters, P. Clough, J. Gonzalo, G.J.F. Jones, M. Kluck &amp; B. Magnini</editor>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>Springer-Verlag</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
