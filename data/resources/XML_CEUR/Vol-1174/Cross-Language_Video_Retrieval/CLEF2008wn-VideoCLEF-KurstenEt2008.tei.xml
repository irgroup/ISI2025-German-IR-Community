<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,107.20,110.86,397.60,15.15;1,214.98,132.78,182.03,15.15">VideoCLEF 2008: ASR Classification based on Wikipedia Categories</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,196.19,166.68,55.33,8.74"><forename type="first">Jens</forename><surname>Kürsten</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Faculty of Computer Science</orgName>
								<orgName type="department" key="dep2">Dept. Computer Science and Media</orgName>
								<orgName type="institution">Chemnitz University of Technology</orgName>
								<address>
									<postCode>09107</postCode>
									<settlement>Chemnitz</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,259.57,166.68,63.12,8.74"><forename type="first">Daniel</forename><surname>Richter</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Faculty of Computer Science</orgName>
								<orgName type="department" key="dep2">Dept. Computer Science and Media</orgName>
								<orgName type="institution">Chemnitz University of Technology</orgName>
								<address>
									<postCode>09107</postCode>
									<settlement>Chemnitz</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,345.38,166.68,70.43,8.74"><forename type="first">Maximilian</forename><surname>Eibl</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Faculty of Computer Science</orgName>
								<orgName type="department" key="dep2">Dept. Computer Science and Media</orgName>
								<orgName type="institution">Chemnitz University of Technology</orgName>
								<address>
									<postCode>09107</postCode>
									<settlement>Chemnitz</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,107.20,110.86,397.60,15.15;1,214.98,132.78,182.03,15.15">VideoCLEF 2008: ASR Classification based on Wikipedia Categories</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9E36372B7D64DBEDD962C9824C3BBED0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing Measurement</term>
					<term>Performance</term>
					<term>Experimentation Automatic Speech Transcripts</term>
					<term>Video Classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This article describes our participation at the VideoCLEF track of the CLEF campaign 2008. We designed and implemented a prototype for the classification of the Video ASR data. Our approach was to regard the task as text classification problem. We used terms from Wikipedia categories as training data for our text classifiers. For the text classification the Naive-Bayes and kNN classifier from the WEKA toolkit were used. We submitted experiments for classification task 1 and 2. For the translation of the feeds to English (translation task) Google's AJAX language API was used. The evaluation of the classification task showed bad results for our experiments with a precision between 10 and 15 percent. These values did not meet our expectations. Interestingly, we could not improve the quality of the classification by using the provided metadata. But at least the created translation of the RSS Feeds was well.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this article we describe the general architecture of a system for the participation at the VideoCLEF track of the CLEF campaign 2008. The task was to categorize dual-language video into 10 given classes based on provided ASR transcripts <ref type="bibr" coords="1,186.06,600.50,9.96,8.74" target="#b1">[2]</ref>. The participants had to generate RSS Feeds that contain the videos for each of the 10 categories. The content of the RSS items for each of the videos was also given <ref type="foot" coords="1,453.52,610.88,3.97,6.12" target="#foot_0">1</ref> .</p><p>Our approach to solve the problem mainly relies on the application of a text classifier. We use the textual content of Wikipedia<ref type="foot" coords="1,163.65,634.79,3.97,6.12" target="#foot_1">2</ref> categories that are equal or at least highly related to the 10 given categories. The classification of the ASR transcripts will be done by classifiers from the WEKA toolkit <ref type="bibr" coords="1,453.54,648.32,9.96,8.74" target="#b2">[3]</ref>.</p><p>The remainder of the article is organized as follows. In section 2 we describe our system and its architecture. In section 3 we present the results of our submitted experiments. A summary of the result analysis is given in section 4. The final section concludes our experiments with respect to our expectations and gives and outlook to future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Architecture</head><p>The general architecture of the system we used is illustrated in figure <ref type="figure" coords="2,367.57,140.75,3.87,8.74">1</ref>. Besides the given input data (archival metadata, ASR transcripts and RSS items) we used a snapshot of the English and the Dutch Wikipedia as external training data. We extracted terms related to the given categories by applying a category mapping. These extracted terms were later used as training data for our text classifiers. In the following subsections we describe the components and operational steps of our system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Word Processor</head><p>Training Term Dictionary (Wikipedia) </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Classifier Training</head><p>The training of the classifier consists of three essential steps that will be explained in the subsections below. At first a fixed number of terms were extracted by using the JWPL library <ref type="bibr" coords="2,402.20,586.16,10.52,8.74" target="#b3">[4]</ref> for each of the 10 categories. These terms were then used to train two classifiers of the WEKA toolkit. Namely the Naive-Bayes and the kNN (with k = 4) classifier were used. In the last step of the training the classifiers were stored because they should remain available for the later classification step.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Wikipedia Term Extraction</head><p>Before the extraction of the terms was done, we needed to specify a mapping between the two source language categories and the available Wikipedia categories. The specified categories formed the starting points for the Wikipedia term extraction procedure. The final mapping is presented in table 1. Another important parameter of the system and also for the creation of the TRTDs is the depth (D) we use to descend in the Wikipedia link structure. The maximum size of each TRTD directly depends on the parameter D, because only when we descend to a certain depth in the linking structure of the Wikipedia category tree we could extract a sufficient number of unique terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Word Processing</head><p>Before the extracted terms were added to the TRTD, they were processed by our word processor (WP). The word processor simply applied a language-specific stopword list and reduced the term to its root with the help of the Snowball stemmers <ref type="foot" coords="3,204.39,458.71,3.97,6.12" target="#foot_3">4</ref> for English and Dutch.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.4">TRTD Balancing</head><p>After our first experiments with the creation of the TRTDs for all 10 categories we discovered, that the TRTDs were unbalanced with respect to the number of unique terms. This is due to the fact that the categories have different total numbers of sub-categories and these again contain different amounts of terms. To avoid that some categories will get a large weight because of a high TMAX that could never be satisfied by a category with a smaller number of pages, we decided to implement two different thresholds to balance the TRTDs in terms of their size. The first strategy was simply to use the term amount of the smallest category as TMAX, but it turned out that this creates bad classifications when TMAX and D are small. So we decided to use the mean of the term amounts of all 10 categories, which means that some categories might have a too small number of terms, but in general the TRTDs are balanced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.5">TRTD Discrimintation</head><p>For a better discrimination of the categories we implemented a training term duplication threshold (WT). This threshold is used to delete terms from the TRTDs that occur in at least (WT) categories. We assumed that this might help during the classification step. Our idea is that a natural term distribution that can be found in the Wikipedia could not be categorized very well. By implementing this assumption we hoped to improve the precision of the classification.</p><p>Another parameter that might be useful for the discrimination of the TRTDs is the frequency based selection (FS) of the terms. As mentioned before we selected a maximum number of terms (TMAX) for each category. We could use different strategies for that because the TRTDs most likely contain much more terms than we may want to extract. We implemented two options for the selection of the terms. The first is just to use the terms with the highest occurrence and the second is to take the average term occurrence frequency and to extract 0.5 times TMAX of the terms above and below this average.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.6">TRTD Term Statistics</head><p>Table <ref type="table" coords="4,97.38,201.63,4.98,8.74" target="#tab_2">2</ref> represents the TRTD term statistics for all categories (columns 1-10) depending on selected parameter settings for the discrimination threshold (WT) and the depth of the linkage extraction (D) for the English Wikipedia snapshot. We marked the category with the minimum and maximum amount of terms for each of the configurations. It is obvious that the amount of terms increases for all categories when the depth for descending in the link structure (D) is increased. In the English Wikipedia the category science contained the largest amount of terms, followed by history, music and visual arts. The smallest amount of terms could be extracted for the category paintings. In our opinion the statistic allows to draw the following conclusions for the parameter sets. With WT=2, i.e. that all term duplicates were removed that occur in at least two category TRTDs, we could create the most balanced TRTDs. All parameter sets with WT¿3 create TRTDs with more realistic term distributions.</p><p>For the term statistics of the Dutch Wikipedia one could draw similar conclusions, but there are some differences. The most important difference is the smaller number of entries in the Dutch Wikipedia, which generally results in smaller TRTDs. Also the distribution of the specified categories is little different. There are no outliers like science or paintings, which consequently follows from the smaller amount of pages. For the Dutch Wikipedia the category dans produced the smallest TRTD.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.7">Training Setup</head><p>In the first step of the classifier training process we loaded the relevant TRTD for each category. Thereafter, we fed the instances of the TRTD into the Naive-Bayes and kNN classifiers. Finally, the classifiers were stored, because we wanted them to remain for further evaluations of different parameter sets for the complete system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Test Set Creation</head><p>For the preparation of the classification it was necessary to parse the ASR transcripts and to extract the textual information. We also parsed the metadata that could be used for the classification task 2. We used the same procedure for the creation of the test term dictionaries (TSTD) as we did before for the creation of the TRTDs. At first the word processor removes stopwords and then it stems all terms to their root. For the TSTDs we also applied a parameter (VT) for the removal of duplicate terms. We hoped this would help in discriminating the ASR transcripts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Classification</head><p>In the classification process the stored classifiers were reloaded into memory. They were then used to classify the contents of the TSTD for each video. The results of the classification are 10 probabilities for the membership of the video in all of the 10 specified categories. These probabilities sum up to 1 for each term of the TSTD. This was repeated for all terms in the TSTD in order to get a final classification. For the classification task 2 we also used the terms from the metadata files for classification.</p><p>As next step we normalized the returned classifications, i.e. each of the 10 specified categories were normalized to find the final classification of the videos. The normalization is defined as the sum of the arithmetic mean and the standard deviation of each category. This sum was used as final classification threshold (CT) for each corresponding category.</p><p>In the last step the final classification was created. Therefore we iteratively decreased a predefined score (S), which is always larger than CT, until at least one of the ten CT values is larger than S. Finally, we compared the resulting S with all CT for the 10 categories and assigned the corresponding classification to the video.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">RSS Feed Creation</head><p>The RSS Feeds were created continuously during the last step of the classification. Thereby, the RSS item for each video was subsequently added to the corresponding category RSS Feeds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">RSS Feed Translation</head><p>The translation of the RSS Feeds was conducted when all categories were complete. For the translation we used Google's AJAX Language API<ref type="foot" coords="5,228.33,496.66,3.97,6.12" target="#foot_4">5</ref> , which is the actual translation component of the Xtrieval framework <ref type="bibr" coords="5,70.87,510.19,9.96,8.74" target="#b0">[1]</ref>. The translation was technically limited to a maximal amount of 100 characters per time. Therefore we split the Feed contents into sentences and translated these. Thereafter we rebuilt the RSS Feed in the translated language.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head><p>This section provides experimental results on the development and test sets. At first, we describe the determination of the parameters by using the development set and finally we present the setup of the complete system for the experiments on the test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Parameter Tuning with Development Data</head><p>We used the development data for the tuning the parameter set of our system for the experiments on the test data. The system has six important parameters: • Training Term Duplicate Deletion (WT); 5 for deletion of terms that appear in at least 5 categories</p><p>• Test Term Duplicate Deletion (VT); 5 for deletion of terms that appear in at least 5 video ASR transcripts</p><p>• Classifiers (C); we used both Naives-Bayes and kNN (k = 4) for all experiments Table <ref type="table" coords="6,98.31,217.49,4.98,8.74" target="#tab_3">3</ref> shows selected experiments on the development data. We chose the best performing parameter sets for different sizes (TMAX) of the training term dictionaries. For the evaluation of the performance we used the mean average precision (MAP) over the 10 specified categories. We derived two possibly useful parameter sets from table <ref type="table" coords="6,318.79,458.98,3.87,8.74" target="#tab_3">3</ref>. At first for large TRTDs with TMAX &gt; 3000 the parameter set (0;3;2;5) seemed to be promising. For smaller TRTDs with TMAX ≤ 3000 the parameter set (1;2;2;2) could be useful. Unfortunately, we tested the configuration with TMAX = 1000 after the deadline of the submission.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experimental Setup and Results</head><p>We submitted two experiments for each of the two classification tasks. The results of the evaluation are presented in table <ref type="table" coords="6,152.03,553.08,3.87,8.74" target="#tab_4">4</ref>. The results were not very well and did not meet our expectations and observations on the development data. Interestingly, using the metadata in classification task 2 did not improve the classification performance in both cases.</p><p>Additionally, we submitted a translation of the RSS Feeds. The translation was evaluated by three assessors in terms of fluency (1-5) and adequacy (1-5). The higher the score the better was the quality of the translation. The results are summarized in table 5. 4 Result Analysis -Summary</p><p>The following items conclude our observations of the experimental evaluation:</p><p>• Classification task 1: The quality of the video classification was not as good as expected, both in terms of precision and in terms of recall.</p><p>• Classification task 2: Surprisingly, the quality of the video classification could not be improved by utilizing the given metadata. The reason for that might be the small impact of the metadata in comparison to the large size of the TRTD we used.</p><p>• Translation task: The translation of the RSS Feeds was quite good, but there is also room for improvement, especially in terms of fluency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>The experiments showed that the classification of dual-language video based on ASR transcripts is a quite hard task. Nevertheless, we presented an idea to tackle the problem. But there are a number of points to improve the system. The two most important problems are the size of the training data on the one hand and the balance of the categories on the other hand. We consider to omit the TRTD balancing step and to shrink the TRTD size in further experiments. Another point might be to weight the TRTD based on an approximated distribution of the categories in the video collection, because this could be a good indicator on how to find the correct classes for a given video.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,85.81,74.02,207.47,8.74;6,85.81,93.95,455.32,8.74;6,95.77,105.90,24.44,8.74;6,85.81,125.83,216.55,8.74"><head>•</head><label></label><figDesc>Depth of Wikipedia Category Extraction (D) • Frequency-based Selection of Training Terms (FS); 0 for high frequency terms and 1 for mid frequency terms • Maximum Number of Training Terms (TMAX)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,70.87,82.38,470.27,270.63"><head>Table 1 :</head><label>1</label><figDesc>Category mapping for Dutch and English: Specified -WikipediaTo create a training set we extracted a specified number (TMAX) of unique terms from both Wikipedia snapshots by using the JWPL library 3 . This maximum number of terms is one of the most important parameters of the complete system. We have conducted several experiments with different values for TMAX, varying from 3000 to 10000 (see section Evaluation for more details). Since the extraction of the terms is very time consuming due to the large size of the Wikipedia we also stored the training term dictionaries (TRTD) for the categories and for different variations of the parameter TMAX. The training term dictionaries consist of a simple term list with term occurrence frequencies.</figDesc><table coords="3,70.87,94.75,435.03,168.14"><row><cell cols="2">id specified NL cat.</cell><cell cols="2">mapped NL cat. specified EN cat.</cell><cell>mapped EN cat.</cell></row><row><cell>0</cell><cell>archeologie</cell><cell>archeologie</cell><cell>archeology</cell><cell>archaeology</cell></row><row><cell>1</cell><cell>architectuur</cell><cell>architectuur</cell><cell>architecture</cell><cell>architecture</cell></row><row><cell>2</cell><cell>chemie</cell><cell>scheikunde</cell><cell>chemistry</cell><cell>chemistry</cell></row><row><cell>3</cell><cell>dansen</cell><cell>dans</cell><cell>dance</cell><cell>dance</cell></row><row><cell>4</cell><cell>film</cell><cell>film</cell><cell>film</cell><cell>film</cell></row><row><cell>5</cell><cell>geschiedenis</cell><cell>geschiedenis</cell><cell>history</cell><cell>history</cell></row><row><cell>6</cell><cell>muziek</cell><cell>muziek</cell><cell>music</cell><cell>music</cell></row><row><cell>7</cell><cell>schilderijen</cell><cell>schilderkunst</cell><cell>paintings</cell><cell>paintings</cell></row><row><cell>8</cell><cell cols="2">wetenschappelijk onderzoek wetenschap</cell><cell cols="2">scientific research scientific research</cell></row><row><cell>9</cell><cell>beeldende kunst</cell><cell cols="2">beeldende kunst visual arts</cell><cell>visual arts</cell></row><row><cell cols="2">2.1.2 Training Set Creation</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,99.54,268.86,412.92,239.49"><head>Table 2 :</head><label>2</label><figDesc>Training Term Dictionary Statistics</figDesc><table coords="4,99.54,281.23,412.92,227.12"><row><cell cols="3">WT D 0</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell></row><row><cell>0</cell><cell>2</cell><cell>3064</cell><cell>5658</cell><cell cols="2">7999 4073</cell><cell>5359</cell><cell>6062</cell><cell>6781</cell><cell>408</cell><cell>7611</cell><cell>7996</cell></row><row><cell>2</cell><cell>2</cell><cell>680</cell><cell>688</cell><cell>685</cell><cell>681</cell><cell>690</cell><cell>689</cell><cell>689</cell><cell>93</cell><cell>689</cell><cell>3712</cell></row><row><cell>4</cell><cell>2</cell><cell>1181</cell><cell>1471</cell><cell>1445</cell><cell>1275</cell><cell>1470</cell><cell>1509</cell><cell>1437</cell><cell>268</cell><cell>4404</cell><cell>4777</cell></row><row><cell>5</cell><cell>2</cell><cell>1396</cell><cell>1830</cell><cell>1810</cell><cell>1528</cell><cell>1841</cell><cell>1930</cell><cell>5015</cell><cell>300</cell><cell>5049</cell><cell>5461</cell></row><row><cell>6</cell><cell>2</cell><cell>1576</cell><cell>2178</cell><cell>2152</cell><cell>1748</cell><cell>2176</cell><cell>4607</cell><cell>5533</cell><cell>340</cell><cell>5743</cell><cell>6109</cell></row><row><cell>8</cell><cell>2</cell><cell>1972</cell><cell>3138</cell><cell>3142</cell><cell>4017</cell><cell>5223</cell><cell>5606</cell><cell>6651</cell><cell>396</cell><cell>7137</cell><cell>7612</cell></row><row><cell>0</cell><cell>3</cell><cell>8804</cell><cell cols="9">19404 16591 10003 15874 23210 29230 1178 32720 24694</cell></row><row><cell>2</cell><cell>3</cell><cell>2190</cell><cell>2247</cell><cell>2226</cell><cell>2207</cell><cell>2237</cell><cell>2246</cell><cell>2243</cell><cell>480</cell><cell>2247</cell><cell>9259</cell></row><row><cell>4</cell><cell>3</cell><cell>3648</cell><cell>4853</cell><cell>4368</cell><cell>3816</cell><cell>4675</cell><cell>4974</cell><cell>4988</cell><cell>831</cell><cell cols="2">18906 12778</cell></row><row><cell>5</cell><cell>3</cell><cell>4160</cell><cell>6112</cell><cell>5186</cell><cell>4390</cell><cell>5746</cell><cell>6367</cell><cell cols="2">21029 946</cell><cell cols="2">21343 15364</cell></row><row><cell>6</cell><cell>3</cell><cell>4677</cell><cell>7468</cell><cell>6041</cell><cell>4936</cell><cell>6816</cell><cell cols="5">17713 23494 1060 24786 18028</cell></row><row><cell>8</cell><cell>3</cell><cell>6193</cell><cell cols="2">11143 8190</cell><cell>9944</cell><cell cols="6">15715 21632 28726 1172 29963 22869</cell></row><row><cell>0</cell><cell>4</cell><cell cols="10">18115 36674 27080 14024 42627 81622 75143 1284 96156 56295</cell></row><row><cell>2</cell><cell>4</cell><cell>3838</cell><cell>3881</cell><cell>3847</cell><cell>3822</cell><cell>3882</cell><cell>3883</cell><cell>3883</cell><cell>653</cell><cell>3883</cell><cell>15340</cell></row><row><cell>4</cell><cell>4</cell><cell>7148</cell><cell>9974</cell><cell>8106</cell><cell>6735</cell><cell>9886</cell><cell cols="3">10408 10359 974</cell><cell cols="2">50259 24318</cell></row><row><cell>5</cell><cell>4</cell><cell>8356</cell><cell cols="2">13150 9612</cell><cell>7774</cell><cell cols="6">13161 14800 52403 1062 57710 31773</cell></row><row><cell>6</cell><cell>4</cell><cell>9588</cell><cell cols="3">16326 10976 8622</cell><cell cols="6">16350 63649 62477 1200 72852 41990</cell></row><row><cell>8</cell><cell>4</cell><cell cols="10">13572 25228 15168 14013 42465 76956 74530 1284 88037 54257</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,190.95,274.16,230.11,168.16"><head>Table 3 :</head><label>3</label><figDesc>Selected Experiments on the Development Data</figDesc><table coords="6,219.82,286.53,171.34,155.79"><row><cell cols="6">TMAX FS D WT VT MAP</cell></row><row><cell>10000</cell><cell>0</cell><cell>3</cell><cell>2</cell><cell>5</cell><cell>0.4</cell></row><row><cell>10000</cell><cell>0</cell><cell>3</cell><cell>2</cell><cell>7</cell><cell>0.33</cell></row><row><cell>10000</cell><cell>0</cell><cell>2</cell><cell>9</cell><cell>9</cell><cell>0.18</cell></row><row><cell>5000</cell><cell>0</cell><cell>3</cell><cell>2</cell><cell>5</cell><cell>0.4</cell></row><row><cell>5000</cell><cell>1</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>0.4</cell></row><row><cell>5000</cell><cell>1</cell><cell>2</cell><cell>8</cell><cell>2</cell><cell>0.34</cell></row><row><cell>3000</cell><cell>0</cell><cell>3</cell><cell>2</cell><cell>5</cell><cell>0.4</cell></row><row><cell>3000</cell><cell>1</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>0.4</cell></row><row><cell>3000</cell><cell>0</cell><cell>5</cell><cell>9</cell><cell>2</cell><cell>0.37</cell></row><row><cell>1000</cell><cell>1</cell><cell>2</cell><cell>2</cell><cell>7</cell><cell>0.51</cell></row><row><cell>1000</cell><cell>0</cell><cell>5</cell><cell>9</cell><cell>2</cell><cell>0.48</cell></row><row><cell>1000</cell><cell>1</cell><cell>2</cell><cell>2</cell><cell>2</cell><cell>0.48</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,182.52,585.29,246.96,71.72"><head>Table 4 :</head><label>4</label><figDesc>Experimental Results based on the Evaluation Data</figDesc><table coords="6,208.19,597.66,195.62,59.35"><row><cell cols="6">TMAX FS D WT VT P</cell><cell>R</cell></row><row><cell>3000</cell><cell>0</cell><cell>3</cell><cell>2</cell><cell>5</cell><cell cols="2">0.15 0.14</cell></row><row><cell>5000</cell><cell>0</cell><cell>4</cell><cell>5</cell><cell>5</cell><cell cols="2">0.10 0.12</cell></row><row><cell>3000</cell><cell>0</cell><cell>3</cell><cell>2</cell><cell>5</cell><cell cols="2">0.13 0.12</cell></row><row><cell>5000</cell><cell>0</cell><cell>4</cell><cell>5</cell><cell>5</cell><cell cols="2">0.12 0.14</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,199.64,128.20,211.97,47.41"><head>Table 5 :</head><label>5</label><figDesc>Assessment of the Translation</figDesc><table coords="7,199.64,140.57,211.97,35.04"><row><cell cols="5">Criterion Ass. 1 Ass. 2 Ass. 3 Average</cell></row><row><cell>fluency</cell><cell>2.88</cell><cell>2.65</cell><cell>2.93</cell><cell>2.82</cell></row><row><cell cols="2">adequacy 3.53</cell><cell>3.15</cell><cell>3.80</cell><cell>3.49</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,86.11,691.16,240.82,6.99"><p>http://ilps.science.uva.nl/Vid2RSS/Vid2RSS08/Vid2RSS08.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,86.11,700.67,86.81,6.99"><p>http://en.wikipedia.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,86.11,687.34,177.94,6.99"><p>http://www.ukp.tu-darmstadt.de/software/jwpl</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="3,86.11,696.84,104.56,6.99"><p>http://snowball.tartarus.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="5,86.11,689.94,217.17,6.99"><p>http://code.google.com/apis/ajaxlanguage/documentation</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,86.36,526.44,454.77,8.74;7,86.36,538.40,454.77,8.74;7,86.36,550.35,109.09,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,334.78,526.44,206.36,8.74;7,86.36,538.40,33.48,8.74">Extensible retrieval and evaluation framework: Xtrieval</title>
		<author>
			<persName coords=""><forename type="first">Jens</forename><surname>Kürsten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Wilhelm</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maximilian</forename><surname>Eibl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,132.26,538.40,182.25,8.74;7,440.79,538.40,95.98,8.74">LWA 2008: Lernen -Wissen -Adaption</title>
		<meeting><address><addrLine>Würzburg</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-10">October 2008. October 2008</date>
		</imprint>
	</monogr>
	<note>Workshop Proceedings. to appear</note>
</biblStruct>

<biblStruct coords="7,86.36,570.28,454.77,8.74;7,86.36,582.24,454.77,8.74;7,86.36,594.19,22.69,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,323.66,570.28,217.48,8.74;7,86.36,582.24,258.81,8.74">Overview of videoclef 2008: Automatic generation of topic-based feeds for dual language audio-visual content</title>
		<author>
			<persName coords=""><forename type="first">Martha</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eamonn</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gareth</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,356.11,582.24,130.30,8.74">CLEF 2008: Workshop Notes</title>
		<imprint>
			<date type="published" when="2008-09">September 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,86.36,614.12,454.77,8.74;7,86.36,626.07,225.66,8.74" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="7,226.30,614.12,269.14,8.74">Data mining : practical machine learning tools and techniques</title>
		<author>
			<persName coords=""><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eibe</forename><surname>Frank</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Morgan Kaufman</publisher>
			<pubPlace>Amsterdam</pubPlace>
		</imprint>
	</monogr>
	<note>2. ed. edition</note>
</biblStruct>

<biblStruct coords="7,86.36,646.00,454.77,8.74;7,86.36,657.95,454.77,8.74;7,86.36,669.91,99.99,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,342.16,646.00,198.97,8.74;7,86.36,657.95,110.63,8.74">Extracting lexical semantic knowledge from wikipedia and wiktionary</title>
		<author>
			<persName coords=""><forename type="first">Torsten</forename><surname>Zesch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christof</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,209.35,657.95,331.79,8.74;7,86.36,669.91,46.40,8.74">Proceedings of the Sixth International Language Resources and Evaluation (LREC&apos;08)</title>
		<meeting>the Sixth International Language Resources and Evaluation (LREC&apos;08)</meeting>
		<imprint>
			<date type="published" when="2008-05">May 2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
