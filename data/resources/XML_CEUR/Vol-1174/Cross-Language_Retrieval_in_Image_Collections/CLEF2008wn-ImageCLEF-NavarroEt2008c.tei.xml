<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,90.17,148.62,422.77,15.51;1,233.93,170.53,135.15,15.51">A Multimodal Approach to the Medical Retrieval Task using IR-n</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,197.85,204.00,62.66,9.96"><forename type="first">Sergio</forename><surname>Navarro</surname></persName>
							<email>snavarro@dlsi.ua.es</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing and Information Systems Group</orgName>
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,268.51,204.00,57.85,9.96"><forename type="first">Rafael</forename><surname>Mu√±oz</surname></persName>
							<email>rafael@dlsi.ua.es</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing and Information Systems Group</orgName>
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,335.08,204.00,70.11,9.96"><forename type="first">Fernando</forename><surname>Llopis</surname></persName>
							<email>llopis@dlsi.ua.es</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing and Information Systems Group</orgName>
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,90.17,148.62,422.77,15.51;1,233.93,170.53,135.15,15.51">A Multimodal Approach to the Medical Retrieval Task using IR-n</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">11D0392245C20C4BE573B89FB3DBAD42</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.2 Information Storage H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2 [Database Managment]: H.2.5 Heterogenous Databases Measurement, Performance, Experimentation Information Retrieval, Image Retrieval, Multimodal Re-ranking, Late Fusion, Multimodal Relevance Feedback, PRF, LCA, MeSH, Automatic query expansion, Negative query expansion</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In our participation in the Medical Retrieval task we wanted to figure out if good results can be achieved with IR-n -our IR passage based system -for this restricted domain. We have focused on comparing the behaviour of two relevance feedback methods in this task -LCA and PRF -. Furthermore, in order to adapt our system to this task we have used two automatic query expansion techniques related with the medical domain. On one hand we have added to our system an automatic query expansion method based on MeSH ontology and on the other hand we have added a negative query expansion based on the acquisition type of the image. Finally we have added a multimodal re-ranking module -late fusion -. We have used two operation modes, one merges the two list in a classical re-ranking way, and the other mode bases the calculus of the relevance of an image on the quantity and the quality of the text related to the image in order to take the decision as to which system is more confident for that image -the system based on text or the one based on images -. A major finding of the results is that our passage based system fits very well to this task. Within the textual runs submitted by all the participants we have reached the 6th place for our baseline and the 1st place for a run using PRF and query expansion adapted to the medical domain. Our results for multimodal re-ranking have not been successful due to problems with the parameters tuning for the test collection of this year.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This is the first time we are participating in the Medical Retrieval task. We had experience of participation in the photo retrieval task of 2007 . Our participation in ImageCLEFphoto<ref type="foot" coords="2,470.38,144.36,3.97,6.37" target="#foot_0">1</ref> involved the use of an information retrieval system based on passages. We analysed the suitability of our system for the short text annotations related to the images in the collection <ref type="bibr" coords="2,424.39,169.04,14.60,9.96" target="#b10">[11]</ref>.</p><p>We concluded that our system improved the results more in comparison to other systems, which were similar to our system except the fact that they did not use passages. The experiments also showed that relevance feedback is a good tool for improving results. In our participation in the Medical Retrieval task we wanted to figure out if good results can be also achieved with our passage based system for this restricted domain.</p><p>However, we noticed that in spite of the improvements in the general results brought by the relevance feedback -we used PRF <ref type="bibr" coords="2,240.36,252.73,15.51,9.96" target="#b11">[12]</ref> relevance feedback strategy -, this process also adds wrong terms for the expansion in some of the cases. Therefore we decided to focus part of our efforts on finding an alternative strategy for the relevance feedback, Thus, we are comparing in this CLEF edition PRF with Local Context Analisy (LCA) <ref type="bibr" coords="2,303.02,288.59,14.62,9.96" target="#b12">[13]</ref>, as alternate strategy.</p><p>Furthermore, in order to adapt our system to this task we have used two automatic query expansion techniques related with the medical domain. On one hand our system adds expanded terms to the queries based on MeSH ontology. And on the other hand when in the query there are terms related to the type of the images that have to be retrieved, the system uses a negative term expansion based on the terms related to other types of a taxonomy of types of images. In order to move away from the top positions of the ranking, those documents which do not belong to the type/s requested in the query.</p><p>Another important conclusion in our ImageCLEFphoto participation was that a multimedia approximation along with a suitable mixing procedure would constitute the key to successful participation in this task. Thus, we have added to our system a new operation mode that led to the establishment of a multimodal re-ranking strategy based on mixing the ranking that IR-n returns with the ranking that a CBIR returns. We have experimented with two operation modes, one merges the two list in a classical re-ranking way, and the other mode bases the calculus of the relevance of an image on the quantity and the quality of the text related to the image in order to take the decision of which system is more confident for that image.</p><p>This paper is structured as follows: Firstly, it presents the main characteristics of the IR-n system focusing focusing on the relevance feedback strategies, the automatic query expansion and the multimodal re-ranking strategy, then it moves on to explain the experiments we have made to evaluate the system, and finally it describes the results and conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The IR-n System</head><p>In our approach, we used IR-n -an information retrieval system based on passages -. Passagebased IR systems treat each document as a set of passages, with each passage defining a portion of text or contiguous block of text. Unlike document-based systems, these systems can consider the proximity of words with each other, that appear in a document in order to evaluate their relevance <ref type="bibr" coords="2,90.00,618.33,9.96,9.96" target="#b8">[9]</ref>.</p><p>The IR-n passage-based system differs from other systems of the same category with regard to the method proposed for defining the passage -that is -using sentences as unit. Thus, passages are defined by a number of consecutive sentences in a document <ref type="bibr" coords="2,372.77,654.19,9.96,9.96" target="#b8">[9]</ref>.</p><p>IR-n uses stemmer and stopword lists to determine which information in a document will be used for retrieval. For a list of stemmers and stopwords used by IR-n, see www.unine.ch/infor/clef. IR-n uses several weighting models. Weighting models allow the quantification of the similarity between a text -a complete document or a passage in a document -and a query. Values are based on the terms that are shared by the text and query and on the discriminatory importance of each term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Relevance Feedback</head><p>Most IR systems use relevance feedback techniques <ref type="bibr" coords="3,316.36,129.74,9.96,9.96" target="#b0">[1]</ref>. These systems usually employ local feedback. The local feedback assumes that top-ranked documents are relevant. The added terms are, therefore, common terms from the top-ranked documents. Local feedback has become a widely used relevance feedback technique. Although, it can deter retrieval, in case most of the top-ranked documents are not relevant, results in TREC an CLEF conferences show that is an effective technique <ref type="bibr" coords="3,116.20,189.52,14.62,9.96" target="#b12">[13]</ref>. In fact, almost all the systems that participated at ImageCLEF 2007 used Probabilistic Relevance Feedback (PRF) <ref type="bibr" coords="3,211.34,201.47,10.52,9.96" target="#b5">[6]</ref> [8] [5] <ref type="bibr" coords="3,252.87,201.47,9.96,9.96" target="#b2">[3]</ref>.</p><p>In the selection of terms, PRF gives more importance to those terms which have a higher frequency in the top relevant documents than in the whole collection. An alternative query expansion method relies on the Local Context Analysis (LCA), based on the hypothesis that a common term from the top-ranked relevant documents will tend to co-occur with all query terms within the top-ranked documents. That is an attempt to avoid including terms from top-ranked, non-relevant documents in the expansion. Furthermore, in the case of polysemus words, this method will help to retrieve documents more related to the sense of the query, since it is logical to think that the user will use words from the domain associated with this sense to complete the query.</p><p>The IR-n architecture allows us to use query expansion based on either the most relevant passages or the most relevant documents. In our experiments we have compared the performance of these two methods within the Medical Domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Automatic Query Expansion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Expanding Queries with MeSH</head><p>The Medical Subject Headings (MeSH) is a thesaurus developed by the National Library of Medicine. We have used MeSH terms and its synonyms to expand the queries. If all the words of a term are in the query -a term is composed of one or more words -we expand the query with the synonymous of this term. To compare the words of a particular term and those of the query, we first put all the words in lowercase and we do not remove stopwords. This method was implemented by Sinai group in their 2007 participation <ref type="bibr" coords="3,340.84,469.38,9.96,9.96" target="#b2">[3]</ref>. It leads to an improvement of the results, thus we have added it to our system in order to study its behaviour using a passage based system with LCA as relevance feedback method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Negative Expansion Based on the Acquisition Type of the Image</head><p>We have added a module for a negative query expansion. It is based on the acquisition type of the images. In this way, there was a previous work that used a filtering strategy according to the acquisition modality of the images <ref type="bibr" coords="3,239.10,561.48,9.96,9.96" target="#b6">[7]</ref>. That work used a supervised machine learning system witch used visual features to classify and to annotate images according to their acquisition modality.</p><p>In our approach we neither have used visual features nor filtering strategy but we have used a modified version of the classification proposed at this work. In order to analyse whether the negative expansion based on the acquisition modality as well can improve the precision without the use of visual features.</p><p>Our approach use the textual query and the original text annotations for the retrieval. In order to only retrieve images of the desired type in the query, our system looks for the terms that represent each acquisition type -Table <ref type="table" coords="3,259.39,657.12,4.98,9.96" target="#tab_0">1</ref> -in the query. And if there are terms regarding to one or more acquisition modality types, then the query is expanded with a negative weight for the terms related to the other types witch are not in the query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Multimodal Re-ranking Strategy</head><p>This strategy involve the merging of the list returned by the text based IR system and the list returned by the CBIR system. That is done giving a different weight to the normalized relevance value or ranking position for a document in each list. We have included the classical re-ranking strategy and also a variation of it in order to try to improve it and to compare its behaviour.</p><p>In the re-ranking strategy, the IR-n list and the CBIR list are merged in order to obtain one final list with documents ranked by relevance -the final relevance (FR) -. The merging process was done by giving different importance to the visual relevance (VR) given for a document in the visual list and the textual relevance (TR) given by the textual IR system:</p><formula xml:id="formula_0" coords="4,209.51,366.47,303.48,9.96">F R(d) = T R(d) * wT ext + V R(d) * wImg<label>(1)</label></formula><p>where d is a document.</p><p>where V R is a normalized value of the relevance value returned by the CBIR for a document.</p><p>where T R is a normalized value of the relevance value returned by the textual IR system for a document.</p><p>Despite this strategy usually improves the results, it usually adds a great number of non relevant images in the ranking. That is due to the low precision that CBIR systems usually obtains. It makes that when we use an image of the CBIR list there are a high level of probability to be selecting a non relevant image.</p><p>In an effort for overcome this circumstance, we have modified the re-ranking strategy. We have based our approach on two assumptions. On one hand that the textual list is more confident than the list based on images and on the other hand we assume that the TF-IDF formula is a suitable way to measure the quantity and the quality of a text.</p><p>In order to reduce to the minimum the number or non relevant images used from the image based list, we have established a TF-IDF threshold <ref type="bibr" coords="4,322.66,559.10,11.63,9.96" target="#b1">(2)</ref>. The images which annotations have a TF-IDF value over this threshold are skipped.</p><formula xml:id="formula_1" coords="4,214.75,594.96,298.24,9.96">threshold = (M axT F IDF * tImg)/100<label>(2)</label></formula><p>M axT F IDF is the maximum TF-IDF value found in the image list.</p><p>tImg is a user defined parameter which indicates the percentage value respect the M axT T IDF in order to work out the threshold.</p><p>Thus, in the ranking formula (3) the system uses the threshold in order to avoid the risk of use the CBIR relevance values for those images which annotations have enough quantity and quality of text to perform a suitable textual retrieval -without the use of the image -.</p><formula xml:id="formula_2" coords="4,177.61,708.68,335.39,24.31">F R(d) = T R(d) + V R(d), if threshold &gt; T F IDF (d) T R(d), else<label>(3)</label></formula><p>where T F IDF is the TF-IDF value of the text related to an image.</p><p>IR-n is a parameterizable system, which means that it can be adapted in line with the concrete characteristics of the task at hand. The parameters for this configuration are the number of sentences that form a passage, the weighting model to use, the type of expansion, the number of documents/passages on which the expansion is based, the average number of words per document, the use of MeSH for the automatic query expansion, the use of negative expansion based on the acquisition type of the image and the use of multimodal re-ranking,. This section describes the training process that was carried out in order to obtain the best possible features for improving the performance of the system. The collections and resources are described first, and the next section describes specific experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Collection</head><p>In this edition of the medical retrieval task the training for our participation has been done with the Consolidated Collection. This collection consists of the image collection and topics used in ImageCLEFmed 2005-2007 merged into one single new collection, with relevance judgments made for all topics based on all collections. This consolidated collection related files consists of six datasets (CASImage, Pathopic, Peir, MIR, endoscopic and MyPACS) containing 66,662 images. Each subcollection is organized into cases that represent a group of related images and annotations. In every case a group of images and an optional annotation is given. Each image is part of a case and has optional associated annotations, which enclose metadata and/or a textual annotation. All the images and annotations are stored into separated files. There are an index file which contains the connections between collections, cases, images and annotations. The collection annotations are in XML format and most of them are in English.</p><p>For this year task, a new collection has been used in order to evaluate and to compare the participant systems. This collection is the Goldminer collection <ref type="foot" coords="5,377.86,417.50,3.97,6.37" target="#foot_1">2</ref> The subset used contains all images from articles published in Radiology and Radiographics including the text of the captions and a link to the html of the full text articles. The database distributed include an xml file with the image id, the captions of the images, the titles of the journal articles in which the image had appeared and the PubMed ID of the journal article.</p><p>The SINAI group of the University of Jaen kindly has provided us with the preprocessed consolidated collection for this participation-which they used last year for their participation -, and the preprocessed Goldminer collection of this year -only with the captions per article, non full text articles -. They have preprocessed the collections in order to generate a textual document per image, which has been translated to English when it need <ref type="bibr" coords="5,362.97,525.87,9.96,9.96" target="#b3">[4]</ref>.</p><p>Table <ref type="table" coords="5,132.69,537.83,4.98,9.96" target="#tab_1">2</ref> shows the characteristics extracted from the textual annotations in the preprocessed collections using IR-n splitter and the number of queries related to each collection. NoImgs: is the number of images.</p><p>WDAvg: is the average of words by image annotations.</p><p>SentAvg: is the average of sentences by image annotations.</p><p>Language: is the language of the collection.</p><p>NrQ: Number queries related to the collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experiments</head><p>The experiment phase aims to establish the optimum values for the configuration of the system for the collection.</p><p>Below is a description of the input parameters of the system:</p><p>The Passage Size (ps): Number of sentences in a passage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Weight Model (wm):</head><p>We used DFR weighting model.</p><p>Relevance Feedback (relFB): Indicates which relevance feedback uses the system -PRF, LCA -.</p><p>Relevance Feedback parameters: If exp has value 1, this denotes we use relevance feedback based on passages. But, if exp has value 2, the relevance feedback is based on documents. Moreover, num denotes the number of passages or documents that the relevance feedback will use, term indicates the k terms extracted from the best ranked passages or documents from the original query.</p><p>Automatic query expansion based on MeSH (mesh): Indicates if the system has to use this expansion or not.</p><p>Negative expansion based on the acquisition type of the image (NType): Indicates if the systems has to use this negative expansion or not.</p><p>Multimodal Re-ranking Strategy (rr): Indicates if the system has to use the multimodal re-ranking strategy or not, and which one in particular. The standard one -RR -or TF-IDF version -RRidf -Multimodal Re-ranking parameters: wT xt and wImg, are the weight of the textual list and the image based list respectively in the standard re-ranking formula. And tImg is the percentage respect the maximum TF IDF value found in the image list which the system uses to calculate the threshold in order to perform the TF-IDF multimodal re-ranking process.</p><p>For the experiments we have worked with DFR as the weighting schema. We have taken this decision based on the training results obtained with participation in the English monolingual task within the ImageCLEFphoto edition of last year.</p><p>Furthermore, is is important to take in account that for the training phase of the re-ranking strategies we have used the University of Geneva CBIR baseline run for the 2007 query set -we have not found a CBIR baseline that answer to the whole consolidated query set -. Since that the re-ranking results have been obtained with runs that for the 2007 queries -30 queries of a total of 85 queries -use the re-ranking technique and for the other queries they use a purely textual retrieval. Bearing that in mind we have evaluated the results of the re-ranking experiments as if its improvement or worsening was minimized by its partial use with the training query set.</p><p>In the next tables we show the results obtained in the training phase. In order to evaluate the experiments, we use as evaluation measure the Mean Average Precision (MAP) and the Recall.</p><p>In the Table <ref type="table" coords="6,160.50,647.79,4.98,9.96" target="#tab_2">3</ref> we show the best configurations obtained for each combination of N T ype, mesh and relF B, in order to compare the performance of the different relevance feedback and query expansion methods. It's data is presented in the increasing order of MAP value.</p><p>On one hand we can observe that the only run which is able to improve the baseline is the one that only uses the negative expansion based on the image type. On the other hand we have to highlight that the passage size for all the best runs is lower than the average of sentences per image of the collection. Furthermore we can see that PRF always obtains better results than LCA for the same combination of parameters. The total number of submissions that we are allowed to send for the official results is 10. Thus, in order to have at least an official result per technique for our participation in the task within the textual modality, we have selected the best three runs in MAP terms, and furthermore, the best run only using LCA in order to compare it with PRF run, and finally, two runs using the two query expansion modules -NType and mesh -with and without relevance feedback -Table <ref type="table" coords="7,491.23,369.85,3.68,9.96" target="#tab_2">3</ref>-. For the training of the two re-ranking techniques, we have worked with the best run of the textual training process and the baseline CBIR run of the University of Geneva for the 2007 query set. Furthermore, in order to complete the number of runs that we are allowed to send we have also trained the re-ranking strategies with the best run in Recall terms, in order to study how it can influence this measure in the final MAP obtained with a re-ranking strategy. The Table <ref type="table" coords="7,505.24,570.17,3.87,9.96" target="#tab_4">5</ref>, shows us the best results obtained in that training process. We can see that the two techniques improve the MAP results sightly. We believe that this improvement would have had a greater impact in the overall results of MAP if we had used a CBIR run for all the training query set. Furthermore it is important to highlight that despite the fact that standard re-ranking obtains better MAP results than the TF-IDF re-ranking we can observe that TF-IDF improves the Recall measure, while the first one does not.</p><p>We have sent these four latter runs for our participation. We have mixed our textual runs with a CBIR baseline obtained with FIRE <ref type="bibr" coords="8,257.27,135.26,10.52,9.96" target="#b1">[2]</ref> and distributed by the organization. It is important to stand out the extremely low threshold percentage value used in the best TF-IDF re-ranking runs -specially if we compare it with the 60% value obtained for the training phase of the TF-IDF re-ranking technique in our ImageCLEFphoto participation of this year <ref type="bibr" coords="8,410.84,171.12,15.50,9.96" target="#b9">[10]</ref> -paper pendent of publication -. This is a risk for the success of the TF-IDF re-ranking strategy in the participation of this year, due to wich we think that this value is very dependent on the characteristics of the collection and for this year edition the competition uses a different collection for testing the participant systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results in ImageCLEF Medical Retrieval 2008</head><p>Table <ref type="table" coords="8,118.01,273.67,4.98,9.96" target="#tab_5">6</ref> shows us the official results obtained by our runs in the ImageCLEF Medical Retrieval 2008 task for the textual modality. We can see that our best run has been ranked in the 1st place for the textual systems classification -txt rk -from a total of 69 submitted runs within this classification. And in the 2nd place within the general classification of the task -CLEF rk -from a total number of 119 submitted runs. With the new collection, our best run in the training phase -the run which only uses negative expansion -has obtained worse results than the baseline run. However, the best ranked run in the task is one that in the training phase was not between the best runs. In fact baseline run is the run that showed better results have been shown in the training phase and in the competition. Furthermore, we can see that the LCA submitted run shows better results than the runs which only use PRF -contrary to what we experience in the training phase -.</p><p>Table <ref type="table" coords="8,132.34,557.54,4.98,9.96" target="#tab_6">7</ref> shows our official results within the mixed runs submisions. With respect to this results, despite the fact that we have obtained the 3rd position from a total of 36 submitted runs in this modality. However, this results does not represent the ones that can be achieved with these strategies. The reason is that if we observe the MAP values obtained by the TF-IDF re-ranking techniques, we can see that these are the same results obtained by the textual run with the same parameters. It has happened because the threshold that we have used for TF-IDF re-ranking strategy is too much low for the competition collection. It makes that the system treat all the documents retrieved by the CBIR as if they have enough textual information to perform a suitable retrieval -skipping their CBIR relevance value-. We also have had a tuning problem with the parameters of the standard re-ranking strategy. Since that we only trained it using a subset of the whole training query set and that we have used a different collection and a different CBIR from the ones we used in the competition. All of this has affected negatively to the performance of this strategy with the test collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>A major finding of these results is that our passage based systems fits very well to this task, demonstrating at another instance its usefulness in narrow texts domain. Indeed, our baseline run only uses a passage size of 3 sentences and with DFR as weighting schema, has obtained the 6th best result of the textual participant systems. And moreover, it has showed a constant behaviour in the training and in the competition tests.</p><p>With respect to the results obtained with the relevance feedback strategies, it is difficult to have a conclusion, because the results in the training and in the participation are opposite. We would like to work further in the future with LCA in order to filter the terms of the query that it uses in order to measure which documents have greater probabilities of be relevant in order to perform the expansion. The idea is to filter those terms of the query which do not pertain to the medical domain.</p><p>An interesting result has been to check that the negative query expansion based on the acquisition type of the image always was being used in our best runs -in the training phase and in the competition -, although it have not improved meaningfully the results. It demonstrates that this technique can improve the results even when it is based only on the captions of the image -there are not any visual system tagging the images with its acquisition type -. In future works we would like to compare its behaviour with a visual system for tagging the images.</p><p>Furthermore we have to work to analyse the reasons why our system does not improve always its performance when it uses the MeSH query expansion, Especially when this techniques has given good results in other systems <ref type="bibr" coords="9,247.77,476.95,9.96,9.96" target="#b2">[3]</ref>. Finally, in order to avoid the problems experienced with the TF-IDF re-ranking strategy, we are planning on to work on finding an alternative method to establish the TF-IDF re-ranking threshold. Which instead of using the documents retrieved, uses the whole collection to work out this value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgement</head><p>This research has been partially funded by the Spanish Government within the framework of the TEXT-MESS (TIN-2006-15265-C06-01) project and by European Union (EU) within the framework of the QALL-ME project (FP6-IST-033860).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,155.93,118.27,291.17,132.85"><head>Table 1 :</head><label>1</label><figDesc>Taxonomy of Image Acquisition Types</figDesc><table coords="4,155.93,129.97,291.17,121.15"><row><cell>Type</cell><cell>Terms</cell></row><row><cell>Angiogram</cell><cell>angiogram, angiograms, angiography, angiographies</cell></row><row><cell>CT Scan</cell><cell>ct, cts, tomography, tomographies</cell></row><row><cell>MRI:</cell><cell>mri, mris, resonance, resonances</cell></row><row><cell>Ultrasound</cell><cell>ultrasound, ultrasounds</cell></row><row><cell>Scintigraphy</cell><cell>scintigraphy, scintigraphies</cell></row><row><cell>X-Ray</cell><cell>x ray, x rays, xray, xrays</cell></row><row><cell>Microscope</cell><cell>microscope</cell></row><row><cell>Gross Path</cell><cell>gross path</cell></row><row><cell>Endoscopy</cell><cell>endoscopy, endoscopies</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,104.94,579.90,350.81,81.70"><head>Table 2 :</head><label>2</label><figDesc>Data Collection</figDesc><table coords="5,104.94,589.66,350.81,71.94"><row><cell>Collection</cell><cell cols="5">NoImgs WDAvg SentAvg Language NrQ</cell></row><row><cell>Consolidated</cell><cell>66,662</cell><cell>93,87</cell><cell>4,29</cell><cell>English</cell><cell>85</cell></row><row><cell>Goldminer</cell><cell>67,115</cell><cell>55,37</cell><cell>3,82</cell><cell>English</cell><cell>30</cell></row><row><cell cols="3">Bellow is a descriptions of Table 2 columns:</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,114.66,118.27,373.66,169.96"><head>Table 3 :</head><label>3</label><figDesc>Best Textual Runs</figDesc><table coords="7,114.66,128.03,373.66,160.20"><row><cell cols="3">NType mesh ps</cell><cell>c</cell><cell cols="5">avgld relFB exp num k</cell><cell>map</cell><cell>recall</cell></row><row><cell>yes</cell><cell>no</cell><cell>3</cell><cell>3.5</cell><cell>120</cell><cell>no</cell><cell>0</cell><cell>0</cell><cell cols="3">0 0.2174 0.5095</cell></row><row><cell>no</cell><cell>no</cell><cell cols="2">3 3.5</cell><cell>120</cell><cell>no</cell><cell>0</cell><cell>0</cell><cell cols="3">0 0.2170 0.5048</cell></row><row><cell>no</cell><cell>no</cell><cell>3</cell><cell>7.5</cell><cell>40</cell><cell>prf</cell><cell>1</cell><cell>5</cell><cell cols="2">10 0.2142</cell><cell>0.4980</cell></row><row><cell>yes</cell><cell>no</cell><cell>2</cell><cell>6</cell><cell>40</cell><cell>prf</cell><cell>1</cell><cell>10</cell><cell>5</cell><cell>0.2132</cell><cell>0.5103</cell></row><row><cell>no</cell><cell>no</cell><cell>3</cell><cell>6.5</cell><cell>40</cell><cell>lca</cell><cell>1</cell><cell>20</cell><cell>5</cell><cell>0.2102</cell><cell>0.4993</cell></row><row><cell>no</cell><cell>yes</cell><cell>2</cell><cell>6</cell><cell>40</cell><cell>prf</cell><cell>1</cell><cell>10</cell><cell>5</cell><cell>0.2065</cell><cell>0.5052</cell></row><row><cell>yes</cell><cell>no</cell><cell>2</cell><cell>5.5</cell><cell>40</cell><cell>lca</cell><cell>1</cell><cell>10</cell><cell>5</cell><cell>0.2053</cell><cell>0.4971</cell></row><row><cell>no</cell><cell>yes</cell><cell>2</cell><cell>5.5</cell><cell>40</cell><cell>lca</cell><cell>1</cell><cell>10</cell><cell>5</cell><cell>0.2052</cell><cell>0.4870</cell></row><row><cell>yes</cell><cell>yes</cell><cell>3</cell><cell>3</cell><cell>40</cell><cell>no</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell cols="2">0.2050 0.5189</cell></row><row><cell>no</cell><cell>yes</cell><cell>3</cell><cell>3</cell><cell>40</cell><cell>no</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0.2043</cell><cell>0.5111</cell></row><row><cell>yes</cell><cell>yes</cell><cell>3</cell><cell>7.5</cell><cell>40</cell><cell>prf</cell><cell>1</cell><cell>5</cell><cell>5</cell><cell>0.2029</cell><cell>0.5159</cell></row><row><cell>yes</cell><cell>yes</cell><cell>2</cell><cell>3.5</cell><cell>40</cell><cell>lca</cell><cell>1</cell><cell>5</cell><cell>5</cell><cell>0.2020</cell><cell>0.5049</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,201.37,400.59,200.25,95.84"><head>Table 4 :</head><label>4</label><figDesc>Textual Runs Submitted 2008 task</figDesc><table coords="7,201.37,410.34,200.25,86.08"><row><cell cols="3">NType mesh relFB</cell><cell>map</cell><cell>recall</cell></row><row><cell>no</cell><cell>no</cell><cell>no</cell><cell>0.2170</cell><cell>0.5048</cell></row><row><cell>no</cell><cell>no</cell><cell>prf</cell><cell>0.2142</cell><cell>0.4980</cell></row><row><cell>no</cell><cell>no</cell><cell>lca</cell><cell>0.2102</cell><cell>0.4993</cell></row><row><cell>yes</cell><cell>no</cell><cell>no</cell><cell cols="2">0.2174 0.5095</cell></row><row><cell>yes</cell><cell>yes</cell><cell>no</cell><cell>0.2050</cell><cell>0.5189</cell></row><row><cell>yes</cell><cell>yes</cell><cell>prf</cell><cell>0.2029</cell><cell>0.5159</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,99.30,612.85,447.19,70.33"><head>Table 5 :</head><label>5</label><figDesc>Best Multimodal Runs</figDesc><table coords="7,290.76,634.57,255.72,9.96"><row><cell>wTxt/</cell><cell>rr</cell><cell>rr</cell><cell>%</cell><cell>rrTfIdf rrTfIdf</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,125.12,350.22,352.78,107.79"><head>Table 6 :</head><label>6</label><figDesc>Official Textual Runs Results</figDesc><table coords="8,421.07,359.99,56.82,9.96"><row><cell>txt CLEF</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,95.98,586.28,445.37,95.04"><head>Table 7 :</head><label>7</label><figDesc>Official Mixed Runs Results</figDesc><table coords="8,480.70,607.99,60.65,9.96"><row><cell>mix CLEF</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,105.25,743.05,93.74,7.97"><p>http://www.imageclef.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="5,105.25,746.47,94.52,7.97"><p>http://goldminer.arrs.org</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,110.48,646.26,402.51,9.96;9,110.47,658.22,402.52,9.96;9,110.47,670.17,402.52,9.96;9,110.47,682.13,402.55,9.96;9,110.47,694.09,30.46,9.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,259.22,646.26,253.77,9.96;9,110.47,658.22,122.82,9.96">Combining Query Translation and Document Translation in Cross-Language Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Aitao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fredric</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,145.30,670.51,235.53,9.18">4th Workshop of the Cross-Language Evaluation Forum</title>
		<title level="s" coord="9,444.79,670.51,68.20,9.18;9,110.47,682.13,236.41,9.96">Lecture notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</editor>
		<meeting><address><addrLine>CLEF; Trondheim, Norway</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
	<note>Lecture notes in Computer Science</note>
</biblStruct>

<biblStruct coords="9,110.48,714.01,402.51,9.96;9,110.47,725.96,184.58,9.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,257.07,714.01,251.19,9.96">Features for image retrieval: An experimental comparison</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,110.47,726.30,92.98,9.18">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="77" to="107" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,111.36,402.55,9.96;10,110.48,123.31,76.50,9.96" xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">C</forename><surname>D√≠az-Galiano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Garc√≠a-Cumbreras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Ure√±a L√≥pez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Mart√≠n-Valdivia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Montejo-Raez</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,143.23,402.52,9.96;10,110.47,155.18,402.52,9.96;10,110.47,167.15,114.91,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,160.97,155.18,75.13,9.96">Sinai at imageclef</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">C</forename><surname>Daz-Galiano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Garca-Cumbreras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Martn-Valdivia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Montejo-Raez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Urea-Lpez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,275.27,155.52,186.22,9.18">Working Notes of the 2007 CLEF Workshop</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">2007. September 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,187.07,402.52,9.96;10,110.47,199.02,402.50,9.96;10,110.47,210.98,374.92,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,328.12,199.02,159.11,9.96">Tia-inaoes participation at imageclef</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">Jair</forename><surname>Escalante</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><forename type="middle">A</forename><surname>Hernndez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aurelio</forename><surname>Lpez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Heidy</forename><forename type="middle">M</forename><surname>Marn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Manuel</forename><surname>Montes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eduardo</forename><surname>Morales</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luis</forename><forename type="middle">E</forename><surname>Sucar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luis</forename><surname>Villaseor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,122.93,211.31,191.91,9.18">Working Notes of the 2007 CLEF Workshop</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">2007. September 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,230.90,402.50,9.96;10,110.48,242.86,402.52,9.96;10,110.48,254.82,265.55,9.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,134.42,242.86,265.37,9.96">Ipal at imageclef 2007 mixing features, models and knowledge</title>
		<author>
			<persName coords=""><forename type="first">Sheng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean-Pierre</forename><surname>Chevallet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thi</forename><surname>Hoang Diem Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Trong Ton</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joo Hwee</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,420.56,243.20,92.44,9.18;10,110.48,255.15,94.99,9.18">Working Notes of the 2007 CLEF Workshop</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">September 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,274.74,402.49,9.96;10,110.48,286.69,240.54,9.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,307.39,274.74,205.58,9.96;10,110.48,286.69,117.87,9.96">Automatic Image Modality Based Classification and Annotation to Improve</title>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jayashree</forename><surname>Kalpathy-Cramera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,249.97,287.03,48.37,9.18">MEDINFO</title>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,306.62,402.53,9.96;10,110.47,318.57,402.52,9.96;10,110.47,330.53,293.81,9.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,256.25,318.57,140.67,9.96">Dcu and uta at imageclefphoto</title>
		<author>
			<persName coords=""><forename type="first">Anni</forename><surname>Jrvelin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Wilkins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tomasz</forename><surname>Adamek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eija</forename><surname>Airio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Gareth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alan</forename><forename type="middle">F</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eero</forename><surname>Smeaton</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Sormunen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,446.64,318.91,66.36,9.18;10,110.47,330.87,123.26,9.18">Working Notes of the 2007 CLEF Workshop</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">2007. September 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,350.46,402.53,9.96;10,110.48,362.41,154.61,9.96" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Llopis</surname></persName>
		</author>
		<title level="m" coord="10,187.98,350.80,296.08,9.18">IR-n: Un Sistema de Recuperacin de Informacin Basado en Pasajes</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>University of Alicante</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="10,110.48,382.34,402.52,9.96;10,110.48,394.29,353.18,9.96" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,341.92,382.34,171.08,9.96;10,110.48,394.29,112.62,9.96">Different Multimodal Approaches using IR-n in ImageCLEFphoto</title>
		<author>
			<persName coords=""><forename type="first">Sergio</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Llopis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rafael</forename><surname>Mu√±oz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,384.33,394.63,48.71,9.18">CLEF 2008</title>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
	<note>In on-line Working Notes</note>
</biblStruct>

<biblStruct coords="10,110.48,414.21,402.52,9.96;10,110.48,426.18,402.53,9.96;10,110.48,438.13,79.34,9.96" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,418.45,414.21,94.55,9.96;10,110.48,426.18,262.13,9.96">Information Retrieval of Visual Descriptions with IR-n System based on Passages</title>
		<author>
			<persName coords=""><forename type="first">Sergio</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Llopis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rafael</forename><surname>Mu√±oz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Elisa</forename><surname>Noguera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,110.48,438.47,48.72,9.18">CLEF 2007</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>In on-line Working Notes</note>
</biblStruct>

<biblStruct coords="10,110.48,458.05,402.52,9.96;10,110.48,470.01,278.42,9.96" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,283.75,458.05,157.03,9.96">Relevance weighting of search terms</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">Sparck</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,450.89,458.39,62.11,9.18;10,110.48,470.34,181.63,9.18">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="129" to="146" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,489.93,402.51,9.96;10,110.48,501.89,265.18,9.96" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,245.29,489.93,267.70,9.96;10,110.48,501.89,68.23,9.96">Improving the effectiveness of information retrieval with local context analysis</title>
		<author>
			<persName coords=""><forename type="first">Jinxi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,187.24,502.23,97.04,9.18">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="112" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
