<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,102.48,98.63,398.29,15.51;1,213.36,120.59,176.41,15.51">Consortium AVEIR at ImageCLEFphoto 2008: on the fusion of runs</title>
				<funder ref="#_V3aSCqG">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,116.64,153.97,65.31,9.96"><forename type="first">Sabrina</forename><surname>Tollari</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">UMR CNRS 7606-LIP6</orgName>
								<orgName type="institution">Université Pierre et Marie Curie-Paris6</orgName>
								<address>
									<settlement>Paris</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,192.36,153.97,79.82,9.96"><forename type="first">Marcin</forename><surname>Detyniecki</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">UMR CNRS 7606-LIP6</orgName>
								<orgName type="institution">Université Pierre et Marie Curie-Paris6</orgName>
								<address>
									<settlement>Paris</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,282.72,153.97,66.99,9.96"><forename type="first">Marin</forename><surname>Ferecatu</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">UMR CNRS 5141 LTCI</orgName>
								<orgName type="institution">TELECOM ParisTech</orgName>
								<address>
									<settlement>Paris</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,360.12,153.97,56.66,9.96"><forename type="first">Hervé</forename><surname>Glotin</surname></persName>
							<affiliation key="aff2">
								<orgName type="laboratory">UMR CNRS 6168 LSIS</orgName>
								<orgName type="institution">Université du Sud Toulon-Var</orgName>
								<address>
									<settlement>Toulon</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,427.32,153.97,75.41,9.96"><forename type="first">Philippe</forename><surname>Mulhem</surname></persName>
							<affiliation key="aff3">
								<orgName type="laboratory">UMR CNRS 5217 LIG</orgName>
								<orgName type="institution">Université Joseph Fourier</orgName>
								<address>
									<settlement>Grenoble</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,106.68,168.01,84.84,9.96"><forename type="first">Massih-Reza</forename><surname>Amini</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">UMR CNRS 7606-LIP6</orgName>
								<orgName type="institution">Université Pierre et Marie Curie-Paris6</orgName>
								<address>
									<settlement>Paris</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,202.20,168.01,77.42,9.96"><forename type="first">Ali</forename><surname>Fakeri-Tabrizi</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">UMR CNRS 7606-LIP6</orgName>
								<orgName type="institution">Université Pierre et Marie Curie-Paris6</orgName>
								<address>
									<settlement>Paris</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,289.80,168.01,73.24,9.96"><forename type="first">Patrick</forename><surname>Gallinari</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">UMR CNRS 7606-LIP6</orgName>
								<orgName type="institution">Université Pierre et Marie Curie-Paris6</orgName>
								<address>
									<settlement>Paris</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,373.44,168.01,60.14,9.96"><forename type="first">Hichem</forename><surname>Sahbi</surname></persName>
							<affiliation key="aff1">
								<orgName type="laboratory">UMR CNRS 5141 LTCI</orgName>
								<orgName type="institution">TELECOM ParisTech</orgName>
								<address>
									<settlement>Paris</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,444.00,168.01,71.60,9.96"><forename type="first">Zhong-Qiu</forename><surname>Zhao</surname></persName>
							<affiliation key="aff2">
								<orgName type="laboratory">UMR CNRS 6168 LSIS</orgName>
								<orgName type="institution">Université du Sud Toulon-Var</orgName>
								<address>
									<settlement>Toulon</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,102.48,98.63,398.29,15.51;1,213.36,120.59,176.41,15.51">Consortium AVEIR at ImageCLEFphoto 2008: on the fusion of runs</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5A44D906FABB1D5FDE1712CBEED950F7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Management]: Languages-Query Languages Measurement, Performance, Experimentation Rank Fusion, Image Retrieval, Multimodal Information Retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this working note, we present the submission of the AVEIR consortium, composed of 4 French laboratories, to ImageCLEFphoto 2008. The submitted runs correspond to different fusion strategies applied to four individual ranks, each proposed by an AVEIR consortium partner. In particular, we study the complete, and partial, average of the ranking values, the minimum of these values, and a random based diversification. We first briefly describe the individual run of each partner, then we describe the fusion runs. The official results classed one of the runs, the MEAN fusion, as the third best in the automatic text-image run category. This run gives better results than the best partner run.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The overall goal of the project is to enrich image retrieval systems with semantic indexation and annotation, and with symbolic relational description, all being automatically extracted and built from the textual and image content extracted from documents or web pages. This semantic and symbolic information are, then, used to reduce the visual ambiguity in images and to enhance the retrieval of images from large databases. The project develops 3 research axes. The first axis focuses on image analysis, feature extraction and visual feature representations. The second axis is concerned with automatic labeling of image components or objects with textual concepts. The third axis considers image retrieval and evaluation of the proposed algorithms. For more details please refer to http://aveir.lip6.fr.</p><p>In order to compare the state of the art approaches, each of the partners participated individually to ImageCLEFphoto (cf. <ref type="bibr" coords="2,226.58,228.01,10.57,9.96" target="#b0">[1,</ref><ref type="bibr" coords="2,240.38,228.01,7.81,9.96" target="#b1">2,</ref><ref type="bibr" coords="2,251.55,228.01,7.69,9.96" target="#b2">3,</ref><ref type="bibr" coords="2,262.59,228.01,7.15,9.96" target="#b3">4]</ref>).</p><p>The particularity of the 2008 ImageCLEFphoto edition was its focus on diversity. The evaluation was based on two measures: precision at 20 and instance recall at rank 20 (also called cluster recall or S-recall), which calculates the percentage of different classes or clusters represented in the top 20. The idea behind these measures was to focus on relevant but diverse -in terms of clusters -images.</p><p>In order to analyze if combining different runs improves the diversity, a submission under the label AVEIR was proposed. In this paper we briefly discuss the former submission, in particular the different fusion strategies, and the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Description of individual runs</head><p>Although each of the partners had its own diversification strategy, for the fusion we used the non diversified runs. In table 1, we briefly describe each the used runs. For more details please refer to the specific papers: LIG histo 3 p o 1.5 4 0 NOCLUST EN-EN-AUTO-TXTIMG <ref type="bibr" coords="2,402.23,418.45,11.47,9.96" target="#b2">[3]</ref>: this run is based on the linear combination of the scores provided by a language model using Dirichlet smoothing on the text and by a Jeffrey-Divergence correspondence on the images.</p><p>UPMC-LIP6 r3tfidf VCDTWN EN-EN-AUTO-TXTIMG <ref type="bibr" coords="2,382.92,460.69,11.47,9.96" target="#b3">[4]</ref>: the text processing is based on standard TF-IDF with cosine similarity. Forest of Fuzzy Decision Trees (FFDT) trained on VCDT ImageCLEF task 2008 are used for a visual concept filtering of the textual results. The matching of the concepts and the topics text used WordNet LSIS EN-EN-AUTO-TXTIMG-AUTO GLOZHA ar 12 NOCLUST <ref type="bibr" coords="2,429.73,514.93,11.47,9.96" target="#b1">[2]</ref>: the visual features are entropic features. Lots of SVMs are trained and generated with different parameters using the sample images provided. Then the first 20 images of the LIG run are used as the positive samples for each topic, and the others as the negative samples to construct the validation set for selecting the best one among the generated SVMs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>PTECH-EN-EN-AUTO-TXTIMG-AMKNR [1]</head><p>: the run uses a combination of text and image descriptors. For a given topic, a separate query is performed for each modality (text and image). The results are merged by a minimum rank criterion: each image keeps the best rank.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Description of AVEIR runs</head><p>The AVEIR consortium proposed, for ImageCLEFphoto2008, 4 runs each with a different fusion strategy. Since for each partner's run, we have at most 1000 images ranked by topic, some images are sometimes not ranked. AVEIR LIG LIP6 LSIS PTECH EN-EN-AUTO-TXTIMG MIN: for each image, the fusionrank corresponds to the minimum rank observed on each of the 4 partner's runs. This strategy corresponds to creating a rank by alternatively choosing an image from each of the partners' runs. The first image of the fusion rank corresponds to the first image of the first partner; the second image corresponds to the first image of the second partner; the fifth corresponds to the second image of the first partner, and so on.</p><p>AVEIR LIG LIP6 LSIS PTECH EN-EN-AUTO-TXTIMG MEAN: for each image, the fusion-rank corresponds to the average rank observed on each of the 4 partner's runs. This strategy corresponds to a compromise taking into account all the systems. Images not present in one of the ranked lists are considered as having rank 1001.</p><p>AVEIR LIG LIP6 LSIS PTECH EN-EN-AUTO-TXTIMG MEAN2on4: here only images that were ranked by at least two partners where considered. The fusion-rank correspond to the average of the available ranks. The idea behind this strategy is to avoid fusionning images returned only by one partner.</p><p>AVEIR LIG LIP6 LSIS PTECH EN-EN-AUTO-TXTIMG MEAN DIVALEA40: the first 40 images of the MEAN run were randomly shuffled. The objective of this run is to observe how randomness affects diversity and to provide a baseline for the instance recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and discussion</head><p>Figure <ref type="figure" coords="3,120.85,604.57,4.98,9.96" target="#fig_1">1</ref> compares Precision and Cluster Recall when considering the first n retrieved images. The average precision at 20 (P20) and the average cluster recall at 20 (CR20), of the best 4 runs from each participating group (25 groups and 100 runs), was respectively P20= 0.32 and CR20= 0.35. All the fusion strategies are above these scores. This may be explained by the fact that some of the partners' runs performed very well. When comparing MEAN and MEAN DIV (for n &lt; 40) on figure <ref type="figure" coords="3,385.21,664.33,3.90,9.96" target="#fig_1">1</ref>, we conclude that a random diversification worsens the results as well for the precision as for the cluster recall. In terms of precision, the best fusion strategy is the MEAN, the worse being the <ref type="bibr" coords="3,395.77,688.21,17.20,9.96">MIN</ref>  the precision point of view, it is more interesting to base the fusion on a compromise. In fact, the MIN strategy considers an image as very good as long as one of the partners, independently of the others, ran it high. The best images, when using the MEAN strategy, correspond to images that were highly ranked by all the systems. Surprisingly, from the cluster precision perspective, in average (over all the topics), there is not much difference between the runs, although the MIN slightly outperforms the other strategies (in particular when considering the very first images). If we look at figure 2(a), we discover that there are topics for which the MIN strategy is better and topics for which the MEAN is better. Although the reasons behind this behaviour needs further research, it explains why in average there is no difference between the two strategies.</p><p>Table <ref type="table" coords="4,131.28,641.77,4.98,9.96" target="#tab_1">2</ref> compares the best individual run with the AVEIR fusion runs. Only the MEAN strategy shows an improvement with respect to the best of the individual runs. The Mean Average Precision is clearly improved. There is no improvement in the cluster recall, actually there is a slight drop. The explanation lies in the behaviour per topic. On figure 2(b), we observe that for some topics the best individual run outperforms any fusion, while for others the fusion improves beyond the best individual run. The fusion is not correlated to best individual run. Furthermore, the topics that have a high cluster recall score (i.e. with a score higher than 0.5 for as well for the MEAN as for the Best Individual) are better served by the best individual run, while the ones with a low score are better with the MEAN fusion. The compromise pays, in terms of diversity, when the problem is difficult. This may be explained by our previous observation that the MEAN improves the precision. In fact, for difficult topics, the MEAN brigs new images up, increases the precision and the cluster recall, since a new relevant image belongs with a high probability to a new class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this working note, we presented the submission, of the AVEIR consortium, to ImageCLEFphoto 2008. The particularity of this year edition was its focus on diversity. The evaluation was based on the relevance, measured by the precision at 20 and by the diversity measured by the cluster recall at rank 20. The idea behind these two measures was to focus on relevant but diverse images.</p><p>The submitted runs correspond to different fusion strategies applied to four individual ranks, each proposed by a partner. In particular we study the complete, and partial, average of the rank values (MEAN and MEAN2on4), the minimum of these values (MIN), and a random based diversification (DIVALEA40). The official results<ref type="foot" coords="5,306.00,270.02,3.97,4.84" target="#foot_0">1</ref> classed one of the runs, the MEAN fusion, as the third best. Our experiments showed why this fusion particularly improves the precision and, even more, the mean average precision. We also observed that it only slightly affects the diversity.</p><p>Furthermore, the MIN fusion -which corresponds to alternating images from each individual run -despite its weak precision at 20, improves slightly the overall diversity. The weak precision at 20 may be partially explained by the disparity, in terms of quality, of the runs. In fact, low scoring runs bring non-relevant images, lowering the precision, but also keeping the diversity of the runs' information.</p><p>Finally, the experiments also pointed out that the diversity is strongly affected by the relevance, in particularly for difficult queries. Although the experiments showed that, in terms of diversity, the best individual run performs better than any type of fusion, we observed that for low precision topics it is more interesting to perform a MEAN fusion (that increases the mean average precision) and that for high precision topics it is more interesting to fusion with the MIN (as long as the runs have similar performance). In other terms diversity comes after a good relevance.  </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="1,90.00,591.32,8.08,12.93;1,114.25,591.32,88.80,12.93;1,90.00,615.73,422.98,9.96;1,90.00,627.73,423.03,9.96;1,90.00,639.61,358.35,9.96;1,90.00,659.53,376.83,9.96;1,90.00,679.45,422.95,9.96;1,114.96,691.45,41.06,9.96;2,90.00,61.33,423.11,9.96;2,114.96,73.33,56.90,9.96;2,90.00,91.69,423.26,9.96"><head></head><label></label><figDesc>annotation and Visual concept Extraction for Image Retrieval) is the name of a project supported by the French National Agency of Research (ANR-06-MDCA-002). A consortium of four French CNRS research laboratories are involved in the project: LIG Laboratoire d'Informatique de Grenoble at the Université Joseph Fourier (UJF), LIP6 Laboratoire d'Informatique de Paris 6 at the Université Pierre et Marie Curie-Paris 6 (UPMC), LSIS Laboratoire des Sciences de l'Information et des Systèmes at the Université du Sud Toulon-Var (USTV), LTCI Laboratoire Traitement et Communication de l'Information at the TELECOM ParisTech.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,118.08,490.45,366.93,9.96"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Precision and Cluster Recall when considering the n first retrieved images</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,157.48,311.12,3.68,6.12;6,151.97,275.03,9.19,6.12;6,151.97,238.99,9.19,6.12;6,151.97,202.90,9.19,6.12;6,151.97,166.86,9.19,6.12;6,157.48,130.77,3.68,6.12;6,177.62,326.75,3.68,6.12;6,228.53,326.75,9.19,6.12;6,282.19,326.75,9.19,6.12;6,335.85,326.75,9.19,6.12;6,389.51,326.75,9.19,6.12;6,445.92,326.75,3.68,6.12;6,135.47,227.52,6.12,12.86;6,135.47,206.58,6.12,19.11;6,299.28,336.67,26.82,6.12;6,259.22,111.83,106.96,6.12;6,234.04,275.03,3.68,6.12;6,280.99,243.47,3.68,6.12;6,247.46,175.83,3.68,6.12;6,314.53,238.99,3.68,6.12;6,192.05,271.91,7.35,6.12;6,314.53,220.94,7.35,6.12;6,448.68,130.77,7.35,6.12;6,210.19,250.98,7.35,6.12;6,295.35,156.56,7.35,6.12;6,215.38,279.75,7.35,6.12;6,341.36,184.85,7.35,6.12;6,269.80,250.99,7.35,6.12;6,314.53,220.94,7.35,6.12;6,192.57,294.73,7.35,6.12;6,280.99,220.94,7.35,6.12;6,287.70,238.99,7.35,6.12;6,314.53,220.94,7.35,6.12;6,395.02,166.86,7.35,6.12;6,359.26,190.90,7.35,6.12;6,341.36,220.94,7.35,6.12;6,218.74,259.58,7.35,6.12;6,314.53,243.47,7.35,6.12;6,280.99,220.94,7.35,6.12;6,314.53,266.05,7.35,6.12;6,229.18,245.55,7.35,6.12;6,218.74,311.12,7.35,6.12;6,359.26,230.96,7.35,6.12;6,234.04,250.99,7.35,6.12;6,341.36,202.90,7.35,6.12;6,269.80,220.94,7.35,6.12;6,333.71,182.30,7.35,6.12;6,257.04,259.58,7.35,6.12;6,448.68,220.94,7.35,6.12;6,381.61,175.83,7.35,6.12;6,314.53,250.99,7.35,6.12;6,341.36,275.03,7.35,6.12;6,395.02,238.99,7.35,6.12;6,314.53,175.83,7.35,6.12;6,448.68,190.90,7.35,6.12;6,304.28,227.65,3.68,6.12;6,247.20,348.54,108.45,7.97;6,157.48,574.16,3.68,6.12;6,151.97,538.07,9.19,6.12;6,151.97,502.03,9.19,6.12;6,151.97,465.94,9.19,6.12;6,151.97,429.90,9.19,6.12;6,157.48,393.81,3.68,6.12;6,177.62,589.79,3.68,6.12;6,228.53,589.79,9.19,6.12;6,282.19,589.79,9.19,6.12;6,335.85,589.79,9.19,6.12;6,389.51,589.79,9.19,6.12;6,445.92,589.79,3.68,6.12;6,135.47,501.41,6.12,12.86;6,135.47,479.72,6.12,19.85;6,135.47,458.78,6.12,19.11;6,273.56,599.71,78.27,6.12;6,222.65,374.87,180.09,6.12;6,341.36,538.07,3.68,6.12;6,280.99,506.51,3.68,6.12;6,280.99,438.87,3.68,6.12;6,314.53,502.03,3.68,6.12;6,227.05,534.95,7.35,6.12;6,314.53,483.98,7.35,6.12;6,448.68,393.81,7.35,6.12;6,210.19,514.02,7.35,6.12;6,333.71,419.60,7.35,6.12;6,203.71,542.79,7.35,6.12;6,341.36,447.89,7.35,6.12;6,180.38,514.02,7.35,6.12;6,180.38,483.98,7.35,6.12;6,180.38,557.77,7.35,6.12;6,381.61,483.98,7.35,6.12;6,287.70,502.03,7.35,6.12;6,314.53,483.98,7.35,6.12;6,448.68,429.90,7.35,6.12;6,359.26,453.94,7.35,6.12;6,287.70,483.98,7.35,6.12;6,295.35,522.62,7.35,6.12;6,314.53,506.51,7.35,6.12;6,280.99,483.98,7.35,6.12;6,314.53,529.09,7.35,6.12;6,229.17,508.59,7.35,6.12;6,295.35,574.16,7.35,6.12;6,269.80,494.00,7.35,6.12;6,251.94,514.02,7.35,6.12;6,395.02,465.94,7.35,6.12;6,269.80,483.98,7.35,6.12;6,410.32,445.34,7.35,6.12;6,257.04,522.62,7.35,6.12;6,448.68,483.98,7.35,6.12;6,381.61,438.87,7.35,6.12;6,269.80,514.02,7.35,6.12;6,395.02,538.07,7.35,6.12;6,395.02,502.03,7.35,6.12;6,381.61,438.87,7.35,6.12;6,359.26,453.94,7.35,6.12;6,311.08,490.69,3.68,6.12;6,197.40,611.58,208.21,7.97"><head></head><label></label><figDesc>Best individual run vs best fusion strategy (MEAN)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="6,90.00,635.53,423.01,9.96;6,90.00,647.41,414.24,9.96"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Comparison of some AVEIR results by topic in terms of Cluster Recall at 20 (CR20). Points are labeled by topic numbers. Point labeled 0 corresponds to Cluster Recall on all topic</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,90.00,66.64,428.21,236.14"><head>Table 1 :</head><label>1</label><figDesc>Short description of runs used by AVEIR for the fusion. For more details please refer to partners' papers.</figDesc><table coords="3,96.60,66.64,421.61,202.41"><row><cell>Partner</cell><cell>Text preprocessing</cell><cell>Visual descriptors</cell><cell>Approach</cell></row><row><cell>LIG [3]</cell><cell>use of the &lt;narr&gt; field, stopwords, Porter's lemmatization</cell><cell>grid segmentation into 9 regions, RGB histograms, Jeffrey-divergence</cell><cell>language model with Dirichlet smoothing, linear combination of text and image results</cell></row><row><cell></cell><cell>&lt;narr&gt; without</cell><cell>segmentation into 9</cell><cell>TF-IDF, Forest of Fuzzy Decision Trees</cell></row><row><cell>LIP6 [4]</cell><cell>sentences containing "not", stopwords</cell><cell>overlapping regions, HSV histo for VCDT</cell><cell>(FFDT) used for learning VCDT concepts, use of WordNet for the matching of VCDT</cell></row><row><cell></cell><cell>adapted to image</cell><cell>task, no other visual</cell><cell>concepts and the topics, visual filtering</cell></row><row><cell></cell><cell>retrieval</cell><cell>in ImageCLEFphoto</cell><cell>using VCDT concepts</cell></row><row><cell>LSIS [2]</cell><cell>-</cell><cell>RGB entropic features</cell><cell>use of LIG's results to perform visual queries with a two-class SVM with Gaussian Kernel</cell></row><row><cell></cell><cell>&lt;narr&gt; field,</cell><cell></cell><cell></cell></row><row><cell>PTECH [1]</cell><cell>stopwords, Porter's lemmatization,</cell><cell>color, texture, shape</cell><cell>visual queries performed with a two-class SVM with Laplacian Kernel</cell></row><row><cell></cell><cell>linear PCA</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,412.96,688.21,100.08,9.96"><head>Table 2 :</head><label>2</label><figDesc>. In other words, from Individual runs, AVEIR's fusion runs, ImageCLEFphoto Average and Best ImageCLEFphoto EN-AUTO-TXTIMG run in terms of precision at 20 (P20), cluster recall at 20 (CR20) and Mean Average Precision (MAP). Partner runs are ordered from worst to best precision at 20. The gains are calculated in function of the best individual run score (ref) *this run was not submitted</figDesc><table coords="4,110.52,60.13,382.00,416.96"><row><cell>Run</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>P20</cell><cell cols="2">Gain % CR20 Gain % MAP Gain %</cell></row><row><cell cols="4">Run of partner X</cell><cell></cell><cell>0.260</cell><cell>-</cell><cell>0.293</cell><cell>-</cell><cell>0.191</cell><cell>-</cell></row><row><cell cols="4">Run of partner Y*</cell><cell></cell><cell>0.292</cell><cell>-</cell><cell>0.383</cell><cell>-</cell><cell>0.155</cell><cell>-</cell></row><row><cell cols="4">Run of partner Z</cell><cell></cell><cell>0.303</cell><cell>-</cell><cell>0.380</cell><cell>-</cell><cell>0.212</cell><cell>-</cell></row><row><cell cols="5">Best individual run (PTECH)</cell><cell>0.400</cell><cell>(ref)</cell><cell>0.487</cell><cell>(ref)</cell><cell>0.264</cell><cell>(ref)</cell></row><row><cell cols="3">AVEIR MIN</cell><cell></cell><cell></cell><cell>0.337</cell><cell>-16</cell><cell>0.462</cell><cell>-5</cell><cell>0.236</cell><cell>-11</cell></row><row><cell cols="4">AVEIR MEAN2on4</cell><cell></cell><cell>0.346</cell><cell>-13</cell><cell>0.431</cell><cell>-11</cell><cell>0.244</cell><cell>-8</cell></row><row><cell cols="4">AVEIR MEAN</cell><cell></cell><cell>0.420</cell><cell>+5</cell><cell>0.463</cell><cell>-5</cell><cell>0.303</cell><cell>+15</cell></row><row><cell cols="5">AVEIR MEAN DIVALEA40</cell><cell>0.377</cell><cell>-6</cell><cell>0.458</cell><cell>-6</cell><cell>0.274</cell><cell>+11</cell></row><row><cell cols="5">ImageCLEFphoto Average</cell><cell>0.320</cell><cell>-20</cell><cell>0.353</cell><cell>-28</cell><cell>0.219</cell><cell>-17</cell></row><row><cell cols="6">Best EN-AUTO-TXTIMG run 0.512</cell><cell>+28</cell><cell>0.426</cell><cell>-13</cell><cell>0.366</cell><cell>+39</cell></row><row><cell></cell><cell cols="2">0.5</cell><cell></cell><cell></cell><cell></cell><cell cols="2">ImageCLEFphoto Average P20=0.32</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>AVEIR MIN</cell></row><row><cell>Precision(n)</cell><cell cols="2">0.3 0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>AVEIR MEAN2on4 AVEIR MEAN AVEIR MEAN DIV</cell></row><row><cell></cell><cell cols="2">0.2</cell><cell>0</cell><cell>20</cell><cell>40</cell><cell></cell><cell>60</cell><cell>80</cell><cell>100</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>n</cell></row><row><cell></cell><cell>0.7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>CR(n)</cell><cell>0.4 0.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">ImageCLEFphoto Average CR20=0.35</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>AVEIR MIN</cell></row><row><cell></cell><cell>0.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>AVEIR MEAN2on4 AVEIR MEAN</cell></row><row><cell></cell><cell>0.2</cell><cell cols="2">0</cell><cell>20</cell><cell>40</cell><cell></cell><cell>60</cell><cell>80 AVEIR MEAN DIV</cell><cell>100</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>n</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="5,105.24,696.42,168.56,7.97"><p>http://www.imageclef.org/2008/results-photo</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgment</head><p>This work was supported by the <rs type="funder">French National Agency of Research</rs> (<rs type="grantNumber">ANR-06-MDCA-002</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_V3aSCqG">
					<idno type="grant-number">ANR-06-MDCA-002</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,105.48,534.37,407.65,9.96;5,105.48,546.37,407.38,9.96;5,105.48,558.37,73.09,9.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,261.88,534.37,251.26,9.96;5,105.48,546.37,236.63,9.96">TELECOM ParisTech at ImageClefphoto 2008: Bi-modal text and image retrieval with diversity enhancement</title>
		<author>
			<persName coords=""><forename type="first">Marin</forename><surname>Ferecatu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hichem</forename><surname>Sahbi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,371.16,546.82,141.70,9.07;5,105.48,558.82,41.80,9.07">Working Notes of ImageCLEFphoto2008</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.48,576.61,407.77,9.96;5,105.48,588.61,407.38,9.96;5,105.48,600.61,73.09,9.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,261.64,576.61,251.61,9.96;5,105.48,588.61,245.31,9.96">Affinity propagation promoting diversity in visuo-entropic and text features for clef photo retrieval 2008 campaign</title>
		<author>
			<persName coords=""><forename type="first">Hervé</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhong-Qiu</forename><surname>Zhao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,374.64,589.06,138.22,9.07;5,105.48,601.06,41.80,9.07">Working Notes of ImageCLEFphoto2008</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.48,618.85,406.93,9.96;5,105.48,630.85,22.93,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,185.91,618.85,109.63,9.96">LIG at ImageCLEFphoto</title>
		<author>
			<persName coords=""><forename type="first">Philippe</forename><surname>Mulhem</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,335.16,619.30,172.03,9.07">Working Notes of ImageCLEFphoto2008</title>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.48,649.21,407.50,9.96;5,105.48,661.09,407.42,9.96;5,105.48,673.09,218.77,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,129.25,661.09,377.99,9.96">UPMC/LIP6 at ImageCLEFphoto 2008: on the exploitation of visual concepts (VCDT)</title>
		<author>
			<persName coords=""><forename type="first">Sabrina</forename><surname>Tollari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marcin</forename><surname>Detyniecki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ali</forename><surname>Fakeri-Tabrizi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Massih-Reza</forename><surname>Amini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Patrick</forename><surname>Gallinari</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,117.96,673.54,174.31,9.07">Working Notes of ImageCLEFphoto2008</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
