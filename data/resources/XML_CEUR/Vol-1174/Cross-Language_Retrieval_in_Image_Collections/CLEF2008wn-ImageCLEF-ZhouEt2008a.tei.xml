<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,170.05,148.86,262.89,15.15">MedGIFT at ImageCLEF 2008</title>
				<funder ref="#_dqARzyn">
					<orgName type="full">European Union</orgName>
				</funder>
				<funder ref="#_9tUGWjm">
					<orgName type="full">Swiss National Science Foundation</orgName>
				</funder>
				<funder ref="#_zejaWeu">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,198.35,182.75,41.23,8.74"><forename type="first">Xin</forename><surname>Zhou</surname></persName>
							<email>xin.zhou@sim.hcuge.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Medical Informatics</orgName>
								<orgName type="institution">Geneva University Hospitals and University of Geneva</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,250.14,182.75,60.81,8.74"><forename type="first">Julien</forename><surname>Gobeill</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Medical Informatics</orgName>
								<orgName type="institution">Geneva University Hospitals and University of Geneva</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,321.51,182.75,68.10,8.74"><forename type="first">Henning</forename><surname>Müller</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Medical Informatics</orgName>
								<orgName type="institution">Geneva University Hospitals and University of Geneva</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Applied Sciences Western Switzerland (HES SO)</orgName>
								<address>
									<settlement>Sierre</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,170.05,148.86,262.89,15.15">MedGIFT at ImageCLEF 2008</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7558BBA9FCA5840EF9799746EE669662</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Management]: Languages-Query Languages Measurement, Performance, Experimentation Image Retrieval, Text categorization, Image Classification, Medical Imaging</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This article describes the participation of the Geneva University Hospitals and the University of Geneva at the 2008 ImageCLEF image retrieval benchmark. We concentrated on the two tasks concerning medical imaging. The visual information analysis is based on the GNU Image Finding Tool (GIFT). Other information such as textual information and aspect ratio are integrated to improve the results. The main techniques are the same as in past years, with a little tuning to slightly improve results.</p><p>For the visual tasks it becomes clear that the baseline GIFT runs do not have the same performance as more sophisticated modern techniques do. GIFT can be seen as a baseline for the visual retrieval as it has been used for the past five years in ImageCLEF. Due to time constraints no optimizations could be performed and no relevance feedback was used, usually one of the strong points of GIFT.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Geneva University Hospitals and the University of Geneva contribute regularly to the Im-ageCLEF<ref type="foot" coords="1,131.10,624.97,3.97,6.12" target="#foot_0">1</ref> campaign. The domains of interest are medical image retrieval and medical image annotation <ref type="bibr" coords="1,140.36,638.50,9.96,8.74" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Retrieval strategies</head><p>This section describes the basic technologies that are used for the retrieval. More details on optimizations per task are given in the results section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Text retrieval approach</head><p>The text retrieval approach used in 2008 is detailed in a paper of the text retrieval group of the Geneva University Hospitals. It is very similar to approaches in pas years, where queries and documents are tranlated into MeSH (Medical Subject Headings) terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Visual retrieval techniques</head><p>The technology used for the visual retrieval is mainly taken from the Viper<ref type="foot" coords="2,414.89,198.83,3.97,6.12" target="#foot_1">2</ref> project <ref type="bibr" coords="2,456.09,200.40,9.96,8.74" target="#b2">[3]</ref>. Outcome of the Viper project is the GNU Image Finding Tool, GIFT<ref type="foot" coords="2,349.50,210.78,3.97,6.12" target="#foot_2">3</ref> . This tool is open source and can be used by other participants of ImageCLEF as well. A ranked list of visually similar images for every query topic was made available for participants and serves as a baseline to measure the quality of submissions. Feature sets used by GIFT are:</p><p>• Local color features at different scales by partitioning the images successively into four equally sized regions (four times) and taking the mode color of each region as a descriptor;</p><p>• global color features in the form of a color histogram, compared by a simple histogram intersection;</p><p>• local texture features by partitioning the image and applying Gabor filters in various scales and directions, quantized into 10 strengths;</p><p>• global texture features represented as a simple histogram of responses of the local Gabor filters in various directions and scales.</p><p>A particularity of GIFT is that it uses many techniques well-known from text retrieval. Visual features are quantized and the feature space is similar to the distribution of words in texts. A simple tf/idf weighting is used and the query weights are normalized by the results of the query itself. The histogram features are compared based on a histogram intersection <ref type="bibr" coords="2,434.49,428.35,9.96,8.74" target="#b4">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>In this section the results and technical details for the two medical tasks of ImageCLEF 2008 are detailed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Medical image retrieval</head><p>Results for the medical retrieval task are shown in Table <ref type="table" coords="2,342.47,540.96,4.98,8.74" target="#tab_0">1</ref> highlighting the most important performance measures such as MAP, Bpref, and early precision. 3 purely visual retrieval runs using GIFT with 4 gray levels (GIFT4 ), 8 gray levels (GIFT8 ), 16 gray levels (GIFT16 ) were submitted for evaluation. Using GIFT with 8 gray levels gives the best result for purely visual retrieval.</p><p>Increasing the number of gray levels decreases basically all performance measures. Purely visual retrieval results proved to be little robust <ref type="bibr" coords="2,356.15,600.74,9.96,8.74" target="#b6">[6]</ref>. Thus, more effort was invested into mixing visual retrieval and textual retrieval. The textual retrieval run (HUG-BL-EN ) was provided our collaborator <ref type="bibr" coords="2,204.80,624.65,9.96,8.74" target="#b0">[1]</ref>, we use it to combine with our best visual run (GIFT8 ). In total 5 mixed-media automatic runs were generated with the following combination strategies:</p><p>• combining textual and visual runs with equal weight (GIFT8 EN0.5 );</p><p>• reordering the textual runs based on a visual run (EN reGIFT8 );</p><p>• mixing two runs by giving varying weights based on the topic, for visual topics, the visual run is weighted 90%, for textual topics, the visual run is weighted 10%, and for mixed topics, the visual run is weighted 50% (EN GIFT8 mix ); • combining textual and visual runs but favoring the text (90%) over visual information (10%) (GIFT8 EN0.9 );</p><p>• reordering the visual runs based on a textual run (GIFT8 reEN ).</p><p>Mixing two runs with varying weights based on the topics (EN GIFT8 mix ) gives second best early precision (P30), and third best MAP among the 5 runs. The best MAP is given by simply combining textual and visual runs with equal weight (GIFT8 EN0.5 ). Favoring the textual run (GIFT8 EN0.9 ) gives best early precision, but surprisingly poor MAP. Compared to the original text runs, the combination with our visual run improves early precision slightly, but reduces MAP significantly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Medical image annotation</head><p>For the medical image annotation task, the basic GIFT system was used for the feature extraction. The work of this year followed work performed in 2007 <ref type="bibr" coords="3,335.42,463.10,9.96,8.74" target="#b5">[5]</ref>. The techniques showed to be stable. Adding aspect ratio as feature and performing annotation by axis were reused for our participation in 2008 as well. Main new approaches were a modified classification strategy and changed parameter settings.</p><p>The annotation is based on the known labels of similar images retrieved by the GIFT system. In <ref type="bibr" coords="3,103.33,522.87,9.96,8.74" target="#b5">[5]</ref>, the classification strategies were regrouped around a kNN approach and a voting-based approach. The voting-based approach takes into account the n most similar images. In 2008, we took into account two other factors: the frequency of images of each class in the training data and the hierarchy information inside each axis of the IRMA code.</p><p>One problem of classifying images with similar images with known labels is that the classification strategy favors large classes in the training data and punishes small ones, as images of large classes have a higher chance to be selected. The frequency of each class in the training data is analyzed to avoid this bias. Such a dynamic kNN approach is then used instead of a standard kNN approach to give a different k value for each class. As a result, the disadvantages of small classes are reduced.</p><p>Another useful information is the hierarchy information inside each code axis (there are four in the IRMA code). The output of classification per axis is usually an entire axis or a wildcard for the entire axis. Another possibility is to chop only the lowest level (the last letter) of each axis. The remainder can then be used for a second round of classification. This additional step gives the possibility to use less wildcards in the classification process and thus can potentially improve the score.</p><p>The results of our submitted runs and the best overall system are presented in Table <ref type="table" coords="3,475.41,714.16,3.87,8.74">2</ref>. Three submitted runs use the kNN approach with classification for the entire code (kNN ), classification per axis (akNN ), and dynamic kNN classification per axis (adkNN ). Dynamic kNN gives the Table <ref type="table" coords="4,159.73,118.94,3.87,8.74">2</ref>: Results of the runs submitted to the medical image annotation task.</p><p>run ID score best system 74.92 GE-GIFT0.9 0.5 vad 5.run 209.70 GE-GIFT0.9 0.5 vcad 5.run 210.93 GE-GIFT0.9 0.5 vca 5.run 217.34 GE-GIFT0.9 adkNN 2.run 233.02 GE-GIFT0.9 akNN 2.run 241.11 GE-GIFT0.9 kNN 2.run 251.97</p><p>Table <ref type="table" coords="4,123.53,257.51,3.87,8.74">3</ref>: Classification per axis with and without a "chopping" strategy with descending vote. run ID score GE-GIFT0.9 0.5 vad 5.run 209.70 GE-GIFT0.9 0.6 vad 5.run 198.79 GE-GIFT0.9 0.7 vad 5.run 198.79 GE-GIFT0.9 0.8 vad 5.run 198.79 GE-GIFT0.9 0.9 vad 5.run 208.23 GE-GIFT0.9 0.5 vcad 5.run 210.93 GE-GIFT0.9 0.6 vcad 5.run 191.53 GE-GIFT0.9 0.7 vcad 5.run 191.53 GE-GIFT0.9 0.8 vcad 5.run 191.53 GE-GIFT0.9 0.9 vcad 5.run 181.17 best results in our tests. Three submitted runs use a voting-based approach as described in <ref type="bibr" coords="4,499.71,433.39,9.96,8.74" target="#b5">[5]</ref>, respectively per axis with descending vote (vad ), per axis with chopping letter by letter with descending vote (vcad ), and per axis with chopping letter by letter using equal weights (vca). The thresholds were all set to 0.5 and we submit the runs which take into account the first 5 similar images. The best result among the submitted runs is obtained using the voting strategy per axis with descending vote(vad ). Surprisingly, chopping the lowest level and redoing the classification for the rest gives slightly worse results. As the difference between the strategies with and without "chopping" is not significant, a further comparison is given and the results are presented in Table <ref type="table" coords="4,505.25,517.08,3.87,8.74">3</ref>.</p><p>Chopping at the lowest level and redoing the classification performs better but only with a high threshold.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>For the medical retrieval task the use of text alone is still better than our combinations with visual retrieval, which means that combination techniques still need significant work to preform reasonably well and stable. Only early precision can be improved through the combination of textual runs with visual runs. The visual baseline seems to be of insufficient quality for really improving the combined runs. A small number of colors still gives best results. For a significant improvement in visual retrieval quality new visual features seem necessary.</p><p>For the classification of images the difference between our runs and the best techniques is reduced compared to previous years. The voting-based approaches perform generally better than the simple kNN approaches. Classifying each axis separately with a suitable threshold gives always good results. When the threshold cannot be reached in the first step, chopping the lowest level and redoing the classification for the remaining levels can further improve the result significantly. The advantage of the "chopping" strategy is that the classification is redone iteratively, thus high threshold values increase the confidence without totally blocking the classification.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,114.24,118.94,374.52,139.25"><head>Table 1 :</head><label>1</label><figDesc>Results of the runs submitted to the medical retrieval task.</figDesc><table coords="3,114.24,128.70,374.52,129.48"><row><cell>Run</cell><cell cols="2">run type MAP</cell><cell>bpref</cell><cell>P10</cell><cell>P30</cell><cell>num ret</cell></row><row><cell>best system</cell><cell>Mixed</cell><cell cols="4">0.2908 0.327 0.4267 0.3956</cell><cell>30000</cell></row><row><cell>HUG-BL-EN</cell><cell cols="3">Textual 0.1365 0.2053</cell><cell>0.26</cell><cell>0.24</cell><cell>28095</cell></row><row><cell>GE-GE GIFT8 EN0.5</cell><cell>Mixed</cell><cell cols="4">0.0848 0.1927 0.2433 0.2378</cell><cell>29999</cell></row><row><cell>GE-GE EN reGIFT8</cell><cell>Mixed</cell><cell cols="4">0.0815 0.1896 0.2267 0.2267</cell><cell>29452</cell></row><row><cell>GE-GE EN GIFT8 mix</cell><cell>Mixed</cell><cell cols="2">0.0812 0.1867</cell><cell>0.24</cell><cell>0.2467</cell><cell>29999</cell></row><row><cell>GE-GE GIFT8 EN0.9</cell><cell>Mixed</cell><cell cols="3">0.0731 0.1248 0.2733</cell><cell>0.25</cell><cell>30000</cell></row><row><cell>GE-GE GIFT8 reEN</cell><cell>Mixed</cell><cell cols="4">0.0724 0.1244 0.2433 0.2544</cell><cell>30000</cell></row><row><cell>GE-GE GIFT4</cell><cell>Visual</cell><cell cols="3">0.0315 0.0901 0.1433</cell><cell>0.12</cell><cell>30000</cell></row><row><cell>GE-GE GIFT8</cell><cell>Visual</cell><cell cols="2">0.0349 0.0898</cell><cell>0.17</cell><cell>0.1511</cell><cell>30000</cell></row><row><cell>GE-GE GIFT16</cell><cell>Visual</cell><cell cols="4">0.0255 0.0715 0.1333 0.1111</cell><cell>30000</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,105.24,724.72,105.85,6.64"><p>http://www.imageclef.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,105.24,738.07,93.15,6.64"><p>http://viper.unige.ch/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,105.24,747.58,139.73,6.64"><p>http://www.gnu.org/software/gift/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This study was partially supported by the <rs type="funder">Swiss National Science Foundation</rs> (Grants <rs type="grantNumber">200020-118638/1</rs>), the <rs type="projectName">HES SO</rs> with the <rs type="projectName">BeMeVIS</rs> project, and the <rs type="funder">European Union</rs> in the <rs type="programName">6th Framework Program</rs> through the <rs type="projectName">KnowARC project</rs> (Grant <rs type="grantNumber">IST 032691</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_9tUGWjm">
					<idno type="grant-number">200020-118638/1</idno>
					<orgName type="project" subtype="full">HES SO</orgName>
				</org>
				<org type="funded-project" xml:id="_dqARzyn">
					<orgName type="project" subtype="full">BeMeVIS</orgName>
					<orgName type="program" subtype="full">6th Framework Program</orgName>
				</org>
				<org type="funded-project" xml:id="_zejaWeu">
					<idno type="grant-number">IST 032691</idno>
					<orgName type="project" subtype="full">KnowARC project</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,105.50,212.52,407.50,8.74;5,105.50,224.47,407.51,8.74;5,105.50,236.43,22.69,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,299.97,212.52,213.03,8.74;5,105.50,224.47,40.13,8.74">Text-only cross-language image search at medical imageclef</title>
		<author>
			<persName coords=""><forename type="first">Julien</forename><surname>Gobeill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Patrick</forename><surname>Ruch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xin</forename><surname>Zhou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,186.92,224.47,189.47,8.74">Working Notes of the 2008 CLEF Workshop</title>
		<meeting><address><addrLine>Aarhus, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-09">2008. September 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,256.35,407.50,8.74;5,105.50,268.31,407.50,8.74;5,105.50,280.26,407.50,8.74;5,105.50,292.22,278.25,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,304.57,268.31,208.43,8.74;5,105.50,280.26,130.78,8.74">Overview of the ImageCLEFmed 2007 medical retrieval and annotation tasks</title>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eugene</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jayashree</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">M</forename><surname>Deserno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,259.07,280.26,103.02,8.74">CLEF 2007 Proceedings</title>
		<title level="s" coord="5,440.60,280.26,72.40,8.74;5,105.50,292.22,108.75,8.74">Lecture Notes in Computer Science (LNCS</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">5152</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,312.14,407.51,8.74;5,105.50,324.10,407.51,8.74;5,105.50,336.05,407.50,8.74;5,105.50,348.01,48.70,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,421.78,312.14,91.23,8.74;5,105.50,324.10,231.02,8.74">Content-based query of image databases: inspirations from text retrieval</title>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Mcg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wolfgang</forename><surname>Squire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thierry</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Pun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,479.28,324.10,33.72,8.74;5,105.50,336.05,330.63,8.74">Selected Papers from The 11th Scandinavian Conference on Image Analysis SCIA &apos;99)</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1193" to="1198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,158.62,348.01,137.87,8.74" xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">K</forename><surname>Ersboll</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Johansen</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,367.94,407.51,8.74;5,105.50,379.89,108.54,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,286.35,367.94,62.88,8.74">Color indexing</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dana</forename><forename type="middle">H</forename><surname>Swain</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ballard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,359.70,367.94,153.31,8.74;5,105.50,379.89,26.61,8.74">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="32" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,399.82,407.50,8.74;5,105.50,411.77,407.50,8.74;5,105.50,423.73,321.85,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,361.49,399.82,151.51,8.74;5,105.50,411.77,236.32,8.74">Hierarchical classification using a frequency-based weighting and simple visual features</title>
		<author>
			<persName coords=""><forename type="first">Xin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrien</forename><surname>Depeursinge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,482.28,411.77,30.72,8.74;5,105.50,423.73,244.50,8.74">Special Issue on Medical Image Annotation in ImageCLEF 2007</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct coords="5,105.50,443.65,407.50,8.74;5,105.50,455.61,407.50,8.74;5,105.50,467.56,278.58,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,367.98,443.65,145.01,8.74;5,105.50,455.61,75.86,8.74">University and hospitals of geneva at imageclef 2007</title>
		<author>
			<persName coords=""><forename type="first">Xin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julien</forename><surname>Gobeill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Patrick</forename><surname>Ruch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,206.93,455.61,104.11,8.74">CLEF 2007 Proceedings</title>
		<title level="s" coord="5,392.08,455.61,120.92,8.74;5,105.50,467.56,62.29,8.74">Lecture Notes in Computer Science (LNCS</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008-</date>
			<biblScope unit="volume">5152</biblScope>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
