<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,96.96,108.23,398.86,12.22">Text-only Cross-language image search at medical ImageCLEF 2008</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,212.46,138.91,58.68,9.45"><forename type="first">Julien</forename><surname>Gobeill</surname></persName>
							<email>julien.gobeill@sim.hcuge.ch</email>
							<affiliation key="aff0">
								<orgName type="institution">University and Hospitals of Geneva</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,278.17,138.91,53.19,9.45"><forename type="first">Patrick</forename><surname>Ruch</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University and Hospitals of Geneva</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,338.98,138.91,41.29,9.45"><forename type="first">Xin</forename><surname>Zhou</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University and Hospitals of Geneva</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,96.96,108.23,398.86,12.22">Text-only Cross-language image search at medical ImageCLEF 2008</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F533A89D103F7670757C889E89D76403</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Managment]: Languages -Query Languages Measurement, Performance, Experimentation Image Retrieval, Text categorization, multimodal retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We report on simple textual strategies with thesaural resources in order to perform document and query translation for cross-language information retrieval in a collection of annotated medical images. The keystone of our strategy for the previous medical ImageCLEF was to enrich documents and queries with Medical Subject Headings (MeSH) terms extracted from them, in order to translate the more important concepts into an intermediate language. The core technical component of our cross-language search engine is an automatic text categorizer, which associates a set of MeSH terms to any input text, with a top precision at above 90%. Nevertheless, in the new 2008 collection, images are given with more verbose captions, and with an associated article relative to a specific case study. Therefore, our strategy to enrich each document is either to collect MeSH terms from the associated article, either to extract them from the caption. Our results are fair, as we stand on the first part of the participants (0.176 for mean average precision). Nevertheless, it appears that MeSH terms collected from the relative article are not always relevant, as this article can concern a huge set of images in general, and can not to describe precisely the associated image. Moreover, the MeSH terms directly extracted from the captions lead to worst performances, possibly due to the more verbose captions. We try different strategies on weighting scheme or retrieval on articles, but without significant improvements. In conclusion, a mixed strategy to combine the two origins of the MeSH terms should be planned for the next ImageCLEF, while better performances should be obtained in the future by tuning the system with the existing benchmark.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Cross-Language Information Retrieval (CLIR) is increasingly relevant as network-based resources become commonplace. In the medical domain it is of strategic importance in order to fill the gap between clinical records, written in national languages and research reports massively written in English. Images are also getting increasingly important and varied in the medical domain, and they become available in digital form. Despite the fact that images are language-independent, they are most often accompanied by textual notes in various languages and these textual notes can strongly improve retrieval quality <ref type="bibr" coords="1,357.40,623.64,10.33,8.77" target="#b0">(1)</ref>.</p><p>Historically, the most traditional approach to IR in general and to multilingual retrieval in particular, uses a controlled vocabulary for indexing and retrieval. In this approach, a librarian selects for each document a few descriptors taken from a closed list of authorized terms. A good example of such a human indexing is found in the MEDLINE database, where records are manually annotated with Medical Subject Headings (MeSH). The MeSH is a terminology maintained by the National Library of Medicine and which exists in a dozen languages. However, it can be difficult for users to think in terms of a controlled vocabulary. Actually, the use of terminology-based systems -like most Boolean-supported engines -is often performed by professionals rather than general users. Therefore, it can be more efficient for realistic search engine to automatically handle the documents enrichment and query expansion by MeSH concepts.</p><p>The Cross Language Evaluation Forum (CLEF) is a challenge which occurs each year since 2000. The goal of this challenge is to evaluate the participants on a common multilingual task, to establish a state of the art of the techniques used in a domain, and to build a benchmark for future evaluations. Medical ImageCLEF has started in 2004 with the goal to retrieve relevant medical images in a multilingual document collection, using visual features -images -or textual features -associated captions, titles and articles.</p><p>Our group is specialized in Natural Language Processing; nevertheless, we always participate to medical ImageCLEF, applying textual strategies based on the picture's metadata, and the use of MeSH as an intermediate language (2) (3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data and Strategies</head><p>In 2008, the collection is entirely new, as organizers were able to obtain images from the GoldMiner system (4). The collections used in the previous three medical ImageCLEF -2005 to 2007 -were merged into one single new collection, in order to build a unique benchmark. Therefore, the 2008 ImageCLEF collection consists of new images from two radiology journals, along with their captions, article titles, and linkage to PubMed and the full text of the associated article. It contains a set of 67 115 images. In addition to the images, XML files are distributed, which contains the metadata. A detailed description of the protocol can be found in (5).  The title and caption parts are directly used by our system to retrieve relevant documents, while the PubMed id (PMID) and the article's URL can be used to extract some descriptors as MeSH terms.</p><p>Several differences between this new collection and the previous ones must be noted. Firstly, the 2008 collection contains only English texts, contrary to the previous ones which also contained French and German texts. Queries are, as previous years, asked in English, French and German. Secondly, as metadata give a PubMed id (PMID) to each document, human-generated MeSH terms can be automatically collected and associated by following the link to PubMed. Thirdly, an article is provided for each document, even if a set of images belongs to the same article -there are 4961 articles for 67115 images.</p><p>The strong point of our strategy, for we participate to ImageCLEF, is focused on associating MeSH terms to any textual components -documents or queries -in order to enrich the text with language-independent descriptors, and to perform a standard Information Retrieval process. The core technical component of our crosslanguage search engine is an automatic text categorizer, which associates a set of MeSH terms to any input text; the precision at high ranks of this engine for MeSH terms is above 90% <ref type="bibr" coords="2,356.79,637.32,10.38,8.77" target="#b4">(6)</ref>.  We merge three versions of MeSH (English, German and French (see figure <ref type="figure" coords="3,408.75,118.08,3.80,8.77" target="#fig_2">2</ref>)) in order to enrich each document with several MeSH terms -between 3 and 8 in 2006, 15 in 2007 -and their unique identifier, making them efficient regardless of the original language of the document (see figure <ref type="figure" coords="3,394.05,140.52,3.53,8.77" target="#fig_3">3</ref>). The number of terms is an important parameter, as in 2006, the more MeSH terms were added, the best the run was. We finally showed in 2007 that with the previous collection, the ideal number of MeSH concepts per document was around 15 (2) (3) -which is the mean for an article in MEDLINE. The enriched documents are then indexed in a standard way.  The same MeSH categorization is then performed on queries; according to past studies, the ideal number of terms associated by each query is 3 <ref type="bibr" coords="3,230.73,466.50,10.33,8.77" target="#b1">(2)</ref>. For instance, if a German query deals with magen-darm-endoskopie (see figure <ref type="figure" coords="3,120.43,477.72,3.51,8.77">4</ref>), this concept has great chances to be mapped by our categorizer, and to enrich the query with this German form and the MeSH id: then, even if we work in an English collection, the MeSH id D016099 will be a strongly discriminant feature. The search engine then performs a standard Information Retrieval process. So, MeSH is seen like an intermediate language between documents and queries (2).</p><p>« Magen-Darm-Endoskopie mit Geschwür » Magen-Darm-Endoskopie D016099 Geschwür D010437 Endoskopie D004724</p><p>Figure <ref type="figure" coords="3,134.77,577.92,4.02,8.77">4</ref>: example of the same treatment for a German query: even if we retrieve German terms in an English collection, the MeSH identifiers will be strongly discriminant features.</p><p>With the new collection used for ImageCLEF 2008, and the PMID associated to each document, our strategy is lightly different. Human-generated MeSH terms can be collected for each document, thanks to the PMID contained in the metadata. So, even if our MeSH categorizer obtains good results, we can suppose that "official" descriptors are more accurate and more complete. So, one strong skill of our strategy becomes needless, but we choose to enrich images with the MeSH terms attached to their PMID. Nevertheless, we choose to keep a run where metadata are enriched with MeSH terms found by our categorizer. We try different weighting schemes too, and different combinations between captions, full texts and MeSH terms. The last strategy is to supply a textual run to another team of University and Hospitals of Geneva, Xin Zhou and Henning Muller, who work on visual Information Retrieval, in order to produce a mixed run. More details for each run are given in the Results part.</p><p>An important point for us is the use of the three languages into the same query. We think that having the same queries, perfectly translated into three languages, is not a realistic task. No human user asks a question into three different perfect translations in a system. So, we think preferable, for each query, to make a run for each language: English (EN), French (FR) and German (GE). This is an opinion that we defend in each ImageCLEF we participate, even if we can lose some performance, as seen in 2007 (3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">MeSH-driven Text Categorization</head><p>Automatic text categorization has been studied largely and has led to an impressive amount of papers. A partial list of machine learning approaches applied to text categorization includes naïve Bayes <ref type="bibr" coords="4,419.11,196.38,10.33,8.77" target="#b5">(7)</ref>, k-nearest neighbours <ref type="bibr" coords="4,75.84,207.60,10.38,8.77" target="#b6">(8)</ref>, boosting <ref type="bibr" coords="4,128.60,207.60,10.38,8.77" target="#b7">(9)</ref>, and rule-learning algorithms <ref type="bibr" coords="4,259.23,207.60,14.96,8.77" target="#b8">(10)</ref>. However, most of these studies apply text classification to a small set of classes; usually a few hundred, as in the Reuters collection <ref type="bibr" coords="4,357.80,218.76,14.96,8.77" target="#b9">(11)</ref>. In comparison to this our system is designed to handle large class sets <ref type="bibr" coords="4,214.57,229.92,15.13,8.77" target="#b10">(12)</ref>: retrieval tools used are only limited by the size of the inverted file, but 10 5-6 documents is still a modest range. Our approach is data-poor because it only demands a small collection of annotated texts for fine tuning: instead of inducing a complex model using large training data, our categorizer indexes the collection of MeSH terms as if they were documents and then it treats the input as if it was a query to be ranked regarding each MeSH term. The classifier is tuned by using English abstracts and English MeSH terms. Then, we apply the system on the medical ImageCLEF collection. For tuning the categorizer, the top 15 returned terms are selected because it is the average number of MeSH terms per abstract in the OHSUMED collection. When applied on the medical ImageCLEF collection, the number of categories to be attached to every document will be an important parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Collection and Metrics</head><p>The mean average precision (map): is the main measure for evaluating ad hoc retrieval tasks (for both monolingual and bilingual runs). Following <ref type="bibr" coords="4,264.93,364.14,14.96,8.77" target="#b11">(13)</ref>, we also use this measure to tune the automatic text categorization system. We tune the categorization system on a small set of OHSUMED abstracts: 1200 randomly selected abstracts were used to select the weighting parameters of the vector space classifier and the best combination of these parameters with the regular expression-based classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head><p>Two main modules constitute the skeleton of our categorization system: the regular expression (RegEx) component, and the vector space (VS) component. Each of the basic classifiers implements known approaches to document retrieval. The first tool is based on a regular expression pattern matcher <ref type="bibr" coords="4,399.84,480.42,14.92,8.77" target="#b12">(14)</ref>, it is expected to perform well when applied on very short documents such as keywords: MeSH terms do not contains more than 5 tokens. The second classifier is based on a vector space engine. This second tool is expected to provide high recall in contrast to the regular expression-based tool, which should privilege precision. The former component uses tokens as indexing units and can be merged with a thesaurus, while the latter uses stems (Porter). Regular expressions and MeSH thesaurus. The regular expression search tool is applied on the canonic MeSH collection augmented with the MeSH thesaurus (120'020 synonyms). In this system, string normalization is mainly performed by the MeSH terminological resources when the thesaurus is used. Indeed, the MeSH provides a large set of related terms, which are mapped to a unique MeSH representative in the canonic collection. The related terms gather morpho-syntactic variants, strict synonyms, and a last class of related terms, which mixes up generic and specific terms. The system cuts the abstract into 5-token-long phrases and moves the window through the abstract: the edit-distance is computed between each of these 5 token sequences and each MeSH term. Basically, the manually crafted finite-state automata allow two insertions or one deletion within a MeSH term, and ranks the proposed candidate terms based on these basic edit operations: insertion costs 1, while deletion costs 2. The resulting pattern matcher behaves like a term proximity scoring system <ref type="bibr" coords="4,469.96,637.02,15.00,8.77" target="#b13">(15)</ref>, but is restricted to a 5-token matching window. Vector space classifier. The vector space module is based on a general IR engine with the tf.idf weighting schema. The engine uses a list of 544 stop words. As for setting the weighting factors, we observed that cosine normalization was especially effective for our task. This is not surprising, considering the fact that cosine normalization performs well when documents have a similar length <ref type="bibr" coords="4,340.80,692.88,14.95,8.77" target="#b14">(16)</ref>.</p><p>Classifier fusion. The hybrid system combines the regular expression classifier with the vector-space classifier. We do not merge our classifiers by linear combination, because the RegEx module does not return a scoring consistent with the vector space system. The combination does not use the RegEx's edit distance, and instead it uses the list returned by the vector space module as a reference list, while the list returned by the regular expression module is used as boosting list, which serves to improve the ranking of terms listed in RL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Cross-Language Categorization and Indexing</head><p>To translate the medical ImageCLEF textual contents (queries or documents), we transform the English MeSH mapping tool described above, attributing MeSH terms to English abstracts or queries. Thus, the English, French, and German version of the MeSH are simply merged in the categorizer. We use the weighting schema and system combination ( [ dtu.dtn | ltc.atn ] + RegEx ) as described in <ref type="bibr" coords="5,368.89,218.76,10.38,8.77" target="#b1">(2)</ref>. Then, the annotated collection is indexed using the vector-space engine used by the categorizer. For the document indexing, we rely on weighting schemas based on pivoted normalization (dtu.dtn): because the documents have a very variable length in the collection such a factor can be important. A slightly modified version, ltc.atn, which has shown some effectiveness for the TREC Genomics, is used too in a run. The English stop word list is merged with a French and a German stop words list. Porter stemming is used for all documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussion</head><p>We then describe each run separately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Baseline run</head><p>The Baseline run (BL) is submitted to evaluate the performance of our Information Retrieval Engine alone. The strategy is simple: for each image, the caption and the title are indexed. As captions and titles are in English, it is not stunning that the English run is the best one. Nevertheless, map of French and German runs, without any strategy, is quite high. Actually, map is very different depending on the queries, because some German and French queries have very specific disease or anatomic names, which are unchanged across languages. For example, the query 24 deals with "malformation de Budd-Chiari" in French. "Budd-Chiari" is a very specific term which is supposed to be a strongly discriminant feature: the query 24 has a map of 0.89 for French. On the contrary, the query 21 "photographies de tumeur" in French has no chance to be associated with a relevant English word contained in a caption: map for the query 21 is 0.002.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">MeSH run</head><p>The MeSH run (MH) is finally the best one, while it uses the simplest strategy. For each image, the caption, the title and the MeSH terms extracted from MEDLINE with their PMID -MeSH term + MeSH id as seen in figure <ref type="figure" coords="5,75.84,652.56,4.87,8.77" target="#fig_3">3</ref>  The benefit for English is +30%, for French +52%, and for German +8%. This is nearly the same order of performance than in the previous ImageCLEF for our strategy. But while we thought that MeSH terms collected from PubMed will be more accurate and more complete, it's not always the case. For example, the relevant document g01oc14g23x deals with "Budd-Chiari syndrome". But the MeSH concept "Budd-Chiari syndrome" (D006502) is not a MeSH term for the corresponding PMID (11598252). While the query 24 is enriched with the concept "Budd-Chiari syndrome D006502", the relevant document is not; so we lose the discriminant power of the feature D006502, which is the keystone of our strategy.</p><p>The associated article -and its MeSH terms -seems to be sometimes too general; it perhaps describes more a case study, through a set of images, than the specific image. For example, the PMID 11598252 corresponds to 46 images and deals with hepatocellular carcinoma; the image showing a Budd-Chiari syndrome is not necessarily relevant with this general set, and with the associated MeSH terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Assignment of MeSH terms for German queries with OVID</head><p>A problem that we manually discover with the German queries is the complexity of the words used, especially when several words are aggregated in only one. For instance, for the German query 25 "Merkelzellkarzinom", our categorizer returns no MeSH terms, while we can suppose that some concepts can be mapped if the word was split in "Merkel" "Zell" and "Karzinom". As the query is enriched with no MeSH terms, the retrieval step returns no documents.</p><p>A simple strategy that we choose to beat this difficulty is to use OVID. OVID is a multilingual search engine in MEDLINE, developed and maintained by the University and Hospitals of Geneva (17). Queries which return no MeSH terms with our MeSH categorizer are submitted to OVID. We obtain a list of relevant documents from PubMed. Then, we simply retain the 3 most frequent MeSH terms in the 10 most relevant documents, and we enrich the query with these MeSH terms. map MHnOVID GE 0.107 Table <ref type="table" coords="6,174.61,512.29,4.02,8.76">3</ref>: mean average precision (map) for the OVID strategy (MHnOVID)</p><p>The benefit for German is +40%. We think it's a better strategy, at least for our approach based on MeSH descriptors, than trying to translate the German query with an automatic translator -as Babelfishbecause we translate directly the query into the chosen intermediate language, i.e. the MeSH. Nevertheless, it could be interesting to compare these results with runs composed with translations strategies.</p><p>All following runs are performed with German queries enriched with this strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">ltc run</head><p>The ltc run is the same as the MeSH run, but the weighting scheme used for Information Retrieval is ltc.atn instead of dtu.dtn. ltc.atn is a weighting scheme which showed good performances at TREC Genomics last years. The utilization of this weighting scheme shows no improvements for English and French, while it lightly increase German map.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5">weight mix run</head><p>The weight mix run (mixWeight) is computed by linearly combining the two weighting schemes: dtu.dtn and ltc.atn. Document's scores from two runs are normalized, then merged. map mixWeight EN 0.17 FR 0.115 GE 0.103</p><p>Table <ref type="table" coords="7,174.19,350.77,4.05,8.76">5</ref>: mean average precision (map) for the weight mix run (mixWeight)</p><p>While the linear combination increases the map for German and French, it doesn't for English, which brings the best results. It seems that the combination should be obtained with different factors than 50-50; nevertheless, these factors have to be tuned, and it was impossible to do before having a benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.6">mix papers run</head><p>The mix papers run (mixPapers) is the more sophisticated one. We start working from the MH run. All scores are normalized. Then, we index the full texts attached to the images, and perform a retrieval from the query on this collection: the top relevant documents are then used in order to boost the associated images in the first run (score increased by 10% There is no improvement obtained for English, but we obtain our best run for German. We can suppose that, as the MeSH strategy is less effective with German (see 4.2) and captions are relatively short documents, articles bring more textual data in order to compare with the German queries. Nevertheless, for English, articles seem to bring more noise than more precisions; there still needs to work on the coefficients of the combination in order to confirm this hypothesis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.7">MeSH terms extracted from captions</head><p>For this run, the MeSH terms associated to captions and title are not extracted from MEDLINE thanks to their PMID, but they are mapped with our MeSH categorizer. We choose to keep <ref type="bibr" coords="7,373.75,668.10,9.74,8.77" target="#b13">15</ref>  The improvement for English is null. Nevertheless, the improvement is significant for French (+34%). It appears that while the MeSH terms collected from the associated article are not relevant for each image, the MeSH terms extracted with our categorizer are certainly not precise enough. We can suppose that the more verbose captions of the images, compared to the previous years' ones, leads to poorer performances of our MeSH categorizer. The solution could be to mix the two origins of MeSH terms in order to obtain a more complete set of descriptors for each image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.8">map of English MeSH run depending on queries type</head><p>We split the results of our best run, MeSH run for English (see 4.2) in the three types of queries: visual (1-10), mixed <ref type="bibr" coords="8,102.61,312.60,12.47,8.77" target="#b9">(11)</ref><ref type="bibr" coords="8,115.09,312.60,4.16,8.77" target="#b10">(12)</ref><ref type="bibr" coords="8,115.09,312.60,4.16,8.77" target="#b11">(13)</ref><ref type="bibr" coords="8,115.09,312.60,4.16,8.77" target="#b12">(14)</ref><ref type="bibr" coords="8,115.09,312.60,4.16,8.77" target="#b13">(15)</ref><ref type="bibr" coords="8,115.09,312.60,4.16,8.77" target="#b14">(16)</ref><ref type="bibr" coords="8,115.09,312.60,4.16,8.77">(17)</ref><ref type="bibr" coords="8,115.09,312.60,4.16,8.77">(18)</ref><ref type="bibr" coords="8,115.09,312.60,4.16,8.77">(19)</ref><ref type="bibr" coords="8,119.24,312.60,12.47,8.77">(20)</ref>  This is obviously the semantics queries which achieved the best results. Nevertheless, we notice that this run is nearly at the same rank compared to all participants' runs, no matter we split the queries in visual, mixed or semantics ones. Actually, it appears that the teams which choose a visual strategy obtain poor results on this benchmark. Taking a closer look to participants' results shows that some textual runs performs better in the visual queries than in the mix ones (SINAI-sinai_CT_Mesh for instance), and some visual runs performs better in the mixed queries than in the visual ones (GE-GE_GIFT8). We suppose that these anomalies should disappear when the visual techniques will be more adapted to this collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.9">combination of the best run with a visual run from another participating team</head><p>To obtain these last runs, we supply our best run (MH-EN) to another team of University and Hospitals of Geneva, Xin Zhou and Henning Muller, who are specialized in Visual Information Retrieval. Muller team, and for the best mixed run (GE-GE_GIFT8_EN0.5) X Zhou and H Muller performed runs relied mainly on GIFT (3); their runs are more supposed to be baseline runs than candidates for the high ranks. As, moreover, the visual strategies leads quite poor performances this year, it is not surprising that the combination with a visual run leads to no improvements. We hope this combination will be better for medical ImageCLEF 2009.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Map</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>The keystone of our strategy for the previous medical ImageCLEF was to enrich documents and queries with Medical Subject Headings (MeSH) terms extracted from them, in order to translate the more important concepts into an intermediate language. Nevertheless, in the new 2008 collection, images are given with more verbose captions, and with an associated article relative to a specific case study. It appears that MeSH terms of the associated article collected from MEDLINE are not always relevant, as this article can concern a huge set of images dealing with a more general subject, and can not to describe precisely the associated image. Moreover, the MeSH terms extracted directly from the captions leads worst performance, possibly due to the more verbose captions. For the future ImageCLEF, a mixed to combine the two origins of the MeSH terms should be planned. Better performances should be obtained too by tuning the system with the existing benchmark.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,103.44,480.78,369.99,8.77;2,103.44,492.00,369.84,8.77;2,103.44,503.22,287.22,8.77"><head>Figure 1 :</head><label>1</label><figDesc>Figure1: example of the metadata for one of the 67115 images. The title and caption parts are directly used by our system to retrieve relevant documents, while the PubMed id (PMID) and the article's URL can be used to extract some descriptors as MeSH terms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,110.88,659.32,126.02,6.10;2,110.88,668.14,406.01,6.10;2,110.88,676.96,223.99,6.10"><head></head><label></label><figDesc>MeSH D010437 : Peptic Ulcer Synonyms : Ulcère gastroduodénal, Gastroduodenal Ulcer, Marginal Ulcer, Ulcus pepticum, Ulcus marginale, Ulcus gastroduodenale</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="2,103.44,694.98,369.87,8.77;2,103.44,706.14,327.34,8.77"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: example of a MeSH concept as indexed by our categorizer: behind the MeSH identifier stands the concept described with French, English and German synonyms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="3,103.44,377.04,369.92,8.77;3,103.44,388.26,369.91,8.77;3,103.44,399.42,369.92,8.77;3,103.44,410.58,369.97,8.77;3,103.44,421.80,316.96,8.77"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: example of the MeSH categorization for one document in previous ImageCLEF. a) Caption of an image of the endoscopic collection (in English). b) output of our MeSH categorizer for the previous caption : concept score in first column, concept in second one, MeSH identifier for the third one. c) final document indexed : the caption is enriched with found MeSH descriptors and their MeSH id, making them language-independent.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,75.84,379.80,441.19,114.01"><head>Table 1 :</head><label>1</label><figDesc>Then, queries are submitted in 3 languages, without add of MeSH descriptors. mean average precision (map) for the Baseline run (BL)</figDesc><table coords="5,245.58,415.33,107.47,51.66"><row><cell>map</cell><cell>BL</cell></row><row><cell>EN</cell><cell>0.136</cell></row><row><cell>FR</cell><cell>0.069</cell></row><row><cell>GE</cell><cell>0.07</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,83.17,652.56,373.84,8.77"><head>Table 2 :</head><label>2</label><figDesc>-are indexed. Queries are enriched by 3 MeSH terms too (see figure4), and are then submitted. mean average precision (map) for the MeSH run (MH)</figDesc><table coords="6,245.58,108.91,107.47,51.66"><row><cell>map</cell><cell>MH</cell></row><row><cell>EN</cell><cell>0.176</cell></row><row><cell>FR</cell><cell>0.105</cell></row><row><cell>GE</cell><cell>0.076</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,75.84,635.11,95.08,8.77"><head>Table 4 :</head><label>4</label><figDesc>mean average precision (map) for the ltc run (ltc)</figDesc><table coords="6,75.84,635.11,95.08,8.77"><row><cell>See 3.1 for more details.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,141.31,462.42,301.80,102.79"><head>Table 6 :</head><label>6</label><figDesc>). mean average precision (map) for the mix papers run (mixPapers)</figDesc><table coords="7,245.58,486.79,118.70,51.60"><row><cell>map</cell><cell>mixPapers</cell></row><row><cell>EN</cell><cell>0.15</cell></row><row><cell>FR</cell><cell>0.077</cell></row><row><cell>GE</cell><cell>0.118</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="7,385.88,668.10,107.58,8.77"><head>Table 7 :</head><label>7</label><figDesc>MeSH terms per document. mean average precision (map) for the captions MeSH run (capMH)</figDesc><table coords="8,245.58,108.91,112.21,51.66"><row><cell>map</cell><cell>capMH</cell></row><row><cell>EN</cell><cell>0.134</cell></row><row><cell>FR</cell><cell>0.093</cell></row><row><cell>GE</cell><cell>0.073</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="8,95.64,312.60,401.75,102.85"><head>Table 8 :</head><label>8</label><figDesc>and semantics (21-30). mean average precision (map) for the English MeSH run (MH-EN) depending of queries type</figDesc><table coords="8,235.62,337.03,123.25,51.60"><row><cell>map</cell><cell>MH-EN</cell></row><row><cell>visual</cell><cell>0.091</cell></row><row><cell>mixed</cell><cell>0.094</cell></row><row><cell>semantics</cell><cell>0.344</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="8,128.76,574.99,333.14,94.08"><head>Table 9 :</head><label>9</label><figDesc>mean average precision (map) for the best run of the Xin Zhou and Henning</figDesc><table coords="8,176.70,574.99,258.26,67.20"><row><cell></cell><cell>GE-GE_GIFT8</cell><cell>GE-GE_GIFT8_EN0.5</cell></row><row><cell>Visual</cell><cell>0.015</cell><cell>0.076</cell></row><row><cell>Mixed</cell><cell>0.061</cell><cell>0.117</cell></row><row><cell>Semantics</cell><cell>0.027</cell><cell>0.061</cell></row><row><cell>all</cell><cell>0.035</cell><cell>0.085</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,79.50,337.57,415.47,8.76;9,75.84,348.73,425.12,8.76;9,75.84,360.09,32.62,8.62" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,85.62,337.80,395.67,8.54">A review of content-based image retrieval systems in medicine -clinical benefits and future directions</title>
	</analytic>
	<monogr>
		<title level="j" coord="9,311.12,348.87,171.32,8.62">International Journal of Medical Informatics</title>
		<editor>
			<persName><surname>Müller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Michoux</surname></persName>
		</editor>
		<editor>
			<persName><surname>Bandon</surname></persName>
		</editor>
		<editor>
			<persName><surname>Geissbuhler</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,79.50,371.25,435.08,8.62;9,75.84,382.39,384.14,8.76" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="9,85.62,371.34,428.96,8.54;9,75.84,382.62,145.66,8.54">Query and Document Translation by Automatic Text Categorization: A Simple Approach to Establish a String Textual Baseline for ImageCLEFmed</title>
		<editor>J Gobeill, H Muller and P Ruch</editor>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
	<note>ImageCLEF</note>
</biblStruct>

<biblStruct coords="9,79.50,393.55,430.01,8.76;9,75.84,404.85,81.86,8.62" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="9,85.62,393.78,200.02,8.54;9,485.70,393.69,23.80,8.62">University and Hospitals of Geneva at ImageCLEF</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gobeill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ruch</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Muller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
		</imprint>
	</monogr>
	<note>CLEF. Working notes</note>
</biblStruct>

<biblStruct coords="9,79.50,415.99,421.23,8.76;9,75.84,427.23,123.45,8.62" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,85.62,416.22,175.27,8.54">GoldMiner: a radiology image search engine</title>
	</analytic>
	<monogr>
		<title level="j" coord="9,420.78,416.13,79.94,8.62;9,75.84,427.23,57.48,8.62">American Journal of Roentgenology</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Kahn</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><genName>Jr</genName></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thao</forename></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">188</biblScope>
			<biblScope unit="page" from="1475" to="1478" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,79.50,449.53,403.44,8.76;9,75.84,460.83,107.77,8.62" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,85.62,449.76,304.78,8.54">Automatic Assignment of Biomedical Categories: Toward a Generic Approach</title>
	</analytic>
	<monogr>
		<title level="j" coord="9,397.26,449.53,19.66,8.76;9,75.84,460.83,56.77,8.62">Bioinformatics</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="658" to="664" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
	<note>Ruch</note>
</biblStruct>

<biblStruct coords="9,79.50,471.91,401.82,8.76" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="9,85.62,472.14,248.77,8.54">A comparison of event models for naive bayes text classification</title>
		<editor>Nigam, A McCallum and K</editor>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,79.50,483.13,435.22,8.76;9,75.84,494.43,68.92,8.62" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,85.62,483.36,236.05,8.54">An evaluation of statistical approaches to text categorization</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,386.19,483.27,124.72,8.62">Journal of Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="67" to="88" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,79.50,505.51,409.43,8.76;9,75.84,516.81,89.31,8.62" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,85.62,505.74,232.39,8.54">BossTexter: A boosting-based system for text categorization</title>
	</analytic>
	<monogr>
		<title level="m" coord="9,454.86,505.65,34.07,8.62;9,75.84,516.81,33.39,8.62">Machine Learning</title>
		<editor>
			<persName><forename type="first">R</forename><surname>Singer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Y</forename><surname>Shapire</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="135" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,83.97,527.95,430.08,8.76;9,75.84,539.25,264.53,8.62" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,90.42,528.18,231.73,8.54">Automated learning of decision rules for text categorization</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>C Apte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Damerau</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,491.89,528.09,22.16,8.62;9,75.84,539.25,174.41,8.62">ACM Transactions on Information Systems (TOIS)</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="233" to="251" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,83.97,550.33,400.31,8.76;9,75.84,561.63,351.39,8.62" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,90.42,550.56,255.13,8.54">A system for content-based indexing of a database of news stories</title>
	</analytic>
	<monogr>
		<title level="m" coord="9,75.84,561.63,347.68,8.62">Proceedings of the Second Annual Conference on Innovative Applications of Intelligence</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Weinstein</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Hayes</surname></persName>
		</editor>
		<meeting>the Second Annual Conference on Innovative Applications of Intelligence</meeting>
		<imprint>
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,83.97,572.71,426.21,8.76" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,90.42,572.94,135.65,8.54">Learning-Free Text Categorization</title>
		<author>
			<persName coords=""><surname>Ruch</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Baud</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Geissbuhler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,410.82,572.85,23.18,8.62">LNAI</title>
		<imprint>
			<biblScope unit="volume">2780</biblScope>
			<biblScope unit="page" from="199" to="208" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,83.97,583.99,431.11,8.76;9,75.84,595.23,49.37,8.62" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,90.42,584.22,168.77,8.54">Combining classifiers in text categorization</title>
	</analytic>
	<monogr>
		<title level="m" coord="9,391.59,584.13,23.23,8.62">SIGIR</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Croft</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Larkey</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="289" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,83.97,606.31,414.84,8.76;9,75.84,617.67,211.76,8.62" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,90.42,606.54,165.76,8.54">A tool to search through entire file systems</title>
	</analytic>
	<monogr>
		<title level="m" coord="9,352.69,606.31,146.12,8.76;9,75.84,617.67,105.71,8.62">Proceedings of the USENIX Winter 1994 Technical Conference</title>
		<editor>
			<persName><forename type="first">U</forename><surname>Wu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Mamber</surname></persName>
		</editor>
		<meeting>the USENIX Winter 1994 Technical Conference<address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="23" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,83.97,628.69,413.08,8.76;9,75.84,639.99,34.77,8.62" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="9,90.42,628.92,233.41,8.54">Term proximity scoring for keyword-based retrieval systems</title>
		<editor>Savoy, Y Rasolofo and J. ECIR</editor>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="101" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,83.97,651.13,389.87,8.76;9,75.85,662.43,245.25,8.62;9,75.85,673.59,149.67,8.62" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,90.43,651.36,234.79,8.54">Cross-language information retrieval (CLIR) track overview</title>
		<ptr target="http://gateway.ovid.com/" />
	</analytic>
	<monogr>
		<title level="m" coord="9,75.85,662.43,240.42,8.62">Proceedings of The Sixth Text Retrieval Conference (TREC6)</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Sheridan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Schäuble</surname></persName>
		</editor>
		<meeting>The Sixth Text Retrieval Conference (TREC6)</meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
