<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,122.76,148.66,357.52,15.48;1,120.12,170.62,362.80,15.48;1,266.28,192.46,70.42,15.48">Methods for combining content-based and textual-based approaches in medical image retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,164.88,226.27,67.94,9.62"><forename type="first">Mouna</forename><surname>Torjmen</surname></persName>
							<email>mouna.torjmen@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">SIG-IRIT</orgName>
								<address>
									<settlement>Toulouse</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,241.10,226.27,98.99,9.62"><forename type="first">Karen</forename><surname>Pinel-Sauvagnat</surname></persName>
							<email>karen.sauvagnat@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">SIG-IRIT</orgName>
								<address>
									<settlement>Toulouse</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,347.81,226.27,90.52,9.62"><forename type="first">Mohand</forename><surname>Boughanem</surname></persName>
							<email>mohand.boughanem@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">SIG-IRIT</orgName>
								<address>
									<settlement>Toulouse</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,122.76,148.66,357.52,15.48;1,120.12,170.62,362.80,15.48;1,266.28,192.46,70.42,15.48">Methods for combining content-based and textual-based approaches in medical image retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6A7DD4A9E06E69B6E90C5A87CBA8C5AF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing; H.3.3 Information Search and Retrieval Measurement</term>
					<term>Performance</term>
					<term>Experimentation Contextual image retrieval</term>
					<term>content-based image retrieval</term>
					<term>combination</term>
					<term>query classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our participation in the Medical Image Retrieval task of Image CLEF 2008. Our aim was to evaluate different combination methods for purely textual and visual approaches. Our most interesting conclusion is that combining results provided by both methods using classical combination function allows to obtain higher retrieval accuracy in terms of MAP .</p><p>MAP values than combination according to query type. Moreover, it is more reliable than using only textual retrieval or using only visual retrieval.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In Image Retrieval, there are two main approaches <ref type="bibr" coords="1,317.40,596.35,10.57,9.62" target="#b6">[7]</ref> : <ref type="bibr" coords="1,339.61,596.35,12.76,9.62" target="#b0">(1)</ref> Context Based Image Retrieval and (2) Content Based Image Retrieval:</p><p>• The context of an image is all information about the image coming from other sources than the image itself. It is often reduced to textual information. The main problem of this approach is that documents use different words to describe the same image or can use the same words to describe different concepts.</p><p>• Content Based Image Retrieval (CBIR) systems use low-level image features to return images similar to an image used as example. The main problem of this approach is that visual similarity may not correspond to semantic similarity (for example a CBIR system can return a picture of blue sky when the example image is a blue car).</p><p>In order to take advantages of both techniques, we propose in this paper an evaluation of combination methods in the Medical retrieval task of CLEF 2008. Our aim is to compare classical combination using a linear combination function and a combination method that takes into account the query type: visual, textual, mixed. The two systems we used for content-based image retrieval and text-based image retrieval are respectively GIFT <ref type="bibr" coords="2,365.52,159.55,10.57,9.62" target="#b2">[3]</ref> and XFIRM <ref type="bibr" coords="2,437.64,159.55,10.00,9.62" target="#b4">[5]</ref>.</p><p>The rest of the paper is organized as follows. Section 2 describes our approach to evaluate Medical Retrieval queries. In fact, we describe both used systems and our combination techniques. In section 3, we present an empirical evaluation of the proposed methods carried out using the Medical Retrieval Task in Image CLEF 2008. We conclude in section 4 with a discussion on our finding and suggestions for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Retrieval approaches 2.1 The XFIRM model</head><p>We use the XFIRM XML search engine <ref type="bibr" coords="2,260.76,306.43,10.57,9.62" target="#b4">[5]</ref> as a base model for textual queries processing. However, as the document structure in the collection is not complex (the average document depth is low), we use a simplified version of the model.</p><p>The model is based on a relevance propagation method. During query processing, relevance scores are computed at leaf nodes level and then at inner nodes level thanks to a propagation of leaf nodes scores through the document tree. An ordered list of subtrees is then returned to the user.</p><p>Let q = t 1 , . . . , t n be a query composed of n terms. Relevance values of leaf nodes are computed using a similarity function RSV (q, ln).</p><p>RSV (q, ln) = n i=1 w q i * w ln i , where w q i = tf q i * idf i and</p><formula xml:id="formula_0" coords="2,404.04,430.10,109.00,12.74">w ln i = tf ln i * idf i<label>(1)</label></formula><p>Where w q i and w ln i are the weights of term i in query q and leaf node ln respectively. tf q i and tf ln i are the frequency of i in q and ln respectively, idf i = log(|D|/(|di| + 1)) + 1, with |D| the total number of documents in the collection, and |di| the number of documents containing i.</p><p>Each node in the document tree is then assigned a relevance score which is function of the relevance scores of the leaf nodes it contains.</p><formula xml:id="formula_1" coords="2,236.16,543.53,276.88,22.78">r n = |L r n |. ln k ∈Ln α dist(n,ln k )-1<label>(2)</label></formula><p>dist(n, ln k ) is the distance between node n and leaf node ln k in the document tree, i.e. the number of edges that are necessary to join n and ln k , and α ∈]0..1] allows to adapt the importance of the dist parameter. |L r n | is the number of leaf nodes being descendant of n and having a non-zero relevance value (according to equation 1).</p><p>In the indexing phase, only two fields of documents of the medical textual collection are indexed ("caption" and "title") as they are the only ones which contain significant textual information. As the aim of the task is to return image identifier (document), we take α = 1 in equation 2 to ensure that best ranked elements will be documents. As each document corresponds to a single image, we indexed documents using the image name and not the document name, in order to return directly the required element (image). In the rest of the paper, document relevance is thus equivalent to image relevance in the retrieval process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The GIFT System</head><p>GIFT or GNU Image Finding Tool <ref type="bibr" coords="3,248.78,130.03,10.45,9.62" target="#b2">[3]</ref> is a free CBIR system released under GNU After license. It processes Query By Example (QBE<ref type="foot" coords="3,254.64,140.33,3.97,6.97" target="#foot_0">1</ref> ) on images, with the opportunity to improve query results by relevance feedback. It uses common techniques from content-based information retrieval <ref type="bibr" coords="3,398.52,165.91,9.91,9.62" target="#b3">[4]</ref>. A big number of low level features can be used (≻ 80000). These features are both local and global, simple color and texture... <ref type="bibr" coords="3,134.05,189.91,9.91,9.62" target="#b5">[6]</ref>. GIFT system has a variable length list of discrete features for every image.</p><p>In the experiments presented here, we directly used GIFT results kindly provided by organizers, with no further processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Combination of XFIRM and GIFT systems</head><p>In ImageCLEFmed 2008, there are 30 topics composed of both textual and images example queries, with 10 topics classified in the following three categories:</p><p>• Visual : topics where visual system alone is expected to reach good performance (a visual query example is given in figure <ref type="figure" coords="3,257.06,305.83,4.46,9.62" target="#fig_0">1</ref>)</p><p>Show me images of a knee x-ray. Zeige mir Röntgenbilder des Knies. Montre-moi des radiographies du genou.   We evaluated two combination methods between the XFIRM and GIFT systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Classical combination</head><p>In this approach, we used the two aforementioned systems on the whole set of queries and merged their results to obtain a single result list.</p><p>The overall structure of this approach is depicted in figure <ref type="figure" coords="4,362.92,286.03,3.88,9.62">4</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>XFIRM system GIFT system</head><p>Textual corpus</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Images corpus XFIRM results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>GIFT results</head><p>sŝƐƵĂů </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Final results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 4: Overview of our approach</head><p>To merge the two results lists into a single list of ranked results we first normalize scores obtained by the two systems, and then we use a simple and classic linear combination of evidences:</p><formula xml:id="formula_2" coords="4,169.56,654.33,339.23,10.26">F S(image) = α • S XF IRM (image) + (1 -α) • S GIF T (image) (<label>3</label></formula><formula xml:id="formula_3" coords="4,508.78,654.67,4.25,9.62">)</formula><p>when α is a pivot parameter ∈ [0..1], S XF IRM (image) represents the image score obtained using the XFIRM system, and S GIF T (image) is the score of the same image obtained by the GIFT system.</p><p>When α is set to 1, only the image score from the XFIRM system is used. On the other hand, only the image score by the GIFT system is used when the value of α is set to 0. Our official runs in Medical Image Retrieval task were submitted with α equal to 0.1, 0.5, 0.9 and 1.0. The fusion scores of the image and textual retrieval methods are then ranked in a descending order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Combination according to query type</head><p>We also evaluated the processing of each category of queries with a different system. We thus used the GIFT system to evaluate visual topics, the XFIRM system to evaluate textual (semantic) topics, and a classic combination function (Equation <ref type="formula" coords="5,331.00,191.83,4.46,9.62" target="#formula_2">3</ref>) of the two systems to evaluate mixed topics. Figure <ref type="figure" coords="5,154.21,203.83,4.98,9.62" target="#fig_3">5</ref>   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Runs and Results</head><p>Results are presented in table 1. Our official runs are in grayed boxes. In these runs, the number of returned results by the XFIRM system was 250 while the number of returned results can be 1000. We corrected these runs by returning the well number of results.</p><p>XFIRMRun is the complete run of SigRunText, it used only textual parts of all queries and it was processed using the XFIRM system. GiftRun is the run obtained using only example images and was processed using the Gift system. Comparing the two runs, we notice that textual based retrieval approach is much better (MAP=0.1524 versus MAP=0.0349 using the Gift system).</p><p>Our best run, RunComb09, used the classical combination function with α = 0.9. This implies that the two information sources are needed to get the best performances, but textual information must be the main source of evidence and visual information must be used as a complementary evidence element to improve search results. In fact, results are improved when α increases.</p><p>RunMix09 is obtained using the approach illustrated in figure <ref type="figure" coords="5,382.74,722.23,3.90,9.62" target="#fig_3">5</ref>. For the ten mixed queries, the combination factor α used is 0.9 (the best run obtained using the classical combination). The MAP of this run showed that performance increases comparatively to textual processing and classical combination function.</p><p>More work and experimentations are needed to show the difference and the effectiveness of each approach. We plan in future work to evaluate our approaches using other systems as results are also depending of the systems used for retrieval.</p><p>Table <ref type="table" coords="6,131.88,437.59,4.98,9.62" target="#tab_3">2</ref> shows results for each query category using respectively the XFIRM system, the GIFT system and the best combination of both (with α = 0.9). For all query categories, best MAP is obtained using classical combination with α = 0.9. So the intuition that visual queries must be processed with a CBIR system, textual queries must be processed with textual based retrieval system and mixed queries must be processed with a combination of both is not validated in the results. This shows that the classification of queries into visual, mixed and textual categories is not adequate in improving results, and consequently, using classical combination remains the best way to have best results. Our proposed approach described in figure <ref type="figure" coords="6,300.29,737.95,4.98,9.62" target="#fig_3">5</ref> is very simple as it used queries classification provided by organizers. We think that it can be improved and give best results by studying techniques of automatic query classification using other features. In fact, query classification is an active research field where Good <ref type="bibr" coords="7,254.17,135.55,10.57,9.62" target="#b1">[2]</ref> and Fairthorne <ref type="bibr" coords="7,339.04,135.55,10.45,9.62" target="#b0">[1]</ref> were among the first to recommend automatic query classification to improve document retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and future work</head><p>In this paper, we evaluated a classical combination approach and an approach based on queries classification using two systems (GIFT and XFIRM). Best results for the MAP metric are obtained using the classical combination method, more precisely with giving more importance for textual information than visual ones. However, our proposed method of query classification processing leads to a significant performance degradation. This can be explained by the fact that classify queries into visual, textual and mixed queries is not an adequate way of classification. In addition, results are also depending of the used systems.</p><p>In future work, we plan to confirm our conclusions by evaluating this approach using systems other than GIFT and XFIRM and using other collection (as Medical Image Retrieval in Image CLEF 2007). In addition, one of the most enticing directions of future work is to study the automatic classification of queries in order to more study the impact of this technique in image retrieval.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,224.16,456.31,154.82,9.62;3,240.30,328.52,57.51,85.49"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Example of a visual topic</figDesc><graphic coords="3,240.30,328.52,57.51,85.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,223.56,658.51,155.89,9.62;3,237.35,546.32,50.50,66.39"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Example of a mixed topic</figDesc><graphic coords="3,237.35,546.32,50.50,66.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,221.40,194.47,160.22,9.62"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Example of a textual topic</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,120.72,499.99,95.70,9.62;5,237.38,499.99,244.88,9.62"><head>Figure 5 :</head><label>5</label><figDesc>Figure5: Overview of approach that evaluates queries according to their types</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,180.04,309.71,235.18,214.59"><head>Example Image Fusion results results</head><label></label><figDesc></figDesc><table coords="4,180.04,309.71,235.18,29.36"><row><cell>ƋƵĞƌŝĞƐ</cell><cell></cell><cell>DŝǆĞĚ ƋƵĞƌŝĞƐ</cell><cell></cell><cell>dĞǆƚƵĂů ƋƵĞƌŝĞƐ</cell></row><row><cell>Example Image</cell><cell>ƚĞǆƚ</cell><cell>Example Image</cell><cell>ƚĞǆƚ</cell><cell>ƚĞǆƚ</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,162.49,203.83,252.68,271.82"><head></head><label></label><figDesc>illustrates our approach.</figDesc><table coords="5,177.82,226.67,237.35,248.98"><row><cell>sŝƐƵĂů ƋƵĞƌŝĞƐ</cell><cell></cell><cell></cell><cell cols="2">DŝǆĞĚ ƋƵĞƌŝĞƐ</cell><cell cols="2">dĞǆƚƵĂů ƋƵĞƌŝĞƐ</cell></row><row><cell>Example Image</cell><cell>ƚĞǆƚ</cell><cell cols="2">Example Image</cell><cell>ƚĞǆƚ</cell><cell>Example Image</cell><cell>ƚĞǆƚ</cell></row><row><cell cols="2">'/&amp;d ƐǇƐƚĞŵ</cell><cell></cell><cell>'/&amp;d ƐǇƐƚĞŵ</cell><cell>y&amp;/ZD ƐǇƐƚĞŵ</cell><cell>y&amp;/ZD ƐǇƐƚĞŵ</cell></row><row><cell></cell><cell></cell><cell>Images corpus</cell><cell>¢¡ ¥¦ §¨© §</cell><cell>¡¢£¤ ¥¦ §¨© §</cell><cell>corpus Textual</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Classical</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">combination</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">approach</cell><cell></cell></row><row><cell cols="2">sŝƐƵĂů sŝƐƵĂů ƋƵĞƌŝĞƐ ƌĞƐƵůƚƐ</cell><cell></cell><cell cols="2">DŝǆĞĚ DŝǆĞĚ ƋƵĞƌŝĞƐ ƌĞƐƵůƚƐ</cell><cell>dĞǆƚƵĂů dĞǆƚƵĂů ƋƵĞƌŝĞƐ ƌĞƐƵůƚƐ</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">&amp;ŝŶĂů ƌĞƐƵůƚƐ</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,131.52,118.63,334.88,234.98"><head>Table 1 :</head><label>1</label><figDesc>Results of Clef Medical Retrieval Task</figDesc><table coords="6,131.52,128.35,334.88,225.26"><row><cell>Runs</cell><cell>α</cell><cell>MAP</cell><cell>bpref</cell><cell>P@10</cell><cell>p@30</cell></row><row><cell>GiftRun</cell><cell>0</cell><cell>0.0349</cell><cell>0.0898</cell><cell>0.1700</cell><cell>0.1511</cell></row><row><cell>SigRunText</cell><cell>1</cell><cell>0.1410</cell><cell>0.1851</cell><cell>0.2430</cell><cell>0.2244</cell></row><row><cell>XFIRMRun</cell><cell>1</cell><cell>0.1524</cell><cell>0.2454</cell><cell>0.2600</cell><cell>0.2278</cell></row><row><cell>SigCombAlpha01</cell><cell>0.1</cell><cell>0.0427</cell><cell>0.0929</cell><cell>0.2200</cell><cell>0.1600</cell></row><row><cell>RunComb01</cell><cell>0.1</cell><cell>0.0483</cell><cell>0.1021</cell><cell>0.2200</cell><cell>0.1800</cell></row><row><cell>RunComb02</cell><cell>0.2</cell><cell>0.0572</cell><cell>0.1098</cell><cell>0.2700</cell><cell>0.2111</cell></row><row><cell>RunComb03</cell><cell>0.3</cell><cell>0.0658</cell><cell>0.1170</cell><cell>0.3167</cell><cell>0.2311</cell></row><row><cell>RunComb04</cell><cell>0.4</cell><cell>0.0749</cell><cell>0.1190</cell><cell>0.3000</cell><cell>0.2452</cell></row><row><cell>SigCombAlpha05</cell><cell>0.5</cell><cell>0.0432</cell><cell>0.0948</cell><cell>0.2200</cell><cell>0.1600</cell></row><row><cell>RunComb05</cell><cell>0.5</cell><cell>0.0820</cell><cell>0.1376</cell><cell cols="2">0.3733 0.2833</cell></row><row><cell>RunComb06</cell><cell>0.6</cell><cell>0.0909</cell><cell>0.1462</cell><cell cols="2">0.3733 0.2889</cell></row><row><cell>RunComb07</cell><cell>0.7</cell><cell>0.1014</cell><cell>0.1591</cell><cell>0.3433</cell><cell>0.2989</cell></row><row><cell>RunComb08</cell><cell>0.8</cell><cell>0.1409</cell><cell>0.2167</cell><cell>0.3100</cell><cell>0.2933</cell></row><row><cell>SigCombAlpha09</cell><cell>0.9</cell><cell>0.0415</cell><cell>0.0947</cell><cell>0.2170</cell><cell>0.1611</cell></row><row><cell>RunComb09</cell><cell>0.9</cell><cell cols="3">0.1705 0.2614 0.2900</cell><cell>0.2611</cell></row><row><cell>SigMix</cell><cell>0.5</cell><cell>0.1113</cell><cell>0.1637</cell><cell>0.2870</cell><cell>0.2311</cell></row><row><cell>RunMix1</cell><cell>1</cell><cell>0.1043</cell><cell>0.1906</cell><cell>0.2067</cell><cell>0.1678</cell></row><row><cell>RunMix09</cell><cell>0.9</cell><cell>0.1101</cell><cell>0.1914</cell><cell>0.2133</cell><cell>0.1756</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,143.76,552.07,315.70,169.58"><head>Table 2 :</head><label>2</label><figDesc>Some Results of Clef Medical Retrieval Task by query category</figDesc><table coords="6,154.56,563.83,288.68,157.82"><row><cell>Runs</cell><cell>MAP</cell><cell>bpref</cell><cell>P@10</cell><cell>p@30</cell></row><row><cell></cell><cell cols="2">Visual Queries (10)</cell><cell></cell><cell></cell></row><row><cell>RunVisXFIRM</cell><cell>0.1658</cell><cell cols="2">0.2256 0.2600</cell><cell>0.2600</cell></row><row><cell>RunVisGift</cell><cell>0.0159</cell><cell>0.0615</cell><cell>0.1000</cell><cell>0.0800</cell></row><row><cell>RunVisComb09</cell><cell cols="2">0.1667 0.2199</cell><cell cols="2">0.2800 0.2633</cell></row><row><cell></cell><cell cols="2">Mixed Queries (10)</cell><cell></cell><cell></cell></row><row><cell>RunMixXFIRM</cell><cell>0.0630</cell><cell>0.1609</cell><cell>0.1400</cell><cell>0.1033</cell></row><row><cell>RunMixGift</cell><cell>0.0613</cell><cell>0.1302</cell><cell cols="2">0.3200 0.2800</cell></row><row><cell>RunMixComb09</cell><cell cols="3">0.0805 0.1632 0.1600</cell><cell>0.1267</cell></row><row><cell></cell><cell cols="2">Textual Queries (10)</cell><cell></cell><cell></cell></row><row><cell>RunTexXFIRM</cell><cell>0.2341</cell><cell>0.3496</cell><cell cols="2">0.3800 0.3200</cell></row><row><cell>RunTexGift</cell><cell>0.0275</cell><cell>0.0778</cell><cell>0.0900</cell><cell>0.0933</cell></row><row><cell>RunTexComb09</cell><cell cols="3">0.2643 0.4041 0.2800</cell><cell>0.2633</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,105.24,746.79,128.72,7.60"><p>http://en.wikipedia.org/wiki/QBE</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,105.48,376.63,272.29,9.62" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="7,203.29,376.63,144.58,9.62">The mathematics of classification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">A</forename><surname>Fairthorne</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1961">1961</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.48,396.55,407.55,9.62;7,105.48,408.55,290.05,9.62" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="7,154.33,396.55,197.98,9.62">Speculations concerning information retrieval</title>
		<author>
			<persName coords=""><forename type="first">I J</forename><surname>Good</surname></persName>
		</author>
		<idno>PC-78</idno>
		<imprint>
			<date type="published" when="1958">1958</date>
			<pubPlace>Yorktown Heights, New York</pubPlace>
		</imprint>
		<respStmt>
			<orgName>IBM Research Centre</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Research Report</note>
</biblStruct>

<biblStruct coords="7,105.48,428.47,407.74,9.62;7,105.48,440.35,364.22,9.62" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="7,223.00,440.35,242.83,9.62">An open framework for distributed multimedia retrieval</title>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wolfgang</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">Mcg</forename><surname>Squire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zoran</forename><surname>Pecenovic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stéphane</forename><surname>Marchand-Maillet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thierry</forename><surname>Pun</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.48,460.39,407.56,9.62;7,105.48,472.27,407.55,9.62;7,105.48,484.27,407.57,9.62;7,105.48,496.15,293.55,9.62" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,389.52,460.39,123.52,9.62;7,105.48,472.27,256.45,9.62">An efficiency comparison of two content-based image retrieval systems, gift and picsom</title>
		<author>
			<persName coords=""><forename type="first">Mika</forename><surname>Rummukainen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jorma</forename><surname>Laaksonen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Markus</forename><surname>Koskela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="7,105.48,496.15,152.14,9.18">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Erwin</forename><forename type="middle">M</forename><surname>Bakker</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thomas</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Lew</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nicu</forename><surname>Sebe</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Xiang</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">Sean</forename><surname>Zhou</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">2728</biblScope>
			<biblScope unit="page" from="500" to="509" />
			<date type="published" when="2003">2003</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.48,516.07,407.51,9.62;7,105.48,528.07,307.25,9.62" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="7,185.76,516.07,327.24,9.18;7,105.48,528.07,60.49,9.18">Modle flexible pour la recherche d&apos;information dans des corpus de documents semi-structurs</title>
		<author>
			<persName coords=""><forename type="first">Karen</forename><surname>Sauvagnat</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<pubPlace>Toulouse</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Paul Sabatier University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="7,105.48,547.99,407.65,9.62;7,105.48,559.99,407.65,9.62;7,105.48,571.87,22.93,9.62" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="7,328.15,547.99,184.98,9.62;7,105.48,559.99,403.18,9.62">Content-based query of image databases, inspirations from text retrieval: inverted files, frequency-based weights and relevance feedback</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Squire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Raki</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.48,591.79,407.46,9.62;7,105.48,603.79,367.58,9.62" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,191.53,591.79,178.03,9.62">Image retrieval: Content versus context</title>
		<author>
			<persName coords=""><forename type="first">Thijs</forename><surname>Westerveld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,396.00,591.79,116.95,9.18;7,105.48,603.79,242.97,9.18">Content-Based Multimedia Information Access</title>
		<imprint>
			<date type="published" when="2000-04">April 2000</date>
			<biblScope unit="page" from="276" to="284" />
		</imprint>
	</monogr>
	<note>RIAO 2000 Conference Proceedings</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
