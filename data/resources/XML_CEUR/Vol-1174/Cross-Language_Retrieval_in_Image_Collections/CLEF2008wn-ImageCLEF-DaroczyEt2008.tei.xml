<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,117.94,146.73,367.12,18.57;1,262.23,168.65,78.54,18.57;1,340.77,168.17,5.98,10.48">SZTAKI @ ImageCLEF 2008 Visual Concept Detection *</title>
				<funder ref="#_nSuyxbT">
					<orgName type="full">EU</orgName>
				</funder>
				<funder ref="#_Ga5rXJM #_DYFUF4b #_6dEBy57">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,194.62,204.00,65.87,9.96"><forename type="first">B치lint</forename><surname>Dar칩czy</surname></persName>
							<email>daroczyb@ilab.sztaki.hu</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,273.77,204.00,52.76,9.96"><forename type="first">Zsolt</forename><surname>Fekete</surname></persName>
							<email>zsfekete@ilab.sztaki.hu</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,339.81,204.00,68.56,9.96"><forename type="first">M치ty치s</forename><surname>Brendel</surname></persName>
							<email>mbrendel@ilab.sztaki.hu</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,117.94,146.73,367.12,18.57;1,262.23,168.65,78.54,18.57;1,340.77,168.17,5.98,10.48">SZTAKI @ ImageCLEF 2008 Visual Concept Detection *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E3A3B1E4CAE36E34F34490A3D85FD2B6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries General Terms Measurement, Performance, Experimentation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe our approach to the ImageCLEF-VisualConcept 2008 task. Our method is based on image segmentation, using a feature vector describing the visual content of image segments or the entire image. Logistic regression was used for classication. Images were segmented by a home developed segmenter. While in this preliminary report classication by global image features performed best, preliminary results suggest the importance of segmentation for certain classes. We are planning to provide improved analysis in the near future.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper we describe our approach to the ImageCLEF Visual Concept 2008 evaluation campaign over the IAPR TC-12 Benchmark <ref type="bibr" coords="1,264.93,584.89,9.96,9.96" target="#b5">[6]</ref>. The Visual Concept Detection Task has the objective to identify visual concepts. Both the training and test-set was a part of the IAPR TC-12 database. 1,800 images were published, which were classied according to a small concept hierarchy with 17 concepts. The test database consisted of 1,000 images. For each of these images it was required to determine the presence or absence of the concepts.</p><p>Our method is based on our approach to the object classication track of the previous year ( <ref type="bibr" coords="1,93.50,656.62,10.51,9.96" target="#b3">[4]</ref>). As a main dierence, we used global features in addition to segment based ones, since concepts such as night and day are characterized by the entire image. For this reason our CBIR method is based on segmentation of the image and on the comparison of features globally as well as segmentwise. While may of the existing CBIR systems rely on so called blobs, regions, or segments <ref type="bibr" coords="1,90.00,704.45,10.51,9.96" target="#b2">[3,</ref><ref type="bibr" coords="1,103.83,704.45,7.75,9.96" target="#b7">8,</ref><ref type="bibr" coords="1,114.90,704.45,7.75,9.96" target="#b1">2,</ref><ref type="bibr" coords="1,125.96,704.45,7.01,9.96" target="#b6">7]</ref>, the specialty of our method is our special segmentation method and the combining of global and segment based approach.</p><p>Due to processing and classication costs we show preliminary results only that we plan to revise in the near future. As a main issue, we were not able to perform method selection and blending on a separate heldout set that, as expected, resulted in overtting both for our classicator combination and for our segment ltering methods.</p><p>2 Visual feature generation Our CBIR system <ref type="bibr" coords="2,171.72,201.65,10.51,9.96" target="#b3">[4,</ref><ref type="bibr" coords="2,185.44,201.65,7.75,9.96" target="#b0">1]</ref> relies on so called blobs, regions or segments. Classes such as building or people are classied by extracting specic features from the segments. For segmentation we use the code of the Felzenszwalb and Huttenlocher <ref type="bibr" coords="2,302.15,225.56,10.51,9.96" target="#b4">[5]</ref> graph-based method. Global classes such as outdoor are classied by using the entire image as a single segment.</p><p>By the distinction of classes that characterize global and local features of the image, respectively, we experimented with the number and size of the segments starting from a single segment per image for global classes down to a very large number of segments. After resizing images to a size of maximum 500x500 by keeping the aspect ratio, we tuned the minimum segment size and the cut parameters of the FelzenszwalbHuttenlocher algorithm to select a small and a medium granularity segmentation. The small version resulted typically in more than 100 while medium in less than 100 segments per image. The minimum segment size is 50 pixels for small and 1500 for medium.</p><p>The runs submitted also dier in the features used to characterize the segments. We use mean color, RGB histogram and the 2D Fourier transform of the image in addition to shape values formed by converting segments to binary pattern, then resizing to 10x10 so that binary values are converted to grayscale values proportionally. small: Same as medium with small size segments, i.e. more than 100 segments per image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Classication</head><p>We use logistic regression for classication with the global or segment features as input. The output real value is interpreted as the probability of the image or segment belonging to the specic class. For a single image we averaged the segment based predictions, which turned out more accurate than either the minimum or the maximum. Finally, a threshold of 0,5 was applied to get binary values. We did not use the logical information included in the class hierarchy, which could improve our method.</p><p>In our mixed run for each class we used the classier that performed best on the training data. Due to time constraints we did not use a heldout set, which resulted in overtraining for this run. By closer analysis the glob1 run was overtrained the most. By replacing glob1 by glob2 the combined performance improved over the best single run even in this overtrained scenario. The explanation for the overtraining for glob1 may lie in the low number of features used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>Table <ref type="table" coords="2,117.06,733.02,4.98,9.96" target="#tab_0">1</ref> summarizes our runs. The results were evaluated by the ImageCLEF organizers using the measures of equal error rate (EER) and area under ROC curve (AUC). The three main variants are based on the granularity of the segmentation. We distinguish the single, 100-and 100+ segments per image labeled Glob, Small and Medium, respectively.</p><p>In the case of the segment based classication we introduced further variants for ltering out irrelevant segments from the training data. After ltering a new training was applied. The lack of a heldout data resulted in overtting in this case as well. The four variants are no lter: all segments are used for training the class; ppnn: stands for discarding all segments from the training set except for those labeled correctly (positive for positive, negative for negative); ppnpnn: is a more admissive lter that discards only segments with positive true label classied as negative.</p><p>relabel: stands for changing the true label of negatively classied segments to negative before the second training step.</p><p>Finally we submitted three combinations, all of them suering from overtraining due to the lack of a heldout set.</p><p>Logreg: the output of the classiers are combined by logistic regression again.</p><p>Mixed: For each class the method performing best on the training data was selected.</p><p>Mixed2: Partially resolving the overtting of Mixed, glob1 is always replaced by glob2. This run is included only in the post submission error analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion and future work</head><p>In summary we may observe best overall performance for the high dimensional global feature space, closely followed by the medium resolution segmentation. We also reached improvement (although not among the submitted runs) by combination. Results in this report are preliminary and we are planning to rerun all our classicators by using separate heldout sets for segment ltering and combination.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,90.00,397.27,423.00,12.73;2,114.91,411.30,169.28,9.96;2,90.00,428.38,423.00,12.73;2,114.91,442.41,398.10,9.96;2,114.91,454.36,289.45,9.96;2,90.00,471.44,423.00,12.73;2,114.91,485.47,257.28,9.96"><head></head><label></label><figDesc>glob1: 33 values per image for mean color (RGB) and a 10-bin histogram for all the 3 channels (RGB). No segmentation is performed. glob2: 173 values per image for mean color (RGB), a 20-bin histogram, 2x5 contrast (5 maximal and 5 minimal values of L-channel in HSL color-space) and 100 values of a 2D Fourier transform (sampled along zig-zag). No segmentation is performed.medium: 135 values per segments for mean color, 3x10 histogram and 10x10 shape. Segments are of medium size, i.e. less than 100 in number per image.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,90.00,110.16,423.00,143.39"><head>Table 1 :</head><label>1</label><figDesc>Performance of the three basic methods and their combination, evaluated by dierent measures</figDesc><table coords="3,144.73,110.16,313.54,105.54"><row><cell></cell><cell cols="2">Glob1 Glob2</cell><cell></cell><cell></cell><cell>Small</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="6">no lter relabel ppnpnn ppnn</cell></row><row><cell></cell><cell>EER 45.72</cell><cell>31.14</cell><cell>32.44</cell><cell cols="2">32.48</cell><cell cols="2">32.46</cell><cell>36.07</cell></row><row><cell></cell><cell>AUC 52.78</cell><cell>74.90</cell><cell>73.32</cell><cell cols="2">73.03</cell><cell cols="2">73.05</cell><cell>67.15</cell></row><row><cell></cell><cell></cell><cell cols="2">Medium</cell><cell></cell><cell cols="4">Logreg Mixed Mixed2</cell></row><row><cell></cell><cell cols="4">no lter relabel ppnpnn ppnn</cell><cell></cell><cell></cell><cell></cell></row><row><cell>EER</cell><cell>32.10</cell><cell>32.47</cell><cell>32.47</cell><cell>37.01</cell><cell cols="2">37.12</cell><cell cols="2">38.34</cell><cell>29.92</cell></row><row><cell>AUC</cell><cell>74.18</cell><cell>73.57</cell><cell>73.61</cell><cell>59.30</cell><cell cols="2">66.53</cell><cell cols="2">63.80</cell><cell>72.77</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div><p>* This work was supported by the <rs type="funder">EU</rs> <rs type="projectName">FP7</rs> project <rs type="projectName">JUMAS Judicial Management</rs> by <rs type="projectName">Digital Libraries Semantics</rs> and by grants <rs type="grantNumber">OTKA NK 72845</rs> and <rs type="grantNumber">NKFP-07-A2 TEXTREND</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_nSuyxbT">
					<orgName type="project" subtype="full">FP7</orgName>
				</org>
				<org type="funded-project" xml:id="_Ga5rXJM">
					<orgName type="project" subtype="full">JUMAS Judicial Management</orgName>
				</org>
				<org type="funded-project" xml:id="_DYFUF4b">
					<idno type="grant-number">OTKA NK 72845</idno>
					<orgName type="project" subtype="full">Digital Libraries Semantics</orgName>
				</org>
				<org type="funding" xml:id="_6dEBy57">
					<idno type="grant-number">NKFP-07-A2 TEXTREND</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="3,105.50,697.82,407.50,9.96;3,105.49,709.78,407.51,9.96;3,105.49,721.73,228.66,9.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="3,142.44,709.78,265.95,9.96">Cross-modal retrieval by text and image feature biclustering</title>
		<author>
			<persName coords=""><forename type="first">Andr치s</forename><surname>Bencz칰r</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Istv치n</forename><surname>B칤r칩</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M치ty치s</forename><surname>Brendel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Csalog치ny</forename><surname>K치roly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B치lint</forename><surname>Dar칩czy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D치vid</forename><surname>Sikl칩si</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,431.69,712.67,81.31,6.11;3,105.49,724.62,110.82,6.11">Working Notes for the CLEF 2007 Workshop</title>
		<meeting><address><addrLine>Budapest,Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,111.35,407.51,9.96;4,105.49,123.31,407.50,9.96;4,105.49,135.27,224.85,9.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,414.03,111.35,98.97,9.96;4,105.49,123.31,344.95,9.96">Blobworld: Image segmentation using expectation-maximization and its application to image querying</title>
		<author>
			<persName coords=""><forename type="first">Chad</forename><surname>Carson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hayit</forename><surname>Greenspan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,458.14,126.20,54.86,6.11;4,105.49,138.15,118.88,6.11">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">10261038</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,155.19,407.51,9.96;4,105.49,167.15,169.41,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,249.95,155.19,258.89,9.96">Image categorization by learning and reasoning with regions</title>
		<author>
			<persName coords=""><forename type="first">Yixin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,105.49,170.03,90.46,6.11">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">913939</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,187.07,407.50,9.96;4,105.49,199.03,407.50,9.96;4,105.49,210.98,407.51,9.96;4,105.49,222.94,407.51,9.96;4,105.49,234.89,407.50,9.96;4,105.49,246.85,22.69,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,373.95,222.94,139.05,9.96;4,105.49,234.89,88.10,9.96">Overview of the imageclef 2007 object retrieval task</title>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ville</forename><surname>Viitaniemi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andr치s</forename><surname>Bencz칰r</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M치ty치s</forename><surname>Brendel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B치lint</forename><surname>Dar칩czy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hugo</forename><surname>Jair Escalante</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Theo</forename><surname>Balderas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>Gever</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hern치ndez</forename><surname>Arturo</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Gracidas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>Steven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jorma</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mingjing</forename><surname>Laaksonen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Heidy</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marin</forename><surname>Marisol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hermann</forename><surname>Castro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaoguang</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nicu</forename><surname>Rui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julian</forename><surname>Sebe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lei</forename><surname>St칬ttinger</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,219.03,237.78,200.74,6.11">Working Notes for the CLEF 2007 Workshop</title>
		<meeting><address><addrLine>Budapest,Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,266.77,407.50,9.96;4,105.49,278.73,228.40,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,330.02,266.77,178.35,9.96">Ecient graph-based image segmentation</title>
		<author>
			<persName coords=""><forename type="first">Pedro</forename><forename type="middle">F</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><forename type="middle">P</forename><surname>Huttenlocher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,105.49,281.62,181.91,6.11">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,298.65,407.51,9.96;4,105.49,310.61,407.50,9.96;4,105.49,322.56,53.68,9.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,435.82,298.65,77.19,9.96;4,105.49,310.61,306.33,9.96">The IAPR TC-12 benchmark -a new evaluation resource for visual information systems</title>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>M칲ller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselears</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,434.72,313.50,45.58,6.11">OntoImage</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page">1323</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,342.49,407.50,9.96;4,105.49,357.33,407.51,6.11;4,105.49,366.40,355.06,9.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,267.34,342.49,228.65,9.96">Image similarity search with compact data structures</title>
		<author>
			<persName coords=""><forename type="first">Qin</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Moses</forename><surname>Charikar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,105.49,357.33,407.51,6.11;4,105.49,369.29,102.89,6.11">CIKM &apos;04: Proceedings of the Thirteenth ACM International Conference on Information and Knowledge Management</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">208217</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,386.32,407.50,9.96;4,105.49,398.28,378.35,9.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,313.48,386.32,199.52,9.96;4,105.49,398.28,137.08,9.96">Region-based image retrieval using integrated color, shape, and location index</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">G</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">K</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">K</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,251.37,401.17,127.30,6.11">Comput. Vis. Image Underst</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page">193233</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
