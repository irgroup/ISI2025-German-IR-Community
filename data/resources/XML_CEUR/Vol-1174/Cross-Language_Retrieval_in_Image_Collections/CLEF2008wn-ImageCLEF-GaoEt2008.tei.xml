<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,113.88,148.63,375.43,15.51;1,110.40,170.59,382.34,15.51;1,218.04,192.43,167.03,15.51">IPAL at CLEF 2008: Mixed-Modality based Image Search, Novelty based Re-ranking and Extended Matching</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,185.52,225.93,44.78,9.96"><forename type="first">Sheng</forename><surname>Gao</surname></persName>
							<email>gaosheng@i2r.a-star.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="institution">Institute for Infocomm Research</orgName>
								<address>
									<settlement>A*Star</settlement>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,238.69,225.93,93.64,9.96"><forename type="first">Jean-Pierre</forename><surname>Chevallet</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Institute for Infocomm Research</orgName>
								<address>
									<settlement>A*Star</settlement>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,354.99,225.93,62.53,9.96"><forename type="first">Joo-Hwee</forename><surname>Lim</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Institute for Infocomm Research</orgName>
								<address>
									<settlement>A*Star</settlement>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,113.88,148.63,375.43,15.51;1,110.40,170.59,382.34,15.51;1,218.04,192.43,167.03,15.51">IPAL at CLEF 2008: Mixed-Modality based Image Search, Novelty based Re-ranking and Extended Matching</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D1BFD0400E2C1FEE7179D1FB48DC5729</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Managment]: Languages-Query Languages Measurement, Performance, Experimentation Language model, information retrieval, multimodality fusion, content-based image retrieval, text based image search, clustering</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper introduces the IPAL participation at CLEF 2008 on the new TEL collection and on the ad-hoc photographic retrieval ImageClef. Following the changes in evaluation criterion this year in ImageClef, i.e. promoting diversity in the top ranked images, we have integrated the novelty measure in our similarity based system developed in ImageCLEF 2007. The novelty score is calculated between an image in the ranked list and the images ranked higher than it. The system is still an automatic and mixed-modality based image search, which is similar to the previous years. 10 runs are submitted this year in ImageClef. In the overall ranking, our group stands at the 3rd place in 25 participants. 4 runs are submitted for the TEL collection. In this working note, we will share our experience in participating these two tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This year IPAL group continues to participate in the task of ad-hoc photographic retrieval. The evaluation image database still uses the previous year's, which contains 20,000 images attached with some text description (e.g. title, short description, narrative description, location, date, etc) about the image. The obvious change of this year is the evaluation criterion. Rather than simply focusing on mean average precision, i.e. MAP, over all queries, this year is to promote the diversity at the top ranking images. It means that a good image search engine ensures that duplicate or near-duplicate documents retrieved in response to a query are hidden from the user and ideally the top results 1 of a ranked list will contain diverse items representing different sub-topics within the results. 39 queries which are parts of 60 queries used in the previous year are re-defined for this year. An additional tag, i.e. cluster tag, is added in the query. Here is a query example (query 2):</p><p>Evaluation is based on two measures: precision at 20 (p20) and instance recall at rank 20 (cr20), which calculates the percentage of different clusters represented in the top 20.</p><p>Although it is possible to learn a ranking function to maximize the p20 or cr20 metric of the retrieved system, a few annotated samples must be provided. This is suitable for an interactive search but we prefer to set up a fully automatic retrieval system. The baseline system is similar to our system in 2007. Both are content-based image retrieval systems (CBIR) with multiple visual features. The text based image retrieval system (TBIR) is using a language model approach <ref type="bibr" coords="2,502.46,368.73,10.57,9.96" target="#b6">[7]</ref> and their combination using cross-media pseudo-relevance feedback method <ref type="bibr" coords="2,430.33,380.73,10.57,9.96" target="#b5">[6,</ref><ref type="bibr" coords="2,445.09,380.73,7.05,9.96" target="#b4">5]</ref>. To improve the diversity, we introduce a novelty score for each image in the ranked list and combine it with it similarity score to generate the ranking score for ranking images. Novelty is calculated from the pair-wise distance between the images. To incorporate the hidden clustering information, we apply unsupervised clustering algorithm, affinity propagation based clustering, to get the cluster size, the representative image in each cluster and the cluster identity of each image. However, we do not use the cluster tag provided in the query in our current systems. For the textual part only, we experiment this year an extended matching that consists of a fusion of the matching inner product with probability links computed on Wikipedia source text.</p><p>In the next section, we introduce the details of our systems and the submitted runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Systems Details</head><p>We build various CBIR and TBIR systems using different indexing methods and similarity functions. Totally we submit 10 runs for ImageCLEF and 4 for TEL. In the following, the details are given.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">CBIR System</head><p>To enrich the visual content representation, 4 types of low-level visual feature are extracted from the local regions or global images. They are detailed in the following:</p><p>COR: Auto color correlogram with the depth 2 in the HSV space. It is extracted from the whole image and is represented by one 324-dimensional vector.</p><p>HSV: Histogram in HSV and gray-level space with 162-dimension for HSV plus 4-dimension for gray-level. An image is represented by a 166-dimensional vector.</p><p>GABOR: texture feature using Gabor filter in the uniformly segmented 5x5 grids at the 2-scale and 12-orientations. Thus, the mean and variance are calculated at each grid to generate 48-dimensional feature vector. We concatenate the vectors from 25 grids into one 1,200dimensional vector.</p><p>EDGE: 18-dimensional edge orientation histogram is calculated from an image.</p><p>Then we apply SVD to remove correlation among the feature components. Assuming the full rank is N , we empirically select the top N × 0.8 eigenvectors and index the image in the eigenspace. The cosine function is used to calculate similarity score. Thus, we have 4 CBIR systems based on each of visual features in the above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">TBIR System</head><p>For the LM-based TBIR used in ImageClef only, we first build a lexicon dictionary (7,866 words) from all text documents (including title, narrative, location) and then train a unigram language model only based on the attached text document for each image in the database. This is done using the CMU-Cambridge Statistical Language Modeling Toolkit <ref type="bibr" coords="3,356.31,251.25,10.54,9.96" target="#b1">[2]</ref> with the Witten-Bell smoothing. Thus, each image is indexed by the word probabilities in the lexicon. Given a query topic and any image in the database, the probability of query words generated by the corresponding image LM can be calculated. The image documents in the database are ranked by the probability from the highest to the lowest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Pseudo-Relevance Feedback</head><p>Learned from the ImageClef 2006 <ref type="bibr" coords="3,238.92,345.33,10.57,9.96" target="#b5">[6,</ref><ref type="bibr" coords="3,252.72,345.33,6.97,9.96" target="#b4">5]</ref>, the cross-modality pseudo-relevance feedback (PRF) can improve the system performance, i.e. the TBIR can be boosted by the top-N (here 10 documents are selected) documents from the CBIR as the feedback and vice versa. This year PRF is also adopted.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Novelty based Re-ranking</head><p>In our system, the novelty scores are used for re-ranking the images in the top-1000 generated by the traditional similarity based ranking. Two methods are used to calculate the novelty score for the image in the top-1000. Both derive a novel measure through calculating the pair-wise distance between the image and all images ranked higher than it. The pair-wise distance can be calculated from the low-level image feature (in the first approach) or from both the low-level feature and the cluster identity assigned by unsupervised clustering (in the second approach). Let I(i) be the i-th image in the top-1000 list as well as its corresponding feature vector, and r(i) be its ranking position in the list. Given I(i), we denote by R(i) the set of images whose ranking position is higher than r(i). Thus the novelty score novelty(i) of the image I(i), is defined as,</p><formula xml:id="formula_0" coords="3,225.36,547.05,287.68,10.69">novelty(i) = max j∈R(i) f (I(i), I(j))<label>(1)</label></formula><p>where f (x, y) is a distance function. Higher value the function has, more novelty I(i) is. In the LM-based indexing, KL-distance is used and the cosine distance is used for visual features.</p><p>Besides the low-level feature, we also incorporate the cluster identity of images in the novelty score. We apply affinity propagation based clustering in the top-1000 list <ref type="bibr" coords="3,411.24,600.93,10.00,9.96" target="#b3">[4]</ref>. Unlike the k-means clustering which generally needs to input the cluster number and the cluster is described by the samples mean in the cluster, this method <ref type="bibr" coords="3,274.08,624.81,10.57,9.96" target="#b3">[4]</ref> can automatically find the cluster number from the input pair-wise similarity matrix and the cluster is represented by the representative sample in the cluster rather the mean. In our case, the representative image can be selected for describing the cluster and has the higher novelty than other images in the same cluster. Then, a new novelty is derived by fusing the cluster based novelty with the low-level feature based.</p><p>When the novelty values are calculated, they are combined with the similarity scores to reranking the top-1000 images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Maximum Similarity Extended Matching</head><p>Both document collections we have worked on this year (ImageCLEF and TEL) are very small: only few sentences. For this reason we had the idea to use another source of information to enhance the matching between short query and short documents.</p><p>So this year, we continue to use Wikipedia information, but in a different way: we have modified the matching function to directly incorporate weighted links between words. So, neither document nor query are extended statically, but it is the matching function that dynamically (at querying time) choose the best matching between one word of the query and one word of the document.</p><p>We compute probability links between terms by computing the probability of a word w 1 to appear in a Wiki document, knowing that a word w 2 is in this document : P (w 1 |w 2 ). This forms a probability graph. This computation is done by counting all concurrencies of all terms in all wikipedia documents. The raw couple frequency is called "support" in text mining. By imposing a minimum support, we force the computed probability to be computed using a minimum of occurrences. This should enhance their quality: the biggest support, then the more significant the relation should be. But it also reduces the number of links in the graph and may miss some interesting ones.</p><p>In practice we have filtered Wikipedia using words from documents and queries test collection in order to fasten the concurrency computation, otherwise the number of possible concurrency couples is too large and the time to compute them is too long (days). For the TEL collection we limit the computation to the most frequent 300 million of possible relations, in order to feet into 6Mb of main memory of our server. Using only main memory speed up the computation. These probabilistic links are then used directly into the matching function in this way: for a given t, t * = argmax</p><formula xml:id="formula_1" coords="4,316.56,390.06,196.48,17.93">t ′ ∈D (p(t ′ |t))<label>(2)</label></formula><formula xml:id="formula_2" coords="4,182.52,421.38,330.52,21.53">RSV max(Q⊲D) (D, Q) = t∈Q k × p(t * |t) × w d (t * ) × w q (t)<label>(3)</label></formula><p>When computing the matching between document D and query Q (eq. ( <ref type="formula" coords="4,427.59,450.81,3.87,9.96" target="#formula_2">3</ref>)), for each term t of the query, we select the term t * of the document D (eq. ( <ref type="formula" coords="4,358.75,462.69,4.15,9.96" target="#formula_1">2</ref>)) that maximize the probabilistic link computed in wikipedia: p(t * |t). Of course, it is done only when the term t does not appear in the document D. If t is in document D, then obviously p(t|t) = 1. If not, we replace the missing t from D, by t * , and we use its weighting. This method, that we call "maximum similarity extended matching", is an extension of the classical inner product and enables us to retrieve document with a very small term intersection, even with no term intersection at all. This matching technic comes from a work of Crestani <ref type="bibr" coords="4,197.53,534.45,10.00,9.96" target="#b2">[3]</ref>. In this way, we can expand the matching process with links but still use classical document weighting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.1">Extended Matching in ImageCLEF</head><p>The IPAL CLEF Photo test collection is mainly composed of image annotations. So our extended matching technics should be well adapted to this collection. The proposed runs use the Divergence From Randomness (DFR) document weighting <ref type="bibr" coords="4,297.49,614.61,9.91,9.96" target="#b0">[1]</ref>. The unique constant of this weighting is kept at 1.0. Standard stemming and stop-word removal is applied. For query we only use the "title" field.</p><p>We have used our extended maximum matching using Wikipedia documents as a source for the term probability link. We use the WIKI file of January 2008 (enwiki-20080103-pages-articles.xml), which has about 14Gb of text.</p><p>All runs (pt = probabilistic term extension) use DFR weighting with constant k at 1.0, the extended matching uses also an arbitrary constant k set to 0.01 to combine the term weight with term link. Finally, we have tested different "support". It is in fact the minimum of couple frequency in Wikipedia that is necessary to keep the link in the similarity graph. We have tested 10, 100, and 1000, with correspond to the 3 proposed runs (IPALpt1, IPALpt2, IPALpt3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.2">Extended Matching in AD-HOC Task TEL</head><p>This collection is also composed of small documents. We apply the same technic described before. For all run (except IPAL04), we have used the following document field: oai_dc:dc, dc:title, dc:subject, dcterms:alternative, dc:description. For queries, only the "title" field is used. We have performed a standard stemming and stop-word removal. All runs use the Deviation From Randomness weighting (DFR), with constant left to 1.0. The minimum support (the minimum number of couple concurrencies) if fixed to 10 for all runs. The computation of the Wiki term dependency graph is based on the filtered version of wiki. We first remove all the stop-words and then do a standard stemming, the same applied to the document and queries. Finally, we filter wikipedia, keeping only stemmed terms that effectively appears in the collection and in the query. Unfortunately, this filtering is not enough to reduce significantly the size of Wiki, and hence to enable a full computation of the concurrencies. So because of these technical reasons (to long computation, not enough main memory when running the process), in these run, only a very small part of the wiki is effectively used the the runs about the first 2400 Wiki documents. This may be the explanation of the very little influence of this technic to the results (see below). Since these experiments, we managed to compute the full Wiki concurrency but not in time to be used in the run. We will evaluate later the impact of the size of the Wiki used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Description of Submitted Runs</head><p>A total of 14 runs has been submited: 10 runs are submitted for ImageClef, including the similarity based CBIR run, TBIR run, cross-modality run, and the novelty based runs and 4 runs for the TEL collection. To combine the ranking scores from different runs, the linear fusion method is utilized. The coefficients of each system are equally set. Now we will describe the condition of each type of run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>IPAL01V 4RUNS EQWEIGHT: a visual run by equally combining 4 CBIR system;</head><p>IPAL02T LM: a LM-based text run;</p><p>IPAL03TfV LM FB: a mixed-modality run using cross-media pseudo-relevance feedback from IPAL01V_4RUNS_EQWEIGHT (Top-5 documents in IPAL01V_4RUNS_EQWEIGHT are used to boost IPAL02T_LM);</p><p>IPAL04T LM Tnov: a text run with the novelty score to re-rank IPAL02T_LM;</p><p>IPAL05TfV LM FB Tnov: a mixed-modality run with novelty scores calculated from the text and visual features (Baseline is IPAL03TfV_LM_FB);</p><p>IPAL06T LM Tnov Cluster: a text run with novelty score calculated from text feature and cluster identity (Baseline is IPAL04T_LM_Tnov);</p><p>IPAL07TfV LM FB Tnov Cluster: a mixed-modality run with novelty scores calculated from the text and visual features and cluster identity (Baseline is IPAL05TfV_LM_FB_Tnov);</p><p>IPALpt1: the text based Deviation From Randomness with maximum similarity extended matching using a support of 10;</p><p>IPALpt2: The same as previous but with a support of 100;</p><p>IPALpt3: The same as IPALpt1 but with a support of 1000;</p><p>The next four runs concerns the Had hoc task for the TEL document collection.</p><p>IPAL01: a simple reference run with DFR and no extended matching;</p><p>IPAL02: the maximum similarity extended matching using wikipedia (small part see above). The k mixing constant is set to 0.001;</p><p>IPAL03: the same at previous, but with a stronger influence of the Wiki extension because the k constant is set to 0.01;</p><p>IPAL04: Because we think that the field dc:description is not a good source of information, and can produce noise, we rerun the previous run without this field;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>The official evaluation results of 10 runs for ImageClef are reported in table <ref type="table" coords="6,411.86,209.97,4.98,9.96" target="#tab_0">1</ref> for precision at top-20 and Table <ref type="table" coords="6,134.53,221.97,4.98,9.96">2</ref> for instance recall at top-20. In terms of AP@20, the best run is IPAL05TfV_LM_FB_Tnov.</p><p>Its AP is 0.4295. Similarly, the run is also best in terms of CR@20 with 0.4235. However, comparing with the corresponding baseline, IPAL03TfV_LM_FB, which has 0.4282 and 0.4217 respectively, the improvement is not obvious. When comparing IPAL02T_LM with IPAL04T_LM_Tnov, the performance is degraded due to the introduction of novelty score. From these results, we found that little benefit is obtained from the novelty score compared with the traditional similarity search. Similarly, the cluster identity of images discovered from unsupervised clustering has little help to improve the instance recall. It may be helpful when the cluster tag in the query is used. We will evaluate it in future. The use of DFR measure in all IPALpt is too low compared with language model, and the use of Wikipedia does not help. The respective MAP for the four runs on TEL collection are: 0.2624, 0.2623, 0.2618 and 0.2579. It shows a degradation of performances using Wikipedia probabilistic links. We thinks that the quality of these extracted link may not be hight enough to show any improvement. Finally, we summarize the top-10 runs in all submitted runs from 25 participants in Table <ref type="table" coords="6,505.22,377.37,3.90,9.96">3</ref>, of which 3 runs are from IPAL. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this paper we introduced our ad-hoc photographic retrieval system submitted to ImageClef 2008 and experiments using Wikipedia. None improvement is shown using probabilistic links from Wikipedia. On the image collection, we calculate the novelty score from pair-wise distances among the top-1000 ranked images and then integrate them with the similarity score in order to improve the diverse at the top ranked images. However, the improvement is not significant when comparing with traditional similarity based system and the cluster identity of images cannot give us benefit as we expected. This year, cluster tag in the query is not used. We would like to get some positive effect of unsupervised clustering on the performance when combining with the cluster tag.</p><p>Table <ref type="table" coords="7,136.44,247.17,3.90,9.96">2</ref>: Official evaluation results for 10 submitted runs (Instance recall at top-N, cr@) Table <ref type="table" coords="7,189.48,388.41,3.90,9.96">3</ref>: Top-10 runs in all submitted runs from 25 participants</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" coords="6,90.05,409.93,425.15,133.86"><head></head><label></label><figDesc></figDesc><graphic coords="6,90.05,409.93,425.15,133.86" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="7,90.05,110.09,424.83,122.54"><head></head><label></label><figDesc></figDesc><graphic coords="7,90.05,110.09,424.83,122.54" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,122.16,558.33,358.72,9.96"><head>Table 1 :</head><label>1</label><figDesc>Official evaluation results for 10 submitted runs (Precision at top-N, p@)</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,105.24,746.42,141.57,7.97"><p>http://www.imageclef.org/2008/photo</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,105.48,452.13,407.67,9.96;7,105.48,464.01,407.50,9.96;7,105.48,476.01,154.10,9.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,322.00,452.13,191.15,9.96;7,105.48,464.01,228.15,9.96">Probabilistic models of information retrieval based on measuring the divergence from randomness</title>
		<author>
			<persName coords=""><forename type="first">Gianni</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cornelis</forename><surname>Joost Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,342.96,464.35,170.02,9.18;7,105.48,476.35,18.34,9.18">ACM Transaction on Information Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="357" to="389" />
			<date type="published" when="2002-10">October 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.48,495.93,407.75,9.96;7,105.48,507.81,213.13,9.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,275.93,495.93,237.30,9.96;7,105.48,507.81,27.63,9.96">Statistical language modeling using the cmu-cambridge toolkit</title>
		<author>
			<persName coords=""><forename type="first">Philip</forename><surname>Clarkson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ronald</forename><surname>Rosenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,153.96,508.15,55.50,9.18">Eurospeech97</title>
		<imprint>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="2707" to="2710" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.48,527.85,407.46,9.96;7,105.48,539.73,174.86,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,177.98,527.85,280.37,9.96">Exploiting the similarity of non-matching terms at retrievaltime</title>
		<author>
			<persName coords=""><forename type="first">Fabio</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,467.88,528.19,45.06,9.18;7,105.48,540.07,92.95,9.18">Journal of Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="47" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.48,559.65,407.51,9.96;7,105.48,571.65,162.39,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,282.16,559.65,226.64,9.96">Clustering by passing messages between data points</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Brendan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Delbert</forename><surname>Frey</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Dueck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,105.48,571.99,30.46,9.18">Science</title>
		<imprint>
			<biblScope unit="volume">315</biblScope>
			<biblScope unit="page" from="972" to="976" />
			<date type="published" when="2007-02">February 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.48,591.57,407.54,9.96;7,105.48,603.45,407.43,9.96;7,105.48,615.45,370.21,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,105.48,603.45,262.71,9.96">Ipal at imageclef 2007 mixing features, models and knowledge</title>
		<author>
			<persName coords=""><forename type="first">Sheng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean-Pierre</forename><surname>Chevallet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thi</forename><surname>Hoang Diem Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Trong Ton</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joo Hwee</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,387.84,603.79,125.07,9.18;7,105.48,615.79,172.16,9.18">Working Notes for the CLEF 2007 Cross Language Evaluation Forum</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09-21">19-21 September 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.48,635.37,407.58,9.96;7,105.48,647.37,407.41,9.96;7,105.48,659.25,297.37,9.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,441.60,635.37,71.47,9.96;7,105.48,647.37,303.95,9.96">Ipal inter-media pseudo-relevance feedback approach to imageclef 2006 photo retrieval</title>
		<author>
			<persName coords=""><forename type="first">Nicolas</forename><surname>Maillot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean-Pierre</forename><surname>Chevallet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vlad</forename><surname>Valea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joo Hwee</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,431.40,647.71,81.49,9.18;7,105.48,659.59,111.58,9.18">Working Notes for the CLEF 2006 Workshop</title>
		<meeting><address><addrLine>Alicante, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-09-22">20-22 September. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.48,679.17,407.56,9.96;7,105.48,691.51,407.58,9.18;7,105.48,703.17,407.55,9.96;7,105.48,715.05,25.92,9.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,259.36,679.17,236.97,9.96">A language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Jay</forename><forename type="middle">M</forename><surname>Ponte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,105.48,691.51,407.58,9.18;7,105.48,703.51,180.02,9.18">SIGIR &apos;98: Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="275" to="281" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
