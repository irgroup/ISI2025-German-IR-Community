<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,178.32,74.29,250.19,12.64;1,114.00,90.37,378.78,12.64">MIRACLE-FI at ImageCLEFphoto 2008: Experiences in merging text-based and content-based retrievals</title>
				<funder ref="#_cCyw8eX">
					<orgName type="full">Spanish R+D National Plan</orgName>
				</funder>
				<funder ref="#_pRG2pmD">
					<orgName type="full">Madrid R+D Regional Plan</orgName>
				</funder>
				<funder ref="#_kyHEPqQ">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,182.64,116.80,49.95,8.96"><forename type="first">R</forename><surname>Granados</surname></persName>
							<email>rgranados@fi.upm.es</email>
							<affiliation key="aff0">
								<orgName type="institution">Universidad Politécnica de Madrid</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,240.84,116.80,49.93,8.96"><forename type="first">X</forename><surname>Benavent</surname></persName>
							<email>xaro.benavent@uv.es</email>
							<affiliation key="aff1">
								<orgName type="institution">Universidad de Valencia</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,299.16,116.80,73.14,8.96"><forename type="first">A</forename><surname>García-Serrano</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Universidad Nacional de Educación a Distancia</orgName>
								<orgName type="institution" key="instit2">UNED</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,380.64,116.80,40.33,8.96"><forename type="first">J</forename><forename type="middle">M</forename><surname>Goñi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universidad Politécnica de Madrid</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,178.32,74.29,250.19,12.64;1,114.00,90.37,378.78,12.64">MIRACLE-FI at ImageCLEFphoto 2008: Experiences in merging text-based and content-based retrievals</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">44706A4F2A5F1C3644A39E28C188BB77</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.2 Information Storage</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital libraries. H.2 [Database Management]: H.2.5 Heterogeneous Databases</term>
					<term>E.2 [Data Storage Representations] Information Retrieval, Content-based image Retrieval, Merged result lists, Indexing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the participation of the MIRACLE consortium at the ImageCLEF Photographic Retrieval task of ImageCLEF 2008. In this is new participation of the group, our first purpose is to evaluate our own tools for text-based retrieval and for content-based retrieval using different similarity metrics and the aggregation OWA operator to fuse the three topic images.</p><p>From the MIRACLE last year experience, we implemented a new merging module combining the text-based and the content-based information in three different ways: FILTER-N, ENRICH and TEXT-FILTER. The former approaches try to improve the text-based baseline results using the content-based results lists. The last one was used to select the relevant images to the content-based module. No clustering strategies were analyzed.</p><p>Finally, 41 runs were submitted: 1 for the text-based baseline, 10 content-based runs, and 30 mixed experiments merging text and content-based results. Results in general can be considered nearly acceptable comparing with the best results of other groups. Obtained results from textbased retrieval are better than content-based. Merging both textual and visual retrieval we improve the text-based baseline when applying the ENRICH merging algorithm although visual results are lower than textual ones.</p><p>From these results we were going to try to improve merged results by clustering methods applied to this image collection.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>MIRACLE is a research consortium formed by research groups of three different universities in Madrid, Universidad Politécnica (UPM), Universidad Autónoma and Universidad Carlos III, along with DAEDALUS, a small/medium size enterprise (SME) founded in 1998 as a spin-off of UPM. This paper describes our participation (Mir-FI, stands for Miracle subgroup at Facultad de Informática) at the ImageCLEF Photographic Retrieval task of ImageCLEF 2008. The goal of this task was fully described last year in <ref type="bibr" coords="1,81.12,710.56,10.69,8.96" target="#b5">[6]</ref>. The reference database is the IAPR TC-12 Benchmark <ref type="bibr" coords="1,318.84,710.56,10.89,8.96" target="#b6">[7,</ref><ref type="bibr" coords="1,332.28,710.56,7.26,8.96">8]</ref>. This year our experiments were due to evaluate our own tools for text-based and content-based retrieval. The text-based technique is based in the classical Vector Space Model (VSM) with TF-IDF weights and the tool for image-based retrieval includes different image color and texture descriptors <ref type="bibr" coords="2,378.12,73.12,10.89,8.96" target="#b7">[9,</ref><ref type="bibr" coords="2,391.68,73.12,11.86,8.96" target="#b8">10]</ref>. In addition, we have applied some merging algorithms to fuse together both textual and visual results in order to evaluate if this improve our baseline. All the 41 experiments and results are explained in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Description</head><p>We have a tool implementing different techniques for image-based retrieval, based on several components that allow different configurations in order to easily execute sequentially text-based, content-based and the merge of the results. Fig. <ref type="figure" coords="2,135.00,184.36,4.98,8.96">1</ref> presents an overview of the system architecture.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 1. System overview</head><p>Our main goal was to evaluate both textual and visual retrieval baselines and the experimentation with different combinations of them. Thus, the system is built up from three main different components: Text-based retrieval module, Image-content based retrieval module and the Merging module that is in charge of combine the results lists from textual and visual retrieval using different approaches. A more detailed explanation is included in section 2.1 and 2.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Textual Retrieval</head><p>MIRACLE-FI textual retrieval is based on the VSM approach using weighted vectors based on the TF-IDF weight. Applying this approach, a representing vector will be calculated for each one of the image annotations provided by the IAPR TC-12. The textual retrieval task architecture can be seen in the Figure <ref type="figure" coords="2,450.84,563.68,3.76,8.96">1</ref>. Each one of the components takes care of a specific task. These tasks will be sequentially executed:</p><p>-Text Extractor. Is in charge of extracting the text from the different files. It uses the JDOM Java API to identify the content of each of the tags of the annotations files. This API has problems with some special characters (accents), so it is needed to carry out a pre-process of the text to eliminate them.</p><p>-Preprocess. This component process the text in two ways: o Special characters deletion: characters with no statistical meaning, like punctuation marks. o Stopword detection: exclusion of semantic empty words.</p><p>-Annotations/Topics Tags Selection. With these components, it is possible to select the desired XML tags of the annotations/topics files, which will compound the associated text describing each image/query. In the annotations files there are eight different tags (DOCNO, TITLE, DESCRIPTION, NOTES, LOCATION, DATE, IMAGE and THUMBNAIL) and in the topics ones there are seven (NUM, TITLE, CLUSTER, NARR, and 3 IMGAGE). In all our experiments, the selected tags from the annotations files had been four: TITLE, DESCRIPTION, NOTES and LOCATION. In the case of the topics, the selected tags were two: TITLE and NARR. -MirFi-VSM Index. This module indexes the selected text associated with each image. All the weights values of each vector will be normalized using the Euclidean distance between the elements of the vector.</p><p>-MirFi-VSM Search. For the query text is also calculated his weights vector. To measure the proximity between two vectors we use the cosine. Then, all the images will be ranked in descending order with respect to this value. This ranked list is the first results list.</p><p>These methods are executed sequentially and obtain the results list for the textual run submitted. The goal of our experiments is to evaluate how good the results are using just textual retrieval, and to see if the merge with any of the visual ones can improve it in any way.</p><p>It takes less than 20 minutes to extract the text from the provided annotations files, to delete the special characters, and to exclude stopwords. To build and save the vector space with all the weights vectors corresponding to each annotation file, it takes almost 7 hours of processing in this first version.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Visual Retrieval</head><p>This campaign MIRACLE team joined the VISION-Team at the Computer Science Department of the University of Valencia who has its own CBIR system mainly used for relevance feedback algorithms evaluation <ref type="bibr" coords="3,70.92,298.84,11.46,8.96" target="#b7">[9,</ref><ref type="bibr" coords="3,82.37,298.84,11.46,8.96" target="#b8">10]</ref>. The low-level features of the original CBIR system have been adapted to be used at the ImageCLEFphoto for image retrieval and for merging image and text information retrieval.</p><p>We use different low-level features describing color and texture to build a vector of features with 68 components:</p><p>• Color information: a feature vector of 30 components represents the color information. Each of these components represents a bin on a HS (hue-saturation) histogram of size 10 x 3. For this database the last 10 histogram (the highest saturated) where eliminated so that their values where almost zero. Therefore, a feature vector of 20 components has been used for extracting color information. • Texture information: six feature textures have been computed for this repository respectively. The first three ones use code from the implementation done by Smith and Burn in Meastex <ref type="bibr" coords="3,471.24,415.84,15.65,8.96" target="#b12">[13]</ref>; the rest have been implemented by the authors. The total of texture features builds a vector of 48 components. o Gabor Convolution Energies <ref type="bibr" coords="3,260.28,438.76,10.78,8.96" target="#b4">[5]</ref>.</p><p>o Gray Level Coocurrence Matrix also known as Spatial Gray Level Dependence <ref type="bibr" coords="3,462.96,450.28,10.69,8.96" target="#b3">[4]</ref>. o Gaussian Random Markov Fields <ref type="bibr" coords="3,279.60,461.80,10.69,8.96" target="#b1">[2]</ref>. o The granulometric distribution function, first proposed by Dougherty <ref type="bibr" coords="3,428.52,473.32,10.69,8.96" target="#b2">[3]</ref>. We have used here not the raw distribution but the coefficients that result of fitting its plot with a B-spline basis. o Finally, the Spatial Size Distribution <ref type="bibr" coords="3,292.80,496.36,10.69,8.96" target="#b0">[1]</ref>. We have used two different versions of it by using as the structuring elements for the morphological operation that get size both a horizontal and a vertical segment.</p><p>The second step is to calculate the similarity distance between the feature vectors from each image on the database to the three topic images. We have used two distance metrics on the experiments: the Euclidean and the Mahalanobis distance. Therefore, three similarity distances from each image on the repository to the three query images are calculated so that only a content-based image list is needed.</p><p>Mathematical aggregation operators transform a finite number of inputs into a single output and play an important role in image retrieval. We decided to use the so-called OWA operators to aggregate the three lowlevel feature vectors of the topic images. These operators were introduced in <ref type="bibr" coords="3,379.44,617.32,15.43,8.96" target="#b15">[16]</ref>.</p><p>With the OWA operator no weight is associated with any particular input; instead, the relative magnitude of the input decides which weight corresponds to each input. In our application, the inputs are similarity distances to each of the three topic images and this property is very interesting because we do not know, a priori, which image of the three will provide us with the best information.</p><p>The goal of the content-based image system is to evaluate the three different aspects used in content-based image retrieval system: the low-level features, the OWA aggregation methods, and the different distance metrics to measure the similarity. About the time of execution, the most demanding task is feature extraction that is done just once and then the values are stored on the database. Therefore, it takes less than 5 minutes the calculation of the content-based list for all the questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Merging</head><p>Textual and image results lists will be merged in two different ways, using the textual results lists (T) as principal list and the image ones (I) as a support list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FILTER-N.</head><p>This way of merging the image and textual results lists consists on checking which results in the T list are also included in the N first results of the I list. The value of N indicates the number of results taken into account from the I list when narrowing down the T list. The resulting merged list will have a maximum of 1000 results for each query to follow the ImageCLEFphoto indications.</p><p>This merging strategy tries to eliminate from the main list those results that are not considered sufficiently relevant according to the support list. We consider that a result is important in the support list if it is ranked in the N firsts positions. The value of N can be modified to demand a higher degree of relevancy in the support list.</p><p>ENRICH. This kind of merging also uses two results lists, the main list and the support list. If a concrete result appears in both lists for the same query, the relevance of this result in the merged list will be increased in the following way:</p><p>( ) Relevance values will be then normalized from 0 to 1.</p><p>Every results appearing in the support list but not in the main one (for each query), will be added at the end of the results for each query. In this case, relevance values will be normalized according with the lower value in this moment. In the submitted experiments this addition of the results from the support list not appearing in the main list seems not working correctly. Algorithm has already been modified to add these results in the proper way.</p><p>The merged lists resulting will be limited to the same number of results per query (1000), to follow the task indications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TEXT-FILTER.</head><p>In this kind of experiments the text-based module is applied to the complete database and those images that have a relevance value above zero are passed to the content-based image module. In this experiment, the content-based image module only works with the images filter by the text module. Then, the content-based image module calculates the similarity of each feature vector of the text-filter images to each of the query images. Moreover, this three relevance values are merged with the different OWA aggregation operators as mentioned in section 2.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head><p>Finally it was sent one text-based run, 10 content-based runs and 30 mixed runs using a combination of both. The name of the runs identifiers indicate the different configurations applied. All the names of the runs begin with EN-EN-AUTO because the used language is English and all of them are fully automatic, avoiding any manual intervention.</p><p>The text-based run identifier, MirFIbaseline is based on the vector space model using the TF-IDF weight.</p><p>There are 10 content-based experiments, built combining different distances for calculating similarity from each feature vector to the topic, and different aggregation OWA operators for combining the three topic feature vectors for each topic image. The two similarity distances are Euclidean and Mahalanobis, and five aggregation OWA operators for combining the three topic images are used (max, min, med, o3, o7). The name of the 10 content-based runs indicates which distance and aggregation operator has been used in each case. The name will be MirFIdistmerge where dist = {euc, maha} and merge = {max, med, min, o3, o7}.</p><p>The combination of the results obtained from both the textual and visual retrieval will form a set of 30 mixed runs. FILTER-10000 and ENRICH have been used to generate the first 20 runs. The last 10 runs have been obtained by the TEXT-FILTER method.</p><p>The following table shows all the submitted runs identifiers built for this edition of ImageCLEFphoto. After the evaluation by the task organizers, obtained results for the different experiments are presented in the following tables. Each table shows the run identifier, the mean average precision (MAP), the precision at 5, 10, 20 and 30 first results, and the number of relevant images retrieved (out of 2401 relevant images).</p><p>Obtained results with the textual-based retrieval module can be considered acceptable, having into account that no linguistic processes were applied. The MAP (0.2253) is higher than the average MAP taken from the best 4 runs for each participating group (0.2187).</p><p>For the content-based image module was testing we can observe that the Mahalanobis distance outperforms the Euclidean distance, and the best aggregation method in both metrics is the minimum (AND), followed by the orness(W)_0.3 that is a smoothed AND. Our best result for this group of experiments is the combination of the Mahalanobis metrics with orness(W)_0.3 with a MAP(0.0213) and a P20(0.0679). Our best result is considerably lower than the best result for this group. The FILTER-10000 merge algorithm improves the baseline in the precision at low values (5, 10) but never improves the MAP value nor the number of relevant images retrieved. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions and Future Work</head><p>In this participation in the task, results in general can be considered by us acceptable comparing with the best results of all the groups.</p><p>The MAP value obtained for the text-based baseline experiments was 0.2253, higher than the average MAP (0.2187) calculated from the best 4 runs from each participating group.</p><p>For the content-based image retrieval, the results have not been very successful. Our results are lower than the best top ten. However, our challenge this year was to test their different parameters such as the distance metrics and the aggregation methods. The most interesting conclusion in that the Mahalanobis distance works better than the Euclidean one, and the best aggregation method is the AND operator. For following editions more low-level features based on local color descriptors and shape descriptors will be included.</p><p>Merged results show that the ENRICH algorithm improves very lightly the baseline. This is important taken into account the poor results obtained from the visual retrieval. So if we achieve to improve these content-based results, may be better merged results using this algorithm will be obtained. FILTER-10000 algorithm improves the textual baseline results in terms of precision at low values. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,127.92,96.64,334.56,472.32"><head>Table 3 .</head><label>3</label><figDesc>Submitted experiments.</figDesc><table coords="5,127.92,121.41,334.56,447.54"><row><cell>Run Identifier</cell><cell>Textual</cell><cell cols="2">Visual Retrieval</cell><cell>Merge</cell></row><row><cell></cell><cell>Retrieval</cell><cell cols="3">Distance Merge topics</cell></row><row><cell>TXT-MirFIbaseline</cell><cell>SVM</cell><cell>--</cell><cell>--</cell><cell>--</cell></row><row><cell>IMG-MirFIeucmax</cell><cell>--</cell><cell>euc</cell><cell>max</cell><cell>--</cell></row><row><cell>IMG-MirFIeucmed</cell><cell>--</cell><cell>euc</cell><cell>med</cell><cell>--</cell></row><row><cell>IMG-MirFIeucmin</cell><cell>--</cell><cell>euc</cell><cell>min</cell><cell>--</cell></row><row><cell>IMG-MirFIeuc03</cell><cell>--</cell><cell>euc</cell><cell>o3</cell><cell>--</cell></row><row><cell>IMG-MirFIeuc07</cell><cell>--</cell><cell>euc</cell><cell>o7</cell><cell>--</cell></row><row><cell>IMG-MirFImahamax</cell><cell>--</cell><cell>maha</cell><cell>max</cell><cell>--</cell></row><row><cell>IMG-MirFImahamed</cell><cell>--</cell><cell>maha</cell><cell>med</cell><cell>--</cell></row><row><cell>IMG-MirFImahamin</cell><cell>--</cell><cell>maha</cell><cell>min</cell><cell>--</cell></row><row><cell>IMG-MirFImahao3</cell><cell>--</cell><cell>maha</cell><cell>o3</cell><cell>--</cell></row><row><cell>IMG-MirFImahao7</cell><cell>--</cell><cell>maha</cell><cell>o7</cell><cell>--</cell></row><row><cell>TXTIMG-MirFIcriba10000eucmax</cell><cell>SVM</cell><cell>euc</cell><cell>max</cell><cell>FILTER-10000</cell></row><row><cell>TXTIMG-MirFIcriba10000eucmed</cell><cell>SVM</cell><cell>euc</cell><cell>med</cell><cell>FILTER-10000</cell></row><row><cell>TXTIMG-MirFIcriba10000eucmin</cell><cell>SVM</cell><cell>euc</cell><cell>min</cell><cell>FILTER-10000</cell></row><row><cell>TXTIMG-MirFIcriba10000euco3</cell><cell>SVM</cell><cell>euc</cell><cell>o3</cell><cell>FILTER-10000</cell></row><row><cell>TXTIMG-MirFIcriba10000euco7</cell><cell>SVM</cell><cell>euc</cell><cell>o7</cell><cell>FILTER-10000</cell></row><row><cell>TXTIMG-MirFIcriba10000mahamax</cell><cell>SVM</cell><cell>maha</cell><cell>max</cell><cell>FILTER-10000</cell></row><row><cell>TXTIMG-MirFIcriba10000mahamed</cell><cell>SVM</cell><cell>maha</cell><cell>med</cell><cell>FILTER-10000</cell></row><row><cell>TXTIMG-MirFIcriba10000mahamin</cell><cell>SVM</cell><cell>maha</cell><cell>min</cell><cell>FILTER-10000</cell></row><row><cell>TXTIMG-MirFIcriba10000mahao3</cell><cell>SVM</cell><cell>maha</cell><cell>o3</cell><cell>FILTER-10000</cell></row><row><cell>TXTIMG-MirFIcriba10000mahao7</cell><cell>SVM</cell><cell>maha</cell><cell>o7</cell><cell>FILTER-10000</cell></row><row><cell>TXTIMG-MirFImerge06eucmax</cell><cell>SVM</cell><cell>euc</cell><cell>max</cell><cell>ENRICH</cell></row><row><cell>TXTIMG-MirFImerge06eucmed</cell><cell>SVM</cell><cell>euc</cell><cell>med</cell><cell>ENRICH</cell></row><row><cell>TXTIMG-MirFImerge06eucmin</cell><cell>SVM</cell><cell>euc</cell><cell>min</cell><cell>ENRICH</cell></row><row><cell>TXTIMG-MirFImerge06euco3</cell><cell>SVM</cell><cell>euc</cell><cell>o3</cell><cell>ENRICH</cell></row><row><cell>TXTIMG-MirFImerge06euco7</cell><cell>SVM</cell><cell>euc</cell><cell>o7</cell><cell>ENRICH</cell></row><row><cell>TXTIMG-MirFImerge06mahamax</cell><cell>SVM</cell><cell>maha</cell><cell>max</cell><cell>ENRICH</cell></row><row><cell>TXTIMG-MirFImerge06mahamed</cell><cell>SVM</cell><cell>maha</cell><cell>med</cell><cell>ENRICH</cell></row><row><cell>TXTIMG-MirFImerge06mahamin</cell><cell>SVM</cell><cell>maha</cell><cell>min</cell><cell>ENRICH</cell></row><row><cell>TXTIMG-MirFImerge06mahao3</cell><cell>SVM</cell><cell>maha</cell><cell>o3</cell><cell>ENRICH</cell></row><row><cell>TXTIMG-MirFImerge06mahao7</cell><cell>SVM</cell><cell>maha</cell><cell>o7</cell><cell>ENRICH</cell></row><row><cell>TXTIMG-MirFIeucmax</cell><cell>SVM</cell><cell>euc</cell><cell>max</cell><cell>TEXT-FILTER</cell></row><row><cell>TXTIMG-MirFIeucmed</cell><cell>SVM</cell><cell>euc</cell><cell>med</cell><cell>TEXT-FILTER</cell></row><row><cell>TXTIMG-MirFIeucmin</cell><cell>SVM</cell><cell>euc</cell><cell>min</cell><cell>TEXT-FILTER</cell></row><row><cell>TXTIMG-MirFIeuco3</cell><cell>SVM</cell><cell>euc</cell><cell>o3</cell><cell>TEXT-FILTER</cell></row><row><cell>TXTIMG-MirFIeuco7</cell><cell>SVM</cell><cell>euc</cell><cell>o7</cell><cell>TEXT-FILTER</cell></row><row><cell>TXTIMG-MirFImahamax</cell><cell>SVM</cell><cell>maha</cell><cell>max</cell><cell>TEXT-FILTER</cell></row><row><cell>TXTIMG-MirFImahamed</cell><cell>SVM</cell><cell>maha</cell><cell>med</cell><cell>TEXT-FILTER</cell></row><row><cell>TXTIMG-MirFImahamin</cell><cell>SVM</cell><cell>maha</cell><cell>min</cell><cell>TEXT-FILTER</cell></row><row><cell>TXTIMG-MirFImahao3</cell><cell>SVM</cell><cell>maha</cell><cell>o3</cell><cell>TEXT-FILTER</cell></row><row><cell>TXTIMG-MirFImahao7</cell><cell>SVM</cell><cell>maha</cell><cell>o7</cell><cell>TEXT-FILTER</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,109.68,73.12,375.95,191.52"><head>Table 4 .</head><label>4</label><figDesc>Results for text-based and content-based experiments.</figDesc><table coords="6,109.68,102.09,375.95,162.54"><row><cell>Run Identifier</cell><cell>P5</cell><cell>P10</cell><cell>P20</cell><cell>P30</cell><cell cols="2">MAP RelRet</cell></row><row><cell>EN-EN-AUTO-TXT-MirFIbaseline</cell><cell cols="2">0.3179 0.2923</cell><cell>0.2846</cell><cell>0.2701</cell><cell>0.2253</cell><cell>1783</cell></row><row><cell>EN-EN-AUTO-IMG-MirFIeucmax</cell><cell cols="2">0.0256 0.0128</cell><cell>0.0103</cell><cell>0.0128</cell><cell>0.0042</cell><cell>274</cell></row><row><cell>EN-EN-AUTO-IMG-MirFIeucmed</cell><cell cols="2">0.0667 0.0487</cell><cell>0.0282</cell><cell>0.0214</cell><cell>0.0073</cell><cell>358</cell></row><row><cell>EN-EN-AUTO-IMG-MirFIeucmin</cell><cell cols="2">0.1179 0.0667</cell><cell>0.0487</cell><cell>0.0376</cell><cell>0.0137</cell><cell>345</cell></row><row><cell>EN-EN-AUTO-IMG-MirFIeuco3</cell><cell cols="2">0.0923 0.0615</cell><cell>0.0359</cell><cell>0.0299</cell><cell>0.0110</cell><cell>366</cell></row><row><cell>EN-EN-AUTO-IMG-MirFIeuco7</cell><cell cols="2">0.0154 0.0077</cell><cell>0.0077</cell><cell>0.0077</cell><cell>0.0033</cell><cell>328</cell></row><row><cell>EN-EN-AUTO-IMG-MirFImahamax</cell><cell cols="2">0.0410 0.0256</cell><cell>0.0244</cell><cell>0.0205</cell><cell>0.0050</cell><cell>296</cell></row><row><cell>EN-EN-AUTO-IMG-MirFImahamed</cell><cell cols="2">0.0359 0.0333</cell><cell>0.0308</cell><cell>0.0291</cell><cell>0.0067</cell><cell>392</cell></row><row><cell>EN-EN-AUTO-IMG-MirFImahamin</cell><cell cols="2">0.1744 0.1026</cell><cell>0.0679</cell><cell>0.0556</cell><cell>0.0213</cell><cell>371</cell></row><row><cell>EN-EN-AUTO-IMG-MirFImahao3</cell><cell cols="2">0.0615 0.0462</cell><cell>0.0385</cell><cell>0.0350</cell><cell>0.0105</cell><cell>385</cell></row><row><cell>EN-EN-AUTO-IMG-MirFImahao7</cell><cell cols="2">0.0359 0.0256</cell><cell>0.0269</cell><cell>0.0222</cell><cell>0.0057</cell><cell>350</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,89.04,291.88,415.55,194.28"><head>Table 5 .</head><label>5</label><figDesc>Results for the FILTER-10000 merge method experiments.</figDesc><table coords="6,89.04,320.85,415.55,165.30"><row><cell>Run Identifier</cell><cell>P5</cell><cell>P10</cell><cell>P20</cell><cell>P30</cell><cell>MAP RelRet</cell></row><row><cell>EN-EN-AUTO-TXT-MirFIbaseline</cell><cell cols="5">0.3179 0.2923 0.2846 0.2701 0.2253 1783</cell></row><row><cell>EN-EN-AUTO-TXTIMG-MirFIcriba10000eucmax</cell><cell cols="5">0.3385 0.3077 0.2821 0.2573 0.1674 1216</cell></row><row><cell></cell><cell cols="5">0.3282 0.3179 0.2936 0.2692 0.1764 1277</cell></row><row><cell></cell><cell cols="5">0.3641 0.3231 0.3154 0.2803 0.1887 1309</cell></row><row><cell>EN-EN-AUTO-TXTIMG-MirFIcriba10000euco3</cell><cell cols="5">0.3282 0.3154 0.2936 0.2735 0.1820 1301</cell></row><row><cell>EN-EN-AUTO-TXTIMG-MirFIcriba10000euco7</cell><cell cols="5">0.3231 0.3077 0.2846 0.2590 0.1698 1252</cell></row><row><cell>EN-EN-AUTO-TXTIMG-MirFIcriba10000mahamax</cell><cell cols="5">0.3385 0.3333 0.2962 0.2735 0.1846 1306</cell></row><row><cell>EN-EN-AUTO-TXTIMG-MirFIcriba10000mahamed</cell><cell cols="5">0.3436 0.3359 0.3038 0.2769 0.1875 1316</cell></row><row><cell>EN-EN-AUTO-TXTIMG-MirFIcriba10000mahamin</cell><cell cols="5">0.3487 0.3231 0.3179 0.2769 0.1936 1312</cell></row><row><cell></cell><cell cols="5">0.3538 0.3231 0.3115 0.2778 0.1890 1307</cell></row><row><cell></cell><cell cols="5">0.3231 0.3231 0.2962 0.2769 0.1814 1320</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,70.92,536.56,453.49,201.80"><head>Table 6 .</head><label>6</label><figDesc>Results for the ENRICH merge method experiments. improves the baseline experiment in the MAP value and in the number of relevant images retrieved. Best MAP value (0.2401) is achieved merging the textual results with the visuals obtained using the Mahalanobis distance and the AND operator. This value is quite bigger than the average MAP taken from the best 4 runs from each participating group (0.2187).</figDesc><table coords="6,70.92,565.53,434.03,161.31"><row><cell>Run Identifier</cell><cell>P5</cell><cell>P10</cell><cell>P20</cell><cell>P30</cell><cell>MAP</cell><cell>RelRet</cell></row><row><cell>EN-EN-AUTO-TXTIMG-MirFImerge06eucmax</cell><cell cols="5">0.3128 0.2949 0.2808 0.2701 0.2264</cell><cell>1785</cell></row><row><cell>EN-EN-AUTO-TXTIMG-MirFImerge06eucmed</cell><cell cols="5">0.3231 0.3026 0.2897 0.2744 0.2271</cell><cell>1790</cell></row><row><cell>EN-EN-AUTO-TXTIMG-MirFImerge06eucmin</cell><cell cols="5">0.3538 0.3231 0.2987 0.2855 0.2343</cell><cell>1789</cell></row><row><cell>EN-EN-AUTO-TXTIMG-MirFImerge06euco3</cell><cell cols="5">0.3282 0.3128 0.2936 0.2778 0.2291</cell><cell>1790</cell></row><row><cell>EN-EN-AUTO-TXTIMG-MirFImerge06euco7</cell><cell cols="5">0.3077 0.2923 0.2821 0.2684 0.2252</cell><cell>1787</cell></row><row><cell>EN-EN-AUTO-TXTIMG-MirFImerge06mahamax</cell><cell cols="5">0.3179 0.2949 0.2833 0.2701 0.2246</cell><cell>1785</cell></row><row><cell>EN-EN-AUTO-TXTIMG-MirFImerge06mahamed</cell><cell cols="5">0.3128 0.2949 0.2872 0.2735 0.2268</cell><cell>1787</cell></row><row><cell>EN-EN-AUTO-TXTIMG-MirFImerge06mahamin</cell><cell cols="5">0.3744 0.3436 0.3090 0.2915 0.2401</cell><cell>1789</cell></row><row><cell>EN-EN-AUTO-TXTIMG-MirFImerge06mahao3</cell><cell cols="5">0.3026 0.3000 0.2923 0.2769 0.2266</cell><cell>1791</cell></row><row><cell>EN-EN-AUTO-TXTIMG-MirFImerge06mahao7</cell><cell cols="5">0.3231 0.3000 0.2885 0.2718 0.2266</cell><cell>1785</cell></row><row><cell>ENRICH merge method</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="7,70.92,107.56,453.47,211.16"><head>Table 7 .</head><label>7</label><figDesc>Results for the TEXT-FILTER merge method experiments.Applying this merge strategy, obtained results outperform the content-based ones in terms of both precision and MAP. Again, the best results correspond to the experiments which use the Mahalanobis distance and the AND operator.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work has been partially supported by the <rs type="funder">Spanish R+D National Plan</rs>, by means of the project <rs type="projectName">BRAVO (Multilingual and Multimodal Answers Advanced Search -Information Retrieval</rs>), <rs type="grantNumber">TIN2007-67407-C03-03</rs>; by the <rs type="funder">Madrid R+D Regional Plan</rs>, by means of the project <rs type="projectName">MAVIR (Enhancing the Access and the Visibility of Networked Multilingual Information for the Community of Madrid</rs>), <rs type="grantNumber">S-0505/TIC/000267</rs> (<rs type="grantNumber">2006-09</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_cCyw8eX">
					<idno type="grant-number">TIN2007-67407-C03-03</idno>
					<orgName type="project" subtype="full">BRAVO (Multilingual and Multimodal Answers Advanced Search -Information Retrieval</orgName>
				</org>
				<org type="funded-project" xml:id="_pRG2pmD">
					<idno type="grant-number">S-0505/TIC/000267</idno>
					<orgName type="project" subtype="full">MAVIR (Enhancing the Access and the Visibility of Networked Multilingual Information for the Community of Madrid</orgName>
				</org>
				<org type="funding" xml:id="_kyHEPqQ">
					<idno type="grant-number">2006-09</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,106.20,696.16,418.40,8.96;7,106.20,707.68,399.45,8.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,205.68,696.16,289.57,8.96">Spatial Size Distributions. Applications to Shape and Texture Analysis</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Ayala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Domingo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,502.92,696.16,21.68,8.96;7,106.20,707.68,234.59,8.96">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1430" to="1442" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,106.20,725.20,418.28,8.96;7,106.20,736.72,358.05,8.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,223.20,725.20,271.89,8.96">Classification of Textures using Gaussian Markov Random Fields</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Chellapa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chatterjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,502.80,725.20,21.68,8.96;7,106.20,736.72,227.70,8.96">IEEE Transactions on Acoustics Speech and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="959" to="963" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,106.20,73.12,418.33,8.96;8,106.20,84.64,211.53,8.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,225.72,73.12,259.92,8.96">Gray-scale morphological granulometric texture classification</title>
		<author>
			<persName coords=""><forename type="first">Y;</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">R</forename><surname>Dougherty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,495.12,73.12,29.41,8.96;8,106.20,84.64,48.78,8.96">Optical Engineering</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2713" to="2722" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,106.20,102.04,418.26,8.96;8,106.20,113.56,418.27,8.96;8,106.20,125.08,17.61,8.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,311.52,102.04,212.94,8.96;8,106.20,113.56,66.55,8.96">Segmentation of high-resolution urban scene using texture operators</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Conners</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">A</forename><surname>Harlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,179.76,113.56,205.74,8.96">Computer Vision, Graphics, and Image Processing</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="310" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,106.20,142.60,418.41,8.96;8,106.20,154.12,61.17,8.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,182.64,142.60,148.98,8.96">Gabor filters as texture discriminator</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Fogel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Sagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,338.76,142.60,90.94,8.96">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="103" to="113" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,106.20,171.64,418.18,8.96;8,106.20,183.04,418.29,8.96;8,106.20,194.56,150.09,8.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,444.96,171.64,79.42,8.96;8,106.20,183.04,216.38,8.96">Overview of the ImageCLEFphoto 2007 Photographic Retrieval Task</title>
		<author>
			<persName coords=""><forename type="first">Michael</forename><forename type="middle">;</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><forename type="middle">;</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Allan</forename><forename type="middle">;</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Henning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,331.20,183.04,188.39,8.96">Working Notes of the 2007 CLEF Workshop</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">September 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,106.20,212.08,418.33,8.96;8,106.20,223.60,418.38,8.96;8,106.20,235.12,418.38,8.96;8,106.20,246.64,112.77,8.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,406.44,212.08,118.09,8.96;8,106.20,223.60,232.71,8.96">The IAPR-TC12 benchmark: A new evaluation resource for visual information systems</title>
		<author>
			<persName coords=""><forename type="first">Michael</forename><forename type="middle">;</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><forename type="middle">;</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">;</forename><surname>Henning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,357.60,223.60,166.98,8.96;8,106.20,235.12,369.90,8.96">International Workshop OntoImage&apos;2006 Language Resources for Content-Based Image Retrieval, held in conjunction with LREC&apos;06</title>
		<meeting><address><addrLine>Genoa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-05">May 2006</date>
			<biblScope unit="page" from="13" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,106.20,281.56,418.50,8.96;8,106.20,293.08,339.21,8.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,310.56,281.56,214.14,8.96;8,106.20,293.08,162.30,8.96">A novel Bayesian Framework for relevante feedback in image content-based retrieval Systems</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>De Ves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Domingo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Ayala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zuccarello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,275.52,293.08,79.74,8.96">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1622" to="1632" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,106.20,310.60,418.18,8.96;8,106.20,322.12,318.09,8.96" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,357.12,310.60,167.26,8.96;8,106.20,322.12,141.39,8.96">Applying logistic regression to relevance feedback in image retrieval systems</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Leon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zuccarello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Ayala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>De Ves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Domingo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,254.40,322.12,79.74,8.96">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="2621" to="2632" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,106.20,339.64,418.29,8.96;8,106.20,351.04,418.30,8.96;8,106.20,362.56,260.37,8.96" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,106.20,351.04,230.53,8.96">MIRACLE team report for ImageCLEF IR in CLEF</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Martínez-Fernández</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julio</forename><forename type="middle">;</forename><surname>Villena-Román</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ana</forename><forename type="middle">M</forename><surname>García-Serrano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paloma</forename><surname>Martínez-Fernández</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,370.68,351.04,153.82,8.96;8,106.20,362.56,72.42,8.96">Proceedings of the Cross Language Evaluation Forum</title>
		<meeting>the Cross Language Evaluation Forum<address><addrLine>Alicante, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-09-22">2006. 2006. 20-22 September 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,106.20,380.08,418.42,8.96;8,106.20,391.60,418.21,8.96;8,106.20,403.12,418.29,8.96;8,106.20,414.52,169.05,8.96" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,142.08,391.60,272.67,8.96">Combining Textual and Visual Features for Image Retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Martínez-Fernández</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julio</forename><forename type="middle">;</forename><surname>Villena-Román</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ana</forename><forename type="middle">M</forename><surname>García-Serrano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">José</forename><surname>González-Cristóbal</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Carlos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,426.12,391.60,98.29,8.96;8,106.20,403.12,413.76,8.96">Accessing Multilingual Information Repositories: 6th Workshop of the Cross-Language Evaluation Forum, CLEF 2005</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint/>
	</monogr>
	<note>Revised Selected Papers</note>
</biblStruct>

<biblStruct coords="8,277.92,414.52,246.45,8.96;8,106.20,426.04,142.89,8.96" xml:id="b11">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="s" coord="8,378.84,414.52,141.35,8.96">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<idno type="ISSN">0302-9743</idno>
		<imprint>
			<biblScope unit="volume">4022</biblScope>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,106.20,443.56,418.41,8.96;8,106.20,455.08,123.09,8.96" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,193.56,443.56,176.46,8.96">Measuring texture classification algorithms</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Burns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,378.24,443.56,112.95,8.96">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="1495" to="1501" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,106.32,472.60,373.77,8.96" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="8,145.32,472.60,238.49,8.96">Morphological Image Analysis: Principles and Applications</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Soille</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>Springer</publisher>
			<pubPlace>Berlin</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,106.20,490.12,418.27,8.96;8,106.20,501.52,418.26,8.96;8,106.20,513.04,138.45,8.96" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="8,148.08,501.52,376.38,8.96;8,106.20,513.04,134.54,8.96">MIRACLE at ImageCLEFphoto 2007: Evaluation of Merging Strategies for Multilingual and Multimedia Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Julio</forename><surname>Villena-Román</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sara</forename><surname>Lana-Serrano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">José</forename><surname>Luis Martínez-Fernández</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">José</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><surname>González-Cristóbal</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,106.20,530.56,418.29,8.96;8,106.20,542.08,327.09,8.96" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="8,159.36,530.56,360.50,8.96">On ordered weighted averaging aggregation operators in multi-criteria decision making</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">R</forename><surname>Yager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,106.20,542.08,199.11,8.96">IEEE Transactions Systems Man and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="183" to="190" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
