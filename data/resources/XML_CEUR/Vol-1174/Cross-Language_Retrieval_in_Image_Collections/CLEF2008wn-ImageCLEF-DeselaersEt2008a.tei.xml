<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,99.94,148.86,403.12,15.15">Medical Image Annotation in ImageCLEF 2008</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,202.22,182.75,78.65,8.74"><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
							<email>deselaers@cs.rwth-aachen.de</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">RWTH Aachen University</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,308.03,182.75,88.28,8.74"><forename type="first">Thomas</forename><forename type="middle">M</forename><surname>Deserno</surname></persName>
							<email>deserno@ieee.org</email>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Medical Informatics</orgName>
								<orgName type="institution">RWTH Aachen University</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,99.94,148.86,403.12,15.15">Medical Image Annotation in ImageCLEF 2008</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C9BD4FB27F3D17227BC0DF33961593B0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>ImageCLEF</term>
					<term>medical image annotation</term>
					<term>image classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The ImageCLEF 2008 medical image annotation task is designed to assess the quality of content-based image retrieval and image classification by means of global signatures. In total, 12,076 images were used. In contrast to previous years, the task was designed such that the hierarchy of reference IRMA code classifications is essential for good performance. 24 runs of 6 groups were submitted. Multi-class classification schemes for support vector machines outperformed the other methods. The obtained scores rage from 74.92 over 182.77 to 313.01 for best, baseline and worst results, respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Over the last three years, automatic medical image annotation evolved form a simple classification task with only about 60 classes <ref type="bibr" coords="1,224.46,455.28,10.52,8.74" target="#b0">[1]</ref> to a task with nearly 120 classes <ref type="bibr" coords="1,376.40,455.28,10.52,8.74" target="#b3">[4]</ref> and further to a task where a complex class hierarchy of potentially several thousand classes had to be considered <ref type="bibr" coords="1,455.77,467.24,9.96,8.74" target="#b1">[2]</ref>. However, even the 2007 task could be solved using flat classification hierarchies since large parts of the hierarchy were unused and the effective number of classes was only slightly higher than in 2006.</p><p>The aim of this years medical image annotation task is to promote the use of hierarchical classification hierarchies and foster the use of the prior knowledge encoded into the hierarchy of classes.</p><p>The task of this year is similar to last year in that the classes are again based on the IRMA code <ref type="bibr" coords="1,112.74,550.92,9.96,8.74" target="#b2">[3]</ref>. The main difference this year is that the prior distribution of the classes in the test data is strongly different from the prior distribution of the training data and that thus in particular classes which are badly represented in the training data are present in the test data to encourage the use of the hierarchy and the placement of wild card operators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Database and Task Description</head><p>The training data of this year consists of 12,076 images (10,000 training images from last year + 1,000 development images from last year + 1,000 test images from last year + 76 new images) and the test data consists of 1,000 new images. In total 196 unique codes are present in the training images and 187 of these are present in the test images. The most frequent class in the training data consists of more than 2,300 images, but the test data has only one example from this class. In Figure <ref type="figure" coords="1,134.22,701.33,4.98,8.74" target="#fig_2">1</ref>    Each of the radiographs is annotated with its complete IRMA code (see Sec. 2.1). In total, 196 different IRMA codes occur in the database. Example images from the database together with textual labels and their complete code are given in Figure <ref type="figure" coords="2,345.99,417.53,3.87,8.74">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">IRMA Code</head><p>Existing medical terminologies such as the MeSH thesaurus are poly-hierarchical, i.e., a code entity can be reached over several paths. However, in the field of content-based image retrieval, we frequently find class-subclass relations. The mono-hierarchical multi-axial IRMA code strictly relies on such part-of hierarchies and, therefore, avoids ambiguities in textual classification <ref type="bibr" coords="2,499.72,499.51,9.96,8.74" target="#b2">[3]</ref>. In particular, the IRMA code is composed from four axes having three to four positions, each in {0, . . . 9, a, . . . z}, where "'0"' denotes "'not further specified"'. More precisely,</p><p>• the technical code (T) describes the imaging modality;</p><p>• the directional code (D) models body orientations;</p><p>• the anatomical code (A) refers to the body region examined; and</p><p>• the biological code (B) describes the biological system examined. This results in a string of 13 characters (IRMA: TTTT -DDD -AAA -BBB). A small exemplary excerpt from the anatomy axis of the IRMA code is given in Table <ref type="table" coords="2,384.48,632.49,3.87,8.74" target="#tab_0">1</ref>.</p><p>The IRMA code can be easily extended by introducing characters in a certain code position, e.g., if new imaging modalities are introduced. Based on the hierarchy, the more code position differ from "'0"', the more detailed is the description.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Hierarchical Classification</head><p>Let an image be coded by the above 4 independent axes, such that we can consider the axes independently and just sum up the errors for each axis independently:</p><p>-let l I 1 = l 1 , l 2 , . . . , l i , . . . , l I be the correct code (for one axis) of an image; where l i is specified precisely for every position, and in li it is allowed to say "don't know ", which is encoded by *. Note that I (the depth of the tree to which the classification is specified) may be different for different images.</p><p>Given an incorrect classification at position li we consider all succeeding decisions to be wrong and given a not specified position, we consider all succeeding decisions to be not specified. Furthermore, we do not count any error if the correct code is unspecified and the predicted code is a wildcard. In that case, we do consider all remaining positions to be not specified.</p><p>Since we want to penalise wrong decisions that are easy (fewer possible choices at that node) over wrong decisions that are difficult (many possible choices at that node), a decision at position l i is considered to be correct by chance with a probability of 1 bi , if b i is the number of possible labels for position i. This assumes equal priors for each class at each position.</p><p>Furthermore, we want to penalise wrong decisions at an early stage in the code (higher up in the hierarchy) over wrong decisions at a later stage in the code (lower down on the hierarchy) (i.e. l i is more important than l i+1 ).</p><p>Putting this together yields:</p><formula xml:id="formula_0" coords="3,259.84,552.13,253.16,40.96">I i=1 1 b i (a) 1 i (b) δ(l i , li ) (c)<label>(1)</label></formula><p>with</p><formula xml:id="formula_1" coords="3,226.89,609.56,148.04,41.38">δ(l i , li ) =      0 if l j = lj ∀j ≤ i 0.5 if l j = * ∃j ≤ i 1 if l j = lj ∃j ≤ i</formula><p>where the parts of the equation account for (a) difficulty of the decision at position i (branching factor);</p><p>(b) the level in the hierarchy (position in the string); and</p><p>(c) the correct/not specified/wrong labelling, respectively. In addition, for every axis, the maximal possible error is calculated and the errors are normed such that a completely wrong decision (i.e. all positions for that axis wrong) gets an error count of 0.25 and a completely correctly predicted axis has an error of 0. Thus, an image where all positions in all axes are wrong has an error count of 1, and an image where all positions in all axes are correct has an error count of 0.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results from the Evaluation</head><p>In 2008, only 6 groups participated in the medical annotation task submitting 24 runs in total. In the following, we describe the methods applied by the participating groups.</p><p>FEIT. The Faculty of Electrical Engineering and Information Technologies from the University of Skopje in Macedonia submitted 2 runs using global and local image descriptors which are classified using bagging and random forests.</p><p>medGIFT. The medGIFT group from University Hospitals of Geneva in Switzerland submitted 4 runs using different descriptors and voting schemes in the medGIFT image retrieval system.</p><p>Miracle. The Miracle group from Daedalus University in Spain submitted four runs using different global and local image descriptors in a nearest neighbour classifier.</p><p>TAU-BIOMED. The Medical Image Processing Lab from Tel Aviv University in Israel submitted four runs using a bag-of-visual words approach with dense sampling and support vector machines for classification.</p><p>IDIAP. The IDIAP research institute from Switzerland submitted 9 runs using different multiclass classification schemes for support vector machines and different image descriptors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RWTH-MI.</head><p>The Image Retrieval in Medical Applications (IRMA) group at RWTH Aachen University in Aachen, Germany, provides a baseline-run that was computed using Tamura Texture Measures and the Image Distortion Model. Since 2004, the parameterization remains unchanged, and, therefore, the hierarchy was disregarded.</p><p>The results from the evaluation are given in Table <ref type="table" coords="4,328.32,676.92,4.98,8.74" target="#tab_2">3</ref> sorted by error score. It an be seen that the classification accuracy varies strongly from 74.9 errors to 313 errors according to the above described error measurement. Also the number of wildcards used varies very strongly between 0 in the model free approach from the IRMA group to up to 7000, which means that almost 7 wildcards per image were used on the average, i.e. more than half of the positions for the images are undefined. In general, it an be seen that the discriminative models using local descriptors from the IDIAP group outperform the other approaches.</p><p>In Figure <ref type="figure" coords="6,148.46,135.93,3.87,8.74">2</ref>, some example test images are given along with their full IRMA code, the number of wildcards used by the submitted runs on average and the number of training images from this particular class. The top-part and the bottom-part of the figure show the images where, on the average, the most and the fewest wildcards were used, respectively. It can be observed that for classes with bad support in the training data far more wildcards were used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion and Conclusion</head><p>We have presented the ImageCLEF 2008 medical image annotation task. In contrast to previous years, the distribution of training and test images was chosen such that using the hierarchy of the IRMA code was necessary to obtain good results. For classes with very few training images, the submitted runs employed up to more than 8 wildcards out of 13 code positions per image to express their uncertainty about certain classifications. Multi-class classification schemes for support vector machines, as used by the IDIAP Research Institute of Switzerland, outperformed the other methods. The obtained scores rage from 74.92 over 182.77 to 313.01 for best, baseline and worst, respectively.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="1,142.69,701.33,370.30,8.74;1,90.00,713.29,423.00,8.74;1,90.00,725.24,180.24,8.74"><head></head><label></label><figDesc>the frequency of classes in the training and in the test data is shown. It can be seen that the classes in the test data are nearly uniformly distributed but in the training data some classes are far more frequent than others.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="2,170.09,360.86,262.82,8.74"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Frequency of images in the training and test data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,106.60,120.39,335.62,243.27"><head>Table 1 :</head><label>1</label><figDesc>Examples from the IRMA code</figDesc><table coords="3,106.60,145.82,320.40,215.77"><row><cell cols="2">code textual description</cell></row><row><cell>000</cell><cell>not further specified</cell></row><row><cell>...</cell><cell></cell></row><row><cell>400</cell><cell>upper extremity (arm)</cell></row><row><cell>410</cell><cell>upper extremity (arm); hand</cell></row><row><cell>411</cell><cell>upper extremity (arm); hand; finger</cell></row><row><cell>412</cell><cell>upper extremity (arm); hand; middle hand</cell></row><row><cell>413</cell><cell>upper extremity (arm); hand; carpal bones</cell></row><row><cell>420</cell><cell>upper extremity (arm); radio carpal join ...</cell></row><row><cell>430</cell><cell>upper extremity (arm); forearm</cell></row><row><cell>431</cell><cell>upper extremity (arm); forearm; distal forearm</cell></row><row><cell>432</cell><cell>upper extremity (arm); forearm; proximal forearm</cell></row><row><cell>440</cell><cell>upper extremity (arm); ellbow</cell></row><row><cell>...</cell><cell></cell></row><row><cell>-let lI</cell><cell></cell></row></table><note coords="3,132.27,357.55,3.97,6.12;3,139.80,350.22,302.42,11.37"><p>1 = l1 , l2 , . . . , li , . . . , lI be the classified code (for one axis) of an image;</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,90.00,120.39,423.00,142.04"><head>Table 2 :</head><label>2</label><figDesc>Example for different errors in the hierarchical classification scheme. Assuming the code 318a is correct.</figDesc><table coords="4,248.81,157.77,105.38,104.66"><row><cell>318a</cell><cell>0.0</cell></row><row><cell cols="2">318* 0.0244653860094</cell></row><row><cell cols="2">3187 0.0489307720188</cell></row><row><cell cols="2">31*a 0.0824574121058</cell></row><row><cell cols="2">31** 0.0824574121058</cell></row><row><cell>3177</cell><cell>0.164914824212</cell></row><row><cell>3***</cell><cell>0.34342152954</cell></row><row><cell>32**</cell><cell>0.686843059079</cell></row><row><cell>1000</cell><cell>1.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,169.39,276.37,264.23,316.21"><head>Table 3 :</head><label>3</label><figDesc>Results from the medical image annotation task.</figDesc><table coords="5,169.39,291.84,264.23,300.74"><row><cell>group</cell><cell>run</cell><cell cols="2">error score wildcards</cell></row><row><cell>idiap</cell><cell>LOW_MULT_2MARG</cell><cell>74.92</cell><cell>4148</cell></row><row><cell>idiap</cell><cell>LOW_MULT</cell><cell>83.45</cell><cell>3154</cell></row><row><cell>idiap</cell><cell>LOW_2MARG</cell><cell>83.79</cell><cell>4353</cell></row><row><cell>idiap</cell><cell>MCK_MULT_2MARG</cell><cell>85.91</cell><cell>4655</cell></row><row><cell>idiap</cell><cell>LOW_lbp_siftnew</cell><cell>93.20</cell><cell>3157</cell></row><row><cell>idiap</cell><cell>SIFTnew</cell><cell>100.27</cell><cell>3144</cell></row><row><cell>TAU</cell><cell>BIOMED-svm_full</cell><cell>105.75</cell><cell>1000</cell></row><row><cell>TAU</cell><cell>BIOMED-svm_prob</cell><cell>105.86</cell><cell>4868</cell></row><row><cell>TAU</cell><cell>BIOMED-svm_vote</cell><cell>109.37</cell><cell>1000</cell></row><row><cell>TAU</cell><cell>BIOMED-svm_small</cell><cell>117.17</cell><cell>1000</cell></row><row><cell>idiap</cell><cell>LBP</cell><cell>128.58</cell><cell>3173</cell></row><row><cell>rwth_mi</cell><cell>baseline</cell><cell>182.77</cell><cell>0</cell></row><row><cell>MIRACLE</cell><cell>MIRACLE-3I-0F</cell><cell>187.90</cell><cell>4426</cell></row><row><cell>MIRACLE</cell><cell>MIRACLE-2I-0F</cell><cell>190.38</cell><cell>3194</cell></row><row><cell>MIRACLE</cell><cell>MIRACLE-2I-2F</cell><cell>190.38</cell><cell>3194</cell></row><row><cell>MIRACLE</cell><cell>MIRACLE-3I-2F</cell><cell>194.26</cell><cell>3871</cell></row><row><cell>GE</cell><cell>GIFT0.9_0.5_vcad_5</cell><cell>210.93</cell><cell>2146</cell></row><row><cell>GE</cell><cell>GIFT0.9_0.5_vca_5</cell><cell>217.34</cell><cell>2466</cell></row><row><cell>idiap</cell><cell>MCK_pix_sift_2MARG</cell><cell>227.82</cell><cell>6994</cell></row><row><cell>GE</cell><cell>GIFT0.9_akNN_2</cell><cell>241.11</cell><cell>1000</cell></row><row><cell>GE</cell><cell>GIFT0.9_kNN_2</cell><cell>251.97</cell><cell>1000</cell></row><row><cell>FEIT</cell><cell>1</cell><cell>286.48</cell><cell>1117</cell></row><row><cell>FEIT</cell><cell>2</cell><cell>290.50</cell><cell>1024</cell></row><row><cell>idiap</cell><cell>MCK_pix_sift</cell><cell>313.01</cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,105.50,376.97,407.50,8.74;6,105.50,388.93,407.50,8.74;6,105.50,400.88,113.80,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,495.84,376.97,17.16,8.74;6,105.50,388.93,216.32,8.74">The clef 2005 automatic medical image annotation task</title>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clogh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hermann</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">M</forename><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,329.24,388.93,179.33,8.74">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="58" />
			<date type="published" when="2007-08">August 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,420.81,407.50,8.74;6,105.50,432.76,407.50,8.74;6,105.50,444.72,62.13,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,375.26,420.81,137.73,8.74;6,105.50,432.76,253.62,8.74">Automatic medical image annotation in imageclef 2007: Overview, results, and discussion</title>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">M</forename><surname>Deserno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,367.61,432.76,118.13,8.74">Pattern Recognition Letters</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>page in press</note>
</biblStruct>

<biblStruct coords="6,105.50,464.64,407.50,8.74;6,105.50,476.60,407.50,8.74;6,105.50,488.55,90.83,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,105.50,476.60,247.27,8.74">The irma code for unique classification of medical images</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Kohnen</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Berthold B Wein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,373.99,476.60,73.72,8.74">Proceedings SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">5033</biblScope>
			<biblScope unit="page" from="440" to="451" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,508.48,407.50,8.74;6,105.50,520.43,407.50,8.74;6,105.50,532.39,407.51,8.74;6,105.50,544.34,407.50,8.74;6,105.50,556.30,407.50,8.74;6,105.50,568.25,95.20,8.74;7,122.50,234.95,74.72,8.74;7,130.81,246.90,58.11,8.74;7,126.89,258.86,65.95,8.74;7,219.14,234.95,74.72,8.74;7,227.44,246.90,58.11,8.74;7,223.53,258.86,65.95,8.74;7,315.78,234.95,74.72,8.74;7,324.08,246.90,58.11,8.74;7,320.17,258.86,65.95,8.74;7,412.42,234.95,74.72,8.74;7,420.72,246.90,58.11,8.74;7,414.31,258.86,70.93,8.74;7,115.63,359.99,75.27,8.74;7,124.21,371.95,58.11,8.74;7,117.80,383.90,70.93,8.74;7,217.76,355.45,74.72,8.74;7,226.06,367.40,58.11,8.74;7,222.15,379.36,65.95,8.74;7,319.33,359.99,74.72,8.74;7,327.64,371.95,58.11,8.74;7,321.23,383.90,70.93,8.74;7,415.97,359.99,74.72,8.74;7,424.27,371.95,58.11,8.74;7,417.87,383.90,70.93,8.74;7,245.47,399.46,118.71,6.99;7,122.50,508.44,74.72,8.74;7,130.81,520.40,58.11,8.74;7,124.40,532.35,70.93,8.74;7,219.14,508.44,74.72,8.74;7,227.44,520.40,58.11,8.74;7,221.04,532.35,70.93,8.74;7,315.78,508.44,74.72,8.74;7,324.08,520.40,58.11,8.74;7,317.68,532.35,70.93,8.74;7,412.42,508.44,74.72,8.74;7,420.72,520.40,58.11,8.74;7,414.31,532.35,70.93,8.74;7,120.84,633.49,74.72,8.74;7,129.15,645.44,58.11,8.74;7,122.74,657.40,70.93,8.74;7,217.48,633.49,74.72,8.74;7,225.78,645.44,58.11,8.74;7,219.38,657.40,70.93,8.74;7,314.12,633.49,74.72,8.74;7,322.42,645.44,58.11,8.74;7,316.02,657.40,70.93,8.74;7,410.76,633.49,74.72,8.74;7,419.06,645.44,58.11,8.74;7,412.65,657.40,70.93,8.74;7,242.88,672.95,123.88,6.99;7,90.00,693.76,28.12,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,105.50,520.43,336.29,8.74">Overview of the imageclefmed 2006 medical retrieval and annotation tasks</title>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">M</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
		<idno>WC: 4.4 train images: 78 1124-410-610-625 avg. WC: 4.3 train images: 73</idno>
	</analytic>
	<monogr>
		<title level="m" coord="6,140.38,544.34,372.62,8.74;6,105.50,556.30,176.23,8.74">Evaluation of Multilingual and Multi-modal Information Retrieval -Seventh Workshop of the Cross-Language Evaluation Forum</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Gey</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Karlgren</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Magnini</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Stempfhuber</surname></persName>
		</editor>
		<meeting><address><addrLine>CLEF; Alicante, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006. 2007</date>
			<biblScope unit="volume">4730</biblScope>
			<biblScope unit="page" from="1121" to="1220" />
		</imprint>
	</monogr>
	<note>train images: 15 (a) images with most wildcards.. (b) images with fewest wildcards. Figure</note>
</biblStruct>

<biblStruct coords="7,121.77,693.76,391.23,8.74;7,90.00,705.72,148.83,8.74" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="7,250.80,693.76,262.21,8.74;7,90.00,705.72,144.50,8.74">IRMA database with their full IRMA code and the average number of wildcards over all runs</title>
		<imprint/>
	</monogr>
	<note>2: Example images from the</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
