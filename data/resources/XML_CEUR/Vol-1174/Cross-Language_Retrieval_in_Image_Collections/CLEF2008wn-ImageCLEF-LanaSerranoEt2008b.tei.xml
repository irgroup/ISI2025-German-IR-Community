<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,181.92,80.29,231.59,12.64;1,190.68,96.37,213.95,12.64;1,217.56,112.45,160.32,12.64">MIRACLE at ImageCLEFannot 2008: Classification of Image Features for Medical Image Annotation</title>
				<funder ref="#_8TVEWED">
					<orgName type="full">Madrid R+D Regional Plan</orgName>
				</funder>
				<funder ref="#_b9gy6Zb">
					<orgName type="full">Spanish R+D National Plan</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,207.96,139.36,74.58,8.96"><forename type="first">Sara</forename><surname>Lana-Serrano</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universidad Politécnica de Madrid</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">DAEDALUS -Data, Decisions and Language</orgName>
								<address>
									<country>S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,295.80,139.36,83.46,8.96"><forename type="first">Julio</forename><surname>Villena-Román</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Universidad Carlos III de Madrid</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">DAEDALUS -Data, Decisions and Language</orgName>
								<address>
									<country>S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,172.68,150.88,126.13,8.96"><forename type="first">José</forename><surname>Carlos González-Cristóbal</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universidad Politécnica de Madrid</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">DAEDALUS -Data, Decisions and Language</orgName>
								<address>
									<country>S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,312.00,150.88,107.46,8.96"><forename type="first">José</forename><forename type="middle">Miguel</forename><surname>Goñi-Menoyo</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universidad Politécnica de Madrid</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,181.92,80.29,231.59,12.64;1,190.68,96.37,213.95,12.64;1,217.56,112.45,160.32,12.64">MIRACLE at ImageCLEFannot 2008: Classification of Image Features for Medical Image Annotation</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">09673772204344FD02CCC08E11E46D8B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.2 Information Storage</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital libraries Information Retrieval, medical image, image annotation, classification, IRMA code, axis, learning algorithms, nearest-neighbour, machine learning, ImageCLEF Medical Automatic Image Annotation task, CLEF, 2008</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the participation of MIRACLE research consortium at the ImageCLEF Medical Image Annotation task of ImageCLEF 2008. A lot of effort was invested this year to develop our own image analysis system, based on MATLAB, to be used in our experiments. This system extracts a variety of global and local features including histogram, image statistics, Gabor features, fractal dimension, DCT and DWT coefficients, Tamura features and coocurrency matrix statistics. Then a k-Nearest Neighbour algorithm analyzes the extracted image feature vectors to determine the IRMA code associated to a given image. The focus of our experiments is mainly to test and evaluate this system in-depth and to make a comparison among diverse configuration parameters such as number of images for the relevance feedback to use in the classification module.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>MIRACLE team is a research consortium formed by research groups of three different universities in Madrid (Universidad Politécnica de Madrid, Universidad Autónoma de Madrid and Universidad Carlos III de Madrid) along with DAEDALUS, a small/medium size enterprise (SME) founded in 1998 as a spin-off of two of these groups and a leading company in the field of linguistic technologies in Spain. MIRACLE has taken part in CLEF since 2003 in many different tracks and tasks, including the main bilingual, monolingual and cross lingual tasks as well as in ImageCLEF, Question Answering, WebCLEF, GeoCLEF and VideoCLEF (VID2RSS) tracks.</p><p>This paper describes our participation in the Medical Image Annotation task of ImageCLEF 2008 <ref type="bibr" coords="1,476.04,618.28,10.69,8.96" target="#b5">[6]</ref>. Briefly, the objective of this task is to provide the IRMA (Image Retrieval in Medical Applications) code <ref type="bibr" coords="1,475.92,629.68,11.71,8.96" target="#b3">[4]</ref> for each image of a given set of 1,000 previously unseen medical (radiological) images covering different medical pathologies. Over 12,000 classified training images were provided this year to be used in any way to train a classifier. This task uses no textual information, but only image-content information.</p><p>While in previous participations <ref type="bibr" coords="1,202.32,681.76,11.71,8.96" target="#b4">[5]</ref>  <ref type="bibr" coords="1,216.72,681.76,11.71,8.96" target="#b6">[7]</ref> we approached this task as a machine learning problem, regardless of the domain, as our areas of expertise did not include image analysis research <ref type="bibr" coords="1,368.16,693.16,11.71,8.96" target="#b1">[2]</ref> [3], a lot of effort was invested last year to develop our own image analysis system, based on MATLAB, to be used in our experiments. Thus, now the main purpose of our experiments is to test and evaluate this system in-depth and make a comparison among diverse configuration parameters such as number of images for the relevance feedback to use in the classification module.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Description of Experiments</head><p>The architecture of our system is composed of different functional blocks:</p><p>• Feature extraction module: in charge of the calculation and extraction of a variety of features of each image, both the training set used to build the classifier and the test set that is to be actually classified. This module has been entirely developed using MATLAB and extracts vectors with a total of 3,741 features for each image.</p><p>Images are converted to gray-scale, rescaled to 256x256 pixels and the following features are extracted: • Classifier: determines the IRMA code associated to a given image, from its feature vector and the feature matrix of the training set. The classifier is internally composed of two blocks: an initial module in charge of selecting those images in the training set whose vectors are at a distance lower than a given threshold from the vector associated to the image to classify, and then a second module that actually generates the IRMA code, depending on the codes and similarity of nearby images.</p><formula xml:id="formula_0" coords="2,124.92,181.18,5.97,7.83">o</formula><p>Finally, we submitted four runs to be evaluated, described in Table <ref type="table" coords="2,342.00,337.36,3.76,8.96">1</ref>. For all of them, the returned IRMA code is generated from the combination of the first N images in the training set that are most similar to the image to classify. The combination consists of a simple "addition" of strings characters in which, if both characters are different, the result is the wildcard "*" representing the ambiguity (or "hesitation" to choose). This algorithm actually could be considered as a variation of the classical k-Nearest Neighbour algorithm <ref type="bibr" coords="2,448.44,383.32,11.71,8.96" target="#b7">[8]</ref> with a specific definition of the generating the output class.</p><p>Additionally, two runs use relevance feedback (RF) with the first two images in the training set that are at a lowest distance. Vectors of those images are added and averaged to build a new vector that is used for querying the system again.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1. Experiment set</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run Identifier Description MIRACLE-2I-0F Merge code of 2 first results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MIRACLE-3I-0F Merge code of 3 first results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MIRACLE-2I-2F</head><p>Merge code of 2 first results + RF with 2 images MIRACLE-3I-2F Merge code of 3 first results + RF with 2 images</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Results</head><p>Results are shown in Table <ref type="table" coords="2,184.20,573.64,3.70,8.96" target="#tab_1">2</ref>. The "Error score" column contains the experiment score as computed by the task organizers <ref type="bibr" coords="2,115.80,585.04,10.69,8.96" target="#b0">[1]</ref>. This score is defined so as to penalize wrong decisions that are easy to take (i.e., there are few possible choices at that node) over wrong decisions difficult to take (i.e., there are many possible choices at that node). Furthermore, it also penalizes wrong decisions at an early stage in the code (higher up in the IRMA code hierarchy) over wrong decisions at a later stage (lower down in the hierarchy). The "Well Classified" column shows the actual number of images with complete correct predicted code. The "Bad-Classified" column shows the number of images with error score equal to 1.0 (wrong prediction of all code axis). The best score is achieved by the run that combines the codes of the first 3 images, with no relevance feedback. Moreover, runs using the codes of the first 2 images seem to get the same final score no matter if relevance feedback is considered or not. However, the analysis axis-by-axis shows interesting differences that will be described later.</p><p>Table <ref type="table" coords="3,96.36,125.08,4.98,8.96" target="#tab_2">3</ref> shows the average results from all groups. Comparing our scores to the scores of other participants in the task, we achieve average results and rank 4 th out of 6 groups. Table <ref type="table" coords="3,97.44,255.04,4.98,8.96" target="#tab_3">4</ref> shows an axis-by-axis analysis of the results. For each of the four axis of the IRMA code, this table shows the "Error Score", calculated as the sum of the errors made for each image, and the number of images in which the full prediction of the axis (i.e., no wildcards in the output) is correct. Next figures allow to make a graphical comparison of the results obtained by each experiment, showing both the global evaluation of the experiment and the specific evaluation of each individual axis. Figure <ref type="figure" coords="3,473.64,439.60,4.98,8.96">1</ref> shows the number of images for which the complete code (no wildcards) has been correctly predicted. Figure <ref type="figure" coords="3,476.16,451.12,4.98,8.96" target="#fig_0">2</ref> shows the number of images for which the complete prediction of the axis is completely wrong.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1. Correctly predicted axis</head><p>As observed in the previous figure, the Technical (T) and Anatomical (A) axis are the best predicted axis, with a significant difference with respect to the others. However this is misleading in the case of the Technical axis, as the value of this axis for all images to classify is either "1121", "1123", "1124" or "112d", thus, in practice, having to decide only among four codes -in fact, 93% of the images have "1121" and 4% have "1124". </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusions and Future Work</head><p>Based on the analysis performed over each axis, the first conclusion to be drawn is that the first weak point of our experiments is the prediction of the Direction (D) and Biological (B) axis. Some extra effort must be invested on determining which image features could be most useful to predict those axis.</p><p>In addition, it can be observed that although the number of incorrect predictions is relatively low, this does not correspond to a high number of correct predictions (which in fact is also relatively low), as it would be expected applying a binary "correct" vs. "incorrect" logic. This is due to the fact that, as the cost of making an incorrect decision is higher than the cost of not actually making a decision, the design criteria of the system is biased for "hesitation", i.e., the system is very cautious and assigns a wildcard "*" if there is any kind of ambiguity. This explanation also confirmed by the result of the run that takes 3 codes for generating the final IRMA code: when the number of codes increases, so ambiguity does, thus the number of complete correct predictions decreases and also the error score.</p><p>Finally, in all runs, the calculation of the distance among vectors assigns the same weight to every dimension of the vectors, regardless of the nature of the feature to which this component belongs and/or the number of components belonging to that feature. This was actually our mistake when carrying out the experiments and the feature matrix should have been divided into the different feature sub-matrixes that employ different distances for calculating similarity and are combined to each other using different weight strategies. For sure this will be taken into account for future participations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,226.20,315.76,142.95,8.96"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Incorrectly predicted axis</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,124.92,180.64,399.58,83.96"><head>Global features: gray</head><label></label><figDesc>histogram (128 levels of gray), image statistics (mean, median, variance, maximum singular value, skewness and kurtosis ), Gabor features (4 scales, 6 filter orientations), fractal dimension, Discrete Cosine Transform (DCT) coefficients, Discrete Wavelet Transform (DWT) coefficients, Tamura features (coarseness, contrast, directionality), and coocurrency matrix statistics (energy, entropy, contrast, homogeneity, correlation) o Local features: images are cut up into 64x64 pixel blocks and then the previous features are extracted for each block.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,148.68,672.04,302.18,79.28"><head>Table 2 .</head><label>2</label><figDesc>Results of experiments</figDesc><table coords="2,148.68,690.88,302.18,60.44"><row><cell cols="2">Run Identifier Error Score</cell><cell>Well Classified</cell><cell>Bad Classified</cell></row><row><cell>MIRACLE-2I-0F</cell><cell>190.38</cell><cell>219</cell><cell>0</cell></row><row><cell>MIRACLE-3I-0F</cell><cell>187.90</cell><cell>144</cell><cell>0</cell></row><row><cell>MIRACLE-2I-2F</cell><cell>190.38</cell><cell>219</cell><cell>0</cell></row><row><cell>MIRACLE-3I-2F</cell><cell>194.26</cell><cell>167</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,216.60,160.12,138.75,79.28"><head>Table 3 .</head><label>3</label><figDesc>Summary of results</figDesc><table coords="3,216.60,180.28,132.78,59.12"><row><cell>Maximum error score 313.01</cell></row><row><cell>Minimum error score 74.92</cell></row><row><cell>Average error score 169.71</cell></row><row><cell>Mode error score 190.38</cell></row><row><cell>Number of runs 24</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="3,105.60,301.60,378.78,104.72"><head>Table 4 .</head><label>4</label><figDesc>Axis-by-axis analysis</figDesc><table coords="3,105.60,320.44,378.78,85.88"><row><cell cols="2">T-Axis</cell><cell cols="2">D-Axis 318.04 381</cell><cell>362.56</cell><cell>283</cell><cell>75.6</cell><cell>789</cell></row><row><cell>MIRACLE-3I-0F 6.32</cell><cell>808</cell><cell>309.78</cell><cell>293</cell><cell>367.82</cell><cell>206</cell><cell>67.67</cell><cell>735</cell></row><row><cell>MIRACLE-2I-2F 5.24</cell><cell>852</cell><cell>318.04</cell><cell>381</cell><cell>362.56</cell><cell>283</cell><cell>75.67</cell><cell>789</cell></row><row><cell>MIRACLE-3I-2F 6.12</cell><cell>818</cell><cell>322.09</cell><cell>318</cell><cell>374.74</cell><cell>235</cell><cell>74.07</cell><cell>744</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work has been partially supported by the <rs type="funder">Spanish R+D National Plan</rs>, by means of the project <rs type="projectName">BRAVO (Multilingual and Multimodal Answers Advanced Search -Information Retrieval</rs>), <rs type="grantNumber">TIN2007-67407-C03-03</rs> and by <rs type="funder">Madrid R+D Regional Plan</rs>, by means of the project <rs type="projectName">MAVIR (Enhancing the Access and the Visibility of Networked Multilingual Information for the Community of Madrid</rs>), <rs type="grantNumber">S-0505/TIC/000267</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_b9gy6Zb">
					<idno type="grant-number">TIN2007-67407-C03-03</idno>
					<orgName type="project" subtype="full">BRAVO (Multilingual and Multimodal Answers Advanced Search -Information Retrieval</orgName>
				</org>
				<org type="funded-project" xml:id="_8TVEWED">
					<idno type="grant-number">S-0505/TIC/000267</idno>
					<orgName type="project" subtype="full">MAVIR (Enhancing the Access and the Visibility of Networked Multilingual Information for the Community of Madrid</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,97.92,694.12,426.49,8.96;4,97.92,705.52,52.74,8.96;4,170.64,705.52,11.59,8.96;4,202.32,705.52,49.33,8.96;4,271.68,705.52,20.10,8.96;4,311.88,705.52,32.77,8.96;4,364.68,705.52,24.82,8.96;4,409.68,705.52,47.37,8.96;4,477.24,705.52,12.18,8.96;4,509.40,705.52,14.98,8.96;4,97.92,717.04,328.41,8.96" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="4,475.08,694.12,49.33,8.96;4,97.92,705.52,52.74,8.96;4,170.64,705.52,11.59,8.96;4,202.32,705.52,49.33,8.96;4,271.68,705.52,20.10,8.96;4,311.88,705.52,32.77,8.96;4,364.68,705.52,24.82,8.96;4,409.68,705.52,43.06,8.96">Hierarchical classification for ImageCLEF 2008 Medical Image Annotation</title>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">;</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jayashree</forename><forename type="middle">;</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">;</forename><surname>Henning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deserno</surname></persName>
		</author>
		<ptr target="http://www.imageclef.org/system/files/hierarchical2008.pdf" />
		<imprint>
			<date type="published" when="2008-08-14">14/08/2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,97.92,734.56,426.49,8.96;4,97.92,746.08,168.33,8.96" xml:id="b1">
	<monogr>
		<ptr target="http://www-i6.informatik.rwth-aachen.de/~deselaers/fire.html" />
		<title level="m" coord="4,97.92,734.56,192.21,8.96">FIRE: Flexible Image Retrieval System</title>
		<imprint>
			<date type="published" when="2008-08-14">14/08/2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,97.92,73.12,426.49,8.96;5,97.92,84.64,85.05,8.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,164.04,73.12,257.95,8.96">Image Information Retrieval: An Overview of Current Research</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">A</forename><surname>Goodrum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,429.36,73.12,72.81,8.96">Informing Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="63" to="66" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,97.92,102.04,426.42,8.96;5,97.92,113.56,51.45,8.96" xml:id="b3">
	<monogr>
		<ptr target="http://www.irma-project.org/[Visited10/08/2008" />
		<title level="m" coord="5,97.92,102.04,231.30,8.96">IRMA project: Image Retrieval in Medical Applications</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,97.92,131.08,426.45,8.96;5,97.92,142.60,426.57,8.96;5,97.92,154.12,335.61,8.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,97.92,142.60,422.26,8.96">MIRACLE at ImageCLEFannot 2007: Machine Learning Experiments on Medical Image Annotation</title>
		<author>
			<persName coords=""><forename type="first">Lana-Serrano</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sara</forename><forename type="middle">;</forename><surname>Villena-Román</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julio</forename><forename type="middle">;</forename><surname>González-Cristóbal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">José</forename><surname>Carlos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">;</forename><surname>Goñi-Menoyo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">José</forename><surname>Miguel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,97.92,154.12,178.05,8.96">Working Notes of the 2007 CLEF Workshop</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">September 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,97.92,171.64,426.49,8.96;5,97.92,183.04,86.25,8.96" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="5,97.92,171.64,227.54,8.96">ImageCLEF Medical Automatic Image Annotation Task</title>
		<ptr target="http://www.imageclef.org/2008/medaat[Visited14/08/2008" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,97.92,200.56,426.45,8.96;5,97.92,212.08,426.42,8.96;5,97.92,223.60,137.61,8.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,97.92,212.08,261.46,8.96">MIRACLE&apos;s Naive Approach to Medical Images Annotation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Villena-Román</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>González-Cristóbal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Goñi-Menoyo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Fernández</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,369.24,212.08,155.10,8.96;5,97.92,223.60,39.23,8.96">Working Notes for the CLEF 2005 Workshop</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,97.92,241.12,426.45,8.96;5,97.92,252.64,165.33,8.96" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="5,216.00,241.12,304.37,8.96">Data Mining: Practical machine learning tools and techniques, 2nd Edition</title>
		<author>
			<persName coords=""><forename type="first">Ian</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eibe</forename><surname>Frank</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Morgan Kaufmann</publisher>
			<pubPlace>San Francisco</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
