<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,116.44,151.38,370.13,12.38;1,267.78,173.29,67.43,12.38;1,335.22,168.17,5.98,10.48">Increasing cluster recall of cross-modal image retrieval *</title>
				<funder ref="#_6zDrtmx">
					<orgName type="full">EU</orgName>
				</funder>
				<funder ref="#_DjTfFbr #_8hvZmvR #_Bkk8WzU">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,200.89,206.49,51.59,6.64"><forename type="first">Simon</forename><surname>Rácz</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,265.77,206.49,65.87,6.64"><forename type="first">Bálint</forename><surname>Daróczy</surname></persName>
							<email>daroczyb@ilab.sztaki.hu</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,344.93,206.49,57.18,6.64"><forename type="first">Dávid</forename><surname>Siklósi</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,180.53,220.44,76.86,6.64"><forename type="first">Attila</forename><surname>Pereszlényi</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,270.67,220.44,68.56,6.64"><forename type="first">Mátyás</forename><surname>Brendel</surname></persName>
							<email>mbrendel@ilab.sztaki.hu</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,352.51,220.44,69.97,6.64"><forename type="first">András</forename><surname>Benczúr</surname></persName>
							<email>benczur@ilab.sztaki.hu</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,116.44,151.38,370.13,12.38;1,267.78,173.29,67.43,12.38;1,335.22,168.17,5.98,10.48">Increasing cluster recall of cross-modal image retrieval *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FC740975D775AB680C222B061966F4F5</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Management]: LanguagesQuery Languages Measurement, Performance, Experimentation Cross-modal retrieval, image annotation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe our approach to the ImageCLEF Photo and WikiMediaMM 2008 tasks.</p><p>The novelty of our method consists of combining image segment based image retrieval with our text based approach. We rank text hits by our own Okapi BM25 based information retrieval system and image similarities by using a feature vector describing the visual content of image segments. Images were segmented by a home developed segmenter. We use automatic query expansion by adding new terms from the top ranked documents. Queries were generated automatically from the title and the downweighted</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper we describe our approach to the ImageCLEF Photo and WikiMediaMM 2008 evaluation campaigns <ref type="bibr" coords="1,170.99,648.58,9.96,6.64" target="#b4">[5]</ref>. ImageCLEF Photo is over the IAPR TC-12 benchmark of 20,000 tourist photos <ref type="bibr" coords="1,121.33,660.54,10.51,6.64" target="#b5">[6]</ref> and WikiMediaMM is over the INEX MM image database which contains approximately 150,000 images that cover diverse topics of interest. These images are associated with unstructured and noisy textual annotations in English. Both campaigns are ad-hoc image retrieval tasks: nd as many relevant images as possible from the image collections.</p><p>The key feature of our solution in both cases is to combine text based and content based image retrieval. Our method is similar to the method we applied last year for ImageCLEF Photo <ref type="bibr" coords="1,499.72,720.31,9.96,6.64" target="#b0">[1]</ref>.</p><p>Our CBIR method is based on segmentation of the image and on the comparison of features of the segments. We use the Hungarian Academy of Sciences search engine <ref type="bibr" coords="2,416.66,125.80,10.51,6.64" target="#b1">[2]</ref> as our information retrieval system that is based on Okapi BM25 and automatic query expansion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The base text search engine</head><p>We use the Hungarian Academy of Sciences search engine <ref type="bibr" coords="2,344.16,192.51,10.51,6.64" target="#b1">[2]</ref> as our information retrieval system.</p><p>Its ranking algorithm was developed originally for HTML pages. It uses the Okapi BM25 ranking <ref type="bibr" coords="2,90.00,216.43,10.51,6.64" target="#b7">[8]</ref> with the proximity of query terms taken into account <ref type="bibr" coords="2,335.58,216.43,13.20,6.64" target="#b6">[7,</ref><ref type="bibr" coords="2,352.27,216.43,7.01,6.64" target="#b2">3]</ref>. We deploy stopword removal and stemming by the Porter stemmer. We extended of stop word list with terms such as photo or image that are frequently used in annotations but does not have a distinctive meaning in this task.</p><p>We considered the text annotation of images including the title, the description and (in case of ImageCLEF Photo) the location separately. The ranking algorithm uses dierent weights depending on which part of the document contains the query term. Since many topics have location reference, we get the best results if the weight of hits inside the location is much higher than the weights of title and the description.</p><p>For queries we use the title and description of the topics with dierent weight. In addition to stop words we also removed sentences containing the phrase not relevant. We apply automatic query expansion based on the method described in <ref type="bibr" coords="2,317.01,347.93,9.96,6.64" target="#b8">[9]</ref>. For a given query Q, we ranked every w word in the top 10 documents according to the following formula.</p><formula xml:id="formula_0" coords="2,171.95,381.42,341.05,20.06">Score(Q, w) = ti∈Q (idf i log (δ + log(af (w, t i ))idf w / log(n)))<label>(1)</label></formula><p>1. af (w, t i ) = 10 j=1 f t ij f w j 2. idf i = max{1, log ((N -N i + 0.5)/(N i + 0.5))} 3. idf w = max{1, log ((N -N w + 0.5)/(N w + 0.5))} Here f t ij is the number of occurrences of t i in the jth document and similarly f w j is the number of occurrences of w in the jth document. At the 2th and 3th lines N is the total number of documents in the collection, N i is the number of documents containing t i and N w is the number of documents containing w. We used a correcting term δ to avoid minus innity scores.</p><p>After these computations we expanded our query with those new w words whose score was above zero and we gave them the weight (Score(w) + 10)/500 as query term weight. We also ensured that at most the rst 15 words with highest rank got attached to the query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The content based IR system</head><p>The task of the CBIR part was to help annotation based retrieval with a content based method.</p><p>Our method for this year is similar to that of 2007 <ref type="bibr" coords="2,330.94,616.19,9.96,6.64" target="#b0">[1]</ref>. The basis of our method is to nd segments on the images of the collection similar to the segments in the sample images. We used the Felzenszwalb and Huttenlocher <ref type="bibr" coords="2,244.43,640.10,10.51,6.64" target="#b3">[4]</ref> graph based segmentation algorithm with dierent number of segments for the two tasks that turned out most eective by manual investigation. The number of segments for dierent runs vary with an extreme case of even a single segment per image corresponding to global similarity measurement. Images were resized to the same size prior to segmentation.</p><p>We extracted 20 features for mean color, size, shape information, and histogram information.</p><p>Our histograms had 5 bins in each channel. In addition we used contrast and 2D Fourier coecients. Contrast means the maximal and minimal values of the L-channel in HSL color space. The discrete Fourier transformation was sampled along a zig-zag order, i.e. the low frequency components were included. The DFT features were weighted 10 time higher compared to the other features. Similarity is measured in the above feature space as dist(S i , S j ) = d(F (S i ), F (S j )) : S i ∈ S(X), S j ∈ S(I) <ref type="bibr" coords="3,500.27,159.00,12.73,6.64" target="#b1">(2)</ref> where S(X) is the set of segments of an image X of the collection and S(I) is the set of segments of the sample image I; d is a distance function in the feature space and F assigns features to image segments.</p><p>Given the distance dist(S, S ) of two segments, the distance of image X to sample image I is computed from pairwise distances between pairs of segments S(X) and S(I) of images X and I, respectively. In the base method we averaged over S i ∈ S(I) such that for each S i we took the closest segment from S(X)</p><formula xml:id="formula_1" coords="3,162.67,251.97,350.33,44.02">as dist(X, I) = 1 |S(I)| j min i {dist(S i , S j ) : S i ∈ S(X), S j ∈ S(I)}.<label>(3)</label></formula><p>We introduce another method for computing image distances from segment distances that also takes the relative position of the segments into account. For a pair of images I and X rst for all segments S in I the most similar segment R(S) is searched in X. Then we look for the N closest neighbors S 1 , . . . , S N that have common border with S. We dene R(S i ) as the segment of X closest in relative spatial position to R(S). The distance is computed as</p><formula xml:id="formula_2" coords="3,107.44,375.72,405.56,30.32">dist(I , X) = a 1 • dist(S, R(S)) + a 2 • 1 N N i=1 dist(S i , R(S i )) + a 3 • 1 N N i=1 dist * (S i , R(S i ))<label>(4)</label></formula><p>where dist * is spatial distance within the image. The weights used are a 1 =1.0, a 2 =0.8 and a 3 =0.2.</p><p>When combining TBIR and CBIR we considered TBIR much more reliable than CBIR. Since image distance decreases with relevance, we used CBIR scores by subtracting them from a suciently high constant that leaves the rank always positive. <ref type="bibr" coords="3,90.00,479.69,7.89,15.78" target="#b3">4</ref> The WikiMedia Task</p><p>In the WikiMedia Task part of the topics included a sample image. For these topics we combined the text score with a visual score described next. First we resized images to a maximum size of 800x800 by keeping the aspect ratio. We used a global one segment per image method in addition to a medium granularity segmentation with a minimum segment size of 1500 pixels. This latter method resulted in less than 100 segments per image.</p><p>The WikiMedia task, with over 100,000 images, already raises scalability issues for a CBIR. The total size of the feature vectors reached 10 Gigabytes, hence pairwise segment similarity scores were computed by a parallel matrix multiplication algorithm for which we utilized a computer cluster. For a single sample image with less than 100 segments, similarity computation with all 100,000 images took over 5 CPU hours by this method. This implies that for a larger collection similarity search data structures will have to be used.</p><p>There were several variants of our CBIR method for this task. Due to computational limitations we only used the more complex distance function based on the relative position of the segments.</p><p>The comparison with the simple averaging method will be performed in the near future.</p><p>Variants submitted were named as follows. Since the distance of two images as dened in the previous section is asymmetric, we computed both dist(I , X) and dist(X, I). Label avg stands for the average of the two while in avgw we give 70% weight for the distance of the target image to the sample image dist(I , X).</p><p>We also used global, single segment per image runs labeled glob10. Here the Fourier coecients had weight 10.0 and the other features weight 1.0. The variant avgw_glob10 combined avgw with glob10 where the later had half the weight of the former.  <ref type="bibr" coords="4,90.00,235.13,7.89,15.78" target="#b4">5</ref> The Photo Task</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>MAP</head><p>In the Photo Retrieval Task we used medium sized segmentation as in the WikiMedia task. We only used plain segment distances with no relative position taken into account; a comparison will be performed in the near future. In distance computation we weighted the features as follows. For variant w5 we had size 1; ratio 3; average color 1; shape 1; contrast 1. And for w10 size 1; ratio 3; average color 20; histogram 50; shape 50 and contrast 10.</p><p>In the Photo Task 3 sample images were given for each topic. Consequently, for each image there are 3 distances. The 3 distances can be combined as average, minimum or maximum. We tried all of them, which is indicated in the name of the variant as min, max or avg.</p><p>Best performing pure CBIR MAP score 0.0243 was obtained by w5_min with a runner up 0.0212 of w10_min. Ocial runs submitted were unfortunately combined with the avg variants that performed below a MAP of 0.003 only. In combination with the TBIR score we were able to improve the MAP from 0.2978 to 0.3014 by w10_min. Ocial runs performed slightly below this value.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Increasing cluster recall</head><p>We modied our method to achieve greater diversity within the top 20. For each topic in the ImageCLEF Photo set, relevant images were manually clustered into sub-topics. Evaluation was be based on two measures: precision at 20 and instance recall at rank 20 (also called S-recall) which calculates the percentage of dierent clusters represented in the top 20.</p><p>Our method works as follows. Let Orig(i) be the ith document (0 ≤ i &lt; 999) and OrigSc(i) be the score of this element on the original list for a given query Q j . We modied these scores by giving penalties to the scores of the documents based on their Kullback-Leibler distance. We used the following algorithm.</p><p>1. New (0) = Orig(0) and NewSc(0) = OrigSc(0)</p><formula xml:id="formula_3" coords="4,90.00,570.93,231.35,92.31">2. For i = 1 to 20 (a) New(i) = argmax k {CL i (k) |i &lt;= k &lt; 999} (b) NewSc(i) = max{CL i (k) |i &lt;= k &lt; 999} (c) For = 0 to (i -1) NewSc( ) = NewSc( ) + c(i) Here CL i (k) = OrigSc(k) + α i-1 l=0 KL(i, k).</formula><p>where α is a tunable parameter and KL(i, k) is the Kullback-Leibler distance of the ith and kth documents. We used a correction term c(i) at Step 2c to ensure that the new scores will be also in descending order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">results</head><p>Table <ref type="table" coords="4,117.96,723.56,4.98,6.64" target="#tab_0">1</ref> shows the results of the text based and the mixed method. The results were evaluated by the ImageCLEF organizers using the following measures: Mean Average Precision (MAP), Precision at 20 (P20) and Cluster Recall at 20 (CR20).</p><p>The number in the names indicate the value of α from the previous section. As it can be seen the algorithm used to increase CR20 was successful with α = 0.5. The cost of increasing CR20 was worse MAP and P20. The value α = 5.0 turned out to be too much. Using CBIR and query expansion improved the algorithm a little, and the same trend is true for α.</p><p>Unfortunately at the moment we do not have evaluations for text+qe and text+image without qe to check which part is responsible for the improvement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion and future work</head><p>We have demonstrated that image based retrieval based on segmentation can improve the performance of an IR system. In future work we will conduct a more thorough comparison of the dierent CBIR techniques introduced. We also plan to improve on the performance of query expansion.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,133.06,112.65,336.88,106.67"><head>Table 1 :</head><label>1</label><figDesc>Performance of the variants method evaluated by dierent measures</figDesc><table coords="4,204.72,112.65,190.25,80.76"><row><cell></cell><cell></cell><cell>P20</cell><cell>CR20</cell></row><row><cell>text0</cell><cell>0.2988</cell><cell>0.3718</cell><cell>0.3592</cell></row><row><cell>text0.5</cell><cell>0.2469</cell><cell>0.3179</cell><cell>0.3703</cell></row><row><cell>text5.0</cell><cell>0.1739</cell><cell>0.2410</cell><cell>0.3421</cell></row><row><cell>text+img+qe0</cell><cell>0.3003</cell><cell>0.3769</cell><cell>0.3560</cell></row><row><cell>text+img+qe0.5</cell><cell>0.2495</cell><cell>0.3218</cell><cell>0.3703</cell></row><row><cell>text+img+qe5.0</cell><cell>0.1737</cell><cell>0.2423</cell><cell>0.3402</cell></row></table></figure>
		</body>
		<back>

			<div type="funding">
<div><p>* This work was supported by the <rs type="funder">EU</rs> <rs type="projectName">FP7</rs> project <rs type="projectName">JUMAS Judicial Management</rs> by <rs type="projectName">Digital Libraries Semantics</rs> and by grants <rs type="grantNumber">OTKA NK 72845</rs> and <rs type="grantNumber">NKFP-07-A2 TEXTREND</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_6zDrtmx">
					<orgName type="project" subtype="full">FP7</orgName>
				</org>
				<org type="funded-project" xml:id="_DjTfFbr">
					<orgName type="project" subtype="full">JUMAS Judicial Management</orgName>
				</org>
				<org type="funded-project" xml:id="_8hvZmvR">
					<idno type="grant-number">OTKA NK 72845</idno>
					<orgName type="project" subtype="full">Digital Libraries Semantics</orgName>
				</org>
				<org type="funding" xml:id="_Bkk8WzU">
					<idno type="grant-number">NKFP-07-A2 TEXTREND</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,105.50,319.01,407.50,6.64;5,105.49,330.96,407.51,6.64;5,105.49,342.92,231.98,6.64" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,142.44,330.96,265.95,6.64">Cross-modal retrieval by text and image feature biclustering</title>
		<author>
			<persName coords=""><forename type="first">András</forename><surname>Benczúr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">István</forename><surname>Bíró</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mátyás</forename><surname>Brendel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Csalogány</forename><surname>Károly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bálint</forename><surname>Daróczy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dávid</forename><surname>Siklósi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,431.69,331.36,81.31,6.11;5,105.49,343.32,110.82,6.11">Working Notes for the CLEF 2007 Workshop</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,362.84,407.50,6.64;5,105.49,374.80,407.50,6.64;5,105.49,386.75,299.74,6.64" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,245.93,374.80,245.50,6.64">Searching a small national domainpreliminary report</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>András</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Károly</forename><surname>Benczúr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eszter</forename><surname>Csalogány</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dániel</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tamás</forename><surname>Fogaras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Máté</forename><surname>Sarlós</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eszter</forename><surname>Uher</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Windhager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,105.49,387.15,266.95,6.11">Proceedings of the 12th World Wide Web Conference (WWW)</title>
		<meeting>the 12th World Wide Web Conference (WWW)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,406.68,407.51,6.64;5,105.49,418.63,407.51,6.64;5,105.49,430.59,78.58,6.64" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,364.70,406.68,148.30,6.64;5,105.49,418.63,166.67,6.64">Term proximity scoring for ad-hoc retrieval on very large text collections</title>
		<author>
			<persName coords=""><forename type="first">Stefan</forename><surname>Büttcher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Brad</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Lushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,295.46,419.03,44.39,6.11">SIGIR &apos;06</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page">621622</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,450.51,407.50,6.64;5,105.49,462.47,228.40,6.64" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,330.02,450.51,178.35,6.64">Ecient graph-based image segmentation</title>
		<author>
			<persName coords=""><forename type="first">Pedro</forename><forename type="middle">F</forename><surname>Felzenszwalb</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><forename type="middle">P</forename><surname>Huttenlocher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,105.49,462.87,181.91,6.11">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,482.39,407.51,6.64;5,105.49,494.35,407.51,6.64;5,105.49,506.30,162.11,6.64" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,412.63,482.39,100.38,6.64;5,105.49,494.35,192.62,6.64">Overview of the Image-CLEFphoto 2007 photographic retrieval task</title>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,318.63,494.75,189.35,6.11">Working Notes of the 2007 CLEF Workshop</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">September 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,526.23,407.51,6.64;5,105.49,538.18,407.50,6.64;5,105.49,550.14,53.68,6.64" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,435.82,526.23,77.19,6.64;5,105.49,538.18,306.33,6.64">The IAPR TC-12 benchmark -a new evaluation resource for visual information systems</title>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselears</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,434.72,538.58,45.58,6.11">OntoImage</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page">1323</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,570.06,407.51,6.64;5,105.49,582.02,134.33,6.64" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,253.45,570.06,255.00,6.64">Term proximity scoring for keyword-based retrieval systems</title>
		<author>
			<persName coords=""><forename type="first">Yves</forename><surname>Rasolofo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,117.95,582.42,22.20,6.11">ECIR</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page">207218</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,601.95,407.51,6.64;5,105.49,613.90,407.51,6.64;5,105.49,625.86,22.69,6.64" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,329.99,601.95,160.88,6.64">Relevance weighting of search terms</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karen</forename><forename type="middle">Sparck</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,105.49,614.30,120.11,6.11">Document retrieval systems</title>
		<meeting><address><addrLine>London, UK, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Taylor Graham Publishing</publisher>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page">143160</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.50,645.78,407.51,6.64;5,105.49,658.14,407.51,6.11;5,105.49,669.69,172.44,6.64" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,205.82,645.78,249.86,6.64">Query expansion using local and global document analysis</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,463.35,646.18,49.65,6.11;5,105.49,658.14,407.51,6.11;5,105.49,670.09,89.42,6.11">Proceedings of the 19th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 19th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page">411</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
