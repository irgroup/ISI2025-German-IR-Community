<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,99.41,148.62,404.25,15.51;1,203.80,170.53,195.48,15.51">Different Multimodal Approaches using IR-n in ImageCLEFphoto 2008</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,197.85,204.00,62.66,9.96"><forename type="first">Sergio</forename><surname>Navarro</surname></persName>
							<email>snavarro@dlsi.ua.es</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing and Information Systems Group</orgName>
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,268.51,204.00,68.74,9.96"><forename type="first">Fernando</forename><surname>Llopis</surname></persName>
							<email>llopis@dlsi.ua.es</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing and Information Systems Group</orgName>
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,344.72,204.00,60.48,9.96"><forename type="first">Rafael</forename><surname>Mu√±oz</surname></persName>
							<email>rafael@dlsi.ua.es</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing and Information Systems Group</orgName>
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,99.41,148.62,404.25,15.51;1,203.80,170.53,195.48,15.51">Different Multimodal Approaches using IR-n in ImageCLEFphoto 2008</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0102D047E9C6EDF0052C02815FC94330</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.2 Information Storage H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2 [Database Managment]: H.2.5 Heterogenous Databases Measurement, Performance, Experimentation Information Retrieval, Image Retrieval, Multimodal Re-ranking, Late Fusion, Intermedia Pseudo Relevance Feedback, Multimodal Relevance Feedback, PRF, LCA, Visual Concepts</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the approach of the university of Alicante to the problem of finding a suitable handling of multimodal sources within the ImageCLEF ad-hoc competition. We have worked on to add modifications to the most common multimodal techniques used in the image retrieval area in order to improve their performance. Moreover, we have added a clustering module in order to increase the number of different clusters that can be found within the top 20 images returned. Finally, we have studied the effect of using visual concepts in the retrieval phase and in the clustering phase. We can see in the results that with these multimodal techniques we have improved up to a 27% our results in a MAP way, respect the ones obtained using our last year configuration -a textual run using PRF -. Furthermore, we have seen that the use of LCA in a multimodal way outperforms clearly the MAP and P20 results obtained with other common methods used -it has obtained 0.3436 MAP, 4th place in the published task results, and 0.4564 P20, 5th place in the published task results -. Finally our TF-IDF re-ranking run method has showed the best behaviour for the top 20 documents returned from our submissions, obtaining a F-measure value of 0.4051 -based on P20 and CR20 measures -. It makes us to conclude that the combination of these two mutimodal techniques will be the key for improving the performance in our system in future works.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This is the second time we are participating in the ImageCLEFphoto<ref type="foot" coords="2,399.66,132.40,3.97,6.37" target="#foot_0">1</ref> task. Our participation in ImageCLEFphoto of last year involved the use of an information retrieval system based on passages. We analyzed the suitability of our system for the short text annotations related to the images in the collection. We concluded that our system improved the results more in comparison to other systems, which were similar to our system except the fact that they did not use passages. The experiments also showed that relevance feedback is a good tool for improving results <ref type="bibr" coords="2,482.60,192.95,9.96,9.96" target="#b6">[7]</ref>.</p><p>However, we noticed that in spite of the improvements in the general results brought by the relevance feedback -we used PRF <ref type="bibr" coords="2,242.36,216.86,10.52,9.96" target="#b8">[9]</ref> relevance feedback strategy -, this process also adds wrong terms for the expansion in some of the cases. Thus, we believe that solving the problem of using non relevant documents for the expansion is an important issue, mainly because in our participation of this year we have planned to add to our system a content based information retrieval (CBIR) system -such systems use only visual information (image characteristic) for IR and nowadays this type of systems have low precision -. Thus, in order to avoid the great number of non relevant documents existent in the image based list, we need an accurate relevance feedback method. Such a solution could help our system to obtain more suitable terms for the expansion of the query.</p><p>So far, the most common relevance feedback strategy between the participants of ImageCLEFphoto task on last years edition was to use PRF <ref type="bibr" coords="2,295.42,324.46,10.52,9.96" target="#b8">[9]</ref> [4] [3] <ref type="bibr" coords="2,334.50,324.46,9.96,9.96" target="#b4">[5]</ref>. Thus, we are comparing in this CLEF edition it with the Local Context Analisy (LCA) <ref type="bibr" coords="2,310.43,336.41,15.51,9.96" target="#b9">[10]</ref> as an alternate strategy for a multimodal approach. This strategy has been used in other works within the image retrieval dominion, but only for textual retrieval not in a multimodal way <ref type="bibr" coords="2,311.24,360.32,14.61,9.96" target="#b10">[11]</ref>.</p><p>Furthermore we have added to our system a new operation mode that let to establish a multimodal re-ranking strategy based on mixing the ranking that IR-n returns with the ranking that a CBIR returns. We have experimented with two operation modes, one merges the two list in a classical re-ranking way, and the other mode bases the calculus of the relevance of an image on the quantity and the quality of the text related to the image in order to take the decision of which system is more confident for that image.</p><p>Moreover, in order to attempt to bridge the existent semantic gap between the image and the natural language we have taken the opportunity of experiment with the output of one of the participant systems in the visual detection task, which has been made available by the organization.</p><p>Finally, in order to improve the recall of the different image cluster detected within the 20 top ranked documents, we have added to our system a clustering module based on the image annotations and the visual concepts related to each image -returned by the visual concept detection system -.</p><p>This paper is structured as follows: Firstly, it presents the main characteristics of the IRn system focusing on the relevance feedback strategies, the multimodal re-ranking strategy, the handling of the image concept annotations and the clustering module, then it moves on to explain the experiments we have made to evaluate the system, and finally it describes the results and conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The IR-n System</head><p>In our approach, we used IR-n -an information retrieval system based on passages -. Passagebased IR systems treat each document as a set of passages, with each passage defining a portion of text or contiguous block of text. Unlike document-based systems, these systems can consider the proximity of words with each other, that appear in a document in order to evaluate their relevance <ref type="bibr" coords="2,90.00,678.10,9.96,9.96" target="#b5">[6]</ref>.</p><p>The IR-n passage-based system differs from other systems of the same category with regard to the method proposed for defining the passage -that is -using sentences as unit. Thus, passages are defined by a number of consecutive sentences in a document <ref type="bibr" coords="2,372.77,713.97,9.96,9.96" target="#b5">[6]</ref>. IR-n uses stemmer and stopword lists to determine which information in a document will be used for retrieval. For a list of stemmers and stopwords used by IR-n, see www.unine.ch/infor/clef. IR-n uses several weighting models. Weighting models allow the quantification of the similarity between a text -a complete document or a passage in a document -and a query. Values are based on the terms that are shared by the text and query and on the discriminatory importance of each term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Multimodal Relevance Feedback</head><p>Under a textual viewpoint, most IR systems use relevance feedback techniques <ref type="bibr" coords="3,433.15,217.40,9.96,9.96" target="#b0">[1]</ref>. These systems usually employ local feedback. The local feedback assumes that top-ranked documents are relevant. The added terms are, therefore, common terms from the top-ranked documents. Local feedback has become a widely used relevance feedback technique. Although, it can deter retrieval, in case most of the top-ranked documents are not relevant, results in TREC an CLEF conferences show that is an effective technique <ref type="bibr" coords="3,218.73,277.18,14.62,9.96" target="#b9">[10]</ref>.</p><p>In the selection of terms, PRF gives more importance to those terms which have a higher frequency in the top relevant documents than in the whole collection. An alternative query expansion method relies on the Local Context Analysis (LCA), based on the hypothesis that a common term from the top-ranked relevant documents will tend to co-occur with all query terms within the top-ranked documents. That is an attempt to avoid including terms from top-ranked, non-relevant documents in the expansion. Furthermore, in the case of polysemus words, this method will help to retrieve documents more related to the sense of the query, since it is logical to think that the user will use words from the domain associated with this sense to complete the query.</p><p>The IR-n architecture allows us to use query expansion based on either the most relevant passages or the most relevant documents.</p><p>Under a multimodal viewpoint, relevance feedback involves the use of two systems, each one threats with a type of media -text or image -. The n-top documents returned by one system are used to enrich the query before use it as input of the other system.</p><p>For our multimodal approach we have used the n-top ranked documents from the baseline run of the FIRE system <ref type="bibr" coords="3,180.14,468.47,10.52,9.96" target="#b1">[2]</ref> -it was supplied by the task organization -. In order to select the terms to expand the query processed by IR-n, the system lets us to select between PRF and LCA term expansion strategies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Multimodal Re-ranking Strategy</head><p>This strategy involve the merging of the list returned by the text based IR system and the list returned by the CBIR system. That is done giving a different weight to the normalized relevance value or ranking position for a document in each list. We have included the classical re-ranking strategy and also a variation of it in order to try to improve it and to compare its behaviour.</p><p>In the re-ranking strategy, the IR-n list and the CBIR list are merged in order to obtain one final list with documents ranked by relevance -the final relevance (FR) -. The merging process was done by giving different importance to the visual relevance (VR) given for a document in the visual list and the textual relevance (TR) given by the textual IR system:</p><formula xml:id="formula_0" coords="3,209.51,646.25,303.48,9.96">F R(d) = T R(d) * wT ext + V R(d) * wImg (1)</formula><p>where d is a document.</p><p>where V R is a normalized value of the relevance value returned by the CBIR for a document.</p><p>where T R is a normalized value of the relevance value returned by the textual IR system for a document.</p><p>Despite this strategy usually improves the results, it usually adds a great number of non relevant images in the ranking. That is due to the low precision that CBIR systems usually obtains. It makes that when we use an image of the CBIR list there are a high level of probability to be selecting a non relevant image.</p><p>In an effort for overcome this circumstance, we have modified the re-ranking strategy. We have based our approach on two assumptions. On one hand that the textual list is more confident than the list based on images and on the other hand we assume that the TF-IDF formula is a suitable way to measure the quantity and the quality of a text.</p><p>In order to reduce to the minimum the number or non relevant images used from the image based list, we have established a TF-IDF threshold <ref type="bibr" coords="4,322.66,218.95,11.63,9.96" target="#b1">(2)</ref>. The images which annotations have a TF-IDF value over this threshold are skipped.</p><formula xml:id="formula_1" coords="4,214.75,254.81,298.24,9.96">threshold = (M axT F IDF * tImg)/100<label>(2)</label></formula><p>M axT F IDF is the maximum TF-IDF value found in the image list.</p><p>tImg is a user defined parameter which indicates the percentage value respect the M axT T IDF in order to work out the threshold.</p><p>Thus, in the ranking formula (3) the system uses the threshold in order to avoid the risk of use the CBIR relevance values for those images which annotations have enough quantity and quality of text to perform a suitable textual retrieval -without the use of the image -.</p><formula xml:id="formula_2" coords="4,177.61,374.05,335.39,24.31">F R(d) = T R(d) + V R(d), if threshold &gt; T F IDF (d) T R(d), else<label>(3)</label></formula><p>where T F IDF is the TF-IDF value of the the text related to an image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Clustering Module</head><p>Usually, when the users performs a query in a IR system that works with images, they find that there are several similar images between top 20 results. Thus, if they want to find different relevant images they have to navigate through the rest of the returned list.</p><p>Our approach is a naive attempt to solve this problem using Carrot2<ref type="foot" coords="4,398.19,492.54,3.97,6.37" target="#foot_1">2</ref> an open source clustering engine for text. Our clustering module pass the query and the documents of the ranking listwhich optionally can be enriched with its related visual concepts -to Caroot2. It uses the texts passed to perform the clustering. For each cluster returned, our module selects in the ranking list the images with the best relevance within its cluster. If there are a number of clusters lower than twenty, the images without a cluster assigned are selected until complete the selection of twenty images. Afterwards, the module adds to the relevance value of the selected images the maximum relevance value in the whole list, in order to take up this images to the top 20 positions in the ranking.</p><p>We have worked with Lingo <ref type="bibr" coords="4,229.65,600.91,9.96,9.96" target="#b7">[8]</ref>, the default clustering algorithm of Carrot2. Lingo has 2 parameters that influence the number and contents of clusters is creates:</p><p>Cluster Assignment Threshold: determines how precise the assignment of documents to clusters should be. For low values of this threshold, Lingo will assign more documents to clusters, which will result in less documents ending up in "Other topics", but also some irrelevant documents making its way to the clusters. For high values of this parameter, Lingo will assign less documents to clusters, which will result in better assignment precision, but also more documents in "Other topics" and less clusters being created.</p><p>Candidate Cluster Threshold: determines how many clusters Lingo will try to create, higher values of the parameter will give more clusters. However, it is not possible to exactly predict the number of clusters based on the value of this parameter before clustering is actually run.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Training</head><p>IR-n is a parametrizable system, which means that it can be adapted in line with the concrete characteristics of the task at hand. The parameters for this configuration are the number of sentences that form a passage, the weighting model to use, the type of expansion, the number of documents/passages on which the expansion is based, the average number of words per document, the use of multimodal relevance feedback, the use of multimodal re-ranking, the use of clustering and the use of visual concepts for the retrieval phase or the clustering phase. This section describes the training process that was carried out in order to obtain the best possible features for improving the performance of the system.</p><p>The collections and resources are described first, and the next section describes specific experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Collection</head><p>In this edition of ImageCLEFphoto the IAPR TC-12 collection has been used for the evaluation of the participant systems -it was used for the 2006 and 2007 editions too -.</p><p>Table <ref type="table" coords="5,131.77,378.29,4.98,9.96" target="#tab_0">1</ref> shows the characteristics extracted from the textual annotations in the collection using IR-n splitter. NoDocs: is the number of documents.</p><p>WDAvg: is the average of words by document.</p><p>WD Max: is the maximum number of words in a document.</p><p>SentAvg: is the average of sentences by document.</p><p>Sent Max: is the maximum number of sentences in a document.</p><p>Language: is the language of the collection.</p><p>IAPR TC-12 corpus uses a semi-structured format based on XML. Thus, as in our last participation we have used for the text retrieval the five text fields corresponding to the title (TI-TLE), description (DESCRIPTION), notes (NOTES), place (LOCATION), and date of the photo (DATES) as input for IR-n.</p><p>The queries also have a semi-structured format, this year the organization has employed the same queries than the last two years, but with two additional tag, the cluster tag, which defines how the clustering of images should take place, and the narrative field, which obtain a longer description about the topic. We can see an example of a query in the Figure <ref type="figure" coords="5,425.68,685.20,3.87,9.96" target="#fig_0">1</ref>, there we saw how the text within the narrative tag contains relevant terms for the query, as 'church', 'cathedral' or 'mosque'. Despite that we have the belief that narrative field contains relevant information that could be very useful for a successful query expansion, in order to work with a more realistic environment, where the user does not give this kind of long descriptions, we only have used the title field for our participation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experiments</head><p>The experiment phase aims to establish the optimum values for the configuration of the system for the collection. We have worked in the training phase with the query subset of this year jointly with the extra data distributed by the organization. A 2007 GIFT baseline run and the output of the visual concept detection system developed by Thomas Desealers from RWTH Aachen University.</p><p>Below is a description of the input parameters of the system:</p><p>The Passage size (ps): Number of sentences in a passage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Weight model (wm):</head><p>We used DFR weighting model.</p><p>Relevance Feedback (relFB): Indicating which relevance feedback uses the system -PRF, LCA -and if its the multimodal version -MM -.</p><p>Relevance Feedback parameters: If exp has value 1, this denotes we use relevance feedback based on passages. But, if exp has value 2, the relevance feedback is based on documents. Moreover, num denotes the number of passages or documents that the relevance feedback will use from the textual ranking, ncbir denotes the number of documents that the multimodal relevance feedback will use from an image based list and finally, term indicates the k terms extracted from the best ranked passages or documents from the original query.</p><p>Visual Concept (vcon): Indicate if the system has to use the visual concept detection module for the retrieval.</p><p>Multimodal Re-ranking Strategy (rr): Indicate if the system has to use the multimodal re-ranking strategy, and which one. The standard one -RR -or TF-IDF version -RRidf -Multimodal Re-ranking parameters: wT xt and wImg, are the weight of the textual list and the image based list respectively in the standard re-ranking formula. And tImg is the percentage respect the M axF IDF value found in the image list which the system use to calculate the threshold in order to perform the TF-IDF multimodal re-ranking process.</p><p>Clustering (clust): Indicate if the system has to use the clustering module and whether for the input it has to use the visual concepts annotation jointly with the textual annotations -clustC value -or it only has to use the textual annotations -clust value -.</p><p>For the experiments we have worked with a passage size of 3, and with DFR as the weighting schema. We have taken this decision based on the training results obtained on last edition.</p><p>In respect the training of the clustering module, we have not done any experiment due to we do not have any training query set to help us with the best clustering parameters selection in order to increase the number of cluster selected between the 20 top ranked images returned. We have set for all the clustering runs a value of 0.5 for the cluster assignment parameter that is the default value used by Carrot and a value of 20 clusters for the candidate cluster parameter -in order to set within the top 20 ranked images an image pertaining to each cluster -.</p><p>In the next tables we show the results obtained in the training phase. In order to evaluate the experiments, we use as evaluation measure the Mean Average Precision (MAP).</p><p>In the Table <ref type="table" coords="7,164.79,183.08,4.98,9.96" target="#tab_1">2</ref> we show the best configurations obtained for each combination of vcon and relF B, in order to compare the performance of the different relevance feedback techniques used depending of the use of visual concept or not . On one hand we can see that while for the textual relevance feedback runs, the system has obtained better results when it has used visual concepts. On the other hand the use of visual concepts has decreased the performance of the multimodal and baseline runs. It is important to highlight that LCA usually uses a greater number of document for the expansion than PRF, And it is important to highlight too, that for the multimodal runs, PRF best run uses a low number of documents of the top ranked documents of each list -textual list and image based list -while the best LCA run only uses a greater amount of documents of the image based list. It could be explained by the good performance of the LCA method discriminating the non relevant documents of the image based list and by the more enriching terms added by the relevant annotations related to the image based list than the annotations related to the textual list. Since that the relevant documents of the image based list must give access to annotations with terms which a textual IR system difficulty could access -.</p><p>Table <ref type="table" coords="7,131.96,554.38,4.98,9.96" target="#tab_2">3</ref> show us in a synthesized way the relevance feedback results -the data are presented in decreasing order of MAP -in order to make easier the comparison between LCA and PRF. We can see how LCA obtains better results for all the runs that use multimodal information -multimodal relevance feedback and/or visual concepts -. In order to compare the two basic methods for mixing multimodal results -multimodal reranking and multimodal relevance feedback -. For the re-ranking experiments, we only have mixed with the FIRE baseline list the output returned by the best baselines and the best textual relevance feedback runs. The following table -Table <ref type="table" coords="8,327.08,123.31,4.98,9.96" target="#tab_3">4</ref> -shows us the re-ranking configurations which best results returned -the data are presented in decreasing order of re-ranking map -. We can see how the re-ranking always improves the results, and how small is the difference between the results of the two strategies -RR and RRidf -.</p><p>The optimal parameters for almost all RR runs is to use a weight of 0.6 for the textual list and 0.4 for the image based list. And for all the RRidf runs 60% is the best value in order to obtain the TF-IDF threshold which decide for each image whether its annotation is enough to evaluate its relevance or is need it the normalized relevance value of the CBIR system for that image in order to add it to the textual relevance.</p><p>Finally, the MAP results obtained using the clustering module with each one of the previous runs -the baseline runs, the best multimodal relevance feedback runs and the best multimodal re-ranking runs -are showed in the Table <ref type="table" coords="8,279.21,384.61,3.87,9.96" target="#tab_4">5</ref>. In this table the data are presented in decreasing order of clustering MAP -. We can see definitely that despite clustering get worse results in MAP way -we expected it happen -the use of visual concepts in the clustering phase improves the performance of the clustering module in comparision. Moreover, we can see in this global results that LCA has been used in all the top ranked runs.</p><p>For our participation in ImageCLEFphoto08 we have sent 10 runs corresponding with the runs showed in the Table <ref type="table" coords="8,201.33,672.23,3.87,9.96">6</ref>. We have selected for the TEXT modality the best run of the training process with and without clustering for which has not been used any image resource, neither visual concepts nor CBIR list. For the MIXED modality we have sent the best run for each combination of V isualConcept, M M , RR and RRIDF techniques with and without clustering using visual concepts .</p><p>As we expected a major finding of these results is that in MAP terms LCA has obtained a better performance than PRF in a multimodal environment. In fact, it has been the key that has allowed to select more accurately the relevant documents within the image baseline list, avoiding the great number of non relevant documents that a CBIR system usually ranks between the top documents returned.</p><p>With respect to the multimodal TF-IDF re-ranking, it has showed that for the top 20 documents returned it accomplishes its objective of incrementing the precision and the variety of images using the CBIR output only when the textual information is not enough. Indeed the worse results obtained with the TF-IDF re-ranking than with the standard re-ranking when they used clustering, are a probe of the good performance of the TF-IDF re-ranking method. Since that the textual clustering drops from the top ranked result the images without meaningful annotations. The fact that TF-IDF re-ranking has had more penalty with the clustering, means that it is returning a greater number of relevant images with annotations without clustering..</p><p>In future works we would like to extend the experiments with LCAMM to other query sets and even to other collections in order confirm what seems by this results a more confident method for the multimodal relevance feedback expansion. Furthermore, in an attempt of improving the global MAP results of the TF-IDF re-ranking, we will study its modification, in order to limit the images used for the re-ranking. Since an image with poor annotations and a medium CBIR relevance value, has low probabilities of being a relevant image. And finally, we will work in experimenting with the joining of LCAMM and TF-IDF re-ranking methods in order to improve the performance of our system..</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgement</head><p>This research has been partially funded by the Spanish Government within the framework of the TEXT-MESS (TIN-2006-15265-C06-01) project and by European Union (EU) within the framework of the QALL-ME project (FP6-IST-033860).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,228.22,118.27,146.56,9.96"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Metadata File Example</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,104.94,419.28,359.24,68.26"><head>Table 1 :</head><label>1</label><figDesc>Data Collection</figDesc><table coords="5,104.94,429.05,359.24,58.50"><row><cell cols="6">NoDocs WDAvg WD Max SentAvg Sent Max Language</cell></row><row><cell>20.000</cell><cell>38,2</cell><cell>118</cell><cell>2,6</cell><cell>6</cell><cell>English</cell></row><row><cell cols="3">Bellow is a descriptions of Table 1 columns:</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,140.54,237.77,321.91,147.20"><head>Table 2 :</head><label>2</label><figDesc>Best Relevance Feedback Configurations</figDesc><table coords="7,140.54,249.47,321.91,135.49"><row><cell>relFB</cell><cell>vcon</cell><cell>c</cell><cell cols="4">avgld exp num ncbir</cell><cell>k</cell><cell>map</cell></row><row><cell>NO</cell><cell>NO</cell><cell>8.5</cell><cell>120</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0.2373</cell></row><row><cell>NO</cell><cell>YES</cell><cell>6</cell><cell>120</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0.2296</cell></row><row><cell>PRF</cell><cell>NO</cell><cell>8</cell><cell>80</cell><cell>2</cell><cell>5</cell><cell>0</cell><cell>5</cell><cell>0.2710</cell></row><row><cell>LCA</cell><cell>NO</cell><cell>8.5</cell><cell>120</cell><cell>1</cell><cell>5</cell><cell>0</cell><cell cols="2">5 0.2667</cell></row><row><cell>PRF</cell><cell>YES</cell><cell>9</cell><cell>40</cell><cell>2</cell><cell>5</cell><cell>0</cell><cell cols="2">10 0.2756</cell></row><row><cell>LCA</cell><cell>YES</cell><cell>8.5</cell><cell>40</cell><cell>2</cell><cell>15</cell><cell>0</cell><cell>5</cell><cell>0.2853</cell></row><row><cell>PRF MM</cell><cell>NO</cell><cell>6</cell><cell>120</cell><cell>2</cell><cell>5</cell><cell>5</cell><cell cols="2">5 0.3206</cell></row><row><cell cols="2">LCA MM NO</cell><cell>6</cell><cell>40</cell><cell>2</cell><cell>0</cell><cell>20</cell><cell>5</cell><cell>0.3430</cell></row><row><cell>PRF MM</cell><cell>YES</cell><cell>8</cell><cell>40</cell><cell>1</cell><cell>5</cell><cell>5</cell><cell cols="2">20 0.3192</cell></row><row><cell>LCA MM</cell><cell>YES</cell><cell>8</cell><cell>40</cell><cell>2</cell><cell>0</cell><cell>20</cell><cell cols="2">20 0.3337</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,205.88,621.57,193.06,83.09"><head>Table 3 :</head><label>3</label><figDesc>Best Relevance Feedback Results</figDesc><table coords="7,205.88,631.34,193.06,73.32"><row><cell></cell><cell></cell><cell></cell><cell>PRF</cell><cell>LCA</cell></row><row><cell cols="3">vcon map 0 MM</cell><cell>map</cell><cell>map</cell></row><row><cell>NO</cell><cell cols="3">0.2373 YES 0.3206</cell><cell>0.3430</cell></row><row><cell>YES</cell><cell cols="3">0.2296 YES 0.3192</cell><cell>0.3337</cell></row><row><cell>YES</cell><cell>0.2296</cell><cell>NO</cell><cell>0.2756</cell><cell>0.2853</cell></row><row><cell>NO</cell><cell>0.2373</cell><cell>NO</cell><cell>0.2710</cell><cell>0.2667</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,142.12,166.04,322.05,85.02"><head>Table 4 :</head><label>4</label><figDesc>Best Re-ranking Results</figDesc><table coords="8,142.12,177.74,322.05,73.32"><row><cell></cell><cell></cell><cell>NoRR</cell><cell></cell><cell></cell><cell>RR</cell><cell>%</cell><cell>RRidf</cell></row><row><cell cols="2">relFB vcon</cell><cell>map</cell><cell cols="2">wTxt wImg</cell><cell>map</cell><cell>tImg</cell><cell>map</cell></row><row><cell>LCA</cell><cell>YES</cell><cell>0.2853</cell><cell>0.6</cell><cell>0.4</cell><cell>0.3120</cell><cell>60</cell><cell>0.3095</cell></row><row><cell>PRF</cell><cell>NO</cell><cell>0.2710</cell><cell>0.6</cell><cell>0.4</cell><cell>0.2943</cell><cell>60</cell><cell>0.2938</cell></row><row><cell>NO</cell><cell>YES</cell><cell>0.2296</cell><cell>0.5</cell><cell>0.5</cell><cell>0.2780</cell><cell>60</cell><cell>0.2791</cell></row><row><cell>NO</cell><cell>NO</cell><cell>0.2373</cell><cell>0.6</cell><cell>0.4</cell><cell>0.2785</cell><cell>60</cell><cell>0.2785</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,184.16,427.35,234.66,159.15"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table coords="8,184.16,427.35,234.66,159.15"><row><cell></cell><cell></cell><cell cols="2">Clustering Results</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>map</cell><cell>map</cell></row><row><cell>strategy</cell><cell>vcon</cell><cell>map 0</cell><cell>clust</cell><cell>clustC</cell></row><row><cell>LCAMM</cell><cell>NO</cell><cell>0.3430</cell><cell>0.3070</cell><cell>0.3260</cell></row><row><cell>LCAMM</cell><cell>YES</cell><cell>0.3337</cell><cell>0.2777</cell><cell>0.3038</cell></row><row><cell>LCA RR</cell><cell>YES</cell><cell cols="2">0.3120 0.2738</cell><cell>0.2917</cell></row><row><cell cols="2">LCA RRIDF YES</cell><cell>0.3095</cell><cell>02688</cell><cell>0.2837</cell></row><row><cell>PRF RRIDF</cell><cell>NO</cell><cell>0.2938</cell><cell>0.2523</cell><cell>0.2656</cell></row><row><cell>LCA</cell><cell>YES</cell><cell>0.2853</cell><cell>0.2473</cell><cell>0.2648</cell></row><row><cell>PRF RR</cell><cell>NO</cell><cell>0.2943</cell><cell>0.2498</cell><cell>0.2645</cell></row><row><cell>PRF</cell><cell>NO</cell><cell>0.2710</cell><cell>0.2314</cell><cell>0.2437</cell></row><row><cell>NO</cell><cell>NO</cell><cell>0.2373</cell><cell>0.2050</cell><cell>0.2157</cell></row><row><cell>NO</cell><cell>YES</cell><cell>0.2296</cell><cell>0.1966</cell><cell>0.2056</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,105.25,733.59,93.74,7.97"><p>http://www.imageclef.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,105.25,713.63,85.88,7.97"><p>http://www.carrot2.org</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Table <ref type="table" coords="9,117.57,133.17,4.98,9.96">6</ref> shows us the official results obtained by our mixed runs and textual runs respectively in the imageCLEFphoto08 task, we have found a not meaningful difference in our MAP values with the official ones. It has been due to we were using an older version of the trec eval tool for the experiments than the one used by the organization of the task. The data are presented in decreasing order of F-measure. We have worked out this value basing in the official P20 and CR20 measures published by the organization. We use F-measure in order to evaluate which run is the most balanced for P20 and CR20 measures, according with the objective of the task for this year.</p><p>Observing the results we can see that despite LCAMM is the best run in MAP and P20 measures -LCAMM has obtained 0.3436 MAP, 4th place in the published task results, and 0.4564 P20, 5th place in the published task results -. The low result in CR20 shades its good performance. Furthermore, we see that TF-IDF re-ranking obtains our best F-measure result, and it is very close to the 10 best ones published by the organization, in F-measure terms -1st task run 0.4650, 10th task run 0.4148 and our run 0.4051-. In deed all the TF-IDF runs which not use clustering always have better F-meassure than the standard re-ranking runs.</p><p>Moreover, we see that clustering always decreases the f-meassure, due to this reason, it affects always very negatively the P20 precision, however it does not improve too many the -CR20measure. Indeed, it decreases the CR20 measure too for all the TF-IDF re-ranking runs.</p><p>Finally we would like to highlight that our best textual run has reached the 6th place in terms of F-measure within the 10 best results published by the organizations in this modality -1st task run 0.4008, 10th task run 0.2861 and our run 0.3015 -.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="10,110.48,505.16,402.51,9.96;10,110.47,517.11,402.52,9.96;10,110.47,529.07,402.51,9.96;10,110.47,541.02,402.55,9.96;10,110.47,552.98,30.46,9.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,259.21,505.16,253.77,9.96;10,110.47,517.11,122.82,9.96">Combining Query Translation and Document Translation in Cross-Language Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Aitao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fredric</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,145.30,529.41,235.53,9.18">4th Workshop of the Cross-Language Evaluation Forum</title>
		<title level="s" coord="10,444.79,529.41,68.19,9.18;10,110.47,541.02,236.41,9.96">Lecture notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</editor>
		<meeting><address><addrLine>CLEF; Trondheim, Norway</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
	<note>Lecture notes in Computer Science</note>
</biblStruct>

<biblStruct coords="10,110.48,572.25,402.51,9.96;10,110.47,584.21,184.58,9.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,257.06,572.25,251.18,9.96">Features for image retrieval: An experimental comparison</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,110.47,584.54,92.98,9.18">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="77" to="107" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,603.48,402.50,9.96;10,110.47,615.43,402.52,9.96;10,110.47,627.39,265.55,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,134.41,615.43,265.37,9.96">Ipal at imageclef 2007 mixing features, models and knowledge</title>
		<author>
			<persName coords=""><forename type="first">Sheng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean-Pierre</forename><surname>Chevallet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thi</forename><surname>Hoang Diem Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Trong Ton</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joo Hwee</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,420.55,615.77,92.44,9.18;10,110.47,627.73,94.99,9.18">Working Notes of the 2007 CLEF Workshop</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">September 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,646.66,402.52,9.96;10,110.47,658.61,402.50,9.96;10,110.47,670.57,374.92,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,328.12,658.61,159.11,9.96">Tia-inaoes participation at imageclef</title>
		<author>
			<persName coords=""><forename type="first">Aurelio</forename><surname>Lpez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">Jair</forename><surname>Escalante</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><forename type="middle">A</forename><surname>Hernndez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Heidy</forename><forename type="middle">M</forename><surname>Marn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Manuel</forename><surname>Montes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eduardo</forename><surname>Morales</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luis</forename><forename type="middle">E</forename><surname>Sucar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luis</forename><surname>Villaseor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,122.93,670.91,191.91,9.18">Working Notes of the 2007 CLEF Workshop</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">2007. September 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,689.84,402.53,9.96;10,110.47,701.79,402.52,9.96;10,110.47,713.75,293.81,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,256.24,701.79,140.67,9.96">Dcu and uta at imageclefphoto</title>
		<author>
			<persName coords=""><forename type="first">Anni</forename><surname>Jrvelin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Wilkins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tomasz</forename><surname>Adamek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eija</forename><surname>Airio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Gareth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alan</forename><forename type="middle">F</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eero</forename><surname>Smeaton</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Sormunen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,446.63,702.13,66.36,9.18;10,110.47,714.09,123.26,9.18">Working Notes of the 2007 CLEF Workshop</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">2007. September 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,733.02,402.52,9.96;10,110.47,744.97,154.61,9.96" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Llopis</surname></persName>
		</author>
		<title level="m" coord="10,187.98,733.36,296.08,9.18">IR-n: Un Sistema de Recuperacin de Informacin Basado en Pasajes</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>University of Alicante</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="11,110.48,111.36,402.52,9.96;11,110.48,123.31,402.53,9.96;11,110.48,135.26,79.34,9.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,418.45,111.36,94.55,9.96;11,110.48,123.31,262.13,9.96">Information Retrieval of Visual Descriptions with IR-n System based on Passages</title>
		<author>
			<persName coords=""><forename type="first">Sergio</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Llopis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rafael</forename><surname>Mu√±oz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Elisa</forename><surname>Noguera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,110.48,135.60,48.72,9.18">CLEF 2007</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>In on-line Working Notes</note>
</biblStruct>

<biblStruct coords="11,110.48,155.18,402.52,9.96;11,110.48,167.15,402.51,9.96;11,110.48,179.10,63.64,9.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,370.74,155.18,142.26,9.96;11,110.48,167.15,211.83,9.96">Lingo: Search results clustering algorithm based on singular value decomposition</title>
		<author>
			<persName coords=""><forename type="first">Stanislaw</forename><surname>Osinski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jerzy</forename><surname>Stefanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dawid</forename><surname>Weiss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,344.56,167.48,136.35,9.18">Intelligent Information Systems</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="359" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,110.48,199.02,402.52,9.96;11,110.47,210.98,278.42,9.96" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,283.75,199.02,157.03,9.96">Relevance weighting of search terms</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">Sparck</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,450.89,199.36,62.11,9.18;11,110.47,211.31,181.63,9.18">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="129" to="146" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,110.48,230.90,402.51,9.96;11,110.47,242.86,265.18,9.96" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,245.29,230.90,267.70,9.96;11,110.47,242.86,68.23,9.96">Improving the effectiveness of information retrieval with local context analysis</title>
		<author>
			<persName coords=""><forename type="first">Jinxi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,187.23,243.20,97.04,9.18">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="112" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,110.48,262.79,402.52,9.96;11,110.47,274.74,252.41,9.96" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,246.89,262.79,266.10,9.96;11,110.47,274.74,45.84,9.96">A review of text and image retrieval approaches for broadcast news video</title>
		<author>
			<persName coords=""><forename type="first">Rong</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hauptmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,165.04,275.08,92.97,9.18">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4-5</biblScope>
			<biblScope unit="page" from="445" to="484" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
