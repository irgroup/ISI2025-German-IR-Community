<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,103.90,148.86,395.20,15.15;1,217.74,170.78,167.51,15.15">Overview of the ImageCLEFmed 2008 medical image retrieval task</title>
				<funder ref="#_rDgZfa2">
					<orgName type="full">University of Applied Sciences Western Switzerland (HES SO)</orgName>
				</funder>
				<funder ref="#_SmhXrvB">
					<orgName type="full">Swiss National Science Foundation (FNS)</orgName>
				</funder>
				<funder ref="#_QFCtybp">
					<orgName type="full">American National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,110.13,204.67,68.10,8.74"><forename type="first">Henning</forename><surname>Müller</surname></persName>
							<email>henning.mueller@sim.hcuge.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Medical Informatics</orgName>
								<orgName type="institution">University Hospitals and University of Geneva</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University of Applied Sciences Western Switzerland</orgName>
								<address>
									<settlement>Sierre</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,195.13,204.67,123.43,8.74"><forename type="first">Jayashree</forename><surname>Kalpathy-Cramer</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Oregon Health and Science University (OHSU)</orgName>
								<address>
									<settlement>Portland</settlement>
									<region>OR</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,329.12,204.67,83.91,8.74"><forename type="first">Charles</forename><forename type="middle">E</forename><surname>Kahn</surname><genName>Jr</genName></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">Medical College of Wisconsin</orgName>
								<address>
									<settlement>Milwaukee</settlement>
									<region>WI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,427.51,204.67,58.12,8.74"><forename type="first">William</forename><surname>Hatt</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Oregon Health and Science University (OHSU)</orgName>
								<address>
									<settlement>Portland</settlement>
									<region>OR</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,229.80,218.62,65.20,8.74"><forename type="first">Steven</forename><surname>Bedrick</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Oregon Health and Science University (OHSU)</orgName>
								<address>
									<settlement>Portland</settlement>
									<region>OR</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,305.55,218.62,63.19,8.74"><forename type="first">William</forename><surname>Hersh</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Oregon Health and Science University (OHSU)</orgName>
								<address>
									<settlement>Portland</settlement>
									<region>OR</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,103.90,148.86,395.20,15.15;1,217.74,170.78,167.51,15.15">Overview of the ImageCLEFmed 2008 medical image retrieval task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1FE9B353163181967C61AE882D1DA8AD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Managment]: Languages-Query Languages Measurement, Performance, Experimentation Image Retrieval, Performance Evaluation, Image Classification, Medical Imaging</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>2008 was the fifth year for the medical image retrieval task of ImageCLEF, one of the most popular tracks within CLEF. Participation continued to increase in 2008. A total of 15 groups submitted 111 valid runs. Several requests for data access were also received after the registration deadline.</p><p>The most significant change in 2008 was the use of a new database containing images from the medical literature. These images, part of the Goldminer collection, were from the RSNA journals Radiology and Radiographics. Besides the images, the figure captions and the part of the caption referring to a particular sub figure were supplied to the participants. Access to the full text articles in HTML was also provided, as was each article's Medline PMID (PubMed Identifier). An article's PMID could be used to obtain the officially assigned MeSH (Medical Subject Headings) terms. Unlike previous years, this year's collection was entirely in English, as it was obtained from English-language medical literature. However, the topics were, as in previous years, supplied in German, French, and English. The topics used in 2008 were a subset of the 85 topics used in 2005-2007. Thirty topics were made available, ten in each of three categories: visual, mixed, and semantic.</p><p>As in previous years, most groups concentrated on fully automatic retrieval. However, three groups submitted a total of seven manual or interactive runs; these runs did not show a substantial increase in performance over the automatic approaches. In previous years, multi-modal combinations were the most frequent submissions. However, in 2008 only half as many mixed runs as purely textual runs were submitted. Very few fully visual runs were submitted, and the ones submitted performed poorly. This may be explained in part by the heavily semantic nature of the 2008 topics.</p><p>The best MAP scores were very similar for textual and multi-modal approaches, whereas early precision performance was clearly better for the multi-modal approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>ImageCLEF 1 <ref type="bibr" coords="2,151.17,231.45,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="2,163.35,231.45,7.75,8.74" target="#b1">2,</ref><ref type="bibr" coords="2,172.75,231.45,7.75,8.74" target="#b4">5]</ref> started within CLEF 2 (Cross Language Evaluation Forum, <ref type="bibr" coords="2,447.15,231.45,10.79,8.74" target="#b5">[6]</ref>) in 2003. A medical image retrieval task was added in 2004 to explore domain-specific multilingual visual information retrieval and also multi-modal retrieval by combining visual and textual features for retrieval. A medical retrieval task and a medical image annotation task have been part of ImageCLEFmed since 2005 <ref type="bibr" coords="2,212.23,279.27,9.96,8.74" target="#b4">[5]</ref>.</p><p>This paper reports on the medical retrieval task whereas additional papers describe the four other tasks of ImageCLEF. More detailed information can also be found on the task web pages for ImageCLEFmed. A detailed analysis of a previous medical image retrieval task is available in <ref type="bibr" coords="2,90.00,327.10,9.96,8.74" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The medical retrieval task in 2008</head><p>The main change in the medical retrieval task in 2008 was the use of a new database. The search tasks remained essentially the same as in the previous years. The collection distributed to the participants included the images and the captions, as published in the medical journals. URLs to access the full text of the journal article were also made available to the participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Registration and participation</head><p>As in previous years, registration for the medical retrieval task increased in 2008, albeit slowly. Several of the groups registered solely to obtain the test collection in order to use it as training data for their algorithms, rather than actually participating in the competition. In the end, 15 research groups submitted a total of 130 runs. Groups were asked to not submit more than ten runs in 2008 (different from previous years) so as not to bias the pools too much towards any single group.</p><p>There were significant problems with many of the 130 initial runs: some were submitted in incorrect formats; several runs were duplicated; and there were runs that provided search results for only a subset of the thirty topics. These problems were corrected in collaboration with the authors as much as was possible, resulting in 111 valid runs that were used to generate the pools that were finally judged for relevance. The following groups submitted valid runs:</p><p>• Hungarian Acadamy of Sciences, Budapest, Hungary;</p><p>• National Library of Medicine (NLM), National Institutes of Health NIH, Bethesda, MD, USA;</p><p>• Bania Luka University, Bosnia-Hercegovina;</p><p>• MedGIFT group, University of Geneva, Switzerland;</p><p>• Natural Language Processing group, University Hospitals of Geneva, Switzerland;</p><p>• GPLSI group, University of Alicante, Spain;</p><p>1 http://www.imageclef.org/ 2 http://www.clef-campaign.org/</p><p>• Multimedia Modelling Group, LIG, Grenoble, France;</p><p>• Natural Language Processing at UNED. Madrid, Spain;</p><p>• Miracle group, Spain;</p><p>• Oregon Health and Science University (OHSU), Portland, OR, USA;</p><p>• IRIT Toulouse, France;</p><p>• University of Jaen, Spain;</p><p>• Tel Aviv University, Israel;</p><p>• National University of Bogota, Colombia;</p><p>• TextMess group, University of Alicante, Spain.</p><p>Thus, a total of 15 groups from eight countries and four continents submitted results that are presented in the following chapters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Database</head><p>The database used for the task in 2008 was made available by the Radiological Society of North America (RSNA). The database contains in total slightly more than 66,000 images taken from the radiological journals Radiology and Radiographics. The images are original figures used in published articles. The collection is a subset of a larger database that is available via the Goldminer<ref type="foot" coords="3,114.93,375.66,3.97,6.12" target="#foot_0">3</ref> image search engine. For each image, the text of the figure caption was supplied as free text. However, this caption was sometimes associated with a multi-part image. In over 90% of the images the part of the caption actually referring to this sub-image was also provided. Additionally, links to HTML versions of the full-text articles were provided along with the relevant PubMed accession ID numbers. Both the full-size images as well as thumbnails were available to the participants. All text was in English. The contents of this database represent a broad and significant body of medical knowledge, which makes this year's competition a potentially realistic scenario for how clinicians might use image retrieval systems in the future.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Query topics</head><p>The query topics in 2008 were a selection of 30 topics from the previous three years of Image-CLEFmed <ref type="bibr" coords="3,139.16,530.28,9.96,8.74" target="#b3">[4]</ref>. Training data in the form of the 2005-2007 database with images, annotations, topics, sample query images and qrel files was made available to participants. All topics were supposed to cover at least two of the following axes:</p><p>• Anatomic region shown in the image;</p><p>• Image modality (x-ray, CT, MRI, gross pathology, ...);</p><p>• View (frontal, sagittal,...);</p><p>• Pathology or disease shown in the image;</p><p>• abnormal visual observation (eg. enlarged heart).</p><p>From the 85 possible topics of past years, similar topics were removed to cover a wide range of different modalities and anatomic regions. A visual and textual check was then performed to make sure that at least a few relevant images exist in the dataset. Since the databases of 2008 and 2007 were very different, we wanted to ensure that each topic had more than one relevant image exist.</p><p>Each query topic consists of the information need in three languages (English, French, German) and at least two example images. Groups could decide which language and media to use for the query processing and also which part of the text to use.</p><p>A new system for relevance judgments was introduced in 2008 building on a Ruby for Rails framework and allowing for simple judgments via a web interface for all judges. The first 35 images of every run were combined into "pools" with an average size of around 900 images. Such pooling is necessary to reduce the amount of data to judge, and the bias can be regarded as very limited <ref type="bibr" coords="4,123.59,178.23,9.96,8.74" target="#b6">[7]</ref>. Medical Doctors who are also students of biomedical informatics at OHSU were hired for the judgment process and paid by the hour for the judgments.</p><p>A ternary judgment scheme was used, wherein each image in each pool was judged to be "relevant", "partly relevant", or "non-relevant". Images clearly corresponding to all criteria were judged as "relevant", images whose relevance could not be safely confirmed but could still be possible were marked as "partly relevant", and images for which one or more criteria of the topic were not met were marked as "non-relevant". Judges were instructed in these criteria and results were manually controlled during the judgment process.</p><p>During the judging, the new system exhibited a minor problem that resulted in certain images losing their judgments. This resulted in a short delay in the judging process, after which the affected images were re-judged by the same persons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Submissions and results</head><p>This section details the submissions for the tasks and a first brief evaluation. A more detailed evaluation of the techniques will follow in the final proceedings when more details on the techniques used for the submissions will be known. Unfortunately, information on the techniques used in the submissions is not always made available by the participants well ahead of time and in great detail.</p><p>Trec eval was used for the evaluation process with most of its performance measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Submissions</head><p>A total of 130 runs were submitted via the electronic submission system. Scripts to check the validity of the runs were made available to participants ahead of the submission phase, but even so, almost half of the submitted runs contained errors in either content or format and required changes. Common mistakes included a wrong trec eval format, use of only a subset of the topics and incorrect image identifiers. In collaboration with the authors a large number of runs were repaired, resulting in 111 valid runs taken into account for the pools. In total, only seven runs were "manual" or "interactive". There were also fewer "visual-only" runs than in all previous years, with only 8 such runs being submitted. The large majority were text-only runs, with 65 submissions. Mixed automatic runs had 31 submissions.</p><p>Groups subsequently had the chance to evaluate additional runs themselves as the qrels were made available to participants two weeks ahead of the submission deadline for these working notes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Visual retrieval</head><p>The number of visual runs in 2008 was much lower than in previous years, and the evolution is not as fast as with textual retrieval techniques. Five groups submitted a total of eight runs in 2008. Performance as measured in MAP is very low for all these runs, reaching a maximum of 0.04 for the best run. Early precision averaged over all topics reaches around 0.2, which is absolutely acceptable. When taking into account only the visual topics these results are much better, whereas the purely semantic topics obtained extremely poor results.</p><p>Table <ref type="table" coords="4,132.61,684.21,4.98,8.74" target="#tab_0">1</ref> shows the results and particularly the large differences between the runs. Some runs managed to retrieve a larger part of the relevant images (809) but with a fairly low MAP, whereas some runs with a higher MAP only found a very small number of relevant images in the first 1000 results. A higher bpref in this context can mean that a larger number of images from these runs were not judged for relevance. This might also be due to the fact that only very few visual runs were submitted and thus only few visually retrieved documents were finally judged. Results of GIFT were available to the all the participants for combinations of visual and textual runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Textual retrieval</head><p>Purely automatic textual retrieval had by far the largest number of runs in 2008 with 65, more than half of all submitted runs. Table <ref type="table" coords="5,260.13,327.75,4.98,8.74" target="#tab_1">2</ref> shows the results for all submitted automatic text runs, ordered by MAP. Most performance measures such as bpref and early precision are similar in order. Only early precision sometimes has significant differences from the ranking with MAP.</p><p>Runs from the University of Alicante (Textmess), University of Jaen (SINAI), and LIG Grenoble teams obtained the best results, mainly by using ontologies such as MeSH (Medical Subject Headings) to code the documents. A MAP of 0.29 could be obtained and several systems have a high score very close to this. A more detailed analysis is required with the exact techniques applied for each of the runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Using various languages for the retrieval</head><p>Unfortunately, very little information was available on which languages the groups used for the retrieval. It can be assumed that most groups used English as this promises the best results. It was also possible to use all three query languages together, for example, for extracting MeSH terms. While this multi-lingual approach is not necessarily a realistic scenario, it can lead to interesting results.</p><p>The HUG group used the same techniques with several languages and showed that English obtained by far the best results, better than either French or German. The technique they applied was to map of MeSH terms form the text and queries in various languages. Through the PMIDs, the officially (manually) assigned MeSH terms of the articles were also available. The MeSH terms extracted from the article and query text performed worse for retrieval than the officially assigned terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Additional resources used for the retrieval</head><p>Groups could also state which additional resources were used for retrieval. The goal of this was to assemble a collection of available resources that could potentially be shared among participants to improve performance in future challenges. A large variety of resources were used, in large part for the combination of visual and textual runs, but also for purely textual runs. Many of the best runs used the ImageCLEFmed 2005-2007 data for training. Official MeSH terms manually assigned by the National Library of Medicine could be used through the PMIDs of the articles.</p><p>The most commonly used resources were the training data sets of ImageCLEF 2005-2007. There were numerous challenges with this approach, as the database used from 2005-07 differed greatly from the 2008 database. The annotations in the '05-07 database were of much poorer quality than in the 2008 database, and the two databases were made up of very different types  of images. Nonetheless, the 2008 topics were a subset of those from previous years' competitions, and so the scenario was somewhat realistic with respect to the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Mixed retrieval</head><p>The promotion of mixed-media retrieval has always been one of the main goals of ImageCLEF.</p><p>In past years, mixed-media retrieval had the highest submission rate. In 2008, however, only half as many mixed runs were submitted than purely textual runs. Table <ref type="table" coords="7,131.74,559.88,4.98,8.74" target="#tab_2">3</ref> shows the results for all submitted runs. It is clear that, for a large number of the runs, the MAP results for the mixed retrieval submissions were very similar to those from the purely textual retrieval systems. An interesting observation is that the mixed-media submissions often have higher early precision than the purely textual retrieval submissions. This confirms what has been previously observed.</p><p>The text-only runs exhibited relatively high correlation between MAP and bpref. This was not the case among the mixed-media runs. One possible explanation for this difference could be that the mixed-media runs used a wider variety of techniques than the text-only runs. Another possible explanation is that more of the mixed-media runs were submitted after the deadline for pool inclusion. If the mixed-media runs retrieved a higher proportion of non-judged images than the text-only runs, the result would be a larger MAP/bpref variance.</p><p>When comparing these mixed-media results with those from the text-only runs, it becomes clear that mixed retrieval can obtain very low results. From examining mixed-media runs which had corresponding text-only runs, it is particularly clear that combining good textual retrieval techniques with questionable visual retrieval techniques can negatively affect system performance. This demonstrates the difficulty of usefully integrating both textual and visual information, and the fragility that such combinations can introduce into retrieval systems. As seen in 1, the distribution of MAP for the textual runs was higher than that for the mixed runs. A significant mode exists around a MAP of 0.05 for the mixed runs, while the modes for the textual runs are at 0.15 and 0.28. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Interactive retrieval</head><p>This year, as in previous years, interactive retrieval was only used by a very small number of participants. Interactive retrieval is extremely important, and it is a pity so few groups chose to attempt anything other than purely automated systems. Table <ref type="table" coords="8,132.10,576.85,4.98,8.74" target="#tab_3">4</ref> shows the results of all manual and interactive runs submitted. Two runs from OHSU had fairly good results; the other runs were competitive in neither the MAP nor the early precision categories when compared to the fully automatic runs. In general, MAP and early precision were well-correlated (R 2 = 0.82 for textual runs, 0.68 for mixed runs); these two runs, however, had higher early precision than their MAP would predict.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6">Topic Analysis</head><p>Overall, most groups performed significantly better on the semantic topics than on the mixed or visual topics, as can be seen in the table below. Topics 6 and 11-18 were quite difficult for many participants. Table <ref type="table" coords="8,178.12,694.86,4.98,8.74" target="#tab_4">5</ref> gives an overview of the best and average perform per topic. Some topics with a small number of relevant images have a particularly low performance.</p><p>The fact that many of the visual topics obtained poorer performance than the semantic topics also shows that groups have much more experience working on semantic topics, and that visual retrieval currently has much more difficulty obtaining good results. That said, visual retrieval can have an important positive influence, and it seems necessary to promote it further by having potentially a larger number of visual topics to push groups towards using visual techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7">Inter-rater agreement</head><p>Four topics were each judged by two judges. We performed tests of inter-rater agreements using kappa statistics, as seen in table <ref type="table" coords="10,238.73,280.43,3.87,8.74" target="#tab_5">6</ref>. In 3 of the four cases, the inter-rater agreement was quite good. In the last case, one judge interpreted the query more strictly than the other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>The focus of many participants in this year's ImageCLEF 2008 has been text-based retrieval.</p><p>The increasingly semantic topics combined with a database containing high-quality annotations in 2008 may have resulted in less impact of using visual techniques as compared to previous years. This tendency is also seen when looking at the performance by topic where visual topics had significantly lower results than the semantic topics. Our goal in the upcoming ImageCLEF medical retrieval task is to increase the number of visual runs submitted. We hope to modify the task to favor more integrated approaches. Another important aspect is that interactive retrieval has always had a poor participation and definitely needs to be regarded more strongly. Relevance feedback and query modifications have a potential to significantly improve results, but of course research favors laboratory style evaluations. Visual runs were rare and had no single run with a very convincing performance as was the case in 2007, where the best visual runs had an extremely good performance. Mixed-media runs were very similar in performance to textual runs when looking at MAP. The only difference was that mixed-media runs obtained better early precision in general. Several mixed-media runs were also broken, resulting in a very poor performance. This highlights that the combination is still not very stable.</p><p>A per-topic analysis shows that visual topics obtained lower average results than semantic topics. The analysis also shows that several runs with very few relevant images have a very low average performance, whereas topics with a larger number seem to perform better.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="8,154.30,301.40,294.40,8.74"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Histogram of MAP for textual and mixed automatic runs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,108.29,118.94,386.42,103.89"><head>Table 1 :</head><label>1</label><figDesc>Results of the automatic runs using only visual information.</figDesc><table coords="5,108.29,130.26,386.42,92.57"><row><cell>Run</cell><cell>run type</cell><cell cols="2">MAP bpref</cell><cell>P5</cell><cell>P10</cell><cell>P30</cell><cell>num rel</cell></row><row><cell>TAU MIPLAB-TAU norm</cell><cell>Visual Automatic</cell><cell>0.04</cell><cell>0.09</cell><cell cols="3">0.22 0.17 0.15</cell><cell>568</cell></row><row><cell>UNAL-W+QE+JS</cell><cell>Visual Automatic</cell><cell>0.04</cell><cell>0.06</cell><cell cols="3">0.13 0.13 0.11</cell><cell>297</cell></row><row><cell>GE GIFT8</cell><cell>Visual Automatic</cell><cell>0.03</cell><cell>0.09</cell><cell cols="3">0.17 0.17 0.15</cell><cell>809</cell></row><row><cell>MIPLAB-TAU orig</cell><cell>Visual Automatic</cell><cell>0.03</cell><cell>0.08</cell><cell cols="3">0.16 0.14 0.11</cell><cell>519</cell></row><row><cell>etfbl-max11111</cell><cell>Visual Automatic</cell><cell>0.03</cell><cell>0.04</cell><cell cols="3">0.15 0.13 0.11</cell><cell>212</cell></row><row><cell>etfbl-sum11111</cell><cell>Visual Automatic</cell><cell>0.03</cell><cell>0.04</cell><cell cols="3">0.12 0.10 0.12</cell><cell>194</cell></row><row><cell>GE GIFT16</cell><cell>Visual Automatic</cell><cell>0.03</cell><cell>0.07</cell><cell cols="3">0.13 0.13 0.11</cell><cell>670</cell></row><row><cell>LSI UNED</cell><cell>Visual Automatic</cell><cell>0.02</cell><cell>0.03</cell><cell cols="3">0.11 0.11 0.08</cell><cell>94</cell></row><row><cell>CEB Image</cell><cell>Visual Automatic</cell><cell>0.01</cell><cell>0.04</cell><cell cols="3">0.03 0.04 0.05</cell><cell>390</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,111.48,118.94,380.03,633.90"><head>Table 2 :</head><label>2</label><figDesc>Results of the automatic runs using only text.</figDesc><table coords="6,111.48,130.26,380.03,622.58"><row><cell>Run</cell><cell>run type</cell><cell cols="2">MAP bpref</cell><cell>P5</cell><cell>P10</cell><cell>P30</cell><cell>num rel</cell></row><row><cell>EXPPRFNegativaMesh</cell><cell>Text Automatic</cell><cell>0.29</cell><cell>0.35</cell><cell cols="3">0.49 0.46 0.41</cell><cell>2165</cell></row><row><cell>sinai CT Mesh</cell><cell>Text Automatic</cell><cell>0.28</cell><cell>0.33</cell><cell cols="3">0.44 0.41 0.37</cell><cell>2106</cell></row><row><cell>LIG COS0506 MPTT Emi</cell><cell>Text Automatic</cell><cell>0.28</cell><cell>0.34</cell><cell cols="3">0.51 0.47 0.43</cell><cell>2224</cell></row><row><cell>LIG-LIG MPTT Emix</cell><cell>Text Automatic</cell><cell>0.28</cell><cell>0.34</cell><cell cols="3">0.43 0.45 0.43</cell><cell>2138</cell></row><row><cell>TEXTMESSmeshType CT</cell><cell>Text Automatic</cell><cell>0.28</cell><cell>0.32</cell><cell cols="3">0.43 0.41 0.37</cell><cell>2106</cell></row><row><cell>IRn2baseline</cell><cell>Text Automatic</cell><cell>0.28</cell><cell>0.33</cell><cell cols="3">0.48 0.42 0.35</cell><cell>1986</cell></row><row><cell>IRn2ExpNeg</cell><cell>Text Automatic</cell><cell>0.28</cell><cell>0.33</cell><cell cols="3">0.45 0.40 0.34</cell><cell>2006</cell></row><row><cell>LIG RET MPTT Emix</cell><cell>Text Automatic</cell><cell>0.27</cell><cell>0.34</cell><cell cols="3">0.46 0.45 0.41</cell><cell>2129</cell></row><row><cell>LIG COS MPTT Emix</cell><cell>Text Automatic</cell><cell>0.27</cell><cell>0.33</cell><cell cols="3">0.47 0.47 0.43</cell><cell>2275</cell></row><row><cell>LIG CR MPTT Emix</cell><cell>Text Automatic</cell><cell>0.27</cell><cell>0.33</cell><cell cols="3">0.48 0.47 0.41</cell></row><row><cell>IRn2ExpNegMesh</cell><cell>Text Automatic</cell><cell>0.27</cell><cell>0.32</cell><cell cols="3">0.45 0.42 0.36</cell><cell>2038</cell></row><row><cell>MirBaselineEN</cell><cell>Text Automatic</cell><cell>0.27</cell><cell>0.32</cell><cell cols="3">0.51 0.47 0.39</cell><cell>1861</cell></row><row><cell>IRn2Explca</cell><cell>Text Automatic</cell><cell>0.26</cell><cell>0.33</cell><cell cols="3">0.45 0.41 0.35</cell><cell>2096</cell></row><row><cell>LIG RET MP Emix</cell><cell>Text Automatic</cell><cell>0.26</cell><cell>0.32</cell><cell cols="3">0.47 0.45 0.42</cell><cell>1979</cell></row><row><cell>IRn2ExpPRF</cell><cell>Text Automatic</cell><cell>0.26</cell><cell>0.32</cell><cell cols="3">0.47 0.41 0.36</cell><cell>1980</cell></row><row><cell>LIG MP Emix</cell><cell>Text Automatic</cell><cell>0.25</cell><cell>0.33</cell><cell cols="3">0.45 0.42 0.43</cell><cell>2007</cell></row><row><cell>MirAPEN</cell><cell>Text Automatic</cell><cell>0.25</cell><cell>0.31</cell><cell cols="3">0.49 0.46 0.39</cell><cell>1773</cell></row><row><cell>sinai CT Base</cell><cell>Text Automatic</cell><cell>0.25</cell><cell>0.31</cell><cell cols="3">0.32 0.35 0.33</cell><cell>2030</cell></row><row><cell>MirTaxEN</cell><cell>Text Automatic</cell><cell>0.25</cell><cell>0.32</cell><cell cols="3">0.38 0.37 0.37</cell><cell>1867</cell></row><row><cell>LIG-LIG COS MP Emix</cell><cell>Text Automatic</cell><cell>0.24</cell><cell>0.31</cell><cell cols="3">0.45 0.41 0.41</cell><cell>2120</cell></row><row><cell>LIG-LIG CR MP Emix</cell><cell>Text Automatic</cell><cell>0.24</cell><cell>0.31</cell><cell cols="3">0.47 0.40 0.39</cell><cell>2108</cell></row><row><cell>sinai CT Umls</cell><cell>Text Automatic</cell><cell>0.23</cell><cell>0.27</cell><cell cols="3">0.37 0.35 0.30</cell><cell>1927</cell></row><row><cell>bp acad textonly</cell><cell>Text Automatic</cell><cell>0.22</cell><cell>0.28</cell><cell cols="3">0.49 0.43 0.35</cell><cell>1726</cell></row><row><cell>Ssinai CTA Mesh</cell><cell>Text Automatic</cell><cell>0.21</cell><cell>0.27</cell><cell cols="3">0.46 0.40 0.29</cell><cell>1683</cell></row><row><cell>ohsu text umls 4</cell><cell>Text Automatic</cell><cell>0.20</cell><cell>0.30</cell><cell cols="3">0.31 0.29 0.25</cell><cell>1973</cell></row><row><cell>sinai CTA Base</cell><cell>Text Automatic</cell><cell>0.20</cell><cell>0.27</cell><cell cols="3">0.41 0.36 0.30</cell><cell>1702</cell></row><row><cell>LIG-LIG MPadd Emix</cell><cell>Text Automatic</cell><cell>0.19</cell><cell>0.29</cell><cell cols="3">0.34 0.37 0.34</cell><cell>2032</cell></row><row><cell>sinai CTS Base</cell><cell>Text Automatic</cell><cell>0.18</cell><cell>0.25</cell><cell cols="3">0.33 0.31 0.31</cell><cell>1790</cell></row><row><cell>sinai CTA Umls</cell><cell>Text Automatic</cell><cell>0.18</cell><cell>0.25</cell><cell cols="3">0.35 0.32 0.32</cell><cell>1553</cell></row><row><cell>HUG-MH-EN</cell><cell>Text Automatic</cell><cell>0.18</cell><cell>0.24</cell><cell cols="3">0.34 0.30 0.22</cell><cell>1957</cell></row><row><cell>HUG-MHnOVID-EN</cell><cell>Text Automatic</cell><cell>0.18</cell><cell>0.24</cell><cell cols="3">0.34 0.30 0.22</cell><cell>1957</cell></row><row><cell>sinai CTS Mesh</cell><cell>Text Automatic</cell><cell>0.16</cell><cell>0.24</cell><cell cols="3">0.32 0.29 0.27</cell><cell>1828</cell></row><row><cell>HUG-ltc-EN</cell><cell>Text Automatic</cell><cell>0.16</cell><cell>0.23</cell><cell cols="3">0.31 0.28 0.20</cell><cell>1713</cell></row><row><cell>HUG-mixPapers EN</cell><cell>Text Automatic</cell><cell>0.15</cell><cell>0.21</cell><cell cols="3">0.33 0.27 0.20</cell><cell>1883</cell></row><row><cell>ohsu text 3</cell><cell>Text Automatic</cell><cell>0.15</cell><cell>0.23</cell><cell cols="3">0.39 0.31 0.22</cell><cell>1786</cell></row><row><cell>sinai CTS Umls</cell><cell>Text Automatic</cell><cell>0.14</cell><cell>0.21</cell><cell cols="3">0.23 0.21 0.21</cell><cell>1558</cell></row><row><cell>TEXTMESSumlsType CT</cell><cell>Text Automatic</cell><cell>0.14</cell><cell>0.17</cell><cell cols="3">0.33 0.32 0.25</cell><cell>1045</cell></row><row><cell>sigRunTxt</cell><cell>Text Automatic</cell><cell>0.14</cell><cell>0.19</cell><cell cols="3">0.29 0.24 0.22</cell><cell>858</cell></row><row><cell>HUG-BL EN</cell><cell>Text Automatic</cell><cell>0.14</cell><cell>0.21</cell><cell cols="3">0.31 0.26 0.24</cell><cell>1615</cell></row><row><cell>HUG-HUG-BL HUG-BL</cell><cell>Text Automatic</cell><cell>0.14</cell><cell>0.21</cell><cell cols="3">0.31 0.26 0.24</cell><cell>1615</cell></row><row><cell>HUG-capMH EN</cell><cell>Text Automatic</cell><cell>0.13</cell><cell>0.19</cell><cell cols="3">0.33 0.28 0.24</cell><cell>1499</cell></row><row><cell>HUG-capMH EN</cell><cell>Text Automatic</cell><cell>0.13</cell><cell>0.19</cell><cell cols="3">0.33 0.28 0.24</cell><cell>1499</cell></row><row><cell>OHSU-text or 1</cell><cell>Text Automatic</cell><cell>0.11</cell><cell>0.18</cell><cell cols="3">0.31 0.26 0.24</cell><cell>1420</cell></row><row><cell>HUG-ltc-FR</cell><cell>Text Automatic</cell><cell>0.11</cell><cell>0.18</cell><cell cols="3">0.19 0.20 0.16</cell><cell>1218</cell></row><row><cell>HUG-MH-FR</cell><cell>Text Automatic</cell><cell>0.11</cell><cell>0.17</cell><cell cols="3">0.19 0.17 0.16</cell><cell>1419</cell></row><row><cell>HUG-MHnOVID-FR</cell><cell>Text Automatic</cell><cell>0.11</cell><cell>0.17</cell><cell cols="3">0.19 0.17 0.16</cell><cell>1419</cell></row><row><cell>MirRF0505EN</cell><cell>Text Automatic</cell><cell>0.11</cell><cell>0.18</cell><cell cols="3">0.28 0.24 0.24</cell><cell>1372</cell></row><row><cell>HUG-MHnOVID-GE</cell><cell>Text Automatic</cell><cell>0.10</cell><cell>0.14</cell><cell cols="3">0.21 0.19 0.17</cell><cell>894</cell></row><row><cell>TEXTMESSmeshType CTS</cell><cell>Text Automatic</cell><cell>0.10</cell><cell>0.18</cell><cell cols="3">0.23 0.23 0.15</cell><cell>1828</cell></row><row><cell>HUG-ltc-GE</cell><cell>Text Automatic</cell><cell>0.09</cell><cell>0.14</cell><cell cols="3">0.17 0.16 0.13</cell><cell>869</cell></row><row><cell>HUG-capMH FR</cell><cell>Text Automatic</cell><cell>0.09</cell><cell>0.16</cell><cell cols="3">0.23 0.20 0.17</cell><cell>1364</cell></row><row><cell>TEXTMESSumlsType CTS</cell><cell>Text Automatic</cell><cell>0.09</cell><cell>0.14</cell><cell cols="3">0.23 0.23 0.16</cell><cell>933</cell></row><row><cell>CEB BaseC QE</cell><cell>Text Automatic</cell><cell>0.08</cell><cell>0.14</cell><cell cols="3">0.33 0.29 0.23</cell><cell>887</cell></row><row><cell>CCEB BaseC QE</cell><cell>Text Automatic</cell><cell>0.08</cell><cell>0.14</cell><cell cols="3">0.35 0.28 0.23</cell><cell>887</cell></row><row><cell>CEB BaseC</cell><cell>Text Automatic</cell><cell>0.08</cell><cell>0.14</cell><cell cols="3">0.31 0.28 0.22</cell><cell>893</cell></row><row><cell>MirRF1005EN</cell><cell>Text Automatic</cell><cell>0.07</cell><cell>0.15</cell><cell cols="3">0.22 0.16 0.15</cell><cell>1248</cell></row><row><cell>HUG-MH-GE</cell><cell>Text Automatic</cell><cell>0.07</cell><cell>0.11</cell><cell cols="3">0.17 0.15 0.14</cell><cell>866</cell></row><row><cell>HUG-BL-FR</cell><cell>Text Automatic</cell><cell>0.07</cell><cell>0.11</cell><cell cols="3">0.17 0.16 0.15</cell><cell>942</cell></row><row><cell>MirRFTax1005EN</cell><cell>Text Automatic</cell><cell>0.07</cell><cell>0.14</cell><cell cols="3">0.15 0.13 0.14</cell><cell>1260</cell></row><row><cell>MirRFTax1005FR</cell><cell>Text Automatic</cell><cell>0.07</cell><cell>0.11</cell><cell cols="3">0.13 0.11 0.09</cell><cell>823</cell></row><row><cell>MirRFTax1005DE</cell><cell>Text Automatic</cell><cell>0.05</cell><cell>0.08</cell><cell cols="3">0.09 0.09 0.06</cell><cell>461</cell></row><row><cell>CEB BaseM</cell><cell>Text Automatic</cell><cell>0.04</cell><cell>0.09</cell><cell cols="3">0.20 0.17 0.15</cell><cell>532</cell></row><row><cell>HUG-BL-GE</cell><cell>Text Automatic</cell><cell>0.03</cell><cell>0.05</cell><cell cols="3">0.07 0.06 0.06</cell><cell>432</cell></row><row><cell>HUG-capMH GE</cell><cell>Text Automatic</cell><cell>0.03</cell><cell>0.05</cell><cell cols="3">0.07 0.06 0.06</cell><cell>432</cell></row><row><cell>CEB BaseC QE</cell><cell>Text Automatic</cell><cell>0.02</cell><cell>0.03</cell><cell cols="3">0.06 0.05 0.04</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,110.92,118.94,381.16,312.11"><head>Table 3 :</head><label>3</label><figDesc>Results of the automatic runs mixing text and visual information.</figDesc><table coords="7,110.92,130.26,381.16,300.79"><row><cell>Run</cell><cell>run type</cell><cell cols="2">MAP bpref</cell><cell>P5</cell><cell>P10</cell><cell>P30</cell><cell>num rel</cell></row><row><cell>sinai CT Mesh Fire20</cell><cell>Mixed Automatic</cell><cell>0.29</cell><cell>0.33</cell><cell cols="3">0.45 0.43 0.40</cell><cell>2132</cell></row><row><cell cols="2">TEXTMESSmeshTypeFIREidf CT Mixed Automatic</cell><cell>0.28</cell><cell>0.32</cell><cell cols="3">0.43 0.41 0.37</cell><cell>2106</cell></row><row><cell>IRn2ExpNegRRIDF</cell><cell>Mixed Automatic</cell><cell>0.28</cell><cell>0.33</cell><cell cols="3">0.45 0.40 0.34</cell><cell>2006</cell></row><row><cell>IRn2ExpNegMeshRRIDF</cell><cell>Mixed Automatic</cell><cell>0.27</cell><cell>0.32</cell><cell cols="3">0.45 0.42 0.36</cell><cell>2038</cell></row><row><cell>ohsu vis mod umls 4</cell><cell>Mixed Automatic</cell><cell>0.23</cell><cell>0.35</cell><cell cols="3">0.41 0.37 0.28</cell><cell>2052</cell></row><row><cell>ohsu vis mod 5</cell><cell>Mixed Automatic</cell><cell>0.23</cell><cell>0.33</cell><cell cols="3">0.41 0.38 0.29</cell><cell>1995</cell></row><row><cell>EXTMESSmeshTypeFIRE CT</cell><cell>Mixed Automatic</cell><cell>0.22</cell><cell>0.27</cell><cell cols="3">0.30 0.30 0.30</cell><cell>2106</cell></row><row><cell>ohsu mod pars2 sp</cell><cell>Mixed Automatic</cell><cell>0.21</cell><cell>0.30</cell><cell cols="3">0.58 0.55 0.46</cell><cell>1561</cell></row><row><cell>OHSU vis mod 3</cell><cell>Mixed Automatic</cell><cell>0.15</cell><cell>0.25</cell><cell cols="3">0.41 0.32 0.24</cell><cell>1829</cell></row><row><cell cols="2">TEXTMESSumlsTypeFIREidf CT Mixed Automatic</cell><cell>0.14</cell><cell>0.17</cell><cell cols="3">0.33 0.32 0.25</cell><cell>1045</cell></row><row><cell cols="2">TEXTMESSumlsTypeFIRE CT Mixed Automatic</cell><cell>0.13</cell><cell>0.18</cell><cell cols="3">0.25 0.22 0.23</cell><cell>1045</cell></row><row><cell cols="2">TEXTMESSmeshTypeFIRE CTS Mixed Automatic</cell><cell>0.12</cell><cell>0.19</cell><cell cols="3">0.25 0.25 0.20</cell><cell>1828</cell></row><row><cell>SIG IRIT-SigRunMixt</cell><cell>Mixed Automatic</cell><cell>0.11</cell><cell>0.16</cell><cell cols="3">0.30 0.29 0.23</cell><cell>859</cell></row><row><cell cols="2">TEXTMESSumlsTypeFIRE CTS Mixed Automatic</cell><cell>0.09</cell><cell>0.15</cell><cell cols="3">0.21 0.22 0.21</cell><cell>928</cell></row><row><cell>GE GIFT8 EN 0.5</cell><cell>Mixed Automatic</cell><cell>0.08</cell><cell>0.19</cell><cell cols="3">0.27 0.24 0.24</cell><cell>1835</cell></row><row><cell>GE EN reGIFT8</cell><cell>Mixed Automatic</cell><cell>0.08</cell><cell>0.19</cell><cell cols="3">0.24 0.23 0.23</cell><cell>1957</cell></row><row><cell>GE EN GIFT8 mix</cell><cell>Mixed Automatic</cell><cell>0.08</cell><cell>0.19</cell><cell cols="3">0.28 0.24 0.25</cell><cell>1610</cell></row><row><cell>GE GIFT8 EN 0.9</cell><cell>Mixed Automatic</cell><cell>0.07</cell><cell>0.12</cell><cell cols="3">0.31 0.27 0.25</cell><cell>812</cell></row><row><cell>GE GIFT8 reEN</cell><cell>Mixed Automatic</cell><cell>0.07</cell><cell>0.12</cell><cell cols="3">0.29 0.24 0.25</cell><cell>812</cell></row><row><cell>IRn2ExpNegGiftRR</cell><cell>Mixed Automatic</cell><cell>0.05</cell><cell>0.11</cell><cell cols="3">0.13 0.12 0.11</cell><cell>830</cell></row><row><cell>IRIT-SigRunComb5</cell><cell>Mixed Automatic</cell><cell>0.05</cell><cell>0.10</cell><cell cols="3">0.28 0.24 0.17</cell><cell>793</cell></row><row><cell>IRIT-SigRunComb1</cell><cell>Mixed Automatic</cell><cell>0.05</cell><cell>0.10</cell><cell cols="3">0.28 0.25 0.17</cell><cell>791</cell></row><row><cell>IRIT-SigRunComb2</cell><cell>Mixed Automatic</cell><cell>0.05</cell><cell>0.10</cell><cell cols="3">0.28 0.24 0.16</cell><cell>789</cell></row><row><cell>IRIT-SigRunComb3</cell><cell>Mixed Automatic</cell><cell>0.05</cell><cell>0.10</cell><cell cols="3">0.27 0.24 0.16</cell><cell>782</cell></row><row><cell>IRIT-SigRunComb7</cell><cell>Mixed Automatic</cell><cell>0.04</cell><cell>0.09</cell><cell cols="3">0.25 0.22 0.16</cell><cell>805</cell></row><row><cell>IRIT-SigRunComb4</cell><cell>Mixed Automatic</cell><cell>0.04</cell><cell>0.09</cell><cell cols="3">0.25 0.22 0.16</cell><cell>770</cell></row><row><cell>IRIT-SigRunComb6</cell><cell>Mixed Automatic</cell><cell>0.04</cell><cell>0.09</cell><cell cols="3">0.25 0.22 0.16</cell><cell>771</cell></row><row><cell>IRIT-SigRunComb8</cell><cell>Mixed Automatic</cell><cell>0.04</cell><cell>0.09</cell><cell cols="3">0.24 0.22 0.16</cell><cell>817</cell></row><row><cell>CEB IBaseC</cell><cell>Mixed Automatic</cell><cell>0.04</cell><cell>0.13</cell><cell cols="3">0.17 0.15 0.10</cell><cell>893</cell></row><row><cell>CEB ITD3</cell><cell>Mixed Automatic</cell><cell>0.03</cell><cell>0.10</cell><cell cols="3">0.07 0.11 0.10</cell><cell>945</cell></row><row><cell>IRn2ExpNegMeshGiftRR</cell><cell>Mixed Automatic</cell><cell>0.03</cell><cell>0.08</cell><cell cols="3">0.11 0.11 0.09</cell><cell>662</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,110.80,118.94,381.40,83.02"><head>Table 4 :</head><label>4</label><figDesc>Results of the interactive and manual runs.</figDesc><table coords="8,110.80,128.32,381.40,73.64"><row><cell>Run</cell><cell>run type</cell><cell cols="2">MAP bpref</cell><cell>P5</cell><cell>P10</cell><cell>P30</cell><cell>num rel</cell></row><row><cell>ohsu int 2</cell><cell>Mixed Interactive</cell><cell>0.22</cell><cell>0.31</cell><cell cols="3">0.57 0.49 0.39</cell><cell>1580</cell></row><row><cell>ohsu sdb full interactive</cell><cell>Mixed Interactive</cell><cell>0.18</cell><cell>0.29</cell><cell cols="3">0.53 0.46 0.33</cell><cell>1626</cell></row><row><cell>ohsu sdb lsa</cell><cell>Mixed Interactive</cell><cell>0.10</cell><cell>0.20</cell><cell cols="3">0.27 0.27 0.27</cell><cell>1601</cell></row><row><cell>CEB ITD ALL</cell><cell>Mixed Manual</cell><cell>0.03</cell><cell>0.11</cell><cell cols="3">0.08 0.11 0.11</cell><cell>964</cell></row><row><cell>CEB IBaseM</cell><cell>Mixed Manual</cell><cell>0.02</cell><cell>0.10</cell><cell cols="3">0.08 0.08 0.06</cell><cell>532</cell></row><row><cell>CEB TD ALL</cell><cell>Text Manual</cell><cell>0.08</cell><cell>0.16</cell><cell cols="3">0.24 0.27 0.25</cell><cell>1198</cell></row><row><cell>CEB TD3</cell><cell>Text Manual</cell><cell>0.08</cell><cell>0.16</cell><cell cols="3">0.24 0.27 0.25</cell><cell>1189</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,90.00,273.54,431.26,312.66"><head>Table 5 :</head><label>5</label><figDesc>Best results and average for all topics, showing the significant differences between topics.</figDesc><table coords="9,95.98,294.87,52.89,6.99"><row><cell>Topic Topic</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="10,188.39,118.94,226.23,56.56"><head>Table 6 :</head><label>6</label><figDesc>Inter-rater reliability</figDesc><table coords="10,188.39,130.26,226.23,45.25"><row><cell cols="5">Topic Judge 1 Judge 2 Strict Kappa Lenient kappa</cell></row><row><cell>3.</cell><cell>User 3</cell><cell>User 4</cell><cell>0.91</cell><cell>0.95</cell></row><row><cell>5.</cell><cell>User 5</cell><cell>User 7</cell><cell>0.70</cell><cell>0.79</cell></row><row><cell>6.</cell><cell>User 3</cell><cell>User 5</cell><cell>0.48</cell><cell>0.48</cell></row><row><cell>25.</cell><cell>User 7</cell><cell>User 10</cell><cell>0.69</cell><cell>0.70</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="3,105.24,747.58,110.09,6.64"><p>http://goldminer.arrs.org/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to thank the CLEF campaign for supporting the ImageCLEF initiative. The images for the 2008 ImageCLEFmed challenge were contributed by the <rs type="institution">Radiological Society of North America (RSNA)</rs>. This work was partially funded by the <rs type="funder">Swiss National Science Foundation (FNS)</rs> under contract <rs type="grantNumber">205321-109304/1</rs>, the <rs type="funder">American National Science Foundation (NSF)</rs> with grant <rs type="grantNumber">ITR-0325160</rs>, and by the <rs type="funder">University of Applied Sciences Western Switzerland (HES SO)</rs> in the context of the <rs type="projectName">BeMeVIS</rs> project.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_SmhXrvB">
					<idno type="grant-number">205321-109304/1</idno>
				</org>
				<org type="funding" xml:id="_QFCtybp">
					<idno type="grant-number">ITR-0325160</idno>
				</org>
				<org type="funded-project" xml:id="_rDgZfa2">
					<orgName type="project" subtype="full">BeMeVIS</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="11,105.50,133.84,407.51,8.74;11,105.50,145.80,407.51,8.74;11,105.50,157.75,407.50,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,105.50,145.80,336.98,8.74">Overview of the ImageCLEF 2006 photo retrieval and object annotation tasks</title>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Allan</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,462.70,145.80,50.30,8.74;11,105.50,157.75,48.06,8.74">CLEF 2006 Proceedings</title>
		<title level="s" coord="11,227.31,157.75,189.13,8.74">Springer Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4730</biblScope>
			<biblScope unit="page" from="579" to="594" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,105.50,177.68,407.50,8.74;11,105.50,189.63,407.50,8.74;11,105.50,201.59,407.50,8.74;11,105.50,213.54,407.51,8.74;11,105.50,225.50,345.32,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,332.82,177.68,180.17,8.74;11,105.50,189.63,85.74,8.74">The CLEF cross-language image retrieval track (ImageCLEF)</title>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,327.67,201.59,185.33,8.74;11,105.50,213.54,294.45,8.74">Multilingual Information Access for Text, Speech and Images: Result of the fifth CLEF evaluation campaign</title>
		<title level="s" coord="11,481.67,213.54,31.33,8.74;11,105.50,225.50,149.00,8.74">Lecture Notes in Computer Science (LNCS</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Gareth</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Bernardo</forename><surname>Kluck</surname></persName>
		</editor>
		<editor>
			<persName><surname>Magnini</surname></persName>
		</editor>
		<meeting><address><addrLine>Bath, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004. 2005</date>
			<biblScope unit="volume">3491</biblScope>
			<biblScope unit="page" from="597" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,105.50,245.42,407.51,8.74;11,105.50,257.38,407.50,8.74;11,105.50,269.33,372.32,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,105.50,257.38,366.06,8.74">Advancing biomedical image retrieval: Development and analysis of a test collection</title>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeffery</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianji</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Gorman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Patrick</forename><surname>Ruch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,479.89,257.38,33.11,8.74;11,105.50,269.33,212.07,8.74">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="page" from="488" to="496" />
			<date type="published" when="2006-10">September/October. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,105.50,289.26,407.50,8.74;11,105.50,301.21,301.58,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,397.54,289.26,115.45,8.74;11,105.50,301.21,148.40,8.74">The imageclefmed medical image retrieval task test collection</title>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jayashree</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,262.29,301.21,114.07,8.74">Journal of Digital Imaging</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,105.50,321.14,407.50,8.74;11,105.50,333.09,407.50,8.74;11,105.50,345.05,407.50,8.74;11,105.50,357.00,278.25,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,304.57,333.09,208.43,8.74;11,105.50,345.05,130.78,8.74">Overview of the ImageCLEFmed 2007 medical retrieval and annotation tasks</title>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eugene</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jayashree</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">M</forename><surname>Deserno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,259.07,345.05,103.02,8.74">CLEF 2007 Proceedings</title>
		<title level="s" coord="11,440.60,345.05,72.40,8.74;11,105.50,357.00,108.75,8.74">Lecture Notes in Computer Science (LNCS</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">5152</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,105.50,376.93,407.50,8.74;11,105.50,388.88,407.51,8.74;11,105.50,400.84,22.69,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,173.94,376.93,152.86,8.74">Report on CLEF-2001 experiments</title>
		<author>
			<persName coords=""><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,348.16,376.93,164.84,8.74;11,105.50,388.88,154.42,8.74">Report on the CLEF Conference 2001 (Cross Language Evaluation Forum)</title>
		<meeting><address><addrLine>Darmstadt, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer LNCS</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page">2406</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,105.50,420.76,407.51,8.74;11,105.50,432.72,407.50,8.74;11,105.50,444.68,407.50,8.74;11,105.50,456.63,407.50,8.74;11,105.50,468.59,101.87,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,170.42,420.76,337.82,8.74">How reliable are the results of large-scale information retrieval experiments</title>
		<author>
			<persName coords=""><forename type="first">Justin</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,140.44,444.68,372.56,8.74;11,105.50,456.63,167.59,8.74">Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Alistair</forename><surname>Moffat</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ross</forename><surname>Wilkinson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Justin</forename><surname>Zobel</surname></persName>
		</editor>
		<meeting>the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Melbourne, Australia; New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1998-08">August 1998</date>
			<biblScope unit="page" from="307" to="314" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
