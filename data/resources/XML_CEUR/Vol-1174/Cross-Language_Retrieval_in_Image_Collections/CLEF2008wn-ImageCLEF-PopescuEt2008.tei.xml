<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,135.84,60.10,323.46,12.52">Conceptual image retrieval over the Wikipedia corpus</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,162.00,89.11,73.83,10.91"><forename type="first">Adrian</forename><surname>Popescu</surname></persName>
							<email>adrian.popescu@cea.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Multimedia Knowledge Engineering Laboratory)</orgName>
								<orgName type="institution">CEA-LIST LIC2M (Multilingual</orgName>
								<address>
									<addrLine>B., 6 -F92265</addrLine>
									<settlement>Fontenay-aux-roses Cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,244.20,89.11,80.61,10.91"><forename type="first">Hervé</forename><surname>Le Borgne</surname></persName>
							<email>herve.le-borgne@cea.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Multimedia Knowledge Engineering Laboratory)</orgName>
								<orgName type="institution">CEA-LIST LIC2M (Multilingual</orgName>
								<address>
									<addrLine>B., 6 -F92265</addrLine>
									<settlement>Fontenay-aux-roses Cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,333.25,89.11,99.76,10.91"><forename type="first">Pierre-Alain</forename><surname>Moëllic</surname></persName>
							<email>pierre-alain.moellic@cea.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Multimedia Knowledge Engineering Laboratory)</orgName>
								<orgName type="institution">CEA-LIST LIC2M (Multilingual</orgName>
								<address>
									<addrLine>B., 6 -F92265</addrLine>
									<settlement>Fontenay-aux-roses Cedex</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,135.84,60.10,323.46,12.52">Conceptual image retrieval over the Wikipedia corpus</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">38CD2D265344FF27B338841217F697A1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Image retrieval in large-scale databases is currently based on a textual chains matching procedure, a technique that produces good results as long as the annotations associated to pictures are accurate and detailed enough. These conditions are not met for a large majority of image corpuses, such as the Wikipedia collection, and it is interesting to explore methods that go beyond chain matching. In this paper, we present our approach to image retrieval, tested in the ImageCLEF 2008 WikipediaMM. The approach is based on a query reformulation using concepts that are semantically related to those in the initial query. For each interesting entity in the query, we used Wikipedia and WordNet to extract and list of related concepts, which were further ranked in order to propose the most salient in priority. We also made a list of visual concepts which were used in order to re-rank the answers to queries that included, implicitly or explicitly, these visual concepts. The CEA submitted two automatic runs, one based on query reformulation only and one combining query reformulation and visual concepts, which were ranked 4 th and 2 nd using the MAP measure.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The search for multimedia documents represents a growing trend in Web search. For this, new retrieval paradigms, going beyond text chains matching, are needed in order to better respond to user needs. Current image retrieval systems highly rely on text searching techniques and, although people search for images, the results are returned based on the associated text only. The results are obtained by simple match of the terms of the query to an index of terms associated to the images in a corpus. This technique is simple but its efficiency strongly depends on the terms associated to pictures, as well as their accuracy. For instance, in this paradigm, it would be impossible to know if a query with bridge regards the structures with this name or the cards game. If the request is relative to the first meaning of the term, the search engine would return only images explicitly annotated with bridge whereas it would be pertinent to propose answers for Pont Neuf or Ponte Vecchio. The exploitation of semantic structures represents a possible solution to cope with such problems if these structures are developed enough to cover the query space. In spite of flourishing research on content-based image retrieval <ref type="bibr" coords="1,320.89,514.13,15.43,9.05" target="#b16">[17]</ref>, the introduction of image processing techniques in image search engines architectures is limited, for the moment, to face detection (proposed by Google, Live Search or Exalead). The adoption of more image processing techniques is conditioned by the achievement of good quality results on large amounts of data and this imperative is not met in most cases <ref type="bibr" coords="1,334.69,548.69,15.43,9.05" target="#b25">[26]</ref>.</p><p>The introduction of conceptual structures and image processing techniques in image retrieval raises a number of hard questions and we try to tackle several of these questions in our work. Namely:</p><p>When dealing with large conceptual domains are there enough resources available or is it necessary to enrich them? Generic semantic structures, like WordNet <ref type="bibr" coords="1,292.82,606.17,10.69,9.05" target="#b6">[7]</ref>, exist and were used in image retrieval <ref type="bibr" coords="1,464.66,606.17,15.43,9.05" target="#b39">[40]</ref>, <ref type="bibr" coords="1,486.62,606.17,16.63,9.05" target="#b41">[42]</ref> but they do not ensure a sufficient coverage of the query space. Wikipedia is a rich source of semi-structured and has been used to structure large quantities of knowledge <ref type="bibr" coords="1,313.32,629.09,10.69,9.05" target="#b0">[1]</ref>, <ref type="bibr" coords="1,331.32,629.09,15.43,9.05" target="#b24">[25]</ref>. We exploit both WordNet and Wikipedia for extracting the information we need when processing the WikipediaMM queries. Should image processing techniques be introduced alone or should they be fused with other information? A large body of work <ref type="bibr" coords="1,172.56,663.65,15.43,9.05" target="#b39">[40]</ref>, <ref type="bibr" coords="1,194.76,663.65,15.33,9.05" target="#b41">[42]</ref>, <ref type="bibr" coords="1,216.72,663.65,16.63,9.05" target="#b38">[39]</ref> advocates for the use of both low level and high level image description in order to improve image search. We follow a somewhat similar approach and investigate a late fusion of textual information and low-level image description of items in the database.</p><p>What terms in a query should be reformulated? When dealing with mono-conceptual queries, the answer to this query is straightforward: if knowledge about that particular concept is available, we should use it to expand the query. The problem gets complicated for more complex queries because the number of reformulations becomes rapidly unmanageable. We consider that nouns are the most important part of image queries and focus the query expansion on them. Happily, the WikipediaMM queries follow the general distribution of Web queries and contain a hefty part of mono-conceptual queries.</p><p>The remainder of this paper is structured as follows: in the next section, we describe related work; in Section 3, we present our method for automatically building conceptual structures; in Section 4, we introduce the automatic query reformulation algorithm used in the WikipediaMM task and, before concluding, we discuss the results of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>We describe related work from several relevant research areas, including: information extraction, image retrieval, query reformulation, visual concepts detection. Wikipedia is a rich resource that is used in a variety of information extraction or structuring tasks. In <ref type="bibr" coords="2,502.20,155.33,15.43,9.05" target="#b34">[35]</ref>, the encyclopaedia is used to automatically construct lists of place and people names. <ref type="bibr" coords="2,390.37,166.85,16.75,9.05" target="#b24">[25]</ref> proposes a method for cleaning the categorical tree of Wikipedia in order to obtain a sound taxonomy. The result is compared to Cyc and the precision of the results reaches 86.6%, with a recall of 89.1%. Kazama et al. <ref type="bibr" coords="2,347.65,189.89,16.75,9.05" target="#b12">[13]</ref> introduce a syntaxic analysis of the first sentence in Wikipedia articles in order to extract IsA relations. These sentences are often definitional and the approach is successful in nearly 90% of the cases. <ref type="bibr" coords="2,225.01,212.93,16.75,9.05" target="#b42">[43]</ref> and <ref type="bibr" coords="2,262.44,212.93,16.75,9.05" target="#b43">[44]</ref> explore the automatic enrichment of WordNet using Wikipedia content. The authors try to extract hyponymy, hyperonymy, holonymy and meronymy relations based on lexical patterns learned from a text corpus. The overall precision of the extraction process exceeds 50% and there are a lot of incorrect relations that are extracted. DBPedia <ref type="bibr" coords="2,211.34,247.37,11.59,9.05" target="#b0">[1]</ref> is a translation of parts of Wikipedia articles to a database format, enabling structured queries over the content of the encyclopedia. The authors parse structured parts of the articles (such as info boxes, tables, or categories), which contain a fairly detailed description of the concepts described in the article and which can be later used in information retrieval tasks. The introduction of semantic structures in image retrieval architectures is a well-known practice. WordNet is exploited in a number of applications: to build a visual catalogue from the Web <ref type="bibr" coords="2,342.01,304.85,15.65,9.05" target="#b41">[42]</ref>; to propose lists of related concepts in <ref type="bibr" coords="2,519.00,304.85,15.56,9.05" target="#b39">[40]</ref>; to create multimodal similarity vectors (based on WordNet and on a visual description of the images) in <ref type="bibr" coords="2,477.12,316.37,10.90,9.05" target="#b7">[8]</ref>; to limit the conceptual neighbourhood where visually similar images are searched <ref type="bibr" coords="2,339.84,327.89,15.43,9.05" target="#b25">[26]</ref>. Wang et al. <ref type="bibr" coords="2,107.65,339.41,16.75,9.05" target="#b38">[39]</ref> reuse a taxonomy of animals created by the BBC (« BBC Science and Nature Animal Category »), which contains 620 terms. This taxonomy is enriched the description of the included concepts with visual information concerning the animal's color but also image properties (like outdoor/indoor image, photo/graph) and the result is called a multimedia ontology. They authors select 20 animal species, collect corresponding pictures from Google Image provide results for the precision at several ranks (P@20, P@40, P@60 and P@80), these values corresponding to one, two, three and four pages of results in a Web search engine. A comparison between Google Image, the use of a textual ontology and the use of a multimedia ontology and the average precision is best in the last setting, followed by the textual ontology. These results are interesting but they are limited to a specific domain, where the colour of the target concepts (animals) is stable.</p><p>Image queries reformulation based on semantic ressources is tested, among others, in <ref type="bibr" coords="2,407.89,442.85,16.51,9.05" target="#b10">[11]</ref> et <ref type="bibr" coords="2,437.89,442.85,15.43,9.05" target="#b11">[12]</ref>. In <ref type="bibr" coords="2,471.72,442.85,15.14,9.05" target="#b10">[11]</ref>, the authors exploit ConceptNet <ref type="bibr" coords="2,137.65,454.37,16.75,9.05" target="#b16">[17]</ref> to expand image queries and report a slight improvement of results (3% for a precision around 40%) when the query expansion is used. In <ref type="bibr" coords="2,242.77,465.89,15.43,9.05" target="#b11">[12]</ref>, the same group compares a WordNet based query expansion to a ConceptNet based one and conclude that the two semantic structures are complementary. The use of WordNet provides a better discrimination of the expanded queries whereas the use of ConceptNet results in more diversified queries. This finding is not surprising when considering the structure of the two resources, with ConceptNet including a larger number of inter-conceptual relations. <ref type="bibr" coords="2,211.58,511.85,16.75,9.05" target="#b44">[45]</ref> takes a different approach to query reformulation and discusses the use of query logs for expanding queries and structuring results.</p><p>Visual concepts detection has been a well studied problem in computer vision, including the work on object detection and scene recognition. It is often posed as a binary classification task consisting in deciding between the considered visual concept and other possible type of images. Hence, the general scheme of the works in this field consists of three main steps, namely region of interest detection, feature extraction and classification. Different proposals for one or several of these steps led to numerous approaches The regions of interest of an image are the spatial localizations the feature will be extracted in the next step. The simplest approach consists of considering no region of interest and extracting the features globally, as it was the case for seminal works in image classification <ref type="bibr" coords="2,210.26,626.81,10.89,9.05" target="#b8">[9,</ref><ref type="bibr" coords="2,223.82,626.81,11.86,9.05" target="#b32">33]</ref>. Such a holistic representation was shown to be particularly relevant in the case of scene recognition <ref type="bibr" coords="2,166.21,638.33,15.93,9.05" target="#b22">[23,</ref><ref type="bibr" coords="2,186.25,638.33,12.57,9.05" target="#b13">14,</ref><ref type="bibr" coords="2,202.93,638.33,11.86,9.05" target="#b15">16]</ref>. Among the alternatives considered in the literature to detect ROIs, one can distinguish between the following approaches: regular <ref type="bibr" coords="2,278.64,649.85,11.71,9.05" target="#b5">[6]</ref> or random <ref type="bibr" coords="2,338.04,649.85,16.75,9.05" target="#b21">[22]</ref> sampling of patches, image segmentation <ref type="bibr" coords="2,527.52,649.85,10.89,9.05" target="#b1">[2,</ref><ref type="bibr" coords="2,56.64,661.37,11.95,9.05" target="#b33">34]</ref>, or more often using interest point detectors <ref type="bibr" coords="2,249.62,661.37,15.91,9.05" target="#b28">[29,</ref><ref type="bibr" coords="2,268.08,661.37,11.86,9.05" target="#b18">19]</ref>.</p><p>Once the ROI are determined, a recognition system usually extracts some visual features. Numerous approaches were proposed since the seminal work of Swain and Ballard who used global colour histograms <ref type="bibr" coords="2,443.76,684.29,15.43,9.05" target="#b31">[32]</ref>, including various colour and texture descriptors <ref type="bibr" coords="2,184.21,695.81,15.43,9.05" target="#b19">[20]</ref>, wavelets <ref type="bibr" coords="2,246.25,695.81,15.93,9.05" target="#b29">[30,</ref><ref type="bibr" coords="2,266.16,695.81,13.39,9.05" target="#b36">37]</ref> and more recently local descriptors computed around interest points. This last trend consists of computing simple features on patches around interest points <ref type="bibr" coords="2,435.26,707.33,15.43,9.05" target="#b17">[18]</ref>, then aggregate them into a given number of clusters in order to define a visual vocabulary, that is former used to describe the images in term of "bag of features" <ref type="bibr" coords="2,138.61,730.37,15.93,9.05" target="#b37">[38,</ref><ref type="bibr" coords="2,157.20,730.37,12.45,9.05" target="#b9">10,</ref><ref type="bibr" coords="2,172.32,730.37,12.45,9.05" target="#b40">41,</ref><ref type="bibr" coords="2,187.44,730.37,7.53,9.05" target="#b4">5,</ref><ref type="bibr" coords="2,197.52,730.37,11.86,9.05" target="#b21">22]</ref>. An alternative to this scheme is to learn analysis filters from the learning images and define a signature from their responses <ref type="bibr" coords="2,231.25,741.89,15.93,9.05" target="#b14">[15,</ref><ref type="bibr" coords="2,249.73,741.89,11.84,9.05" target="#b15">16]</ref>.</p><p>The last important step of visual concept detection consists of learning each concept. At this level, various classifier have been used including SVM <ref type="bibr" coords="2,184.92,764.81,15.93,9.05" target="#b23">[24,</ref><ref type="bibr" coords="2,203.40,764.81,12.57,9.05" target="#b19">20,</ref><ref type="bibr" coords="2,218.52,764.81,11.86,9.05" target="#b15">16]</ref>, boosting <ref type="bibr" coords="2,273.72,764.81,15.43,9.05" target="#b36">[37]</ref>, Naïve Bayes <ref type="bibr" coords="2,348.84,764.81,15.93,9.05" target="#b29">[30,</ref><ref type="bibr" coords="2,367.32,764.81,7.26,9.05" target="#b4">5]</ref>, neural networks <ref type="bibr" coords="2,447.49,764.81,15.43,9.05" target="#b27">[28]</ref>, generative model <ref type="bibr" coords="3,56.64,58.73,10.69,9.05" target="#b5">[6]</ref>, graphical model <ref type="bibr" coords="3,140.53,58.73,16.75,9.05" target="#b20">[21]</ref> and, regularly, K-nearest neighbours from <ref type="bibr" coords="3,329.76,58.73,11.71,9.05" target="#b8">[9]</ref> to <ref type="bibr" coords="3,351.78,58.73,15.48,9.05" target="#b35">[36]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Automatic building of conceptual structures</head><p>The acquisition of knowledge related to concepts appearing in the queries is the key element of our image retrieval method. We aim at processing diversified queries and this implies and automatic building of conceptual structures. In this section, we briefly present the employed data sources, the extraction of related concepts and the ranking of the extracted terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Data sources</head><p>The main resource we exploited was Wikipedia. Dumps of the encyclopaedia are regularly provided for a free use <ref type="foot" coords="3,516.96,176.22,3.24,5.89" target="#foot_0">1</ref> . We downloaded the Mars 12, 2008 English dump, which contains over two millions articles and is provided as a single file, in XML format. Next, we split the dump into individual articles in order to process the information faster. The information in Wikipedia spans over a large number of conceptual domains, with a high number of articles describing known people, places, entertainment, organisations animals and plants. Each article is placed in at least one category, a property that facilitates the extraction of IsA relations from Wikipedia.</p><p>WordNet is a lexical database, including parts for different parts of speech, such as nouns, verbs or adjectives. As our approach focuses on nouns, we only used the nouns hierarchy which contains 117798 nominal chains, corresponding to 146312 senses. These nouns are grouped in 82115 sets of synonyms (or synsets), the sense separation being an interesting property for image retrieval tasks as it makes possible a separation of the different visual representation of the same terms. Out of the total number of synsets in WordNet, around 75% are common nouns and 25% are instances. That being, WordNet ensures an acceptable coverage for concepts but only a poor coverage of instances which have around 20000 associated synsets. For comparison, there are at least 80000 articles for person names in the English Wikipedia and around 300000 for place names<ref type="foot" coords="3,243.36,325.74,3.24,5.89" target="#foot_1">2</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Conceptual neighbourhood building</head><p>The text associated to the pictures in the WikipediaMM corpus is generally short, containing few terms. In this context, query reformulation is a way to improve recall and, if realized in a judicious way, to also improve the precision of the answers. In <ref type="bibr" coords="3,105.60,385.37,15.43,9.05" target="#b26">[27]</ref>, we showed that the use of subtypes of generic concepts like dog or skyscraper is beneficial in image retrieval. This hypothesis is justified by the fact that, from a visual perspective, a concept like dog is well represented by dog races such as German shepherd, Doberman or basset. For specific concepts, having no subtypes, it is possible to build a list of synonyms in order to reformulate the queries containing them. For image queries, nouns are the most informative parts of the user's request and we focus our work on them. From the list of queries provided for WikipediaMM, we build an initial list of all nouns, which is subsequently filtered in order to eliminate visual concepts. We decided not to try to reformulate visual concepts but to employ them in the visual concepts detection framework described in <ref type="bibr" coords="3,241.46,465.89,15.43,9.05" target="#b19">[20]</ref>. The list of visual concepts contains terms like: night, day, face, portrait, graph, drawing, cartoon, photo, picture or painting.</p><p>In our approach, we favour the processing of concepts in queries rather than processing words separated by blank spaces. For instance, hunting dog is regarded as a single concept and not as a composition of hunting and dog as separate terms. The same observation stands for Da Vinci paintings, threes terms that form a unique concept. When searching for subtypes of hunting dog and Da Vinci paintings, the two expressions will be considered as single concepts. The first type of composed concept is a multiword and it is detected with WordNet. "Da Vinci paintings" is retained as a single concept by comparing it to the list of categories in Wikipedia. The same rule is applied for Ice hockey players or Roads in California, which are processed as single concepts.</p><p>The list of concepts was first enriched using WordNet hyponyms (for those terms that, when a term existed in the hierarchy. If we get back to the example of hunting dog, the list of hyponyms contains intermediary concepts like sporting dog, hound or retriever, as well as race names such as labrador retriever, Ibizan hound or Irish Terrier. Other terms, such as Ferrari, are not described in WordNet and they constitute an argument for using a broader resource in order to build lists of subtypes. WordNet was also used to determine the right sense for an ambiguous text queries such as the one formed of plant as text query (which is disambiguated using building, a visual concept included in the query). We were able to map this query to the second sense of plant in WordNet and extract the right set of hyponyms. A third role of WordNet was to provide a list of synonyms for terms having no subtypes in the hierachy. For example, polar bear was enriched with ice bear, Ursus Maritimus, Thalarctos Maritimus.</p><p>When using Wikipedia, we first probed each member of the list of nominal concepts (including the terms extracted from WordNet) against the categories associated to articles in the encyclopedia. Wikipedia is generally more detailed than WordNet and, when existing, the lists of subtypes extracted from WordNet were enriched with terms from the encyclopedia. For instance, Mudhol Hound or Azawakh (races of hounds) were added to the list of hyponyms of hunting dog. For categories which are not represented in WordNet, i.e. Ferrari or Da Vinci paintings, we mined Wikipedia content and extracted list of instances. Ferrari hyponyms include: Ferrari F40, Ferrari GT4 or Ferrari Testarossa.</p><p>Among the extracted Da Vinci paintings, we cite: Mona Lisa, The Last Supper or The Battle of Anghiari.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Subtypes ranking</head><p>The lists of subtypes we constituted often contain a lot of terms (hundreds for terms like bridge or castle) and, given that they are to be used in an information retrieval application, it is necessary to rank these terms. We propose a two steps ranking process: First, the query is examined to see if it includes a useful qualifier of the concept (usually an adjective) and if so, terms associated to that qualifier are ranked first. Qualifiers appear in queries such as female players beach volleyball, red Ferrari or blue flower. These qualifiers are matched against WordNet glosses for terms in WordNet and against the categories as well as the text of the article for terms extracted from Wikipedia. Second, we use the length of the dedicated Wikipedia article to associate a pertinence value to each member of the subtypes list. The intuition behind this choice is that interesting concepts are usually described in more detail than the others. This simple way to rank entities generally gives satisfying results. For example, after ranking the list of subtypes of bridge, the first terms were: I-35w Mississippi River Bridge; San francisco-Oakland Bay Bridge; Golden Gate Bridge; Millau Viaduct; Luding Bridge; Brooklyn Bridge and Sydney Harbour Bridge. All these terms correspond to well-known bridges. Note that, for those queries where qualifiers appear, they are prioritary. All ranks are normalized to values smaller than one. The term ranking will be used to order the pictures that are retrieved for a query. If a picture of the Golden Gate Bridge and one of the Luding Bridge are found for a query with bridges, they will be presented in this order on the results page.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Query reformulation and matching procedure</head><p>We performed two types of query reformulation, one implying only text and a second implying both text and visual concepts (called multimedia reformulation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Textual query reformulation and matching</head><p>We preprocess the textual queries in the WikipediaMM set. First, we do not consider as concepts the stop words that appear in the queries; they are stripped off before the reformulation. For instance bridges at night is processed as bridges night. Second, nouns in the queries are stemmed and both forms of the word are searched in the text associated to the images in the dataset. Third, when possible, verbs are transformed into corresponding nouns (dance becomes dancing). Also, all capitalized letters are transformed to low-case.</p><p>The concepts are three types:</p><p>Visual concepts -belonging to a pre-established closed list of terms (including graph, map or night). They are not subject to textual reformulation and are only used in the multimedia reformulation. Expandable concepts -terms for which we built a list of subtypes from WordNet and Wikipedia. Non-expandable concepts -terms for which there is no available reformulation. They include qualifiers (i.e. blue, military) or instances (i.e. Golden Gate Bridge). All concepts in a query, as well as the subtypes of expandable concepts, are tested against the text associated to images and, whenever a match is found, we increase the matching score between the query and the image. Visual concepts and expandable terms are given a higher score compared to that given to subtypes, which are, better scored than qualifiers in turn. The ranking of the image results is done by summing all the individual scores associated to query components. This ensures that the images with the most concepts in the (expanded) query appear in the descriptive text are best ranked. For instance if an image description contains both hunting dog and labrador retriever, it will be better ranked than an image described only by hunting dog, which, in its turn, will be better ranked than a third image described associated with labrador retriever. When two texts match only subtypes of the concept in the query, we use the subtypes ranking in order to differentiate between both (an images described by labrador retriever is ranked better than one described by Tenterfield terrier). In the case of the queries containing more than one concept, no image results are returned when a qualifier or a visual concept in the query matches the analyzed text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Multimedia query reformulation and matching</head><p>This section describes the third layer of the system that aims at (eventually) rearranging the order of the answers returned to a query by the first two layers, depending on its content in terms of visual concepts.</p><p>We used two systems to detect visual concepts within the images. The first one is the Viola-Jones face detector that is based on the boosting of Haar wavelets <ref type="bibr" coords="4,216.25,693.53,15.43,9.05" target="#b36">[37]</ref>. The second system (extensively described in <ref type="bibr" coords="4,237.74,705.05,16.09,9.05" target="#b19">[20]</ref>) is a set of SVM-based classifiers learnt (RBF kernel) to determine:</p><p>• The type of an image: clipart, map, painting or photo.</p><p>• In this last case (if the image is a photo), other sets of SVM determine whether the image is:</p><p>o Indoor or outdoor o Day or night o Urban or natural scene The features extracted include texture LEP <ref type="bibr" coords="4,234.03,775.49,10.69,9.05" target="#b2">[3]</ref>, colour histogram <ref type="bibr" coords="4,323.04,775.49,16.75,9.05" target="#b31">[32]</ref> and connected pixels mutual extension [Ste 02].</p><p>For each classifier, the images of the learning databases were chosen separately of the wikipedia corpus considered at imageCLEF. When more than two concepts are considered, the multi-class paradigm was solved using a one-versus-one approach. The implementation was based on LibSVM <ref type="bibr" coords="5,275.18,81.77,10.67,9.05" target="#b3">[4]</ref>.</p><p>The queries were analysed to detect those which have to be filtered by one of the systems described above. Each visual concept was linked to a pre-defined list of textual concept that triggers its use. For instance, the presence of a named entity of a person (such as "Georges W Bush") will trigger the use of the face detector. The presence of the word "map" within the query will claim for the use of the "image type detector" and favour the images tagged as map while the word "cartoon" will do the same for the images classified as clipart. When a list of answers coming from the two first layers is reordered, the images detected as relevant according to the visual concept associated to the query are put at the head of the list without changing their relative order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results and discussion</head><p>Table <ref type="table" coords="5,83.53,222.05,4.98,9.05">1</ref> gives the main results of the two runs we submitted. The run ceaTxt is the output of the textual query reformulation and matching only, while the run ceaConTxt is the output of the full system including the multimedia query reformulation and matching. The results are given in terms of Mean Average Precision as well as the precision at ranks five and ten.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>MAP P@5 P@10 ceaConTxt 0.2735 0.5467 0.4653 ceaTxt 0.2632 0.52 0.4427 Table <ref type="table" coords="5,183.85,328.61,3.90,9.05">1</ref>: main results of the CEA LIST at ImageCLEF wikipedia task Our system returns good results, which were ranked at the fourth and second place of the WikipediaMM task at imageCLEF 2008. The difference between our two runs shows the slight interest of the multimedia reformulation and rearrangement that led to an improvement of one point in terms of MAP (from 0.263 to 0.273). It is worth noting that about half of the images were judged as relevant among the ten first answers returned by our system, demonstrating a practical interest for a real user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions and perspectives</head><p>We proposed a new scheme to exploit both textual and visual information in the context of image retrieval. The approach is based on a query reformulation using concepts that are semantically related to those in the initial query. For each interesting entity in the query, we used Wikipedia and WordNet to extract and list of related concepts, which were further ranked in order to propose the most salient in priority. These answers were ultimately rearranged in function of the query reformulation in terms of visual concepts. The results submitted at ImageCLEF 2008 were ranked 4 th and 2 nd with a mean average precision of 0.2632 and 0.2735. The small difference between the two submitted runs shows that the greater contribution to the final results was probably due to the use of conceptual structures, although a rigorous comparison would have required submitting a run with the third layer (visual concept detection) only. Nevertheless, the improvement of the results' precision accounts for the interest of introducing visual concept detection in the retrieval schema. We described an ongoing work and a number of features of our system are currently under investigation. The detection of associated concepts is currently limited to the use of Wikipedia and WordNet. We plan on extending our approach so as to exploit search engine snippets, in order to improve the coverage of the resources. Also, there exist domain-related semantic structures, like Geonames<ref type="foot" coords="5,198.24,595.50,3.24,5.89" target="#foot_2">3</ref> for geography, which could be used to improve the coverage. A second line of work concerns the concept ranking process described in this paper. While simple and generally effective, the current approach can certainly be ameliorated if, for instance, we favour unambiguous hyponyms over ambiguous ones. Concerning the third layer, we are currently exploring a finer grained filtering of visual concepts. Indeed, the current implementation uses a classifier that does not require any setting put aside the choice of the kernel. Hence, stepping up our system (in terms of number of visual concepts) is a problematic subject on its own that consists of being able to build the learning databases (images and triggering words) automatically for a large number of concepts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Acknowledgement</head><p>We thank the Direction Générale des Entreprises for funding us through the regional business cluster Systematic (project POPS <ref type="foot" coords="5,114.12,735.78,3.24,5.89" target="#foot_3">4</ref> ) and Cap Digital (project Mediatic 5 ).</p></div>			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,62.40,764.21,239.34,9.05"><p>http://en.wikipedia.org/wiki/Wikipedia:Database_download</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,62.40,775.73,71.35,9.05"><p>http://dbpedia.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="5,62.40,764.09,88.93,9.21"><p>http://geonames.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="5,62.40,775.61,141.01,9.21"><p>http://www.pops-systematic.org/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,71.16,100.13,467.46,9.05;6,56.64,111.65,481.88,9.05;6,56.64,123.17,169.66,9.05" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,346.08,100.13,173.66,9.05">Dbpedia : A nucleus for a web of open data</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Kobilarov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Cyganiak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Ives</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,56.64,111.65,291.73,9.05">Proceedings of the 6th International Semantic Web Conference (ISWC)</title>
		<title level="s" coord="6,426.49,111.65,112.03,9.05;6,56.64,123.17,29.27,9.05">Lecture Notes in Computer Science</title>
		<meeting>the 6th International Semantic Web Conference (ISWC)</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">4825</biblScope>
			<biblScope unit="page" from="722" to="735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,71.88,134.69,466.65,9.05;6,56.64,146.21,240.07,9.05" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,414.84,134.69,119.82,9.05">Matching Words and Pictures</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Barnard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Duygulu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Forsyth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nando</forename><surname>De Freitas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,56.64,146.21,155.35,9.05">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1107" to="1135" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,70.80,157.73,467.70,9.05;6,56.64,169.13,65.37,9.05" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,189.48,157.73,208.87,9.05">Image classification using color, texture and regions</title>
		<author>
			<persName coords=""><forename type="first">Y.-C</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S.-Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,405.13,157.73,115.82,9.05">image and Vision Computing</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="759" to="776" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,70.92,180.65,462.86,9.05;6,56.64,192.17,163.65,9.05" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="6,225.73,180.65,191.71,9.05">LIBSVM : a library for support vector machines</title>
		<author>
			<persName coords=""><forename type="first">Chih-Chung</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chih-Jen</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://www.csie.ntu.edu.tw/~cjlin/libsvm" />
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,71.76,203.69,466.64,9.05;6,56.64,215.21,218.70,9.05" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,218.43,203.69,279.78,9.05">Discriminative Training for Object Recognition using Image Patches</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,509.88,203.69,22.82,9.05">CVPR</title>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="157" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,71.40,226.73,467.01,9.05;6,56.64,238.13,71.22,9.05" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,175.20,226.73,285.80,9.05">A Bayesian Hierarchical Model for Learning Natural Scene Categories</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,468.14,226.73,70.26,9.05;6,56.64,238.13,48.57,9.05">IEEE Comp. Vis. Patt. Recog</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,70.92,249.65,324.58,9.05" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="6,152.89,249.65,160.01,9.05">WordNet : an electronic lexical database</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,72.12,261.17,466.21,9.05;6,56.64,272.69,278.85,9.05" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,250.86,261.17,287.47,9.05;6,56.64,272.69,75.24,9.05">Semantic interactive image retrieval combining visual and conceptual content description</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ferecatu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Crucianu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,142.33,272.69,67.70,9.05">Multimedia Syst</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">5-6</biblScope>
			<biblScope unit="page" from="309" to="322" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,71.88,284.21,466.72,9.05;6,56.64,295.61,22.65,9.05" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,214.32,284.21,207.00,9.05">Texture Orientation for Sorting Photos at a Glance</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Gorkani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">W</forename><surname>Picard</surname></persName>
		</author>
		<idno>TR #292</idno>
	</analytic>
	<monogr>
		<title level="m" coord="6,429.25,284.21,44.23,9.05">Proc. ICPR</title>
		<meeting>ICPR</meeting>
		<imprint>
			<date type="published" when="1994-10">Oct 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,76.91,307.13,461.58,9.05;6,56.64,318.65,70.97,9.05" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,193.92,307.13,328.94,9.05">Pyramid match kernels: Discriminative classification with sets of image features</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Grauman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Darrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,56.64,318.65,43.34,9.05">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,75.83,330.17,462.46,9.05;6,56.64,341.69,481.86,9.05;6,56.64,353.21,164.95,9.05" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="6,180.85,330.17,208.42,9.05">Information retrieval with commonsense knowledge</title>
		<author>
			<persName coords=""><forename type="first">M.-H</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H.-H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,412.57,330.17,125.73,9.05;6,56.64,341.69,428.54,9.05">SIGIR &apos;06 : Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="651" to="652" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,76.55,364.61,461.97,9.05;6,56.64,376.13,481.89,9.05;6,56.63,387.65,29.25,9.05" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="6,230.50,364.61,299.08,9.05">Query expansion with ConceptNet and Wordnet : An intrinsic comparison</title>
		<author>
			<persName coords=""><forename type="first">M.-H</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-F</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H.-H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,68.99,376.13,411.36,9.05">Proceedings of the Third Asia Information Retrieval Symposium Information Retrieval Technology</title>
		<meeting>the Third Asia Information Retrieval Symposium Information Retrieval Technology</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,79.19,399.17,459.30,9.05;6,56.63,410.69,481.81,9.05;6,56.63,422.21,177.58,9.05" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="6,197.20,399.17,318.86,9.05">Exploiting wikipedia as external knowledge for named entity recognition</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kazama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Torisawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,56.63,410.69,481.81,9.05;6,56.63,422.21,76.10,9.05">Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="698" to="707" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,78.23,433.61,460.21,9.05;6,56.63,445.13,481.86,9.05;6,56.63,456.65,118.39,9.05" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="6,239.88,433.61,298.56,9.05;6,56.63,445.13,82.58,9.05">Sparse-Dispersed Coding and Images Discrimination with Independent Component Analysis</title>
		<author>
			<persName coords=""><forename type="first">H</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Le</forename><surname>Borgne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Guérin-Dugué</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,146.40,445.13,369.78,9.05">Third International Conference on Independent Component Analysis and Signal Separation</title>
		<meeting><address><addrLine>San Diego, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="9" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,77.75,468.17,460.69,9.05;6,56.63,479.69,234.54,9.05" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="6,284.51,468.17,253.93,9.05;6,56.63,479.69,30.27,9.05">Representation of images for classification with independent features</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Le Borgne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Guérin-Dugué</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Antoniadis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,93.24,479.69,108.67,9.05">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="141" to="154" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,78.11,491.21,460.26,9.05;6,56.63,502.61,467.37,9.05" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="6,291.59,491.21,246.78,9.05;6,56.63,502.61,86.40,9.05">Learning Mid-level Image Features for Natural Scene and Texture Classification</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Le Borgne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Guérin-Dugué</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">E</forename><surname>O'connor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,149.41,502.61,254.72,9.05">IEEE transaction on Circuits and Systems for Video Technology</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="286" to="297" />
			<date type="published" when="2007-03">march 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,75.83,514.13,462.55,9.05;6,56.63,525.65,149.01,9.05" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="6,226.85,514.13,271.93,9.05">A survey of content-based image retrieval with high-level semantics</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W.-Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,510.00,514.13,28.38,9.05;6,56.63,525.65,31.06,9.05">Pattern Recogn</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="262" to="282" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,76.31,537.17,462.11,9.05;6,56.63,548.69,288.21,9.05" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="6,116.75,537.17,225.50,9.05">Object Recognition from Local Scale-Invariant Features</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,360.36,537.17,178.06,9.05;6,56.63,548.69,79.19,9.05">Proceedings of the International Conference on Computer Vision</title>
		<meeting>the International Conference on Computer Vision<address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-09">September 1999</date>
			<biblScope unit="page" from="1150" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,78.71,560.09,459.70,9.05;6,56.63,571.61,274.29,9.05" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="6,222.12,560.09,213.37,9.05">Indexing Based on Scale Invariant Interest Points</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,458.41,560.09,80.01,9.05;6,56.63,571.61,181.33,9.05">Proceedings of the International Conference on Computer Vision</title>
		<meeting>the International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="525" to="531" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,76.31,583.13,462.11,9.05;6,56.63,594.65,50.37,9.05" xml:id="b19">
	<monogr>
		<title level="m" type="main" coord="6,117.48,583.13,396.18,9.05">Automatic image annotation: consistent annotation, and creating automatically a learning database</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Millet</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="6,76.67,606.17,461.74,9.05;6,56.63,617.69,452.61,9.05" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="6,257.28,606.17,281.13,9.05;6,56.63,617.69,72.22,9.05">Using the forest to see the trees: a graphical model relating features, objects and scenes</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Murphy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">T</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,135.00,617.69,190.83,9.05">Adv. in Neural Information Processing Systems</title>
		<meeting><address><addrLine>Vancouver, BC</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,76.55,629.09,462.07,9.05;6,56.63,640.61,130.86,9.05" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="6,216.84,629.09,240.38,9.05">Sampling strategies for bag-of-features image classification</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Novak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Jurie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,475.43,629.09,63.19,9.05;6,56.63,640.61,104.15,9.05">IEEE European Conf. on Computer Vision</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,77.27,652.13,461.14,9.05;6,56.63,663.65,252.57,9.05" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="6,195.00,652.13,339.12,9.05">Modelling the shape of a scene: a holistic representation of the spatial envelope</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,56.63,663.65,164.13,9.05">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="145" to="175" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,77.27,675.17,461.37,9.05;6,56.63,686.69,22.65,9.05" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="6,212.64,675.17,159.75,9.05">A trainable system for object detection</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Papageorgiou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Poggio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,380.17,675.17,98.38,9.05">Intl. J. Computer Vision</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="33" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,76.07,698.09,462.18,9.05;6,56.63,709.61,208.67,9.05" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="6,185.99,698.09,193.14,9.05">Deriving a large scale taxonomy from wikipedia</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">P</forename><surname>Ponzetto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Strube</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,398.53,698.09,139.72,9.05;6,56.63,709.61,172.94,9.05">Proceedings of the Twenty-Second AAAI Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Second AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,77.39,721.13,461.07,9.05;6,56.63,732.65,225.69,9.05" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="6,200.28,721.13,240.40,9.05">Moëllic Ontology Driven Content Based Image Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Millet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P-A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,449.18,721.13,89.29,9.05;6,56.63,732.65,27.38,9.05">CIVR 2007 -posters session</title>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">July 9 -11, 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,75.59,744.17,462.93,9.05;6,56.64,773.70,3.24,5.89" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="6,192.60,744.17,232.23,9.05">Kanellos A Conceptual Approach to Web Image Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P-A</forename><surname>Moëllic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,432.86,744.17,46.20,9.05">LREC 2008</title>
		<imprint>
			<date>May 28 -30, 5</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,77.28,70.25,458.97,9.05;7,56.64,81.77,422.59,9.05" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="7,234.81,70.25,235.98,9.05">Rotation Invariant Neural Network-Based Face Detection</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">A</forename><surname>Rowley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Baluja</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,79.20,81.77,372.67,9.05">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR&apos;98)</title>
		<imprint>
			<date type="published" when="1998">1998. 1998</date>
			<biblScope unit="page">963</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,76.92,93.29,461.43,9.05;7,56.64,104.81,212.87,9.05" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="7,181.80,93.29,197.54,9.05">Local Grayvalue Invariants for Image Retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mohr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,383.68,93.29,154.68,9.05;7,56.64,104.81,100.21,9.05">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="530" to="535" />
			<date type="published" when="1997-05">May 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,76.32,116.33,461.98,9.05;7,56.64,127.73,207.71,9.05" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="7,212.41,116.33,273.21,9.05">A statistical model for 3D object detection applied to faces and cars</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schneiderman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Kanade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,492.36,116.33,45.94,9.05;7,56.64,127.73,178.23,9.05">Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,77.28,139.25,461.34,9.05;7,56.64,150.77,481.91,9.05;7,56.64,162.29,227.14,9.05" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="7,292.44,139.25,246.18,9.05;7,56.64,150.77,135.64,9.05">A compact and efficient image retrieval approach based on border/interior pixel classification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">O</forename><surname>Stehling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Nascimento</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">X</forename><surname>Falcão</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,198.87,150.77,339.68,9.05;7,56.64,162.29,48.64,9.05">Proceedings of the eleventh international conference on Information and knowledge management</title>
		<meeting>the eleventh international conference on Information and knowledge management<address><addrLine>McLean, Virginia, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="102" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,75.96,173.81,410.49,9.05" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="7,180.85,173.81,59.00,9.05">Color Indexing</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Swain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ballard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,246.61,173.81,163.07,9.05">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="11" to="32" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,76.44,185.33,462.07,9.05;7,56.64,196.73,200.38,9.05" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="7,211.35,185.33,143.05,9.05">Indoor-outdoor image classification</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Szummer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">W</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,365.05,185.33,173.46,9.05;7,56.64,196.73,109.33,9.05">Int. Workshop on Content-based Access of Image and Video Databases</title>
		<imprint>
			<date type="published" when="1998-01">Jan. 1998</date>
			<biblScope unit="page" from="42" to="51" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,78.36,208.25,460.21,9.05;7,56.64,219.77,375.80,9.05" xml:id="b33">
	<analytic>
		<title level="a" type="main" coord="7,233.90,208.25,304.67,9.05;7,56.64,219.77,135.64,9.05">Enhancement of Textual Images Classification Using Segmented Visual Contents for Image Search Engine</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Tollari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">Le</forename><surname>Maitre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,199.22,219.77,141.15,9.05">Multimedia Tools and Applications</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="405" to="417" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,76.32,231.29,462.19,9.05;7,56.64,242.81,399.23,9.05" xml:id="b34">
	<analytic>
		<title level="a" type="main" coord="7,168.78,231.29,369.73,9.05;7,56.64,242.81,62.12,9.05">A proposal to automatically build and maintain gazetteers for named entity recognition by using wikipedia</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Toral</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Muñoz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,140.52,242.81,248.17,9.05">NEW TEXT -Wikis and blogs and other dynamic text sources</title>
		<meeting><address><addrLine>Trento</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,76.08,254.33,462.35,9.05;7,56.64,265.73,374.58,9.05" xml:id="b35">
	<analytic>
		<title level="a" type="main" coord="7,232.63,254.33,305.80,9.05;7,56.64,265.73,44.06,9.05">80 million tiny images: a large dataset for non-parametric object and scene recognition</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Freeman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,111.36,265.73,260.28,9.05">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<date type="published" when="2008-05">May 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,75.84,277.25,462.54,9.05;7,56.64,288.77,107.26,9.05" xml:id="b36">
	<analytic>
		<title level="a" type="main" coord="7,174.00,277.25,261.65,9.05">Rapid object detection using a boosted cascade of simple features</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,453.02,277.25,85.36,9.05;7,56.64,288.77,77.79,9.05">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,73.90,300.29,464.51,9.05;7,56.64,311.81,87.81,9.05" xml:id="b37">
	<analytic>
		<title level="a" type="main" coord="7,230.53,300.29,198.07,9.05">Recognition with local features: the kernel recipe</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Wallraven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Graf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,446.55,300.29,43.67,9.05">Proc. ICCV</title>
		<meeting>ICCV</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="257" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,77.40,323.21,461.17,9.05;7,56.64,334.73,481.89,9.05;7,56.64,346.25,373.51,9.05" xml:id="b38">
	<analytic>
		<title level="a" type="main" coord="7,207.30,323.21,331.27,9.05;7,56.64,334.73,206.14,9.05">Does ontology help in image retrieval ? -a comparison between keyword, text ontology and multi-modality ontology approaches</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L.-T</forename><surname>Chia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,288.48,334.73,250.05,9.05;7,56.64,346.25,156.57,9.05">MULTIMEDIA &apos;06 : Proceedings of the 14th annual ACM international conference on Multimedia</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="109" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,78.72,357.77,459.69,9.05;7,56.64,369.29,143.97,9.05" xml:id="b39">
	<analytic>
		<title level="a" type="main" coord="7,275.61,357.77,255.51,9.05">Thesaurus-aided approach for image browsing and retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Wenyin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhuang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,56.64,369.29,107.76,9.05">Proceedings of ICME 2001</title>
		<meeting>ICME 2001</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,76.56,380.81,461.82,9.05;7,56.64,392.21,371.25,9.05" xml:id="b40">
	<monogr>
		<title level="m" type="main" coord="7,300.00,380.81,238.38,9.05;7,56.64,392.21,142.25,9.05">Local features and kernels for classification of texture and object categories: An in-depth study</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Marszalek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<idno>RR-5737</idno>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>INRIA Rhône-Alpes</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="7,78.36,403.73,460.14,9.05;7,56.64,415.25,482.02,9.05;7,56.64,426.77,108.58,9.05" xml:id="b41">
	<analytic>
		<title level="a" type="main" coord="7,214.59,403.73,303.31,9.05">Data-driven approach for bridging the cognitive gap in image retrieval</title>
		<author>
			<persName coords=""><forename type="first">X</forename><forename type="middle">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Y</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,56.64,415.25,327.06,9.05">Proceedings of the 2004 IEEE International Conference on Multimedia and Expo</title>
		<meeting>the 2004 IEEE International Conference on Multimedia and Expo<address><addrLine>Taipei, Taiwan</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2004-06">June 2004</date>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="2231" to="2234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,76.92,438.29,461.41,9.05;7,56.64,449.81,255.21,9.05" xml:id="b42">
	<analytic>
		<title level="a" type="main" coord="7,255.97,438.29,282.36,9.05;7,56.64,449.81,27.60,9.05">\Automatic assignment of wikipedia encyclopedic entries to wordnet synsets</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ruiz-Casado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Alfonseca</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Castells</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,94.08,449.81,118.45,9.05">Advances in Web Intelligence</title>
		<imprint>
			<biblScope unit="page" from="380" to="386" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,77.16,461.21,461.39,9.05;7,56.64,472.73,482.01,9.05;7,56.64,484.25,29.25,9.05" xml:id="b43">
	<analytic>
		<title level="a" type="main" coord="7,256.45,461.21,282.10,9.05;7,56.64,472.73,309.36,9.05">Automatising the learning of lexical patterns : An application to the enrichment of wordnet by extracting semantic relationships from wikipedia</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ruiz-Casado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Alfonseca</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Castells</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,378.13,472.73,72.55,9.05">Data Knowl. Eng</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="484" to="499" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,77.04,495.77,461.58,9.05;7,56.64,507.29,333.80,9.05;7,56.64,518.81,2.49,9.05" xml:id="b44">
	<analytic>
		<title level="a" type="main" coord="7,282.24,495.77,236.07,9.05">Liveimage : Organizing web images by relevant concepts</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">P</forename><surname>Liao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">C</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">F</forename><surname>Chien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,56.64,507.29,235.08,9.05">Proc. of the Workshop on the Science of the Artificial 2004</title>
		<meeting>of the Workshop on the Science of the Artificial 2004</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="210" to="220" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
