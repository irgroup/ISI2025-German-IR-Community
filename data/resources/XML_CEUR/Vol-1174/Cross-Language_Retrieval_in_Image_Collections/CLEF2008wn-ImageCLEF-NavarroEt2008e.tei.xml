<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,105.74,148.62,391.62,15.51;1,160.44,170.53,282.18,15.51">A Textual Approach Based on Passages Using IR-n in WikipediaMM Task 2008</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,197.85,204.00,62.66,9.96"><forename type="first">Sergio</forename><surname>Navarro</surname></persName>
							<email>snavarro@dlsi.ua.es</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing and Information Systems Group</orgName>
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,268.51,204.00,57.85,9.96"><forename type="first">Rafael</forename><surname>Mu√±oz</surname></persName>
							<email>rafael@dlsi.ua.es</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing and Information Systems Group</orgName>
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,335.08,204.00,70.11,9.96"><forename type="first">Fernando</forename><surname>Llopis</surname></persName>
							<email>llopis@dlsi.ua.es</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Natural Language Processing and Information Systems Group</orgName>
								<orgName type="institution">University of Alicante</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,105.74,148.62,391.62,15.51;1,160.44,170.53,282.18,15.51">A Textual Approach Based on Passages Using IR-n in WikipediaMM Task 2008</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A11A740DA01ABE0DBEF94428D081CC70</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.2 Information Storage H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2 [Database Managment]: H.2.5 Heterogenous Databases Measurement, Performance, Experimentation Information Retrieval, Image Retrieval, Geographic Expansion, Relevance Feedback, PRF, LCA, Camel Case decompounding</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we have focused our efforts on comparing the behaviour of two relevance feedback methods in this task -LCA and PRF -and in checking if our passage based information rerieval (IR) system is useful in a competition with small sized documents. Furthermore we have added an adaptation to this domain based on decompound in single terms those file names which use a Camel Case notation. We base our decision on the belief that the most meaningful information of an image file appointed by a human is on the file name itself. Thus, it is important to make visible this terms when they are hidden in a compounded file name. Finally we have added a geographical query expansion and a visual concept expansion. We have obtained a 29th place within a total of 77 runs with our baseline run -which only used the passage IR system -, and a 3rd place obtained with our best run -which used the passage IR system with Camel Case decompounding -. It shows us on one hand the usefulness of our passage based IR system in this domain, and on the other hand it confirms our belief in the existence of specially meaningful information within the file names. In the the relevance feedback respect, we have obtained contradictory results about the suitability of LCA or PRF to the task, but we have found that LCA has a more robust behavior than PRF.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This is the first time we are participating in the WikipediaMM task. We had experience of participation in the photo retrieval task of 2007 <ref type="bibr" coords="1,310.36,719.52,9.96,9.96" target="#b7">[8]</ref>. Our participation in ImageCLEFphoto <ref type="foot" coords="1,508.53,718.75,3.97,4.77" target="#foot_0">1</ref>involved the use of an information retrieval system based on passages. We analyzed the suitability of our system for the short text annotations related to the images in the collection. We concluded that our system improved the results more in comparison to other systems, which were similar to our system except the fact that they did not use passages. The experiments also showed that relevance feedback is a good tool for improving results.</p><p>Since our last participation in ImageCLEF our efforts has been focused on finding an alternative strategy for the relevance feedback. So far, the most common strategy between the participants of ImageCLEFphoto task on last year edition was to use PRF <ref type="bibr" coords="2,360.94,195.04,9.96,9.96" target="#b8">[9]</ref>. Thus, we are comparing in this CLEF edition PRF with Local Context Analisy (LCA) <ref type="bibr" coords="2,333.06,207.00,14.61,9.96" target="#b9">[10]</ref>, as alternate strategy.</p><p>Thus, in our participation in the WikipediaMM task we wanted to figure out if good results can be also achieved with our passages based system for this domain.</p><p>Furthermore, in order to adapt our system to this task we have added a module to preprocess the wikipedia documents. It skips the useless tags and decompose the file names with camel case notation in single terms.</p><p>Finally, due to it is so common to see queries that are looking for an image that involve a geographical term. We have added a geographical query expansion module in order to experiment its behavior in this task.</p><p>This paper is structured as follows: Firstly, it presents the main characteristics of the IR-n system focusing on the relevance feedback strategies, the geographical query expansion and the Wikipedia processing module, then it moves on to explain the experiments we have made to evaluate the system, and finally it describes the results and conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The IR-n System</head><p>In our approach, we used IR-n -an information retrieval system based on passages -. Passagebased IR systems treat each document as a set of passages, with each passage defining a portion of text or contiguous block of text. Unlike document-based systems, these systems can consider the proximity of words with each other, that appear in a document in order to evaluate their relevance <ref type="bibr" coords="2,90.00,453.04,9.96,9.96" target="#b5">[6]</ref>.</p><p>The IR-n passage-based system differs from other systems of the same category with regard to the method proposed for defining the passage -that is -using sentences as unit. Thus, passages are defined by a number of consecutive sentences in a document <ref type="bibr" coords="2,372.77,488.91,9.96,9.96" target="#b5">[6]</ref>.</p><p>IR-n uses stemmer and stopword lists to determine which information in a document will be used for retrieval. For a list of stemmers and stopwords used by IR-n, see www.unine.ch/infor/clef. IR-n uses several weighting models. Weighting models allow the quantification of the similarity between a text (a complete document or a passage in a document) and a query. Values are based on the terms that are shared by the text and query and on the discriminatory importance of each term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Relevance Feedback</head><p>Most IR systems use relevance feedback techniques <ref type="bibr" coords="2,316.36,606.92,9.96,9.96" target="#b0">[1]</ref>. These systems usually employ local feedback. The local feedback assumes that top-ranked documents are relevant. The added terms are, therefore, common terms from the top-ranked documents. Local feedback has become a widely used relevance feedback technique. Although, it can deter retrieval, in case most of the top-ranked documents are not relevant, results in TREC an CLEF conferences show that is an effective technique <ref type="bibr" coords="2,116.31,666.69,14.61,9.96" target="#b9">[10]</ref>. In fact, almost all the systems that participated at ImageCLEF 2007 used Probabilistic Relevance Feedback (PRF) -the most common relevance feedback method - <ref type="bibr" coords="2,425.87,678.65,10.52,9.96" target="#b3">[4]</ref> </p><formula xml:id="formula_0" coords="2,439.72,678.65,40.97,9.96">[5] [3] [2].</formula><p>In the selection of terms, PRF gives more importance to those terms which have a higher frequency in the top relevant documents than in the whole collection. An alternative query expansion method relies on the Local Context Analysis (LCA), based on the hypothesis that a common term from the top-ranked relevant documents will tend to co-occur with all query terms within the top-ranked documents. That is an attempt to avoid including terms from top-ranked, non-relevant documents in the expansion. Furthermore, in the case of polysemus words, this method will help to retrieve documents more related to the sense of the query, since it is logical to think that the user will use words from the domain associated with this sense to complete the query.</p><p>The IR-n architecture allows us to use query expansion based on either the most relevant passages or the most relevant documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Geographical Query Expansion</head><p>To carry out the geographical terms expansion, our system first determines which are the geographical terms of the query. And afterwards generates the terms expansion based on the features of the term found.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Selecting Geographical Terms</head><p>During the search phase using Freeling<ref type="foot" coords="3,270.04,284.83,3.97,4.77" target="#foot_1">2</ref> a language analysis tool suite the system extracts from the query the names and adjectives with their Wordnet<ref type="foot" coords="3,365.61,296.78,3.97,4.77" target="#foot_2">3</ref> most frequent sense. With this information, the Semantic Domains <ref type="bibr" coords="3,248.26,309.51,10.52,9.96" target="#b6">[7]</ref> associated to the sense of each term are obtained.</p><p>The system consider as geographical terms of the query the terms that pertain to the 'administration' or 'geography' dominions and that are hyponym of one of these concepts: 'location' or 'landmass' for toponyms, 'nationality', 'asian', 'european', 'australian', 'american', 'african', 'person of color' for demonyms 'language' for names for languages.</p><p>For instance, consider the following query from the ImageCLEF07: "Asian women and/or girls". 'Asian' term pertains to the Semantic Domain 'geography', and it is an hyponym of 'person of color', our system classify it as a demonym.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Terms Expansion</head><p>The toponyms are expanded using WordNet with their synonyms, their direct holonyms and their hierarchical meronyms. And the names of inhabitants or languages are expanded with WordNet synonyms and hierarchical meronyms of their direct pertainyms concept.</p><p>The system uses a little stopword list for the geographical expansion to determine which of the generated terms by the expansion will be skipped. These terms are so common between locations and are not relevant to distinguish different locations.</p><p>Following the sample of the query "Asian women and/or girls". How 'Asian' term has been classified as a demonym, the system obtain its pertainyms concept, which is 'Asia'. The expansion terms are the hierarchical meronyms of the 'Asia'term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Wikipedia Preprocessing Module</head><p>In order to use significant information in the IR-n indexing phase of the collection, our preprocessing module skips the useless information and optionally it can decompose the compounded file names in single terms with meaning.</p><p>Specifically, for the IMAGE tag the preprocessing module skips the data which it contain, and for the other tags it only uses their text nodes. Optionally, the decompounding function can be activated. It decompose the file names which use camel case notation in single terms. An example of a document before and after the preprocessing phase can be seen at Figure <ref type="figure" coords="3,445.98,651.13,4.98,9.96" target="#fig_0">2</ref> and Figure <ref type="figure" coords="3,508.02,651.13,4.98,9.96">1</ref> respectively. We can observe in this example how the terms "EgiptyanDesert" that are joined in a file name are decomposed, making this document more visible to a textual query based on natural language.</p><p>IR-n is a parameterizable system, which means that it can be adapted in line with the concrete characteristics of the task at hand. The parameters for this configuration are the number of sentences that form a passage, the weighting model to use, the type of expansion, the number of documents/passages on which the expansion is based, the average number of words per document, and the use of geographical query expansion. This section describes the training process that was carried out in order to obtain the best possible features for improving the performance of the system. The collections and resources are described first, and the next section describes specific experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data Collection</head><p>In 2008, ImageCLEF wikipediaMM have used the image collection created and employed by the INEX Multimedia (MM) <ref type="bibr" coords="4,202.27,275.09,50.61,9.96">Track (2006</ref><ref type="bibr" coords="4,257.35,275.09,22.35,9.96">Track ( -2007))</ref>. This collection contains approximately 150,000 images that cover diverse topics of interest. These images are associated with unstructured and noisy textual annotations in English. Table <ref type="table" coords="4,254.68,299.01,4.98,9.96" target="#tab_0">1</ref> shows the characteristics extracted from the textual annotations in the collection using IR-n splitter after preprocessing it with the wikipedia preprocessing module -without Camel Case decompounding -. NoDocs: is the number of documents.</p><p>WDAvg: is the average of words by document.</p><p>WD Max: is the maximum number of words in a document.</p><p>SentAvg: is the average of sentences by document.</p><p>Sent Max: is the maximum number of sentences in a document.</p><p>Language: is the language of the collection.</p><p>Each image is associated with user-generated alphanumeric, unstructured metadata in English. These metadata usually contain a brief caption or description of the image,the Wikipedia user who uploaded the image, and the copyright information. These descriptions are highly heterogeneous and of varying length. The Figure <ref type="figure" coords="4,242.43,589.06,4.98,9.96">1</ref> provides a metadata example associated to an image.</p><p>The topics for the 2008 ImageCLEF wikipediaMM task on one hand have included the topics previously used in INEX MM and ImageCLEF photo tasks, and on the other hand topics created by this year's task participants.</p><p>The topics are multimedia queries that can consist of a textual, a visual and a conceptual part, with the latter two parts being optional. The tags that compound a topic are the TITLE, which contains the query by keywords, the CONCEPT, which contains query by one or more visual concepts -optional -, and the IMAGE, which contains query by one or more images -optional -.</p><p>For the training of systems, the organization distributed between the participants the topics used in INEX MM 2006 and 2007 editions and their relevance assessments.</p><p>Figure <ref type="figure" coords="5,259.67,118.27,3.87,9.96">1</ref>: Metadata File Example &lt;?xml version="1.0"?&gt; &lt;article&gt;&lt;name id="103136"&gt;EgyptianDesert.JPG&lt;/name&gt; &lt;image xmlns:xlink="http://www.w3.org/1999/xlink" xlink:type="simple" xlink:actuate="onLoad" xlink:show="embed" xlink:href="../pictures/EgyptianDesert.JPG" id="103136" part="images-20000"&gt; EgyptianDesert.JPG&lt;/image&gt; &lt;text&gt;&lt;wikitemplate parameters="2"&gt; &lt;wikiparameter number="0"&gt;&lt;value&gt;PD-user&lt;/value&gt;&lt;/wikiparameter&gt; &lt;wikiparameter number="1" last="1"&gt;&lt;value&gt;Manos&lt;/value&gt; &lt;/wikiparameter&gt;&lt;/wikitemplate&gt; brrrrrrrrrrrrrrkjfhdikfhas &lt;/text&gt;&lt;/article&gt; </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experiments</head><p>The experiment phase aims to establish the optimum values for the configuration of the system. Below is a description of the input parameters of the system used in this task:</p><p>Passage size (PS): Number of sentences in a passage.</p><p>Weight model: We used DFR weighting model. We have based this decision on the good results obtained with this model for English language on our last participation in ImageCLEF.</p><p>Query expansion parameters: we can use relevance feedback based on passages or based on documents. Moreover we have to select the number of passages or documents that the expansion will use, and indicate the k terms extracted from the best ranked passages or documents from the original query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Geographical query expansion (Geog): Indicate if the system use the geographical query expansion module.</head><p>Camel Case: Indicate if the system use the collection with camel case terms decompounded.</p><p>Concept: Indicate if the system has to join the terms that represent the visual concepts of the topic to the topic title in order to compound the query. Or if it only has to use the TITLE keywords for the query.</p><p>For this phase we have carried out all the experiments separately for the two training query sets -INEX MM 2006 and 2007 -. Our objective was to find which parameter values are better independent of the query set used. Thus, we have looked for common parameter values between best runs which have used 2006 query set and best runs which have used 2007 query set.</p><p>Due to the great number of configurations used for this training. We have had to made an effort for synthesizing the results obtained, in order to find common issues of the best runs. We have focused on the comparison of the best results obtained for each combination of Camel Case, Concept and Geog parameters. Moreover, in order to analyze the suitability of LCA an PRF to the task, we have showed the best results for each Camel Case, Concept and Geog combination using LCA or PRF as relevance feedback strategy.</p><p>Next, there is a description of the fields compounding the result tables: [lca|prf ] impro: Shows the percentage of improvement using LCA or PRF regarding not use relevance feedback.</p><formula xml:id="formula_1" coords="6,114.90,179.10,13.53,9.96">rk:</formula><p>maIm: Mean average of percentage of improvement -for lcaimpro and prf impro -.</p><p>The following tables -Table <ref type="table" coords="6,233.22,358.42,4.98,9.96" target="#tab_2">2</ref> and Table <ref type="table" coords="6,290.02,358.42,4.98,9.96" target="#tab_3">3</ref> -shows the best results obtained in the training phase, their data is presented in the increasing order of rk value. Table <ref type="table" coords="6,133.19,595.88,4.98,9.96" target="#tab_2">2</ref> shows us that for 2006 query set the best run has been obtained with the configuration that use only the visual concept and PRF as relevance feedback strategy. However this configuration without relevance feedback (NOFB) obtains the worst MAP value. Moreover, we can see that almost all the runs with and without relevance feedback which use the camel case decompounding, improve the baseline result -MAP 0.4065 -. And therefore they are top ranked in the table. We also can observe that geographical expansion always get worse results than the results obtained with the same configuration but without the geographical expansion.</p><p>In relevance feedback respect we observe that PRF has obtained the best result but the worst too. Showing LCA a better behaviour if we attend to the mean average improvement (MaImpr).</p><p>And finally in passage size respect we see that there is not an ideal size to use with this query set. Since each configuration has its own suitable passage size.</p><p>The experiments with the 2007 query set show us that camel case decompounding obtains the best results. We also can observe that visual concept expansion always get worse results than the results obtained with the same configuration but without the visual concept. In geographical expansion respect, we observe that it does not meaningfully change the results. Furthermore we saw that relevance feedback always improves the results. On one hand PRF as well as for 2006 query set experiments obtains the best and the worst results of the relevance feedback runs and on the other hand LCA shows another time a good performance in a mean average improvement way.</p><p>In passage size respect we see that for almost all the runs the best passage size has a value of 5.</p><p>Finally, for our participation in WikipediaMM08, we have sent 24 runs corresponding with the configurations that better results have given with the 2007 query set. This is because we have found very few common values between the parameters of the best runs of the 2006 and 2007 query sets experiments. Thus, we decided to use the parameter values which best results obtained for 2007 query set since those parameter values were more homogeneous than the parameter values which gave best results for the 2006 query set -it can be observed seeing the passage sizes but it is extensible to other parameters as the number of documents and terms used for the relevance feedback that in order to summarise we have not shown in the data tables -.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results in WikipediaMM08</head><p>Table <ref type="table" coords="7,117.52,555.00,4.98,9.96" target="#tab_4">4</ref> shows the results for each Camel Case, Concept and Geog combination in the Wikipedi-aMM task of this year. It also shows us the ranking position for each run in the WikipediaMM08 task ranking (RK CLEF).</p><p>As we expected the best results has been obtained using camel case decompounding. However we have obtained unexpected negative results with the runs using relevance feedback. Even so it is observable that LCA always has better MAP results than PRF, and therefore a great difference for the MAImpr.</p><p>Table <ref type="table" coords="7,132.85,638.69,4.98,9.96" target="#tab_4">4</ref> shows together a comparison of the MAP results of our baseline run and the 5 best MAP results in the competition, along with an average for the 77 runs -which have been sent by a total number of 12 participants -(Avg MAP CLEF). Moreover it is showed the improvement of each run respect the Avg MAP CLEF.</p><p>It is important to highlight that our baseline run using only a passage based system -with a passage size of 3 sentences -has obtained the 29th position in the ranking of 77 runs submitted. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Future Work</head><p>A major finding of these results is that, camel case decompounding has been decisive for the success in this task. It makes us to believe that there are two main reasons for it. The first and most obvious one is that with this procedure we have accessed the terms, not visible for other systems and therefore we have increased our chances to perform a good retrieval. The other onemore intuitive -is that the terms used for a file name usually are the most meaningful terms that exist within the metadata of an image. The reason is that the user tries to synthesize the image content from a few words. It would explain the boost with this procedure experimented by our system. The problem of mismatch between a concept in a query and in a document when it is expressed -with different terms than found in the collection -is aggravated in collections with small sized documents. Hitherto relevance feedback always has been a good tool for improving the results in our experiments with image annotations. However unexpected results has been obtained with relevance feedback strategies. Even though we have seen that LCA has showed a more robust behaviour, while PRF shows more unpredictable results.</p><p>As future work study we will research the causes of the relevance feedback negative results. and if it is possible, we will try to develop a method to forecast when a relevance feedback is going to be negative for the retrieval, in order to refrain from using it.</p><p>Furthermore, in order to achieve the continuing improvement of the system, we shall attempt to include an efficient method for the decompounding file names which does not use a standard notation. Moreover, in accordance with our intuition with respect to the significance of file name, we will research the effect of giving more weight in the retrieval phase to the terms that compound the file names.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgement</head><p>This research has been partially funded by the Spanish Government within the framework of the TEXT-MESS (TIN-2006-15265-C06-01) project and by European Union (EU) within the framework of the QALL-ME project (FP6-IST-033860).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,205.25,323.28,192.48,9.96;5,90.00,345.76,146.44,9.20;5,90.00,357.71,88.91,9.20;5,90.00,369.66,240.55,9.20"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Processed Metadata File Example &lt;DOC&gt;&lt;DOCNO&gt; 103136 &lt;/DOCNO&gt; Egyptian Desert . PD user Manos brrrrrrrrrrrrrrkjfhdikfhas&lt;/DOC&gt;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,104.94,353.69,360.90,69.99"><head>Table 1 :</head><label>1</label><figDesc>Data CollectionNoDocs WDAvg WD Max SentAvg Sent Max Language</figDesc><table coords="4,104.94,377.80,353.32,45.88"><row><cell>151.519</cell><cell>20,03</cell><cell>3.101</cell><cell>1,7</cell><cell>784</cell><cell>English</cell></row><row><cell cols="3">Bellow is a descriptions of Table 1 columns:</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,114.90,179.10,398.15,117.56"><head></head><label></label><figDesc>Shows the ranking position of a combination of Camel Case, Concept and Geog parameter values. It is based on the maximum MAP measure obtained. rk [no fb|prf|lca]: Shows the ranking position based on MAP for the best run that have used LCA/PRF or that not have used relevance feedback (NOFB). ps [no fb|prf|lca]: Shows the passage size of the best run that that have used LCA/PRF or that not have used relevance feedback (NOFB). map [no fb|prf|lca]: MAP or Mean Average Precision of the best run that have used LCA/PRF or that not have used relevance feedback (NOFB).</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,95.98,401.16,466.45,168.77"><head>Table 2 :</head><label>2</label><figDesc>Query Set 2006 -Best Results</figDesc><table coords="6,209.56,422.87,72.01,9.96"><row><cell>rk ps</cell><cell>map</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,95.98,118.27,466.45,168.77"><head>Table 3 :</head><label>3</label><figDesc>Query Set 2007 -Best Results</figDesc><table coords="7,209.56,139.99,72.01,9.96"><row><cell>rk ps</cell><cell>map</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="8,95.98,118.27,423.20,323.28"><head>Table 4 :</head><label>4</label><figDesc>Results in WikipediaMM08</figDesc><table coords="8,95.98,139.99,423.20,301.55"><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>rk</cell><cell>map</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>%</cell><cell>%</cell></row><row><cell>rk</cell><cell>rk</cell><cell cols="2">cam vis</cell><cell></cell><cell>no</cell><cell>no</cell><cell>rk</cell><cell>map</cell><cell></cell><cell>rk</cell><cell>map</cell><cell>lca</cell><cell>prf</cell></row><row><cell></cell><cell cols="5">clef case con geo fb</cell><cell>fb</cell><cell>lca</cell><cell>lca</cell><cell></cell><cell>prf</cell><cell>prf</cell><cell cols="2">impro impro</cell></row><row><cell>1</cell><cell>3</cell><cell>yes</cell><cell>no</cell><cell>no</cell><cell>1</cell><cell>0.2700</cell><cell>1</cell><cell cols="2">0.2614</cell><cell>2</cell><cell>0.2321</cell><cell>-3.19</cell><cell>-14,04</cell></row><row><cell>2</cell><cell>6</cell><cell>yes</cell><cell>no</cell><cell>yes</cell><cell>2</cell><cell>0.2605</cell><cell>3</cell><cell cols="2">0.2583</cell><cell>3</cell><cell>0.2287</cell><cell>-0.84</cell><cell>-12,21</cell></row><row><cell>3</cell><cell>8</cell><cell>yes</cell><cell>yes</cell><cell>no</cell><cell>3</cell><cell>0.2587</cell><cell>2</cell><cell cols="2">0.2593</cell><cell>1</cell><cell>0.2326</cell><cell>0.23</cell><cell>-10.09</cell></row><row><cell>4</cell><cell>17</cell><cell>yes</cell><cell>yes</cell><cell>yes</cell><cell>4</cell><cell>0.2509</cell><cell>4</cell><cell cols="2">0.2537</cell><cell>4</cell><cell>0.2238</cell><cell>1,11</cell><cell>-10.80</cell></row><row><cell>5</cell><cell>30</cell><cell>no</cell><cell>yes</cell><cell>no</cell><cell>5</cell><cell>0.2183</cell><cell>5</cell><cell cols="2">0.2158</cell><cell>5</cell><cell>0.2083</cell><cell>-1.15</cell><cell>-4.58</cell></row><row><cell>6</cell><cell>31</cell><cell>no</cell><cell>no</cell><cell>no</cell><cell>6</cell><cell>0.2178</cell><cell>7</cell><cell cols="2">0.2053</cell><cell>6</cell><cell>0.2033</cell><cell>-5,74</cell><cell>-6.66</cell></row><row><cell>7</cell><cell>35</cell><cell>no</cell><cell>yes</cell><cell>yes</cell><cell>7</cell><cell>0.2091</cell><cell>6</cell><cell cols="2">0.2067</cell><cell>8</cell><cell>0.1997</cell><cell>-1.15</cell><cell>-4.50</cell></row><row><cell>8</cell><cell>36</cell><cell>no</cell><cell>no</cell><cell>yes</cell><cell>8</cell><cell>0.2091</cell><cell>8</cell><cell cols="2">0.2010</cell><cell>7</cell><cell>0.2003</cell><cell>-3,87</cell><cell>-4.21</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">maIm: -1.83</cell><cell>-8.39</cell></row><row><cell></cell><cell></cell><cell cols="11">Table 5: Comparation with Other Participants WikipediaMM08</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>%</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">cam vis</cell><cell></cell><cell>rel</cell><cell></cell><cell></cell><cell>avg</cell><cell>run</cell></row><row><cell></cell><cell>rk</cell><cell></cell><cell>run</cell><cell></cell><cell cols="4">case con geo fb</cell><cell cols="2">map</cell><cell>map</cell><cell>impro</cell></row><row><cell></cell><cell>1</cell><cell cols="3">(upeking)zzhou3</cell><cell></cell><cell></cell><cell></cell><cell cols="5">0.3444 0.1756 0,9613</cell></row><row><cell></cell><cell>2</cell><cell></cell><cell cols="2">ceaTxtCon</cell><cell></cell><cell></cell><cell></cell><cell cols="3">0.2735</cell><cell></cell><cell>0,5575</cell></row><row><cell></cell><cell>3</cell><cell cols="3">IRnNoCamel</cell><cell>yes</cell><cell>no</cell><cell cols="4">no no 0.2700</cell><cell></cell><cell>0,5376</cell></row><row><cell></cell><cell>4</cell><cell></cell><cell>ceaTxt</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">0.2632</cell><cell></cell><cell>0,4989</cell></row><row><cell></cell><cell>5</cell><cell cols="3">IRnNoCamelLca</cell><cell>yes</cell><cell>no</cell><cell>no</cell><cell cols="3">lca 0.2614</cell><cell></cell><cell>0,4886</cell></row><row><cell></cell><cell>29</cell><cell></cell><cell>IRn</cell><cell></cell><cell>no</cell><cell>no</cell><cell cols="4">no no 0.2178</cell><cell></cell><cell>0,2403</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,105.25,739.14,93.74,7.97"><p>http://www.imageclef.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,105.25,706.07,175.64,7.97"><p>available at http://garraf.epsevg.upc.es/freeling</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,105.25,715.57,152.78,7.97"><p>available at http://wordnet.princeton.edu</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,110.48,244.80,402.51,9.96;9,110.47,256.75,402.52,9.96;9,110.47,268.71,402.52,9.96;9,110.47,280.66,402.55,9.96;9,110.47,292.61,30.46,9.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,259.21,244.80,253.77,9.96;9,110.47,256.75,122.82,9.96">Combining Query Translation and Document Translation in Cross-Language Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Aitao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fredric</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,145.30,269.05,235.53,9.18">4th Workshop of the Cross-Language Evaluation Forum</title>
		<title level="s" coord="9,444.79,269.05,68.19,9.18;9,110.47,280.66,236.41,9.96">Lecture notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</editor>
		<meeting><address><addrLine>CLEF; Trondheim, Norway</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
	<note>Lecture notes in Computer Science</note>
</biblStruct>

<biblStruct coords="9,110.48,312.54,402.52,9.96;9,110.47,324.49,402.52,9.96;9,110.47,336.45,114.91,9.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,160.97,324.49,75.13,9.96">Sinai at imageclef</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">C</forename><surname>Daz-Galiano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Garca-Cumbreras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">T</forename><surname>Martn-Valdivia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Montejo-Raez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Urea-Lpez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,275.27,324.83,186.22,9.18">Working Notes of the 2007 CLEF Workshop</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">2007. September 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,356.38,402.52,9.96;9,110.47,368.33,402.50,9.96;9,110.47,380.28,374.92,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,328.12,368.33,159.11,9.96">Tia-inaoes participation at imageclef</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">Jair</forename><surname>Escalante</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><forename type="middle">A</forename><surname>Hernndez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aurelio</forename><surname>Lpez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Heidy</forename><forename type="middle">M</forename><surname>Marn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Manuel</forename><surname>Montes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eduardo</forename><surname>Morales</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luis</forename><forename type="middle">E</forename><surname>Sucar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luis</forename><surname>Villaseor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,122.93,380.62,191.91,9.18">Working Notes of the 2007 CLEF Workshop</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">2007. September 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,400.21,402.50,9.96;9,110.47,412.17,402.52,9.96;9,110.47,424.12,265.55,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,134.42,412.17,265.37,9.96">Ipal at imageclef 2007 mixing features, models and knowledge</title>
		<author>
			<persName coords=""><forename type="first">Sheng</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean-Pierre</forename><surname>Chevallet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thi</forename><surname>Hoang Diem Le</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Trong Ton</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joo Hwee</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,420.56,412.51,92.44,9.18;9,110.47,424.46,94.99,9.18">Working Notes of the 2007 CLEF Workshop</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">September 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,444.05,402.53,9.96;9,110.47,456.00,402.52,9.96;9,110.47,467.96,293.81,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,256.25,456.00,140.67,9.96">Dcu and uta at imageclefphoto</title>
		<author>
			<persName coords=""><forename type="first">Anni</forename><surname>Jrvelin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Wilkins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tomasz</forename><surname>Adamek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eija</forename><surname>Airio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Gareth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alan</forename><forename type="middle">F</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eero</forename><surname>Smeaton</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Sormunen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,446.64,456.34,66.36,9.18;9,110.47,468.30,123.26,9.18">Working Notes of the 2007 CLEF Workshop</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09">2007. September 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,487.89,402.52,9.96;9,110.47,499.84,154.61,9.96" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Llopis</surname></persName>
		</author>
		<title level="m" coord="9,187.98,488.23,296.08,9.18">IR-n: Un Sistema de Recuperacin de Informacin Basado en Pasajes</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>University of Alicante</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="9,110.48,519.77,402.52,9.96;9,110.47,531.72,402.54,9.96;9,110.47,543.68,402.54,9.96;9,110.47,555.63,22.68,9.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,437.54,519.77,75.46,9.96;9,110.47,531.72,245.31,9.96">Revising wordnet domains hierarchy: Semantics, coverage, and balancing</title>
		<author>
			<persName coords=""><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luisa</forename><surname>Bentivogli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pamela</forename><surname>Forner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Emanuele</forename><surname>Pianta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,381.26,532.06,131.75,9.18;9,110.47,544.02,199.57,9.18">Proceedings of COLING 2004 Workshop on &apos;Multilingual LinguisticResources</title>
		<meeting>COLING 2004 Workshop on &apos;Multilingual LinguisticResources<address><addrLine>Geneva, Switzerland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-08">August 2004</date>
			<biblScope unit="page" from="101" to="108" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,575.56,402.52,9.96;9,110.48,587.51,402.53,9.96;9,110.48,599.47,79.34,9.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,418.45,575.56,94.55,9.96;9,110.48,587.51,262.13,9.96">Information Retrieval of Visual Descriptions with IR-n System based on Passages</title>
		<author>
			<persName coords=""><forename type="first">Sergio</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Llopis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rafael</forename><surname>Mu√±oz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Elisa</forename><surname>Noguera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,110.48,599.81,48.72,9.18">CLEF 2007</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>In on-line Working Notes</note>
</biblStruct>

<biblStruct coords="9,110.48,619.40,402.52,9.96;9,110.47,631.35,273.44,9.96" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,283.75,619.40,157.03,9.96">Relevance weighting of search terms</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">Sparck</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,450.89,619.74,62.11,9.18;9,110.47,631.69,181.63,9.18">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="129" to="146" />
			<date type="published" when="1976">1976</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,651.27,402.51,9.96;9,110.47,663.23,265.18,9.96" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,245.29,651.27,267.70,9.96;9,110.47,663.23,68.23,9.96">Improving the effectiveness of information retrieval with local context analysis</title>
		<author>
			<persName coords=""><forename type="first">Jinxi</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,187.23,663.57,97.04,9.18">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="112" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
