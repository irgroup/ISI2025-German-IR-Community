<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,392.42,148.79,41.59,15.48;1,173.50,170.71,256.01,15.48;1,169.97,194.92,263.07,12.35">at the CLEF 2008 Domain Specific Track Parsimonious Relevance and Concept Models</title>
				<funder ref="#_QwrZSdJ #_xqtMj3F">
					<orgName type="full">Netherlands Organisation for Scientific Research (NWO)</orgName>
				</funder>
				<funder ref="#_efpsZhK">
					<orgName type="full">Ministry of Economic Affairs (EZ)</orgName>
				</funder>
				<funder ref="#_Xvx953S">
					<orgName type="full">Dutch Ministry of Education, Culture and Science (OC&amp;W)</orgName>
				</funder>
				<funder ref="#_mDdvsby #_fvfC7Ue #_F8tKwBb #_CrZUTw9 #_gdMq3dm #_PMp4Ktj #_TcubbB9">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,202.44,230.37,54.06,10.37"><forename type="first">Edgar</forename><surname>Meij</surname></persName>
							<email>emeij@science.uva.nlmaartenderijkemdr@science.uva.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Amsterdam</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">ISLA</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,392.42,148.79,41.59,15.48;1,173.50,170.71,256.01,15.48;1,169.97,194.92,263.07,12.35">at the CLEF 2008 Domain Specific Track Parsimonious Relevance and Concept Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">AC3B55A8247B1E58210AE000B268C41C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.7 Digital Libraries Algorithms, Theory, Experimentation, Measurement Parsimonious Models, Language Models, Relevance Feedback</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe our participation in the CLEF 2008 Domain Specific track. The research questions we address are threefold: (i) what are the effects of estimating and applying relevance models to the domain specific collection used at CLEF 2008, (ii)  what are the results of parsimonizing these relevance models, and (iii) what are the results of applying concept models for blind relevance feedback? Parsimonization is a technique by which the term probabilities in a language model may be re-estimated based on a comparison with a reference model, making the resulting model more sparse and to the point. Concept models are term distributions over vocabulary terms, based on the language associated with concepts in a thesaurus or ontology and are estimated using the documents which are annotated with concepts. Concept models may be used for blind relevance feedback, by first translating a query to concepts and then back to query terms. We find that applying relevance models helps significantly for the current test collection, in terms of both mean average precision and early precision. Moreover, parsimonizing the relevance models helps mean average precision on title-only queries and early precision on title+narrative queries. Our concept models are able to significantly outperform a baseline query-likelihood run, both in terms of mean average precision and early precision on both title-only and title+narrative queries.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>We describe our participation in the 2008 CLEF Domain Specific track. Our main motivation for participating was to evaluate the retrieval models we have developed for another, very similar domain on the CLEF Domain Specific test collection. Our concept models have thus far been developed and evaluated on the TREC Genomics test collections, which also consists of documents which are manually annotated using concepts from a thesaurus <ref type="bibr" coords="2,220.32,124.29,10.79,8.64" target="#b4">[5,</ref><ref type="bibr" coords="2,233.60,124.29,7.19,8.64" target="#b5">6]</ref>.</p><p>The main idea behind our approach is to model the language use associated with concepts from a thesaurus or ontology. To this end we use the document annotations as a bridge between vocabulary terms and the concepts in the knowledge source at hand. We model the language use around concepts using a generative language modeling framework, which provides theoretically sound estimation methods and builds upon a solid statistical background.</p><p>Our concept models may be used to determine semantic relatedness or to generate navigational suggestions, either in the form of concepts or vocabulary terms. These can then be used as suggestions for the user or for blind relevance feedback <ref type="bibr" coords="2,251.12,219.94,15.77,8.64" target="#b12">[13,</ref><ref type="bibr" coords="2,269.54,219.94,12.45,8.64" target="#b13">14,</ref><ref type="bibr" coords="2,284.64,219.94,11.83,8.64" target="#b17">18]</ref>. In order to apply blind relevance feedback using our models, we perform a double translation. First we estimate the most likely concepts given a query and then we use the most distinguishing terms from these concepts to formulate a new query. In a sense we are using the concepts as a pivot language <ref type="bibr" coords="2,224.83,255.80,10.58,8.64" target="#b8">[9]</ref>. To find the most distinguishing terms given a concept, we apply a technique called parsimonization <ref type="bibr" coords="2,224.73,267.76,10.58,8.64" target="#b7">[8]</ref>. Parsimonization is an algorithm based on expectation-maximization (EM) <ref type="bibr" coords="2,113.85,279.71,11.62,8.64" target="#b2">[3]</ref> and may be used to re-estimate probabilities of one model with respect to another. Events that are well-predicted by the latter model will lose probability mass, which in turn will be given to the remaining events. Recently, we have successfully applied parsimonization to the estimation of relevance models on a variety of tasks and collections <ref type="bibr" coords="2,225.55,315.58,15.27,8.64" target="#b14">[15]</ref>. In all of these cases, as well as with our concept models, we find that interpolating the newly found query with the original one yields the best performance-an observation which is in line with the literature <ref type="bibr" coords="2,226.98,339.49,15.27,8.64" target="#b9">[10]</ref>.</p><p>The research questions we address are threefold: (i) what are the effects of estimating and applying relevance models to the collection used at the CLEF 2008 Domain Specific track <ref type="bibr" coords="2,424.62,363.40,15.27,8.64" target="#b11">[12]</ref>, (ii) what are the results of parsimonizing these relevance models, and (iii) what are the results of applying our concept models for blind relevance feedback?</p><p>We find that applying relevance models helps significantly for the current test collection, in terms of both mean average precision and early precision. Moreover, we find that parsimonizing the relevance models helps mean average precision on title-only queries and early precision on title+narrative queries. Our concept models are able to significantly outperform a baseline query-likelihood run, both in terms of mean average precision and in terms of early precision on both title-only and title+narrative queries.</p><p>The remainder of this paper is organized as follows. In Section 2 we introduce the retrieval framework we have used for our submission, i.e., statistical language modeling. In Section 3 and 4 we introduce the specifics of our models and techniques. In Section 5 we describe the experimental setup, our parameter settings, and the preprocessing steps we performed on the collection. In Section 6 we discuss our experimental results and we end with a concluding section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Language Modeling</head><p>Language modeling is a relatively new framework in the context of information retrieval <ref type="bibr" coords="2,448.61,562.47,10.79,8.64" target="#b6">[7,</ref><ref type="bibr" coords="2,462.29,562.47,12.45,8.64" target="#b15">16,</ref><ref type="bibr" coords="2,477.63,562.47,11.83,8.64" target="#b19">20]</ref>. It is centered around the assumption that a query as issued by a user is a sample generated from some underlying term distribution-the information need. The documents in the collection are modeled in a similar fashion and are usually considered to be a mixture of a document-specific model and a more general background model. At retrieval time, each document is ranked according to the likelihood of having generating the query (query-likelihood).</p><p>Lafferty and Zhai <ref type="bibr" coords="2,177.94,634.20,16.60,8.64" target="#b10">[11]</ref> propose to generalize the query likelihood model to the KL-divergence scoring method, in which the query is modeled separately. Scoring documents then comes down to measuring the divergence between a query model P (t|θ Q ) and each document model P (t|θ D ), in which the divergence is negated for ranking purposes. When the query model is generated using the empirical, maximumlikelihood estimate (MLE) on the original query as follows:</p><formula xml:id="formula_0" coords="2,250.83,700.74,262.17,22.31">P (t| θQ ) = n(t; Q) |Q| ,<label>(1)</label></formula><p>where n(t; Q) is the number of occurrences of term t in query Q and |Q| the length of the query, it can be shown that documents are ranked in the same order as using the query likelihood model <ref type="bibr" coords="2,466.79,745.96,15.27,8.64" target="#b19">[20]</ref>. More formally, the score for each document given a query using the KL-divergence retrieval model is:</p><formula xml:id="formula_1" coords="3,112.46,135.60,400.54,20.06">Score(Q, D) = -KL(θ Q ||θ D ) = - t∈V P (t|θ Q ) log P (t|θ D ) + t∈V P (t|θ Q ) log P (t|θ Q ),<label>(2)</label></formula><p>where V denotes the vocabulary. The entropy of the query-t∈V P (t|θ Q ) log P (t|θ Q )-remains constant per query and can be ignored for ranking purposes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Smoothing</head><p>Each document model is estimated as the MLE of each term in the document P (t|θ D ), linearly interpolated with a background language model P (t), which in turn is calculated as the likelihood of observing t in a sufficiently large collection, such as the document collection:</p><formula xml:id="formula_2" coords="3,215.45,272.44,297.55,9.65">P (t|θ D ) = βP (t|θ D ) + (1 -β)P (t).<label>(3)</label></formula><p>We smooth using Bayesian smoothing with a Dirichlet prior and set β = µ |D|+µ and (1 -β) = |D| |D|+µ , where µ is the Dirichlet prior that controls the influence of smoothing <ref type="bibr" coords="3,369.94,309.24,10.79,8.64" target="#b1">[2,</ref><ref type="bibr" coords="3,383.22,309.24,11.83,8.64" target="#b21">22]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Query Modeling</head><p>Relevance feedback can be applied to better capture a user's information need <ref type="bibr" coords="3,407.98,356.44,10.79,8.64" target="#b0">[1,</ref><ref type="bibr" coords="3,421.80,356.44,12.45,8.64" target="#b11">12,</ref><ref type="bibr" coords="3,437.30,356.44,11.83,8.64" target="#b18">19]</ref>. In the context of statistical language modeling, this is usually performed by estimating a new query model, viz. P (t|θ Q ), in Eq. 2 <ref type="bibr" coords="3,124.02,380.35,15.77,8.64" target="#b15">[16,</ref><ref type="bibr" coords="3,142.39,380.35,11.83,8.64" target="#b20">21]</ref>. Automatically reformulating queries (or blind relevance feedback) entails looking at the terms in some set of (pseudo-)relevant documents and selecting the most informative ones with respect to the set or the collection. These terms may then be reweighed based on information pertinent to the query or to the documents and-in a language modeling setting-be used to estimate a query model.</p><p>Relevance modeling is one specific technique by which to estimate a query model given a set of (pseudo-)relevant documents D Q . The query and documents are both taken to samples of an underlying generative model-the relevance model. There are several ways by which to estimate the parameters of this model given the observed data (query and documents), each following a different independence assumption <ref type="bibr" coords="3,137.88,475.99,15.27,8.64" target="#b11">[12]</ref>. For our current experiments we use method 2, which is formulated as:</p><formula xml:id="formula_3" coords="3,193.17,496.62,319.83,23.31">P (t| θQ ) ∝ P (t) qi∈Q Di∈D Q P (q i |θ Di )P (θ Di |t),<label>(4)</label></formula><p>where q 1 , . . . , q k are the query terms, D a document, and t a term. Bayes' rule is used to estimate the term P (θ D |t):</p><formula xml:id="formula_4" coords="3,234.80,564.76,278.20,22.31">P (θ D |t) = P (t|θ D )P (θ D ) P (t) ,<label>(5)</label></formula><p>where we assume the document prior P (θ D ) to be uniform. Similar to Eq. 3, the term P (t|θ D ) may be interpreted as a way of accounting for the fact that the (pseudo-)relevant documents contain terms related to the information need as well as terms from a more general model. We set it to the following mixture:</p><formula xml:id="formula_5" coords="3,218.53,643.75,294.47,22.31">P (t|θ D ) = α n(t; D) |D| + (1 -α)P (t),<label>(6)</label></formula><p>where P (t) is the probability of observing t in a sufficiently large collection such as the entire document collection. Query models obtained using relevance models perform better when they are subsequently interpolated with the initial query using a mixing weight λ <ref type="bibr" coords="3,325.50,702.48,15.49,8.64" target="#b9">[10]</ref>:</p><formula xml:id="formula_6" coords="3,213.30,721.45,299.70,12.28">P (t|θ Q ) = λP (t| θQ ) + (1 -λ)P (t| θQ )<label>(7)</label></formula><p>In order to leverage the explicit knowledge encapsulated in the GIRT/CSASA thesauri, we perform blind relevance feedback using the concepts defined therein. We leverage the dual document representationsconcepts and terms-to create a generative language model for each concept, which bridges the gap between terms and concepts. Related work has also used textual representations to represent concepts, see e.g., <ref type="bibr" coords="4,109.45,182.43,10.79,8.64" target="#b3">[4,</ref><ref type="bibr" coords="4,122.82,182.43,11.83,8.64" target="#b16">17]</ref>, however, we use statistical language modeling techniques to parametrize the concept models, by leveraging the dual representation of the documents.</p><p>To incorporate concepts in the retrieval process, we propose a conceptual query model which is an interpolation of the initial query with another query model. This model is obtained from a double concept translation. In this translation, concepts are used as a pivot language <ref type="bibr" coords="4,369.59,230.25,10.79,8.64" target="#b8">[9]</ref>; the initial query is translated to concepts and back to expanded query terms:</p><formula xml:id="formula_7" coords="4,188.62,261.10,324.38,22.69">P (t|θ Q ) = λP (t| θQ ) + (1 -λ) c∈C P (t|c)P (c|Q).<label>(8)</label></formula><p>Note that we assume that the probability of selecting a term is no longer dependent on the query once we have selected a concept given that query. Then, two components need to be estimated: the probability of a concept given a query P (c|Q) and of a term given a concept P (t|c). To acquire P (t|c), we will use the assignments of GIRT/CSASA thesaural concepts to the documents in the collection and aggregate over the documents D c which are labeled with a particular concept c:</p><formula xml:id="formula_8" coords="4,223.42,362.84,136.24,20.06">P (t|c) = D∈Dc P (t|D, c)P (D|c).</formula><p>We drop the conditional dependence of t on c given D, again assume the document prior to be uniform, and apply Bayes' rule to obtain:</p><formula xml:id="formula_9" coords="4,212.04,422.53,300.96,27.42">P (t|c) = 1 P (c) D∈D C P (t|θ D )P (c|θ D ),<label>(9)</label></formula><p>where P (c) is a maximum likelihood (ML) estimate on the collection:</p><formula xml:id="formula_10" coords="4,234.98,479.06,111.93,24.85">P (c) = D n(c; D) c D n(c ; D )</formula><p>and P (c|θ D ) is determined using the ML of the concepts associated with that document</p><formula xml:id="formula_11" coords="4,238.70,531.64,274.30,24.72">P (c|θ D ) = n(c; D) c n(c ; D) .<label>(10)</label></formula><p>Next, we also need need a way of estimating concepts for each query, which means that we are looking for a set of concepts C Q such that c ∈ C Q have the highest posterior probability P (c|Q). We approach this by looking at the assignment of concepts to documents ane again consider documents which are related to the original query, by using the top ranked documents D Q from the initial retrieval run:</p><formula xml:id="formula_12" coords="4,220.74,622.63,292.26,20.68">P (c|Q) = D∈D Q P (c|θ D )P (D|Q),<label>(11)</label></formula><p>where P (D|Q) is determined using the retrieval scores. Note that we again assume that the probability of observing a concept is independent of the query, once we have selected a document given the query, i.e., P (c|D, Q) = P (c|θ D ). This enables us to directly use Eq. 10.  used to reduce the amount and probability mass of non-specific terms in a language model by iteratively adjusting the individual term probabilities based on a comparison with a large reference corpus, such as the collection <ref type="bibr" coords="5,131.67,516.50,10.58,8.64" target="#b7">[8]</ref>. While one of the introduced models may already contain a way of incorporating a reference corpus, viz. Eq. 6, we propose to make the estimates more sparse. Doing so enables more specific terms to receive more probability mass, thus making the resulting model more to the point. In order to achieve this, we consider both models to be a mixture of a document model P (x|θ D ) and a background model P (x), where x ∈ {t, c}, and we "parsimonize" the estimates through applying the following EM algorithm until the estimates do not change significantly anymore: E-step:</p><formula xml:id="formula_13" coords="5,90.00,596.54,291.97,68.55">e x = n(x; D) γP (x|θ D ) (1 -γ)P (x) + γP (x|θ D ) M-step: P (x|θ D ) = e x x e x</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Setup</head><p>We did not perform any preprocessing on the document collection, besides replacing German characters as well as HTML entities. To estimate our concept models, we have used the CONTROLLED-TERM-EN field in the documents. We submitted the following runs: UAmsBaseline -a baseline run based with P (t|θ Q ) in Eq. 2 set to the empirical estimate on the query (Eq. 1), UAmsRelModels -a run based on relevance models, viz. Eq. 4, UAmsParsRelModels -a run based on parsimonious relevance models, viz. Eq. 4 in conjunction with the E-and M-steps described in the previous section, UAmsConceptModels -a run based on concept models, viz. Section 3 and Section 4.</p><p>Something went wrong with the submitted UAmsParsRelModels run based on parsimonious relevance models, making it identical to the UAmsRelModels run. In this paper we report on the corrected version. In all runs which use blind relevance feedback, we use the 5 terms with the highest probability from the 10 highest ranked documents to estimate our query models. We have then used the 2007 CLEF Domain Specific topics to find the optimal parameter settings for α (Eq. 6) and λ (Eq. 7 and Eq. 8). For our current experiments we set µ = 50 and fix γ = 0.15 <ref type="bibr" coords="6,269.53,439.29,10.58,8.64" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results and Discussion</head><p>Table <ref type="table" coords="6,114.30,495.18,4.98,8.64" target="#tab_0">1</ref> lists the results of our runs. On the 2007 data, we found that adding the narrative field of the topics helps retrieval effectiveness. For comparative purposes we have included results for both title-only and title+narrative runs. On the 2008 topics, we do not find the same improvement when adding the narrative field, besides slightly improving precision@10. When looking at the longer topics (title+narrative), applying parsimonization to the relevance models hurts mean average precision, but helps early precision. This precision-enhancing effect is in line with earlier results <ref type="bibr" coords="6,311.65,554.95,15.27,8.64" target="#b14">[15]</ref>.</p><p>The proposed concept models improve significantly over the query-likelihood baseline, both in terms of mean average precision and precision@10 and for both title-only and title+narrative topics. From the precision-recall plot in Figure <ref type="figure" coords="6,214.63,590.82,4.98,8.64" target="#fig_0">1</ref> (title-only) it is clear that our concept model improves slightly in early precision and that the biggest gain is obtained between recall levels 0.2 and 0.7. It also shows that the relevance modeling approaches mainly help to improve recall and not so much precision.</p><p>Figure <ref type="figure" coords="6,133.60,626.69,4.98,8.64" target="#fig_1">2</ref> displays a per-topic comparison between the query-likelihood run and each of the other runs. From these contrastive plots it emerges that topics 205 and 225 are hurt most when using relevance models. Further analysis should indicate which characteristics of these topics are responsible for this result. Interestingly, these two topics are hurt less when we apply our concepts models, whereas topic 219 is hurt most in this run. On the other side of the graph, there are quite a few topics which are helped using either relevance models or concept models. Especially topic 216 is improved when applying parsimonious relevance models (&gt; 0.25 increase in mean average precision). The positive difference when applying concept models is even more distinctive; topic 217 is nearly improved by a 0.5 increase in mean average precision.</p><p>We have described our participation in this year's CLEF Domain Specific track. Our aim was to evaluate blind relevance feedback models as well as concept models on the CLEF Domain Specific test collection. The results of our experiments show that applying relevance modeling techniques has a significant positive effect on the current topics, in terms of both mean average precision and precision@10. Moreover, we find that parsimonizing the relevance models helps mean average precision on title-only queries and early precision on title+narrative queries. When we apply concept models for blind relevance feedback, we observe an even bigger as well as significant improvement over the query-likelihood baseline, also in terms of mean average precision and early precision. Moreover, unlike (parsimonious) relevance models, our concept model improves title-only as well as title+narrative queries on both measures.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,198.40,460.54,206.21,8.64"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Precision-recall graph of the various runs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,90.00,219.95,423.00,8.64;6,90.00,231.90,423.00,8.64;6,90.00,243.86,297.33,8.64"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Per-topic breakdown of the difference in terms of average precision between the baseline run and UAmsRelModels (a), UAmsParsRelModels (b), and UAmsConceptModels (c). Topics are sorted by increasing difference, the labels indicate the respective topic identifiers.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,90.00,119.13,423.00,326.46"><head>Table 1 :</head><label>1</label><figDesc>Empirical results of our submitted runs, in terms of mean average precision (MAP) and precision@10 (P10). Best scores are marked in boldface. A †/ ‡ indicates a statistically significant difference as compared to the baseline at the 0.05/0.01 level respectively (tested using a Wilcoxon signed rank test).</figDesc><table coords="5,157.71,154.96,287.09,290.63"><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>title</cell><cell></cell><cell></cell><cell cols="3">title+narrative</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>MAP</cell><cell cols="2">P10</cell><cell></cell><cell>MAP</cell><cell></cell><cell>P10</cell></row><row><cell cols="3">UAmsBaseline</cell><cell></cell><cell></cell><cell>0.2433</cell><cell cols="2">0.4560</cell><cell></cell><cell>0.2077</cell><cell cols="2">0.4600</cell></row><row><cell cols="4">UAmsRelModels</cell><cell></cell><cell cols="3">0.2737  ‡ 0.5040</cell><cell></cell><cell>0.2396</cell><cell cols="2">0.4400</cell></row><row><cell cols="8">UAmsParsRelModels 0.2779  † 0.5000</cell><cell></cell><cell>0.2271</cell><cell cols="2">0.4800  †</cell></row><row><cell cols="8">UAmsConceptModels 0.2922  † 0.5160  †</cell><cell></cell><cell cols="3">0.2581  † 0.5240  †</cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">UAmsBaseline.res.eval</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">UAmsConceptModels.res.eval</cell><cell></cell></row><row><cell></cell><cell>0.7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">UAmsParsRelModels.eval UAmsRelModels.eval</cell><cell></cell></row><row><cell></cell><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Precision</cell><cell>0.4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.0</cell><cell>0.1</cell><cell>0.2</cell><cell>0.3</cell><cell>0.4</cell><cell>0.5</cell><cell>0.6</cell><cell>0.7</cell><cell>0.8</cell><cell>0.9</cell><cell>1.0</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Recall</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0" coords="4,90.00,733.69,423.00,9.65;4,90.00,745.96,423.00,8.64"><p>If P (t|θ D ) and P (c|θ D ) in Eq. 6 and Eq. 10 are estimated based on MLE, general terms and concepts may acquire too much probability mass, simply because they occur more frequently. Parsimonization may be</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>8 Acknowledgements This work was carried out in the context of the Virtual Laboratory for e-Science project, which is supported by a <rs type="grantName">BSIK grant</rs> from the <rs type="funder">Dutch Ministry of Education, Culture and Science (OC&amp;W)</rs> and is part of the <rs type="programName">ICT innovation program</rs> of the <rs type="funder">Ministry of Economic Affairs (EZ)</rs>. <rs type="person">Maarten</rs> de Rijke was supported by the <rs type="programName">E.U. IST programme</rs> of the <rs type="programName">6th FP for RTD</rs> under project <rs type="projectName">MultiMATCH</rs> contract <rs type="grantNumber">IST-033104</rs>, and by the <rs type="funder">Netherlands Organisation for Scientific Research (NWO)</rs> under project numbers <rs type="grantNumber">220-80-001</rs>, <rs type="grantNumber">017.001.190</rs>, <rs type="grantNumber">640.001.501</rs>, <rs type="grantNumber">640.002.501</rs>, <rs type="grantNumber">612.066.512</rs>, <rs type="grantNumber">STE-07-012</rs>, <rs type="grantNumber">612.061.814</rs>, <rs type="grantNumber">612.061.815. 9</rs> References</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Xvx953S">
					<orgName type="grant-name">BSIK grant</orgName>
					<orgName type="program" subtype="full">ICT innovation program</orgName>
				</org>
				<org type="funding" xml:id="_efpsZhK">
					<orgName type="program" subtype="full">E.U. IST programme</orgName>
				</org>
				<org type="funded-project" xml:id="_QwrZSdJ">
					<idno type="grant-number">IST-033104</idno>
					<orgName type="project" subtype="full">MultiMATCH</orgName>
					<orgName type="program" subtype="full">6th FP for RTD</orgName>
				</org>
				<org type="funding" xml:id="_xqtMj3F">
					<idno type="grant-number">220-80-001</idno>
				</org>
				<org type="funding" xml:id="_mDdvsby">
					<idno type="grant-number">017.001.190</idno>
				</org>
				<org type="funding" xml:id="_fvfC7Ue">
					<idno type="grant-number">640.001.501</idno>
				</org>
				<org type="funding" xml:id="_F8tKwBb">
					<idno type="grant-number">640.002.501</idno>
				</org>
				<org type="funding" xml:id="_CrZUTw9">
					<idno type="grant-number">612.066.512</idno>
				</org>
				<org type="funding" xml:id="_gdMq3dm">
					<idno type="grant-number">STE-07-012</idno>
				</org>
				<org type="funding" xml:id="_PMp4Ktj">
					<idno type="grant-number">612.061.814</idno>
				</org>
				<org type="funding" xml:id="_TcubbB9">
					<idno type="grant-number">612.061.815. 9</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,111.58,401.63,401.42,8.81;7,111.58,413.76,22.42,8.64" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,150.93,401.80,301.28,8.64">Using terminological feedback for web search refinement: a log-based study</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Anick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,470.00,401.63,39.06,8.58">SIGIR &apos;03</title>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,111.58,426.71,401.42,8.64;7,111.58,438.50,110.39,8.81" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,227.57,426.71,268.65,8.64">An empirical study of smoothing techniques for language modeling</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">F</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,111.58,438.50,15.35,8.58">ACL</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="310" to="318" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,111.58,451.62,401.42,8.64;7,111.58,463.40,401.42,8.81" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,307.96,451.62,205.04,8.64;7,111.58,463.57,54.40,8.64">Maximum likelihood from incomplete data via the EM algorithm</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">M</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,173.35,463.40,261.49,8.58">Journal of the Royal Statistical Society. Series B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,111.58,476.52,401.42,8.64;7,111.58,488.31,151.34,8.81" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,256.48,476.52,256.52,8.64;7,111.58,488.48,68.65,8.64">Computing semantic relatedness using wikipedia-based explicit semantic analysis</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Markovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,198.45,488.31,35.17,8.58">IJCAI&apos;07</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,111.58,501.43,401.42,8.64;7,111.58,513.22,329.57,8.81" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,421.35,501.43,91.66,8.64;7,111.58,513.38,56.51,8.64">TREC 2005 Genomics track overview</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">T</forename><surname>Bhupatiraju</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hearst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,186.73,513.22,198.03,8.58">Proceedings of the 14th Text Retrieval Conference</title>
		<meeting>the 14th Text Retrieval Conference</meeting>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,111.58,526.17,384.71,8.81" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,260.35,526.34,149.77,8.64">TREC 2007 Genomics track overview</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,428.76,526.17,38.68,8.58">TREC &apos;07</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,111.58,539.12,401.42,8.81;7,111.58,551.24,87.44,8.64" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,168.22,539.29,280.85,8.64">A linguistically motivated probabilistic model of information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,468.83,539.12,40.23,8.58">ECDL &apos;98</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="569" to="584" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,111.58,564.19,401.42,8.64;7,111.58,575.98,78.85,8.81" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,290.23,564.19,219.25,8.64">Parsimonious language models for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,122.37,575.98,39.22,8.58">SIGIR &apos;04</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,111.58,588.93,401.42,8.81" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,214.87,589.10,146.03,8.64">Transitive probabilistic CLIR models</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Jong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,379.32,588.93,104.40,8.58">Proceedings of RIAO 2004</title>
		<meeting>RIAO 2004</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,111.58,602.05,401.42,8.64;7,111.58,613.84,231.10,8.81" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,268.76,602.05,244.24,8.64;7,111.58,614.01,144.19,8.64">Better than the real thing?: iterative pseudo-query processing using cluster-based language models</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Kurland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Domshlak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,274.62,613.84,39.21,8.58">SIGIR &apos;05</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,111.58,626.96,401.42,8.64;7,111.58,638.75,147.79,8.81" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,209.52,626.96,303.48,8.64;7,111.58,638.91,61.84,8.64">Document language models, query models, and risk minimization for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,191.31,638.75,39.21,8.58">SIGIR &apos;01</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,111.58,651.70,341.17,8.81" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,231.92,651.87,133.92,8.64">Relevance based language models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">W</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,384.68,651.70,39.21,8.58">SIGIR &apos;01</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,111.58,664.82,401.42,8.64;7,111.58,676.60,109.30,8.81" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,215.97,664.82,297.03,8.64;7,111.58,676.77,21.91,8.64">Thesaurus-based feedback to support mixed search and browsing environments</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Meij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,152.25,676.60,39.78,8.58">ECDL &apos;07</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,111.58,689.55,401.42,8.81;7,111.58,701.68,22.42,8.64" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="7,324.95,689.72,125.82,8.64">Parsimonious concept modeling</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Meij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Trieschnigg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,469.80,689.55,39.26,8.58">SIGIR &apos;08</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,111.58,714.46,401.42,8.81;7,111.58,726.59,22.42,8.64" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="7,324.41,714.63,124.39,8.64">Parsimonious relevance models</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Meij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Weerkamp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,469.42,714.46,39.64,8.58">SIGIR &apos;08</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.58,112.17,401.42,8.81;8,111.58,124.29,22.42,8.64" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="8,230.65,112.34,220.10,8.64">A language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Ponte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,469.61,112.17,39.44,8.58">SIGIR &apos;98</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.58,137.25,401.42,8.64;8,111.58,149.03,212.07,8.81" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="8,181.20,137.25,331.80,8.64;8,111.58,149.20,78.77,8.64">A new unsupervised method for document clustering by using wordnet lexical and conceptual relations</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">R</forename><surname>Recupero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,197.62,149.03,33.43,8.58">Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="563" to="579" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.58,162.15,401.42,8.64;8,111.58,173.94,113.71,8.81" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="8,326.86,162.15,186.14,8.64;8,111.58,174.11,26.81,8.64">Measuring concept relatedness using language models</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Trieschnigg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Meij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,157.23,173.94,39.22,8.58">SIGIR &apos;08</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.58,186.89,401.42,8.81;8,111.58,199.01,72.50,8.64" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="8,210.04,187.06,237.87,8.64">Query expansion using local and global document analysis</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,469.13,186.89,39.93,8.58">SIGIR &apos;96</title>
		<imprint>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="4" to="11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.58,211.80,401.42,8.81;8,111.58,223.92,68.41,8.64" xml:id="b19">
	<monogr>
		<title level="m" type="main" coord="8,148.43,211.80,240.76,8.58">Risk Minimization and Language Modeling in Text Retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="8,111.58,236.87,401.42,8.64;8,111.58,248.66,321.86,8.81" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="8,213.56,236.87,299.45,8.64;8,111.58,248.83,31.67,8.64">Model-based feedback in the language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,161.14,248.66,39.22,8.58">CIKM &apos;01</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="403" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,111.58,261.78,401.42,8.64;8,111.58,273.56,239.09,8.81" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="8,210.52,261.78,302.48,8.64;8,111.58,273.73,31.67,8.64">A study of smoothing methods for language models applied to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,150.35,273.56,84.18,8.58">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="214" />
			<date type="published" when="2004-04">April 2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
