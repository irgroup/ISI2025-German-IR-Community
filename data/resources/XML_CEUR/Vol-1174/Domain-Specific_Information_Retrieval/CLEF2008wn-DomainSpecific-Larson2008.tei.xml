<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,111.72,98.73,379.88,15.51;1,263.04,120.69,76.91,15.51">Back to Basics -Again -for Domain Specific Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,269.76,154.07,63.74,9.96"><forename type="first">Ray</forename><forename type="middle">R</forename><surname>Larson</surname></persName>
							<email>ray@sims.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,111.72,98.73,379.88,15.51;1,263.04,120.69,76.91,15.51">Back to Basics -Again -for Domain Specific Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CCA1547DA8EB39E0AAD4AF520C192801</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing; H.3.3 Information Search and Retrieval Algorithms</term>
					<term>Performance</term>
					<term>Measurement Cheshire II</term>
					<term>Logistic Regression</term>
					<term>Entry Vocabulary Indexes</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we will describe Berkeley's approach to the Domain Specific (DS) track for CLEF 2008. Last year we used Entry Vocabulary Indexes and Thesaurus expansion approaches for DS, but found in later testing that some simple text retrieval approaches had better results than these more complex query expansion approaches. This year we decided to revisit our basic text retrieval approaches and see how they would stack up against the various expansion approaches used by other groups. The results are now in and the answer is clear, they perform pretty badly compared to other groups' approaches.</p><p>All of the runs submitted were performed using the Cheshire II system. This year the Berkeley/Cheshire group submitted a total of twenty-four runs, including two for each subtask of the DS track. These include six Monolingual runs for English, German, and Russian, twelve Bilingual runs (four X2EN, four X2DE, and four X2RU), and six Multilingual runs (two EN, two DE, and two RU). The overall results include Cheshire runs in the top five participants for each task, but usually as the lowest of the five (and often fewer) groups.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper discusses the retrieval methods and evaluation results for Berkeley's participation in the CLEF 2008 Domain Specific track. In 2007 we focused on query expansion using Entry Vocabulary Indexes(EVIs) <ref type="bibr" coords="1,149.09,645.71,13.64,9.96" target="#b3">[4,</ref><ref type="bibr" coords="1,165.60,645.71,7.05,9.96" target="#b5">6]</ref>, and thesaurus lookup of topic terms. Once the relevance judgements for 2007 were released we discovered that these rather complex method actually did not perform as well as basic text retrieval on the topics without additional query expansion. So, this year for the Domain Specific track we have returned to using a basic text retrieval approach using Probabilistic retrieval based on Logistic Regression with the inclusion of blind feedback, as used in 2006 <ref type="bibr" coords="1,443.24,693.59,12.47,9.96" target="#b4">[5]</ref>. All of the submitted runs for this year's Domain Specific track used the Cheshire II system for indexing and retrieval.</p><p>This paper first very briefly describes the probabilistic retrieval methods used, including our blind feedback method for text, which are also discussed in our other notebook papers for this year. We then describe our submissions for the various DS sub-tasks and the results obtained. Finally we present conclusions and discussion of future approaches to this track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Retrieval Algorithms</head><p>As we have discussed in our other papers for the Adhoc-TEL and GeoCLEF tracks, basic form and variables of the Logistic Regression (LR) algorithm used for all of our submissions were originally developed by Cooper, et al. <ref type="bibr" coords="2,218.06,600.35,10.00,9.96" target="#b2">[3]</ref>. To formally the LR method, the goal of the logistic regression method is to define a regression model that will estimate (given a set of training data), for a particular query Q and a particular document D in a collection the value P (R | Q, D), that is, the probability of relevance for that Q and D. This value is then used to rank the documents in the collection which are presented to the user in order of decreasing values of that probability. To avoid invalid probability values, the usual calculation of P (R | Q, D) uses the "log odds" of relevance given a set of S statistics, s i , derived from the query and database, giving a regression formula for estimating the log odds from those statistics:</p><formula xml:id="formula_0" coords="3,235.08,483.04,277.96,30.50">log O(R | Q, D) = b 0 + S i=1 b i s i (1)</formula><p>where b 0 is the intercept term and the b i are the coefficients obtained from the regression analysis of a sample set of queries, a collection and relevance judgements. The final ranking is determined by the conversion of the log odds form to probabilities:</p><formula xml:id="formula_1" coords="3,232.44,567.91,280.60,25.00">P (R | Q, D) = e log O(R|Q,D) 1 + e log O(R|Q,D)<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">TREC2 Logistic Regression Algorithm</head><p>For all of our Domain Specific submissions this year we used a version of the Logistic Regression (LR) algorithm that has been used very successfully in Cross-Language IR by Berkeley researchers for a number of years <ref type="bibr" coords="3,179.50,649.31,12.29,9.96" target="#b0">[1]</ref> and which is also used in our GeoCLEF and Domain Specific submissions.</p><p>For the Domain Specific track we used the Cheshire II information retrieval system implementation of this algorithm. One of the current limitations of this implementation is the lack of decompounding for German documents and query terms in the current system. As noted in our other CLEF notebook papers, the Logistic Regression algorithm used was originally developed by Cooper et al. <ref type="bibr" coords="4,151.44,73.43,10.57,9.96" target="#b1">[2]</ref> for text retrieval from the TREC collections for TREC2. The basic formula is:</p><formula xml:id="formula_2" coords="4,184.08,91.52,233.67,147.48">log O(R|C, Q) = log p(R|C, Q) 1 -p(R|C, Q) = log p(R|C, Q) p(R|C, Q) = c 0 + c 1 * 1 |Q c | + 1 |Qc| i=1 qtf i ql + 35 + c 2 * 1 |Q c | + 1 |Qc| i=1 log tf i cl + 80 -c 3 * 1 |Q c | + 1 |Qc| i=1 log ctf i N t + c 4 * |Q c |</formula><p>where C denotes a document component (i.e., an indexed part of a document which may be the entire document) and Q a query, R is a relevance variable, c k are the k coefficients obtained though the regression analysis.</p><formula xml:id="formula_3" coords="4,90.00,276.35,422.96,59.58">p(R|C, Q) is the probability that document component C is relevant to query Q, p(R|C, Q) the probability that document component C is not relevant to query Q, which is 1.0 - p(R|C, Q) |Q c |</formula><p>More details of this algorithm and the coefficients used with it may be found in our Adhoc-TEL notebook paper where the same algorithm and coefficients were used. In addition to this primary algorithm we used a version that performs "blind feedback" during the retrieval process. The method used is also described in detail in our Adhoc-TEL paper. Our blind feedback approach uses some number of top-ranked documents from an initial retrieval using the LR algorithm above, and selects some number of terms from the content of those documents, using a version of the Robertson and Sparck Jones probabilistic term relevance weights <ref type="bibr" coords="4,384.24,545.27,10.00,9.96" target="#b6">[7]</ref>. Those terms are merged with the original query and new term frequency weights are calculated, and the revised query submitted to obtain the final ranking. We used different numbers of documents and terms for different collections based on some tests run the 2007 data, varying these numbers to find the optimal point for the specific collection. For the German collection we selected 20 documents and the 35 topranked terms from those documents for feedback. For English we used 14 documents and 16 terms, and for Russian we used 16 documents and the topranked 10 terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approaches for Domain Specific Retrieval</head><p>In this section we describe the specific approaches taken for our submitted runs for the Domain Specific track. First we describe the database creation and the indexing and term extraction methods used, and then the search features we used for the submitted runs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Database creation</head><p>We essentially used the same databases used in 2007. Although the Thesaurus and Classification Clusters created for last year were available, we did not use them this year.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Indexing and Term Extraction</head><p>Although the Cheshire II system uses the XML structure of documents and extracts selected portions of the record for indexing and retrieval, for the submitted runs this year we used only a single one of these indexes that contains the entire content of the document.</p><p>Table <ref type="table" coords="5,132.12,574.31,4.98,9.96" target="#tab_1">1</ref> lists the indexes created for the Domain Specific database and the document elements from which the contents of those indexes were extracted. The "Used" column in Table <ref type="table" coords="5,466.81,586.31,4.98,9.96" target="#tab_1">1</ref> indicates whether or not a particular index was used in the submitted Domain Specific runs.</p><p>For all indexing we used language-specific stoplists to exclude function words and very common words from the indexing and searching. The German language runs, however, did not use decompounding in the indexing and querying processes to generate simple word forms from compounds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Search Processing</head><p>Searching the Domain Specific collection used Cheshire II scripts to parse the topics and submit the title and description elements from the topics to the "topic" index containing all terms from the documents. For the monolingual search tasks we used the topics in the appropriate language (English, German, or Russian), and for bilingual tasks the topics were translated from the source language to the target language using the LEC Power Translator PC-based program. Overall we have found that this translation program seems to generate good translations between any of the languages needed for this track, but we still intend to do some further testing to compare to previous approaches (which used web-based translation tools like Babelfish and PROMT). We suspect that, as always, different tools provide a more accurate representation of different topics for some languages, but the LEC Power Translator seemed to do pretty good (and often better) translations for all of the needed languages. All searches were submitted using the TREC2 Algorithm with blind feedback described above. This year we did no expansion of topics or use of the thesaurus or the classification clusters created last year. The differences in the runs for a given language or language pair (for bilingual) in Table <ref type="table" coords="6,90.00,427.55,4.98,9.96" target="#tab_2">2</ref> are primarily whether the topic title and description only (TD) or title, description and narrative (TDN).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results for Submitted Runs</head><p>The summary results (as Mean Average Precision) for all of our submitted runs for English, German and Russian are shown in Table <ref type="table" coords="6,277.46,506.27,3.90,9.96" target="#tab_2">2</ref>, the Recall-Precision curves for these runs are also shown in Figure <ref type="figure" coords="6,164.18,518.15,4.98,9.96" target="#fig_0">1</ref> (for monolingual), Figure <ref type="figure" coords="6,287.33,518.15,4.98,9.96" target="#fig_1">2</ref> (for bilingual) and Figure <ref type="figure" coords="6,411.74,518.15,4.98,9.96" target="#fig_2">3</ref> (for multilingual). In Figures <ref type="figure" coords="6,124.68,530.15,7.81,9.96" target="#fig_0">1,</ref><ref type="figure" coords="6,135.25,530.15,3.90,9.96" target="#fig_1">2</ref>, and 3 the names are abbrevated to the letters and numbers of the full name in Table <ref type="table" coords="6,507.99,530.15,4.98,9.96" target="#tab_2">2</ref> describing the languages and query expansion approach used. For example, in Figure <ref type="figure" coords="6,458.54,542.15,4.98,9.96" target="#fig_1">2</ref> DEEN-TD corresponds to run BRK-BI-DEEN-TD in Table <ref type="table" coords="6,303.73,554.03,3.90,9.96" target="#tab_2">2</ref>.</p><p>We observe that for the vast majority of our runs, using the narrative tends to degrade instead of improve performance. (We observed the same in other tracks as well.)</p><p>It is worth noting that the approaches used in our submitted runs provided the best results when testing with 2007 data and topics when compared to our official 2007 runs. In fact we may have over-simplified for this track. Although at least one Cheshire run appeared in the top five runs of the overall summary results available on the DIRECT system, none of them were top-ranked and for many tasks there appeared to be fewer than five participants. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>Since we have not yet had a chance to test alternative approaches on the 2008 topics and relevance judgement, we don't yet have much to report on ways forward. Given that the re-introduction of fusion approaches in our GeoCLEF entry led to very good results, we suspect that the application of selected fusion approaches for this task may also prove valuable.</p><p>We are much more curious to see what approaches the other groups in this task used this year, since some very strong results (at least compared to our own) appeared in the overall summary data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,90.00,68.87,423.05,9.96;2,90.00,80.87,87.40,9.96"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Berkeley Domain Specific Monolingual Runs for English (top left), German (top right), and Russian (lower)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,90.00,68.87,423.19,9.96;3,90.00,80.87,99.53,9.96"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Berkeley Domain Specific Bilingual Runs -To English (top left), to German (top right) and to Russian (lower)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,90.00,68.87,423.16,9.96;5,90.00,80.87,163.27,9.96"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Berkeley Domain Specific Multilingual Runs -From English (top left), from German (top right), and from Russian (lower)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,136.92,68.39,329.12,181.16"><head>Table 1 :</head><label>1</label><figDesc>Cheshire II Indexes for Domain Specific 2008</figDesc><table coords="6,136.92,81.08,329.12,168.47"><row><cell>Name</cell><cell>Description</cell><cell>Content Tags</cell><cell>Used</cell></row><row><cell>docno</cell><cell>Document ID</cell><cell>DOCNO, DOCID</cell><cell>no</cell></row><row><cell>author</cell><cell>Author name</cell><cell>AUTHOR</cell><cell>no</cell></row><row><cell>title</cell><cell>Article Title</cell><cell>TITLE-DE, TITLE-EN,</cell><cell>no</cell></row><row><cell></cell><cell></cell><cell>TITLE-RU, TITLE</cell><cell></cell></row><row><cell>topic</cell><cell>All Content Words</cell><cell>DOC</cell><cell>yes</cell></row><row><cell>date</cell><cell>Date</cell><cell>DATE, PUBLICATION-YEAR</cell><cell>no</cell></row><row><cell>subject</cell><cell cols="2">Controlled Vocabulary CONTROLLED-TERM-EN</cell><cell>yes</cell></row><row><cell></cell><cell></cell><cell>CONTROLLED-TERM-DE,</cell><cell></cell></row><row><cell></cell><cell></cell><cell>CLASSIFICATION-TEXT-EN,</cell><cell></cell></row><row><cell></cell><cell></cell><cell>CLASSIFICATION-TEXT-DE,</cell><cell></cell></row><row><cell></cell><cell></cell><cell>CLASSIFICATION,</cell><cell></cell></row><row><cell></cell><cell></cell><cell>KEYWORDS, KEYWORDS-RU,</cell><cell></cell></row><row><cell cols="2">geoname Geographic names</cell><cell>GEOGR-AREA, COUNTRY-CODE</cell><cell>no</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,150.12,68.39,302.57,323.48"><head>Table 2 :</head><label>2</label><figDesc>Submitted Domain Specific Runs</figDesc><table coords="7,150.12,81.08,302.57,310.79"><row><cell>Run Name</cell><cell>Description</cell><cell>Exp.</cell><cell>MAP</cell></row><row><cell>BRK-MO-DE-TD</cell><cell>Monolingual German</cell><cell>TD auto</cell><cell>0.3155</cell></row><row><cell>BRK-MO-DE-TDN</cell><cell>Monolingual German</cell><cell cols="2">TDN auto 0.3111</cell></row><row><cell>BRK-MO-EN-TD</cell><cell>Monolingual English</cell><cell>TD auto</cell><cell>0.3200</cell></row><row><cell>BRK-MO-EN-TDN</cell><cell>Monolingual English</cell><cell cols="2">TDN auto 0.3095</cell></row><row><cell>BRK-MO-RU-TD</cell><cell>Monolingual Russian</cell><cell>TD auto</cell><cell>0.1306</cell></row><row><cell>BRK-MO-RU-TDN</cell><cell>Monolingual Russian</cell><cell cols="2">TDN auto 0.1260</cell></row><row><cell>BRK-BI-ENDE-TD</cell><cell>Bilingual English⇒German</cell><cell>TD auto</cell><cell>0.1982</cell></row><row><cell cols="2">BRK-BI-ENDE-TDN Bilingual English⇒German</cell><cell cols="2">TDN auto 0.1726</cell></row><row><cell>BRK-BI-RUDE-TD</cell><cell cols="2">Bilingual Russian⇒German TD auto</cell><cell>0.1188</cell></row><row><cell cols="4">BRK-BI-RUDE-TDN Bilingual Russian⇒German TDN auto 0.1087</cell></row><row><cell>BRK-BI-DEEN-TD</cell><cell>Bilingual German⇒English</cell><cell>TD auto</cell><cell>0.1668</cell></row><row><cell cols="2">BRK-BI-DEEN-TDN Bilingual German⇒English</cell><cell cols="2">TDN auto 0.1454</cell></row><row><cell>BRK-BI-RUEN-TD</cell><cell>Bilingual Russian⇒English</cell><cell>TD auto</cell><cell>0.1765</cell></row><row><cell cols="4">BRK-BI-RUEN-TDN Bilingual Russian⇒ English TDN auto 0.1748</cell></row><row><cell>BRK-BI-DERU-TD</cell><cell cols="2">Bilingual German⇒Russian TD auto</cell><cell>0.0515</cell></row><row><cell cols="4">BRK-BI-DERU-TDN Bilingual German⇒Russian TDN auto 0.0550</cell></row><row><cell>BRK-BI-ENRU-TD</cell><cell>Bilingual English⇒Russian</cell><cell>TD auto</cell><cell>0.0857</cell></row><row><cell cols="2">BRK-BI-ENRU-TDN Bilingual English⇒Russian</cell><cell cols="2">TDN auto 0.0662</cell></row><row><cell>BRK-MU-DE-TD</cell><cell>Multilingual German</cell><cell>TD auto</cell><cell>0.0984</cell></row><row><cell>BRK-MU-DE-TDN</cell><cell>Multilingual German</cell><cell cols="2">TDN auto 0.0984</cell></row><row><cell>BRK-MU-EN-TD</cell><cell>Multilingual English</cell><cell>TD auto</cell><cell>0.1057</cell></row><row><cell>BRK-MU-EN-TDN</cell><cell>Multilingual English</cell><cell cols="2">TDN auto 0.1034</cell></row><row><cell>BRK-MU-RU-TD</cell><cell>Multilingual Russian</cell><cell>TD auto</cell><cell>0.0662</cell></row><row><cell>BRK-MU-RU-TDN</cell><cell>Multilingual Russian</cell><cell cols="2">TDN auto 0.0701</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,105.48,576.71,407.67,9.96;7,105.48,588.59,350.66,9.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,248.79,576.71,264.37,9.96;7,105.48,588.59,169.07,9.96">Multilingual information retrieval using machine translation, relevance feedback and decompounding</title>
		<author>
			<persName coords=""><forename type="first">Aitao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fredric</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,284.04,588.59,92.95,9.96">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="149" to="182" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.48,608.51,407.64,9.96;7,105.48,620.51,407.61,9.96;7,105.48,632.51,53.89,9.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,283.36,608.51,229.76,9.96;7,105.48,620.51,195.69,9.96">Full Text Retrieval based on Probabilistic Equations with Coefficients fitted by Logistic Regression</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">S</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,320.88,620.51,159.94,9.96">Text REtrieval Conference (TREC-2)</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.48,652.43,407.55,9.96;7,105.48,664.31,407.58,9.96;7,105.48,676.31,407.89,9.96;7,105.48,688.31,101.65,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,375.06,652.43,137.98,9.96;7,105.48,664.31,106.59,9.96">Probabilistic retrieval based on staged logistic regression</title>
		<author>
			<persName coords=""><forename type="first">William</forename><forename type="middle">S</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fredric</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><forename type="middle">P</forename><surname>Dabney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,232.92,664.31,280.14,9.96;7,105.48,676.31,180.45,9.96">15th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting><address><addrLine>Copenhagen, Denmark; New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1992">June 21-24. 1992</date>
			<biblScope unit="page" from="198" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.48,61.43,407.78,9.96;8,105.48,73.43,407.49,9.96;8,105.48,85.31,295.70,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,373.21,61.43,140.05,9.96;8,105.48,73.43,111.79,9.96">Entry vocabulary -a technology to enhance digital search</title>
		<author>
			<persName coords=""><forename type="first">Fredric</forename><surname>Gey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Buckland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aitao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ray</forename><surname>Larson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,244.44,73.43,268.53,9.96;8,105.48,85.31,124.98,9.96">Proceedings of HLT2001, First International Conference on Human Language Technology</title>
		<meeting>HLT2001, First International Conference on Human Language Technology<address><addrLine>San Diego</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-03">March 2001</date>
			<biblScope unit="page" from="91" to="95" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.48,105.35,407.45,9.96;8,105.48,117.23,407.37,9.96;8,105.48,129.23,340.25,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,183.97,105.35,185.54,9.96">Domain specific retrieval: Back to basics</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Larson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,396.48,105.35,116.45,9.96;8,105.48,117.23,407.37,9.96;8,105.48,129.23,115.14,9.96">Evaluation of Multilingual and Multi-modal Information Retrieval -Seventh Workshop of the Cross-Language Evaluation Forum, CLEF 2006, LNCS</title>
		<meeting><address><addrLine>Alicante, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-09">September 2006</date>
		</imprint>
	</monogr>
	<note>page to appear</note>
</biblStruct>

<biblStruct coords="8,105.48,149.15,407.55,9.96;8,105.48,161.03,407.37,9.96;8,105.48,173.03,407.77,9.96;8,105.48,185.03,22.93,9.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,310.72,149.15,202.31,9.96;8,105.48,161.03,269.03,9.96">Domain-specific CLIR of english, german and russian using fusion and subject metadata for query expansion</title>
		<author>
			<persName coords=""><forename type="first">Vivien</forename><surname>Petras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fredric</forename><surname>Gey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ray</forename><surname>Larson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,395.04,161.03,117.81,9.96;8,105.48,173.03,83.39,9.96">Cross-Language Evaluation Forum: CLEF 2005</title>
		<title level="s" coord="8,305.81,173.03,178.29,9.96">Lecture Notes in Computer Science LNCS</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">4022</biblScope>
			<biblScope unit="page" from="226" to="237" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.48,204.95,407.54,9.96;8,105.48,216.83,328.46,9.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,281.32,204.95,158.14,9.96">Relevance weighting of search terms</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">Sparck</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,450.36,204.95,62.67,9.96;8,105.48,216.83,181.66,9.96">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="page" from="129" to="146" />
			<date type="published" when="1976-06">May-June 1976</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
