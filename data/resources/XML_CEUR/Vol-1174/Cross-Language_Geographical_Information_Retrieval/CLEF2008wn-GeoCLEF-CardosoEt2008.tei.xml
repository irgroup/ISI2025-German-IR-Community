<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,141.47,148.79,320.07,15.48">The University of Lisbon at GeoCLEF 2008</title>
				<funder>
					<orgName type="full">Portuguese government</orgName>
				</funder>
				<funder ref="#_TuaSZwS">
					<orgName type="full">FCT (Portugal)</orgName>
				</funder>
				<funder>
					<orgName type="full">POSI</orgName>
				</funder>
				<funder ref="#_sGjU3st #_QcE5Yp2">
					<orgName type="full">European Union (FEDER and FSE)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,204.16,183.07,55.86,8.64"><forename type="first">Nuno</forename><surname>Cardoso</surname></persName>
						</author>
						<author role="corresp">
							<persName coords="1,266.97,183.07,56.58,8.64"><forename type="first">Patrícia</forename><surname>Sousa</surname></persName>
							<email>csousa@xldb.di.fc.ul.pt</email>
						</author>
						<author>
							<persName coords="1,342.92,183.07,55.93,8.64"><forename type="first">Mário</forename><forename type="middle">J</forename><surname>Silva</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Sciences</orgName>
								<orgName type="institution">University of Lisbon</orgName>
								<address>
									<postCode>1749-016</postCode>
									<settlement>LaSIGE, Lisboa</settlement>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<address>
									<settlement>Buildings</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,141.47,148.79,320.07,15.48">The University of Lisbon at GeoCLEF 2008</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5ED5F1496E1928EFE92D24CBF8B3F8AE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:17+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software Measurement, Performance, Experimentation Geographic IR, Named Entity Recognition, BM25 Optimisation, Query Expansion, GeoCLEF, Evaluation BRF Expansion biggest, tallest, skyscrapers, usa{1.0} | local:california{0.5}</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper reports the participation of the XLDB team from the University of Lisbon at the 2008 GeoCLEF task. We focused on developing a better text annotation tool for geo-parsing the documents, handling both explicit geographic evidence (as given by placenames) and implicit geographic evidence (as given by monuments, for example). The query processing and geographic ranking approaches were redesigned to handle thematic and geographic criteria of each search in a non-segregation way. We detail the GIR system, describe the optimisation procedure that preceded the run generation, and dissect the results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper presents the participation of the XLDB team from the University of Lisbon at the 2008 Geo-CLEF task. We matured the ideas implemented on last year's GIR system <ref type="bibr" coords="1,396.91,571.74,10.58,8.64" target="#b2">[3]</ref>, that achieved interesting results and pointed out some weaknesses of our approach. The main conclusions drawn were the following:</p><p>Best practices for handling thematic and geographic criteria. Our GIR methodology so far was moulded on the assumption that the thematic and geographic facets of documents and queries were complementary and non-redundant <ref type="bibr" coords="1,258.07,641.48,10.58,8.64" target="#b0">[1]</ref>. We therefore focused our research on GIR prototypes with separated pipelines for handling thematic and geographic subspaces, computing two different ranking scores that were combined in the end to generate a final ranking score. The evaluation results did not show a significative improvement compared to classic IR retrieval, and we wonder whether if this segregational approach is indeed a good practice for GIR <ref type="bibr" coords="1,372.42,689.30,10.58,8.64" target="#b3">[4]</ref>.</p><p>Capturing additional geographic evidence from documents. People describe places of their interest in several other ways, other than explicit placenames. Entities such as "Big Apple", "Kremlin" or "UE Headquarters" are easily connotated to their respective locations, and these entities might have a decisive role on the defining the geographic scope (that is, the geographic area of interest) of the document. Our shallow text mining approaches often failed to capture essential geographic evidence to geo-reference many documents, and this naïve text mining approach was reflected on poor retrieval results for some geographically challenging topics <ref type="bibr" coords="2,323.11,136.25,10.58,8.64" target="#b2">[3]</ref>. We therefore need to reformulate our text annotation tools, making it capable of recognising all kinds of entities with a geographic flavour and grounding them to their corresponding locations.</p><p>Smoothing the effects of text and geographic query expansion. Query expansion (QE) is known to improve IR performance in most queries, but often at the cost of degrading the performance on other queries <ref type="bibr" coords="2,146.97,203.80,10.58,8.64" target="#b7">[8]</ref>. QuerCol, the QE module used in our GIR prototypes, does not assign weights to the query terms, so the expanded terms have the same weight than the initial query terms. This means that we do not control the impact of QE in some topics, which led in some cases to query drifting and thus lead to poor retrieval results. We want to improve QueCol to perform automatic re-weighting of text and geographic terms, in order to soften the QE effect and prevent query drifting.</p><p>For this year's participation, we addressed these topics on the main improvements made in our GIR system, namely:</p><p>Query Processing: We now handle placenames as both geographic criteria and as plain query terms. In contrast to our initial ideas, placenames revealed to be in fact good retrieval terms, and they were frequently selected as the top ranking terms in the blind relevance feedback (BRF) process <ref type="bibr" coords="2,498.90,330.37,10.58,8.64" target="#b2">[3]</ref>. While placenames may be used in other unrelated contexts, such as proper names, they seem to help retrieval recall when used as plain terms, while its geographic content can be used afterwards to refine the ranking scores and promote documents with placenames referred in a geographic context.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Text mining:</head><p>We developed a new named entity recognition module, REMBRANDT, and used it as a text annotation tool to identify and classify all kinds of named entities in the CLEF collection <ref type="bibr" coords="2,477.11,397.93,10.58,8.64" target="#b1">[2]</ref>. This allows us to generate a more comprehensive geographic document signatures (D sig ), which is a list of geographic concepts already grounded from placenames found on each document. The D sig were first introduced on last year's participation as a representation of the document's scopes, and were used to compute the geographic similarity of documents to the query's scope <ref type="bibr" coords="2,422.62,445.75,10.58,8.64" target="#b2">[3]</ref>. The D sig comprise two kinds of geographic evidence: i) explicit geographic evidence, consisting of grounded placenames that designate geographic locations, such as countries, divisions or territories, and ii) implicit geographic evidence, consisting of other grounded entities that do not designate explicitly geographic locations but are strongly related to a geographic location, such as monuments, buildings, company headquarters or summits.</p><p>Document Processing: To cope with the new approaches on query processing, we needed a simple ranking model that elegantly combined the text and geographic subspace models, eliminating the need for merging text and geographic ranking scores, while still allowing us to assign a weight for each model on the retrieval. Therefore, we extended MG4J to suit our requirements for this year's experiments <ref type="bibr" coords="2,157.54,573.08,15.27,8.64" target="#b11">[12]</ref>, and we chose the BM25 weighting scheme to compute a single ranking score for documents <ref type="bibr" coords="2,161.62,585.03,10.58,8.64" target="#b8">[9]</ref>, using three index fields: text field, for standard term indexes, explicit local field, for geographic terms considered as explicit geographic evidence, and implicit local field, for geographic terms associated to the implicit geographic evidence.</p><p>The rest of the paper is organised as follows. Section 2 outlines our GIR prototype and describes in detail each module. Section 3 presents the optimising steps and the configurations selected for the submitted runs. Section 4 dissects both the official results in GeoCLEF and our post-hoc evaluation results, and Section 5 concludes the paper with insights drawn from this participation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Description</head><p>Figure <ref type="figure" coords="2,118.57,722.05,4.98,8.64" target="#fig_0">1</ref> describes the architecture of our GIR prototype. In a nutshell, the CLEF topics are pre-processed by QuerCol, generating query strings in MG4J syntax. The CLEF documents are geo-parsed by REM-BRANDT, a named entity recognition module, that plays the role as a text annotation tool and identifies</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>QuerCol 2008</head><p>Query expansion</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Geographic Ontology</head><p>GeoCLEF topics named entities that have geographic evidence, generating the geographic document signatures (D sig ). Afterwards, the text and D sig of the documents are indexed by MG4J. The document retrieval uses an optimised BM25 weighting scheme and receives the query strings from QuerCol, generating results in the trec_eval format. The geographic ontology assists only QuerCol in its geographic term expansions, as REMBRANDT and MG4J use other geographic knowledge resources, as described further in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>REMBRANDT</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">REMBRANDT</head><p>REMBRANDT is a language-dependent named-entity recognition (NER) system that uses Wikipedia as a raw knowledge resource, and explores the Wikipedia document structure to classify all kinds of named entities in the text. By using Wikipedia, REMBRANDT obtains additional knowledge on every named entity that can be useful for understanding the context, detecting relationships with other named entities, and use this information to contextualise and classify surrounding named entities in the text. One example of this additional knowledge in practice is the use of the Wikipedia page categories to derive implicit geographic evidence for each named entity. REMBRANDT handles category strings as text sentences and searches for place names in a similar way as it is performed on normal texts, generating a list of captured place names that are considered as implicit geographic evidence for the given named entity.</p><p>REMBRANDT currently classifies named entities using the 9 main categories and 47 sub-categories defined by the second edition of HAREM, a NER system evaluation contest for Portuguese <ref type="bibr" coords="3,459.32,536.51,15.77,8.64" target="#b10">[11,</ref><ref type="bibr" coords="3,477.84,536.51,11.83,8.64" target="#b9">10]</ref>. The main categories are: PERSON, ORGANIZATION, PLACE, DATETIME, VALUE, ABSTRACTION, EVENT, THING and MASTERPIECE. Rembrandt can handle vagueness in named entities, by tagging the named entities with more than one category or sub-category.</p><p>The REMBRANDT classification strategy relies on mapping each named entity to a Wikipedia page and subsequently analysing its document structure, links and categories, searching for suggestive evidences. REMBRANDT also relies on manually crafted rules for capturing internal and external evidence of named entities for both Portuguese and English texts, as suggested by McDonald <ref type="bibr" coords="3,397.39,620.20,10.58,8.64" target="#b6">[7]</ref>. These rules are used to classify named entities that were not mapped to a Wikipedia page or mapped to a page with insufficient information, and to contextualise named entities that have a different meaning (for example, in "I live in Portugal street", where the named entity "Portugal" designates a street, not a country).</p><p>The classification is best illustrated by following how the example named entity, "Empire State Building", is handled: the english Wikipedia page of the Empire State Building (en.wikipedia.org/wiki/ Empire_State_Building) is labelled with 10 categories, such as "Skyscrapers in New York City" and "Office buildings in the United States". With this information, REMBRANDT classifies the named entity as a PLACE/HUMAN/CONSTRUCTION. In the hypothetical case that this named entity could not be mapped to a Wikipedia page, internal evidence rules, such as the presence of the term "Building" in the end, can classify the named entity as a PLACE/HUMAN/CONSTRUCTION. which the named entity is inserted, ensuring that the named entity is not referred in another context (for example, as an hypothetical movie, street or restaurant name). For the detection of implicit geographic evidence, the categories "Skyscrapers in New York City" and "Office buildings in the United States" are handled by REMBRANDT as additional text, and the place names "New York City" and "United States" are captured and listed as implicit geographic evidence associated to the named entity "Empire State Building".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>From REMBRANDT annotations to geographic document signatures</head><p>Each CLEF document annotated with REMBRANDT contains a list of named entities that might convey explicit or implicit geographic evidence. We can now generate rich geographic document signatures D sig by adding named entities that have explicit geographic evidence, together with the placenames that were associated as implicit geographic evidence for other named entities. We divide the 47 sub-categories of named entities into 3 levels of eligibility, as depicted in Table <ref type="table" coords="4,336.65,509.37,3.88,8.64" target="#tab_0">1</ref>  This eligibility table of named entity classifications into D s ig signatures is a simplification exercise, and it is far from consensual. It is questionable whether categories such as PERSON can also convey a significative geographic evidence to define the document scopes. For instance, the named-entity "Nelson Mandela", as processed by REMBRANDT, is associated to "South Africa" as its implicit geographic evidence because the Wikipedia page of Nelson Mandela (en.wikipedia.org/wiki/Nelson_Mandela) contains the category "Presidents of South Africa". Yet, this geographic evidence may cause the drift from the document scope, because not all documents mentioning "Nelson Mandela" have the South African territory as their geographic scope.</p><p>On the other hand, we are assuming that all captured geographic evidence is relevant for the document scope, but this is not always true. Take for instance the named entity example "Empire State Building"; while it conveys an implicit location when it is addressed, for example, in a context of office headquarters, it is not important for the document scope when it is addressed on a context of its architectural style.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">QuerCol</head><p>QuerCol's query reformulation has two different procedures: first, it uses blind relevance feedback (BRF) for selected terms, and secondly, it performs geographic query expansion for geographic terms, by exploring the relationships between geographic concepts on a geographic ontology <ref type="bibr" coords="5,397.13,477.04,10.58,8.64" target="#b4">[5]</ref>.</p><p>Figure <ref type="figure" coords="5,134.40,488.99,4.98,8.64" target="#fig_1">2</ref> illustrates the two different expansion procedures of QuerCol, for the example query "Tall buildings in the USA". First, QuerCol removes the stopwords from the query, and recognises the geographic terms with the help of REMBRANDT. Afterwards, the non-stopwords tall, buildings and usa are expanded through BRF, using the w t (p t -q t ) algorithm to weight terms in a normalised scale of [0,1]. <ref type="bibr" coords="5,443.78,524.86,11.62,8.64" target="#b5">[6]</ref> The expanded terms are then merged with the initial query terms with an OR logic operator (|), labelled with their targeted index field and corresponding term weights, and finally assembled in a single query string.</p><p>On the other hand, the geographic term "USA" is grounded to the geographic concept 'United States of America (country)', triggering the ontology-driven geographic query expansion that searches for other geographic concepts known to be contained within the USA territory. The new geographic terms are then re-weighted according to the ontology node distance between the root node and the leaf node by the formula 1 n-1 . For the given example, USA generates 50 states with a weight of 1  2 and several cities with weight 1   3   (considering that the node distance in the ontology between states and countries is 1, and between cities and countries is 2). In the end, terms are labelled as search terms for the explicit local and implicit local index fields. These list of terms is desigated as the query geographic signature, the Q sig .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">MG4J indexing and ranking</head><p>MG4J is responsible for the indexing and retrieval of documents. MG4J indexes the text of CLEF documents into a text index field, while the D sig of the documents is divided in two geographic indexes: the explicit local and implicit local index fields, according to each type of geographic evidence. Figure <ref type="figure" coords="5,118.50,727.47,4.98,8.64" target="#fig_2">3</ref> presents an example of REMBRANDT's annotation and subsequent MG4J indexing steps.  We define term similarity as the similarity between query subjects and document subjects, and computed with the use of BM25 on the text index field only, and geographic similarity as the similarity between geographic signatures of queries and documents (Q sig and D sig ), computed with the use of BM25 on the explicit local and implicit local index fields. MG4J allows us to dynamically select the indexes to be used in the retrieval, and to change the weight of a field before retrieval.</p><formula xml:id="formula_0" coords="6,126.45,150.61,2.50,8.42">I</formula><p>Unfortunately, we were not able to extend the BM25 implementation on MG4J to support term weight, so all the terms weights were set to the defalut value of 1 for all the generated runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Run Generation</head><p>The run generation procedure is depicted in Figure <ref type="figure" coords="6,304.51,399.96,3.74,8.64" target="#fig_3">4</ref>. In an initial step, QuerCol processes the topics and performs only a geographic query expansion, generating an ontology expanded query. The ontology expanded query is submitted to MG4J, generating the initial run. The initial run with the best men average precision (MAP) value is chosen as the source of relevance for the blind relevance feedback step, performed by QuerCol on the ontology expanded query. In the end, QuerCol generates a final BRF + ontology expanded query, which is submitted to MG4J to generate the final run.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Optimising the GIR parameters</head><p>We thoroughly optimised the parameters of our GIR prototype, so that we could minimise the effect of a detuned GIR system on the MAP values, and increase our confidence that the results are a direct consequence of the approaches being evaluated. local index fields. For the QE step, we experimented with different blind relevance feedback parameters: the number of terms added for the final query, top-k-terms, and the number of top documents considered relevant, top-k-docs.</p><p>Figure <ref type="figure" coords="7,134.32,372.95,4.98,8.64" target="#fig_4">5</ref> describes the optimisation procedure performed on our GIR prototype with the help of the 2007 GeoCLEF data. We started with the default values for the BM25 parameters, and using only the text index field, we searched for the best BM25 values that generated the optimal MAP values. Then, with these BM25 parameters, we then optimised the index weight values according to the MAP values. The best initial run fed the blind relevance feedback process, and the optimisation procedure was repeated for the final run stage, using several combinations of top-k-terms and top-k-docs. In 2008, GeoCLEF allowed up to 12 official runs to be submitted, for each of the monolingual subtask. We submitted a total of 12 runs for each subtask, using the most promising parameters from the optimisation procedure, with a sligh variation on the index weights. Table <ref type="table" coords="7,352.92,681.52,4.98,8.64">2</ref> resumes the parameter values used for the official runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Configuration of the official runs</head><p>The official runs are composed by initial runs (#1 to #3) and final runs (#4 to #12). We experimented different ratios of text / explicit local index weights, by increasing and decreasing the text index weight by 0.5. This year, we participated in GeoCLEF with the purpose of maturing the ideas first coined on last year's participation, namely: i) the document geographic signatures must be more comprehensive, extraction all kinds of geographic evidence that can be derived from all named entities in the text, and ii) the thematic and geographic facets of each search are not antagonic, and could be used together to retrieve documents in a common weighting scheme that can elegantly combine term and geographic index fields.</p><p>The results showed that our GIR prototype is consistently better when using the geographic indexes on the retrieval, meaning that our GIR approach outperforms a classic IR retrieval in every GeoCLEF evaluation scenario since 2006. For future work, we plan to improve REMBRANDT's strategy for capturing implicit geographic evidence, as we believe that its naïve approach generated noisy signatures and it was responsible for the futility of the implicit local index field. We also want to develop a new adaptive strategy for QuerCol, as the optimal QE parameters vary for each topic, and using the same configuration set for all topics generates sub-optimal expanded queries. We also plan to rebuild the BM25 implementation of MG4J, so that term weights can be properly used on document retrieval.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,164.37,289.89,274.26,8.64"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Architecture of the GIR prototype used in GeoCLEF 2008.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,183.68,242.38,235.64,8.64"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: QuerCol's query reformulation strategy for 2008.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,163.17,240.29,276.66,8.64"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: REMBRANDT's text annotation and MG4J's indexing steps.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="6,228.85,644.52,145.30,8.64"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Run generation procedure.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="7,194.11,305.04,214.77,8.64"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Optimisation procedure for the GIR system.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="7,210.06,490.67,38.61,7.77;7,318.86,490.67,16.95,7.77;7,407.48,490.67,35.62,7.77;7,105.85,502.03,389.29,7.77;7,105.85,513.39,39.85,7.77;7,168.71,513.23,4.48,7.73;7,188.40,513.23,7.46,9.03;7,219.89,513.39,13.32,7.77;7,256.33,513.39,91.28,7.77;7,364.64,513.23,4.48,7.73;7,384.32,513.23,7.47,9.03;7,415.81,513.39,13.32,7.77;7,452.25,513.39,44.90,7.77;7,105.85,524.75,35.87,7.77;7,161.99,524.75,155.28,7.77;7,337.89,524.75,2.99,7.77;7,366.13,524.75,2.99,7.77;7,389.30,524.75,2.99,7.77;7,445.08,524.75,2.99,7.77;7,469.06,524.75,2.99,7.77;7,494.17,524.75,2.99,7.77;7,105.85,535.71,35.87,7.77;7,161.99,535.71,34.38,7.77;7,240.94,535.71,77.08,7.77;7,337.14,535.71,160.01,7.77;7,105.85,546.66,35.87,7.77;7,161.99,546.66,34.38,7.77;7,240.94,546.66,77.08,7.77;7,337.14,546.66,160.01,7.77;7,105.85,557.62,90.52,7.77;7,240.94,557.62,77.08,7.77;7,337.14,557.62,160.01,7.77;7,105.85,568.98,27.40,7.77;7,105.85,580.34,35.87,7.77;7,157.50,580.34,159.76,7.77;7,337.89,580.34,2.99,7.77;7,366.13,580.34,2.99,7.77;7,389.30,580.34,2.99,7.77;7,445.08,580.34,2.99,7.77;7,469.06,580.34,2.99,7.77;7,494.17,580.34,2.99,7.77;7,105.85,591.30,35.87,7.77;7,157.50,591.30,38.86,7.77;7,240.94,591.30,77.08,7.77;7,334.90,591.30,162.25,7.77;7,105.85,602.26,35.87,7.77;7,161.99,602.26,34.38,7.77;7,240.94,602.26,77.08,7.77;7,334.90,602.26,162.25,7.77;7,105.85,613.21,90.52,7.77;7,240.94,613.21,77.08,7.77;7,337.14,613.21,160.01,7.77;7,174.17,633.97,254.65,8.64"><head>Table 2 :</head><label>2</label><figDesc>number BM25 opt. Index weight optimisation top-k top-k BM25 opt. Index weight optimisation. The configuration parameters used for the official runs.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,303.95,739.75,209.04,8.64"><head>Table 1 :</head><label>1</label><figDesc>Finally, external evidence rules check the context on List of classification of NE categories and sub-categories, as having explicit, implicit or no geographic evidence for the generation of D sig .</figDesc><table coords="4,129.40,109.13,344.20,200.45"><row><cell>Explicit geographic evidence</cell><cell cols="2">No geographic evidence</cell></row><row><cell>PLACE/PHYSICAL/ISLAND</cell><cell>THING/CLASS</cell><cell>ABSTRACTION/DISCIPLINE</cell></row><row><cell>PLACE/PHYSICAL/WATERCOURSE</cell><cell>THING/CLASSMEMBER</cell><cell>ABSTRACTION/STATE</cell></row><row><cell>PLACE/PHYSICAL/WATERMASS</cell><cell>THING/OBJECT</cell><cell>ABSTRACTION/IDEA</cell></row><row><cell>PLACE/PHYSICAL/MOUNTAIN</cell><cell>THING/SUBSTANCE</cell><cell>ABSTRACTION/NAME</cell></row><row><cell>PLACE/PHYSICAL/REGION</cell><cell></cell><cell></cell></row><row><cell>PLACE/PHYSICAL/PLANET</cell><cell>PLACE/VIRTUAL/MEDIA</cell><cell>MASTERPIECE/WORKOFART</cell></row><row><cell></cell><cell>PLACE/VIRTUAL/ARTICLE</cell><cell>MASTERPIECE/REPRODUCED</cell></row><row><cell>PLACE/HUMAN/REGION</cell><cell>PLACE/VIRTUAL/SITE</cell><cell>MASTERPIECE/PLAN</cell></row><row><cell>PLACE/HUMAN/DIVISION</cell><cell></cell><cell></cell></row><row><cell>PLACE/HUMAN/STREET</cell><cell>PERSON/POSITION</cell><cell>TIME/GENERIC</cell></row><row><cell>PLACE/HUMAN/COUNTRY</cell><cell>PERSON/INDIVIDUAL</cell><cell>TIME/DURATION</cell></row><row><cell></cell><cell>PERSON/INDIV.GROUP</cell><cell>TIME/FREQUENCY</cell></row><row><cell>Implicit geographic evidence</cell><cell>PERSON/POSIT.GROUP</cell><cell>TIME/HOUR</cell></row><row><cell></cell><cell>PERSON/MEMBER</cell><cell>TIME/INTERVAL</cell></row><row><cell>EVENT/PASTEVENT</cell><cell>PERSON/MEMBERGROUP</cell><cell>TIME/DATE</cell></row><row><cell>EVENT/ORGANIZED</cell><cell>PERSON/PEOPLE</cell><cell></cell></row><row><cell>EVENT/HAPPENING</cell><cell></cell><cell></cell></row><row><cell></cell><cell>VALUE/CURRENCY</cell><cell></cell></row><row><cell>PLACE/HUMAN/CONSTRUCTION</cell><cell>VALUE/CLASSIFICATION</cell><cell></cell></row><row><cell></cell><cell>VALUE/QUANTITY</cell><cell></cell></row><row><cell>ORGANIZATION/ADMINISTRATION</cell><cell></cell><cell></cell></row><row><cell>ORGANIZATION/INSTITUTION</cell><cell></cell><cell></cell></row><row><cell>ORGANIZATION/COMPANY</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,102.45,509.37,410.55,225.82"><head>: 1 .</head><label>1</label><figDesc>Sub-categories that have explicit geographic evidence: all sub-categories under the main category PLACE, with the exception of the sub-categories PLACE/HUMAN/CONSTRUCTION and PLACE/VIRTUAL/*. The category PLACE mostly spans the administrative domain and physical domain, but the PLACE/VIRTUAL/* sub-categories span virtual places such as web sites, newspaper articles or TV programs, and therefore are not eligible for inclusion in the geographic signatures. In HAREM, the subcategory PLACE/HUMAN/CONSTRUCTION is included in the PLACE main category, precisely because of its strong geographic connotation, but it is not an explicit geographic entity. As such, the subcategory PLACE/HUMAN/CONSTRUCTION is handled in the next level.</figDesc><table coords="4,102.45,634.51,410.55,56.85"><row><cell>2. Sub-categories that have implicit geographic evidence: the categories ORGANIZATION, EVENTS</cell></row><row><cell>and sub-category PLACE/HUMAN/CONSTRUCTION. The category ORGANIZATION spans institutions and</cell></row><row><cell>corporations, such as city halls, schools or companies, which are normally related to a defined geo-</cell></row><row><cell>graphic area of interest. The category EVENTS spans organised events that normally take place in a</cell></row><row><cell>defined place, such as olympic games, rock concerts or conferences.</cell></row></table><note coords="4,102.45,702.26,410.55,9.03;4,114.91,714.61,398.09,8.64;4,114.91,726.56,286.41,8.64"><p>3. Sub-categories that have no geographic evidence: categories considered to have no significative contribution for the geographic signatures. It spans the categories PERSON, THING, ABSTRACTION, MASTERPIECE, TIME and VALUE, and sub-categories PLACE/VIRTUAL/*.</p></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We thank <rs type="person">David Cruz</rs> and <rs type="person">Sebastiano Vigna</rs> for the modifications made to MG4J according to the experiments, and to <rs type="person">Marcirio Chaves</rs> for updating the geographic ontology. Our participation was jointly funded by the <rs type="funder">Portuguese government</rs> and the <rs type="funder">European Union (FEDER and FSE)</rs> under contract ref. <rs type="grantNumber">POSC/339/1.3/C/NAC</rs> (Linguateca), and partially supported by grants <rs type="grantNumber">SFRH/BD/29817/2006</rs> and <rs type="grantNumber">POSI/SRI/40193/2001</rs> (<rs type="projectName">GREASE</rs>) from <rs type="funder">FCT (Portugal)</rs>, co-financed by <rs type="funder">POSI</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_sGjU3st">
					<idno type="grant-number">POSC/339/1.3/C/NAC</idno>
				</org>
				<org type="funding" xml:id="_QcE5Yp2">
					<idno type="grant-number">SFRH/BD/29817/2006</idno>
				</org>
				<org type="funded-project" xml:id="_TuaSZwS">
					<idno type="grant-number">POSI/SRI/40193/2001</idno>
					<orgName type="project" subtype="full">GREASE</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>During the optimisation, we observed that the BM25 optimisation for the Portuguese subtask presentes many local optimal MAP values, so we decided to submit runs with three BM25 configurations from different areas, to increase the odds of standing near a global optimal BM25 parameter. For the English optimisation, we observed that the BRF parameters had more influence on the optimal MAP values than the BM25 parameters, so we submitted runs with different BRF parameter values. Also worth mentioning is the fact that the implicit local index field did not improved MAP values in any optimisation scenario, and thus it was turned off on all official runs.  We observe that our best Portuguese run was in fact an initial run (with a MAP of 0.2234), and the post-hoc optimisation corroborated the fact that the best MAP values for Portuguese are achieved by initial runs (with the best MAP value of 0.2301), which is somewhat unexpected. For the English subtask, the best run was indeed a final run, achieving a MAP value of 0.2755, that could be pushed further up to 0.2814 with optimised parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Best</head><p>The results show that the use of explicit local index field on the retrieval process improves the results in all evaluation scenarios, while the explicit local index field does not contribute at all to the improvement of the retrieval results. This fact proves that the GIR prototype is able to outperform a classic IR system in a consistently way, but it also contradicts our initial beliefs that implicit geographic evidence would have an important role on the D sig . In fact, we only observe that the explicit local index field takes part on the best MAP values for GeoCLEF 2006, which we think that it might be related to the geographically generic topics used in that year (mostly about countries and continents), which favours the implicit geographic evidence (that is also normally given by countries and continents).</p><p>Another topic of interest of the results is that we were not so far away from the optimal MAP values as we initially expected to be, and thus we believe that we did not over-fitted our GIR system with the 2007 data. Nonetheless, the post-hoc optimisation revealed that the English topic sets are quite balanced, where we consistently achieved MAP values around 0.28, while the difficulty of the Portuguese topic sets is more unpredictable. This reveals how important it is to tune up a system according to the collections and topics, as the default parameter values rarely produce good results.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="9,109.92,418.73,403.08,7.93;9,109.92,427.50,403.08,7.93;9,109.92,436.43,59.33,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,158.72,418.89,252.07,7.77">GeoVSM: An Integrated Retrieval Model for Geographic Information</title>
		<author>
			<persName coords=""><forename type="first">Guoray</forename><surname>Cai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,429.23,418.73,83.77,7.73;9,109.92,427.50,275.20,7.73">Proceedings of the 2nd International Conference on Geographic Information Science, GIScience&apos;02</title>
		<meeting>the 2nd International Conference on Geographic Information Science, GIScience&apos;02<address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="65" to="79" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,109.92,447.59,403.08,7.77;9,109.92,456.20,403.08,7.93;9,109.92,465.13,133.48,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,168.51,447.59,344.49,7.77;9,109.92,456.36,68.23,7.77">REMBRANDT -Reconhecimento de Entidades Mencionadas Baseado em Relações e Análise Detalhada do Texto</title>
		<author>
			<persName coords=""><forename type="first">Nuno</forename><surname>Cardoso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,339.59,456.20,105.24,7.73">Encontro do Segundo HAREM</title>
		<editor>
			<persName><forename type="first">Cristina</forename><surname>Mota</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Diana</forename><surname>Santos</surname></persName>
		</editor>
		<meeting><address><addrLine>Aveiro, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-09-11">11th September 2008</date>
		</imprint>
	</monogr>
	<note>in Portuguese</note>
</biblStruct>

<biblStruct coords="9,109.92,476.29,403.08,7.77;9,109.92,484.90,403.08,7.93;9,109.92,493.66,403.08,7.93;9,109.92,502.43,237.97,7.93" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,354.98,476.29,158.02,7.77;9,109.92,485.06,130.63,7.77">Using Geographic Signatures as Query and Document Scopes in Geographic IR</title>
		<author>
			<persName coords=""><forename type="first">Nuno</forename><surname>Cardoso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Cruz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marcirio</forename><surname>Chaves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mário</forename><forename type="middle">J</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,260.00,484.90,253.00,7.73;9,109.92,493.66,188.90,7.73">Advances in Multilingual and Multimodal Information Retrieval: 8th Workshop of the Cross-Language Evaluation Forum</title>
		<title level="s" coord="9,414.36,493.66,98.64,7.73;9,109.92,502.43,25.92,7.73">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>CLEF</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007. 2008</date>
			<biblScope unit="volume">5152</biblScope>
			<biblScope unit="page" from="802" to="810" />
		</imprint>
	</monogr>
	<note>Revised Selected papers</note>
</biblStruct>

<biblStruct coords="9,109.92,513.60,403.08,7.93;9,109.92,522.36,403.08,7.93;9,109.92,531.29,74.46,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,231.59,513.76,216.58,7.77">To separate or not to separate: reflections about GIR practice</title>
		<author>
			<persName coords=""><forename type="first">Nuno</forename><surname>Cardoso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Diana</forename><surname>Santos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,464.07,513.60,48.93,7.73;9,109.92,522.36,363.75,7.73">1st Workshop on Novel Methodologies for Evaluation in Information Retrieval, NMEIR 2008 (ECIR&apos;2008 Workshop)</title>
		<meeting><address><addrLine>Glasgow, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-03-30">30 March 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,109.92,542.30,403.07,7.93;9,109.92,551.06,403.08,7.93;9,109.92,559.99,22.31,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,242.37,542.46,199.05,7.77">Query Expansion through Geographical Feature Types</title>
		<author>
			<persName coords=""><forename type="first">Nuno</forename><surname>Cardoso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mário</forename><forename type="middle">J</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,462.07,542.30,50.93,7.73;9,109.92,551.06,256.23,7.73">4th Workshop on Geographic Information Retrieval, GIR&apos;07 (CIKM&apos;2007 Workshop)</title>
		<meeting><address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007-11-09">9th November 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,109.92,571.16,403.08,7.77;9,109.92,579.76,196.56,7.93" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,204.10,571.16,292.65,7.77">A user-centered evaluation of ranking algorithms for interactive query expansion</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Efthimis</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Efthimiadis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,109.92,579.76,112.07,7.73">Proceedings of ACM SIGIR &apos;93</title>
		<meeting>ACM SIGIR &apos;93</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="146" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,109.92,591.09,403.07,7.77;9,109.92,599.69,403.08,7.93;9,109.92,608.62,147.94,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,165.59,591.09,343.22,7.77">Internal and external evidence in the identification and semantic categorization of proper names</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,268.97,599.69,189.32,7.93">Corpus processing for lexical acquisition, chapter 2</title>
		<editor>
			<persName><forename type="first">I</forename><surname>Boguraev</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Pustejovsky</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="21" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,109.92,619.63,403.07,7.93;9,109.92,628.39,403.08,7.73;9,109.92,637.32,205.60,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,260.31,619.79,144.01,7.77">Improving Automatic Query Expansion</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,425.76,619.63,87.23,7.73;9,109.92,628.39,398.94,7.73">Proceedings of the 21st Annual International ACM Conference on Research and Development in Information Retrieval, SIGIR&apos;1998</title>
		<meeting>the 21st Annual International ACM Conference on Research and Development in Information Retrieval, SIGIR&apos;1998<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="206" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,109.92,648.49,403.07,7.77;9,109.92,657.09,390.50,7.93" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,481.65,648.49,31.35,7.77;9,109.92,657.25,27.97,7.77">Okapi at TREC-3</title>
		<author>
			<persName coords=""><forename type="first">Steve</forename><surname>Stephen E Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Micheline</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aarron</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marianna</forename><surname>Gull</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,155.49,657.09,176.73,7.73">Proceedings of the 3rd Text REtrieval Conference</title>
		<meeting>the 3rd Text REtrieval Conference<address><addrLine>Gaithersburg, MD, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="21" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,109.92,668.42,403.08,7.77;9,109.92,677.02,403.08,7.93;9,109.92,685.95,244.44,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,360.15,668.42,152.85,7.77;9,109.92,677.19,26.26,7.77">Second HAREM: new challenges and old wisdom</title>
		<author>
			<persName coords=""><forename type="first">Diana</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paula</forename><surname>Carvalho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hugo</forename><surname>Oliveira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cláudia</forename><surname>Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,156.10,677.02,352.10,7.73">International Conference on Computational Processing of Portuguese Language, PROPOR&apos;2008</title>
		<meeting><address><addrLine>Aveiro, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-09-10">8-10th September 2008</date>
		</imprint>
	</monogr>
	<note>Accepted for publication</note>
</biblStruct>

<biblStruct coords="9,109.92,697.12,403.08,7.77;9,109.92,705.88,403.08,7.77;9,109.92,714.49,403.08,7.93;9,109.92,723.26,268.88,7.93" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,331.14,697.12,181.86,7.77;9,109.92,705.88,51.57,7.77">HAREM: An Advanced NER Evaluation Contest for Portuguese</title>
		<author>
			<persName coords=""><forename type="first">Diana</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nuno</forename><surname>Seco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nuno</forename><surname>Cardoso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rui</forename><surname>Vilela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,234.03,714.49,278.97,7.73;9,109.92,723.26,84.41,7.73">Proceedings of the 5th International Conference on Language Resources and Evaluation, LREC&apos;2006</title>
		<editor>
			<persName><forename type="first">Nicoletta</forename><surname>Calzolari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Khalid</forename><surname>Choukri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Aldo</forename><surname>Gangemi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Bente</forename><surname>Maegaard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Joseph</forename><surname>Mariani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jan</forename><surname>Odjik</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Daniel</forename><surname>Tapias</surname></persName>
		</editor>
		<meeting>the 5th International Conference on Language Resources and Evaluation, LREC&apos;2006<address><addrLine>Genoa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-05">May 2006</date>
			<biblScope unit="page" from="22" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,109.92,734.59,403.08,9.73;9,109.92,745.32,59.26,7.77" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="9,242.62,734.59,145.69,9.73">MG4J: Managing Gigabytes for Java TM</title>
		<author>
			<persName coords=""><forename type="first">Sebastiano</forename><surname>Vigna</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paolo</forename><surname>Boldi</surname></persName>
		</author>
		<ptr target="http://mg4j.dsi.unimi.it/" />
		<imprint>
			<date type="published" when="2007-12">December 2007</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
