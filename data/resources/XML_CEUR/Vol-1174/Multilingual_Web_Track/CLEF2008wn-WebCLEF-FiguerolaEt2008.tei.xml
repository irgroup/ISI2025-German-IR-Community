<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,187.66,148.86,227.68,15.15">REINA at WebCLEF 2008</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,101.56,182.75,84.24,8.74"><forename type="first">Carlos</forename><forename type="middle">G</forename><surname>Figuerola</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">REINA Research Group</orgName>
								<orgName type="institution">University of Salamanca</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,193.48,182.75,102.19,8.74"><forename type="first">José</forename><forename type="middle">L Alonso</forename><surname>Berrocal</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">REINA Research Group</orgName>
								<orgName type="institution">University of Salamanca</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,304.62,180.24,105.89,11.26"><forename type="first">Ángel</forename><forename type="middle">F</forename><surname>Zazo Rodríguez</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">REINA Research Group</orgName>
								<orgName type="institution">University of Salamanca</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,418.53,182.75,82.92,8.74"><forename type="first">Montserrat</forename><surname>Mateos</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">REINA Research Group</orgName>
								<orgName type="institution">University of Salamanca</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,187.66,148.86,227.68,15.15">REINA at WebCLEF 2008</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">AC00A6156E77388B62F3C8C5820630BE</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Managment]: Languages-Query Languages Measurement, Performance, Experimentation Web retrieval, Text segmentation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The task for this year is very similar to last year. However, this time we incorporate last year's experience, in particular, we explored the possibility of improving the selection of snippets, eliminating those that do not make sense, as well as those containing duplicate information. Also, it is intended to explore the real impact of the use of several languages in obtaining relevant fragments.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This year, the WebCLEF track is similar to the 2007 edition, that is: retrieving text snippets or fragments of web pages which bring up information about a topic; additionally, snippets must be in a language from a set of accepted ones. As in 2007, we have a set of topics, each with a title and a short description, as well as several documents or known sources about the topic. Additionally, for each topic, we have one or several searches in Google, with the first 1000 documents retrieved.</p><p>The system used is basically the same as last year, for each topic we considered all documents retrieved after queries to Google as the collection of documents with which to work. These documents are to be fragmented into pieces, each of whom will be treated as a separate document.</p><p>For the queries, we use the description that we have for each topic. This query can be enriched with more terms from the known sources. So, the task can be approached like a classic problem of retrieval, and apply, consequently, conventional techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Segmentation od web pages</head><p>Organizers of task provide us the translation to plain text of documents retrieved by Google. We have valued equal all the searches in Google for same topic. UTF-8 worked fine in almost all cases, something important as there was documents in several languages and with different alphabets (including Cyrillic, for example). That freed us of the many problems experienced in previous editions with the detection of the coding system of each document. So, for each document translated to plain text, we have to segment it in fragments, to obtain the terms of each fragment and to calculate its weights.</p><p>To segment documents and to obtain fragments or short text passages can be applied diverse techniques. Basically, ones are based on the size in bytes, or words; and others are oriented in the separation in phrases or paragraphs <ref type="bibr" coords="2,272.92,171.80,9.96,8.74" target="#b6">[6]</ref>. The former techniques produce, of course, pieces more homogenous in size, but often devoid of sense, as the partition point is blind. The other techniques tend to produce fragments of very different size. In addition, its application not always is simple; in many cases the conversion to plain text of a web document loses the separations between paragraphs, nondifference between soft and hard line feeds, or blurs structural elements, like the tables <ref type="bibr" coords="2,154.26,231.57,9.96,8.74" target="#b5">[5]</ref>.</p><p>A simplist approach, like the election of a orthographic character, as the period (.) like reference to fragment the text <ref type="bibr" coords="2,183.68,255.48,9.96,8.74" target="#b1">[2]</ref>, tends to produce passages too short and, therefore, little useful for the objectives of this task. In our case, we adopted a mixed approach. After several tests, we decided that the suitable size for each fragment was around the 1500 bytes, but as we wanted fragments that had informative sense, our fragmenter looks for the period closest the 1500 bytes, and part by that point. Some other transformations were carried out: conversion to small letters, removing accents, removing stopwords, (with a long list of stop words for all the accepted languages), application of a simple s-stemmer.</p><p>Each fragment thus obtained and transformed was considered an independent document. Terms were extracted and they were weighed according to scheme ATU (slope=0.2) <ref type="bibr" coords="2,459.05,363.08,9.96,8.74" target="#b3">[3]</ref>, applying to the good well-known vectorial model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Formation of queries</head><p>From the document collection formed with snippets, we must select those that are more usefull for each topic. The key is in composing suitable queries that can produce this selection. As sources of information to compose those queries, we have topics with a short title and a brief description. Additionally, we also have, for each topic, a few documents denominated known sources, in full text.</p><p>So we can use topics (title and description) like nucleus of each query, and enrich this one with terms coming from the known sources. The known sources are complete documents, which can contain many terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">What's new for this year</head><p>Last year we worked on the formation of the queries. The basic dilemma was whether the core of each topic (title and description) could be enriched by the terms of the known sources, and to what extent the use of these terms adds useful information to the query.</p><p>Results showed little difference in using terms of known sources or not. It's better to use these terms, ma non tropo. However, runs of last year showed more things. Web pages are not conventional documents; in addition to hyperlinks and hypermedia elements, they have a structure that is not always sequentially. Many web pages are viewed by the user as a set of visual blocks that have different functions and containing different types of information <ref type="bibr" coords="2,407.34,651.94,9.96,8.74" target="#b4">[4]</ref>. From the standpoint of obtaining this information, some blocks are more useful than others. The conventional tools of conversion to plain text are not able to reproduce this visual structure, the result is that many of the fragments that we get are meaningless. Others contain information not relevant to our purposes: navigational aids, copyright notices, advertising, etc..</p><p>Unfortunately, this visual structure can not be obtained from the elements of HTML and this a difficult area to address, although there are some jobs that are trying to solve these problems <ref type="bibr" coords="2,90.00,735.63,9.96,8.74" target="#b0">[1]</ref>.</p><p>We tried a very naive approach, filtering and dropping snippets based on a simple heuristics: fragments with too many blank lines, with very short lines, with a few words in relation to the size of the fragment, and so on. So, from 639 215 snippets obtained from documents , our filter deleted 165 442 (=25.88 %). This would suggest that we work with a database with a lot of noise, a deepening in the way of extracting fragments could possibly significantly improve results.</p><p>In similar way, last year we observed a lot of duplicated snippets. Information is replicated across the web, and so we have fragments of different pages that have the same information. However, as visual presentation is not always the same, the results of the conversion to plain text produces different strings. We used the Dice Coefficient as measure to compare snippets and discover duplicates and almost duplicates. In this case, we applied detection of duplicates on the retrieved snippets for each topic. So, if we consider snippets with Dice similarity greater than 0.7, we found that 11.08 % are duplicates ones.</p><p>On the other hand, one may wonder whether the retrieval of fragments in different languages provide more relevant information, and to what extent. All topics allow at least fragments into English as a useful response and, additionally, in other languages. It is expected that these fragments in other languages are derived from queries which include terms in those other languages. We made a run using queries in English only, which should allow us to compare results and assess whether the extent to which the use of other languages aid in retrieval.</p></div>		</body>
		<back>

			<div type="acknowledgement">
<div><head n="5">Conclusions</head><p>We have described our approach to WebCLEF task, similar to last year, but incorporating the experience of the last edition. On this occasion, although on the same basis, we have focused on the effect of filtering meaningless fragments, detect duplicates, as well as in estimating the importance of documents in languages other than English. At the time of writing these notes does not yet have the results of experiments.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="3,105.50,472.61,407.51,8.74;3,105.50,484.57,407.50,8.74;3,105.50,496.52,115.43,8.74" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="3,208.20,472.61,304.81,8.74;3,105.50,484.57,112.28,8.74">A preliminary report for an information extraction system based on visual block segmentation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<idno>TR-IS-2007-1</idno>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>Hanyang University, Intelligent Systems Laboratory</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="3,105.50,516.45,407.50,8.74;3,105.50,528.40,383.01,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="3,186.92,516.45,125.40,8.74">Tagging sentence boundaries</title>
		<author>
			<persName coords=""><forename type="first">Andrei</forename><surname>Mikheev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,338.22,516.45,174.79,8.74;3,105.50,528.40,318.52,8.74">Proceedings of the First Meeting of the North American Chapter of the Computational Linguistics (NAACL2000)</title>
		<meeting>the First Meeting of the North American Chapter of the Computational Linguistics (NAACL2000)</meeting>
		<imprint>
			<biblScope unit="page">264271</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,491.66,528.40,21.34,8.74;3,105.50,540.36,93.27,8.74" xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Morgan</forename><surname>Kaufmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,105.50,560.28,407.50,8.74;3,105.50,572.24,407.50,8.74;3,105.50,584.19,407.50,8.74;3,105.50,596.15,209.25,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="3,334.25,560.28,174.28,8.74">Pivoted document length normalization</title>
		<author>
			<persName coords=""><forename type="first">Amit</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mandar</forename><surname>Mitra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,119.24,572.24,393.76,8.74;3,105.50,584.19,163.11,8.74">Proceedings of the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>Zurich, Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1996">August 18-22, 1996. 1996</date>
			<biblScope unit="page" from="21" to="29" />
		</imprint>
	</monogr>
	<note>Special Issue of the SIGIR Forum</note>
</biblStruct>

<biblStruct coords="3,105.50,616.07,407.50,8.74;3,105.50,628.03,201.69,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="3,275.75,616.07,177.67,8.74">Html page analysis based on visual cues</title>
		<author>
			<persName coords=""><forename type="first">Yudong</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hongjiang</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,477.32,616.07,29.73,8.74">ICDAR</title>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="859" to="864" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,105.50,647.95,407.51,8.74;3,105.50,659.91,407.50,8.74;3,105.50,671.87,407.50,8.74;3,105.50,683.82,110.47,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="3,352.37,647.95,160.64,8.74;3,105.50,659.91,261.26,8.74">Improving pseudo-relevance feedback in web information retrieval using web page segmentation</title>
		<author>
			<persName coords=""><forename type="first">Shipeng</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Deng</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ji-Rong</forename><surname>Wen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,394.70,659.91,118.29,8.74;3,105.50,671.87,237.82,8.74">Proceedings of the Twelfth International World Wide Web Conference, WWW2003</title>
		<meeting>the Twelfth International World Wide Web Conference, WWW2003<address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003-05-24">20-24 May 2003. 2003</date>
			<biblScope unit="page" from="11" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,106.74,701.23,406.26,11.26;3,105.50,715.70,407.51,8.74;3,105.50,727.66,48.70,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="3,472.42,703.75,40.58,8.74;3,105.50,715.70,174.32,8.74">Reformulation of queries using similarity thesauri</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Ángel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><forename type="middle">G</forename><surname>Zazo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">José</forename><surname>Figuerola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alonso</forename><surname>Luis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Emilio</forename><surname>Berrocal</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Rodríguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="3,287.51,715.70,166.95,8.74">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1163" to="1173" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
