<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,131.15,148.86,340.69,15.15;1,92.37,170.78,418.26,15.15">Exploiting Cooccurrence on Corpus and Document Level for Fair Crosslanguage Retrieval</title>
				<funder>
					<orgName type="full">State of Styria</orgName>
				</funder>
				<funder>
					<orgName type="full">Austrian Research Promotion Agency FFG</orgName>
				</funder>
				<funder ref="#_w4HXUM6">
					<orgName type="full">Austrian Ministry of Transport, Innovation and Technology</orgName>
				</funder>
				<funder>
					<orgName type="full">Austrian Ministry of Economics and Labor</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,181.26,204.67,75.61,8.74"><forename type="first">Andreas</forename><surname>Juffinger</surname></persName>
							<email>ajuffinger@know-center.at</email>
							<affiliation key="aff0">
								<orgName type="department">Know-Center</orgName>
								<address>
									<settlement>Graz</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,264.26,204.67,56.06,8.74"><forename type="first">Roman</forename><surname>Kern</surname></persName>
							<email>rkern@know-center.at</email>
							<affiliation key="aff0">
								<orgName type="department">Know-Center</orgName>
								<address>
									<settlement>Graz</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,343.02,204.67,78.71,8.74"><forename type="first">Michael</forename><surname>Granitzer</surname></persName>
							<email>mgranitzer@know-center.at</email>
							<affiliation key="aff0">
								<orgName type="department">Know-Center</orgName>
								<address>
									<settlement>Graz</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,131.15,148.86,340.69,15.15;1,92.37,170.78,418.26,15.15">Exploiting Cooccurrence on Corpus and Document Level for Fair Crosslanguage Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">72CC237AC8139440385B260C55D10409</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Managment]: Languages Measurement, Performance, Experimentation Information Retrieval, Associative Thesaurus, Word Sense Disambiguation, Crosslanguage Retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe the methodology, architecture and implementation of the information retrieval system we have developed for the Robust WSD Task at CLEF 2008. Our system is based on an extensive query preprocessing step for homogenisation of the corpus queries. The preprocessing of queries includes: firstly, an query expansion step based on Wordnet Synonsyms or an Associative Index, secondly a query translation step based on corpus article cooccurrence in Wikipedia, and thirdly a standard disjunct index search in the CLEF corpus. The crosslanguage enabled system behaves thereby as much as possible fair over different languages. We apply the same preprocessing steps, independent of the query and corpus language, to all queries.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The CLEF 2008 robust task has aimed at combining semantic and information retrieval. The goal of the task was to test whether WSD can be used beneficially for retrieval systems. For this the organizers provided document collections annotated with word sense disambiguation (WSD) from previous CLEF campaigns. The english documents and the queries have been annotated by the winning WSD system from the previous year by <ref type="bibr" coords="1,326.97,658.42,10.52,8.74" target="#b0">[1]</ref> and <ref type="bibr" coords="1,361.66,658.42,10.52,8.74" target="#b1">[2]</ref> based on WordNet version 1.6. The spanish queries have been annotated by the "First Sense Heuristic" based on the spanish WordNet. The organizers believe that polysemy is among the reasons for information retrieval systems to fail.</p><p>Our approach for this task is based on the following methodology: Firstly, we build an index for the document corpus. Secondly, for each query we generate a list of hierarchical disjunct query terms in the corpus language, and thirdly, we use these query terms to search in one of the corpus index: plain document index, WSD document index, and MST network index. The plain document index was used to calculate the result without WSD information, the WSD document index to get the task result including WSD information and at last a the MST network index for retrieval with implicetly disambiguation for baseline comparison. Altough we have deployed only a single run from our system to the challange, we discuss the idea behind the whole system architecture and lessons learned also for the crosslanguage task.</p><p>In order to compare different translation and disambiguation strategies our goal was to provide a fair approach to crosslanguage retrieval: each query is preprocessed in the same way independent of the query and target language. In other words: the system aim was to build a cross language retrieval system which is fair across different languages Fig. <ref type="figure" coords="2,358.55,207.66,16.38,8.74" target="#fig_0">1(a)</ref>. The positive bias for English queries, resulting from their formulation in the corpus language, is reduced yielding to more comparable, more fair results between different languages.</p><p>Within our retrieval system we exploit cooccurrences on corpus level to achive thid fair cross language retrieval under these conditions. For the experiments in this task we used the English and Spanish Wikipedia<ref type="foot" coords="2,192.18,265.86,3.97,6.12" target="#foot_0">1</ref> . For the mapping between the articles from one language to the other language we have extracted the cross-language links between the spanish articles and their english counterparts. Every query was then processed as shown in Fig <ref type="figure" coords="2,382.53,291.35,16.83,8.74" target="#fig_0">1(b)</ref>: Firstly, we queried the Wikipedia index in the query language. Secondly, we used the appropriate english articles to extract significant english query terms. Thirdly, we used these query terms to query one of the CLEF indexes (see Sections 2.3).  The remaining contribution is structured as follows: Section 2 provides an overview on our system in terms of index structures and methodology used. Section 3 details the query processing technique which is at the heart of our approach. Results are outlined in Section 4 and Section 5 concludes this contribution with an future outlook.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Architecture</head><p>The whole system is based on a number of different indexes as shown in Figure <ref type="figure" coords="2,427.95,624.13,3.87,8.74">2</ref>. The Multilingual Wikipedia Index and the Associative Index apply thereby at the query preprocessing layer and the Plain, WSD and MST Index are the different indexes of the task corpus data. The whole system was implemented in Java, based on the Apache Lucene<ref type="foot" coords="2,366.06,658.42,3.97,6.12" target="#foot_1">2</ref> text search engine library. This search engine library provides a high performance text retrieval engine for arbitrary, configurable indexes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Statistical Corpus Analysis</head><p>For statistical corpus analyse we have developed a dictionary modul in Java. The calculation of term weighting functions like TFIDF <ref type="bibr" coords="3,244.08,319.96,15.72,8.74" target="#b3">[4,</ref><ref type="bibr" coords="3,262.62,319.96,7.75,8.74" target="#b5">6]</ref> or BM25 TFIDF <ref type="bibr" coords="3,340.08,319.96,15.72,8.74" target="#b4">[5]</ref> is very data intensive and one needs many statistics from the dictionary. To calculate these weighting functions as well as to reveal other term statistics from the corpus we have tuned our dictionary to fit into memory. A simple implementation with a single document term matrix is unfeasable, due to the fact that this matrix would have a minimum size 80 bill. cells, 160000 articles multiplied by at least 500000 terms. Our implementation exploits the sparsity of the document term matrix and stores therefore only the term vectors per document. A first implementation based on java.lang.String revealed, that most of the memory is used to store the terms, Fig. <ref type="figure" coords="3,321.51,403.64,4.57,8.74" target="#fig_3">3</ref>(b) triangle trajectory. For calculating the statistics it is not necessary to store the terms text and therefore we implemented a disk based mapping from strings to integer values and we hold only these integer ids in memory with the effect of a tenth memory usage: Fig. <ref type="figure" coords="3,231.17,439.51,4.57,8.74" target="#fig_3">3</ref>(b) squares trajectory. With this approach we have been able to calculate all statistics in memory but with the drawback of complex reconstruction of human readable document term vectors. Due to the fact that every Java object needs at least 16bytes of memory, and strings are represented in UTF16 (4bytes per character) we decided to store the terms as UTF8 in byte arrays. The average length of the terms in this corpus is 6 characters what leads to an average term size of 6 bytes (nearly no non ascii characters occurre in english texts). Note that an integer always needs 4 bytes, so the overhead of storing the terms in byte arrays is 2 byte per term and therefore about 2 megabytes for a million terms. One can see in Fig. <ref type="figure" coords="3,494.73,523.19,13.70,8.74" target="#fig_3">3(b</ref>) diamond trajectory, that this approach is competitive with the integer id approach but with the advantage of holding all information in memory for fast document term vector reconstruction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Query Preprocessing Indexes</head><p>As discussed in the introduction we perform query preprocessing on every incoming query independent of the query language. The indexes we have build for query preprocessing are the Multilingual Wikipedia Index and the Cooccurrence Association Index.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Multilingual Wikipedia Index</head><p>One important component of the system is the multilingual Wikipedia index. This index is created using the English and Spanish Wikipedia data. If an article is available in both langugae versions it is added to the multilangual Wikipedia index and an internal reference between the english and spanish text is created. Thus it is possible to search in one language and retrieve the article in the other language. To build this index the public available XML dumps are parsed and indexed. No special treatment was applied to the article text. The MediaWiki content was indexed as is without processing, stemming or stop-word removal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Cooccurrence Association Index</head><p>One standard procedure applied for query expansion is the usage of term cooccurrence statistics. This approach calculates a weigthing scheme between terms based on their cooccurrence within all documents of an corpus. The basic rationale behind this calculations is the assumption that statistically significant cooccurrences have a good chance to be synonyms <ref type="bibr" coords="4,405.00,166.27,13.93,8.74" target="#b2">[3]</ref>.</p><p>The cooccurrence network in our system is based on the Wikipedia multilingual index. For each language of this corpus (english and spanish) a separate term-term network is computed. The weights between terms are calculated by using an similarity measure based on the cosine similarity. Only cooccurrences within a predefined token vicinity are used and additionaly the distances between two terms within an Wikipedia article also contribute to the term similarity weights. Each term-term network is then stored in an associative index for fast retrieval of adjacent terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Robust Task Retrieval Indexes</head><p>In this section we describe the different indexes we have created to retrieve the news articles from the CLEF corpus. Each of the following CLEF index contains all documents from the Los Angeles Times (1994) and Glasgow Herald (1995) dataset. From the documents only the content was processed, title or other metadata has been ignored.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Plain Document Index</head><p>For the plain text variant, the data has been processed by the default Lucene indexing chain. The newspaper plain text has been tokenized by whitespaces and then transformed to lower case. The dictionary containes about 600000 terms and tokens and the overall index uses 3.4G disk storage. The analysis of the term dictionary revealed a interesting artefact of the corpus in the vocabulary growth function. One easily discover that there are two different underlying datasources for the corpus (see Fig. <ref type="figure" coords="4,166.11,436.17,17.27,8.74" target="#fig_3">3(a)</ref>) -the LA Times (1994) and the Glasgow Herald (1995) with a slightly different vocabulary. A growth function for a homogen corpus would look like a single continous growing logarithmic function without an inflexion point. The reason for this inflexion point is the addition of two different logarithmic functions -one for each newspaper. The reason for the different logarithmic functions is the cultural difference and therefore a different word pool between Scotland and California.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">WSD Document Index</head><p>For the word sense disambiguated variant, we used the available WSD information to compute the synonyms for the document terms. To maximize the impact of the WSD information we decided to only take the WordNet Sense with highest WSD value from the data if the term was annotated with more than one sense. All found synonym terms were indexed at the same position within the document as the original term to prevail phrase queries. Simply speaking, the Lucene index is a document term matrix. Each document is thereby represented as a vector of terms. Lucene does further allow to put more than one term on every term vector position. All terms on the same position are then transparently interchangeable. For example the term baby and the synonym infant indexed on the same position makes it possible, that the phrase query baby food would retrieve all documents, where either baby food or infant food occurs as phrase. This behavior comes from the way as Lucene processes phrase queries: Firstly, all documents are searched with a "boolean and query" for all terms in the phrase. Secondly, Lucene retrieves the "distance" inbetween the terms within the term vector of all matching documents. Thirdly, if the "distance" inbetween the query terms is one, then the phrase matches. Thats the reason why terms at the same position are completly interchangeable in phrase queries. Again no additional processing other than case normalization were applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">MST Network Index</head><p>For the maximum spanning tree (MST) network index we extracted, based on the part of speach (POS) tags in the corpus, only nouns from each newspaper article. Note that the focus on nouns is necessary due to the fact that otherwise the following network calculations became inpracticable and nouns carry the most valuable information. After stemming and stopword removal we ended up with an adequate list of nouns per document. To identify significant cooccurring terms α and β we test the statistical evidence by a chi-square test of independence for with the following contingency table (Tab. 1). The values A, B, C and D are the respective counts of the terms based on the scope: A the total number of terms in the corpus, B the number of occurences of the term β, C number of terms associated with the term α and D the number of terms wich occure with term α and β.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>∀ β Corpus Distribution A B Cooccurring with α C D Table 1: Chi-Square Contingency Table</head><p>Statistically significant tuples are then used to construct a document cooccurrence network. Each document is therefore described by a term network which contains only corpus significant term tuples where both terms occure in the document. At this level all term networks are fully connected if one takes all cooccurrences on document level into account. To prune the networks we used only the 50 top most tuples. Note that the tuple ranking is based on a corpus wide level and so the globally most significant tuples are used for each document and the fixed number of tuples leads to a corpus based "length" normalisation.</p><p>To index these networks it is necessary to serialize the term graphs into a term sequence. A general graph has no explizit start node, neither an intuitive walking strategy to visit every node. A solution to the travelling salesman problem (TSP) starting at a specific term, would lead to a reproducable term ordering, but the TSP is NP hard and therefore not computable in reasonable time. The serialization of trees is deterministic and so we transform the network in a tree and then serialize the tree in infix order. As a first heuristically transformation of the network into a tree we calculate the maximum spanning tree, based on the cooccurrence weights, of the term network. Note that higher weights stand for statistically more significant cooccurring terms. The resulting tree was then serialized in infix order starting by alphabetically lower node of the most significant term tuple.</p><p>Each query is first processed and special characters are removed, like for example interpunctation. Query terms that contain underscore charaters or terms enclosed with quotation marks are treated as phrases. For these phrases the word order is maintained throughout the whole process. After the tokenization process all query terms are removed that are found in a language specific stop word list.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Wordnet Query Expansion</head><p>The first query expansion strategy makes use of the available word sense disambiguation information. For each term that carries Wordnet synset annotations the synset with the highest score is selected. Only from this synset the synonyms form the query expansion terms. The synonyms for the spanish query terms were also taken from the english Wordnet thus no further translation processes were needed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Associative Query Expansion</head><p>For the query expansion the individual terms are used as start nodes in the term network calculated from the cooccurrence associative index. Adjacent terms from this network were then included in  One can see that the associative expanded query terms are quite different for the term report. The reason for this is that the associative results are computer generated based on cooccurrence statistics and the Wordnet expansion is based on human edited synonyms. Note that we have discovered, that for other terms the results are fully "overlapping" between the association and the wordnet method. Althought extensive evaluations are depending we are confident, that the association method is very helpfull for query expansion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Query Translation</head><p>After the query terms has been preprocessed and optionally the query has been expanded by synonyms or cooccurrences, each query terms is translated to the search corpus target language. For this task. we have applied this processing to both spanish and english queries, even if the target language is english. This is done to achieve optimal fairness for each query language.</p><p>Each term forms a search query within the multilingual Wikipedia index restricted to the language of the query. From the search result set the ids and the score of the top 50 results were collected. Using these ids the english version of the Wikipedia articles are retrieved from the index. All term from these articles are extracted and a weight for each term was aggregated. The weight for each term were calculated using the score of the article multiplied with the inverse document frequency of that term. For all terms from all top articles the aggregated weight was used to sort the result terms. From this sorted list of terms the top 5 were selected and used to build the final query for the target index.</p><p>A major advantage of this approach is that it relies only on term distribution statistics to"translate" english and spanish terms into english query terms. No additional knowledge base, like an dictionary are used. Note that the presented results have been reached without extensive tuning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Search CLEF Articles</head><p>The collected and translated query terms, developed by the whole query preprocessing pipeline as shown in Fig. <ref type="figure" coords="7,164.32,685.15,4.98,8.74" target="#fig_4">4</ref> with or without the optional query expansion and multilingual steps, are then used to build up a hierarchical disjunction query. Depending on the task either the index with or withoud WSD information was then searched with this disjunction query. The default Lucene scoring algorithm, based on TFIDF, was used to calculate the rank of the retrieved articles.</p><p>As one of our best system configuration we have applied at the CLEF 2008 Robust Task the Associative Pipeline as shown in Fig. <ref type="figure" coords="8,254.02,145.80,16.38,8.74" target="#fig_8">6(a)</ref>. For this pipeline we used the associative query expansion modul, the english Wikipedia translation modul. The query terms developed by this process haven then been applied as disjunct query terms to the CLEF Plain Index with the results shown in Fig. <ref type="figure" coords="8,122.72,181.66,16.83,8.74" target="#fig_8">6(b)</ref>. As mandatory by the task we also have applied the WSD Version of this run with the pipeline shown in Fig. <ref type="figure" coords="8,206.70,193.62,4.43,8.74" target="#fig_10">7</ref>(a) and the results shown in Fig. <ref type="figure" coords="8,358.14,193.62,3.87,8.74" target="#fig_10">7</ref>   Based on the original system implementation we haven't been able to successfully apply WSD information. Although the results are slightly better for a number of queries, we have not been able to show a statistically significant improvement.   Motivated by the fact that our system failes by a hight number of queries we tried to figure out whats the reason for this. We have identified a bug in our system in the preprocessing pipeline of the Wikipedia Index, which we have fixed for later runs. Deflated by the suboptimal results we also evaluated the impact of the methodology of beeing fair to every language. As shown in Fig. <ref type="figure" coords="9,110.27,123.98,4.43,8.74">8</ref>(a) started to evaluate the impact of the earlier noted bug in our implementation. Without the improvements we lost about 6 to 7 percentage precision for our Wikipedia methodology in comparance to "direct" retrieval without the Wikipedia normalisation. Unfortunately, the impact of the parsing problem biased our applied result significantly. The improved system is now about 2 to 3 percentage points worse than the "direct" retrieval baseline, and therefore we know that our system can perform significantly better. One can see in Fig. <ref type="figure" coords="9,379.56,183.75,4.57,8.74">8</ref>(b) our system now performs always better than the earlier version, what makes us confident that will be able to resolve the remaining difference, or in other words the costs for the methodology will be insignificant. (a) Negligible Methodology Impact P@1 P@2 P@3 P@5 P@10 P@50 P@100 P@500P@1000 0 0.1 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Evaluation of the Crosslanguage Methodology</head><p>The central point in our methodology is that the system is able to do fair cross language retrieval. Therefore we have evaluated the system performance on spanish queries. For this test we have used the pipeline shown in Fig. <ref type="figure" coords="9,230.22,510.58,4.43,8.74" target="#fig_14">9</ref>(a) with Wordnet Query Expansion and the Spanish Wikipedia and Plain CLEF Index. The performance of the retrieval task is shown in Fig. <ref type="figure" coords="9,442.87,522.54,4.21,8.74" target="#fig_14">9</ref>(b). Again the "optimal" performance of the system is the "direct" english method WN Min.EN.</p><p>The crosslanguage retrieval performance is shown in this Figure as WN Plain.ES. One can see that this crosslingual system performance ist nearly the same as the WN Plain.EN monolingual performance, from which one can derive, that our system is, as intended, also competitive for the crosslingual case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this working note we have outlined our retrieval system for fair crosslanguage retrieval. Although we have applied only on the monolingual task we have been able to show, that our system perform as good as for the monolingual task in the crosslingual setup. Further we have shown that this fairness condition is not a major constraint. For the applied results we have not been able to show a significant improvement for the retrieval task when using word sense disambiguation information. The reason for this is probably, that the system is still not optimal for the retrieval task without WSD so the expected improvement through WSD might be lost by still undiscovered systematical faults of the system.</p><p>One of our next steps will be a deeper analysis of a number of Wikipedia articles as cooccurrence corpus. Although we have already looked up a number of articles we have not been able to develop Query Spanish Wordnet Expansion Spanish Wikipedia</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CLEF Plain Index</head><p>Search Result (a) Query Pipeline Crosslingual Retrieval P@1 P@2 P@3 P@5 P@10 P@50 P@100 P@500 P@1000  explezit characteristics to select the optimal cooccurring articles from the Wikipedia. Another important improvement to our system would be a more sophisitcated preprocessing module for our indexes.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,230.07,510.14,142.85,8.74"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Retrieval Methodology</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,237.19,257.79,128.63,8.74"><head></head><label></label><figDesc>Figure 2: Sytem Architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,223.19,668.45,156.62,8.74"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Corpus Growth Functions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="6,207.23,543.56,188.54,8.74"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Overview of the query processing</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="7,167.96,112.50,87.47,8.74;7,170.45,124.45,82.49,8.74;7,131.82,160.60,109.10,9.13;7,265.49,160.99,17.32,8.74;7,166.68,182.98,83.39,6.99;7,382.84,118.08,26.90,8.74;7,320.11,160.60,25.46,8.74;7,364.03,160.99,22.66,8.74;7,407.13,160.60,21.51,8.74;7,448.88,159.68,23.04,8.74;7,337.86,182.98,113.54,6.99;7,289.71,210.04,26.90,8.74;7,248.24,252.56,25.46,8.74;7,288.85,253.92,79.31,8.74;7,240.45,274.38,122.10,6.99"><head>Find</head><label></label><figDesc></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="7,237.05,297.76,128.91,8.74"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Query Process Tree</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="8,195.10,358.19,5.36,3.17;8,195.10,345.11,5.36,3.17;8,195.10,332.02,5.36,3.17;8,195.10,318.94,5.36,3.17;8,195.10,305.85,5.36,3.17;8,339.17,378.36,26.12,3.17;8,188.28,354.88,4.46,12.19;8,188.28,351.07,4.46,2.86;8,188.28,340.02,4.46,10.10;8,188.28,336.20,4.46,2.86;8,188.28,330.48,4.46,4.77;8,188.28,312.19,4.46,17.34;8,254.35,302.07,198.57,3.17;8,279.90,391.43,134.64,6.99"><head></head><label></label><figDesc>of the Experiment Ad-Hoc Robust Monolingual English Test Task -Distribution of the Topics of the Experiment (b) Comparison Median R-Precision</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8" coords="8,202.14,422.39,198.73,8.74"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Associative Retrieval without WSD</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9" coords="8,195.10,633.65,5.36,3.17;8,195.10,620.57,5.36,3.17;8,195.10,607.48,5.36,3.17;8,195.10,594.40,5.36,3.17;8,195.10,581.31,5.36,3.17;8,339.17,653.82,26.12,3.17;8,188.28,630.34,4.46,12.19;8,188.28,626.53,4.46,2.86;8,188.28,615.48,4.46,10.10;8,188.28,611.66,4.46,2.86;8,188.28,605.94,4.46,4.77;8,188.28,587.65,4.46,17.34;8,223.34,577.53,261.01,3.17;8,279.90,666.89,134.64,6.99"><head></head><label></label><figDesc>of the Experiment Ad-Hoc Robust Word Sense Disambiguation Monolingual English Test Task -Distribution of the Topics of the Experiment (b) Comparison Median R-Precision</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10" coords="8,209.33,697.85,184.33,8.74"><head>Figure 7 :</head><label>7</label><figDesc>Figure 7: Associative Retrieval with WSD</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12" coords="9,241.64,428.44,119.71,8.74"><head></head><label></label><figDesc>Figure 8: Improved Results</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_14" coords="10,202.93,317.97,197.15,8.74"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Crosslingual Retrieval Performance</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,95.49,193.62,402.04,214.27"><head></head><label></label><figDesc>.</figDesc><table coords="8,95.49,211.13,402.04,196.76"><row><cell></cell><cell></cell><cell></cell><cell>Ad-Hoc Robust Monolingual English Test Task -Box plot of the Topics of the Experiment</cell></row><row><cell>Query</cell><cell></cell><cell></cell><cell></cell></row><row><cell>English</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Associative</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Expansion</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0%</cell><cell>5%</cell><cell>10% 15% 20% 25% 30% 35% 40% 45% 50% 55% 60% 65% 70% 75% 80% 85% 90% 95% 100%</cell></row><row><cell></cell><cell></cell><cell></cell><cell>R-Precision</cell></row><row><cell>English</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Wikipedia</cell><cell></cell><cell></cell><cell></cell></row><row><cell>CLEF Plain</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Index</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Search</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Result</cell><cell>0% 0</cell><cell>5%</cell><cell>10% 15% 20% 25% 30% 35% 40% 45% 50% 55% 60% 65% 70% 75% 80% 85% 90% 95% 100%</cell></row><row><cell>(a) Query Pipeline As-</cell><cell></cell><cell></cell><cell></cell></row><row><cell>sociative Retrieval</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,105.24,701.47,101.62,6.64"><p>http://www.wikipedia.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,105.24,710.97,101.62,6.64"><p>http://lucene.apache.org</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>The <rs type="institution">Know-Center</rs> is funded within the <rs type="programName">Austrian COMET Program -Competence Centers for Excellent Technologies</rs> -under the auspices of the <rs type="funder">Austrian Ministry of Transport, Innovation and Technology</rs>, the <rs type="funder">Austrian Ministry of Economics and Labor</rs> and by the <rs type="funder">State of Styria</rs>. COMET is managed by the <rs type="funder">Austrian Research Promotion Agency FFG</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_w4HXUM6">
					<orgName type="program" subtype="full">Austrian COMET Program -Competence Centers for Excellent Technologies</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,105.50,519.10,407.50,8.74;10,105.50,531.06,304.98,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,240.08,519.10,214.15,8.74">UBC-ALM: Combining k-NN with SVD for WSD</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Agiree</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><forename type="middle">L</forename><surname>De Lacall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,478.43,519.10,34.57,8.74;10,105.50,531.06,206.39,8.74">Proc. of the 4th Int. Workshop on Semantic Evaluations</title>
		<meeting>of the 4th Int. Workshop on Semantic Evaluations</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="341" to="345" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,105.50,550.98,407.50,8.74;10,105.50,562.94,407.50,8.74;10,105.50,574.90,79.33,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,271.71,550.98,241.28,8.74;10,105.50,562.94,186.34,8.74">NUS-PT: Exploiting parallel texts for word sense disambiguation in the english all-words tasks</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">T</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,315.99,562.94,197.00,8.74;10,105.50,574.90,48.87,8.74">Proc. of the 4th Int. Workshop on Semantic Evaluations</title>
		<meeting>of the 4th Int. Workshop on Semantic Evaluations</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,105.50,594.82,407.50,8.74;10,105.50,606.78,407.50,8.74;10,105.50,618.73,111.93,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,278.44,594.82,176.55,8.74">Extending folksonomies for image tagging</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Kern</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Granitzer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Pammer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,473.43,594.82,39.57,8.74;10,105.50,606.78,327.46,8.74">WIAMIS 2008 , Special Session on Multimedia Metadata Management andRetrieval</title>
		<meeting><address><addrLine>Klagenfurt</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,105.50,638.66,323.91,8.74" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="10,183.33,638.66,93.25,8.74">Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Rijsbergen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
			<publisher>Butterworths</publisher>
		</imprint>
	</monogr>
	<note>2nd Edition</note>
</biblStruct>

<biblStruct coords="10,105.50,658.58,407.50,8.74;10,105.50,670.54,407.50,8.74;10,105.50,682.49,188.28,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,245.39,658.58,267.61,8.74;10,105.50,670.54,147.48,8.74">Some simple effective approximations to the 2-poisson model for probabilistic weighted retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,285.48,670.54,227.53,8.74;10,105.50,682.49,158.43,8.74">Proc. of the ACM SIGIR conference on research and development in information retrieval</title>
		<meeting>of the ACM SIGIR conference on research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,105.50,702.42,407.50,8.74;10,105.50,714.37,186.15,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,226.72,702.42,238.57,8.74">Term-weighting approaches in automatic text retrieval</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,487.65,702.42,25.36,8.74;10,105.50,714.37,154.84,8.74">Information Processing and Management</title>
		<imprint>
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
