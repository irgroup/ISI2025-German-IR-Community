<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,158.76,92.27,294.15,11.88">UniNE at CLEF 2008: TEL, Persian and Robust IR</title>
				<funder ref="#_ZmpzCBE">
					<orgName type="full">Swiss National Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,218.88,114.45,61.86,8.43"><forename type="first">Ljiljana</forename><surname>Dolamic</surname></persName>
							<email>ljiljana.dolamic@unine.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Neuchatel</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,289.80,114.45,52.65,8.43"><forename type="first">Claire</forename><surname>Fautsch</surname></persName>
							<email>claire.fautsch@unine.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Neuchatel</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,351.12,114.45,54.95,8.43"><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
							<email>jacques.savoy@unine.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="institution">University of Neuchatel</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,158.76,92.27,294.15,11.88">UniNE at CLEF 2008: TEL, Persian and Robust IR</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">39FB1FD8F800949C84383F01FD1C0687</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.1 [Content Analysis and Indexing]: Indexing methods</term>
					<term>Linguistic processing. I.2.7 [Natural Language Processing]: Language models. H.3.3 [Information Storage and Retrieval]: Retrieval models. H.3.4 [Systems and Software]: Performance evaluation Experimentation</term>
					<term>Performance</term>
					<term>Measurement</term>
					<term>Algorithms Natural Language Processing</term>
					<term>Stemmer</term>
					<term>Digital Libraries</term>
					<term>Persian Language (Farsi)</term>
					<term>Robust Retrieval. 2</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In participating in this evaluation campaign, our first objective is to analyze the retrieval effectiveness when using TEL (The European Library) corpora composed of very short descriptions (library catalogue records) and to evaluate the retrieval effectiveness of several IR models. As a second objective we want to design and evaluate a stopword list and a light stemming strategy for the Persian language, a language belonging to the Indo-European family and having a relatively simple morphology. Finally, we participated in the robust track in an attempt to understand the difficulty involved in retrieving pertinent documents, even when the query and document representations share many common terms. Moreover, we made use of word sense disambiguation (WSD) information to order to reduce problems related to polysemy when matching topic and document representation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>During the last few years, the IR group at University of Neuchatel has been involved in designing, implementing and evaluating IR systems for various natural languages, including both European and popular Asian languages (namely, Chinese, Japanese, and Korean). Our main objective in this context is to promote effective monolingual IR in those languages.</p><p>The rest of this paper is organized as follows: Section 2 describes the main characteristics of the TEL corpus used in the CLEF-2008 ad hoc track. Section 3 outlines the main aspects of different IR models used with TEL collections together with the evaluation of our official runs and certain related experiments. Section 4 presents the principal features of the Persian (Farsi) language, presents the stopword list and stemming strategy we developed for this language and describes our official runs and results for this task. Our participation and results concerning the robust task are outlined in Section 5, and Section 6 presents our main conclusions. challenge was to retrieve pertinent records composed of a very short description of the referred information item. The only information contained in many records consists of only a title and author, and manually assigned subject headings.</p><p>Typical documents are shown in the tables below. Table <ref type="table" coords="2,321.72,106.05,8.83,8.43">1a</ref> (British Library), Table <ref type="table" coords="2,424.44,106.05,9.47,8.43" target="#tab_1">1b</ref> (Austrian National Library), and Table <ref type="table" coords="2,169.20,116.73,8.83,8.43">1c</ref> (Bibliothèque nationale de France) shown the descriptions that appear in different languages. Table <ref type="table" coords="2,161.04,127.29,8.95,8.43">1a</ref> shows a record with a title (tag &lt;dc:title&gt;) in German from a BL record and the subject in English (tag &lt;dc:subject&gt;). Table <ref type="table" coords="2,223.44,137.85,8.95,8.43">1c</ref> illustrates another example with the title (tag &lt;dc:title&gt;) and a part of the description (tag &lt;dc:description&gt;) written in Latin. &lt;record&gt; &lt;set&gt; TEL_BL_opac &lt;/set&gt; &lt;header&gt; &lt;id&gt; 010624878 &lt;/id&gt; &lt;/header&gt; &lt;document format="index"&gt; &lt;index&gt; &lt;topic&gt; BL_opac &lt;/topic&gt; &lt;/index&gt; &lt;/document&gt; &lt;document format="dcx"&gt; &lt;oai_dc:dc&gt; &lt;dc:title&gt; Fehlprägungen und Fälschungen von Schweizer Münzen ab 1850 : mit Preisangaben. &lt;/dc:title&gt; &lt;dc:contributor&gt; Richter, Jürg. &lt;/dc:contributor&gt; &lt;dc:publisher&gt; Zürich : Helvetische Münzenzzeitung, <ref type="bibr" coords="2,314.28,229.77,25.19,8.43">[1988]</ref> &lt;/dc:publisher&gt; &lt;dcterms:issued&gt; <ref type="bibr" coords="2,177.84,240.45,25.31,8.43">[1988]</ref> &lt;/dcterms:issued&gt; &lt;dcterms:extent&gt; 132p. : ill. &lt;/dcterms:extent&gt; &lt;dc:language xsi:type="ISO639-2"&gt; ger &lt;/dc:language&gt; &lt;dc:subject&gt; Swiss coins to date Catalogues &lt;/dc:subject&gt; &lt;dc:type&gt; text &lt;/dc:type&gt; &lt;dc:identifier xlink:href="http://catalogue.bl.uk/F/-?func=direct-doc-set&amp;amp;amp;l_base=BLL01&amp;amp;from=TELgateway&amp;amp;doc_number=010624878"&gt;010624878&lt;/dc:identif ier&gt; &lt;dc:identifier &gt; &lt;dc:identifier xsi:type="dcterms:URI"&gt;http://catalogue.bl.uk/F/-?func=direct-doc-set&amp;amp;amp;l_base=BLL01&amp;amp;from=TELgateway&amp;amp;doc_number=010624878&lt;/dc:identifier&gt; &lt;mods:location&gt; British Library HMNTS YA.1992.b.771 &lt;/mods:location&gt; &lt;/oai_dc:dc&gt; &lt;/document&gt; &lt;/record&gt; Table 1a: Example of a British Library (BL) record &lt;record&gt; &lt;set&gt; TEL_ONB_onb01 &lt;/set&gt; &lt;id&gt; oai:aleph.onb.ac.at:ONB01-000000086 &lt;/id&gt; &lt;document format="index"&gt; &lt;index&gt; &lt;topic&gt; ONB_onb01 &lt;/topic&gt; &lt;/index&gt; &lt;/document&gt; &lt;document format="dcx"&gt; &lt;oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:dcterms="http://purl.org/dc/dc/terms/" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/oai_dc/ http://www.openarchives.org/OAI/2.0/oai_dc.xsd"&gt; &lt;dc:identifier xsi:type="onb:ACCRecordId"&gt; AC00454800 &lt;/dc:identifier&gt; &lt;dcterms:spatial xsi:type="dcterms:ISO3166"&gt; DE &lt;/dcterms:spatial&gt; &lt;dc:language xsi:type="dcterms:ISO639-2"&gt; ger   <ref type="table" coords="3,302.28,525.57,3.57,8.43" target="#tab_4">2</ref>. The average size of each descriptor is relatively short (between 10 and 16), and similar across all three languages (perhaps a bit longer for the French corpus). During the indexing process we retained only the following logical sections from the original documents: &lt;dc:title&gt;, &lt;dc:description&gt;, &lt;dc:subject&gt;, and &lt;dcterms:alternative&gt;. From the topic descriptions we automatically removed certain phrases such as "Relevant document report …" or "Relevante Dokumente berichten …", etc. All our runs were fully automatic.</p><p>As shown in Appendix 2, the available topics cover various subjects (e.g., Topic #452: "Celtic Art," Topic #500: "Gauguin and Tahiti," Topic #470: "Car Industry in Europe," or Topic #498: "World War I Aviation"). We were surprised to see that the topic descriptions do not contain many proper names (creators and their works or geographical names). We found two topics with personal names ("Henry VIII" and "Gauguin") but 23 with geographical names (e.g., "Europe," "Eastern," "Bordeaux" or "Greek"). The expression used to refer to a given location is not standardized, with various expressions being used to refer to a similar location (e.g., "USA," "North America," or "America"). Also, time periods are infrequently used (7 topics) and many include expressions having rather broad (e.g., "Modern," "Ancient," or "Roman") or more precise ("World War I") interpretations.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">IR models and Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Indexing Approaches</head><p>In defining our indexing strategies, we used a stopword list to denote very frequent forms having no important impact on sense-matching between topic and document representatives (e.g., "the," "in," "or," "has," etc.). In our experiments, the stopword list contains 589 English, 484 French and 578 German terms. The diacritics were replaced by their corresponding non-accented equivalent. We reused the light stemmers we developed for the French and German languages, because removing the inflectional suffixes attached only to nouns and adjectives tends to result in better retrieval effectiveness than more aggressive stemmers that also remove derivational suffixes <ref type="bibr" coords="4,124.56,466.29,51.43,8.43" target="#b19">(Savoy, 2006)</ref>. These stemmers and stopword lists are freely available at the Web site www.unine.ch/info/clef. For the English languages we tried both a light stemming (S-stemmer proposed by <ref type="bibr" coords="4,141.48,487.77,57.59,8.43" target="#b7">Harman (1991)</ref> that removes only the plural form '-s') and a more aggressive one <ref type="bibr" coords="4,446.04,487.77,53.03,8.43" target="#b13">(Porter, 1980)</ref> based on a list of around 60 suffixes.</p><p>In the German language, compound words are widely used. For example, a life insurance company employee would be "Lebensversicherungsgesellschaftsangestellter" ("Leben" + 's' + "Versicherung" + 's' + "Gesellschaft" + 's' + "Angestellter" for life + insurance + company + employee). The augment (i.e. the letter 's' in our previous example) is not always present (e.g., "Bankangestelltenlohn" combines "Bank" + "Angestellten" + "Lohn" (salary)). Since compound construction is so widely used and written in many different forms, it is almost impossible to compile a dictionary providing quasi-total coverage of the German language. Thus an effective IR system including an automatic decompounding procedure for German had to be developed <ref type="bibr" coords="4,435.00,578.25,48.79,8.43;4,92.88,588.81,65.11,8.43" target="#b2">(Braschler &amp; Ripplinger, 2004)</ref>. In our experiments, we used our own automatic decompounding procedure <ref type="bibr" coords="4,449.76,588.81,53.15,8.43" target="#b15">(Savoy, 2004)</ref> leaving both the compounds and their composite parts in the topic and document representatives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">IR Models</head><p>In order to obtain high MAP values, we considered adopting different weighting schemes for the terms included in documents or queries. This would allow us to account for term occurrence frequencies (denoted tf ij for indexing term t j in document D i ), as well as their inverse document frequency (denoted idf j ). Moreover, we considered normalizing each indexing weight using the cosine to obtain the classical tf . idf formulation.</p><p>In addition to this classical vector-space approach, we also considered probabilistic models such as the Okapi (or BM25) <ref type="bibr" coords="4,135.96,695.25,87.35,8.43" target="#b14">(Robertson et al. 2000)</ref> that also take document length into account. As a second probabilistic approach, we implemented three variants of the DFR (Divergence from Randomness) family of models suggested by <ref type="bibr" coords="5,104.40,79.17,117.55,8.43" target="#b1">Amati &amp; van Rijsbergen (2002)</ref>. In this framework, the indexing weight w ij attached to term t j in document D i combines two information measures as follows</p><formula xml:id="formula_0" coords="5,145.56,103.96,204.83,11.24">w ij = Inf 1 ij • Inf 2 ij = -log 2 [Prob 1 ij (tf)] • (1 -Prob 2 ij (tf))</formula><p>As a first model, we implemented the PB2 scheme, defined by the following equations:</p><formula xml:id="formula_1" coords="5,145.56,136.58,373.07,30.46">Prob 1 ij = (e -λ j • λ j tf ij )/tf ij ! with λ j = tc j / n (1) Prob 2 ij = 1 -[(tc j +1) / (df j • (tfn ij + 1))] with tfn ij = tf ij • log 2 [1 + ((c•mean dl) / l i )]<label>(2)</label></formula><p>where tc j indicates the number of occurrences of term t j in the collection, l i the length (number of indexing terms) of document D i , mean dl the average document length, n the number of documents in the corpus, and c a constant (the corresponding values are given in the Appendix 1).</p><p>For the second model called GL2, the implementation of Prob 1 ij is given by Equation <ref type="formula" coords="5,427.20,211.53,3.51,8.43">3</ref>, and Prob 2 ij is given by Equation <ref type="formula" coords="5,140.64,222.09,3.57,8.43" target="#formula_2">4</ref>, as follows:</p><formula xml:id="formula_2" coords="5,145.56,237.52,373.07,29.36">Prob 1 ij = [1 / (1+λ j )] • [λ j / (1+λ j )] tfn ij (3) Prob 2 ij = tfn ij / (tfn ij + 1)<label>(4)</label></formula><p>where λ j and tfn ij were defined previously.</p><p>For the third model called I(n e )B2, the implementation was applied using the following two equations:</p><formula xml:id="formula_3" coords="5,145.56,307.53,373.07,29.92">Inf 1 ij = tfn ij • log 2 [(n+1) / (n e +0,5)] with n e = n • [1 -[(n-1)/n] tc j ] (5) Prob 2 ij = 1 -[(tc j +1) / (df j • (tfn ij + 1))] with tfn ij = tf ij • log 2 [1 + ((c•mean dl) / l i )]<label>(6)</label></formula><p>where n, tc j and tfn ij were defined previously, and df j indicates the number of documents in which the term t j occurs.</p><p>Finally, we also considered an approach based on a statistical language model (LM) <ref type="bibr" coords="5,423.00,372.45,63.56,8.43" target="#b8">(Hiemstra, 2000;</ref><ref type="bibr" coords="5,489.00,372.45,20.35,8.43" target="#b9">2002)</ref>, known as a non-parametric probabilistic model (the Okapi and DFR are viewed as parametric models). Probability estimates would thus not be based on any known distribution (e.g., as in Equation <ref type="formula" coords="5,444.60,393.69,4.67,8.43">1</ref>or 3), but rather be directly estimated based on the term occurrence frequencies in document D i or corpus C. Within this language model paradigm, various implementations and smoothing methods might be considered, although in this study we adopted a model proposed by <ref type="bibr" coords="5,257.28,425.49,60.20,8.43" target="#b9">Hiemstra (2002)</ref>, as described in Equation <ref type="formula" coords="5,418.20,425.49,3.57,8.43">7</ref>, combining an estimate based on document (P[t j | D i ]) and on corpus (P[t j | C]) corresponding to the Jelinek-Mercer smoothing approach.</p><formula xml:id="formula_4" coords="5,145.56,451.48,373.07,23.72">P[D i | Q] = P[D i ] . ∏ t j ∈Q [λ j . P[t j | D i ] + (1-λ j ) . P[t j | C]] with P[t j | D i ] = tf ij /l i and P[t j | C] = df j /lc with lc = ∑ k df k (7)</formula><p>where λ j is a smoothing factor (constant for all indexing terms t j , and usually fixed at 0.35) and lc an estimate of the size of the corpus C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Overall Evaluation</head><p>To measure retrieval performance, we adopted MAP values computed on the basis of 1,000 retrieved items per request as calculated with the TREC_EVAL program. Using this evaluation tool, some evaluation differences may occur in the values computed according to the official measure (the latter always takes 50 queries into account while in our presentation we do not account for queries having no relevant items). In the following tables, the best performance under the given conditions (with the same indexing scheme and the same collection) is listed in bold type.</p><p>Table <ref type="table" coords="5,130.08,601.41,4.67,8.43" target="#tab_6">3</ref> shows the MAP achieved by various probabilistic models using the English collection with two different query formulations (T or TD) and two stemmers. The last two columns show the MAP achieved by the French corpus and using our light stemmer. An analysis of this data shows that the best performing IR model would be usually the DFR I(n e )B2, for all stemming approaches or query sizes. For the English corpus with Porter stemmer and TD query formulation, the LM model produces however a slightly better performance (0.3701 vs. 0.3643, a relative difference of 1.6%).</p><p>In the last lines we reported the MAP average over these 5 IR models together with percentage variations derived from comparing the short (T) query formulation to the performance achieved using Porter stemmer and T query (last line). As depicted in the last lines, increasing the query size improves the MAP (around +12.4% to +14.7%). According to the average performance, the best indexing approach seemed to be the stemming approach using Porter's approach. In this case, the MAP with TD query formulation was 0.3559 on average, versus 0.3416 for the S-stemmer, a relative difference of 4.2%.  In Table <ref type="table" coords="6,140.16,268.77,4.67,8.43" target="#tab_7">4</ref> we reported the MAP achieved by probabilistic models using the German collection with two query formulations (T or TD) and comparing the performance with and without our automatic decompounding approach. The best IR model seemed to be the DFR PB2 (without decompounding) or the LM model when applying our decompounding scheme. By adding terms to the topic descriptions, we were also able to improve retrieval performance (between 17.4% to 31.0%). From comparing the average performances, it can be seen that applying an automatic decompounding approach improves retrieval effectiveness (see last line of Table <ref type="table" coords="6,482.52,321.69,3.57,8.43" target="#tab_7">4</ref>, with an average improvement of 46.8% for short query formulations, or +31.5% when considering TD queries). An analysis showed that pseudo-relevance feedback (whether PRF or blind-query expansion) seemed to be a useful technique for enhancing retrieval effectiveness. In this study, we adopted Rocchio's approach (denoted "Roc" in the following tables) <ref type="bibr" coords="6,207.84,552.21,82.19,8.43" target="#b4">(Buckley et al., 1996)</ref> with α = 0.75, β = 0.75, whereby the system was allowed to add m terms extracted from the k best ranked documents from the original query. From our previous experiments we learned that this type of blind query expansion strategy does not always work well. More particularly, we believe that including terms occurring frequently in the corpus (because they also appear in the top-ranked documents) may introduce more noise, and thus be an ineffective means of discriminating between relevant and non-relevant items <ref type="bibr" coords="6,164.76,605.25,82.51,8.43" target="#b12">(Peat &amp; Willett, 1991)</ref>. Consequently we also chose to apply our idf-based query expansion model (denoted "idf" in following tables) <ref type="bibr" coords="6,250.44,615.81,88.97,8.43" target="#b0">(Abdou &amp; Savoy, 2008)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mean average precision</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mean average precision</head><p>To evaluate these propositions, we applied certain probabilistic models and enlarged the query by adding the 20 to 150 terms retrieved from the 3 to 10 best-ranked articles contained in the English collection (Table <ref type="table" coords="6,487.44,642.69,3.42,8.43" target="#tab_8">5</ref>), and both the French and German corpora (Table <ref type="table" coords="6,260.52,653.25,3.42,8.43" target="#tab_9">6</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mean average precision</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Data Fusion</head><p>It is usually assumed that combining different search models may improve retrieval effectiveness <ref type="bibr" coords="7,471.24,323.61,31.51,8.43;7,92.88,334.29,53.71,8.43" target="#b21">(Vogt &amp; Cottrell, 1999)</ref>, for three main reasons. First there is a skimming process in which only the k top-ranked retrieved items from each ranked list are considered. In this case, we would combine the best answers obtained from various document representations (which would retrieve various pertinent items). Second we would count on the chorus effect, by which different retrieval schemes would retrieve the same item, and as such provide stronger evidence that the corresponding document was indeed relevant. Third, an opposite or dark horse effect may also play a role, whereby a given retrieval model may provide unusually high (low) and accurate estimates regarding a document's relevance. Thus, a combined system could possibly return more pertinent items by accounting for documents having a relatively high (low) score, or when a relatively short (long) result lists occurs. Such a data fusion approach however requires more storage space and processing time. In the trade-off between the advantages and drawbacks, it is unclear whether such approaches might be of any real commercial interest.</p><p>In this current study we combined three probabilistic models representing both the parametric (Okapi and DFR) and non-parametric (language model or LM) approaches. To produce such a combination we evaluated various fusion operators (see Table <ref type="table" coords="7,227.16,477.81,4.67,8.43">7</ref> for a detailed list of their descriptions). The "Sum RSV" operator for example indicates that the combined document score (or the final retrieval status value) is simply the sum of the retrieval status value (RSV k ) of the corresponding document D k computed by each single indexing scheme <ref type="bibr" coords="7,493.92,498.93,17.75,8.43;7,92.88,509.61,55.15,8.43" target="#b6">(Fox &amp; Shaw, 1994)</ref>. Table <ref type="table" coords="7,180.84,509.61,4.67,8.43">7</ref> thus illustrates how both the "Norm Max" and "Norm RSV" apply a normalization procedure when combining document scores. When combining the retrieval status value (RSV k ) for various indexing schemes and in order to favor certain more efficient retrieval schemes, we could multiply the document score by a constant α i (usually equal to 1), reflecting the differences in retrieval performance.</p><formula xml:id="formula_5" coords="7,132.00,560.37,346.91,51.40">Sum RSV SUM (α i . RSV k ) Norm Max SUM (α i . (RSV k / Max i )) Norm RSV SUM [α i . ((RSV k -Min i ) / (Max i -Min i ))] Z-Score α i . [((RSV k -Mean i ) / Stdev i ) + δ i ] with  δ i = [(Mean i -Min i ) / Stdev i ]</formula><p>Table <ref type="table" coords="7,213.84,622.53,3.70,8.43">7</ref>: Data fusion combination operators used in this study</p><p>In addition to using these data fusion operators, we also considered the round-robin approach, wherein we took one document in turn from each individual list and removed any duplicates, retaining only the highest ranking occurrence. Finally we suggested merging the retrieved documents according to the Z-Score, computed for each result list. More details can be found in <ref type="bibr" coords="7,277.20,670.53,86.84,8.43" target="#b16">Savoy &amp; Berger (2005)</ref>. In Table <ref type="table" coords="7,406.92,670.53,3.51,8.43">7</ref>, Min i (Max i ) lists the minimal (maximal) RSV value in the ith result list. Of course, we might also weight the relative contribution of each retrieval scheme by assigning a different α i value to each retrieval model (fixed to 1 in all our experiments).  <ref type="table" coords="8,130.08,643.17,4.67,8.43" target="#tab_10">8</ref> depicts the evaluation of various data fusion operators, comparing them to the best single approach using the Okapi and two DFR probabilistic models (GL2 or I(n e )B2). From this data, we can see that combining three IR models might improve retrieval effectiveness, only slightly for the French or the German collection with short query formulations (T), moderately for the German with TD queries. When combining different retrieval models, the Z-Score scheme tended to perform the best, or at least it had one of the best performing MAP (e.g., for the German corpus with T queries). Finally, when compared to the best single search model, the performance achieved by the various data fusion approaches can not be improved with the English corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Official Results</head><p>Table <ref type="table" coords="9,130.08,117.21,4.67,8.43" target="#tab_11">9</ref> shows the exact specifications of our 12 official monolingual runs for the TEL evaluation task, based mainly on the probabilistic models (Okapi, DFR and statistical language model (LM)). For all languages we submitted three runs with the TD query formulation and one with the T. All runs were fully automatic and in all cases the same data fusion approach (Z-score) was applied. For the German corpus however we sometimes applied our decompounding approach (denoted by "decomp." in the "Index" column), but we always applied our light stemmer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">IR with Persian language</head><p>The Persian (or Farsi) language is a member of the Indo-European family with relatively few morphological variations. This year we used a corpus extracted from the newspapers Hamshahri, made available thought the efforts of the University of Tehran (http://ece.ut.ac.ir/dbrg/hamshahri/). As usual in various evaluation campaigns, the corpus contains news articles (611 MB, for the years 1996 to 2002). This corpus contains exactly 166,774 documents on a variety of subjects (politic, literature, art, and economy, etc.) and includes about 448,100 different words. Hamshahri articles vary between 1 KB and 140 KB in size, comprising on average about 202 tokens (or 127 if we only count the number of word types). The corpus was coded in UTF-8 and written using the 28 Arabic letters plus an additional 4 letters for the Persian language.</p><p>Table 10 lists statistics on the test-collection. Of the three situations considered, there was no stemming approach used in the first, a light stemmer in the second, and 4-gram indexing approach for the third <ref type="bibr" coords="9,470.88,323.37,41.95,8.43;9,92.88,333.93,68.83,8.43" target="#b10">(McNamee &amp; Mayfield, 2004)</ref>  For the Persian language we first built a stopword list containing 884 terms. Unlike most other lists, this one contains words most frequently occurring in the collection (determinants, prepositions, conjunctions, pronouns or some auxiliary verb forms), plus a large number of suffixes already separated from word stems in the collection (see examples given below).</p><p>As a stemming strategy, we can use a morphological analysis <ref type="bibr" coords="9,337.32,675.09,63.11,8.43" target="#b11">(Miangah, 2006)</ref> or our simple, fast and light stemming approach that attempts to remove only nouns and adjective inflections. In the Persian language, the general pattern for inflectional suffixes is as follows: &lt;possessive&gt; &lt;plural&gt; &lt;other-suffix&gt; &lt;stem&gt;. In our light stemming strategy, we usually removed possessive, plural and some of the suffixes marked as others. The following examples of our light stemmer illustrate the relatively simple Persian morphology. From the plural form ‫ناتخرد‬ ("trees"), we can obtain ‫تخرد‬ ("tree"). For the possessive form, ‫مسد‬ ("my hand"), our stemmer will return ‫تسد‬ ("hand"), and for the form ‫نايناريا‬ ("Iranians") we obtain ‫ناريا‬ ("Iran"). In this corpus we saw that in some circumstances the suffixes might be written together or separated from the word as in ‫يتشڪ‬ ‫ا‬ and ‫ا‬ ‫يتشڪ‬ ("boats"), or ‫لزنم‬ ‫ا‬ and ‫ا‬ ‫لزنم‬ ("houses"). The adjectives are usually indeclinable whether used attributively or as a predicate. When used as substantives, adjectives take the normal plural endings, while comparative and superlative forms use the endings ‫رت‬ , and ‫نيزت‬ .</p><p>The Persian language uses few case markers (the accusative case and certain specific genitive cases), unlike the Latin, German or Hungarian languages. The accusative for the definite noun is followed by ‫ار‬ which can be joined to the noun or written separately (e.g., ‫ار‬ ‫درم‬ for the noun "man"). The genitive case is expressed by means of coupling two nouns by means of the particle known as ezafe (e.g.ِ ‫د‬ "man's son"). As is usually done in the English language, other relations are expressed by means of prepositions (e.g., in, with, etc.). Both the stopword list and our light stemmer are freely available at http://www.unine.ch/info/clef/.  Table <ref type="table" coords="10,130.08,380.97,9.35,8.43" target="#tab_16">12</ref> shows the exact specifications of our 4 official monolingual runs for the Persian IR evaluation task, based mainly on three probabilistic models (Okapi, DFR and statistical language model (LM)). We submitted runs with all three topic formulations (short or T, medium or TD, and long or TDN). All runs were fully automated and the same data fusion approach (Z-score) was applied in all cases. The combination strategy we followed attempted to combine different indexing units (words, stemmed words or 4-grams), based on various probabilistic and efficient IR models (Okapi or DFR) and using three different blind-query expansion techniques (Rocchio, idf-based or none). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mean average precision</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run name</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Robust Retrieval</head><p>In the robust task <ref type="bibr" coords="10,173.28,680.61,64.25,8.43" target="#b22">(Voorhees, 2006)</ref>, we were interested in learning why retrieving relevant items for a given topic could be hard, even if the query contains certain common terms found in the relevant documents. In order to evaluate various search techniques, we used a corpus created during recent CLEF evaluation campaigns. This collection consists of articles published in 1994 in the newspaper Los Angeles Times, as well as articles extracted from the Glasgow Herald and published in 1995. This collection contains a total of 169,477 documents (or about 579 MB of data). On average each article contains about 250 (median: 191) content-bearing terms (not counting commonly occurring words such as "the," "of" or "in"). Typically, documents in this collection are represented by a short title plus one to four paragraphs of text, and both American and British English spellings can be found in the corpus. To compile the test set, we used the topics created during the CLEF 2003 campaign (Topics #141 -#200) as well as queries from the 2005 (Topics #251 -#300) and 2006 (Topics #301 -#350) evaluation campaign. In this test set we found 153 queries able to return at least one relevant item from the collection. This year we were interested in verifying whether word-sense disambiguation (WSD) might improve retrieval effectiveness. For this reason the organizers provides us with a new version of both the document and topic descriptions containing the correct lemma (entry in the dictionary) and SYNSET number(s) of the corresponding entry in the WordNet thesaurus (version 1.6). Table <ref type="table" coords="11,291.72,201.45,9.35,8.43" target="#tab_17">13</ref> lists an example for the title of Topic #47. Under the attribute LEMA the corresponding English dictionary entry is shown (therefore a stemming procedure is no more needed) and under the tag SYNSET, we can find both the score and the SYNSET number. The surface form is indicated under the label &lt;WF&gt; and the Part-of-Speech (POS) tag is also available for each word. &lt;num&gt; C047 &lt;/num&gt; &lt;EN-title&gt; Russian Intervention in Chechnya &lt;/EN-title&gt; ... &lt;top&gt; &lt;num&gt; C047 &lt;/num&gt; &lt;EN-title&gt; &lt;TERM ID="C047-1" LEMA="russian" POS="JJ"&gt; &lt;WF&gt; Russian &lt;/WF&gt; &lt;SYNSET SCORE="1" CODE="02726367-a"/&gt; &lt;/TERM&gt; &lt;TERM ID="C047-2" LEMA="intervention" POS="NN"&gt; &lt;WF&gt; Intervention &lt;/WF&gt; &lt;SYNSET SCORE="1" CODE="00805766-n"/&gt; &lt;SYNSET SCORE="0" CODE="04995117-n"/&gt; &lt;/TERM&gt; &lt;TERM ID="C047-3" LEMA="in" POS="IN"&gt; &lt;WF&gt; in &lt;/WF&gt; &lt;/TERM&gt; &lt;TERM ID="C047-4" LEMA="Chechnya" POS="NNP"&gt; &lt;WF&gt; Chechnya &lt;/WF&gt; &lt;/TERM&gt; &lt;/EN-title&gt; ... Various possibilities have been put forward to explain why certain successful IR systems may fail for some queries <ref type="bibr" coords="11,122.28,498.81,60.44,8.43" target="#b3">(Buckley, 2004;</ref><ref type="bibr" coords="11,185.04,498.81,48.43,8.43" target="#b20">Savoy, 2007)</ref>. The organizers thought that the polysemy (already known as a problem in finding pertinent matches between query and document surrogates) could be partially resolved in an appropriate manner by using the SYNSET information.</p><p>Based on past experiments <ref type="bibr" coords="11,208.68,536.25,97.31,8.43" target="#b5">(Dolamic &amp; Savoy, 2008)</ref> with this corpus and using the TD queries and Porter's stemmer <ref type="bibr" coords="11,127.08,546.93,51.43,8.43" target="#b13">(Porter, 1980)</ref>, we achieved a MAP of 0.2216 with tf . idf IR model to 0.4070 with Okapi model <ref type="bibr" coords="11,92.88,557.49,88.03,8.43" target="#b14">(Robertson et al., 2000)</ref>. With this last IR model, the set of hardest topics (defined as a query listing no relevant items in the top-20) were composed of seven topics, namely Topic #153 ("Olympic Games and Peace"), Topic #301 ("Nestlé Brands"), Topic #320 ("Energy Crises"), Topic #188 ("German Spelling Reform"), Topic #258 ("Brain-Drain Impact"), Topic #309 ("Hard Drugs"), and Topic #322 ("Atomic Energy"). In the current experiments, we generated six different runs using word-sense disambiguation information. As shown in Table <ref type="table" coords="12,152.88,299.97,9.35,8.43" target="#tab_18">14</ref> above, we followed our combination strategy, taking into account the various probabilistic models using different blind query expansion approaches. Our best results were achieved in the UniNERobust4 run with a MAP of 0.4515. Moreover, if we compare runs with or without word sense disambiguation (WSD) information (lemma, POS tags and SYNSET), we see no real and important differences (e.g., UniNERobust1 vs. UniNERobust2, and UniNERobust4 vs. UniNERobust3).</p><p>Table 15 below lists the set of hard topics for each of our official runs (hard topics here are defined as those providing no relevant items listed in the top-20). Included in the list covering all six runs (shown in italics in Table <ref type="table" coords="12,116.76,379.89,8.39,8.43" target="#tab_19">15</ref>) were Topic #153 ("Olympic Games and Peace", 1 relevant item), followed by Topic #343 ("South African National Party", 1 relevant article), and Topic #313 ("Centenary Celebrations", 20 relevant documents). As shown in Table <ref type="table" coords="12,178.80,530.73,7.88,8.43" target="#tab_18">14</ref>, in our official runs a hard topic was where the query resulted in low average precision. Using this definition, Table <ref type="table" coords="12,198.24,541.41,9.35,8.43" target="#tab_9">16</ref> lists the 10 topics having the lowest mean average precision. When all six runs are listed we obtain: Topic #153 ("Olympic Games and Peace"), followed by Topic #343 ("South African National Party"), Topic #313 ("Centenary Celebrations"), Topic #320 ("Energy Crises"), Topic #286 ("Football Injuries"). In an attempt to explain why a topic was difficult, we might mention that for Topics #343 and #153 only one relevant document was retrieved. Based on our best run (UniNERobust4), this item was ranked low on the retrieved list (44 th for Topics #343, and 382 th with Topics #153) even though they contained a large number of search terms.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,180.12,700.29,251.39,8.43"><head>Table 1b :</head><label>1b</label><figDesc>Example of an Austrian National Library (ONB) record &lt;record&gt; &lt;set&gt; TEL_BnF_opac &lt;/set&gt; &lt;id&gt;oai:bnf.fr:catalogue/ark:/12148/cb30000394c/description&lt;/id&gt; &lt;document format="index"&gt; &lt;index&gt; &lt;topic&gt;BnF_opac&lt;/topic&gt; &lt;/index&gt; &lt;/document&gt; &lt;document format="dcx"&gt; &lt;oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.openarchives.org/OAI/2.</figDesc><table coords="3,92.88,128.73,410.37,369.39"><row><cell>0/"</cell></row><row><cell>xmlns:dc="http://purl.org/dc/elements/1.1/"&gt;</cell></row><row><cell>&lt;dc:identifier&gt;http://catalogue.bnf.fr/ark:/12148/cb30000394c/description&lt;/dc:identifier&gt;</cell></row><row><cell>&lt;dc:title&gt; Codex canonum vetus ecclesiae romanae a Francisco Pithoeo restitutus..&lt;/dc:title&gt;</cell></row><row><cell>&lt;dc:date&gt; 1687 &lt;/dc:date&gt;</cell></row><row><cell>&lt;dc:description&gt; Comprend : Apologeticus et epistolae &lt;/dc:description&gt;</cell></row><row><cell>&lt;dc:language&gt; lat &lt;/dc:language&gt;</cell></row><row><cell>&lt;dc:type xml:lang="fre"&gt; texte imprimé &lt;/dc:type&gt;</cell></row><row><cell>&lt;dc:type xml:lang="eng"&gt; printed text &lt;/dc:type&gt;</cell></row><row><cell>&lt;dc:type xml:lang="eng"&gt; text &lt;/dc:type&gt;</cell></row><row><cell>&lt;dc:rights xml:lang="fre"&gt; Catalogue en ligne de la Bibliothèque nationale de France &lt;/dc:rights&gt;</cell></row><row><cell>&lt;dc:rights xml:lang="eng"&gt; French National Library online Catalog &lt;/dc:rights&gt;</cell></row><row><cell>&lt;/oai_dc:dc&gt; &lt;/document&gt; &lt;/record&gt;</cell></row><row><cell>...</cell></row><row><cell>&lt;record&gt; &lt;set&gt; TEL_BnF_opac &lt;/set&gt;</cell></row><row><cell>de France &lt;/dc:rights&gt;</cell></row><row><cell>&lt;dc:rights xml:lang="eng"&gt; French National Library online Catalog &lt;/dc:rights&gt;</cell></row><row><cell>&lt;/oai_dc:dc&gt; &lt;/document&gt;</cell></row><row><cell>&lt;/record&gt;</cell></row></table><note coords="3,99.96,287.85,253.91,8.43;3,99.96,298.65,354.71,8.43;3,99.96,309.21,388.65,8.43;3,92.88,319.89,410.37,8.43;3,92.88,330.45,168.95,8.43;3,107.04,341.01,338.87,8.43;3,107.04,351.69,408.59,8.43;3,92.88,362.25,108.71,8.43;3,107.04,372.93,275.27,8.43;3,107.04,383.61,106.55,8.43;3,107.04,394.17,408.54,8.43;3,92.88,404.85,311.75,8.43;3,107.04,415.53,133.91,8.43;3,107.04,426.09,199.19,8.43;3,107.04,436.65,193.19,8.43;3,107.04,447.33,164.15,8.43;3,107.04,457.89,284.95,8.43"><p>&lt;id&gt;oai:bnf.fr:catalogue/ark:/12148/cb319212546/description&lt;/id&gt; &lt;document format="index"&gt; &lt;index&gt; &lt;topic&gt;BnF_opac&lt;/topic&gt; &lt;/index&gt; &lt;/document&gt; &lt;document format="dcx"&gt; &lt;oai_dc:dc xmlns:oai_dc="http://www.openarchives.org/OAI/2.0/oai_dc/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:dc="http://purl.org/dc/elements/1.1/"&gt; &lt;dc:identifier&gt;http://catalogue.bnf.fr/ark:/12148/cb319212546/description&lt;/dc:identifier&gt; &lt;dc:title&gt; Ingénieux Hidalgo Don Quichotte de la Manche. Traduction nouvelle précédée d'une introduction par Jean Babelon &lt;/dc:title&gt; &lt;dc:creator&gt; Cervantes Saavedra, Miguel de (1547-1616) &lt;/dc:creator&gt; &lt;dc:date&gt; 1929 &lt;/dc:date&gt; &lt;dc:description&gt; Comprend : T. I. -Paris, A la Cité des Livres, 27, rue Saint-Sulpice. 1929. (16 mars.) In-8, XXIX-...55 p. [5224] ; T. 3. -1929, 422 p. ; T. 4. -1929, 423 p. &lt;/dc:description&gt; &lt;dc:language&gt; fre &lt;/dc:language&gt; &lt;dc:type xml:lang="fre"&gt; texte imprimé &lt;/dc:type&gt; &lt;dc:type xml:lang="eng"&gt; printed text &lt;/dc:type&gt; &lt;dc:type xml:lang="eng"&gt; text &lt;/dc:type&gt; &lt;dc:rights xml:lang="fre"&gt; Catalogue en ligne de la Bibliothèque nationale</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,106.08,509.37,282.16,24.63"><head>Table 1c: Two examples of French records TEL collections statistics are shown below in Table</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,233.64,329.25,144.52,8.43"><head>Table 2 :</head><label>2</label><figDesc>TEL test-collection statistics</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="6,134.52,252.45,342.59,8.43"><head>Table 3 :</head><label>3</label><figDesc>MAP of various IR models and query formulations (English &amp; French collection)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="6,100.80,361.89,410.75,160.11"><head>Table 4 :</head><label>4</label><figDesc>MAP of various IR models and query formulations (German collection)</figDesc><table coords="6,100.80,361.89,410.75,141.39"><row><cell></cell><cell>German</cell><cell>German</cell><cell>German</cell><cell>German</cell></row><row><cell>Query</cell><cell>T</cell><cell>TD</cell><cell>T</cell><cell>TD</cell></row><row><cell>Decompounding?</cell><cell></cell><cell></cell><cell>+ decompounding</cell><cell>+ decompounding</cell></row><row><cell>Model \ # of queries</cell><cell>50 queries</cell><cell>50 queries</cell><cell>50 queries</cell><cell>50 queries</cell></row><row><cell>Okapi</cell><cell>0.1433</cell><cell>0.1872</cell><cell>0.2145</cell><cell>0.2522</cell></row><row><cell>DFR PB2</cell><cell>0.1603</cell><cell>0.2097</cell><cell>0.2150</cell><cell>0.2555</cell></row><row><cell>DFR GL2</cell><cell>0.1439</cell><cell>0.1878</cell><cell>0.2264</cell><cell>0.2615</cell></row><row><cell>DFR I(n e )B2</cell><cell>0.1574</cell><cell>0.2071</cell><cell>0.2204</cell><cell>0.2615</cell></row><row><cell>LM (λ = 0.35)</cell><cell>0.1499</cell><cell>0.1972</cell><cell>0.2315</cell><cell>0.2697</cell></row><row><cell>tf idf</cell><cell>0.1084</cell><cell>0.1382</cell><cell>0.1286</cell><cell>0.1598</cell></row><row><cell>Average</cell><cell>0.1510</cell><cell>0.1978</cell><cell>0.2216</cell><cell>0.2601</cell></row><row><cell>% change over T</cell><cell></cell><cell>+31.03%</cell><cell></cell><cell>+17.39%</cell></row><row><cell>% change</cell><cell></cell><cell></cell><cell>+46.77%</cell><cell>+31.49%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="7,100.80,81.93,416.27,193.47"><head>Table 5 :</head><label>5</label><figDesc>MAP using blind-query expansion (English collection)</figDesc><table coords="7,100.80,81.93,416.27,193.47"><row><cell>Query TD</cell><cell>English</cell><cell>English</cell><cell>English</cell><cell>English</cell></row><row><cell>PRF</cell><cell>S-stemmer / idf</cell><cell>S-stemmer / idf</cell><cell>Porter / Roc</cell><cell>Porter / Roc</cell></row><row><cell>IR Model / MAP</cell><cell>Okapi 0.3171</cell><cell>DFR GL2 0.3300</cell><cell>Okapi 0.3329</cell><cell>LM 0.3701</cell></row><row><cell>k doc. / m terms</cell><cell>5/10 0.2878</cell><cell>10/10 0.2811</cell><cell>3/10 0.3142</cell><cell>5/10 0.3913</cell></row><row><cell></cell><cell>5/20 0.3076</cell><cell>10/20 0.2983</cell><cell>3/20 0.3178</cell><cell>5/20 0.3991</cell></row><row><cell></cell><cell>5/50 0.3099</cell><cell>10/50 0.3041</cell><cell>3/50 0.3181</cell><cell>5/50 0.4025</cell></row><row><cell></cell><cell>5/100 0.3100</cell><cell>10/100 0.3053</cell><cell>3/100 0.3181</cell><cell>10/50 0.4041</cell></row><row><cell></cell><cell></cell><cell cols="2">Mean average precision</cell><cell></cell></row><row><cell>Query TD</cell><cell>French</cell><cell>French</cell><cell>German</cell><cell>German</cell></row><row><cell>PRF</cell><cell>idf</cell><cell>Roc</cell><cell>+ decomp. / idf</cell><cell>+ decomp. / Roc</cell></row><row><cell>IR Model / MAP</cell><cell>Okapi 0.2998</cell><cell>DFR I(n e )B2 0.3291</cell><cell>Okapi 0.2522</cell><cell>DFR I(n e )B2 0.2615</cell></row><row><cell>k doc. / m terms</cell><cell>10/10 0.2838</cell><cell>5/10 0.3304</cell><cell>3/10 0.2444</cell><cell>5/10 0.2654</cell></row><row><cell></cell><cell>10/20 0.2951</cell><cell>10/10 0.3253</cell><cell>5/10 0.2302</cell><cell>5/20 0.2713</cell></row><row><cell></cell><cell>10/50 0.2953</cell><cell>10/20 0.3239</cell><cell>5/20 0.2414</cell><cell>5/50 0.2757</cell></row><row><cell></cell><cell>5/50 0.3062</cell><cell>10/50 0.3268</cell><cell>5/50 0.2543</cell><cell>10/50 0.2851</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="7,164.64,285.69,282.23,8.43"><head>Table 6 :</head><label>6</label><figDesc>MAP using blind-query expansion (French &amp; German collection)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="8,92.88,69.93,420.63,546.52"><head>Table 8 :</head><label>8</label><figDesc>Mean average precision using different combination operators (with blind-query expansion)</figDesc><table coords="8,92.88,69.93,420.63,546.52"><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Mean average precision (% of change)</cell></row><row><cell cols="2">Language / Query</cell><cell cols="2">English TD</cell><cell cols="2">French TD</cell><cell cols="2">German TD</cell><cell>German T</cell></row><row><cell>Model</cell><cell></cell><cell cols="2">50 queries</cell><cell cols="2">50 queries</cell><cell>50 queries</cell><cell></cell><cell>50 queries</cell></row><row><cell cols="2">Okapi &amp; PRF doc/term</cell><cell cols="2">idf 10/20 0.3190</cell><cell cols="2">idf 10/20 0.2951</cell><cell cols="2">idf 5/10 0.2302</cell><cell>idf 5/10 0.2568</cell></row><row><cell>DFR GL2</cell><cell></cell><cell cols="2">idf 10/50 0.3041</cell><cell cols="2">idf 10/50 0.3070</cell><cell cols="2">Roc 5/20 0.2356</cell><cell>Roc 5/20 0.1967</cell></row><row><cell>DFR I(n e )B2</cell><cell></cell><cell cols="6">Roc 10/10 0.3745 Roc 10/10 0.3253 Roc 5/50 0.2757</cell><cell>Roc 5/50 0.2838</cell></row><row><cell cols="2">Official run name</cell><cell cols="2">UniNEen1</cell><cell cols="2">UniNEfr1</cell><cell>UniNEde1</cell><cell></cell><cell>UniNEde4</cell></row><row><cell>Round-robin</cell><cell></cell><cell cols="2">0.3187 (-14.9%)</cell><cell cols="2">0.2950 (-9.3%)</cell><cell cols="2">0.2045 (-26.0%)</cell><cell>0.2316 (-18.4%)</cell></row><row><cell>Sum RSV</cell><cell></cell><cell cols="2">0.3510 (-6.3%)</cell><cell cols="2">0.3282 (+0.9%)</cell><cell cols="2">0.2917 (+5.8%)</cell><cell>0.2840 (+0.1%)</cell></row><row><cell>Norm Max</cell><cell></cell><cell cols="2">0.3542 (-5.4%)</cell><cell cols="2">0.3284 (+1.0%)</cell><cell cols="2">0.2912 (+5.6%)</cell><cell>0.2730 (-3.8%)</cell></row><row><cell>Norm RSV</cell><cell></cell><cell cols="2">0.3534 (-5.6%)</cell><cell cols="2">0.3274 (+0.6%)</cell><cell cols="2">0.2945 (+6.8%)</cell><cell>0.2777 (-2.1%)</cell></row><row><cell>Z-Score</cell><cell></cell><cell cols="2">0.3543 (-5.4%)</cell><cell cols="2">0.3284 (+1.0%)</cell><cell cols="2">0.3013 (+9.3%)</cell><cell>0.2838 (0.0%)</cell></row><row><cell>Run name</cell><cell>Query</cell><cell>lang.</cell><cell>Index</cell><cell>Model</cell><cell cols="2">Query expansion</cell><cell cols="2">Single MAP Comb MAP</cell></row><row><cell>UniNEen1</cell><cell>TD</cell><cell>EN</cell><cell>Porter</cell><cell>Okapi</cell><cell cols="2">idf 10 docs / 20 terms</cell><cell cols="2">0.3190</cell><cell>Z-score</cell></row><row><cell></cell><cell>TD</cell><cell>EN</cell><cell>S-stem</cell><cell>GL2</cell><cell cols="2">idf 10 docs / 50 terms</cell><cell cols="2">0.3041</cell><cell>0.3543</cell></row><row><cell></cell><cell>TD</cell><cell>EN</cell><cell>Porter</cell><cell cols="3">I(n e )B2 Roc 10 docs / 10 terms</cell><cell cols="2">0.3745</cell></row><row><cell>UniNEen2</cell><cell>TD</cell><cell>EN</cell><cell>Porter</cell><cell>PB2</cell><cell cols="2">Roc 5 docs / 50 terms</cell><cell cols="2">0.3850</cell><cell>Z-Score</cell></row><row><cell></cell><cell>TD</cell><cell>EN</cell><cell>S-stem</cell><cell>Okapi</cell><cell cols="2">idf 5 docs / 50 terms</cell><cell cols="2">0.3099</cell><cell>0.3706</cell></row><row><cell>UniNEen3</cell><cell>TD</cell><cell>EN</cell><cell>Porter</cell><cell>Okapi</cell><cell></cell><cell></cell><cell cols="2">0.3329</cell><cell>Z-score</cell></row><row><cell></cell><cell>TD</cell><cell>EN</cell><cell cols="2">S-stem I(n e )B2</cell><cell></cell><cell></cell><cell cols="2">0.3541</cell><cell>0.3754</cell></row><row><cell></cell><cell>TD</cell><cell>EN</cell><cell>Porter</cell><cell>LM</cell><cell cols="2">Roc 5 docs / 10 terms</cell><cell cols="2">0.3913</cell></row><row><cell>UniNEen4</cell><cell>T</cell><cell>EN</cell><cell>Porter</cell><cell>Okapi</cell><cell cols="2">idf 10 docs / 20 terms</cell><cell cols="2">0.3135</cell><cell>Z-score</cell></row><row><cell></cell><cell>T</cell><cell>EN</cell><cell>S-stem</cell><cell>GL2</cell><cell cols="2">idf 10 docs / 50 terms</cell><cell cols="2">0.3541</cell><cell>0.3446</cell></row><row><cell></cell><cell>T</cell><cell>EN</cell><cell>Porter</cell><cell cols="3">I(n e )B2 Roc 10 docs / 10 terms</cell><cell cols="2">0.3913</cell></row><row><cell>UniNEfr1</cell><cell>TD</cell><cell>FR</cell><cell>stem</cell><cell>Okapi</cell><cell cols="2">idf 10 docs / 20 terms</cell><cell cols="2">0.2951</cell><cell>Z-score</cell></row><row><cell></cell><cell>TD</cell><cell>FR</cell><cell>stem</cell><cell>GL2</cell><cell cols="2">idf 10 docs / 50 terms</cell><cell cols="2">0.3070</cell><cell>0.3284</cell></row><row><cell></cell><cell>TD</cell><cell>FR</cell><cell>stem</cell><cell>I(n e )B2</cell><cell cols="2">Roc 10 docs / 10 terms</cell><cell cols="2">0.3253</cell></row><row><cell>UniNEfr2</cell><cell>TD</cell><cell>FR</cell><cell>stem</cell><cell>PB2</cell><cell cols="2">Roc 5 docs / 50 terms</cell><cell cols="2">0.3052</cell><cell>Z-Score</cell></row><row><cell></cell><cell>TD</cell><cell>FR</cell><cell>stem</cell><cell>Okapi</cell><cell cols="2">idf 5 docs / 50 terms</cell><cell cols="2">0.3262</cell><cell>0.3254</cell></row><row><cell>UniNEfr3</cell><cell>TD</cell><cell>FR</cell><cell>stem</cell><cell>Okapi</cell><cell></cell><cell></cell><cell cols="2">0.2998</cell><cell>Z-score</cell></row><row><cell></cell><cell>TD</cell><cell>FR</cell><cell>stem</cell><cell>I(n e )B2</cell><cell></cell><cell></cell><cell cols="2">0.3291</cell><cell>0.3327</cell></row><row><cell></cell><cell>TD</cell><cell>FR</cell><cell>stem</cell><cell>LM</cell><cell cols="2">Roc 5 docs / 10 terms</cell><cell></cell><cell>0.315</cell></row><row><cell>UniNEfr4</cell><cell>T</cell><cell>FR</cell><cell>stem</cell><cell>Okapi</cell><cell cols="2">idf 10 docs / 20 terms</cell><cell cols="2">0.2741</cell><cell>Z-score</cell></row><row><cell></cell><cell>T</cell><cell>FR</cell><cell>stem</cell><cell>GL2</cell><cell cols="2">idf 10 docs / 50 terms</cell><cell cols="2">0.2856</cell><cell>0.2898</cell></row><row><cell></cell><cell>T</cell><cell>FR</cell><cell>stem</cell><cell cols="3">I(n e )B2 Roc 10 docs / 10 terms</cell><cell cols="2">0.2798</cell></row><row><cell>UniNEde1</cell><cell>TD</cell><cell cols="3">DE decomp. Okapi</cell><cell cols="2">idf 5 docs / 10 terms</cell><cell cols="2">0.2302</cell><cell>Z-score</cell></row><row><cell></cell><cell>TD</cell><cell>DE</cell><cell></cell><cell>GL2</cell><cell cols="2">Roc 5 docs / 20 terms</cell><cell cols="2">0.2356</cell><cell>0.3013</cell></row><row><cell></cell><cell>TD</cell><cell cols="3">DE decomp. I(n e )B2</cell><cell cols="2">Roc 5 docs / 50 terms</cell><cell cols="2">0.2757</cell></row><row><cell>UniNEde2</cell><cell>TD</cell><cell cols="3">DE decomp Okapi</cell><cell cols="2">Roc 5 docs / 20 terms</cell><cell cols="2">0.2521</cell><cell>Z-score</cell></row><row><cell></cell><cell>TD</cell><cell cols="2">DE decomp</cell><cell>PB2</cell><cell cols="2">idf 5 docs / 50 terms</cell><cell cols="2">0.2779</cell><cell>0.2786</cell></row><row><cell>UniNEde3</cell><cell>TD</cell><cell cols="3">DE decomp I(n e )B2</cell><cell cols="2">idf 5 docs / 50 terms</cell><cell cols="2">0.2726</cell><cell>Z-score</cell></row><row><cell></cell><cell>TD</cell><cell>DE</cell><cell></cell><cell>Okapi</cell><cell></cell><cell></cell><cell cols="2">0.1872</cell><cell>0.2797</cell></row><row><cell></cell><cell>TD</cell><cell cols="2">DE decomp</cell><cell>LM</cell><cell cols="2">idf 5 docs / 10 terms</cell><cell cols="2">0.2378</cell></row><row><cell>UniNEde4</cell><cell>T</cell><cell cols="3">DE decomp. Okapi</cell><cell cols="2">idf 5 docs / 10 terms</cell><cell cols="2">0.2568</cell><cell>Z-score</cell></row><row><cell></cell><cell>T</cell><cell>DE</cell><cell></cell><cell>GL2</cell><cell cols="2">Roc 5 docs / 20 terms</cell><cell cols="2">0.1967</cell><cell>0.2838</cell></row><row><cell></cell><cell>T</cell><cell cols="3">DE decomp. I(n e )B2</cell><cell cols="2">Roc 5 docs / 50 terms</cell><cell cols="2">0.2586</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" coords="8,106.08,626.97,379.00,24.63"><head>Table 9 :</head><label>9</label><figDesc>Description and mean average precision (MAP) of our official TEL monolingual runsTable</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" coords="9,159.48,333.93,272.75,265.59"><head></head><label></label><figDesc>.</figDesc><table coords="9,159.48,351.57,272.75,247.95"><row><cell></cell><cell>No stemmer</cell><cell>Light stemmer</cell><cell>4-gram</cell></row><row><cell>Size (in MB)</cell><cell>611 MB</cell><cell>611 MB</cell><cell>611 MB</cell></row><row><cell># of documents</cell><cell>166,774</cell><cell>166,774</cell><cell>166,774</cell></row><row><cell># of distinct terms</cell><cell>448,100</cell><cell>324,028</cell><cell>175,914</cell></row><row><cell cols="4">Number of distinct indexing terms (word type) per document</cell></row><row><cell>Mean</cell><cell>127.23</cell><cell>119.26</cell><cell>258.26</cell></row><row><cell>Standard deviation</cell><cell>124.58</cell><cell>118.1</cell><cell>237</cell></row><row><cell>Median</cell><cell>83</cell><cell>80</cell><cell>178</cell></row><row><cell>Maximum</cell><cell>3,561</cell><cell>2,755</cell><cell>5,266</cell></row><row><cell>Minimum</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell cols="3">Number of indexing terms (tokens) per document</cell><cell></cell></row><row><cell>Mean</cell><cell>202.13</cell><cell>202.13</cell><cell>445.63</cell></row><row><cell>Standard deviation</cell><cell>228.14</cell><cell>228.14</cell><cell>494.26</cell></row><row><cell>Median</cell><cell>123</cell><cell>123</cell><cell>278</cell></row><row><cell>Maximum</cell><cell>12,548</cell><cell>12,548</cell><cell>25,139</cell></row><row><cell>Minimum</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Number of queries</cell><cell>50</cell><cell>50</cell><cell>50</cell></row><row><cell>Number rel. items</cell><cell>5,161</cell><cell>5,161</cell><cell>5,161</cell></row><row><cell>Mean rel./ request</cell><cell>103.22</cell><cell>103.22</cell><cell>103.22</cell></row><row><cell>Standard deviation</cell><cell>67.88</cell><cell>67.88</cell><cell>67.88</cell></row><row><cell>Median</cell><cell>93</cell><cell>93</cell><cell>93</cell></row><row><cell>Maximum</cell><cell>255 (T #552)</cell><cell>255 (T #552)</cell><cell>255 (T #552)</cell></row><row><cell>Minimum</cell><cell>7 (T #574)</cell><cell>7 (T #574)</cell><cell>7 (T #574)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13" coords="9,226.08,610.77,159.64,8.43"><head>Table 10 :</head><label>10</label><figDesc>Persian test-collection statistics</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15" coords="10,151.44,364.77,308.63,8.43"><head>Table 11 :</head><label>11</label><figDesc>MAP of various IR models and query formulations (Persian collection)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16" coords="10,98.16,462.21,415.35,175.11"><head>Table 12 :</head><label>12</label><figDesc>Description and mean average precision (MAP) for our official Persian monolingual runs</figDesc><table coords="10,98.16,462.21,415.35,155.55"><row><cell></cell><cell>Query</cell><cell>Index</cell><cell>Stem</cell><cell>Model</cell><cell>Query expansion</cell><cell cols="2">Single MAP Comb MAP</cell></row><row><cell>UniNEpe1</cell><cell>T</cell><cell>word</cell><cell>none</cell><cell>PL2</cell><cell>none</cell><cell>0.4078</cell><cell>Z-score</cell></row><row><cell></cell><cell>T</cell><cell cols="2">4-gram none</cell><cell>LM</cell><cell>idf 10 docs / 100 terms</cell><cell>0.3783</cell><cell>0.4675</cell></row><row><cell></cell><cell>T</cell><cell>word</cell><cell>none</cell><cell>Okapi</cell><cell>Roc 10 docs / 20 terms</cell><cell>0.4376</cell><cell></cell></row><row><cell>UniNEpe2</cell><cell>TD</cell><cell cols="2">4-gram none</cell><cell>I(n e )C2</cell><cell>none</cell><cell>0.4235</cell><cell>Z-Score</cell></row><row><cell></cell><cell>TD</cell><cell>word</cell><cell>none</cell><cell>PL2</cell><cell>none</cell><cell>0.4274</cell><cell>0.4898</cell></row><row><cell></cell><cell>TD</cell><cell>word</cell><cell>light</cell><cell>PL2</cell><cell>Roc 10 docs / 20 terms</cell><cell>0.4513</cell><cell></cell></row><row><cell></cell><cell>TD</cell><cell>word</cell><cell>none</cell><cell>PL2</cell><cell>idf 10 docs / 20 terms</cell><cell>0.4311</cell><cell></cell></row><row><cell>UniNEpe3</cell><cell>TD</cell><cell cols="2">4-gram none</cell><cell>Okapi</cell><cell>Roc 5 docs / 100 terms</cell><cell>0.4335</cell><cell>Z-Score</cell></row><row><cell></cell><cell>TD</cell><cell>word</cell><cell>none</cell><cell>LM</cell><cell>idf 10 docs / 70 terms</cell><cell>0.4141</cell><cell>0.4814</cell></row><row><cell></cell><cell>TD</cell><cell>word</cell><cell>none</cell><cell>PL2</cell><cell>none</cell><cell>0.4274</cell><cell></cell></row><row><cell>UniNEpe4</cell><cell>TDN</cell><cell cols="2">4-gram none</cell><cell>LM</cell><cell>idf 10 docs / 100 terms</cell><cell>0.3738</cell><cell>Z-score</cell></row><row><cell></cell><cell>TDN</cell><cell>word</cell><cell>none</cell><cell>LM</cell><cell>Roc 10 docs / 20 terms</cell><cell>0.4415</cell><cell>0.4807</cell></row><row><cell></cell><cell>TDN</cell><cell>word</cell><cell>none</cell><cell>PL2</cell><cell>none</cell><cell>0.4425</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17" coords="11,138.12,461.37,335.34,19.11"><head>Table 13 :</head><label>13</label><figDesc>Examples of a query (title-only) with and without WordNet thesaurus number, part of speech tag (POS) and lemma</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18" coords="12,98.16,69.93,415.35,211.59"><head>Table 14 :</head><label>14</label><figDesc>Description and mean average precision (MAP) for our official robust monolingual runs</figDesc><table coords="12,98.16,69.93,415.35,192.76"><row><cell>Run name</cell><cell>Query</cell><cell>Index</cell><cell>Model</cell><cell>Query expansion</cell><cell cols="2">Single MAP Comb MAP</cell></row><row><cell>UniNERobust1</cell><cell>TD</cell><cell></cell><cell>I(n e )C2</cell><cell>idf 5 docs / 50 terms</cell><cell>0.4019</cell><cell>Z-score</cell></row><row><cell></cell><cell>TD</cell><cell></cell><cell>Okapi</cell><cell>none</cell><cell>0.4086</cell><cell>0.4317</cell></row><row><cell>UniNERobust2</cell><cell>TD</cell><cell>WSD &amp; POS</cell><cell>I(n e )C2</cell><cell>idf 5 docs / 50 terms</cell><cell>0.3829</cell><cell>Z-Score</cell></row><row><cell></cell><cell>TD</cell><cell>WSD &amp; POS</cell><cell>Okapi</cell><cell>none</cell><cell>0.3896</cell><cell>0.4000</cell></row><row><cell>UniNERobust3</cell><cell>TD</cell><cell></cell><cell>LM</cell><cell>idf 5 docs / 200 terms</cell><cell>0.4345</cell><cell>Z-Score</cell></row><row><cell></cell><cell>TD</cell><cell>POS</cell><cell>I(n e )C2</cell><cell>win 5 docs / 200 terms</cell><cell>0.4000</cell><cell>0.4347</cell></row><row><cell></cell><cell>TD</cell><cell>WSD</cell><cell>I(n e )C2</cell><cell>win 5 docs / 200 terms</cell><cell>0.3966</cell><cell></cell></row><row><cell>UniNERobust4</cell><cell>TD</cell><cell></cell><cell>I(n e )C2</cell><cell>none</cell><cell>0.3990</cell><cell>Z-score</cell></row><row><cell></cell><cell>TD</cell><cell></cell><cell>LM</cell><cell>win 5 docs / 200 terms</cell><cell>0.4331</cell><cell>0.4515</cell></row><row><cell></cell><cell>TD</cell><cell></cell><cell>Okapi</cell><cell>win 5 docs / 200 terms</cell><cell>0.3783</cell><cell></cell></row><row><cell>UniNERobust5</cell><cell>TD</cell><cell>WSD</cell><cell>I(n e )C2</cell><cell>none</cell><cell>0.4033</cell><cell>Z-score</cell></row><row><cell></cell><cell>TD</cell><cell>WSD</cell><cell>LM</cell><cell>win 5 docs / 200 terms</cell><cell>0.4386</cell><cell>0.4410</cell></row><row><cell></cell><cell>TD</cell><cell>WSD</cell><cell>Okapi</cell><cell>win 5 docs / 200 terms</cell><cell>0.3888</cell><cell></cell></row><row><cell>UniNERobust6</cell><cell>TD</cell><cell></cell><cell>Okapi</cell><cell>none</cell><cell>0.4086</cell><cell>Z-score</cell></row><row><cell></cell><cell>TD</cell><cell>WSD</cell><cell>LM</cell><cell>win 5 docs / 200 terms</cell><cell>0.4294</cell><cell>0.4499</cell></row><row><cell></cell><cell>TD</cell><cell></cell><cell>I(n e )C2</cell><cell>idf 5 docs / 50 terms</cell><cell>0.4019</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19" coords="12,121.80,408.21,346.96,114.75"><head>Table 15 :</head><label>15</label><figDesc>The hardest topics ranked according to the first relevant and retrieved items(and with rank &gt; 20)    </figDesc><table coords="12,121.80,408.21,325.79,85.23"><row><cell>Run name</cell><cell>1st</cell><cell>2nd 3rd</cell><cell>4th</cell><cell>5th</cell><cell>6th</cell><cell>7th</cell><cell>8th</cell><cell>9th 10th</cell></row><row><cell cols="9">UniNERobust1 153 169 316 313 343 266 318 151 314</cell></row><row><cell cols="9">UniNERobust2 153 178 188 266 313 343 280 314 320</cell></row><row><cell cols="8">UniNERobust3 153 343 318 320 286 313 314 280</cell><cell></cell></row><row><cell cols="8">UniNERobust4 153 343 266 318 151 155 313 169</cell><cell></cell></row><row><cell cols="8">UniNERobust5 153 343 318 313 169 266 188 286</cell><cell></cell></row><row><cell cols="7">UniNERobust6 153 169 343 318 313 314 151</cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>The authors would like to also thank the CLEF-2008 task organizers for their efforts in developing various European language test-collections. This research was supported in part by the <rs type="funder">Swiss National Science Foundation</rs> under Grant #<rs type="grantNumber">200021-113273</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_ZmpzCBE">
					<idno type="grant-number">200021-113273</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="table" coords="13,192.36,133.77,253.91,8.43;13,121.80,146.85,324.47,8.43;13,156.96,165.81,37.40,8.43">153 286 313 169 343 320 322 188 266 314  UniNERobust6 153 169 343 286 313 320 280 322 314 151   Table 16:</ref> <p>The ten hardest topics showing their mean average precision (MAP)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>In this ninth CLEF campaign we evaluated various probabilistic IR models using two different testcollections, the first composed of short bibliographic notices extracted from the TEL corpora (written in English, German and French languages), and the second newspapers articles written in the Persian language. For the latter we also suggested a stopword list and a light stemmer strategy.</p><p>The results of our various experiments demonstrate that the I(n e )B2 or PB2 models (or I(n e )C2 for the Persian language) derived from the Divergence from Randomness (DFR) paradigm and the LM model seem to provide the best overall retrieval performances (see Tables <ref type="table" coords="13,284.40,286.77,14.15,8.43">3, 4</ref> and<ref type="table" coords="13,316.80,286.77,7.53,8.43">11</ref>). The Okapi model used in our experiments usually results in retrieval performances inferior to those obtained with the DFR or LM approaches.</p><p>For the Persian language (Tables <ref type="table" coords="13,232.08,313.65,9.35,8.43">11</ref> and<ref type="table" coords="13,259.80,313.65,7.47,8.43">12</ref>), our light stemmer tends to produce better MAP than does the 4gram indexing scheme (relative difference of 5.5%). On the other hand, the performance difference with an approach ignoring a stemming stage is rather small. Using the TEL corpora, the pseudo-relevance feedback (Rocchio's model) tends to hurt the retrieval effectiveness (see Tables <ref type="table" coords="13,188.88,361.65,20.70,8.43">5 or 6</ref>). A data fusion strategy may enhance the retrieval performance for the French and German (Table <ref type="table" coords="13,168.12,372.33,3.96,8.43">8</ref>) or Persian languages (Table <ref type="table" coords="13,285.36,372.33,7.47,8.43">12</ref>), but not with the English corpus.</p><p>In the robust track, using the blind query expansion and data fusion approaches (combining three different probabilistic models), we are able to improve the MAP from 0.4086 (Okapi) to 0.4515. However, if we define hard topics as queries for which we cannot find any relevant items listed in the top-20, then these two runs produce the same number of hard topics (7 over 153). Finally the performance differences with and without word sense disambiguation (WSD) information are rather small. </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="13,92.88,532.53,395.87,8.43;13,112.80,543.21,269.22,8.43" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,213.72,532.53,275.03,8.43;13,112.80,543.21,37.47,8.43">Searching in Medline: Stemming, query expansion, and manual indexing evaluation</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Abdou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,158.76,543.21,147.65,8.43">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="781" to="789" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,92.88,555.69,419.23,8.43;13,112.80,566.25,351.18,8.43" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,254.64,555.69,257.47,8.43;13,112.80,566.25,106.44,8.43">Probabilistic models of information retrieval based on measuring the divergence from randomness</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,228.36,566.25,160.70,8.43">ACM Transactions on Information Systems</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="357" to="389" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,92.88,578.85,392.48,8.43;13,112.80,589.41,138.42,8.43" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,244.44,578.85,240.92,8.43;13,112.80,589.41,31.81,8.43">How effective is stemming and decompounding for German text retrieval</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Braschler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ripplinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,153.12,589.41,38.94,8.43">IR Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="291" to="316" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,92.88,601.89,420.42,8.43" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,171.84,601.89,103.68,8.43">Why current IR engines fail</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,283.20,601.89,114.56,8.43">Proceedings ACM-SIGIR&apos;2004</title>
		<meeting>ACM-SIGIR&apos;2004</meeting>
		<imprint>
			<publisher>The ACM Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="584" to="585" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,92.88,614.49,383.75,8.43;13,112.80,625.05,279.78,8.43" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,312.00,614.49,146.75,8.43">New retrieval approaches using SMART</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<idno>#500-236</idno>
	</analytic>
	<monogr>
		<title level="m" coord="13,112.80,625.05,87.49,8.43">Proceedings of TREC-4</title>
		<meeting>TREC-4<address><addrLine>Gaithersburg</addrLine></address></meeting>
		<imprint>
			<publisher>NIST Publication</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="25" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,92.88,637.53,401.23,8.43;13,112.80,648.21,80.22,8.43" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="13,220.80,637.53,273.31,8.43;13,112.80,648.21,30.88,8.43">Monolingual and Bilingual Searches: Evaluation, Challenges and Failure Analysis</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Dolamic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>Submitted</note>
</biblStruct>

<biblStruct coords="13,92.88,660.69,405.80,8.43;13,112.80,671.37,152.70,8.43" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,218.76,660.69,124.80,8.43">Combination of multiple searches</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Shaw</surname></persName>
		</author>
		<idno>#500-215</idno>
	</analytic>
	<monogr>
		<title level="m" coord="13,362.28,660.69,77.88,8.43">Proceedings TREC-2</title>
		<meeting>TREC-2<address><addrLine>Gaithersburg</addrLine></address></meeting>
		<imprint>
			<publisher>NIST Publication</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="243" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,92.88,683.85,409.62,8.43;13,112.80,694.41,54.30,8.43" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,180.60,683.85,97.72,8.43">How effective is suffixing</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,286.92,683.85,211.68,8.43">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="15" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,92.88,68.61,344.69,8.43" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="14,175.68,68.61,179.70,8.43">Using language models for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
	<note type="report_type">CTIT Ph.D. Thesis</note>
</biblStruct>

<biblStruct coords="14,92.88,81.09,418.91,8.43;14,112.80,91.77,223.14,8.43" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="14,175.68,81.09,320.21,8.43">Term-specific smoothing for the language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,112.80,91.77,116.86,8.43">Proceedings of the ACM-SIGIR</title>
		<meeting>the ACM-SIGIR</meeting>
		<imprint>
			<publisher>The ACM Press</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="35" to="41" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,92.88,104.25,410.71,8.43;14,112.80,114.93,86.70,8.43" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="14,235.92,104.25,250.73,8.43">Character n-gram tokenization for European language text retrieval</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mcnamee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mayfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,494.76,104.25,8.83,8.43;14,112.80,114.93,27.66,8.43">IR Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="73" to="97" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,92.88,127.41,418.38,8.43;14,112.80,137.97,29.10,8.43" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="14,184.44,127.41,158.35,8.43">Automatic lemmatization of Persian words</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">M</forename><surname>Miangah</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,351.72,127.41,130.71,8.43">Journal of Quantitative Linguistics</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,92.88,150.57,411.92,8.43;14,112.80,161.13,356.46,8.43" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="14,219.00,150.57,285.80,8.43;14,112.80,161.13,61.26,8.43">The limitations of term co-occurrence data for query expansion in document retrieval systems</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">J</forename><surname>Peat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Willett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,182.76,161.13,211.58,8.43">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="378" to="383" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,92.88,173.61,306.90,8.43" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="14,173.76,173.61,121.42,8.43">An algorithm for suffix stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,303.48,173.61,31.76,8.43">Program</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,92.88,186.21,383.94,8.43;14,112.80,196.77,208.98,8.43" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="14,291.96,186.21,180.05,8.43">Experimentation as a way of life: Okapi at TREC</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beaulieu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,112.80,196.77,147.53,8.43">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="95" to="108" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,92.88,209.25,395.35,8.43;14,112.80,219.93,86.82,8.43" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="14,161.64,209.25,309.65,8.43">Combining multiple strategies for effective monolingual and cross-lingual retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,479.40,209.25,8.83,8.43;14,112.80,219.93,27.66,8.43">IR Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="121" to="148" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,92.88,232.41,408.92,8.43" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="14,224.04,232.41,261.66,8.43">Selection and merging strategies for multilingual information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P.-Y</forename><surname>Berger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,112.80,242.97,397.79,8.43;14,112.80,253.65,399.90,8.43;14,112.80,264.21,33.78,8.43" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="14,417.00,242.97,93.59,8.43;14,112.80,253.65,131.14,8.43">Multilingual Information Access for text, Speech and Images</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="14,250.56,253.65,132.19,8.43">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Kluck</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Magnini</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">3491</biblScope>
			<biblScope unit="page" from="27" to="37" />
			<publisher>Springer</publisher>
			<pubPlace>Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,92.88,276.69,400.37,8.43;14,112.80,287.37,213.78,8.43" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="14,161.64,276.69,327.87,8.43">Bibliographic database access using free-text and controlled vocabulary: An evaluation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,112.80,287.37,147.53,8.43">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="873" to="890" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,92.88,299.85,408.42,8.43;14,112.80,310.41,211.74,8.43" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="14,161.64,299.85,335.69,8.43">Light stemming approaches for the French, Portuguese, German and Hungarian languages</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,112.80,310.41,86.13,8.43">Proceedings ACM-SAC</title>
		<meeting>ACM-SAC</meeting>
		<imprint>
			<publisher>The ACM Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1031" to="1035" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,92.88,323.01,412.95,8.43;14,112.80,333.57,67.86,8.43" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="14,161.64,323.01,203.63,8.43">Why do successful search systems fail for some topics</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,373.92,323.01,86.13,8.43">Proceedings ACM-SAC</title>
		<meeting>ACM-SAC</meeting>
		<imprint>
			<publisher>The ACM Press</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="872" to="877" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,92.88,346.17,404.70,8.43" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="14,236.28,346.17,153.10,8.43">Fusion via a linear combination of scores</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Vogt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">W</forename><surname>Cottrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,397.80,346.17,39.05,8.43">IR Journal</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="151" to="173" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,92.88,358.65,360.78,8.43" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="14,187.08,358.65,108.15,8.43">The TREC 2005 robust track</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,303.48,358.65,71.37,8.43">ACM SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="41" to="48" />
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
