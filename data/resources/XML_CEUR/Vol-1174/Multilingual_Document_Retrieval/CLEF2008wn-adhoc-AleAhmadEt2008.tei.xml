<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,136.56,74.45,322.10,12.58">Cross Language Experiments at Persian@CLEF 2008</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,87.36,105.13,80.16,9.27"><forename type="first">Abolfazl</forename><surname>Aleahmad</surname></persName>
							<email>a.aleahmad@ece.ut.ac.ir</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="laboratory">Database Research Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,175.45,105.13,69.34,9.27"><forename type="first">Ehsan</forename><surname>Kamalloo</surname></persName>
							<email>e.kamalloo@ece.ut.ac.ir</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="laboratory">Database Research Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,252.20,105.13,51.96,9.27"><forename type="first">Arash</forename><surname>Zareh</surname></persName>
							<email>a.zareh@ece.ut.ac.ir</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="laboratory">Database Research Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,311.42,105.13,35.07,9.27;1,195.66,116.65,42.70,9.27"><forename type="first">Masoud</forename><surname>Rahgozar</surname></persName>
							<email>rahgozar@ut.ac.ir</email>
							<affiliation key="aff0">
								<orgName type="department">School of Electrical and Computer Engineering</orgName>
								<orgName type="laboratory">Database Research Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,396.06,105.13,87.27,9.27"><forename type="first">Farhad</forename><surname>Oroumchian</surname></persName>
							<email>oroumchian@acm.org</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of Wollongong</orgName>
								<address>
									<settlement>Dubai</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,136.56,74.45,322.10,12.58">Cross Language Experiments at Persian@CLEF 2008</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DA81F51BADE1EB8FC844319AA9B362CB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.3 [Information Search and Retrieval]: Information filtering</term>
					<term>Query formulation</term>
					<term>Retrieval models</term>
					<term>Search process</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this study we will discuss our cross language text retrieval (CLIR) experiments of Persian ad hoc track at CLEF 2008. Two teams from University of Tehran were involved in cross language text retrieval part of the track using two different CLIR approaches that are query translation and document translation. For query translation we used a method named Combinatorial Translation Probability (CTP) calculation for estimation of translation probabilities. In the document translation part we used the Shiraz machine translation system for translation of documents into English. Then we create a Hybrid CLIR system by score-based merging of the two retrieval system results. In addition, we investigated N-grams and a light stemmer in our monolingual experiments.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The Persian language is categorized as a branch of Indo-European languages and is the official language of Iran, Afghanistan and Tajikistan and is also spoken in some other countries in the Middle East. Morphological analysis of the language is relatively hard because of its grammatical rules. For example the word ‫"ﺧﺒﺮ"‬ is an Arabic word that is used in Persian. This word has two plural forms in Persian ‫"اﺧﺒﺎر"‬ and " ‫ﺧﺒ‬ ‫ﺮهﺎ‬ ", the first plural form obeys Arabic grammatical rules and the second plural form is obtained by use of Persian rules. After creation of 50 new bilingual topics and standardization of Hamshahri collection according to CLEF standards, we could investigate CLIR on Persian. Persian@CLEF 2008 is our first attempt to evaluate cross language information retrieval on the language. Our aim is to investigate two main approaches of cross language text retrieval on Persian that are query translation and document translation. We used the Hamshahri collection <ref type="bibr" coords="1,214.17,510.39,11.69,8.74" target="#b6">[7]</ref> for evaluation of our retrieval methods. Documents of this collection are actually news articles of Hamshahri newspaper from year 1996 to 2002. The collection contains 160,000+ documents from variety of subjects. The documents size varies from short news (under 1 KB) to rather long articles (e.g. 140 KB) with the average of 1.8 KB. Also we used Apache Lucene <ref type="bibr" coords="1,406.10,544.89,11.68,8.74" target="#b7">[8]</ref> and Lemur toolkit <ref type="bibr" coords="1,497.98,544.89,11.71,8.74" target="#b4">[5]</ref> for indexing and retrieval on the collection. The remaining parts of this paper are organized as follows: section 2 introduces our monolingual experiments, section 3 discusses our query translation method and its results, section 4 contains document translation experimental results and finally we will conclude our paper in section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Experiments on Monolingual Persian Text Retrieval</head><p>We had no efficient morphological analyzer for Persian, so in our monolingual experiments we tried to investigate some alternative methods like n-grams. Also, we used a stop word list in monolingual part of our experiments to improve retrieval results. In order to create the stop word list we manually inspected most frequent words of the collection and extracted actual stop words. Then we added some other words from the Bijankhan Persian corpus <ref type="bibr" coords="1,438.04,668.19,11.68,8.74" target="#b5">[6]</ref> that were marked with tags like proposition and conjunction. The final stop word list contains 796 items. In our monolingual experiments, we submitted top 100 retrieved documents of six monolingual runs that are summarized in table 1 and their description is as follows:</p><p>Run #1: Vector space retrieval model using a light stemmer Run #2: Term based vector space model retrieval Run #3: Using 3-grams with Language Modeling retrieval Run #4: Using 4-grams with Language Modeling retrieval Run #5: Using 5-grams with Language Modeling retrieval Run #6: Term-based Language Modeling retrieval In all of these runs we used just title part of the 50 Persian topics that was made available at CLEF 2008. In the first run, we used a light Persian stemmer that works like the Porter algorithm but it could not improve our results because of the simple algorithm of the stemmer. As an example consider the word ‫"ﻓﻴﻠﻢ"‬ that was a term in topic no 559. This word is a noun that means 'film' in English but our light stemmer considers the final ‫'م'‬ letter of the word as a suffix and converts it to ‫'ﻓﻴﻞ'‬ that means 'elephant' in English. Also, it worth mentioning that we do not cross word boundaries for building N-grams. For example 4-gram of the word ‫"ویﻤﺒﻠﺪون"‬ is ‫ﻝﺪون"‬ ‫ﺏﻠﺪو+‬ ‫ﻡﺒﻠﺪ+‬ ‫یﻤﺒﻞ+‬ ‫ویﻤﺐ+‬ " by use of our method.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">CLIR by Query Translation</head><p>This section illustrates our query translation experiments at Persian ad hoc track of CLEF 2008. As the users query is expressed in English and the collection's documents are written in Persian, we used an English-Persian dictionary with 50,000+ entries for translation of the query terms. In addition, we inserted some proper nouns into the dictionary. The query translation process is accomplished as follows.</p><p>Let M be the number of query terms, then we define users query as:</p><formula xml:id="formula_0" coords="2,251.52,414.36,92.51,15.20">{ } ( ) M i q Q i ,..., 1 = =</formula><p>Then we looked each q i up in the dictionary and after finding translations of q i we split the translations into its constituent tokens. Then we eliminate those tokens that are included in our Persian stop word list. If we define T as the translation function that returns Persian translations set of a given English term q i as described above, then we have |T(q 1 )|×|T(q 2 )|× . . . ×|T(q M )| different possible translations for the query Q and as one can expect |T(q i )|&gt;1 for most of query terms. So, we need a retrieval model which enables us to take translation probabilities into consideration. This model is briefly introduced in section 3.1 and in section 3.2 we propose our method for translation probability calculation. Then our query translation CLIR experimental results are presented in section 3.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Probabilistic Structured Query Method</head><p>Information retrieval systems rely on two basic statistics: the number of occurrences of a term in a document (Term Frequency or TF) and the number of documents in which a term appears (Document Frequency or DF). In case of bilingual text retrieval, when no translation probabilities are known, Pirkola's "structured queries" have been repeatedly shown to be among the most effective known approaches when several plausible translations are known for some query terms <ref type="bibr" coords="2,188.44,589.05,10.64,8.74" target="#b0">[1]</ref>. The basic idea behind Pirkola's method is to treat multiple translation alternatives as if they were all instances of the query term. Darwish and Oard later extended the model to handle the case in which translation probabilities are available by weighting the TF and DF computations, an approach they called probabilistic structured queries (PSQ) <ref type="bibr" coords="2,99.01,635.01,10.61,8.74" target="#b1">[2]</ref>. They found that Pirkola's structured queries yielded declining retrieval effectiveness with increasing numbers of translation alternatives, but that the incorporation of translation probabilities in PSQ tended to mitigate that effect. In our bilingual text retrieval experiments we use the PSQ method <ref type="bibr" coords="2,426.54,658.05,11.72,8.74" target="#b1">[2]</ref> in which TF and DF are calculated as follows:</p><formula xml:id="formula_1" coords="2,212.52,687.90,201.16,56.32">) , ( ) | ( ) , ( k f i i k D f TF e f p D e TF i ∑ × = ∑ × = i f i i f DF e f p e DF ) ( ) | ( ) (<label>(1)</label></formula><p>Where p(f i |e) is the estimated probability that e would be properly translated to f i . Our method for calculation of the translation probability is presented in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Combinatorial Translation Probability</head><p>Translation probability is generally estimated from parallel corpus statistics. But as no parallel corpus is available for Persian, in this section we introduce a method which estimates English to Persian translation probabilities by use of the Persian collection itself. As most user queries contain more than two terms (e.g. in the Hamshahri collection all queries has two or more terms), the main idea is to use co-occurrence probability of terms in the collection for translation probability calculation of adjacent query terms. Consider M as the number of user's query terms then we define the users query as Q = {q i } (i=1,…,M). For translation of Q, we look up Q members in an English to Persian dictionary to find their Persian equivalents. Considering T as the translation function, then we define set of translations of Q members as:</p><formula xml:id="formula_2" coords="3,234.66,226.41,127.93,15.76">{ } ) ( ),..., ( ), ( 2 1 M q T q T q T E =</formula><p>Then the probability that two adjacent query terms q i and q i+1 are translated into E[i,x] and E[i+1,y] respectively, is calculated from the following equation:</p><formula xml:id="formula_3" coords="3,130.08,290.49,334.00,54.52">|) | |, (| | | ]) , 1 [ ] , [ ( 1 1 1 + + + + = + → ∧ → qi qi qi qi i i D D Min c D D y i E q x i E q P I |) ) ( | .. 1 |, ) ( | .. 1 ( 1 + = = i i q T y q T x (2)</formula><p>Where D qi is a subset of collection's documents that contains the term q i and the constant c is a small value to prevent the denominator to become zero. In the next step we create translation probability matrix W k for each pair of adjacent query terms:</p><formula xml:id="formula_4" coords="3,194.22,412.39,205.54,12.71">|) ) ( | .. 1 |, ) ( | .. 1 ( } { 1 , + = = = k k n m k q T n q T m w W</formula><p>Where w m,n is calculated using equation <ref type="bibr" coords="3,256.82,441.33,10.63,8.74" target="#b1">(2)</ref>. Then Combinatorial Translation Probability (CTP) is a |T(q 1 )|×|T(q M )| matrix that is calculated by multiplication of all of the W k matrices:</p><formula xml:id="formula_5" coords="3,222.12,475.21,150.97,12.87">) 1 1 ( ) ( 1 - = × × = M k W W Q CPT k K K</formula><p>In other words, CTP matrix contains probability of translation of Q members into their different possible translations in Persian. Given the CTP(Q) matrix, the algorithm in table 2 returns the TDimes matrix which</p><formula xml:id="formula_6" coords="3,70.92,514.73,207.77,16.03">contains dimensions of { } ) ( ),..., ( ), ( 2 1 M q T q T q T E =</formula><p>matrix that correspond to top n most probable translations of the query Q = {q i } (i=1,…,M). </p><formula xml:id="formula_7" coords="3,72.72,741.31,95.03,9.83">q T q T q T E =</formula><p>and their weight from CTP. For example if we consider an English query that has three terms then the most probable Persian translation of the query terms would be E[1,TDimes <ref type="bibr" coords="4,497.85,73.26,11.45,9.02" target="#b0">[1,</ref><ref type="bibr" coords="4,509.30,73.26,7.63,9.02" target="#b0">1]</ref>], E[2,TDimes <ref type="bibr" coords="4,126.27,84.72,12.08,9.02" target="#b0">[1,</ref><ref type="bibr" coords="4,138.35,84.72,8.05,9.02" target="#b1">2]</ref>] and E[3,TDimes <ref type="bibr" coords="4,240.65,84.72,12.07,9.02" target="#b0">[1,</ref><ref type="bibr" coords="4,252.72,84.72,8.05,9.02" target="#b2">3]</ref>] respectively and the translated query's weight would be CTP[TopColumns <ref type="bibr" coords="4,138.67,96.24,14.52,9.02" target="#b0">[1]</ref>,TopRows <ref type="bibr" coords="4,191.91,96.24,14.52,9.02" target="#b0">[1]</ref>].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Query Translation Experimental Results</head><p>We translated the queries through term lookup in an English-Persian dictionary as described before and using methods of section 3.1 and 3.2. All of our query translation experiments were run using title of the English version of the 50 topics except run #8 in which we used title + description of the topics. In this part of our experiments we had eight runs that are summarized in table <ref type="table" coords="4,311.49,159.99,5.01,8.74" target="#tab_2">3</ref> and their description is as follows:</p><p>Run #1: In this run we concatenate all meanings of each of the query terms to formulate a Persian query.</p><p>Run #2: The same as previous run but uses top 5 Persian meanings of each of the query words for query translation.</p><p>Run #3: The same as previous run but uses the first Persian meaning of each of the query words for query translation.</p><p>Run #4: Uses all Persian meanings of query terms for query translation for calculating CTP. Then we used the PSQ method with top 10 most probable Persian translations of the query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run #5:</head><p>In this run we first look up top 5 meanings of query terms in the dictionary and then we convert them into 4-grams for calculating CTP. Then we use PSQ method with top 10 most probable Persian translations of the query to run 4-gram based retrieval. Run #6: The same as previous run but we use 5-grams instead of 4-grams. Run #7: This run is the same as run #3 but in this run we use the Lucene vector space retrieval model. Run #8: This run is the same as run #7 but in this run we use title + description. We eliminate common words such as 'find', 'information', from the topics description.</p><p>We used the Lemur toolkit <ref type="bibr" coords="4,180.69,378.51,11.65,8.74" target="#b4">[5]</ref> for implementation of our algorithm for run #1 to run #5. The default retrieval model of the lemur's retrieval engine (Indri) is language modeling. The Indri retrieval engine supports structured queries and we could easily implement the PSQ method using CPT for translation probability estimation. Also, run #7 and run #8 are implemented by use of the Lucene retrieval engine. Also Figure <ref type="figure" coords="4,120.93,588.27,5.01,8.74" target="#fig_0">1</ref> depicts the precision-recall graph of the eight runs for top 100 retrieved documents that are calculated by use of the Trec_Eval tool. According to the 'comparison of median average precision' figure that was released at Persian@CLEF 2008, this method could over perform monolingual retrieval results for some topics like topic no 570. This is because of the implicit query expansion effect of this method. The topic's title is 'Iran dam construction' and after its translation into Persian, the CTP method adds the word ‫'ﺁب'‬ to the query that means water in English.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CLIR by Document Translation</head><p>In order to translate the Hamshahri collection's documents from Persian into English, we used the Shiraz machine translation system that is prepared at the New Mexico State University <ref type="bibr" coords="5,420.78,416.91,10.58,8.74" target="#b2">[3]</ref>. The Shiraz machine translation system is an open source project that is written with the C language <ref type="bibr" coords="5,393.25,428.37,10.64,8.74" target="#b3">[4]</ref>. This system uses a bilingual Persian to English dictionary consisting of approximately 50,000 terms, a complete morphological analyzer and a syntactic parser. The machine translation system is mainly targeted at translating news material. Document translation is not a popular approach because this approach of CLIR is not computationally efficient. This fact was also apparent in our experiments. We ran the Shiraz machine translation on a PC with 2G of RAM and an Intel 3.2G CPU and it took more than 12 days to translate nearly 80 percent of the collection. Finally we could translate 134165 out of 166774 documents of the collection and we skipped translation of long documents to save time. In our document translation experiments we had one run, named CLDTDR, by use of document translation that is described below:</p><p>Run #9: In this run we use the English version of the 50 topics of Persian@CLEF 2008. Then we retrieved translated documents of the collection using the Lucene vector space retrieval engine. This run utilizes title + description part of the topics.</p><p>Furthermore, we tried a hybrid CLIR method by score-based merging of the results of query translation and document translation methods. For this purpose we used merge results of the CLDTDR and UTNLPDB1BT4G runs. The two runs used different retrieval engines and hence their retrieval scores were not in the same scale. To address this problem we used the following equation to bring the scores of the two retrieval lists into the same scale:</p><formula xml:id="formula_8" coords="5,231.84,660.31,130.20,28.14">) ( ) ( ) ( S , , , i q i q i q i i L Min L Max L Min x core - - =</formula><p>In which x i and Score i are the old and the normalized scores, Min(L i,q ) and Max(L i,q ) are the minimum and maximum scores in the i th retrieved list for the query q (i=1,2 for the two runs). This normalization normalizes the scores into the range [0, 1]. Then for obtaining the merged results we chose top 100 documents with highest weight from the two lists. Table <ref type="table" coords="6,96.42,73.53,5.01,8.74" target="#tab_4">4</ref> and Figure <ref type="figure" coords="6,150.01,73.53,5.01,8.74" target="#fig_1">2</ref> show performance of our query translation, document translation and hybrid CLIR systems and compare them with one of our monolingual systems as a baseline.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion and Future works</head><p>In Persian ad hoc track of ninth CLEF campaign in addition to some monolingual retrieval systems, we evaluated a number of cross language information retrieval systems. In monolingual part of our experiments we evaluated N-grams and a light stemmer on the Persian language and in cross language part we evaluated query translation and document translation approaches of English-Persian cross language information retrieval. We used combinatorial translation probability method for query translation that uses statistics of the target language for estimating translation probabilities. Result of our hybrid cross language information retrieval experiments also suggests usefulness of combining document translation and query translation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,172.80,362.46,249.73,9.02"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Precision-Recall of the six query translation runs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,196.02,460.62,203.37,9.02"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Precision-Recall of CLIR experiments</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,92.82,130.86,409.63,107.89"><head>Table 1 . Persian monolingual retrieval systems</head><label>1</label><figDesc></figDesc><table coords="2,92.82,144.33,409.63,94.42"><row><cell>Run#</cell><cell>Run Name</cell><cell>tot-ret</cell><cell>rel-ret</cell><cell>MAP</cell><cell>Retrieval Model</cell><cell>Retrieval System</cell></row><row><cell>1</cell><cell>SECMLSR</cell><cell>5161</cell><cell>1967</cell><cell>26.89</cell><cell>Vector Space</cell><cell>Lucene</cell></row><row><cell>2</cell><cell>SECMLUSR</cell><cell>5161</cell><cell>1991</cell><cell>27.08</cell><cell>Vector Space</cell><cell>Lucene</cell></row><row><cell>3</cell><cell>UTNLPDB1M3G</cell><cell>5161</cell><cell>1901</cell><cell>26.07</cell><cell>Language Modeling</cell><cell>Lemur</cell></row><row><cell>4</cell><cell>UTNLPDB1M4G</cell><cell>5161</cell><cell>1950</cell><cell>26.70</cell><cell>Language Modeling</cell><cell>Lemur</cell></row><row><cell>5</cell><cell>UTNLPDB1M5G</cell><cell>5161</cell><cell>1983</cell><cell>27.13</cell><cell>Language Modeling</cell><cell>Lemur</cell></row><row><cell>6</cell><cell>UTNLPDB1MT</cell><cell>5161</cell><cell>2035</cell><cell>28.14</cell><cell>Language Modeling</cell><cell>Lemur</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,70.92,556.38,453.74,196.01"><head>Table 2 . Calculation of the TDimes matrix</head><label>2</label><figDesc></figDesc><table coords="3,70.92,568.26,453.74,184.13"><row><cell></cell><cell></cell><cell></cell><cell cols="7">1. Let TopRows[n] be the row number of n largest members of CTP</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="7">2. Let TopColumns[n] be the column number of n largest members of CTP</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="7">3. For i ← [1,…,n]</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">3.1. Let R = TopRows [i]</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">3.2. Let C = TopColumns [i]</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">3.3. TDimes[i,M] = C</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">3.4. For j ← [M-1,…,1]</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">If (j=1)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Let TDimes[i,j] = R</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">else</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Let TDimes [i,j] = the culomn number of the largest element of Rth row</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>of W i-1</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="7">4. Output the TDimes matrix</cell></row><row><cell cols="10">Having TDimes matrix, we are able to extract different translation of the users query from</cell></row><row><cell>{</cell><cell>(</cell><cell>1</cell><cell>),</cell><cell>(</cell><cell>2</cell><cell>),...,</cell><cell>(</cell><cell>M</cell><cell>} )</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,78.48,435.83,435.94,136.27"><head>Table 3 . English-Persian query translation experiments</head><label>3</label><figDesc></figDesc><table coords="4,78.48,449.25,435.94,122.86"><row><cell>Run#</cell><cell>Run Name</cell><cell cols="3">tot-rel rel-ret MAP</cell><cell>Dif</cell><cell>Retrieval Model</cell><cell>Retrieval System</cell></row><row><cell>1</cell><cell>UTNLPDB1BA</cell><cell>5161</cell><cell>758</cell><cell cols="3">6.73 baseline Language Modeling</cell><cell>Lemur</cell></row><row><cell>2</cell><cell>UTNLPDB1BT5</cell><cell>5161</cell><cell>974</cell><cell cols="2">10.19 + 3.46</cell><cell>Language Modeling</cell><cell>Lemur</cell></row><row><cell>3</cell><cell>UTNLPDB1BT1</cell><cell>5161</cell><cell>930</cell><cell>12.4</cell><cell>+ 5.67</cell><cell>Language Modeling</cell><cell>Lemur</cell></row><row><cell>4</cell><cell cols="2">UTNLPDB1BA10 5161</cell><cell cols="3">1150 14.07 + 7.34</cell><cell>Language Modeling</cell><cell>Lemur</cell></row><row><cell>5</cell><cell cols="2">UTNLPDB1BT4G 5161</cell><cell cols="3">1196 14.46 + 7.73</cell><cell>Language Modeling</cell><cell>Lemur</cell></row><row><cell>6</cell><cell cols="2">UTNLPDB1BT5G 5161</cell><cell cols="3">1166 14.43 + 7.70</cell><cell>Language Modeling</cell><cell>Lemur</cell></row><row><cell>7</cell><cell>CLQTR</cell><cell>5161</cell><cell>677</cell><cell>8.93</cell><cell>+ 2.20</cell><cell>Vector Space</cell><cell>Lucene</cell></row><row><cell>8</cell><cell>CLQTDR</cell><cell>5161</cell><cell>592</cell><cell>6.01</cell><cell>-0.72</cell><cell>Vector Space</cell><cell>Lucene</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,88.38,107.88,411.17,343.75"><head>Table 4 . Comparison of CLIR retireval experiments</head><label>4</label><figDesc></figDesc><table coords="6,88.38,121.90,411.17,329.72"><row><cell cols="2">Run Name</cell><cell>tot-rel</cell><cell>rel-ret</cell><cell>MAP</cell><cell cols="2">CLIR/Mono</cell><cell></cell><cell cols="2">Retrieval Model</cell><cell></cell><cell>Retrieval System</cell></row><row><cell>SECMLUSR</cell><cell></cell><cell>5161</cell><cell>1967</cell><cell>27.08</cell><cell></cell><cell>baseline</cell><cell></cell><cell cols="2">Vector Space</cell><cell></cell><cell>Lucene</cell></row><row><cell cols="2">UTNLPDB1BT4G</cell><cell>5161</cell><cell>1196</cell><cell>14.46</cell><cell></cell><cell>53 %</cell><cell></cell><cell cols="2">Language Modeling</cell><cell></cell><cell>Lemur</cell></row><row><cell>CLDTDR</cell><cell></cell><cell>5161</cell><cell>1234</cell><cell>12.88</cell><cell></cell><cell>48 %</cell><cell></cell><cell cols="2">Vector Space</cell><cell></cell><cell>Lucene</cell></row><row><cell>Hybrid CLIR</cell><cell></cell><cell>5161</cell><cell>1478</cell><cell>16.19</cell><cell></cell><cell>60 %</cell><cell></cell><cell cols="2">LM + Vector Space</cell><cell></cell><cell>Lemur + Lucene</cell></row><row><cell></cell><cell>0.9</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Precision</cell><cell>0.4 0.5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>0.1</cell><cell>0.2</cell><cell>0.3</cell><cell>0.4</cell><cell>0.5</cell><cell>0.6</cell><cell>0.7</cell><cell>0.8</cell><cell>0.9</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Recall</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">CLDTDR; MAP 12.88</cell><cell></cell><cell></cell><cell cols="3">MLUSR1; MAP 27.08</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="4">UT-NLPDB1-BT4G; MAP 14.46</cell><cell></cell><cell cols="3">Hybrid; MAP 16.19</cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to thank CLEF 2008 organizers for their supports in development of the Hamshahri collection.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="6,88.92,658.11,435.71,8.74;6,88.92,669.63,435.63,8.74;6,88.92,681.15,336.21,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,145.01,658.11,379.62,8.74;6,88.92,669.63,82.25,8.74">The effects of query structure and dictionary setups in dictionary-based cross-language information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Ari</forename><surname>Pirkola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,188.63,669.63,335.92,8.74;6,88.92,681.15,169.18,8.74">Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1998-08">August 1998</date>
			<biblScope unit="page" from="55" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,88.92,692.61,435.63,8.74;6,88.92,704.13,435.61,8.74;6,88.92,715.65,158.47,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,255.40,692.61,154.52,8.74">Probabilistic structured query methods</title>
		<author>
			<persName coords=""><forename type="first">Kareem</forename><surname>Darwish</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,429.06,692.61,95.49,8.74;6,88.92,704.13,431.69,8.74">Proceedings of the 21st Annual 26th International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 21st Annual 26th International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2003-07">July 2003</date>
			<biblScope unit="page" from="338" to="344" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,88.92,73.26,435.54,9.02;7,88.92,84.72,435.49,9.02;7,88.92,96.51,144.23,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,459.54,73.26,64.93,9.02;7,88.92,84.72,240.08,9.02">Persian-English Machine Translation: An Overview of the Shiraz Project</title>
		<author>
			<persName coords=""><forename type="first">Jan</forename><forename type="middle">W</forename><surname>Amtrup</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karine</forename><surname>Hamid Mansouri Rad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rémi</forename><surname>Megerdoomian</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Zajac</surname></persName>
		</author>
		<idno>MCCS-00-319</idno>
	</analytic>
	<monogr>
		<title level="s" coord="7,400.17,84.99,124.24,8.74;7,88.92,96.51,73.15,8.74">Memoranda in Computer and Cognitive Science</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>CRL</publisher>
		</imprint>
		<respStmt>
			<orgName>NMSU</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="7,88.92,108.03,238.04,8.74" xml:id="b3">
	<monogr>
		<ptr target="http://crl.nmsu.edu/Research/Projects/shiraz" />
		<title level="m" coord="7,88.92,108.03,55.08,8.74">Shiraz Project</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,88.92,119.49,181.35,8.74" xml:id="b4">
	<monogr>
		<ptr target="http://www.lemurproject.org/" />
		<title level="m" coord="7,88.92,119.49,57.07,8.74">Lemur Toolkit</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,88.92,131.01,211.30,8.74" xml:id="b5">
	<monogr>
		<ptr target="http://ece.ut.ac.ir/dbrg/bijankhan/" />
		<title level="m" coord="7,88.92,131.01,70.56,8.74">Bijankhan Corpus</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,88.92,142.53,226.04,8.74" xml:id="b6">
	<analytic>
		<title/>
		<ptr target="http://ece.ut.ac.ir/dbrg/hamshahri" />
	</analytic>
	<monogr>
		<title level="j" coord="7,88.92,142.53,86.52,8.74">Hamshahri Collection</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,88.92,153.99,196.72,8.74" xml:id="b7">
	<monogr>
		<ptr target="http://lucene.apache.org/" />
		<title level="m" coord="7,88.92,153.99,91.52,8.74">Apache Lucene project</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
