<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,83.64,74.14,428.16,12.64;1,270.00,90.22,55.26,12.64">UFRGS@CLEF2008: Indexing Multiword Expressions for Information Retrieval</title>
				<funder ref="#_YvvC3af">
					<orgName type="full">CNPq Universal</orgName>
				</funder>
				<funder>
					<orgName type="full">CAPES</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,118.44,141.59,80.87,9.02"><forename type="first">Otavio</forename><forename type="middle">Costa</forename><surname>Acosta</surname></persName>
							<email>[ocacosta@inf.ufrgs.br</email>
							<affiliation key="aff0">
								<orgName type="department">Instituto de Informática</orgName>
								<orgName type="institution">Universidade Federal do Rio Grande do Sul (UFRGS</orgName>
								<address>
									<addrLine>Caixa Postal 15.064 -91.501</addrLine>
									<postCode>-970</postCode>
									<settlement>Porto Alegre -RS</settlement>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,206.28,141.59,48.42,9.02"><forename type="first">André</forename><surname>Pinto</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Instituto de Informática</orgName>
								<orgName type="institution">Universidade Federal do Rio Grande do Sul (UFRGS</orgName>
								<address>
									<addrLine>Caixa Postal 15.064 -91.501</addrLine>
									<postCode>-970</postCode>
									<settlement>Porto Alegre -RS</settlement>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,294.60,141.59,96.63,9.02"><forename type="first">Viviane</forename><surname>Moreira Orengo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Instituto de Informática</orgName>
								<orgName type="institution">Universidade Federal do Rio Grande do Sul (UFRGS</orgName>
								<address>
									<addrLine>Caixa Postal 15.064 -91.501</addrLine>
									<postCode>-970</postCode>
									<settlement>Porto Alegre -RS</settlement>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,398.52,141.59,78.42,9.02"><forename type="first">Aline</forename><surname>Villavicencio</surname></persName>
							<email>avillavicencio]@inf.ufrgs.br</email>
							<affiliation key="aff0">
								<orgName type="department">Instituto de Informática</orgName>
								<orgName type="institution">Universidade Federal do Rio Grande do Sul (UFRGS</orgName>
								<address>
									<addrLine>Caixa Postal 15.064 -91.501</addrLine>
									<postCode>-970</postCode>
									<settlement>Porto Alegre -RS</settlement>
									<country key="BR">Brazil</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,83.64,74.14,428.16,12.64;1,270.00,90.22,55.26,12.64">UFRGS@CLEF2008: Indexing Multiword Expressions for Information Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">12DD1B52A7234618F688D9FF9C44C46A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.1 [Content Analysis and Indexing]: Linguistic processing. H.3.4 [Systems and Software]: Performance evaluation Free experimentation</term>
					<term>performance measurement</term>
					<term>multiword expression</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For UFRGS's participation on CLEF's Robust task, our aim was to assess the benefits of identifying and indexing Multiword Expressions (MWEs) for Information Retrieval. The approach used for MWE identification was totally statistical, based association measures such as Mutual Information and Chi-square. Contradicting our results on the training topics, the results on the test topics did not show any significant improvements. However, for some queries, the identification of MWEs was very important. We have also performed bilingual experiments which achieved 84% of their monolingual counterparts.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The identification and treatment of multiword expressions (MWEs) are means to improve the capabilities of Natural Language Processing (NLP) in solving problems. MWEs are sequences of words that act as a single unit for the purpose of linguistic analysis. The meaning of the expression is different from the meaning of its composing terms analysed individually, e.g. the terms "escape" and "goat" have a totally different meaning when used as a MWE.</p><p>The nature of MWEs is varied, which makes it difficult to devise a mechanism to identify and treat them in a uniform manner. Some estimates say that the number of MWEs in a language is in the same order of magnitude as the number of individual words used by a native speaker of that language.</p><p>The correct identification and treatment of MWEs is also important for Information Retrieval (IR). In an ideal IR system, the entries in the index should represent the concepts present in the documents. Indexing a MWE as separate terms will mean loss in semantics.</p><p>Our aim in this paper it to test the validity of applying statistical methods for the identification of MWEs applied to IR. This paper reports on the experiments we performed for CLEF's Robust task.</p><p>The remainder of this paper is organised as follows: Section 2 discusses some methods for the identification of MWEs; Section 3 describes our experimental runs and results; Section 4 presents our conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Identifying Multiword Expressions</head><p>The automatic identification of MWEs has been the focus of many investigations on NLP <ref type="bibr" coords="1,473.88,696.83,50.58,9.02;1,70.92,708.83,82.69,9.02" target="#b1">(Baldwin &amp; Villavicencio, 2002;</ref><ref type="bibr" coords="1,157.08,708.83,118.45,9.02" target="#b3">Nicholson &amp; Baldwin, 2006;</ref><ref type="bibr" coords="1,279.00,708.83,55.45,9.02" target="#b4">Pearce, 2002;</ref><ref type="bibr" coords="1,337.92,708.83,105.19,9.02" target="#b7">Villavicencio et al., 2007)</ref>. Most methods are based solely on statistics of the data collection, and this was the approach adopted here.</p><p>For the experiments described here, we implemented two measures of association that compare the joint probability of occurrence of a certain group of events: Mutual Information and Chi-Square. This probability p(ab) is calculated based on the null hypothesis of statistical independence between these events p 0 (ab) <ref type="bibr" coords="2,489.59,97.67,34.82,9.02;2,70.92,109.67,37.41,9.02" target="#b6">(Press et al., 1992)</ref>. In our case, the events are the occurrences of words in a given position. For each pair of adjacent words, known as bigram, we use these measures to calculate the strength of the association between them. The stronger the association, the more likely the bigram will compose a MWE.</p><p>• Mutual Information (MI) measures the mutual dependence of the terms composing the bigram. The MI for the bigram w 1 w 2 is calculated as shown in Eq 1.</p><formula xml:id="formula_0" coords="2,215.40,181.60,136.25,33.29">      = ∑ ) ( ) ( log ) ( 0 2 , ab n ab n N ab n MI b a</formula><p>(1)</p><p>• Chi-Square (χ 2 ) is based on a comparison of the observed frequencies with the expected frequencies. It is calculated according to Eq 2.</p><formula xml:id="formula_1" coords="2,222.60,256.66,287.60,31.42">∑ - = b a ab n ab n ab n , 0 2 0 2 ) ( )] ( ) ( [ χ (2)</formula><p>where: a corresponds either to the word w 1 or to ¬ w 1 (all but the word w 1 ), and b corresponds to the word w 2 or to ¬ w 2.</p><p>n(ab) is the number of bigrams ab in the corpus n 0 (ab) = n(a)n(b)/N 2 is the predicted number or null hypothesis n(a) is the number of words a N is the number of words in the corpus</p><p>The approach taken for MWE identification was as follows: first, we computed the co-occurrences for all bigrams in the collection. The second step was to collect from the web the frequencies of each single word and each bigram. Next, MI and χ 2 were computed for all bigrams. Then, the bigrams were ranked decreasing order of MI and χ 2 . Finally, the two rankings were merged, and the top k bigrams were kept.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments</head><p>This section describes our experiments submitted to the CLEF-2008 Robust Task. Sections 3.1 and 3.2 describe our monolingual experiments and their results, and Sections 4.3 and 4.4 refer to our bilingual runs and their results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Description of Runs and Resources for Monolingual Experiments</head><p>We worked on the English news collections composed by LA Times 94 and Glasgow Herald 95. There are 169,477 documents in total. Two versions of the collection were available: a "plain" version, and a version with word-sense disambiguation (WSD) data.</p><p>Using the WSD documents (UBC version), we created a document collection composed by the lemmas in the texts. This collection was used as the basis for all our WSD runs.</p><p>For the runs in which we used MWE identification, we computed MI and χ 2 only for bigrams that had nouns (NN). In order to further reduce the number of bigrams, we discarded all word pairs with fewer than ten occurrences. After the rankings for MI and χ 2 were merged, we kept the top 7,500 bigrams. Having this list of MWE candidates, we searched for their occurrence in the text collection. Each time a MWE candidate was found in a document, we added the MWE candidate to the document joined by an underscore. For example, suppose the bigram "home page" was part of the MWE candidate list, all documents that had this bigram would have the term "home_page" appended to them. The underscore is to force the IR system to index the MWE as a unity rather than as two separate terms. Notice that we did not remove the original bigram from the text, we just added the compound form, joined by the underscore.</p><p>We also tested the opposite approach, i.e. removing all compounds from the texts. Since our collections were composed by lemmas, some terms were joined by an underscore, e.g. "to_have". For the two final runs, we removed all underscores joining word forms. We used the Porter stemming algorithm <ref type="bibr" coords="3,268.44,73.67,56.23,9.02" target="#b5">(Porter, 1980)</ref> in three runs. Stop words were not removed.</p><p>The IR system we used was Zettair (Zettair), which is a compact and fast search engine developed by RMIT University (Australia) distributed under a BSD-style license. Zettair implements a series of IR metrics for comparing queries and documents. We used Okapi BM25 as some preliminary tests we performed on other data collections showed it achieved the best results.</p><p>We have submitted two baseline runs indexing the plain collection and five runs using the WSDannotated documents. The details of the monolingual runs are shown in Table <ref type="table" coords="3,384.60,157.67,3.76,9.02" target="#tab_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results for Monolingual Experiments</head><p>The results for our monolingual runs are summarised in Table <ref type="table" coords="3,324.96,325.79,4.98,9.02" target="#tab_1">2</ref> and Figure <ref type="figure" coords="3,378.96,325.79,3.76,9.02">1</ref>. All performances were extremely similar both in terms of MAP and Pr@10. This similarity can be easily seen by the overlap in the recall-precision curves in Figure <ref type="figure" coords="3,140.40,349.79,3.76,9.02">1</ref>. Statistically, the only significant differences were found when comparing the runs in which some kind of linguistic processing was used (Mono2, and all WSD runs) to the baseline run Mono1. A T-test between Mono1 and Mono2, for example, resulted in a p-value of 0.005, showing that stemming yields significant improvements.</p><p>The best run overall was WSD5, however, the superiority to the other runs is only marginal. These results disagree with the results we obtained on the training topics, as for those indexing MWEs significantly improved overall performance. The reasons for this discrepancy still need to be evaluated. We did find great improvements for some individual queries. For example the identification of "oil price" as a MWE in topic 290 and "student fees" in topic 325 led to improvements of 22% in MAP.</p><p>Comparing our results with other participant's, we came in 5 th place for both baseline and WSD tasks. These results are encouraging since the methods we used for MWE identification are very simple and can still be greatly improved. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Description of Runs and Resources for Bilingual Experiments</head><p>In addition to the monolingual experiments, we also submitted four bilingual runs using Spanish topics to query English documents. Our approach used to map concepts between languages was the same as described in <ref type="bibr" coords="4,70.92,344.75,108.19,9.02" target="#b2">(Geraldo &amp; Orengo, 2008)</ref>. The idea is to use algorithms for mining association rules (ARs) to map concepts between languages.</p><p>Since the approach requires a sample of parallel documents and the document collections were in English only, 20% of the collection was automatically translated using Google Translator<ref type="foot" coords="4,462.48,384.58,3.24,5.87" target="#foot_0">1</ref> . The Apriori algorithm <ref type="bibr" coords="4,113.52,398.75,92.47,9.02" target="#b0">(Agrawal et al., 1993)</ref> for mining ARs was applied over these simulated parallel documents. Each word in the original query was replaced by the words in the target language which remained after the filtering step. Table <ref type="table" coords="4,117.84,422.75,4.98,9.02" target="#tab_3">3</ref> shows the details of our bilingual runs. In one of the runs, Bi3, we also tested a modification to the BM25 algorithm that aims at giving more weight to rare terms. This modified version is also described in <ref type="bibr" coords="4,70.92,446.75,104.95,9.02" target="#b2">(Geraldo &amp; Orengo, 2008)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Results for Bilingual Experiments</head><p>The results for our bilingual runs are summarised in Table <ref type="table" coords="4,312.96,589.43,4.98,9.02" target="#tab_4">4</ref> and Figure <ref type="figure" coords="4,367.80,589.43,3.76,9.02">2</ref>. The best performance was achieved by Bi3, which combines stop-word removal, stemming and our modification to BM25. This advantage is statistically significant in relation to all other runs, showing that our modification to BM25 does improve retrieval performance. Stemming was also found to yield significant improvements. The recall-precision curves clearly show the ranking of the runs. When comparing to other participants, our best run scored very well, being the best overall.</p><p>If we compare the performance of a monolingual run and its bilingual counterpart (Mono2 and Bi2), we find that the bilingual version achieves 84% of the monolingual performance. The superiority of the monolingual run is statistically significant.</p><p>The run in which we used WSD information (i.e. the lemmas) was the worst. This is because the sample of parallel documents used as a basis for mining ARs had the original word forms and not the lemmas.  The results of the experiments have shown no significant improvements overall. However, for the training topics we found that indexing MWE enhanced the performance. The methods were used are very simple, and further work will concentrate in improving their results.</p><p>In addition to the monolingual experiments, we also submitted four bilingual runs using Spanish topics to query English documents The method used to map concepts between languages employed algorithms for mining association rules. Our bilingual experiments achieved 84% of their monolingual counterparts.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,184.56,425.21,226.35,8.96"><head>Figure</head><label></label><figDesc>Figure 2 -Recall/Precision curves for Bilingual Runs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,121.32,175.85,350.07,115.76"><head>Table 1 -Details of the test collections for the monolingual runs</head><label>1</label><figDesc></figDesc><table coords="3,121.32,194.33,350.07,97.28"><row><cell>RunID</cell><cell>Description</cell><cell>Number of unique terms</cell></row><row><cell>Mono1</cell><cell>baseline run (plain collection)</cell><cell>595,025</cell></row><row><cell>Mono2</cell><cell>baseline run (plain collection) and stemming</cell><cell>494,861</cell></row><row><cell>WSD1</cell><cell>lemmas</cell><cell>592,459</cell></row><row><cell>WSD2</cell><cell>lemmas and 7500 MWE</cell><cell>606,938</cell></row><row><cell>WSD3</cell><cell>lemmas, 7500 MWE, and stemming</cell><cell>512,896</cell></row><row><cell>WSD4</cell><cell>lemmas, removing compounds</cell><cell>577,508</cell></row><row><cell>WSD5</cell><cell>lemmas, removing compounds and stemming</cell><cell>487,979</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,170.28,511.97,254.82,128.00"><head>Table 2 -Monolingual Results in terms of MAP and Pr@10 RunID Mean Average Precision Precision at 10</head><label>2</label><figDesc></figDesc><table coords="3,172.32,555.83,229.86,84.14"><row><cell>Mono1</cell><cell>0.3120</cell><cell>0.3400</cell></row><row><cell>Mono2</cell><cell>0.3395</cell><cell>0.3544</cell></row><row><cell>WSD1</cell><cell>0.3424</cell><cell>0.3550</cell></row><row><cell>WSD2</cell><cell>0.3391</cell><cell>0.3587</cell></row><row><cell>WSD3</cell><cell>0.3434</cell><cell>0.3531</cell></row><row><cell>WSD4</cell><cell>0.3432</cell><cell>0.3531</cell></row><row><cell>WSD5</cell><cell>0.3465</cell><cell>0.3537</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,222.60,278.33,195.99,8.96"><head>Recall/Precision curves for Monolingual Runs</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,113.16,464.93,366.39,78.32"><head>Table 3 -Details of the test collections for the bilingual runs</head><label>3</label><figDesc></figDesc><table coords="4,113.16,483.41,366.39,59.84"><row><cell>RunID</cell><cell>Description</cell><cell>Number of unique terms</cell></row><row><cell>Bi1</cell><cell>baseline bilingual run, BM25</cell><cell>595,025</cell></row><row><cell>Bi2</cell><cell>stop-word removal, stemming, BM25</cell><cell>487,979</cell></row><row><cell>Bi3</cell><cell>stop-word removal, stemming, BM25+</cell><cell>487,979</cell></row><row><cell>Bi-WSD</cell><cell>stop-word removal, lemmas, BM25</cell><cell>592,459</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,114.19,103.85,353.32,306.70"><head>Table 4 -Bilingual Results in terms of MAP and Pr@10</head><label>4</label><figDesc></figDesc><table coords="5,114.19,122.33,353.32,288.22"><row><cell></cell><cell></cell><cell cols="2">RunID</cell><cell cols="3">Mean Average Precision</cell><cell cols="2">Precision at 10</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Bi1</cell><cell></cell><cell></cell><cell>0.2560</cell><cell></cell><cell></cell><cell>0.2838</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Bi2</cell><cell></cell><cell></cell><cell>0.2860</cell><cell></cell><cell></cell><cell>0.2880</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Bi3</cell><cell></cell><cell></cell><cell>0.3639</cell><cell></cell><cell></cell><cell>0.3575</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">Bi-WSD</cell><cell></cell><cell>0.2177</cell><cell></cell><cell></cell><cell>0.2469</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Bilingual Experiments</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.8000</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Bi1</cell></row><row><cell></cell><cell>0.7000</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Bi2</cell></row><row><cell></cell><cell>0.6000</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Bi3</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Bi-WSD</cell></row><row><cell>Precision</cell><cell>0.3000 0.4000 0.5000</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.2000</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.1000</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.0000</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.0</cell><cell>0.1</cell><cell>0.2</cell><cell>0.3</cell><cell>0.4</cell><cell>0.5</cell><cell>0.6</cell><cell>0.7</cell><cell>0.8</cell><cell>0.9</cell><cell>1.0</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Recall</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,76.68,741.71,139.45,9.02"><p>http://www.google.com/translate_t</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was partially supported by <rs type="funder">CNPq Universal</rs> <rs type="grantNumber">484585/2007-0</rs>. <rs type="person">Otavio Acosta</rs> is funded by a studentship from <rs type="funder">CAPES</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_YvvC3af">
					<idno type="grant-number">484585/2007-0</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,70.92,709.43,453.46,9.02;5,106.92,721.43,393.45,9.02" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,282.12,709.43,242.26,9.02;5,106.92,721.43,38.64,9.02">Mining Association Rules between Sets of Items in Large Databases</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Imielinski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Swami</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,163.20,721.48,258.14,8.86">Proc. of the ACM SIGMOD Conference on Management of Data</title>
		<meeting>of the ACM SIGMOD Conference on Management of Data<address><addrLine>Washington, D.C.</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,70.92,733.43,453.42,9.02;5,106.92,745.48,299.13,8.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,238.44,733.43,248.00,9.02">Extracting the Unextractable: A Case Study on Verb-particles</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Villavicencio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,504.36,733.48,19.98,8.86;5,106.92,745.48,273.97,8.86">Sixth Conference on Computational Natural Language Learning -CoNLL</title>
		<imprint>
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,70.92,73.67,453.58,9.02;6,106.92,85.67,417.45,9.02;6,106.92,97.67,39.57,9.02" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,246.36,73.67,278.14,9.02;6,106.92,85.67,85.82,9.02">UFRGS@CLEF2008: Using Association Rules for Cross-Language Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">P</forename><surname>Geraldo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">M</forename><surname>Orengo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,366.60,85.72,119.14,8.86">Working Notes of CLEF 2008</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Borri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Nardi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Aarhus, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,70.92,109.67,453.66,9.02;6,106.92,121.67,402.69,9.02" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,233.28,109.67,291.30,9.02;6,106.92,121.67,31.18,9.02">Interpretation of Compound Nominalisations Using Corpus and Web Statistic</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Nicholson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Baldwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,155.04,121.72,350.51,8.86">Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,70.92,133.67,453.49,9.02;6,106.92,145.67,209.25,9.02" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,152.52,133.67,269.51,9.02">A Comparative Evaluation of Collocation Extraction Techniques</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Pearce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,446.52,133.67,77.89,9.02;6,106.92,145.67,205.08,9.02">Third International Conference on Language Resources and Evaluation</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,70.92,157.67,332.01,9.02" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,156.60,157.67,136.04,9.02">An Algorithm for Suffix Stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,299.16,157.72,33.89,8.86">Program</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,70.92,169.67,453.49,9.02;6,106.92,181.67,204.57,9.02" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="6,380.28,169.72,144.13,8.86;6,106.92,181.72,82.28,8.86">Numerical Recipes in C: The Art of Scientific Computing</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">H</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Teukolsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">T</forename><surname>Veterling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">P</forename><surname>Flannery</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992">1992</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,70.92,193.67,453.55,9.02;6,106.92,205.67,417.61,9.02;6,106.92,217.72,417.61,8.86;6,106.92,229.67,186.93,9.02;6,70.92,241.67,276.49,9.02" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,399.84,193.67,124.63,9.02;6,106.92,205.67,300.14,9.02">Validations and Evaluation of Automatically Acquired Multiword Expressions for Grammar Engineering</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Villavicencio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kordoni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Idiart</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Ramisch</surname></persName>
		</author>
		<ptr target="www.seg.rmit.edu.au/zettair/" />
	</analytic>
	<monogr>
		<title level="m" coord="6,425.64,205.72,98.89,8.86;6,106.92,217.72,417.61,8.86;6,106.92,229.72,79.26,8.86">Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</title>
		<meeting>the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning<address><addrLine>Prague. Zettair</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-11-06">2007. 11/06/07, 2007</date>
			<biblScope unit="page" from="1034" to="10343" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
