<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,135.60,148.73,332.04,15.51;1,219.84,170.69,163.46,15.51">The Senso Question Answering System at QA</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,232.20,204.41,44.12,9.62"><forename type="first">José</forename><surname>Saias</surname></persName>
							<email>jsaias@di.uevora.pt</email>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Informática</orgName>
								<orgName type="institution">Universidade de Évora</orgName>
								<address>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,298.92,204.41,72.07,9.62"><forename type="first">Paulo</forename><surname>Quaresma</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Informática</orgName>
								<orgName type="institution">Universidade de Évora</orgName>
								<address>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,135.60,148.73,332.04,15.51;1,219.84,170.69,163.46,15.51">The Senso Question Answering System at QA</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F8E1441C629DCD66A9A67CE38310C08A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.7 Digital Libraries</term>
					<term>I.2 [Artificial Intelligence]: I.2.7 Natural Language Processing Natural Language Processing, Question answering, Questions beyond factoids</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The University of Évora participation in QA@CLEF2008 was focused on the Portuguese monolingual task and was based on the updated Senso Question Answering System.</p><p>This system uses a local knowledge base, providing semantic information for text search terms expansion. The solver module uses two components to collect plausible answers: the logic and the ad-hoc solvers. The logic solver starts by producing a First-Order Logic expression representing the question and a logic facts list representing the texts information and then it looks for answers within the facts list that unify and validate the question logic form. The ad-hoc solver is designed for cases where the answer can be directly detected in the text. Then all the results are merged for answer list validation, to filter and adjust answers weight.</p><p>The submitted run had only single answers (the system best answer). The overall accuracy was 46.5% and the overall Confidence Weighted Score was 0.23979. This paper has an overview of the system and its approach to QA@CLEF.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Informatics Department of the University of Évora participated again<ref type="foot" coords="1,417.12,671.00,3.97,4.84" target="#foot_0">1</ref> in the Question Answering (QA) task of the 2008's edition of Cross Language Evaluation Forum (CLEF) 2 . We registered for the Portuguese monolingual QA main task, testing our revised version of the Senso QA System.</p><p>The system mantains the usage of a common sense knowledge base to assist on sentence analysis and text retrieval. The participation on QA@CLEF-2007 <ref type="bibr" coords="2,340.49,123.77,10.45,9.62" target="#b2">[3]</ref> gave some clues about improvements that could be done to reduce the errors. The text retrieval query generation process was updated to improve the candidate document selection. The solver module keeps the two components (logic and ad-hoc) that search in parallel for candidate answers, however there is a new component for answer validation. The question type is taken into account and a Web search might be performed to evaluate each answer and adjust its weight to a more reliable value.</p><p>The next section explains the system architecture. The followed methodology is described with examples in section 3. The evaluation of the obtained results is presented in section 4. Finally, some conclusions and future work are pointed out in section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Architecture</head><p>The main components are the same that were present in 2007. The updates occured only inside some modules. Figure <ref type="figure" coords="2,188.76,286.13,4.98,9.62" target="#fig_0">1</ref> illustrates the system major modules: Libs, Query, Solver, Local KB and Web Interface. The Query Module.performs the question analysis and selects a set of relevant documents for each question, as explained in section 3. The query group identifier determines if a query will be associated with the first from that group, to work with the same topic.</p><p>The Libs Module manages the text collections: news documents from Público and Folha de São Paulo from years 1994 and 1995, plus the Wikipedia documents. These collections are seen as libraries that contain the information needed for question answering. All texts are indexed with Lucene<ref type="foot" coords="2,120.60,513.20,3.97,4.84" target="#foot_3">3</ref> , a full-featured text search engine, with a Senso personalized stemmer for Portuguese.</p><p>The Local KB module has a starting knowledge base, containing common sense facts about places, entities and events. The information is available to a logic tool with some inference capabilities, that helps the automatic capture of sentence meaning.</p><p>Most of the changes happened in the Solver Module. It performs a search for plausible answers using two parallel approaches:</p><p>• logic solver : a logic-programming based tool that looks for answers to a question, being aware of the semantic expressed in Local KB</p><p>• ad-hoc solver : case-based answer detection for questions where the answer can be directly detected in the text</p><p>The results are merged, forming a global and weight sorted list of candidate answers. This list is then processed by the new component: the answer validator. Some answer values are refused if they are not in accordance with the question type. Besides filtering, each answer weight may suffer an adjustment to a more reliable value. The Web redundancy can be exploited as a method for answer validation in QA <ref type="bibr" coords="2,215.19,705.65,10.57,9.62" target="#b5">[6]</ref>  <ref type="bibr" coords="2,229.24,705.65,9.91,9.62" target="#b6">[7]</ref>. The idea is to measure a statement popularity or acceptance with a Web search and take that into account for an answer accuracy validation.</p><p>The Web Interface layer allows an easier usage of the system. It is possible to consult text documents or check each intermediate step in the question analysis process and answer search. Next section explains the QA process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head><p>The Senso approach for QA was firstly inspired on the authors previous work <ref type="bibr" coords="3,431.53,190.49,10.57,9.62" target="#b3">[4]</ref> and <ref type="bibr" coords="3,464.06,190.49,10.00,9.62" target="#b4">[5]</ref>. Appart from the improved operations on text retrieval query formulation and web answer validation, the process is quite similar to last year.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Import the Text Collections</head><p>The XML collection files were processed and split into single texts, along with their metadata. The Libs Module keeps all these individual documents, being aware of their collection temporal context. Because we needed to perform some text search operations, the collections were indexed.</p><p>Each text was processed with Palavras <ref type="bibr" coords="3,279.01,296.68,14.76,7.24" target="#b7">[8]</ref>, a syntactical parser <ref type="foot" coords="3,388.80,295.28,3.97,4.84" target="#foot_4">4</ref> . This tool is based on the Constraint Grammars formalism and gives a detailed text morpho-syntactical representation for later usage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Question Analysis</head><p>Each question is also processed with the syntactical parser Palavras and a semantic analyzer able to obtain a partial semantic representation. The technique used for this process is based on Discourse Representation Structures (DRS) <ref type="bibr" coords="3,285.73,390.65,10.00,9.62" target="#b8">[9]</ref>. We are only dealing with a restricted semantic analysis and we are not able to handle every aspect of the semantics. The DRS is a First-Order Logic expression which the logic resolution tool will try to understand. The partial semantic representation of a sentence is a DRS built with two lists, one with the rewritten sentence and the other with the sentence discourse referents.</p><p>Let us consider the following QA@CLEF question:</p><p>Que instrumento tocava Ringo Starr ? (What instrument did Ringo Starr play ?)</p><p>The morpho-syntactical representation for the question, in figure <ref type="figure" coords="3,402.49,498.17,3.90,9.62">2</ref>, shows the parser tags identifying the subject, the predicate and the interrogative form que (What ). Figure <ref type="figure" coords="3,471.73,510.17,4.98,9.62" target="#fig_1">3</ref> has the DRS for the same question, with the semantic representation used by the system for later logic inference process. The system will search for something that is an instrument. At this point,</p><formula xml:id="formula_0" coords="3,187.44,555.03,236.59,63.57">QUE:fcl =SUBJ:np ==&gt;N:pron-det('que' &lt;interr&gt; M/F S) Que ==H:n('instrumento' &lt;tool&gt; &lt;tool-mus&gt; M S) instrumento =P:v-fin('tocar' IMPF 1/3S IND) tocava =ACC:prop('Ringo_Starr' &lt;hum&gt; M S) Ringo_Starr = ?</formula><p>Figure <ref type="figure" coords="3,236.65,641.57,3.90,9.62">2</ref>: Syntactical Parser: sample output a preliminary document retrieval task is done with Lucene, in order to elect a set of potentially relevant documents for each question. If no candidate documents are found the system cannot find an answer and the result is NIL.</p><p>The Query Module creates the Lucene search query. This is done with the question text terms and, for some, with their related terms as expressed in Local KB. So, when we are looking for instrument it is important to get documents that include synonyms or specialization terms (as  piano, drums and other), because those documents might be relevant as a possible answer source. When the question belongs to a cluster and it is not the first from that group, the query is fed with more terms in order to include the implicit topic. The system goes back to that cluster's first question and gets their search terms and answer into the Lucene query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Answer Engine</head><p>The Solver Module is responsible for finding a list of answers to a question, appreciate them and elect one as the best system answer. The list of candidate documents is processed in parallel by two different tools: the logic solver and the ad-hoc solver.</p><p>The semantic analyzer used before for the query will now create a DRS list for the selected texts. This list is a question dedicated Knowledge Base: the facts list. The logic solver is a logicprogramming based module that performs a pragmatic interpretation of the query DRS over the full system knowledge base (the Local KB and the facts list). It tries to find the best explanations for the question logic form to be true. The inference process is done with the Prolog resolution algorithm.</p><p>The ad-hoc solver is a case-based answer selector for questions where the answer can be directly detected in the text. It uses a text pattern and structure based approach, explored before in <ref type="bibr" coords="4,494.79,472.37,14.60,9.62" target="#b9">[10]</ref>. The algorithm has several rules about the sentence structure for question and text, for certain question types. If the question is 'What is X?' and a text contains 'X is a DEFINITION', then DEFINITION is a possible answer.</p><p>A concrete example for this situation is the question:</p><p>O que é uma cítara ? (What is a cítara ?)</p><p>There was a Wikipedia text stating:</p><p>A 'cítara' é um instrumento musical de várias cordas presas sobre um arco de madeira, com ou sem caixa de ressonância, que se tocavam com ambas as mãos.</p><p>This direct match gave one candidate answer, defining a cítara as a musical instrument having strings attached to a wood arc.</p><p>Each candidate answer has a weight and a snippet: sentence or expression justifying the answer and its document identifier. The results are merged, forming a global and weight sorted list that is processed by the answer validator. This new component does an appreciation of each answer value. Some might be refused if they are not in accordance with the question type.</p><p>Based on the principle that the Web redundancy can be exploited as a method for answer validation in question answering <ref type="bibr" coords="4,240.03,723.41,10.57,9.62" target="#b5">[6]</ref> [7], the system does a quick Web search to measure the answer value popularity with respect to the question. As a consequence, each answer weight may suffer an adjustment to a more reliable value.</p><p>If there is no candidate answer the system returns NIL as result. When the system finds more than one answer for a question, then the QA@CLEF answer is the one with the highest weight.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>As before, the University of Évora's group QA@CLEF participation was focused on the monolingual Portuguese task. The set of 200 questions was processed by the Senso QA system and one run output was sent for evaluation. The system answers were classified as Right for 93 questions, which corresponds to an overall accuracy score of 46.50% (4.5% more than obtained last year).</p><p>The system returned only 21 NIL answers, significantly less when comparing to 2007. Despite this appears to be a better value, the accuracy for the NIL question type went down from 10.81% to 9.52%. In the Factoids category the system had an accuracy of 40.74%, quite similar to last year. The best relative accuracy result was again on the Definition question type with 85.71%, which represents an improvement since 2007.</p><p>Table <ref type="table" coords="5,132.36,298.01,4.98,9.62" target="#tab_1">1</ref> shows the system detailed results, specifying the accuracy values per question type. The overall Confidence Weighted Score over all assessed questions is 47.959/200 = 0.23979. The overall accuracy is slightly better than the obtained last year. The next section has some conclusions about this participation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>The University of Évora's participation on QA@CLEF 2008 was based on their Senso Question Answering System. Being the second time this QA system is used, the results are in line with the expected: close to or a little better than last year.</p><p>The document retrieval process was updated. One of the changes was in the Portuguese stemmer used in the Lucene indexing and search operations. This and the text search query generation process led to the identification of more candidate documents, decreasing the number of NIL answers.</p><p>The logic solver has a few problems with DRS generation, specially when analyzing morphosyntactical representation of non-trivial sentences. Other problems happen in the pragmatic interpretation of the DRS. Most of the answers found by the system are from the ad-hoc solver.</p><p>The answer validation process gave a relevant contribution to accuracy. The redundancy of Web information allows the usage of a search result as a clue for the validity of an answer.</p><p>The ad-hoc solver is a rule based answer generator. Some of those rules need an adjustment. Before applying our system to other source languages, there is some work to do in order to make the system components independent from the language. The rules in ad-hoc solver are language dependent. One possibility for a future participation is the submission of multiple answers per question. That can be accomplished with this system by selecting the N most weighted answers.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,225.96,418.73,151.20,9.62;2,219.13,319.33,164.62,74.48"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: QA System Architecture</figDesc><graphic coords="2,219.13,319.33,164.62,74.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,115.68,214.97,370.39,9.62"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: System's logic representation for 'What instrument did Ringo Starr play ?'</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,99.48,320.94,403.76,112.93"><head>Table 1 :</head><label>1</label><figDesc>University of Évora's results in QA@CLEF2008</figDesc><table coords="5,99.48,320.94,403.76,78.20"><row><cell>Question Type</cell><cell>#</cell><cell cols="5">Right Wrong Unsupported Inexact Accuracy</cell></row><row><cell>Nil</cell><cell>21 returned</cell><cell>2</cell><cell>19</cell><cell>0</cell><cell>0</cell><cell>9.52%</cell></row><row><cell>Temporally Restricted</cell><cell>16</cell><cell>4</cell><cell>12</cell><cell>0</cell><cell>0</cell><cell>25.00%</cell></row><row><cell>Definition</cell><cell>28</cell><cell>24</cell><cell>2</cell><cell>0</cell><cell>2</cell><cell>85.71%</cell></row><row><cell>Lists</cell><cell>10</cell><cell>3</cell><cell>5</cell><cell>0</cell><cell>2</cell><cell>30.00%</cell></row><row><cell>Factoids</cell><cell>162</cell><cell>66</cell><cell>87</cell><cell>2</cell><cell>7</cell><cell>40.74%</cell></row><row><cell>All Questions</cell><cell>200</cell><cell>93</cell><cell>94</cell><cell>2</cell><cell>11</cell><cell>46.50%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,105.24,725.93,246.94,9.60"><p>The University of Évora has previous QA@CLEF participations in</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2004" xml:id="foot_1" coords="1,374.71,727.85,11.35,7.68"><p><ref type="bibr" coords="1,374.71,727.85,8.51,7.68" target="#b0">[1]</ref>,</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2005" xml:id="foot_2" coords="1,408.60,727.85,71.57,7.68;1,101.04,736.22,3.65,4.16;1,105.24,737.45,280.57,7.68"><p><ref type="bibr" coords="1,408.60,727.85,8.95,7.68" target="#b1">[2]</ref> and last year<ref type="bibr" coords="1,471.22,727.85,8.95,7.68" target="#b2">[3]</ref> 2 CLEF detailed information can be found at http://www.clef-campaign.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3" coords="2,105.24,736.61,252.86,7.68"><p>Apache Lucene is an open source project. http://lucene.apache.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4" coords="3,105.24,744.77,282.77,7.68"><p>Tool developed by Eckhard Bick. VISL Project: http://visl.hum.sdu.dk/visl</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,105.48,133.61,407.48,9.62;6,100.56,143.09,327.02,12.14" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,472.80,133.61,40.17,9.18;6,100.56,143.09,196.76,11.70">The University of Évora approach to QA@CLEF-2004</title>
		<author>
			<persName coords=""><forename type="first">Paulo</forename><surname>Quaresma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luis</forename><surname>Quintano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Irene</forename><surname>Rodrigues</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">José</forename><surname>Saias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pedro</forename><surname>Salgueiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,306.72,145.61,116.28,9.62">CLEF 2004 Working Notes</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.48,165.53,407.45,9.62;6,100.56,177.41,151.58,9.62" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="6,271.44,165.53,241.50,9.18;6,100.56,177.41,22.75,9.18">A Logic Programming Based Approach To QA@CLEF05 Track</title>
		<author>
			<persName coords=""><forename type="first">Paulo</forename><surname>Quaresma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Irene</forename><surname>Rodrigues</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note type="report_type">CLEF</note>
	<note>Working Notes</note>
</biblStruct>

<biblStruct coords="6,105.48,197.33,407.62,9.62;6,100.56,209.33,412.55,9.62;6,100.56,221.33,313.80,9.62" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,245.66,197.33,267.45,9.62;6,100.56,209.33,18.34,9.62">The senso question answering approach to portuguese qa@clef-2007</title>
		<author>
			<persName coords=""><forename type="first">José</forename><surname>Saias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paulo</forename><surname>Quaresma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,206.05,209.33,307.06,9.62;6,100.56,221.33,18.25,9.62">CLEF 2007 Working Notes, Cross-Language Evaluation Forum Workshop</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="6,105.48,241.25,407.43,9.62;6,100.56,253.13,412.41,9.62;6,100.56,265.13,412.66,9.62;6,100.56,277.13,219.20,9.62" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,250.32,241.25,262.59,9.18;6,100.56,253.13,31.66,9.18">A methodology to create ontology-based information retrieval systems</title>
		<author>
			<persName coords=""><forename type="first">José</forename><surname>Saias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paulo</forename><surname>Quaresma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,363.55,253.13,149.42,9.62;6,100.56,265.13,359.06,9.62">Progress in Artificial Intelligence -Proceedings of the 11th Protuguese Conference on Artificial Intelligence, EPIA&apos;03</title>
		<editor>
			<persName><forename type="first">Fernando</forename><surname>Moura</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Pires</forename></persName>
		</editor>
		<editor>
			<persName><forename type="first">Salvador</forename><surname>Abreu</surname></persName>
		</editor>
		<meeting><address><addrLine>Beja, Portugal</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.48,297.05,407.45,9.62;6,100.56,308.93,412.64,9.62;6,100.56,320.93,412.60,9.62;6,100.56,332.81,359.16,9.62" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,264.72,297.05,248.21,9.18;6,100.56,308.93,101.55,9.18">A proposal for an ontology supported news reader and question-answer system</title>
		<author>
			<persName coords=""><forename type="first">José</forename><surname>Saias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paulo</forename><surname>Quaresma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,395.66,308.93,117.54,9.62;6,100.56,320.93,412.60,9.62;6,100.56,332.81,127.54,9.62">2nd Workshop on Ontologies and their Applications (WONTO&apos;06) in the Proceedings of International Joint Conference, 10th IBERAMIA, ICMC-USP</title>
		<editor>
			<persName><forename type="first">Solange</forename><surname>Oliveira</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Rezende</forename></persName>
		</editor>
		<meeting><address><addrLine>Ribeirão Preto, Brazil</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.48,352.85,407.49,9.62;6,100.56,364.73,412.69,9.62;6,100.56,376.73,367.61,9.62" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,360.96,352.85,152.01,9.18;6,100.56,364.73,43.34,9.18">Exploiting redundancy in question answering</title>
		<author>
			<persName coords=""><forename type="first">Charles</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gordon</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Lynam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,158.52,364.73,354.72,9.62;6,100.56,376.73,245.25,9.62">Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR-2001)</title>
		<meeting>the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR-2001)</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.48,396.65,407.60,9.62;6,100.56,408.53,412.48,9.62;6,100.56,420.53,412.48,9.62;6,100.56,432.53,110.83,9.62" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,426.24,396.65,86.84,9.18;6,100.56,408.53,253.88,9.18">Is It the Right Answer? Exploiting Web Redundancy for Answer Validation</title>
		<author>
			<persName coords=""><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matteo</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Roberto</forename><surname>Prevete</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hristo</forename><surname>Tanev</surname></persName>
		</author>
		<idno type="DOI">10.3115/1073083.1073154</idno>
	</analytic>
	<monogr>
		<title level="m" coord="6,373.20,408.53,139.83,9.62;6,100.56,420.53,289.91,9.62">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL)</title>
		<meeting>the 40th Annual Meeting of the Association for Computational Linguistics (ACL)<address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.48,452.45,407.49,9.62;6,100.56,464.33,339.86,9.62" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,177.36,452.45,136.51,9.18">The Parsing System &quot;Palavras</title>
		<author>
			<persName coords=""><forename type="first">Eckhard</forename><surname>Bick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,327.96,452.45,185.01,9.18;6,100.56,464.33,197.09,9.18">Automatic Grammatical Analysis of Portuguese in a Constraint Grammar Framework</title>
		<imprint>
			<publisher>Aarhus University Press</publisher>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.48,484.25,331.28,9.62" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Kamp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Reyle</surname></persName>
		</author>
		<title level="m" coord="6,216.00,484.25,105.14,9.18">From Discourse to Logic</title>
		<meeting><address><addrLine>Dordrecht</addrLine></address></meeting>
		<imprint>
			<publisher>Kluwer</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.52,504.17,361.10,9.62" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,174.48,504.17,168.21,9.18">Extraction of Definitions for Bulgarian</title>
		<author>
			<persName coords=""><forename type="first">Hristo</forename><surname>Tanev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,350.76,504.17,116.28,9.62">CLEF 2006 Working Notes</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
