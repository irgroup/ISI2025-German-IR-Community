<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,149.52,74.45,296.28,12.58">Overview of the Answer Validation Exercise 2008</title>
				<funder>
					<orgName type="full">Education Council of the Regional Government of Madrid</orgName>
				</funder>
				<funder ref="#_P9EAxHk">
					<orgName type="full">Spanish Ministry of Science and Innovation</orgName>
				</funder>
				<funder>
					<orgName type="full">European Social Fund</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,199.68,105.42,61.09,9.02"><forename type="first">Álvaro</forename><surname>Rodrigo</surname></persName>
							<email>alvarory@lsi.uned.es</email>
							<affiliation key="aff0">
								<orgName type="department">Sistemas Informáticos</orgName>
								<orgName type="institution">UNED</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,267.65,105.42,60.23,9.02"><forename type="first">Anselmo</forename><surname>Peñas</surname></persName>
							<email>anselmo@lsi.uned.es</email>
							<affiliation key="aff0">
								<orgName type="department">Sistemas Informáticos</orgName>
								<orgName type="institution">UNED</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,337.21,105.42,58.56,9.02"><forename type="first">Felisa</forename><surname>Verdejo</surname></persName>
							<email>felisa@lsi.uned.es</email>
							<affiliation key="aff0">
								<orgName type="department">Sistemas Informáticos</orgName>
								<orgName type="institution">UNED</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,198.66,129.60,66.12,9.02"><forename type="first">Dpto</forename><surname>Lenguajes</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Sistemas Informáticos</orgName>
								<orgName type="institution">UNED</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,149.52,74.45,296.28,12.58">Overview of the Answer Validation Exercise 2008</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EE711588377F4C490849128EF864EE62</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Question Answering</term>
					<term>Evaluation</term>
					<term>Textual Entailment</term>
					<term>Answer Validation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The Answer Validation Exercise at the Cross Language Evaluation Forum (CLEF) is aimed at developing systems able to decide whether the answer of a Question Answering (QA) system is correct or not. We present here the exercise description, the changes in the evaluation with respect to the last edition, and the results of this third edition (AVE 2008). Last year's changes allowed us to measure the possible gain in performance obtained by using AV systems as the selection method of QA systems. In this edition we wanted to reward AV systems able to detect if all the candidate answers to a question are incorrect. 9 groups have participated with 24 runs in 5 different languages, and compared with the QA systems, the results show an evidence of the potential gain that more sophisticated AV modules might introduce in the task of QA.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The first Answer Validation Exercise (AVE 2006) <ref type="bibr" coords="1,286.68,379.26,11.69,9.02" target="#b5">[6]</ref> was activated two years ago in order to promote the development and evaluation of subsystems aimed at validating the correctness of the answers given by Question Answering (QA) systems. In some sense, systems must emulate human assessment of QA responses and decide whether an answer is correct or not according to a given supporting text. This automatic Answer Validation is expected to be useful for improving QA systems performance <ref type="bibr" coords="1,320.93,427.26,10.67,9.02" target="#b3">[4]</ref>. However, the evaluation methodology in AVE 2006 did not permit to quantify this improvement and thus, the exercise was modified in AVE 2007 <ref type="bibr" coords="1,482.72,439.26,10.63,9.02" target="#b7">[8]</ref>, where the problem of Automatic Hypothesis Generation was also opened.</p><p>In AVE 2007 participant systems had to emulate QA systems selecting one answer per question from a set of candidate ones. These candidate answers were the ones given by QA systems participating at the QA main track at CLEF. This allowed us to study the use of Answer Validation (AV) systems as the answer selection method used by a QA system. Nevertheless, it was not acknowledged the ability of an AV system detecting if all the candidate answers to a question were incorrect. Systems with this ability could ask for new answers to the QA systems, opening the possibility of obtaining a correct answer to the question. Besides, NIL answers could be detected. Then, we have studied this behaviour in AVE 2008.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Exercise Description</head><p>Following the format proposed in AVE 2007, in this edition participant systems received a set of triplets (Question, Answer, Supporting Text) and they had to return a value for each triplet rejecting or accepting it. More in detail, the input format was a set of pairs (Answer, Supporting Text) grouped by Question (see Figure <ref type="figure" coords="1,519.57,617.82,5.01,9.02">1</ref> for an example). Systems must consider the Question and validate each of these (Answer, Supporting Text) pairs. The number of answers to be validated per question depends on the number of participant systems at the QA main track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1. Excerpt of the English test collection in AVE 2008</head><p>Participant systems must return one of the following values for each answer according to the response format (see Figure <ref type="figure" coords="2,118.17,379.14,3.72,9.02">2</ref>):</p><p>• VALIDATED indicates that the answer is correct and supported by the given supporting text. There is no restriction in the number of VALIDATED answers returned per question (from zero to all).</p><p>• SELECTED indicates that the answer is VALIDATED and it is the one chosen as the output to the current question by a hypothetical QA system. The SELECTED answers are evaluated against the QA systems of the Main Track. No more than one answer per question can be marked as SELECTED. At least one of the VALIDATED answers must be marked as SELECTED.</p><p>• REJECTED indicates that the answer is incorrect or there is not enough evidence of its correctness.</p><p>There is no restriction in the number of REJECTED answers per question (from zero to all).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2. Response format in AVE 2008</head><p>This configuration permitted us to compare the AV systems responses with the QA ones, and to obtain some evidences about the gain in performance that sophisticated AV modules can give to QA systems (see below).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Collections</head><p>In the exercise we want to promote the development of AV systems that perform an analysis beyond the use of redundancies in answers. Since the fact of grouping all the answers to the same question could lead to provide extra information based on counting answer redundancies, like in AVE 2007, if an answer is contained in another answer, we remove the shorter one. Besides, with this processing no extra information is given with respect to QA participant systems at the main track, allowing the comparison with them. Furthermore, NIL and void answers were discarded for building the collections. This processing lead to a reduction in the number of q_id a_id [SELECTED|VALIDATED|REJECTED] confidence &lt;q id="0001" lang="EN"&gt; &lt;q_str&gt;What was the nationality of Jacques Offenbach?&lt;/q_str&gt; &lt;a id="0001_1" value=""&gt; &lt;a_str&gt;Germany&lt;/a_str&gt; &lt;t_str doc="Offenbach"&gt;Offenbach Offenbach Offenbach can refer to: The city Offenbach in Hesse, Germany.&lt;/t_str&gt; &lt;/a&gt; &lt;a id="0001_2" value=""&gt; &lt;a_str&gt;France&lt;/a_str&gt; &lt;t_str doc="Jacques Offenbach"&gt;His son received the name "Jakob Offenbach" at birth, though he changed it to Jacques when he settled in France.&lt;/t_str&gt; &lt;/a&gt; &lt;a id="0001_3" value=""&gt; &lt;a_str&gt;Thousand Oaks&lt;/a_str&gt; &lt;t_str doc="LA111794-0288"&gt;Ventura College's production of George Bernard Shaw's "Arms and the Man" and Moorpark College's version of the Jacques Offenbach operetta "La Vie Parisienne" are the costume shows; in Thousand Oaks, Cal Lutheran University is mounting the contemporary drama "Minor Demons."&lt;/t_str&gt; &lt;/a&gt; ... &lt;/q&gt; answers initially available in the collections (see Tables <ref type="table" coords="3,311.39,73.68,5.01,9.02" target="#tab_2">1</ref> and<ref type="table" coords="3,339.59,73.68,3.73,9.02" target="#tab_3">2</ref>): from 13.79% in the Italian development collection to 78.57% in the Bulgarian test collection.</p><p>Like in the past edition of QA@CLEF <ref type="bibr" coords="3,247.12,97.68,10.61,9.02" target="#b2">[3]</ref>, questions were grouped by topic. In this organization by topics, the first question of each topic is self contained in the sense that there is no need of information outside the question to answer it. However, the rest of the topic questions can refer to implicit information linked to the previous questions and answers of the topic group (anaphora, co-reference, etc.). Therefore, for the AVE 2008 test collections we only made use of the self-contained questions (the first one of each topic group) and their respective answers given by the participant systems in QA.</p><p>For the assessments, we reused the QA judgements because they were done considering the supporting snippets in a similar way the AV systems must do. The relation between QA assessments and AVE judgements was the following: • Answers not evaluated at the QA main track (if any) are also tagged as UNKNOWN in AVE and they are also ignored in the evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Development Collections</head><p>Development collections were obtained from the QA@CLEF 2006 <ref type="bibr" coords="3,349.93,337.26,11.71,9.02" target="#b4">[5]</ref> and 2007 <ref type="bibr" coords="3,406.62,337.26,11.68,9.02" target="#b2">[3]</ref> main track questions and answers. Table <ref type="table" coords="3,133.53,348.72,5.01,9.02" target="#tab_2">1</ref> shows the number of questions and answers for each language together with the percentage that these answers represent over the number of answers initially available, and the number of answers with VALIDATED and REJECTED values.</p><p>These collections were available for participants after their registration at CLEF at http://nlp.uned.es/clefqa/ave/ </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>German</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Test Collections</head><p>Test collections were obtained from the runs sent to QA@CLEF 2008 main track <ref type="bibr" coords="3,403.52,603.96,10.64,9.02" target="#b1">[2]</ref>. In this edition, there were runs in 9 languages: German, English, Spanish, French, Bulgarian, Dutch, Portuguese, Romanian and Basque. Thus, a test collection in AVE was generated for each of these languages. Table <ref type="table" coords="3,111.40,638.40,5.01,9.02" target="#tab_3">2</ref> shows the number of questions and the number of answers to be validated (or rejected) in the test collections together with the percentage that these answers represent over the answers initially available. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>German</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Evaluation</head><p>In order to evaluate systems' performance, we used two groups of measures. In <ref type="bibr" coords="4,402.48,268.08,11.71,9.02" target="#b6">[7]</ref> was argued why the AVE evaluation is based on the detection of correct answers. Then, instead of using an overall accuracy, the first group of measures is composed by precision (1), recall (2) and F-measure (3) (harmonic mean) over answers that must be VALIDATED (in this first group, when a participant system returns SELECTED to an answer, the answer is considered as VALIDATED).</p><p>Results can be compared between systems but always taking as reference the following baselines:</p><p>1. A system that accepts all answers (returns VALIDATED or SELECTED in 100% of cases) 2. A system that accepts 50% of the answers (random)</p><formula xml:id="formula_0" coords="4,131.94,422.40,359.32,120.59">| _ _ _ _ | | _ _ _ _ det | VALIDATED or SELECTED as predicted VALIDATED or SELECTED as ected precision = (1) | _ | | _ _ _ _ det | answers CORRECT VALIDATED or SELECTED as ected recall = (2) precision recall precision recall F + = * * 2 (3)</formula><p>The aim of this group of measures is to evaluate the performance of an AV system used for ranking or filtering answers. Nevertheless, this is an intrinsic evaluation that is not enough for comparing AVE results with QA results in order to obtain some evidence about the goodness of incorporating more sophisticated validation systems into QA architectures. Our aim was to obtain evidences of this improvement in a comparative and shared evaluation.</p><p>Then, the second group of measures aims at comparing QA systems performance with the potential gain that AV systems could add to them. The first of these measures is qa_accuracy (4), which was already used in AVE 2007. Since answers were grouped by questions and AV systems were requested to SELECT one or none of them, the resulting behaviour is comparable to a QA system: for each question there is no more than one SELECTED answer. The proportion of correctly selected answers is a measure comparable to the accuracy used in the QA Main Track and, therefore, we can compare AV systems taking as reference the QA systems performance over the questions involved in AVE test collections.</p><p>This measure has an upper bound given by the proportion of questions that have at least one correct answer (in its corresponding group). This upper bound corresponds to a perfect selection of the correct answers given by all the QA systems at the main track. The normalization of qa_accuracy with this upper bound is given by %_best_combination <ref type="bibr" coords="5,157.90,84.72,10.61,9.02" target="#b4">(5)</ref>, where the percentage of the perfect selection is calculated.</p><p>Besides the upper bound, results of qa_accuracy can be compared with the following baseline system: a system that validates 100% of the answers and selects randomly one of them. Thus, this baseline can be seen as the average proportion of correct answers per question group. We called this baseline random_qa_accuracy <ref type="bibr" coords="5,510.46,119.22,10.61,9.02" target="#b5">(6)</ref>. Moreover, another baseline can be also taken into account. Since a good AV system should be able to yield the best QA system, we will consider the best QA system of each language as a baseline.</p><formula xml:id="formula_1" coords="5,105.84,171.24,385.42,128.80">| | | _ _ | _ questions correctly SELECTED answers accuracy qa = (4) 100 * | _ _ _ | | _ _ | _ _ % answers correct with questions correctly SELECTED answers n combinatio best = (5) ∑ ∈ = questions q q of answers q of answers correct questions accuracy qa random | ) ( _ | | ) ( _ _ | | | 1 _ _ (6)</formula><p>The problem of qa_accuracy is that it only acknowledges the ability of a system for selecting correct answers and not the ability of detecting that all the answers to a question are incorrect, so in this edition we wanted to acknowledge this ability. The justification of why to acknowledge the recognizing of questions without correct answers arises from the fact that a possible gain in performance could be obtained in these questions. In this situation, the AV system could ask to the QA systems for another answer to the question, opening the possibility of obtaining a correct answer to this question.</p><p>Therefore, we proposed the use of qa_rej_accuracy <ref type="bibr" coords="5,300.24,397.02,10.63,9.02" target="#b6">(7)</ref>, which acknowledges systems capable of detecting when all the answers to a question are incorrect. Then, with this measure and qa_accuracy, we can propose qa_accuracy_max <ref type="bibr" coords="5,146.89,421.02,10.64,9.02" target="#b7">(8)</ref>. This measure represents a range with a lower bound expressed by qa_accuracy and an upper bound that adds to qa_accuracy the accuracy that would be obtained answering correctly all the questions accounted in qa_rej_accuracy.</p><p>An estimation of the value obtained in this range is given by estimated_qa_performance (9). This measure considers that the questions accounted by qa_rej_accuracy are answered with the accuracy given by qa_accuracy. Therefore, this measure acknowledges a higher precision of AV systems detecting incorrect answers. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>Nine groups (the same number that in the last edition) have participated in five different languages (German, English, Spanish, French and Romanian) with 24 runs. Table <ref type="table" coords="6,322.45,109.68,5.01,9.02" target="#tab_5">3</ref> shows the participant groups and the number of runs they submitted per language. Again, English and Spanish were the most popular with 8 and 6 runs respectively.</p><p>Tables 5-9 in the appendix show the results of Precision, Recall and F measure over correct answers for all participant systems in each language. Results cannot be compared between languages since the number of answers to be validated and the proportion of the correct ones are different for each language (due to the real submission of QA systems). However, they can be compared in each language with two baselines values that are given: the results of a system that always accepts all answers (validates 100% of the answers), and the results of a hypothetical system that validates the 50% of answers. In our opinion, F-measure is an appropriate measure to identify the systems that perform better, measuring their ability to detect the correct answers and only them. However, it is also important to try to obtain some evidences about the improvement that AV systems could provide to QA systems. Tables 10-14 in the appendix show the rankings of systems (merging QA and AV systems) according to estimated_qa_performance calculated only over the subset of questions considered in AVE 2008. The tables contain also the information about the results of QA and AVE systems using the measures qa_accuracy, %_best_combination, qa_rej_accuracy and qa_accuracy_max. The values of qa_accuracy and estimated_qa_performance are the same in QA systems. Again, results cannot be compared between different languages, but they can be compared with the random baselines and with the results of the best QA system (which is marked with a shadow).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>German</head><p>The graphic interpretations of these tables are shown in Figures <ref type="figure" coords="6,352.21,553.68,4.44,9.02">3</ref><ref type="figure" coords="6,356.65,553.68,4.44,9.02">4</ref><ref type="figure" coords="6,356.65,553.68,4.44,9.02">5</ref><ref type="figure" coords="6,356.65,553.68,4.44,9.02">6</ref><ref type="figure" coords="6,361.09,553.68,4.44,9.02" target="#fig_0">7</ref>in the appendix. In these graphics the value of qa_accuracy is 1 in the perfect selection baseline. This corresponds to a perfect selection of a correct answer (if any) per question and the detection of all the questions with no correct answers (qa_rej_accuracy). However, the value of estimated_qa_performance in this baseline is not 1 because it is assumed that the questions detected in qa_rej_accuracy will be answered with a precision value equal to the qa_accuracy of the perfect selection baseline. This value represents the accuracy of the best combination of the QA systems involved, which is not perfect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Analysis of results</head><p>In three languages (German, English and Romanian) there has been at least one AV system performing better than the best QA system. In the languages where the best value of qa_accuracy was not obtained by an AV system, the best QA system outperforms in more than a 50% the following QA systems. If we see an AV system as a multi-stream selector of candidate answers, then AV systems follow a behaviour similar to an ensemble of classifiers. In Machine Learning (ML), an ensemble of classifiers is likely to be more accurate than an individual classifier except in the case of an element of the assemble outperforms in a high percent the rest of the classifiers <ref type="bibr" coords="7,70.92,73.68,10.64,9.02" target="#b0">[1]</ref>. Therefore, it seems obvious that there must be more work focused in performing a better selection in this kind of situations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Analysis of the measures</head><p>Regarding the use of the new measure estimated_qa_performance, the rankings are very similar to the ones obtained ranking by qa_accuracy. In fact, there have been only two changes, which are located in the English ranking (see Table <ref type="table" coords="7,155.43,159.48,9.99,9.02" target="#tab_15">13</ref> in the appendix). Firstly, the system uaic_2 obtains a better performance than ofe according to qa_accuracy (0.24 against 0.19). However, according to estimated_qa_performance, ofe is better than uaic_2 (0.27 against 0.24). This means that uaic_2 is better selecting correct answers. Nevertheless, if we consider the possible gain in performance that might be obtained detecting that all the answers to a question are incorrect and asking for new ones to the QA systems, then ofe is better. Therefore, the system ofe may help to obtain better results in QA than the system uaic_2. Besides, it can be seen how the ranking according to estimated_qa_performance is more similar to the one given by F-measure, which in some way, also considers the precision of a system detecting incorrect answers.</p><p>The second change in the rankings involves the QA system dfki081deen, which has a better performance than the AVE system jota_2 according to qa_accuracy. However, according to estimated_qa_performance, the two systems have the same performance. Again, this indicates that AV systems detecting incorrect answers could lead to a better performance in QA.</p><p>Thus, it seams that estimated_qa_performance is a better measure for AV systems than qa_accuracy because it takes into account the ability of a system rejecting incorrect answers. Thus, it is given a better estimation of the performance obtained by using AV systems in QA. Furthermore, the rankings are more similar to the ones obtained by using F-measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Analysis of the techniques used</head><p>All the participants have reported the use of textual entailment in their systems except two groups (LINA and LIMSI). However, while in the past edition the half of the participants reported the use of automatic hypothesis generation, in this edition only two participants (U. Iasi and U. Alicante) have used it. 6 of the 9 groups (FUH, U. Iasi, INAOE, DFKI, U. Alicante and LIMSI) have also participated in the QA main track, showing that there is a growing interest in using AV in QA participant systems at CLEF.</p><p>Table <ref type="table" coords="7,111.03,449.28,5.01,9.02">4</ref> shows the techniques used by AVE participant systems. Following the tendency showed in the past edition, all the systems have reported the use of lexical processing. Moreover, this year there are more groups using syntactic processing, mainly chunking or dependency analysis. Except in Spanish, where none system reported the use of syntactic processing, the system with the best result in each language performed some kind of syntactic processing, mainly by means of dependency parsing. However, the use of semantic analysis has decreased while the use of WordNet has been increased (50% of participants used it). Furthermore, there has been a high increase in the use of Named Entities, with 7 of 9 groups considering them. Therefore, it seems that it can be an important information to be taken into account in AV.</p><p>All the participants except two systems (U. Iasi and LINA) have used ML for taking the validation decision, following the tendency of the last edition. Besides, ML was used by the participants with the best score in each language. While lexical similarity was the most common feature used, syntactic similarity was included by the half of the participants. However, semantics features were taken into account by very few participants. Only one participant (FUH) reported the use of a theorem prover this year. Support vector machines (SVM) and decision trees were the most used classifiers. Nevertheless, there are not evidences about the best performance of one or another of these classifiers.</p><p>Finally, after a comparison between the resources taken into account and the results obtained, it seems that more resources do not imply better performance. In fact, systems performing semantic analysis have not achieved the best results in their languages.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Group</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="13,124.92,635.52,345.59,9.02;13,79.20,424.80,442.56,208.32"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Graphic comparing AV systems performance with QA systems in Romanian</figDesc><graphic coords="13,79.20,424.80,442.56,208.32" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="11,76.80,554.76,442.56,181.44"><head></head><label></label><figDesc></figDesc><graphic coords="11,76.80,554.76,442.56,181.44" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="11,76.32,72.24,443.04,200.76"><head></head><label></label><figDesc></figDesc><graphic coords="11,76.32,72.24,443.04,200.76" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="12,86.88,239.52,422.40,216.48"><head></head><label></label><figDesc></figDesc><graphic coords="12,86.88,239.52,422.40,216.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,94.32,426.19,406.68,114.14"><head>Answers (final) % over available answers</head><label></label><figDesc></figDesc><table coords="3,140.64,426.19,360.36,114.14"><row><cell></cell><cell></cell><cell>English</cell><cell>Spanish</cell><cell>French</cell><cell>Italian</cell><cell>Dutch</cell><cell>Portuguese</cell><cell>Romanian</cell></row><row><cell>Questions</cell><cell>108</cell><cell>67</cell><cell>169</cell><cell>118</cell><cell>100</cell><cell>78</cell><cell>148</cell><cell>82</cell></row><row><cell></cell><cell>264</cell><cell>195</cell><cell>551</cell><cell>171</cell><cell>100</cell><cell>196</cell><cell>346</cell><cell>103</cell></row><row><cell></cell><cell>45.52%</cell><cell>58.21%</cell><cell>64.82%</cell><cell>68.95%</cell><cell>86.21%</cell><cell>50.26%</cell><cell>28.83%</cell><cell>42.21%</cell></row><row><cell>VALIDATED</cell><cell>67</cell><cell>21</cell><cell>127</cell><cell>85</cell><cell>16</cell><cell>31</cell><cell>148</cell><cell>45</cell></row><row><cell>REJECTED</cell><cell>197</cell><cell>174</cell><cell>424</cell><cell>86</cell><cell>84</cell><cell>165</cell><cell>198</cell><cell>58</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,127.08,544.44,341.28,9.02"><head>Table 1 .</head><label>1</label><figDesc>Number of questions and answers in the AVE 2008 development collections</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,75.06,80.59,445.20,136.92"><head>Table 2 .</head><label>2</label><figDesc>Number of questions and answers in the AVE 2008 test collections</figDesc><table coords="4,75.06,80.59,445.20,124.40"><row><cell></cell><cell></cell><cell>English</cell><cell>Spanish</cell><cell>French</cell><cell>Bulgarian</cell><cell>Dutch</cell><cell>Portuguese</cell><cell>Romanian</cell><cell>Basque</cell></row><row><cell>Questions</cell><cell>119</cell><cell>160</cell><cell>136</cell><cell>108</cell><cell>27</cell><cell>128</cell><cell>149</cell><cell>119</cell><cell>104</cell></row><row><cell>Answers (final)</cell><cell>1027</cell><cell>1055</cell><cell>1528</cell><cell>199</cell><cell>27</cell><cell>228</cell><cell>1014</cell><cell>497</cell><cell>541</cell></row><row><cell>% over available answers</cell><cell>39.61%</cell><cell>57.37%</cell><cell>49.98%</cell><cell>60.30%</cell><cell>21.43%</cell><cell>42.54%</cell><cell>43.63%</cell><cell>48.58%</cell><cell>55.09%</cell></row><row><cell>VALIDATED</cell><cell>111</cell><cell>79</cell><cell>153</cell><cell>52</cell><cell>12</cell><cell>44</cell><cell>208</cell><cell>52</cell><cell>39</cell></row><row><cell>REJECTED</cell><cell>854</cell><cell>940</cell><cell>1354</cell><cell>126</cell><cell>9</cell><cell>177</cell><cell>747</cell><cell>406</cell><cell>483</cell></row><row><cell>UNKNOWN</cell><cell>62</cell><cell>36</cell><cell>21</cell><cell>21</cell><cell>6</cell><cell>7</cell><cell>59</cell><cell>39</cell><cell>19</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,136.62,242.42,311.60,176.82"><head>Table 3 .</head><label>3</label><figDesc>Participants and runs per language in AVE 2008</figDesc><table coords="6,136.62,242.42,311.60,164.52"><row><cell></cell><cell></cell><cell>English</cell><cell>Spanish</cell><cell>French</cell><cell>Romanian</cell><cell>Total</cell></row><row><cell>Fernuniversität in Hagen (FUH)</cell><cell>2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>2</cell></row><row><cell>LIMSI</cell><cell></cell><cell></cell><cell></cell><cell>2</cell><cell></cell><cell>2</cell></row><row><cell>U. Iasi</cell><cell></cell><cell>2</cell><cell></cell><cell></cell><cell>2</cell><cell>4</cell></row><row><cell>DFKI</cell><cell>1</cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell>2</cell></row><row><cell>INAOE</cell><cell></cell><cell></cell><cell>2</cell><cell></cell><cell></cell><cell>2</cell></row><row><cell>U. Alicante</cell><cell></cell><cell>1</cell><cell>2</cell><cell></cell><cell></cell><cell>3</cell></row><row><cell>UNC</cell><cell></cell><cell>2</cell><cell></cell><cell></cell><cell></cell><cell>2</cell></row><row><cell>U. Jaén (UJA)</cell><cell></cell><cell>2</cell><cell>2</cell><cell>2</cell><cell></cell><cell>6</cell></row><row><cell>LINA</cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell></cell><cell>1</cell></row><row><cell>Total</cell><cell>3</cell><cell>8</cell><cell>6</cell><cell>5</cell><cell>2</cell><cell>24</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="9,83.40,469.86,405.64,201.38"><head>Table 5 .</head><label>5</label><figDesc>Precision, Recall and F measure over correct answers for German</figDesc><table coords="9,83.40,469.86,405.64,201.38"><row><cell></cell><cell>System</cell><cell>F</cell><cell>Precision</cell><cell>Recall</cell></row><row><cell>DFKI</cell><cell>ltqa</cell><cell>0,61</cell><cell>0,54</cell><cell>0,71</cell></row><row><cell>FUH</cell><cell>glockner_1</cell><cell>0,39</cell><cell>0,33</cell><cell>0,49</cell></row><row><cell>FUH</cell><cell>glockner_2</cell><cell>0,29</cell><cell>0,25</cell><cell>0,34</cell></row><row><cell></cell><cell>100% VALIDATED</cell><cell>0,21</cell><cell>0,12</cell><cell>1</cell></row><row><cell></cell><cell>50% VALIDATED</cell><cell>0,19</cell><cell>0,12</cell><cell>0,5</cell></row><row><cell>Group</cell><cell>System</cell><cell>F</cell><cell>Precision</cell><cell>Recall</cell></row><row><cell>UA</cell><cell>ofe_2</cell><cell>0,44</cell><cell>0,32</cell><cell>0,67</cell></row><row><cell>INAOE</cell><cell>tellez_2</cell><cell>0,39</cell><cell>0,30</cell><cell>0,59</cell></row><row><cell>UA</cell><cell>ofe_1</cell><cell>0,38</cell><cell>0,26</cell><cell>0,76</cell></row><row><cell>INAOE</cell><cell>tellez_1</cell><cell>0,23</cell><cell>0,13</cell><cell>0,86</cell></row><row><cell></cell><cell>100% VALIDATED</cell><cell>0,18</cell><cell>0,10</cell><cell>1</cell></row><row><cell></cell><cell>50% VALIDATED</cell><cell>0,17</cell><cell>0,10</cell><cell>0,5</cell></row><row><cell>UJA</cell><cell>magc_1(timbl)</cell><cell>0,06</cell><cell>0,15</cell><cell>0,04</cell></row><row><cell>UJA</cell><cell>magc_2(bbr)</cell><cell>0,05</cell><cell>0,22</cell><cell>0,03</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="9,166.68,674.64,297.44,9.02"><head>Table 6 .</head><label>6</label><figDesc>Precision, Recall and F measure over correct answers for Spanish</figDesc><table coords="10,83.40,73.86,405.64,92.90"><row><cell>Group</cell><cell>System</cell><cell>F</cell><cell>Precision</cell><cell>Recall</cell></row><row><cell>LIMSI</cell><cell>bgrau_1</cell><cell>0,61</cell><cell>0,75</cell><cell>0,52</cell></row><row><cell>LIMSI</cell><cell>bgrau_2</cell><cell>0,57</cell><cell>0,88</cell><cell>0,42</cell></row><row><cell>LINA</cell><cell>monceaux</cell><cell>0,51</cell><cell>0,56</cell><cell>0,46</cell></row><row><cell></cell><cell>100% VALIDATED</cell><cell>0,45</cell><cell>0,29</cell><cell>1</cell></row><row><cell></cell><cell>50% VALIDATED</cell><cell>0,37</cell><cell>0,29</cell><cell>0,5</cell></row><row><cell>UJA</cell><cell>magc_1(timbl)</cell><cell>0,08</cell><cell>0,15</cell><cell>0,06</cell></row><row><cell>UJA</cell><cell>magc_2(bbr)</cell><cell>0,08</cell><cell>0,13</cell><cell>0,06</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="10,83.88,170.16,413.98,153.08"><head>Table 7 .</head><label>7</label><figDesc>Precision, Recall and F measure over correct answers for French</figDesc><table coords="10,83.88,194.34,413.98,128.90"><row><cell>Group</cell><cell>System</cell><cell>F</cell><cell>Precision</cell><cell>Recall</cell></row><row><cell>DFKI</cell><cell>ltqa</cell><cell>0,64</cell><cell>0,54</cell><cell>0,78</cell></row><row><cell>UA</cell><cell>ofe</cell><cell>0,49</cell><cell>0,35</cell><cell>0,86</cell></row><row><cell>UNC</cell><cell>jota_2</cell><cell>0,21</cell><cell>0,13</cell><cell>0,56</cell></row><row><cell>Iasi</cell><cell>uaic_2</cell><cell>0,19</cell><cell>0,11</cell><cell>0,85</cell></row><row><cell>UNC</cell><cell>jota_1</cell><cell>0,17</cell><cell>0,09</cell><cell>0,94</cell></row><row><cell>Iasi</cell><cell>uaic_1</cell><cell>0,17</cell><cell>0,09</cell><cell>0,76</cell></row><row><cell></cell><cell>100% VALIDATED</cell><cell>0,14</cell><cell>0,08</cell><cell>1</cell></row><row><cell></cell><cell>50% VALIDATED</cell><cell>0,13</cell><cell>0,08</cell><cell>0,5</cell></row><row><cell>UJA</cell><cell>magc_2(bbr)</cell><cell>0,02</cell><cell>0,17</cell><cell>0,01</cell></row><row><cell>UJA</cell><cell>magc_1(timbl)</cell><cell>0</cell><cell>0</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="10,84.42,326.22,412.96,81.02"><head>Table 8 .</head><label>8</label><figDesc>Precision, Recall and F measure over correct answers for English.</figDesc><table coords="10,84.42,350.34,412.96,56.90"><row><cell>Group</cell><cell>System</cell><cell>F</cell><cell>Precision</cell><cell>Recall</cell></row><row><cell>Iasi</cell><cell>uaic_2</cell><cell>0,23</cell><cell>0,13</cell><cell>0,92</cell></row><row><cell>Iasi</cell><cell>uaic_1</cell><cell>0,22</cell><cell>0,12</cell><cell>0,92</cell></row><row><cell></cell><cell>100% VALIDATED</cell><cell>0,20</cell><cell>0,11</cell><cell>1</cell></row><row><cell></cell><cell>50% VALIDATED</cell><cell>0,19</cell><cell>0,11</cell><cell>0,50</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="10,70.92,410.22,453.52,286.52"><head>Table 9 .</head><label>9</label><figDesc>Precision, Recall and F measure over correct answers for Romanian.The following tables and graphics show the comparison of AV systems performance with QA systems of AVE participant systems in different languages.</figDesc><table coords="10,77.52,482.64,440.24,214.10"><row><cell>System</cell><cell>System</cell><cell>estimated_</cell><cell>qa_accuracy (%</cell><cell>qa_rej_</cell><cell>qa_</cell></row><row><cell></cell><cell>type</cell><cell>qa_performance</cell><cell>best combination)</cell><cell>accuracy</cell><cell>accuracy_max</cell></row><row><cell cols="2">Perfect selection</cell><cell>0,77</cell><cell>0,52 (100%)</cell><cell>0,48</cell><cell>1</cell></row><row><cell>ltqa</cell><cell>AV</cell><cell>0,52</cell><cell>0,43 (82,26%)</cell><cell>0,21</cell><cell>0,64</cell></row><row><cell>dfki082dede</cell><cell>QA</cell><cell>0,38</cell><cell>0,38 (72,58%)</cell><cell>0</cell><cell>0,38</cell></row><row><cell>dfki081dede</cell><cell>QA</cell><cell>0,37</cell><cell>0,37 (70,97%)</cell><cell>0</cell><cell>0,37</cell></row><row><cell>glockner_1</cell><cell>AV</cell><cell>0,32</cell><cell>0,32 (61,29%)</cell><cell>0</cell><cell>0,32</cell></row><row><cell>fuha082dede</cell><cell>QA</cell><cell>0,24</cell><cell>0,24 (45,16%)</cell><cell>0</cell><cell>0,24</cell></row><row><cell>glockner_2</cell><cell>AV</cell><cell>0,23</cell><cell>0,23 (43,55%)</cell><cell>0</cell><cell>0,23</cell></row><row><cell>fuha081dede</cell><cell>QA</cell><cell>0,22</cell><cell>0,22 (41,94%)</cell><cell>0</cell><cell>0,22</cell></row><row><cell>loga081dede</cell><cell>QA</cell><cell>0,17</cell><cell>0,17 (32,26%)</cell><cell>0</cell><cell>0,17</cell></row><row><cell>fuha082ende</cell><cell>QA</cell><cell>0,16</cell><cell>0,16 (30,65%)</cell><cell>0</cell><cell>0,16</cell></row><row><cell>fuha081ende</cell><cell>QA</cell><cell>0,16</cell><cell>0,16 (30,65%)</cell><cell>0</cell><cell>0,16</cell></row><row><cell>loga082dede</cell><cell>QA</cell><cell>0,15</cell><cell>0,15 (29,03%)</cell><cell>0</cell><cell>0,15</cell></row><row><cell>dfki081ende</cell><cell>QA</cell><cell>0,14</cell><cell>0,14 (27,42%)</cell><cell>0</cell><cell>0,14</cell></row><row><cell>fuha081esde</cell><cell>QA</cell><cell>0,12</cell><cell>0,12 (22,58%)</cell><cell>0</cell><cell>0,12</cell></row><row><cell>Random</cell><cell></cell><cell>0.11</cell><cell>0.11 (21.13%)</cell><cell>0</cell><cell>0.11</cell></row><row><cell>fuha082esde</cell><cell>QA</cell><cell>0,10</cell><cell>0,10 (19,35%)</cell><cell>0</cell><cell>0,10</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" coords="10,162.54,700.14,305.74,9.02"><head>Table 10 .</head><label>10</label><figDesc>Comparing AV systems performance with QA systems in German Figure3. Graphic comparing AV systems performance with QA systems in German</figDesc><table coords="11,79.14,300.18,437.00,237.62"><row><cell>System</cell><cell>System</cell><cell>estimated_</cell><cell>qa_accuracy (%</cell><cell>qa_rej_</cell><cell>qa_</cell></row><row><cell></cell><cell>type</cell><cell>qa_performance</cell><cell>best combination)</cell><cell>accuracy</cell><cell>accuracy_max</cell></row><row><cell cols="2">Perfect selection</cell><cell>0,85</cell><cell>0,62 (100%)</cell><cell>0,38</cell><cell>1</cell></row><row><cell>prib081eses</cell><cell>QA</cell><cell>0,54</cell><cell>0,54 (88,10%)</cell><cell>0</cell><cell>0,54</cell></row><row><cell>ofe_1</cell><cell>AV</cell><cell>0,37</cell><cell>0,32 (52,38%)</cell><cell>0,14</cell><cell>0,46</cell></row><row><cell>tellez_1</cell><cell>AV</cell><cell>0,34</cell><cell>0,32 (52,38%)</cell><cell>0,06</cell><cell>0,38</cell></row><row><cell>ofe_2</cell><cell>AV</cell><cell>0,33</cell><cell>0,27 (44,05%)</cell><cell>0,21</cell><cell>0,48</cell></row><row><cell>tellez_2</cell><cell>AV</cell><cell>0,33</cell><cell>0,27 (44,05%)</cell><cell>0,22</cell><cell>0,49</cell></row><row><cell>inao081eses</cell><cell>QA</cell><cell>0,25</cell><cell>0,25 (40,48%)</cell><cell>0</cell><cell>0,25</cell></row><row><cell>inao082eses</cell><cell>QA</cell><cell>0,25</cell><cell>0,25 (40,48%)</cell><cell>0</cell><cell>0,25</cell></row><row><cell>qaua082eses</cell><cell>QA</cell><cell>0,22</cell><cell>0,22 (35,71%)</cell><cell>0</cell><cell>0,22</cell></row><row><cell>mira081eses</cell><cell>QA</cell><cell>0,21</cell><cell>0,21 (33,33%)</cell><cell>0</cell><cell>0,21</cell></row><row><cell>mira082eses</cell><cell>QA</cell><cell>0,18</cell><cell>0,18 (29,76%)</cell><cell>0</cell><cell>0,18</cell></row><row><cell>qaua081enes</cell><cell>QA</cell><cell>0,18</cell><cell>0,18 (28,57%)</cell><cell>0</cell><cell>0,18</cell></row><row><cell>qaua082enes</cell><cell>QA</cell><cell>0,13</cell><cell>0,13 (21,43%)</cell><cell>0</cell><cell>0,13</cell></row><row><cell>qaua081eses</cell><cell>QA</cell><cell>0,12</cell><cell>0,12 (19,05%)</cell><cell>0</cell><cell>0,12</cell></row><row><cell>Random</cell><cell></cell><cell>0,11</cell><cell>0,11 (17,12%)</cell><cell>0</cell><cell>0,11</cell></row><row><cell>mira081fres</cell><cell>QA</cell><cell>0,06</cell><cell>0,06 (9,52%)</cell><cell>0</cell><cell>0,06</cell></row><row><cell>magc_1(timbl)</cell><cell>AV</cell><cell>0,06</cell><cell>0,04 (7,14%)</cell><cell>0,32</cell><cell>0,36</cell></row><row><cell>magc_2(bbr)</cell><cell>AV</cell><cell>0,03</cell><cell>0,02 (3,57%)</cell><cell>0,35</cell><cell>0,37</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" coords="11,129.66,541.20,336.15,206.66"><head>Table 11 .</head><label>11</label><figDesc>Comparing AV systems performance with QA systems in Spanish Figure4. Graphic comparing AV systems performance with QA systems in Spanish</figDesc><table coords="12,83.82,74.16,427.64,141.62"><row><cell>System</cell><cell>System</cell><cell>estimated_</cell><cell>qa_accuracy</cell><cell>qa_rej_</cell><cell>qa_</cell></row><row><cell></cell><cell>type</cell><cell>qa_performance</cell><cell></cell><cell>accuracy</cell><cell>accuracy_max</cell></row><row><cell cols="2">Perfect selection</cell><cell>0,73</cell><cell>0,48 (100%)</cell><cell>0,52</cell><cell>1</cell></row><row><cell>syna081frfr</cell><cell>QA</cell><cell>0,47</cell><cell>0,47 (98,08%)</cell><cell>0</cell><cell>0,47</cell></row><row><cell>Random</cell><cell></cell><cell>0,33</cell><cell>0,33 (68,80%)</cell><cell>0</cell><cell>0,33</cell></row><row><cell>bgrau_1</cell><cell>AV</cell><cell>0,32</cell><cell>0,23 (48,08%)</cell><cell>0,39</cell><cell>0,62</cell></row><row><cell>monceaux</cell><cell>AV</cell><cell>0,29</cell><cell>0,21 (44,23%)</cell><cell>0,35</cell><cell>0,56</cell></row><row><cell>bgrau_2</cell><cell>AV</cell><cell>0,29</cell><cell>0,19 (40,38%)</cell><cell>0,48</cell><cell>0,67</cell></row><row><cell>syna081ptfr</cell><cell>QA</cell><cell>0,19</cell><cell>0,19 (40,38%)</cell><cell>0</cell><cell>0,19</cell></row><row><cell>syna081enfr</cell><cell>QA</cell><cell>0,17</cell><cell>0,17 (34,62%)</cell><cell>0</cell><cell>0,17</cell></row><row><cell>magc_1(timbl)</cell><cell>AV</cell><cell>0,04</cell><cell>0,03 (5,77%)</cell><cell>0,41</cell><cell>0,44</cell></row><row><cell>magc_2(bbr)</cell><cell>AV</cell><cell>0,04</cell><cell>0,03 (5,77%)</cell><cell>0,41</cell><cell>0,44</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13" coords="12,130.32,218.76,334.68,248.90"><head>Table 12 .</head><label>12</label><figDesc>Comparing AV systems performance with QA systems in French Figure5. Graphic comparing AV systems performance with QA systems in French</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14" coords="12,84.24,483.12,426.86,225.62"><head>System System type estimated_ qa_performance qa_accuracy (% best combination) qa_rej_ accuracy qa_ accuracy_max</head><label></label><figDesc></figDesc><table coords="12,84.24,507.24,404.82,201.50"><row><cell cols="2">Perfect selection</cell><cell>0,56</cell><cell>0,34 (100%)</cell><cell>0,66</cell><cell>1</cell></row><row><cell>ltqa</cell><cell>AV</cell><cell>0,34</cell><cell>0,24 (70,37%)</cell><cell>0,44</cell><cell>0,68</cell></row><row><cell>ofe</cell><cell>AV</cell><cell>0,27</cell><cell>0,19 (57,41%)</cell><cell>0,4</cell><cell>0,59</cell></row><row><cell>uaic_2</cell><cell>AV</cell><cell>0,24</cell><cell>0,24 (70,37%)</cell><cell>0,01</cell><cell>0,25</cell></row><row><cell>wlvs081roen</cell><cell>QA</cell><cell>0,21</cell><cell>0,21 (62,96%)</cell><cell>0</cell><cell>0,21</cell></row><row><cell>uaic_1</cell><cell>AV</cell><cell>0,19</cell><cell>0,19 (57,41%)</cell><cell>0</cell><cell>0,19</cell></row><row><cell>jota_2</cell><cell>AV</cell><cell>0,17</cell><cell>0,16 (46,30%)</cell><cell>0,1</cell><cell>0,26</cell></row><row><cell>dfki081deen</cell><cell>QA</cell><cell>0,17</cell><cell>0,17 (50%)</cell><cell>0</cell><cell>0,17</cell></row><row><cell>jota_1</cell><cell>AV</cell><cell>0,16</cell><cell>0,16 (46,30%)</cell><cell>0</cell><cell>0,16</cell></row><row><cell>dcun081deen</cell><cell>QA</cell><cell>0,10</cell><cell>0,10 (29,63%)</cell><cell>0</cell><cell>0,10</cell></row><row><cell>Random</cell><cell></cell><cell>0,09</cell><cell>0,09 (25,25%)</cell><cell>0</cell><cell>0,09</cell></row><row><cell>nlel081enen</cell><cell>QA</cell><cell>0,06</cell><cell>0,06 (18,52%)</cell><cell>0</cell><cell>0,06</cell></row><row><cell>nlel082enen</cell><cell>QA</cell><cell>0,05</cell><cell>0,05 (14,81%)</cell><cell>0</cell><cell>0,05</cell></row><row><cell>ilkm081nlen</cell><cell>QA</cell><cell>0,04</cell><cell>0,04 (12,96%)</cell><cell>0</cell><cell>0,04</cell></row><row><cell>magc_2(bbr)</cell><cell>AV</cell><cell>0,01</cell><cell>0,01 (1,85%)</cell><cell>0,64</cell><cell>0,65</cell></row><row><cell>dcun082deen</cell><cell>QA</cell><cell>0,01</cell><cell>0,01 (1,85%)</cell><cell>0</cell><cell>0,01</cell></row><row><cell>magc_1(timbl)</cell><cell>AV</cell><cell>0</cell><cell>0 (0%)</cell><cell>0,63</cell><cell>0,63</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15" coords="12,151.62,712.14,304.11,9.02"><head>Table 13 .</head><label>13</label><figDesc>Comparing AV systems performance with QA systems in English Figure6. Graphic comparing AV systems performance with QA systems in English</figDesc><table coords="13,80.22,285.72,434.84,117.56"><row><cell>System</cell><cell>System</cell><cell>estimated_</cell><cell>qa_accuracy (%</cell><cell>qa_rej_</cell><cell>qa_</cell></row><row><cell></cell><cell>type</cell><cell>qa_performance</cell><cell>best combination)</cell><cell>accuracy</cell><cell>accuracy_max</cell></row><row><cell cols="2">Perfect selection</cell><cell>0,65</cell><cell>0,41 (100%)</cell><cell>0,59</cell><cell>1</cell></row><row><cell>uaic_2</cell><cell>AV</cell><cell>0,25</cell><cell>0,24 (57,14%)</cell><cell>0,05</cell><cell>0,29</cell></row><row><cell>UAIC082roro</cell><cell>QA</cell><cell>0,22</cell><cell>0,22 (53,06%)</cell><cell>0</cell><cell>0,22</cell></row><row><cell>UAIC081roro</cell><cell>QA</cell><cell>0,19</cell><cell>0,19 (46,94%)</cell><cell>0</cell><cell>0,19</cell></row><row><cell>uaic_1</cell><cell>AV</cell><cell>0,17</cell><cell>0,17 (40,82%)</cell><cell>0</cell><cell>0,17</cell></row><row><cell>icia082roro</cell><cell>QA</cell><cell>0,17</cell><cell>0,17 (40,82%)</cell><cell>0</cell><cell>0,17</cell></row><row><cell>Random</cell><cell></cell><cell>0,10</cell><cell>0,10 (24,66%)</cell><cell>0</cell><cell>0,10</cell></row><row><cell>icia081roro</cell><cell>QA</cell><cell>0,08</cell><cell>0,08 (18,37%)</cell><cell>0</cell><cell>0,08</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16" coords="13,106.32,406.68,314.65,9.02"><head>Table 14 .</head><label>14</label><figDesc>Comparing AV systems performance with QA systems in Romanian</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work has been partially supported by the <rs type="funder">Spanish Ministry of Science and Innovation</rs> within the project <rs type="projectName">QEAVis-Catiex</rs> (<rs type="grantNumber">TIN2007-67581-C02-01</rs>), the <rs type="funder">Education Council of the Regional Government of Madrid</rs> and the <rs type="funder">European Social Fund</rs>. We are grateful to all the people involved in the organization of the QA track (specially to the coordinators at CELCT, <rs type="person">Danilo Giampiccolo</rs> and <rs type="person">Pamela Forner</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_P9EAxHk">
					<idno type="grant-number">TIN2007-67581-C02-01</idno>
					<orgName type="project" subtype="full">QEAVis-Catiex</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>U. Iasi</head><p>Coreference resolution Dependency analysis X X X</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Syntactic similarity</head><p>Functions (sub, obj, etc) X X X</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Syntactic transformations</head><p>Semantic role labeling X First order logic representation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>X X</head><p>Theorem prover X Semantic similarity Table <ref type="table" coords="8,195.45,437.34,3.76,9.02">4</ref>. Information about the techniques used by the AVE participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>In AVE 2008 there has been the same number of participants of last year (9) in 5 different languages. However, 8 more runs have been sent, showing a growing interest in the task.</p><p>Results show that AV systems could improve the performance of current QA systems. This improvement comes when AV systems are used for selecting the final answer from a set of candidate ones. In fact, according to the results, except in the languages where the best QA system outperforms the others QA systems in more than a 50%, there was an AV system with better performance than QA systems.</p><p>In this edition new measures have been introduced in order to obtain a more informative estimation of the potential of AV systems in QA performance. These new measures reward the ability of some systems detecting if all the candidate answers to a question are incorrect. These measures have shown to be very useful when two systems have a similar performance according to qa_accuracy. In this situation, the new measure estimated_qa_performance have indicated that AV systems with a better precision detecting incorrect answers would be more useful in QA because more answers could be asked to QA systems when all the candidate answers to a question are incorrect. Then, a correct answer might be found.</p><p>The most used technique continues being lexical processing while the use of syntactic analysis has grown. Nevertheless, very few systems have performed semantic analysis. Besides, a high percent of participants have combined different features using ML. Finally, the best systems performed both lexical and syntactic analysis, and they consider NE.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><p>The following tables show the values of Precision, Recall and F measure over correct answers of AVE participant systems in different languages.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="9,74.69,181.68,448.23,9.02" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,145.06,181.68,202.67,9.02">Machine-learning research: Four current directions</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,354.02,181.68,50.38,9.02">AI Magazine</title>
		<imprint>
			<biblScope unit="page" from="97" to="136" />
			<date type="published" when="1997">1997</date>
			<pubPlace>Winter</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,74.69,193.68,449.87,9.02;9,88.92,205.68,85.31,9.02" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="9,178.01,193.68,278.01,9.02">Overview of the CLEF 2008 Multilingual Question Answering Track</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Giampiccolo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
	<note>Working Notes of CLEF</note>
</biblStruct>

<biblStruct coords="9,74.69,217.68,449.76,9.02;9,88.92,229.68,435.56,9.02;9,88.92,241.68,315.24,9.02" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,203.48,229.68,288.18,9.02">Overview of the CLEF 2007 Multilingual Question Answering Track</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Giampiccolo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Forner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Ayache</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cristea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Jijkoun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Osenova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rocha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Sacaleanu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sutcliffe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,499.99,229.68,24.50,9.02;9,88.92,241.68,18.02,9.02">CLEF 2007</title>
		<title level="s" coord="9,113.93,241.68,170.83,9.02">Lecture Notes in Computer Science LNCS</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">5152</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,74.69,253.68,449.82,9.02;9,88.92,265.68,435.58,9.02;9,88.92,277.68,160.90,9.02" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,190.41,253.68,317.42,9.02">Methods for Using Textual Entailment in Open-Domain Question Answering</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hickl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,88.92,265.68,435.58,9.02;9,88.92,277.68,31.65,9.02">Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL</title>
		<meeting>the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL<address><addrLine>Sydney</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="905" to="912" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,74.69,289.68,449.83,9.02;9,88.92,301.68,435.52,9.02;9,88.92,313.68,315.24,9.02" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,207.08,301.68,284.99,9.02">Overview of the CLEF 2006 Multilingual Question Answering Track</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Giampiccolo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Forner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Ayache</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Jijkoun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Osenova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rocha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Sacaleanu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sutcliffe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,499.95,301.68,24.48,9.02;9,88.92,313.68,18.02,9.02">CLEF 2006</title>
		<title level="s" coord="9,113.93,313.68,170.83,9.02">Lecture Notes in Computer Science LNCS</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">4730</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,74.69,325.68,449.86,9.02;9,88.92,337.68,290.19,9.02" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,266.99,325.68,180.47,9.02">Overview of the Answer Validation Exercise</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Á</forename><surname>Rodrigo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Verdejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,475.05,325.68,45.00,9.02">CLEF 2006</title>
		<title level="s" coord="9,88.92,337.68,170.83,9.02">Lecture Notes in Computer Science LNCS</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006. 2007</date>
			<biblScope unit="volume">4730</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,74.69,349.68,449.77,9.02;9,88.92,361.68,162.81,9.02" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,279.19,349.68,241.21,9.02">Testing the Reasoning for Question Answering Validation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Á</forename><surname>Rodrigo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Sama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Verdejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,88.92,361.68,137.76,9.02">Journal of Logic and Computation</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,74.69,373.68,449.87,9.02;9,88.92,385.68,257.17,9.02" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,230.03,373.68,182.65,9.02">Overview of the Answer Validation Exercise</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Á</forename><surname>Rodrigo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Verdejo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,441.01,373.68,45.46,9.02">CLEF 2007</title>
		<title level="s" coord="9,493.92,373.68,30.64,9.02;9,88.92,385.68,137.72,9.02">Lecture Notes in Computer Science LNCS</title>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007. 2008</date>
			<biblScope unit="volume">5152</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
