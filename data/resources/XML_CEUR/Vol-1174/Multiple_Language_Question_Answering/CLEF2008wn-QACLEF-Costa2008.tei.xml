<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,94.68,74.83,417.24,12.19;1,252.54,90.91,90.26,12.19">Esfinge at CLEF 2008: Experimenting with answer retrieval patterns. Can they help?</title>
				<funder ref="#_FXeyJcM">
					<orgName type="full">Portuguese Government</orgName>
				</funder>
				<funder ref="#_xQDnHSA">
					<orgName type="full">European Union (FEDER and FSE)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,281.82,144.81,43.09,8.74"><forename type="first">Costa</forename><surname>Luís</surname></persName>
							<email>luis.costa@sintef.no</email>
							<affiliation key="aff0">
								<orgName type="institution">SINTEF ICT</orgName>
								<address>
									<country key="NO">NORWAY</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,227.34,167.31,42.71,8.74"><surname>Linguateca</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">SINTEF ICT</orgName>
								<address>
									<country key="NO">NORWAY</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,94.68,74.83,417.24,12.19;1,252.54,90.91,90.26,12.19">Esfinge at CLEF 2008: Experimenting with answer retrieval patterns. Can they help?</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CB2632CCFB5CCEB450517D5501C74372</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Management]: Languages-Query Languages Measurement, Performance, Experimentation Question answering, named-entity recognition, anaphoric reference, Portuguese</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Esfinge is a general domain Portuguese question answering system which has been participating at QA@CLEF since 2004. It uses the information available in the "official" document collections used in QA@CLEF (newspaper text and Wikipedia), but additionally it also uses information from the Web as an additional resource when searching for answers. Where it regards the use of external tools, Esfinge uses a syntactic analyzer, a morphological analyzer and a named entity recognizer. This year an alternative approach to retrieve answers was tested: whereas in previous years, search patterns were used to retrieve relevant documents, this year a new type of search patterns was also used to extract the answers themselves. Besides that we took advantage of the main novelty introduced this year by QA@CLEF organization which was that the systems could return up to three answers for each question, instead of the single answer allowed in previous editions. This enabled the investigation about how good were the second and third best answers returned by Esfinge (when the first answer is not correct). The experiments revealed that the answer retrieval patterns created for this participation improve the results, but only for definition questions. Regarding the study of the three answers returned by Esfinge, the conclusion was that when Esfinge answers correctly a question, it does so usually with its first answer.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The proposed task in this year at QA@CLEF was quite similar to the previous year. The main novelty was the systems could return up to three answers for each question. Besides taking advantage of that possibility, our participation focused in using an alternative approach to retrieve answers. In previous years, search patterns were used to retrieve relevant documents to particular questions. This year we also used search patterns to extract the answers themselves.</p><p>The following sections describe in detail the system architecture used this year, how the answer retrieval patterns were created and the results obtained in the official runs. There is a final section where the results are discussed and where directions for future work are indicated.</p><p>Esfinge has been participating at CLEF since 2004. These participations are described in detail in <ref type="bibr" coords="2,477.46,101.31,10.81,8.74" target="#b1">[2,</ref><ref type="bibr" coords="2,491.73,101.31,7.50,8.74" target="#b2">3,</ref><ref type="bibr" coords="2,502.63,101.31,7.55,8.74" target="#b3">4,</ref><ref type="bibr" coords="2,513.61,101.31,7.23,8.74" target="#b4">5]</ref>. Figure <ref type="figure" coords="2,99.54,112.83,5.01,8.74">1</ref> gives an overview of the system used this year:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1. Modules used in Esfinge</head><p>The Anaphor Resolution module is the first module in Esfinge. It adds to the original questions, a list of alternative questions where the anaphors are tentatively resolved. This module uses the analysis of the PALAVRAS parser <ref type="bibr" coords="2,153.34,390.51,11.69,8.74" target="#b0">[1]</ref> to identify the anaphoric element in a question and a list of candidates to replace it in the context of the other questions in the same topic.</p><p>For each of the alternative questions and until the requested number of answers is found:</p><p>The Question Reformulation Module transforms the question into patterns of text where it is plausible to find answers. This is done using two different approaches: a purely string matching technique and an alternative approach which uses the analysis of PALAVRAS.</p><p>Esfinge starts with the string matching technique. This technique uses patterns which have an associated score giving an indication about how likely the pattern will help to retrieve relevant text passages.</p><p>For example the question Quem foi Baden Powell de Aquino? matches with the patterns (simplified here for illustration purposes):</p><formula xml:id="formula_0" coords="2,70.92,558.39,152.12,20.26">Quem ([^\s?]*) ([^?]*)\??/"$2 $1"/10 Quem ([^?]*)\??/$1/1</formula><p>Which in turn generate the following (Text pattern/Score) pairs: "Baden Powell de Aquino foi"/10 foi Baden Powell de Aquino/1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Searching and supporting answers</head><p>Text patterns are then searched in the document collections (newspapers and Portuguese Wikipedia) using the Search Document Collections module in order to find text passages that are relevant to the question. These patterns are also searched in the Web using Yahoo's search API.</p><p>Then, all the relevant texts retrieved are analyzed in order to obtain candidate answers. Three techniques are used for that purpose: extraction of answers using the answer retrieval patterns created for this year's participation, the named entity recognizer (NER) system SIEMÊS <ref type="bibr" coords="2,338.98,745.47,11.70,8.74" target="#b5">[6]</ref> and an n-grams computing module. Figure <ref type="figure" coords="3,70.92,73.53,5.01,8.74">2</ref> illustrates how these techniques are used: namely each of them is used in sequence until Esfinge finds the required number of answers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2. Answer retrieval techniques</head><p>Esfinge begins by extracting answers using answer retrieval patterns. These patterns associate questions with their respective answers. They are different from the patterns used to retrieve relevant documents because they include the position where the answers should appear.</p><p>The following pattern is a simplified example of the patterns used by Esfinge. The patterns that are actually used are a bit more general in the sense that they can for example cater for some alternative verb tenses (é, são, eram) and alternative articles (a, o, as, os, um, uma):</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>O que é a __X__? __X__ (__ANSWER__)</head><p>This means that the answer to a question like O que é a __X__? can be retrieved inside parenthesis following the string __X__.</p><p>First, Esfinge checks which patterns match with the question (left hand side of the rule). The pattern in the right hand side of the rule is then checked against the relevant documents to the question with the purpose of finding candidate answers.</p><p>The candidate answers are then ranked according to their frequency, length and the score of the passage from where they were retrieved using the formula:</p><p>Candidate answer score = ∑ (F * S * L), through the passages retrieved in the previous modules where: F = Candidate answer frequency S = Score of the passage L = Candidate answer length <ref type="foot" coords="3,204.48,566.17,3.24,5.65" target="#foot_0">1</ref>At this stage Esfinge has a list of candidate answers {A 1 , A 2 … A n }. These candidate answers are then tested using the following filters:</p><p>• A filter that excludes answers contained in the questions. For example, the answer partido (party) is not a good answer to the question A que partido pertence Zapatero? (To which party does Zapatero belong?).</p><p>• A filter that excludes answers contained in a list of undesired answers (very frequent words that usually can not answer questions). This list includes words like parte (part), antigo (old), pessoas (people), mais (more) and was created based on experiments performed with the system. At present, it contains 96 entries.</p><p>An answer that passes all the filters proceeds to the next module which checks whether there are documents in the collections which support the answer.</p><p>If Esfinge does not find the requested number of answers using the answer retrieval patterns, it tries to get more answers using the named entity recognizer (NER) system SIEMÊS <ref type="bibr" coords="4,387.17,108.03,10.63,8.74" target="#b5">[6]</ref>. This system is used for the questions which imply specific types of answers like Place, People, Quantity, Date, Height, Duration, Area, Organization or Distance. Esfinge uses pattern matching to check whether it is possible to infer the type of answer for a given question. For example, questions starting with Onde (Where) imply an answer of type Place, questions starting with Quando (When) imply an answer of type Date, questions starting with Quantos (How Many) imply an answer of type Quantity. For these questions, SIEMÊS tags the relevant text passages in order to count the number of occurrences of named entities belonging to the expected categories. The identified named entities are then ranked, filtrated and checked for the existence of documents which can support them in a similar manner as described previously for the answers obtained using answer retrieval patterns.</p><p>In case the previous efforts still do not yield the necessary number of answers, Esfinge uses its last answer retrieval technique which consists in using an n-grams module. The n-grams computed through this module are also ranked, filtrated and checked for the existence of documents which can support them in a similar manner as described previously for the other two techniques. The answers obtained through n-gram harvesting, however, are submitted to an additional filter that uses the morphological analyzer jspell <ref type="bibr" coords="4,389.58,257.49,11.69,8.74" target="#b7">[7]</ref> to check the PoS of the words contained in the answer. Jspell returns a list of tags for each of the words. Esfinge rejects all answers in which the first and last word are not tagged as one of the following categories: adjectives (adj), common nouns (nc), numbers (card) and proper nouns (np).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Alternative techniques used to find relevant texts</head><p>If at this point of execution, Esfinge did not retrieve the required number of answers, the next step will be to select a new set of relevant texts (this time patterns based on the analysis of the question by PALAVRAS <ref type="bibr" coords="4,507.11,359.49,10.51,8.74" target="#b0">[1]</ref>). These patterns are created using the main verb of the question, its arguments and adjuncts and entities from previous questions belonging to the same topic. From this stage, Esfinge repeats the steps described in subsection 2.1.</p><p>In case the last step did not yield the required number of answers either, a last attempt is tried which consists in selecting relevant texts using again the patterns based on the analysis of the question by PALAVRAS, but excluding the verbs included in these patterns.</p><p>Figure <ref type="figure" coords="4,110.89,440.01,5.01,8.74" target="#fig_0">3</ref> gives an overview about the three techniques used by Esfinge to select relevant texts. The hypothesis we wanted to test this year was whether it would be possible to extract useful answer retrieval patterns from the solutions available from the previous edition of CLEF. Unfortunately, only the solutions for 2007 questions were available (answers and text passages where they occur), since the requirement to support answers with text snippets was only introduced on that year.</p><p>The following is an example of the solution for the question Quem é o Lampadinha? (Who is Lampadinha?) :</p><p>&lt;pergunta ano="2007" id_org="X" new_id_org="070101" categoria="D" tipo="PERSON" restrição="NO" ling_orig="PT" tarefa_pt="0101" tópico="082"&gt; &lt;texto&gt;Quem é o Lampadinha?&lt;/texto&gt; &lt;resposta n="1" docid="Professor Pardal 6afa"&gt; um pequeno andróide com uma lâmpada no lugar da cabeça&lt;/resposta&gt; &lt;extracto n="1" resposta_n="1"&gt;"Pardal é ajudado frequentemente por Lampadinha (criado por <ref type="bibr" coords="5,485.66,153.99,38.84,8.74;5,70.92,165.51,21.49,8.74">Barks em 1953)</ref>, um pequeno andróide com uma lâmpada no lugar da cabeça, que é considerado sua maior invenção (ao lado do ""chapéu pensador"", um dispositivo em forma de telhado com chaminé habitado por corvos, que o ajuda a ter idéias)."&lt;/extracto&gt; &lt;/pergunta&gt;</p><p>From this solution one can derive the following pattern: Quem é o __X__ ? __X__ *, __ANSWER__,</p><p>This pattern means that the answer for a question of the form Quem é o X ? can be retrieved following a comma which appears after an instance of X. The asterisk (* ) stands for 0 or more characters after the sub-string __X__ and immediately before a comma.</p><p>For the participation at CLEF, 24 answer retrieval patterns were derived. The process used to obtain these patterns was semi-automatic: they were derived automatically from the solution file, but then adjusted manually, not only in order to correct or complete them, but also to generalize them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>Since the main goal of this participation was to evaluate the impact of the answer retrieval patterns described in the previous section, two official runs were submitted: esfi081PTPT which uses these patterns and esfi082PTPT which does not use them. Table <ref type="table" coords="5,109.18,421.71,5.01,8.74" target="#tab_1">1</ref> and Figure <ref type="figure" coords="5,167.01,421.71,5.01,8.74" target="#fig_1">4</ref> show the results of the official runs, considering all the questions (Total), only for factoid (F) or definition (D) questions. Table <ref type="table" coords="5,255.11,433.17,5.01,8.74" target="#tab_1">1</ref> includes results where only the first answer is evaluated (labeled first answer in the table and esfg08Nptpt in the figure ), where the first and second answers are evaluated (first 2 Answers in the table and esfg08Nptpt2 in the figure) and where all the three answers returned are evaluated (first 3 Answers in the table and esfg08Nptpt3 in the figure). As an illustration, take a question for which only the third answer is correct: this question is only accounted in the columns labeled first 3 answers.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Right Answers (first answer)</head><note type="other">Right</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>. Results of the official runs</head><p>There were no further developments of the anaphor resolution module of Esfinge for this participation, but since a considerable amount of this year's questions (51 questions) require the processing of anaphors, a study was performed to evaluate how well Esfinge dealt with the anaphors in this year's questions. Table <ref type="table" coords="6,454.11,343.77,5.01,8.74" target="#tab_2">2</ref> summarizes the results of this analysis: more than half of the anaphors are well resolved (26 out of 51) and there were additionally 6 useful resolutions. By useful anaphor resolutions, we mean questions which are not grammatically correct or where it is not possible to say that the anaphor was completely resolved, but where the resolution can nevertheless lead to the discovery of right answers given the techniques used in Esfinge. If one does not consider the questions which require anaphor resolution, the precision increases slightly: 28% against 24.5% when considering all the questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Resolution of anaphors Quantity</head><p>Well We consider our participation at QA@CLEF this year fruitful and rewarding. In our opinion it was wise that the organization proposed a similar task as last year's since a good number of challenges remain to be achieved.</p><p>Nevertheless, the main novelty in this years's task which consisted in allowing the return of up to three answers for each question, allowed us to investigate how good the second and third best answers returned by Esfinge are. The conclusion regarding this matter is that when Esfinge answers correctly a question, it does so usually with its first answer (for example the best run has 49 right answers, but even when considering all the answers returned (3 for each question) the number of right answers amount only to 62 right answers.</p><p>Nonetheless the most relevant result obtained in this year's participation was that the answer retrieval patterns clearly improved the results for definition questions (the first answer is correct for 34% of the definition questions and there is a correct answer in one of the three returned answers for 55% of questions of this type), but the same does not applied for the factoid questions.</p><p>A more detailed error analysis is due in order to better understand the current limitations of Esfinge, but we believe that there is still improvement potential where it regards the use of answer retrieval patterns. We would like to deepen our research on how to create these patterns using a more automated approach (as stated we used a semi-automatic process taking as input last year's solutions). Equally there is also interest in investigating how the results can improve when more answer retrieval patterns are used.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,194.88,623.61,205.59,8.74;4,178.14,460.38,239.10,160.50"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Patterns used to retrieve relevant texts</figDesc><graphic coords="4,178.14,460.38,239.10,160.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,221.40,295.59,152.57,8.74"><head>Figure 4</head><label>4</label><figDesc>Figure 4. Results of the official runs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="2,71.10,135.54,453.18,194.88"><head></head><label></label><figDesc></figDesc><graphic coords="2,71.10,135.54,453.18,194.88" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,72.90,505.05,450.52,56.38"><head>Answers (first 2 Answers) Right Answers (first 3 Answers)</head><label></label><figDesc></figDesc><table coords="5,72.90,505.05,450.52,56.38"><row><cell>Runs</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Inexact</cell><cell>Unsupported</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Answers</cell><cell>Answers</cell></row><row><cell></cell><cell>F</cell><cell>D</cell><cell>Total</cell><cell>F</cell><cell>D</cell><cell>Total</cell><cell>F</cell><cell>D</cell><cell>Total</cell><cell></cell><cell></cell></row><row><cell>esfi081ptpt</cell><cell>39</cell><cell>10</cell><cell>49</cell><cell>44</cell><cell>14</cell><cell>58</cell><cell>46</cell><cell>16</cell><cell>62</cell><cell>14</cell><cell>5</cell></row><row><cell>esfi082ptpt</cell><cell>39</cell><cell>2</cell><cell>41</cell><cell>43</cell><cell>3</cell><cell>46</cell><cell>46</cell><cell>6</cell><cell>52</cell><cell>18</cell><cell>6</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,222.96,564.69,149.45,8.74"><head>Table 1 : Results of the official runs</head><label>1</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,70.92,462.69,453.60,201.81"><head>Table 2 : Evaluation of the anaphor resolution module An</head><label>2</label><figDesc>additional study was performed in order to find how Esfinge supports its right answers (newspaper text or Wikipedia) in the best run. The results, summarized in Table3, reveal that Esfinge finds support in Wikipedia more often than in newspaper texts both for factoid and definition questions.</figDesc><table coords="6,125.40,462.69,336.17,201.81"><row><cell>resolved</cell><cell></cell><cell>26</cell><cell></cell></row><row><cell cols="2">Useful, but not well resolved</cell><cell>6</cell><cell></cell></row><row><cell>Not resolved</cell><cell></cell><cell>19</cell><cell></cell></row><row><cell>Total</cell><cell></cell><cell>51</cell><cell></cell></row><row><cell></cell><cell>Answer</cell><cell>Answer</cell><cell>Right</cell></row><row><cell>Type of Question</cell><cell>supported in</cell><cell>supported in</cell><cell>Answers</cell></row><row><cell></cell><cell>newspaper text</cell><cell>Wikipedia</cell><cell></cell></row><row><cell>Right Definition Answers</cell><cell>4</cell><cell>6</cell><cell>10</cell></row><row><cell>Right Factoid Answers</cell><cell>14</cell><cell>21</cell><cell>35</cell></row><row><cell>Right NIL Answers</cell><cell></cell><cell></cell><cell>4</cell></row><row><cell>Right Answers</cell><cell>18</cell><cell>27</cell><cell>49</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,204.90,667.89,185.55,8.74"><head>Table 3 : Distribution of the answer support</head><label>3</label><figDesc></figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,76.68,723.87,444.63,8.74;3,70.92,735.39,31.40,8.74"><p>This parameter is only used for the answers obtained through the n-grams module. For the other answers this is set to 1.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work was done in the scope of the <rs type="projectName">Linguateca</rs> project, jointly funded by the <rs type="funder">Portuguese Government</rs> and the <rs type="funder">European Union (FEDER and FSE)</rs> under contract ref. <rs type="grantNumber">POSC/339/1.3/C/NAC</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_FXeyJcM">
					<orgName type="project" subtype="full">Linguateca</orgName>
				</org>
				<org type="funding" xml:id="_xQDnHSA">
					<idno type="grant-number">POSC/339/1.3/C/NAC</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,92.30,384.76,432.24,7.85;7,106.92,395.08,227.33,7.85" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="7,163.50,384.76,361.03,7.85;7,106.92,395.08,76.13,7.85">The Parsing System &quot;Palavras&quot;: Automatic Grammatical Analysis of Portuguese in a Constraint Grammar Framework</title>
		<author>
			<persName coords=""><forename type="first">Eckhard</forename><surname>Bick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Aarhus University Press</publisher>
			<pubPlace>Aarhus</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,92.30,405.46,432.19,7.85;7,106.92,415.78,417.52,7.85;7,106.92,426.16,112.65,7.85;7,219.60,424.10,4.68,5.23;7,226.62,426.16,297.83,7.85;7,106.92,436.48,391.47,7.85" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,153.50,405.46,283.89,7.85">First Evaluation of Esfinge -a Question Answering System for Portuguese</title>
		<author>
			<persName coords=""><forename type="first">Luís</forename><surname>Costa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,406.74,415.78,117.70,7.85;7,106.92,426.16,112.65,7.85;7,219.60,424.10,4.68,5.23;7,226.62,426.16,241.24,7.85">Multilingual Information Access for Text, Speech and Images: 5 th Workshop of the Cross-Language Evaluation Forum (CLEF 2004)</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Gareth</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Kluck</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</editor>
		<meeting><address><addrLine>Bath, UK; Heidelberga, Alemanha</addrLine></address></meeting>
		<imprint>
			<publisher>LNCS</publisher>
			<date type="published" when="2004-09-17">15-17 September 2004. 2005</date>
			<biblScope unit="page" from="522" to="533" />
		</imprint>
	</monogr>
	<note>Revised Selected Papers</note>
</biblStruct>

<biblStruct coords="7,92.30,446.86,67.28,7.85;7,159.54,444.80,4.68,5.23;7,166.50,446.86,358.22,7.85;7,106.92,457.18,412.98,7.85;7,519.84,455.12,4.68,5.23;7,106.92,467.56,417.56,7.85;7,106.92,477.88,243.70,7.85" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,106.92,446.86,52.65,7.85;7,159.54,444.80,4.68,5.23;7,166.50,446.86,213.10,7.85">Luís Costa: 20 th Century Esfinge (Sphinx) solving the riddles at CLEF 2005</title>
	</analytic>
	<monogr>
		<title level="m" coord="7,515.40,457.18,4.50,7.85;7,519.84,455.12,4.68,5.23;7,106.92,467.56,252.79,7.85">6 th Workshop of the Cross-Language Evaluation Forum (CLEF&apos;2005)</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Frederic</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Gareth</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Bernardo</forename><surname>Kluck</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Henning</forename><surname>Magnini</surname></persName>
		</editor>
		<editor>
			<persName><surname>Müeller &amp; Maarten De Rijke</surname></persName>
		</editor>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005-09-23">21-23 September 2005. 2006</date>
			<biblScope unit="volume">4022</biblScope>
			<biblScope unit="page" from="467" to="476" />
		</imprint>
	</monogr>
	<note>Revised Selected Papers</note>
</biblStruct>

<biblStruct coords="7,92.30,488.20,432.32,7.85;7,106.92,498.58,412.92,7.85;7,519.78,496.52,4.68,5.23;7,106.92,508.90,417.54,7.85;7,106.92,519.28,326.00,7.85" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,150.48,488.20,203.36,7.85">Question answering beyond CLEF document collections</title>
		<author>
			<persName coords=""><forename type="first">Luís</forename><surname>Costa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,515.34,498.58,4.50,7.85;7,519.78,496.52,4.68,5.23;7,106.92,508.90,249.26,7.85">7 th Workshop of the Cross-Language Evaluation Forum, CLEF 2006</title>
		<title level="s" coord="7,187.18,519.28,126.92,7.85">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Fredric</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Douglas</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Maximilian</forename><surname>Stempfhuber</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<meeting><address><addrLine>Alicante, Spain; Berlin / Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006-09">September 2006. 2007</date>
		</imprint>
	</monogr>
	<note>Revised Selected Papers</note>
</biblStruct>

<biblStruct coords="7,92.30,529.60,432.24,7.85;7,106.92,539.98,417.54,7.85;7,106.92,551.32,281.35,7.85;7,388.26,548.47,5.04,5.65;7,397.44,551.32,126.95,7.85;7,106.92,561.82,417.59,7.85;7,106.92,572.20,188.71,7.85" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,330.79,529.60,126.63,7.85">What happened to Esfinge in 2007?</title>
		<author>
			<persName coords=""><forename type="first">Miguel</forename><surname>Luís</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luís</forename><surname>Cabral</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fernando</forename><surname>Costa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Diana</forename><surname>Santos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,133.62,551.32,254.65,7.85;7,388.26,548.47,5.04,5.65;7,397.44,551.32,126.95,7.85;7,106.92,561.82,116.17,7.85">Advances in Multilingual and Multimodal Information Retrieval: 8 th Workshop of the Cross-Language Evaluation Forum, CLEF 2007</title>
		<title level="s" coord="7,142.41,572.20,126.96,7.85">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Valentin</forename><surname>Jijkoun</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thomas</forename><surname>Mandl</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Doug</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Anselmo</forename><surname>Peñas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Vivien</forename><surname>Petras</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Diana</forename><surname>Santos</surname></persName>
		</editor>
		<meeting><address><addrLine>Budapest, Hungary; Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">September 19-21, 2007. 2008</date>
		</imprint>
	</monogr>
	<note>Revised Selected Papers</note>
</biblStruct>

<biblStruct coords="7,92.30,582.52,432.17,7.85;7,106.92,592.90,417.54,7.85;7,106.92,604.24,259.19,7.85;7,366.06,601.39,5.04,5.65;7,374.04,604.24,150.45,7.85" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,166.98,582.52,313.87,7.85">SIEMÊS -A Named Entity Recognizer for Portuguese Relying on Similarity Rules</title>
		<author>
			<persName coords=""><forename type="first">Luís</forename><surname>Sarmento</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,151.86,604.24,214.25,7.85;7,366.06,601.39,5.04,5.65;7,374.04,604.24,85.01,7.85">Computational Processing of the Portuguese Language: 7 th International Workshop</title>
		<editor>
			<persName><forename type="first">Renata</forename><surname>Vieira</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Paulo</forename><surname>Quaresma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Maria</forename><surname>Da Graça</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Volpes</forename><surname>Nunes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nuno</forename><forename type="middle">J</forename><surname>Mamede</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Cláudia</forename><surname>Oliveira</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">&amp;</forename><surname>Maria</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Carmelita</forename><surname>Dias</surname></persName>
		</editor>
		<meeting><address><addrLine>PROPOR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,106.92,614.74,417.55,7.85;7,106.92,625.06,23.27,7.85" xml:id="b6">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j" coord="7,267.72,614.74,21.50,7.85">LNAI</title>
		<imprint>
			<biblScope unit="volume">3960</biblScope>
			<biblScope unit="page" from="90" to="99" />
			<date type="published" when="2006-05">May 2006. 2006. May 2006</date>
			<publisher>Springer Verlag</publisher>
			<pubPlace>Brazil; Berlin/Heidelberg</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,92.30,635.44,432.23,7.85;7,106.92,645.76,417.50,7.85;7,106.92,656.14,417.55,7.85;7,106.92,666.46,96.55,7.85" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,297.27,635.44,227.26,7.85;7,106.92,645.76,142.10,7.85">Jspell.pm -um módulo de análise morfológica para uso em Processamento de Linguagem Natural</title>
		<author>
			<persName coords=""><forename type="first">Alberto</forename><surname>Manuel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Simões</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">José João</forename><surname>Almeida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,469.74,645.76,54.68,7.85;7,106.92,656.14,280.44,7.85">Actas do XVII Encontro Nacional da Associação Portuguesa de Linguística (APL 2001)</title>
		<editor>
			<persName><forename type="first">Anabela</forename><surname>Gonçalves</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Clara</forename><forename type="middle">Nunes</forename><surname>Correia</surname></persName>
		</editor>
		<meeting><address><addrLine>Lisboa; Lisboa</addrLine></address></meeting>
		<imprint>
			<publisher>APL</publisher>
			<date type="published" when="2001">2-4 de Outubro de 2001</date>
			<biblScope unit="page" from="485" to="495" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
