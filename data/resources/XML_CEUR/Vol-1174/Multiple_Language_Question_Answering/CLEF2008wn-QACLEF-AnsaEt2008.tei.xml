<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,136.07,148.86,330.86,15.15;1,231.53,170.78,139.93,15.15">Ihardetsi question answering system at QA</title>
				<funder>
					<orgName type="full">Basque Government</orgName>
				</funder>
				<funder ref="#_VRJydJa">
					<orgName type="full">Basque Government (Department of Language Policy and Department of Industry Anhitz</orgName>
				</funder>
				<funder ref="#_wPSeapa">
					<orgName type="full">Education Ministry</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,173.12,204.67,46.87,8.74"><forename type="first">Olatz</forename><surname>Ansa</surname></persName>
							<email>olatz.ansa@ehu.es</email>
							<affiliation key="aff0">
								<orgName type="institution">IXA Group University of the Basque Country</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,228.25,204.67,58.31,8.74"><forename type="first">Xabier</forename><surname>Arregi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IXA Group University of the Basque Country</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,294.19,204.67,61.19,8.74"><forename type="first">Arantxa</forename><surname>Otegi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IXA Group University of the Basque Country</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,363.13,204.67,66.75,8.74"><forename type="first">Ander</forename><surname>Soraluce</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">IXA Group University of the Basque Country</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,136.07,148.86,330.86,15.15;1,231.53,170.78,139.93,15.15">Ihardetsi question answering system at QA</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">46AC0F2014EA53B608238CE9D650B9B1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:18+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>I.2 [Artificial Intelligence]: I.2.7 Natural Language Processing Measurement, Performance, Experimentation Question answering, Cross-lingual Question answering, Natural Language Processing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes IHARDETSI, a question answering system for Basque. We present the results of our first participation in the QA@CLEF 2008 evaluation task. We participated in three subtasks using Basque, English and Spanish as source languages and Basque as target language. We approached the Spanish-Basque and English-Basque cross-lingual tasks with a machine translation system that process a question in the source language (i.e. Spanish, English), translates into the target language (i.e. Basque) and, finally, the obtained Basque question is sent to Ihardetsi system. We submitted four runs, one for Basque-Basque subtask, one for English-Basque subtask and two for Spanish-Basque subtask.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Question answering (QA) systems tackle the task of finding a precise and exact answer to a question formulated in a natural language. Cross-lingual QA capabilities enable systems to retrieve the answer in one language (the target language) to a question posed in a different language (the source language). This year, a new Basque-to-Basque monolingual task and English-to-Basque, Spanish-to-Basque cross-lingual QA tasks were organised for the first time within the context of the CLEF campaign.</p><p>The main goal of our first participation in QA@CLEF for Basque with Ihardetsi system was to evaluate our basic system in order to compare with other systems dealing with Basque and the state of the art with non-English question answering systems. Besides, the results analysis will reveal a number of future system improvements directions. We took part in Basque-Basque, Spanish-Basque and English-Basque tasks. Ihardetsi system is a Basque monolingual system, and we use a Spanish-Basque and English-Basque machine translation systems <ref type="bibr" coords="2,412.07,112.02,10.52,8.74" target="#b3">[4]</ref> for the Cross-lingual tasks to translate the questions into Basque.</p><p>This paper is structured as follows. The next section presents the corpus processing. Section 3 describes the system architecture. Section 4 introduces the results and a preliminary analysis of the kind of errors that the system made. Conclusions and directions of future work to solve main problems follow in section 5. The document collection has been lemmatized before indexing it. Due to Basque is an agglutinative language, a given lemma makes many different word forms, depending on the case (genitive, locative, etc.) or the number (singular, plural, indefinite) for nouns and adjectives, and the person (me, he, etc.) and the tense (present, past, etc.) for verbs. For example, the lemma lan ("work") forms the inflections lana ("the work"), lanak ("works" or "the works"), lanari ("to the work"), lanei ("to the works"), lanaren ("of the work"), lanen ("of the works"), etc. This means that looking only for the exact word given or the word plus an "s" for the plural is not enough for Basque. And the use of wildcards, which some search engines allow, is not an adequate solution, as these can return occurrences of not only conjugations or inflections of the word, but also derivatives, unrelated words, etc. For example, looking for lan* would also return all the forms of the words lanabes ("tool"), lanbide ("job"), lanbro ("fog"), and many more.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Corpus processing</head><p>Before the Wikipedia was analysed it needed to be parsed to clean the text, getting out html tags. So, we created a XML parser that extracts page title, paragraphs, and lists creating a simple XML document which is very similar to the XML of the newspaper collection.</p><p>The entire document collection was lemmatized, part-of-speech tagged and named entity recognised. The named entity recogniser for Basque captures entities such as PERSON, ORGANIZA-TION, LOCATION and the numerical and temporal expressions are captured by the lemmatizer/tagger.</p><p>And finally, the document collection was indexed by lemma using Swish-e search engine and the retrieval unit is the passage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">System overview</head><p>The system relies on NLP tools, which perform a linguistic analysis, both on the question and on the corpus.</p><p>A XML configuration file governs the running of these components. The configuration file is a declarative document where all the features involved in a run are described. The set of features is divided into two categories:</p><p>1. General requirements. It includes specifications such as the corpus to be used, the location of the list of questions to be answered, and the metrics and conditions for the evaluation.</p><p>2. Descriptors of the QA process itself. This subset of features represents the characteristics of the answering process. Mainly, it determines which modules act during the answering process, describes them and specifies the parameters of each module. In that way, the process is controlled by means of the configuration file, and different processing options, techniques, and resources can be easily activated/deactivated and adapted. These descriptors constitute the documentation support of the system.</p><p>The principles of versatility and adaptability have guided the development of the system. The system is based on web services, integrated using SOAP communication protocol. Some tools previously developed in the IXA group are used as autonomous web services, and the QA system becomes a client that calls these services when it needs them. This distributed model allows to parameterize the linguistic tools, and to adjust the behaviour of the system during the development and testing phases. The communication between the web services is done using XML documents. This model has been adopted by other systems ( <ref type="bibr" coords="3,230.23,505.11,10.30,8.74" target="#b0">[1]</ref>, <ref type="bibr" coords="3,247.00,505.11,10.30,8.74" target="#b7">[8]</ref>). Each service receives the input data in XML documents, and consults the general configuration file for specific information about execution parameters. The current version has three main modules, as it is very common in the question answering systems: Question analysis, Passage Retrieval and Answer extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Question translation</head><p>A Machine Translation engine named Matxin <ref type="bibr" coords="3,295.85,587.25,10.52,8.74" target="#b1">[2]</ref> has been used for question translations. This engine has been developed for translation from Spanish to Basque and it is rule-based. Due to the different structures of the languages the quality of the translations it is not enough for dissemination, but it can be used for assimilation. It has been developed for a general domain and tested with texts from newspapers, but not with questions. A shallow test was carried out on factoid questions from previous trails of CLEF and we considered the results were enough good for using it in this task. Anyway a wider evaluation is necessary. A free version of the MT engine is in a public repository (matxin.sourceforge.net).</p><p>In the English to Basque translation we have used an early version of the English to Basque engine based on the same technology. The quality was poor and in a similar shallow test with factoid questions we detected that the translation of some question types were wrong, specially when the question marker was composed of two words that appeared as non-contiguous (i.e. Where is he from? ). To face this problem a heuristic was applied after the translation process in order to repair bad translations of question markers. The heuristic was implemented using a few number of conditional rules, which work on the original and the translated sentences.</p><p>In the near future we want to evaluate the quality of the translation of questions and to improve it, using if it is possible a corpus-based approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Question analysis</head><p>The main goal of this module is to analyse the question and to generate the information needed for the next tasks. Concretely, a set of search terms are extracted for the passage retrieval module, the question type (factoid, list or definition) and the expected answer type along with some lexical information is passed to the answer extraction module. To achieve this goal, our question analyser performs the following steps:</p><p>• Linguistic processing: The question analysis uses a set of general purpose tools like the morphological analyser, Morfeus <ref type="bibr" coords="4,261.28,261.91,9.96,8.74" target="#b6">[7]</ref>, and the Name Entity recogniser and classifier, Eihera</p><p>.</p><p>• Question classification: For identifying the question type, the question focus and the expected answer type, a set of rules has been defined after the examination of a Basque question set.</p><p>The question focus is the word or the word sequence that defines or disambiguates the question, i.e. it pinpoints what the question is searching for or what it is about. For example in the question Which river is in the south of this country?, the focus is river and in question What is the North Pole?, the focus is North Pole.</p><p>Next step is to identify the expected answer type. Our system's answer type taxonomy distinguishes the following classes: PERSON, ORGANIZATION, DESCRIPTION, LOCATION, QUANTITY, TEMPORAL, ENTITY, and OTHER. The assignment of a class to analysed question is performed using the question stem, the syntactic construction and the type of the question focus. The question focus type is used to detect the expected answer type using BasqueWN<ref type="foot" coords="4,163.81,443.65,3.97,6.12" target="#foot_0">1</ref> semantic file to the categories PERSON / ORGANIZATION / LOCATION / QUANTITY / TEMPORAL.</p><p>• Query terms extraction and expansion: All nouns, verbs, adjectives and abbreviations of the question constitute the set of search terms. They are lemmatized and arranged in descending order by their Inverse Document Frequency (IDF) value in the corpora.</p><p>Optionally, the search terms can be expanded using synonymy, hyponymy and hypernymy information. To do this, the system uses a service which consults the lexical-semantic database BasqueWN.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Passage retrieval</head><p>The retrieval unit is a passage and not the entire document. The corpus is indexed by lemma using swish-e<ref type="foot" coords="4,121.11,597.52,3.97,6.12" target="#foot_1">2</ref> search engine. The corpus is batch-processed (see section 2): all words are lemmatized, and complex lexical units and entities are marked. This module takes as input:</p><p>1. the search terms selected by the question analysis module 2. the search terms selected by the question analysis module for the first question of a topic (if the question is not the first) 3. the first three answers of the first question of a topic (if the question is not the first) and produces a set of queries. For each group a set of queries are created using relaxation techniques <ref type="bibr" coords="5,139.02,123.98,9.96,8.74" target="#b5">[6]</ref>, and then they are combined to generate the set of final queries. Finally, they are executed until one of them retrieves a passage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Answer extraction</head><p>Two tasks are performed in sequence: Candidate Extraction and Answer Selection. The candidate extraction consists of extracting all the candidate answers from the highest scoring passages. The answer selection consists of choosing the best three answers.</p><p>• Candidate Extraction. The process is carried out on the set of passages obtained in the previous step. First, all candidate answers are detected from each retrieved passage and a set of windows are defined around them. The selected window for each candidate answer is the smaller one which has all the query terms, or taxonomically related terms, in. Then, the candidate answer score is computed like this:</p><formula xml:id="formula_1" coords="5,265.16,291.80,243.59,25.41">score CA = n i=1 w i n (<label>1</label></formula><formula xml:id="formula_2" coords="5,508.76,301.65,4.24,8.74">)</formula><p>where n is the window size and w i is the i word weight. w i is 1 for search terms, 0.8 for the synonyms of the search terms, 0.5 for hyponyms and hypernyms, and 0.3 for other question terms.</p><p>The candidate answers extraction process then addresses each question type in a different manner, as follows:</p><p>-Question type is Factoid: the answer selection depends on entities in the most of the cases except when the expected answer type is Entity or Other. For Entity and Other types we select all the entities and nouns near the question focus. Although the numerical and temporal expressions are marked in the processed corpus (see section 2), a grammar has been applied to mark even more.</p><p>-Question type is Definition: a set of rules have been defined to extract definition from retrieved text passages.</p><p>-Question type is List: an attempt has been done similar to Factoid questions but it was asked to be a list of answers being in the same sentence.</p><p>• Answer Selection. In order to select the best answers from the set of candidates, the same answers that appear in different passages must be combined. We try to map as identical those answers that refer to the same entity. The formula used to compute the final score of each answer is as follows:</p><formula xml:id="formula_3" coords="5,256.45,571.50,252.30,25.41">f inal score CA = p i=1 w i N (<label>2</label></formula><formula xml:id="formula_4" coords="5,508.76,581.34,4.24,8.74">)</formula><p>where p is the number of identical answers and N is the number of candidate answers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>This section describes the results we obtained in our CLEF-2008 participation. We submitted four runs, one for Basque to Basque monolingual QA task, one for English to Basque cross-lingual QA task, and two runs for Spanish to Basque cross-lingual QA task. The methodology we employed targeted precision at the cost of recall, therefore we always choose NIL answers for those questions we could not reliably locate a candidate answer in the retrieved passage. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Monolingual system</head><p>At it was expected the best results were obtained for the monolingual task. Table <ref type="table" coords="6,445.55,233.11,4.98,8.74" target="#tab_0">1</ref> illustrates the results achieved by our system in the monolingual run.</p><p>It is clear that the best results were achieved for factoid questions. It is due to the fact that we focused on this type of questions in the development of the system. There were 145 factoid questions and 50 had a correct or inexact answer in the proposed three answers, 22 had a NIL answer (incorrect) and 73 had an incorrect answer. Analysing these 73 questions we detected that for 17 the correct passage was detected but the system did not extract the correct answer.</p><p>The system answered NIL for 57 questions but only 4 of them were correct. Analysing the reasons for this we can group them in 5 groups:</p><p>• The expected answer type detection failed: 6 questions.</p><p>• No passage was retrieved: 14 questions • The passage had the answer but the system could not extract the answer: 13 question • Retrieved passage had not the answer: 16 questions • Some other reasons: 4 questions After an analysis of the results of the NIL questions, we realized that some questions did not get any documents due to a bug in the system. Once it was corrected we performed a new run for Basque questions; 10 more questions were answered (9 DEFINITION questions and 1 FACTOID question) and for 8 questions the answer was changed (losing two correct answers). The answered new factoid question (i.e. Where is Ocotal? ) was answered correctly and for the nine definitional questions 4 were answered correctly and 2 more had the correct answer in the second place.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Cross-lingual systems</head><p>Three cross-lingual runs, two for Spanish-Basque and one for English-Basque, have been performed. The aim of the second run for Spanish-Basque was to test if the semantic expansion (see 3.2 section) of the question could compensate the lost of precision in the translation process.</p><p>The results of the three runs are shown in Table <ref type="table" coords="6,319.19,590.23,3.87,8.74" target="#tab_1">2</ref>. The main conclusions we want to remark are:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>EN-EU ES-EU ES-EU with synonymy</head><formula xml:id="formula_5" coords="6,167.96,618.55,303.34,6.14">R W X U Acc. R W X U Acc. R W X U</formula><p>• The results are quite poor. The loss of precision respect to the monolingual system is more than 50%.</p><p>• Very similar results are obtained for the basic Spanish-Basque and for the English-Spanish runs (in both there are 11 right answers, 7 right answers in 2 nd or 3 rd place and 7 inexact in the first place). Due to better quality of the Spanish-Basque translator we hoped better results for this run. Anyway, it is necessary a wider evaluation of each MT engine when translating questions.</p><p>• Although the results are similar in average, the right results do not correspond always to the same questions. Only five of the eleven right answer are common.</p><p>• The semantic expansion in the second run for Spanish-Basque do not achieve better results. A slight smaller precision is observed, because some right answer are lost. In compensation to this, new right or inexact answer appear but not in the first place. With this figures we can think that at least a higher number of "passages" are recovered, but it is not true, because the number of recovered "passages" remains at same level (about 40 of 200).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions and Future work</head><p>The development stage of our monolingual Basque to Basque QA system has been described in this paper, as well as our participation in the QA@CLEF campaign. Thanks to this track we have had the opportunity of testing our system. Although the results might look no good, our general conclusion is very positive taking into account that it was our first participation. We can not directly compare our system results with the results of other languages systems due to the particularities of Basque language. However, we have been able to extract some of the strengths and weakness of each module of the system, which we will take into account for future improvements. Besides we study the possibility of adding a fourth module to deal with topicrelated questions.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,90.00,226.56,423.00,8.74;2,90.00,238.52,304.49,8.74"><head></head><label></label><figDesc>This year's document collection consists of two different collections: a dump of the Wikipedia 2006 articles and Egunkaria newswire collection from 2000 until 2002.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,209.86,469.24,183.28,8.74"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The system general architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,98.18,110.06,406.65,81.58"><head>Table 1 :</head><label>1</label><figDesc>Results obtained in Basque to Basque monolingual run at QA@CLEF 2008.</figDesc><table coords="6,98.18,110.06,406.65,60.33"><row><cell></cell><cell>OVERALL</cell><cell>FACTOID</cell><cell>DEFINITION</cell><cell>LIST</cell><cell>TEMPORALLY RESTRICTED</cell></row><row><cell>RIGHT</cell><cell>26</cell><cell>23</cell><cell>3</cell><cell>0</cell><cell>2</cell></row><row><cell>WRONG</cell><cell>163</cell><cell>113</cell><cell>36</cell><cell>14</cell><cell>19</cell></row><row><cell>INEXACT</cell><cell>11</cell><cell>9</cell><cell>0</cell><cell>2</cell><cell>2</cell></row><row><cell>UNSUPPORTED</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>TOTAL</cell><cell>200</cell><cell>145</cell><cell>39</cell><cell>16</cell><cell>23</cell></row><row><cell>ACCURACY</cell><cell>13%</cell><cell>15.862%</cell><cell>7.692%</cell><cell>0</cell><cell>8.696%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,95.98,618.55,411.96,77.20"><head>Table 2 :</head><label>2</label><figDesc>Results obtained in cross-lingual runs at QA@CLEF 2008.</figDesc><table coords="6,486.93,618.55,17.32,6.14"><row><cell>Acc.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,105.24,714.22,407.75,6.99;4,90.00,723.68,318.93,6.99"><p>It is the Basque version of EuroWordNet. This resource is integrated in the Multilingual Central Repository (MCR), which is a multilingual lexical database developed in the Meaning project<ref type="bibr" coords="4,397.64,723.68,8.47,6.99" target="#b4">[5]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,105.24,733.19,67.14,6.99"><p>http://swish-e.org</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6">Acknowledgements</head><p>We would like to thank <rs type="person">Gorka Labaka</rs> and <rs type="person">Mikel Lersundi</rs> who have collaborated in this research. <rs type="person">Arantxa Otegi</rs>'s work is funded by a PhD grant from the <rs type="funder">Basque Government</rs>. Part of this work has been funded by the <rs type="funder">Basque Government (Department of Language Policy and Department of Industry Anhitz</rs> project, Etortek <rs type="grantNumber">IE06-185</rs>) and the <rs type="funder">Education Ministry</rs> (<rs type="projectName">KNOW</rs>, <rs type="grantNumber">TIN2006-15049-C03-01</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_VRJydJa">
					<idno type="grant-number">IE06-185</idno>
				</org>
				<org type="funded-project" xml:id="_wPSeapa">
					<idno type="grant-number">TIN2006-15049-C03-01</idno>
					<orgName type="project" subtype="full">KNOW</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,105.50,563.22,407.50,8.74;7,105.50,575.17,120.52,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,328.69,563.22,184.31,8.74;7,105.50,575.17,43.41,8.74">Building an XML framework for Question Answering</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Tomás</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Vicedo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Saiz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Izquierdo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,170.60,575.17,23.53,8.74">CLEF</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.50,593.88,407.50,8.74;7,105.50,605.84,407.50,8.74;7,105.50,617.79,23.14,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,473.60,593.88,39.40,8.74;7,105.50,605.84,356.16,8.74">Transferbased MT from Spanish into Basque: reusability, standardization and open source</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Alegria</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Díaz De Ilarraza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Labaka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lersundi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mayor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Sarasola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,482.45,605.84,30.55,8.74;7,105.50,617.79,18.51,8.74">Cicling 2007</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.50,636.50,407.50,8.74;7,105.50,648.45,353.11,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,405.53,636.50,107.47,8.74;7,105.50,648.45,265.91,8.74">Design and Development of a Named Entity Recognizer for an Agglutinative Language</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Alegria</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Arregi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Balza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ezeiza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Urizar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,393.21,648.45,33.75,8.74">IJCNLP</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.50,667.16,407.50,8.74;7,105.50,679.12,407.50,8.74;7,105.50,691.07,407.50,8.74;7,105.50,703.03,199.26,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,185.82,679.12,327.18,8.74;7,105.50,691.07,142.02,8.74">Strategies for sustainable mt for basque: incremental design, reusability, standardization and open-source</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Alegria</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Arregi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Artola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Díaz De Ilarraza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Labaka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lersundi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mayor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Sarasola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,273.24,691.07,239.76,8.74;7,105.50,703.03,110.33,8.74">Proceedings of the IJCNLP-08 Workshop on NLP for Less Privileged Languages</title>
		<meeting>the IJCNLP-08 Workshop on NLP for Less Privileged Languages</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="59" to="64" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.50,721.73,407.50,8.74;7,105.50,733.69,407.50,8.74;7,105.50,745.64,22.69,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,495.84,721.73,17.16,8.74;7,105.50,733.69,190.25,8.74">The MEANING Multilingual Central Repository</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Atserias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Villarejo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rigau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Vossen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,316.49,733.69,191.89,8.74">Proc. of the 2nd Global WordNet Conference</title>
		<meeting>of the 2nd Global WordNet Conference</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.50,112.02,407.50,8.74;8,105.50,123.98,172.91,8.74" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="8,160.93,112.02,240.53,8.74">Query Expansion Techniques for Question Answering</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Bilotti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>Massachusetts institute of technology</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Master&apos;s thesis</note>
</biblStruct>

<biblStruct coords="8,105.50,143.90,407.50,8.74;8,105.50,155.86,407.50,8.74;8,105.50,167.81,63.65,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,371.62,143.90,141.38,8.74;8,105.50,155.86,283.95,8.74">Combining Stochastic and Rule-Based Methods for Disambiguation in Agglutinative Languages</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ezeiza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Aduriz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Alegria</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Arriola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Urizar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,417.42,155.86,60.75,8.74">COLING-ACL</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="380" to="384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.50,187.74,369.46,8.74" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="8,186.99,187.74,165.10,8.74">Planning in the JAVELIN QA System</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">S</forename><surname>Hiyakumoto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note type="report_type">CMU-CS-04-132</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
