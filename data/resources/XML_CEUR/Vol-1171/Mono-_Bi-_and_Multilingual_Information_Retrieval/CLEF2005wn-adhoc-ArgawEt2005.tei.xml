<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,104.95,148.86,393.09,15.15;1,263.06,170.78,76.88,15.15">Dictionary-based Amharic-French Information Retrieval</title>
				<funder ref="#_fwBncgy">
					<orgName type="full">French Ministry of Foreign Affairs</orgName>
				</funder>
				<funder ref="#_SrDcxvQ">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,218.59,204.67,96.05,8.74"><forename type="first">Atelach</forename><forename type="middle">Alemu</forename><surname>Argaw</surname></persName>
							<email>[atelach@dsv.su.se</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and Systems Sciences</orgName>
								<orgName type="institution">Stockholm University/KTH</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,337.34,204.67,47.08,8.74"><forename type="first">Lars</forename><surname>Asker</surname></persName>
							<email>asker]@dsv.su.se</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer and Systems Sciences</orgName>
								<orgName type="institution">Stockholm University/KTH</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,185.78,246.52,63.34,8.74"><forename type="first">Rickard</forename><surname>CÃ¶ster</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Swedish Institute of Computer Science (SICS)</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,256.88,246.52,62.85,8.74"><forename type="first">Jussi</forename><surname>Karlgren</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Swedish Institute of Computer Science (SICS)</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,342.42,246.52,74.80,8.74"><forename type="first">Magnus</forename><surname>Sahlgren</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Swedish Institute of Computer Science (SICS)</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,104.95,148.86,393.09,15.15;1,263.06,170.78,76.88,15.15">Dictionary-based Amharic-French Information Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E251BAD34E7677A32CE4498E1B1AE9FA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Managment]: Languages-Query Languages Languages, Measurement, Performance, Experimentation Question answering, Amharic, Cross-Language Information Retrieval 1 2a. Trigram and Bigram dictionary lookup -----| 7a. Retrieval (Indexing, keyword search, ranking) | 8. Retrieved Documents</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present four approaches to the Amharic -French bilingual track at CLEF 2005. All experiments use a dictionary based approach to translate the Amharic queries into French Bags-of-words, but while one approach uses word sense discrimination on the translated side of the queries, the other one includes all senses of a translated word in the query for searching. We used two search engines: The SICS experimental engine and Lucene, hence four runs with the two approaches. Non-content bearing words were removed both before and after the dictionary lookup. TF/IDF values supplemented by a heuristic function was used to remove the stop words from the Amharic queries and two French stopwords lists were used to remove them from the French translations. In our experiments, we found that the SICS search engine performs better than Lucene and that using the word sense discriminated keywords produce a slightly better result than the full set of non discriminated keywords.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Figure <ref type="figure" coords="2,206.14,474.77,3.88,8.74">1</ref>: Generalised flow chart for the four Amh-Fr runs the languages, Amharic has gained ground through out the country. Amharic is used in business, government, and education. Newspapers are printed in Amharic as are numerous books on all subjects <ref type="bibr" coords="2,128.58,530.51,9.97,8.74" target="#b4">[5]</ref>.</p><p>In this paper we describe our experiments at the CLEF 2005 Amharic -French bilingual track. It consists of four fully automatic approaches that differ in terms of how word sense discrimination is done and in terms of what search engine is used. We have experimented with two different search engines -Lucene <ref type="bibr" coords="2,165.43,578.33,9.97,8.74">[9]</ref>, an open source search toolbox, and Searcher, an experimental search engine developed at SICS<ref type="foot" coords="2,171.27,588.71,3.97,6.12" target="#foot_0">1</ref> . Two runs were submitted per search engine, one using all content bearing, expanded query terms without any word sense discrimination, and the other using a smaller 'disambiguated' set of content bearing query terms.</p><p>For the dictionary lookup we used one Amharic -French machine readable dictionary (MRD) containing 12.000 Amharic entries with corresponding 36,000 French entries <ref type="bibr" coords="2,424.62,638.10,9.97,8.74" target="#b0">[1]</ref>. We also used an Amharic -English machine readable dictionary with approximately 15.000 Amharic entries <ref type="bibr" coords="2,490.32,650.06,10.52,8.74" target="#b1">[2]</ref> as a complement for the cases when the Amharic terms where not found in the Amharic -French MRD.</p><p>Figure <ref type="figure" coords="3,121.30,133.84,4.98,8.74">1</ref> above, gives a brief overview of the different steps involved in the retrieval task. Each of these will be described in more detail in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Translation and Transliteration</head><p>The English topic set was initially translated into Amharic by human translators. Amharic uses its own and unique alphabet (Fidel) and there exist a number of fonts for this, but to date there is no standard for the language. The Amharic topic set was originally represented using an Ethiopic font but for ease of use and compatibility reasons we transliterated it into an ASCII representation using SERA<ref type="foot" coords="3,143.65,238.32,3.97,6.12" target="#foot_1">2</ref> . The transliterated Amharic topic set was then used as the input to the following steps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Bigram and trigram matching</head><p>Before any stemming was done on the Amharic topic set, the sentences from each topic was used to generate all possible trigrams and bigrams. These trigrams and bigrams where then matched against the entries in the two dictionaries. First the full (unstemmed) trigrams where matched against the Amharic -French and then the Amharic -English dictionaries. Secondly, prefixes were removed from the first word of each trigram and suffixes were removed from the last word of the same trigram and then what remained was matched against the two dictionaries. In this way, one trigram was matched and translated for the full Amharic topic set, using the Amharic -French dictionary.</p><p>Next, all bigrams where matched against the Amharic -French and the Amharic -English dictionaries. Including the prefix suffix removal, this resulted in the match and translation of 15 unique bigrams. Six were found only in the Amharic -French dictionary, another six were found in both dictionaries, and three were found only in the Amharic -English dictionary. For the six bigrams that were found in both dictionaries, the French translation was used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Stop word removal</head><p>In these experiments, stop words were removed both before and after the dictionary lookup. First the number of Amharic words in the queries was reduced by using a stopword list that had been generated from a 2 million word Amharic news corpus using IDF measures. After the dictionary lookup further stop words removal was conducted on the French side separately for the two sets of experiments using the SICS engine and Lucene. For the SICS engine, this was done by using a separete French stop words list. For the Lucene experiments, we used the French Analyszer from the Apache Lucene Sandbox which supplements the query analyzer with its own list of French stop words and removes them before searching for a specific keywords list.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Amharic stemming and dictionary lookup</head><p>The remaining Amharic words where then stemmed and matched against the entries in the two dictionaries. The Amharic -French dictionary was always preferred over the Amharic -English one. Only in cases when a term had not been matched in the French dictionary was it matched against the English one. In a similar way, trigrams were matched before bigrams, bigrams before unigrams, unstemmed terms before stemmed terms, unchanged root forms were matched before modified root forms, longer matches in the dictionary were preferred before shorter etc.</p><p>The terms for which matches were found only in the Amharic-English MRD where first translated into English and then further translated from English into French using an online electronic dictionary from WordReference (www.wordreference.com).</p><p>Words and phrases that where not found in any of the dictionaries (mostly proper names or inherited words) were not translated and instead handled by an edit-distance based similarity matching algorithm. Frequency counts in a 2.4 million words Amharic news corpus was used to determine whether an out of dictionary word would qualify as a candidate for a proper name or not. The assumption here is that if a word that is not included in any dictionary appears quite often in an Amharic text collection, then it is likely that the word is a term in the language although not found in the dictionary. On the other hand, if a term rarely occurs in the news corpus (in our case we used a threshold of nine times or less, but this of course depends on the size of the corpus), the word has a higher probability of being a proper name or an inherited word. Although this is a crude assumption and inherited words may occur frequently in a language, those words tend to be mostly domain specific. In a news corpus such as the one we used, the occurrence of almost all inherited words which could not be matched in the MRDs was very limited.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Word sense discrimination</head><p>For the word sense discrimination we made use of two MRDs to get all the different senses of a term (word or phrase) -as given by the MRD, and a statistical collocation measure of mutual information using the target language corpus to assign each term to the appropriate sense.</p><p>In our experiments we used the bag of words approach where context is considered as words in some window surrounding the target word, regarded as a group without consideration for their relationships to the target in terms of distance, grammatical relations, etc. There is a big difference between the two languages under consideration (Amharic and French) in terms of word ordering, morphology, syntax etc, and hence limiting the context to a few number of words surrounding the target word was intuitively undesirable. A sentence could have been taken as a context window, but following the "one sense per discourse" constraint <ref type="bibr" coords="4,328.52,397.40,10.52,8.74" target="#b3">[4]</ref> in discriminating amongst word senses, a context window of a whole article was implemented. This constraint states that the sense of a word is highly consistent within any given document, in our case a French news article. The words to be sense discriminated are the query keywords, which are mostly composed of nouns rather than verbs, or adjectives. Noun sense discrimination is reported to be aided by word collocations that have a context window of hundreds of words, while verb and adjective senses tend to fall off rapidly with distance from the target word. After going through the list of translated content bearing keywords, we noticed that the majority of these words are nouns, and hence the selection of the document context window.</p><p>In these experiments the Mutual Information between word pairs in the target language text collection is used to discriminate word senses. (Pointwise) mutual information compares the probability of observing two events x and y together (the joint probability) with the probabilities of observing x and y independently (chance). If two (words), x and y, have probabilities P(x) and P(y), then their mutual information, I(x,y), is defined to be:</p><formula xml:id="formula_0" coords="4,90.00,573.94,154.04,14.38">I(x, y) = log 2 P (x,y) P (x).P (y) = log 2 P (x/y) P (x))</formula><p>If there is a genuine association between x and y, P(x,y) will be much larger than chance P(x)* P(y), thus I(x,y) will be greater than 0. If there is no interesting relationship between x and y, P(x,y) will be approximately equal to P(x)* P(y), and thus, I(x,y) will be close to 0. And if x and y are in complementary distribution, P(x,y) will be much less than P(x)* P(y), and I(x,y) will be less than O.</p><p>Although very widely used by researchers for different applications, MI has also been criticized by many as to its ability to capture the similarity between two events especially when there is data scarcity <ref type="bibr" coords="4,149.29,684.33,9.97,8.74" target="#b5">[6]</ref>. Since we had access to a large amount of text collection in the target language, and because of its wide implementation, we chose to use MI.</p><p>The translated French query terms were put in a bag of words, and the mutual information for each of the possible word pairs was calculated. When we put the expanded words we treat both synonyms and translations with a distinct sense as given in the MRD equally. Another way of handling this situation is to group synonyms before the discrimination. We chose the first approach with two assumptions: one is that even though words may be synonymous, it doesn't necessarily mean that they are all equally used in a certain context, and the other being even though a word may have distinct senses defined in the MRD, those distinctions may not necessarily be applicable in the context the term is currently used. This approach is believed to ensure that words with inappropriate senses and synonyms with less contextual usage will be removed while at the same time the query is being expanded with appropriate terms.</p><p>We used a subset of the CLEF French document collection consisting of 14,000 news articles with 4.5 million words in calculating the MI values. Both the French keywords and the document collection were lemmatized (by SICS using tools from connexor, http://www.connexor.com/) in order to cater for the different forms of each word under consideration.</p><p>Following the idea that ambiguous words can be used in a variety of contexts but collectively they indicate a single context and particular meanings, we relied on the number of association as given by MI values that a certain word has in order to determine whether the word should be removed from the query or not. Given the bag of words for each query, we calculated the mutual information for each unique pair. The next step was to see for each unique word how many positive associations it has with the rest of the words in the bag. We experimented with different levels of combining precision and recall values depending on which one of these two measures we want to give more importance to. To contrast the approach of using the maximum recall of words (no discrimination) we decided that precision should be given much more priority over recall (beta value of 0.15), and we set an empirical threshold value of 0.4. i.e. a word is kept in the query if it shows positive associations with 40% of the words in the list, otherwise it is removed. Here, note that the mutual information values are converted to a binary 0, and 1. 0 being assigned to words that have less than or equal to 0 MI values (independent term pairs), and 1 to those with positive MI values (dependent term pairs). We are simply taking all positive MI values as indicators of association without any consideration as to how strong the association is. This is done to input as much association between all the words in the query as possible rather than putting the focus on individual pairwise association values. Results of the experiments are given in the next section.</p><p>The amount of words in each query (both in the English and corresponding translated Amharic) differed substantially from one query to another. After the dictionary lookup and stop word removal, there were queries with French words that ranged from 2 to 71. This is due to a large difference in the number of words and in the number of stop words in each query as well as the number of senses and synonyms that are given in the dictionary for each word.</p><p>When there were less than or equal to 8 words in the expanded query, there was no word sense discrimination done for those queries. This is an arbitrary number, and the idea here is that if the number of terms is as small as that, then it is much better to keep all words. We believe that erroneously removing appropriate words in short queries has a lot more disadvantage than keeping one with an inappropriate sense.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Retrieval</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.1">Retrieval using Lucene</head><p>Apache Lucene is an open source high-performance, full-featured text search engine library written in Java <ref type="bibr" coords="5,127.60,619.03,9.96,8.74">[9]</ref>. It is a technology deemed suitable for applications that require full-text search, especially in a cross-platform.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.2">Retrieval using Searcher</head><p>The underlying retrieval engine is an experimental system developed at SICS. For retrieval, we use Pivoted Unique Normalization <ref type="bibr" coords="5,245.90,687.22,9.96,8.74" target="#b6">[7]</ref>, where the score for a document d given a query with m query terms is defined as</p><formula xml:id="formula_1" coords="5,194.57,719.35,213.87,27.71">m i=1 1+log (tf i,d ) 1+log (average tf d ) (1 -slope) Ã pivot + slope Ã # of unique terms</formula><p>Recall am-fr-da-l am-fr-nonda-l am-fr-da-s am-fr-nonda-s 0.00 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>We have submitted four parallel Amharic-French runs at the CLEF 2005 ad-hoc bilingual track.</p><p>We have used two search engines -Lucene <ref type="bibr" coords="6,273.38,400.35,9.97,8.74">[9]</ref>, an open source search toolbox, and an experimental search engine developed at SICS (Searcher). The aim of using these two search engines is to compare the performance of the systems as well as to investigate the impact of performing word sense discrimination. Two runs were submitted that use the same search engine, with one of them searching for all content bearing, expanded query terms without any word sense discrimination while the other one searches for the 'disambiguated' set of content bearing query terms. The four runs are:</p><p>1. Lucene with word sense discrimination (am-fr-da-l)</p><p>2. Lucene without word sense discrimination (am-fr-nonda-l)</p><p>3. Searcher with word sense discrimination (am-fr-da-s) 4. Searcher without word sense discrimination (am-fr-nonda-s) Table <ref type="table" coords="6,132.34,571.70,4.98,8.74" target="#tab_0">1</ref> lists the precision at various levels of recall for the four runs. A summary of the results obtained from all runs is reported in Table <ref type="table" coords="6,400.60,583.66,3.88,8.74" target="#tab_1">2</ref>. The number of relevant documents, the retrieved relevant documents, the non-interpolated average precision as well as the precision after R (=num rel) documents retrieved (R-Precision) are summarized in the table. We have demonstrated the feasability of doing cross language information retrieval between Amharic and French. Although there is still much room for improvement of the results, we are pleased to have been able to use a fully automatic approach. The work on this project and the performed experiments have highlighted some of the more crucial steps on the road to better information access and retrieval between the two languages. The lack of electronic resources such as morphological analysers and large machine readable dictionaries have forced us to spend considerable time on getting access to, or developing these resources ourselves. We also believe that, in the absense of larger electronic dictionaries, one of the more important obstacles on this road is how to handle out-of-dictionary words. The approach that we tested in our experiments, to use fuzzy string matching in the retrieval step, seems to be only partially successful, mainly due to the large differences between the two languages. We have also been able to compare the performance between different search engines and to test different approaches to word sense discrimination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relevant-tot Relevant-retrieved Avg Precision R-Precision</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,90.00,122.78,423.00,219.58"><head>Table 1 :</head><label>1</label><figDesc>Recall-Precision tables for the four runswhere tf i,d is the term frequency of query term i in document d, and average tf d is the average term frequency in document d. The slope was set to 0.3, and the pivot to the average number of unique terms in a document, as suggested in<ref type="bibr" coords="6,287.57,333.62,9.96,8.74" target="#b6">[7]</ref>.</figDesc><table coords="6,166.89,122.78,251.40,128.29"><row><cell></cell><cell>16.71</cell><cell>18.67</cell><cell>24.55</cell><cell>23.84</cell></row><row><cell>0.10</cell><cell>6.20</cell><cell>6.93</cell><cell>9.12</cell><cell>9.18</cell></row><row><cell>0.20</cell><cell>4.23</cell><cell>4.70</cell><cell>5.13</cell><cell>4.71</cell></row><row><cell>0.30</cell><cell>2.34</cell><cell>3.76</cell><cell>3.75</cell><cell>3.36</cell></row><row><cell>0.40</cell><cell>1.43</cell><cell>1.76</cell><cell>2.83</cell><cell>2.71</cell></row><row><cell>0.50</cell><cell>1.13</cell><cell>0.79</cell><cell>2.02</cell><cell>1.85</cell></row><row><cell>0.60</cell><cell>0.87</cell><cell>0.57</cell><cell>1.36</cell><cell>1.45</cell></row><row><cell>0.70</cell><cell>0.29</cell><cell>0.32</cell><cell>0.76</cell><cell>0.60</cell></row><row><cell>0.80</cell><cell>0.15</cell><cell>0.08</cell><cell>0.57</cell><cell>0.37</cell></row><row><cell>0.90</cell><cell>0.05</cell><cell>0.04</cell><cell>0.39</cell><cell>0.23</cell></row><row><cell>1.00</cell><cell>0.05</cell><cell>0.04</cell><cell>0.27</cell><cell>0.17</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,123.43,643.14,335.88,73.33"><head>Table 2 :</head><label>2</label><figDesc>Summary of results for the four runs</figDesc><table coords="6,123.43,643.14,335.88,45.80"><row><cell>am-fr-da-l</cell><cell>2,537</cell><cell>479</cell><cell>2.22</cell><cell>3.84</cell></row><row><cell>am-fr-nonda-l</cell><cell>2,537</cell><cell>558</cell><cell>2.51</cell><cell>4.38</cell></row><row><cell>am-fr-da-s</cell><cell>2,537</cell><cell>535</cell><cell>3.43</cell><cell>5.16</cell></row><row><cell>am-fr-nonda-s</cell><cell>2,537</cell><cell>579</cell><cell>3.31</cell><cell>4.88</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,105.24,690.96,160.75,6.99"><p>The Swedish Institute of Computer Science</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,105.24,732.96,415.73,6.99;3,90.00,742.42,30.81,6.99"><p>SERA stands for System for Ethiopic Representation in ASCII, http://www.abyssiniacybergateway.net/fidel/serafaq.html</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The copyright to the two volumes of the French-Amharic and Amharic-French dictionary ("<rs type="programName">Dictionnaire Francais-Amharique</rs>" and "<rs type="programName">Dictionnaire Amharique-Francais</rs>") by <rs type="person">Dr Berhanou Abebe</rs> and loi Fiquet is owned by the <rs type="funder">French Ministry of Foreign Affairs</rs>. We would like to thank the authors and the <rs type="institution">French embassy in Addis Ababafor</rs> allowing us to use the dictionary in this research.</p><p>The content of the "English -Amharic Dictionary" is the intellectual property of <rs type="person">Dr Amsalu Aklilu</rs>. We would like to thank <rs type="person">Dr Amsalu</rs> as well as <rs type="person">Daniel Yacob</rs> of the Geez frontier foundation for making it possible for us to use the dictionary and other resources in this work.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_SrDcxvQ">
					<orgName type="program" subtype="full">Dictionnaire Francais-Amharique</orgName>
				</org>
				<org type="funding" xml:id="_fwBncgy">
					<orgName type="program" subtype="full">Dictionnaire Amharique-Francais</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,105.50,438.12,228.21,8.74" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="7,185.91,438.12,143.07,8.74">Dictionnaire Amharique-Francais</title>
		<author>
			<persName coords=""><forename type="first">Berhanou</forename><surname>Abebe</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.50,458.05,195.33,8.74" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="7,175.56,458.05,120.81,8.74">Amharic English Dictionary</title>
		<author>
			<persName coords=""><forename type="first">Amsalu</forename><surname>Aklilu</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.50,477.97,322.69,8.74" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="7,297.16,477.97,126.39,8.74">The ethiopian writing system</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Bender</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">W</forename><surname>Head</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Cowley</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.50,497.90,407.49,8.74;7,105.50,509.85,205.97,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,352.79,497.90,104.71,8.74">One sense per discourse</title>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Gale</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kenneth</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Yarowsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,482.14,497.90,30.85,8.74;7,105.50,509.85,174.85,8.74">the 4th DARPA Speech and Language Workshop</title>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.50,529.78,341.33,8.74" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Leslau</surname></persName>
		</author>
		<title level="m" coord="7,156.88,529.78,76.42,8.74">Amharic Textbook</title>
		<meeting><address><addrLine>Berkeley, California</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1968">1968</date>
		</imprint>
		<respStmt>
			<orgName>Berkeley University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.50,549.71,407.50,8.74;7,105.50,561.66,203.39,8.74" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hinrich</forename><surname>SchÃ¼tze</surname></persName>
		</author>
		<title level="m" coord="7,318.57,549.71,194.44,8.74;7,105.50,561.66,43.50,8.74">Foundations of Statistical Natural Language Processing</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,105.50,581.59,369.58,8.74" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="7,299.45,581.59,171.16,8.74">Pivoted document length normalization</title>
		<author>
			<persName coords=""><forename type="first">Amit</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
