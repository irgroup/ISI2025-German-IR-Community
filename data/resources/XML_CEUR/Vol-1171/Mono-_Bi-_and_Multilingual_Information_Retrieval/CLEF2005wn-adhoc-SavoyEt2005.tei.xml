<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,159.00,94.53,277.07,15.50;1,126.04,112.53,346.99,15.50">Report on CLEF-2005 Evaluation Campaign: Monolingual, Bilingual, and GIRT Information Retrieval</title>
				<funder ref="#_PzkDnH3">
					<orgName type="full">Swiss National Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,235.00,137.09,55.76,11.07"><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
							<email>jacques.savoy@unine.chwww.unine.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Institut interfacultaire d</orgName>
								<orgName type="institution">informatique University of Neuchatel</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,297.66,137.09,76.45,11.07"><forename type="first">Pierre-Yves</forename><surname>Berger</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Institut interfacultaire d</orgName>
								<orgName type="institution">informatique University of Neuchatel</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,159.00,94.53,277.07,15.50;1,126.04,112.53,346.99,15.50">Report on CLEF-2005 Evaluation Campaign: Monolingual, Bilingual, and GIRT Information Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F7213DFE69206E8CD5738C6D87AF0E30</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.1 [Content Analysis and Indexing]: Linguistic processing. H.3.3 [Information Storage and Retrieval]: Retrieval models</term>
					<term>Relevance feedback. H.3.4 [Systems and Software]: Performance evaluation Experimentation</term>
					<term>Performance</term>
					<term>Measurement</term>
					<term>Algorithms Natural Language Processing with European Languages</term>
					<term>Bilingual Information Retrieval</term>
					<term>Digital Libraries</term>
					<term>Hungarian Language</term>
					<term>Bulgarian Language</term>
					<term>Portuguese Language</term>
					<term>French Language</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For our fifth participation in the CLEF evaluation campaigns, the first objective was to propose an effective and general stopword list along with a light stemming procedure for the Hungarian, Bulgarian and Portuguese (Brazilian) languages. Our second objective was to obtain a better picture of the relative merit of various search engines when processing documents in those languages. To do so we evaluated our scheme using two probabilistic models and nine vectorprocessing approaches. In the bilingual track, we evaluated both the machine translation and bilingual dictionary approaches to automatically translate a query submitted in English into various target languages. This year we explored new freely available translation sources, together with a combined query translation approach in order to obtain a better translation of the user's information need. Finally, using the GIRT corpora (available in English, German and Russian), we investigated variations in retrieval effectiveness when including or excluding manually assigned keywords attached to bibliographic records (mainly comprising a title and an abstract).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Since 2001 our research group has been investigating effective information retrieval (IR) techniques when handling a variety of natural languages <ref type="bibr" coords="1,230.14,566.09,58.24,11.07">(Savoy 2004a;</ref><ref type="bibr" coords="1,290.98,566.09,27.82,11.07">2005a)</ref> in order to improve both monolingual and bilingual searches. Continuing along this same stream, our participation in the CLEF 2005 evaluation campaign will target various objectives. First, our aim is to propose linguistic tools for less frequently spoken languages such as Bulgarian and Hungarian, to explore the underlying IR problems with closely related languages such as Portuguese and Brazilian, and to explore new alternatives when translating a query from one source language (English in this study) to other target languages (more precisely the French, Portuguese, Bulgarian and Hungarian languages). The domain-specific GIRT corpus presents other interesting features, namely questions related to digital libraries with a collection comprising a large number of bibliographic records.</p><p>In addition to these particular objectives, various interesting problems must be analyzed and resolved. All languages are not written with the same alphabet, and Bulgarian for example uses the Cyrillic alphabet. The presence of diacritics in others also raises certain questions that directly affect the effectiveness of IR systems. Can we simply ignore them? Do they have a real impact on mean average precision? Does the distinction between uppercase and lowercase letters really influence information retrieval systems or does this distinction need only be preserved when high search precision is required?</p><p>In our work we have assumed that the semantic content of documents (or requests) is mainly linked to nouns and adjectives, and thus an effective search system can be based on the use of an appropriate set of weighted keywords extracted from corresponding documents (or requests). Based on this assumption, we designed a set of stopword lists and light stemming procedures for certain European and Asian languages. Following our suggestion, these linguistic tools were designed to automatically remove the inflectional suffixes attached to nouns and adjectives linked to gender (masculine, feminine, neural), to number (singular or plural), and to case <ref type="bibr" coords="2,71.00,137.09,136.87,11.07">(nominative, dative, ablative, etc.)</ref>. Needless to say we were also interested in other linguistic phenomena, such as compound constructions (does an effective IR system really need to decompound them and is this linguistic phenomenon really important for the retrieval of languages other than German?)</p><p>The rest of this paper is organized as follows: Section 2 describes the main characteristics of the CLEF-2005 test-collection, Section 3 outlines the main aspects of our stopword lists and light stemming procedures. Section 4 analyses the principal features of different indexing and search strategies, and evaluates their use with the four corpora. The data fusion approaches adapted in our experiments are explained in Section 5, and Section 6 depicts our official results. Our bilingual experiments are presented and evaluated in Section 7 while Section 8 describes our experiments involving the domain-specific GIRT corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Overview of the Test-Collections</head><p>The corpora used in our experiments include newspaper and news agency articles, namely Le Monde <ref type="bibr" coords="2,488.49,286.09,22.11,11.07" target="#b3">(1994</ref><ref type="bibr" coords="2,71.00,297.09,54.67,11.07">( -1995, French), French)</ref>, SDA <ref type="bibr" coords="2,153.56,297.09,22.41,11.07" target="#b3">(1994</ref><ref type="bibr" coords="2,175.97,297.09,22.41,11.07">-1995</ref><ref type="bibr" coords="2,198.37,297.09,99.75,11.07">, French), Público (1994</ref><ref type="bibr" coords="2,298.13,297.09,22.41,11.07">-1995</ref><ref type="bibr" coords="2,320.54,297.09,109.28,11.07">, Portuguese), Folha (1994</ref><ref type="bibr" coords="2,429.82,297.09,22.42,11.07">-1995</ref><ref type="bibr" coords="2,452.24,297.09,49.79,11.07;2,71.00,308.09,86.02,11.07">, Brazilian), Magyar Hirlap (2002</ref><ref type="bibr" coords="2,157.02,308.09,101.98,11.07">, Hungarian), Sega (2002</ref><ref type="bibr" coords="2,259.00,308.09,162.96,11.07">, Bulgarian), Standart (2002, Bulgarian)</ref>. As shown in Table <ref type="table" coords="2,510.48,308.09,3.76,11.07" target="#tab_1">1</ref>, the Portuguese corpus (212.9 indexing terms / document) has a larger mean size article than the French collection (178). This mean value is relatively similar for the Bulgarian (133.7) and Hungarian (142.1) languages. It is interesting to note that even though the Hungarian collection is the smallest (105 MB), it contains the largest number of distinct indexing terms (657,132), computed after stemming.  During the indexing process in our automatic runs, we retained only the following logical sections from the original documents: &lt;TITLE&gt;, &lt;TEXT&gt;, &lt;LEAD&gt;, &lt;LEAD1&gt;, &lt;TX&gt;, &lt;LD&gt;, &lt;TI&gt; and &lt;ST&gt;. For this restriction we found 1,854 documents in the Bulgarian collection to have no indexable content (for example, they may correspond to articles containing only a picture with the tags &lt;PICTURE&gt;, &lt;IMGTEXT&gt; and &lt;IMGAUTHOR&gt;). From the topic descriptions we automatically removed certain phrases such as "Relevant document report …", "Finde Dokumente, die über …", "Keressünk olyan cikkeket, amelyek …" or "Trouver des documents qui …", etc. As shown in the Appendix, the available topics cover various subjects (e.g., "Anti-Smoking Legislation", -"Football Refereeing Disputes", or "Lottery Winnings"), including both regional ("Swiss Referendums") or international coverage ("Anti-abortion Movements").</p><formula xml:id="formula_0" coords="2,122.00,611.09,349.03,22.07">(Q#253) 239 (Q#286) 69 (Q#295) 87 (Q#290) Minimum 1 (Q#255) 2 (Q#258) 1 (Q#258) 1 (Q#272)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Stopword Lists and Stemming Procedures</head><p>In order to define general stopword lists, we first created a list of the top 200 most frequent words found in the various languages, from which some words were removed <ref type="bibr" coords="3,323.38,148.09,165.02,11.07">(e.g., police, minister, president, Magyar)</ref>. From this list of very frequent words, we added articles, pronouns, prepositions, conjunctions or very frequently occurring verb forms (e.g., to be, is, has, etc.). Based on this scheme, we created a new list for the Bulgarian and Hungarian languages (these lists are available at www.unine.ch/info/clef/). Our final stopword list contained 463 words for the French language, 761 for Hungarian, 418 for Bulgarian and 400 for Portuguese-Brazilian (we added 8 Brazilian words to our Portuguese stopword list. These eight words are usually variants with or without accents, such as "vezes" in Portuguese and "vêzes" in Brazilian).</p><p>Once high-frequency words were removed, our indexing procedure generally applied a stemming algorithm in an attempt to conflate word variants into the same stem or root. In developing such a procedure, we first wanted to remove only inflectional suffixes such as singular and plural word forms, and also feminine and masculine forms so that they would conflate to the same root.</p><p>Bulgarian involved additional morphological difficulties, given that in this language the definite article is usually represented by a suffix. For example, "mope" (sea) becomes "mopeto" (the sea) while "mopeta" (seas) becomes "mopetata" (the seas). The general noun pattern is as follows: &lt;stem&gt; &lt;plural&gt; &lt;article&gt;. Contrary to other Slavic languages (such as Russian), Bulgarian does not indicate grammatical cases by adding a suffix.</p><p>The Hungarian language shares certain similarities with the Finnish language (although both languages do not belong strictly to the same family, they can be viewed as cousins). Like Finnish, Hungarian has several number cases (usually 18) and each case has its own unambiguous form. For example, the noun "house" ("hàz") may appear as "hàz at " (accusative case, as in "(I see) the house"), "hàz akat " (accusative plural case, as in "(I see) the houses"), "hàz amat " ("… my house") or "hàz amait " ("… my houses"). In this language, the general construction used for nouns is as follows: &lt;stem&gt; &lt;plural&gt; &lt;possessive marker&gt; &lt;case&gt;. For example, for &lt;hàz&gt; a &lt;m&gt; a &lt;t&gt; in which the letter "a" is introduced to facilitate better pronunciation ("hàzmt" could be difficult to pronounce). From the IR point of view, certain linguistic aspects in Hungarian are viewed as good news. For example, a gender distinction is not attached to each noun (like in English) and adjectives are invariable, as in "… a szép hàzat" ("a beautiful house") or "… a szép hàzamat" ("my beautiful house"). Our suggested stemming procedures for these languages can be found at www.unine.ch/info/clef/. Diacritic characters are usually not present in English collections (with certain exceptions, such as "résumé" or "cliché"). For the Hungarian, and Portuguese languages, these characters were replaced by their corresponding non-accentuated letter. Removing accents may however generate some semantic ambiguity (e.g., between "kor" ("age") and "kór" ("illness"), or "ver" ("hurt") and "vér" ("blood") in Hungarian language). Finally, most European languages manifest other morphological characteristics, with compound word constructions being only one example (e.g., handgun, worldwide). Recently, <ref type="bibr" coords="3,384.11,521.09,123.91,11.07" target="#b1">Braschler &amp; Ripplinger (2004)</ref> showed that decompounding German words could significantly improve retrieval performance, and in some experiments with Hungarian where we used our decompounding algorithm <ref type="bibr" coords="3,374.10,543.09,57.36,11.07" target="#b9">(Savoy 2004b)</ref>, both compound words and their component parts were left in the documents and queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Indexing and Searching Strategies</head><p>In order to obtain a broader view of the relative merit of various retrieval models, we first adopted a binary indexing scheme in which each document (or request) was represented by a set of keywords, without any weight. To measure the similarity between documents and requests, we computed the inner product (retrieval model denoted "doc=bnn, query=bnn" or "bnn-bnn"). In order to weight the presence of each indexing term in a document surrogate (or in a query), we took the term occurrence frequency into account (denoted tfij for indexing term t j in document D i , and the corresponding retrieval model was denoted: "doc=nnn, query=nnn") or we might also account for their inverse document frequency (denoted idfj). Moreover, we might normalize each indexing weight using different weighting schemes, as is described in the Appendix.</p><p>In addition to these models based on the vector-space paradigm, we also considered probabilistic models such as the Okapi model <ref type="bibr" coords="3,172.86,714.09,91.66,11.07" target="#b6">(Robertson et al. 2000)</ref>. As a second probabilistic approach, we implemented the Prosit approach, one member of a family of models suggested by <ref type="bibr" coords="3,335.77,725.09,128.03,11.07" target="#b0">Amati &amp; van Rijsbergen (2002)</ref> and based on combining two information measures, formulated as follows:</p><formula xml:id="formula_1" coords="4,87.67,69.65,335.35,735.85">- wij = Inf 1 ij • Inf 2 ij = (1 -Prob 1 ij) • -log2[Prob 2 ij] Prob 1 ij = tfnij / (tfnij + 1) with tfnij = tfij • log2[1 + ((C • mean dl) / l i )] Prob 2 ij = [1 / (1+lj)] • [lj / (1+lj)] tfn ij with lj = tcj / n</formula><p>where wij indicates the indexing weight attached to term tj in document Di, l i the number of indexing terms included in the representation of D i , where tcj represents the number of occurrences of term tj in the collection and n the number of documents in the corpus. In our experiments, the constants b, k1, avdl, pivot, slope, C and mean dl were fixed according to the values listed in To measure the retrieval performance, we adopted non-interpolated mean average precision (MAP) (computed on the basis of 1,000 retrieved items per request by the new TREC-EVAL program). To statistically determine whether or not a given search strategy would be better than another, we applied the bootstrap methodology <ref type="bibr" coords="4,71.00,369.09,52.66,11.07" target="#b7">(Savoy 1997)</ref>. Thus, in the tables included in this paper we underlined statistically significant differences using on a two-sided non-parametric bootstrap test, and based on the MAP difference with a significance level fixed at 5%. We indexed the different collections using words as indexing units. The evaluations of our two probabilistic models and nine vector-space schemes are listed in Table <ref type="table" coords="4,303.09,624.09,5.00,11.07" target="#tab_3">3</ref> for the French and Portuguese corpus, and in Table <ref type="table" coords="4,518.00,624.09,5.00,11.07" target="#tab_4">4</ref> for the Bulgarian and Hungarian collection. In these tables, the best performance under given conditions (with the same indexing scheme and the same collection) is listed in bold type. Based on the best performance, this approach is also used as a baseline for our statistical testing. The underlined results therefore indicate that the difference in mean average precision can be viewed as statistically significant when compared to the best system value. As depicted in Table <ref type="table" coords="4,187.08,679.09,3.76,11.07" target="#tab_3">3</ref>, the Okapi model was found to be the best IR model for French and Portuguese collection. For these two corpora however, the difference in MAP between the various IR models is usually statistically significant. As shown in Table <ref type="table" coords="4,248.89,701.09,5.00,11.07" target="#tab_4">4</ref> (and in Table <ref type="table" coords="4,313.34,701.09,4.92,11.07">A</ref>.4 in the Appendix) similar conclusions can be drawn for the Bulgarian and Hungarian collection. In this case the best performing system was the Prosit model for Bulgarian, and the Okapi probabilistic approach for Hungarian. Moreover five IR models were shown to have similar statistical performance levels (Okapi, Prosit, "doc=Lnu, query=ltc", "doc=dtu, query=dtn", "doc=atn, query=ntc").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mean average precision</head><p>Moreover, the data in these tables shows that when the number of search terms increases (from T, TD to TDN), retrieval effectiveness usually increases also (except for the "doc=bnn, query=bnn" or "doc=nnn, query=nnn" IR models). From an analysis of the five best retrieval schemes shown in Tables <ref type="table" coords="5,450.20,93.09,5.00,11.07" target="#tab_3">3</ref> and<ref type="table" coords="5,474.98,93.09,5.00,11.07" target="#tab_4">4</ref> (namely, Prosit, Okapi, "doc=Lnu, query=ltc", "doc=dtu, query=dtn" and "doc=atn, query=ntc"), the improvement is around 33.4% when comparing title-only (or T) with TDN queries for the Portuguese collection, 31.3% when comparing the French corpus, 21% for Hungarian (see Table <ref type="table" coords="5,316.99,126.09,4.91,11.07">A</ref>.4 in the Appendix), and 6.4% for the Bulgarian collection. With the Hungarian collection, we automatically decompounded long words (composed by more than 8 characters) using our own algorithm <ref type="bibr" coords="5,219.50,369.09,57.53,11.07" target="#b9">(Savoy 2004b)</ref>. In this experiment, both the compound words and their components were left in documents and queries (under the label "TD-decomp" in Table <ref type="table" coords="5,424.68,380.09,3.61,11.07" target="#tab_4">4</ref>). Using the TD queries and the Okapi model, we achieved a MAP of 0.3391, reflecting a degradation of -3.1% when compared to an indexing approach that did not use decompounding. Based on the five best retrieval schemes, the mean degradation is around -1.6%. Using a lighter stemmer (less rules) for the Hungarian language (retrieval performance depicted under the label "TD-light" in Table <ref type="table" coords="5,303.22,424.09,3.60,11.07" target="#tab_4">4</ref>), the mean difference in MAP over the five best retrieval schemes is around 2% and in favor of a more complex stemming approach. It was observed that pseudo-relevance feedback (PRF or blind-query expansion) seemed to be a useful technique for enhancing retrieval effectiveness. In this study, we adopted Rocchio's approach <ref type="bibr" coords="5,447.97,731.09,46.06,11.07;5,71.00,742.09,36.66,11.07" target="#b2">(Buckley et al. 1996)</ref> with a = 0.75, b = 0.75, whereby the system was allowed to add m terms extracted from the k best ranked documents from the original query. To evaluate this proposition, we used the Okapi and the Prosit probabilistic models and enlarged the query by the 10 to 50 terms retrieved from the 3 to 10 best-ranked articles.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mean average precision</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mean average precision</head><p>Table 5 depicts our best results using pseudo-relevance feedback technique for the Okapi model and demonstrates that the optimal parameter setting seemed to be collection-dependant. Moreover, performance improvement also seemed to be collection dependant (or language dependant), with the French corpus showing an increase of +9.2% (from a mean average precision of 0.3754 to 0.4099), +5.2% for the Portuguese collection (from 0.3477 to 0.3668), +1.3% for the Hungarian collection (from 0.3501 to 0.3545), and +0.8% for the Bulgarian corpus (from 0.2704 to 0.2726). Table <ref type="table" coords="6,273.54,154.09,5.00,11.07" target="#tab_6">6</ref> shows how similar conclusions can be drawn using the Prosit model. In this case however, the blind query expansion depicted a greater improvement for all collections (e.g., for the French corpus, an increase of +14.3%, from a mean average precision of 0.3696 to 0.4225). In both Tables <ref type="table" coords="6,120.74,187.09,5.00,11.07" target="#tab_5">5</ref> and<ref type="table" coords="6,145.42,187.09,3.75,11.07" target="#tab_6">6</ref>, the baseline used for our statistical testing was the MAP, calculated before the query was automatically expanded. In this case, it is interesting to note that our statistical testing cannot always detect a significant difference in MAP before and after blind query expansion, specially for the Bulgarian and Hungarian collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Data Fusion</head><p>It is assumed that combining different search models should improve retrieval effectiveness, due to the fact that different document representations might retrieve different pertinent items and thus increase the overall recall <ref type="bibr" coords="6,71.00,297.09,91.46,11.07" target="#b12">(Vogt &amp; Cottrell 1999)</ref>. On the other hand, when combining different search schemes, we might suppose that these various IR strategies are more likely to rank the same relevant items higher on the list than they would for non-relevant documents (viewed as outliers). Thus, combining them could improve retrieval effectiveness by ranking pertinent documents higher and ranking non-relevant items lower. Based on our previous studies <ref type="bibr" coords="6,71.00,341.09,53.94,11.07" target="#b9">(Savoy 2004b</ref><ref type="bibr" coords="6,132.14,341.09,26.00,11.07">(Savoy , 2005a))</ref>, this expected positive effect does not always work.</p><p>In this current study we combine only the two probabilistic models because they usually depict the best or one of the best retrieval performances <ref type="bibr" coords="6,224.76,369.09,53.72,11.07" target="#b9">(Savoy 2004b</ref><ref type="bibr" coords="6,285.56,369.09,25.93,11.07">(Savoy , 2005a))</ref>. To achieve this we evaluated various fusion operators (see Table <ref type="table" coords="6,155.05,380.09,5.00,11.07">7</ref> for a list of their precise descriptions). For example, the Sum RSV operator indicates that the combined document score (or the final retrieval status value) is simply the sum of the retrieval status value (RSVk) of the corresponding document Dk computed by each single indexing scheme <ref type="bibr" coords="6,415.99,402.09,78.70,11.07" target="#b3">(Fox &amp; Shaw 1994)</ref>. Table <ref type="table" coords="6,96.44,413.09,5.00,11.07">7</ref> thus illustrates how both the Norm Max and Norm RSV apply a normalization procedure when combining document scores. When combining the retrieval status value (RSVk) for various indexing schemes and in order to favor some more efficient retrieval schemes, we could multiply the document score by a constant ai (usually equal to 1) reflecting the differences in retrieval performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sum RSV SUM (ai . RSVk)</head><p>Norm Max SUM (ai . (RSVk / Max i ))</p><formula xml:id="formula_2" coords="6,113.00,494.09,373.34,25.90">Norm RSV SUM [ai . ((RSVk -Min i ) / (Max i -Min i ))] Z-Score ai . [((RSVk -Mean i ) / Stdev i ) + d i ] with d i = [(Mean i -Min i ) / Stdev i ]</formula><p>Table <ref type="table" coords="6,197.49,529.09,3.91,11.07">7</ref>: Data fusion combination operators used in this study</p><p>In addition to using these data fusion operators, we also considered the round-robin approach, wherein we took one document in turn from all individual lists and removed any duplicates, retaining the most highly ranked instance. Finally we suggested merging the retrieved documents according to the Z-Score, computed for each result list. Within this scheme, for the ith result list, we needed to compute the average RSVk value (denoted Mean i ) and the standard deviation (denoted Stdev i ). Based on these we could then normalize the retrieval status value for each document Dk provided by the ith result list by computing the deviation of RSVk with respect to the mean (Mean i ). In Table <ref type="table" coords="6,247.80,612.09,3.77,11.07">7</ref>, Min i (Max i ) denotes the minimal (maximal) RSV value in the ith result list. Of course, we might also weight the relative contribution of each retrieval scheme by assigning a different ai value to each retrieval model. Table <ref type="table" coords="6,110.38,651.09,5.00,11.07">8</ref> depicts the evaluation of various data fusion operators, comparing them to the single approach using the Okapi and the Prosit probabilistic models. From this data, we can see that combining two IR models might improve retrieval effectiveness. When combining two retrieval models, the Z-Score scheme tended to perform the best. In Table <ref type="table" coords="6,146.08,684.09,3.75,11.07">8</ref>, under the heading "Z-ScoreW", we attached a weight of 1.5 to the Prosit model (depicted in bold in the second line), and 1 to the Okapi scheme. Using the Prosit performance as a baseline, our statistical testing was not usually able to detect any significant enhancement when combining two IR models.</p><p>Moreover, the query terms could be preprocessed in order to obtain their part-of-speech (PoS) information (using www.ims.unistuttgart.de/projekte/corplex/TreeTagger/). Using this information, we could find the corresponding lemma and use it instead of the surface word before searching in the bilingual dictionaries. Once this lemmatizing procedure was done, we added the term "+ PoS" in the corresponding run label. Table <ref type="table" coords="8,492.99,248.09,10.01,11.07" target="#tab_7">10</ref> contains an example of this query preprocessing, showing how the plural form was removed (e.g., "disputes" into "dispute") and how various verb forms were transformed into their lexical forms (e.g., "made" into "make" or "refereeing" into "referee"). &lt;num&gt; C263 &lt;/num&gt; &lt;title&gt; Football Refereeing Disputes &lt;/title&gt; &lt;desc&gt; Find documents in which decisions made by a referee during a football match are criticised. &lt;/desc&gt; &lt;narr&gt; Relevant documents report on football (soccer) matches in which the referee made some disputable or disputed decision. &lt;/narr&gt; &lt;num&gt; C263 &lt;/num&gt; &lt;title&gt; Football referee dispute &lt;/title&gt; &lt;desc&gt; find document in which decision make by a referee during a football match be criticize . &lt;/desc&gt; &lt;narr&gt; relevant document report on football (soccer) match in which the referee make some disputable or disputed decision. &lt;/narr&gt;  <ref type="bibr" coords="8,419.95,442.09,35.07,11.07">(bottom)</ref> in which the modifications are underlined</p><p>Table <ref type="table" coords="8,110.40,470.09,10.01,11.07" target="#tab_9">11</ref> shows the mean average precision obtained using the various MT tools and the Okapi probabilistic model, while Table <ref type="table" coords="8,151.83,481.09,10.02,11.07" target="#tab_2">12</ref> depicts the same information when using bilingual dictionaries. Of course, all tools are not always available for each language and thus various entries are missing (as shown in Tables <ref type="table" coords="8,457.90,492.09,10.01,11.07" target="#tab_9">11</ref> and<ref type="table" coords="8,487.49,492.09,8.34,11.07" target="#tab_2">12</ref>, indicated by the label "N/A"). As expected, only a few translation tools are available for translating from English to either Bulgarian or Hungarian languages.  From this data, we can see that for the French collection the best translation is obtained by Google and for the Portuguese corpus by Promt. The FreeTranslation and Promt MT systems usually obtain satisfactory retrieval performances for these two languages (around 79.3% of the MAP obtained by the corresponding</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 12: Mean average precision of various bilingual dictionaries (TD queries, Okapi model)</head><p>Table <ref type="table" coords="9,110.25,368.09,10.00,11.07" target="#tab_10">13</ref> shows the retrieval effectiveness for various query translation combinations when using the Okapi probabilistic model. The top part of the table indicates the exact query translation combination used while the bottom part shows the mean average precision obtained with our combined query translation approach. When selecting which query translations were to be combined, we took our prior findings <ref type="bibr" coords="9,407.02,401.09,54.09,11.07">(Savoy 2005a</ref>) and feelings into consideration when selecting best translation tools. The resulting retrieval performances depicted in Table <ref type="table" coords="9,96.39,423.09,10.01,11.07" target="#tab_10">13</ref> are sometimes better than the best single translation scheme, as indicated in the row labeled "Best single" (e.g., the strategy "Comb 1" for French, or the strategies "Comb 3" or "Comb 5" for Portuguese, "Comb 2" for Bulgarian, and "Comb 5" for Hungarian). Statistically however these combined query translation approaches did not perform better than the best single translation tool (except "Comb 3" with the Portuguese corpus). Finally, Table <ref type="table" coords="10,144.24,284.09,10.02,11.07" target="#tab_11">14</ref> lists the parameter settings used for 12 official runs in the bilingual task. Each experiment uses queries written in English to retrieve documents in the other target languages. Before combining the result lists we automatically expanded the translated queries using a pseudo-relevance feedback method (Rocchio's approach in the present case).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mean average precision (</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Monolingual Domain-Specific Retrieval: GIRT</head><p>In the domain-specific retrieval task (called GIRT), the three available corpora are composed of bibliographic records extracted from various sources in the social sciences domain, see <ref type="bibr" coords="10,363.95,383.09,48.75,11.07" target="#b4">(Kluck 2004</ref>) for a more complete description of these corpora. A few statistics on these collections are given in <ref type="table" coords="10,387.07,394.09,33.75,11.07" target="#tab_13">Table 15</ref>  In total theses collections contain 397,218 documents or about 590 MB, and for the most part are written in German. A typical record in this collection is composed of a title, an abstract, and a set of manually assigned keyword (see Table <ref type="table" coords="11,152.14,361.09,9.99,11.07" target="#tab_14">16</ref> for English examples and Table <ref type="table" coords="11,293.91,361.09,9.99,11.07" target="#tab_15">17</ref> for their corresponding German records). Additional information such as authors' name, publication date, or the language in which the bibliographic notice is written may of course be less important from an IR perspective but they are made available. As depicted in the Appendix, the topics in this domain-specific collection cover a variety of themes (e.g., "Electoral Behaviour", "New Art", "Soccer and Society", or "Churches and Money").  Based on the GIRT corpus we are therefore able to evaluate the impact of manually assigned descriptors as compared to an indexing scheme, based only on the information contained in the corresponding article's title and abstract sections. To tackle this question we evaluated the GIRT collection using all sections (denoted "all" in Table <ref type="table" coords="12,106.82,309.09,7.93,11.07" target="#tab_16">18</ref>), or only using titles and abstracts from bibliographic records (under the label "TI &amp; AB"). In related research using the Amaryllis French corpus, we found that the "TI &amp; AB" indexing scheme presents a loss of around 45% in mean average precision <ref type="bibr" coords="12,258.00,331.09,54.40,11.07" target="#b11">(Savoy 2005b</ref>) when compared to the "all" approach. In our experiments, the decrease in mean average precision is around -14.4% for the German corpus and -36.5% for the English GIRT collection.</p><p>Our 12 official runs in the monolingual GIRT task are described in Table <ref type="table" coords="12,381.91,370.09,8.34,11.07" target="#tab_17">19</ref>. For each language, we submitted the first run using a data fusion operator ("Z-ScoreW" in this case). For all runs, we automatically expanded the queries using a blind relevance feedback method (Rocchio in our experiments), hoping to improve retrieval effectiveness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run name</head><p>Language </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9">Conclusion</head><p>In this sixth CLEF evaluation campaign, we proposed a general stopword list and a light stemming procedure (removing only inflections attached to nouns and adjectives) for the Bulgarian and Hungarian languages (see Table <ref type="table" coords="12,96.14,679.09,5.00,11.07" target="#tab_4">4</ref> and<ref type="table" coords="12,120.45,679.09,29.24,11.07">Table A</ref> <ref type="bibr" coords="12,149.69,679.09,12.29,11.07">.4)</ref>. In order to enhance retrieval performance, we suggested using a data fusion approach based on the Z-Score in order to combine the two probabilistic IR models (see Table <ref type="table" coords="12,415.17,690.09,3.62,11.07">8</ref>). The results of this evaluation campaign seem to indicate that for the French and Portuguese languages such an approach proved to be effective (Table <ref type="table" coords="12,149.05,712.09,3.61,11.07">8</ref>). The use of this search strategy did however require the building of two inverted files and doubling the search time required. For both the Bulgarian and Hungarian languages, more experiments are needed to confirm our first evaluations (especially in the design of a light stemming procedure for the Hungarian language, see Table <ref type="table" coords="12,153.14,745.09,3.62,11.07" target="#tab_4">4</ref>). For all languages however, the probabilistic models (either Okapi or Prosit) usually result in better retrieval performances than do other vector-processing approaches (see Tables <ref type="table" coords="13,445.91,71.09,7.47,11.07" target="#tab_3">3,</ref><ref type="table" coords="13,455.84,71.09,3.74,11.07" target="#tab_4">4</ref>, and 18 for the GIRT corpora), while the data fusion approach did not always improve mean average precision. The automatic decompounding of Hungarian words and its impact in IR remains an open question and our preliminary experiments did not provide a clear and precise answer (our decompounding scheme slightly decreased retrieval performance, as shown in Table <ref type="table" coords="13,201.26,115.09,3.61,11.07" target="#tab_4">4</ref>).</p><p>As in previous evaluation campaigns we were able to confirm that pseudo-relevance feedback based on Rocchio's model usually did improve mean average precision statistics for the French and Portuguese language, even though this improvement is not always statistically significant. For the other languages (Bulgarian and Hungarian), this blind query expansion did not improve mean average precision from the statistics point of view (Tables <ref type="table" coords="13,103.58,176.09,5.00,11.07" target="#tab_5">5</ref> and<ref type="table" coords="13,128.16,176.09,3.62,11.07" target="#tab_6">6</ref>).</p><p>In the bilingual task, the freely available translation tools performed at a reasonable level for both the French and Portuguese languages (based on the three best translation tools, the MAP compared to the monolingual search is around 85% for the French language and 72.6% for the Portuguese). For less frequently used languages such as Bulgarian and Hungarian, the freely available translation tools (either the bilingual dictionary or the MT system) did not perform well. The mean average precision decreased by more than 50% (for Hungarian) to 80% (for Bulgarian), when compared to a monolingual search.</p><p>In the GIRT task (Table <ref type="table" coords="13,183.13,265.09,7.89,11.07" target="#tab_16">18</ref>), we were able to measure the retrieval effectiveness by assigning keywords manually, and the presence of this information improved MAP by around 36.5% for the English corpus and 14.4% for the German collection.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="11,77.00,428.09,163.06,11.07;11,77.00,439.09,432.17,11.07;11,77.00,450.09,116.07,11.07;11,77.00,461.09,114.04,11.07;11,77.00,472.09,121.00,11.07;11,77.00,483.09,106.01,11.07;11,77.00,494.09,159.01,11.07;11,77.00,505.09,215.05,11.07;11,77.00,516.09,208.03,11.07;11,77.00,527.09,230.05,11.07;11,77.00,538.09,137.03,11.07;11,77.00,549.09,151.03,11.07;11,77.00,560.09,195.03,11.07;11,77.00,571.09,427.21,11.07;11,77.00,582.09,405.00,11.07;11,77.00,593.09,429.19,11.07;11,77.00,604.09,384.25,11.07;11,77.00,615.09,397.21,11.07;11,77.00,626.09,286.16,11.07;11,77.00,637.09,163.06,11.07;11,77.00,648.09,400.27,11.07;11,77.00,659.09,330.01,11.07;11,77.00,670.09,128.96,11.07;11,77.00,681.09,121.00,11.07;11,77.00,692.09,106.01,11.07;11,77.00,703.09,187.04,11.07;11,77.00,714.09,185.04,11.07"><head></head><label></label><figDesc>&lt;DOC&gt; &lt;DOCNO&gt; GIRT-DE19909343 &lt;TITLE-DE&gt; Die sozioökonomische Transformation einer Region : Das Bergische Land von 1930 bis 1960 &lt;AUTHOR&gt; Henne, Franz J. &lt;AUTHOR&gt; Geyer, Michael &lt;PUBLICATION-YEAR&gt; 1990 &lt;LANGUAGE-CODE&gt; DE &lt;CONTROLLED-TERM-DE&gt; Rheinland &lt;CONTROLLED-TERM-DE&gt; historische Entwicklung &lt;CONTROLLED-TERM-DE&gt; regionale Entwicklung &lt;CONTROLLED-TERM-DE&gt; sozioökonomische Faktoren &lt;METHOD-TERM-DE&gt; historisch &lt;METHOD-TERM-DE&gt; Aktenanalyse &lt;CLASSIFICATION-TEXT-DE&gt; Sozialgeschichte &lt;ABSTRACT-DE&gt; Die Arbeit hat das Ziel, anhand einer regionalen Studie die Entstehung des "modernen" fordistischen Wirtschaftssystems und des sozialen Systems im Zeitraum zwischen 1930 und 1960 zu beleuchten; dabei geht es auch um das Studium des "Sozial-imaginären", der Veränderung von Bewußtsein und Selbst-Verständnis von Arbeitern durch das Erlebnis und die Erfahrung der Depression, des Nationalsozialismus und der Nachkriegszeit, welches sich in den 1950er Jahren gemeinsam mit der wirtschaftlichen Veränderung zu einem neuen "System" zusammenfügt. &lt;DOC&gt; &lt;DOCNO&gt; GIRT-DE19909106 &lt;TITLE-DE&gt; Politiker einer ethnischen Gruppe im Kongreß: Deutsch-amerikanische Fallstudien zur Interaktion von Ethnizität, Nationalität und demokratischer Regierung, 1865-1930 &lt;AUTHOR&gt; Adams, Willi Paul &lt;PUBLICATION-YEAR&gt; 1990 &lt;LANGUAGE-CODE&gt; DE &lt;CONTROLLED-TERM-DE&gt; ethnische Gruppe &lt;CONTROLLED-TERM-DE&gt; Nordamerika …</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,204.00,643.09,187.04,11.07"><head>Table 1 :</head><label>1</label><figDesc>CLEF 2005 test-collection statistics</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,71.00,158.50,434.19,171.66"><head>Table 2 :</head><label>2</label><figDesc>Table 2 (the German, English and Russian languages are used in the GIRT experiments). Parameter settings for the various test collections</figDesc><table coords="4,131.00,187.09,325.00,122.07"><row><cell></cell><cell></cell><cell>Okapi</cell><cell></cell><cell>Prosit</cell><cell></cell></row><row><cell>Language</cell><cell>b</cell><cell>k1</cell><cell>avdl</cell><cell>C</cell><cell>mean dl</cell></row><row><cell>French</cell><cell>0.7</cell><cell>1.5</cell><cell>600</cell><cell>1.25</cell><cell>182</cell></row><row><cell>Portuguese</cell><cell>0.7</cell><cell>1.5</cell><cell>700</cell><cell>1.7</cell><cell>250</cell></row><row><cell>Bulgarian</cell><cell>0.75</cell><cell>1.2</cell><cell>750</cell><cell>1.25</cell><cell>134</cell></row><row><cell>Hungarian</cell><cell>0.75</cell><cell>1.2</cell><cell>750</cell><cell>1.25</cell><cell>150</cell></row><row><cell>German</cell><cell>0.5</cell><cell>1.2</cell><cell>500</cell><cell>1.75</cell><cell>90</cell></row><row><cell>English</cell><cell>0.9</cell><cell>4</cell><cell>750</cell><cell>1.5</cell><cell>35</cell></row><row><cell>Russian</cell><cell>0.75</cell><cell>1.2</cell><cell>100</cell><cell>1.5</cell><cell>25</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,77.00,421.09,441.03,186.07"><head>Table 3 :</head><label>3</label><figDesc>Mean average precision of various single searching strategies (French &amp; Portuguese languages)</figDesc><table coords="4,77.00,421.09,441.03,165.07"><row><cell>Query Model \ # of queries</cell><cell cols="2">French T 50 queries 50 queries French TD</cell><cell>French TDN 50 queries</cell><cell cols="3">Portuguese Portuguese Portuguese T TD TDN 50 queries 50 queries 50 queries</cell></row><row><cell>Prosit</cell><cell>0.2895</cell><cell>0.3696</cell><cell>0.3961</cell><cell>0.2755</cell><cell>0.3438</cell><cell>0.3697</cell></row><row><cell>doc=Okapi, query=npn</cell><cell>0.3029</cell><cell>0.3754</cell><cell>0.3948</cell><cell>0.2873</cell><cell>0.3477</cell><cell>0.3719</cell></row><row><cell>doc=Lnu, query=ltc</cell><cell>0.2821</cell><cell>0.3437</cell><cell>0.3703</cell><cell>0.2611</cell><cell>0.3338</cell><cell>0.3517</cell></row><row><cell>doc=dtu, query=dtn</cell><cell>0.2726</cell><cell>0.3365</cell><cell>0.3633</cell><cell>0.2571</cell><cell>0.3221</cell><cell>0.3338</cell></row><row><cell>doc=atn, query=ntc</cell><cell>0.2809</cell><cell>0.3328</cell><cell>0.3507</cell><cell>0.2458</cell><cell>0.3076</cell><cell>0.3433</cell></row><row><cell>doc=ltn, query=ntc</cell><cell>0.2588</cell><cell>0.3066</cell><cell>0.3232</cell><cell>0.2149</cell><cell>0.2535</cell><cell>0.2740</cell></row><row><cell>doc=ntc, query=ntc</cell><cell>0.1862</cell><cell>0.2175</cell><cell>0.2335</cell><cell>0.1553</cell><cell>0.1868</cell><cell>0.2221</cell></row><row><cell>doc=ltc, query=ltc</cell><cell>0.1916</cell><cell>0.2363</cell><cell>0.2611</cell><cell>0.1625</cell><cell>0.2234</cell><cell>0.2543</cell></row><row><cell>doc=lnc, query=ltc</cell><cell>0.2050</cell><cell>0.2616</cell><cell>0.2953</cell><cell>0.1811</cell><cell>0.2475</cell><cell>0.2950</cell></row><row><cell>doc=bnn, query=bnn</cell><cell>0.1153</cell><cell>0.0937</cell><cell>0.0514</cell><cell>0.1309</cell><cell>0.1322</cell><cell>0.0900</cell></row><row><cell>doc=nnn, query=nnn</cell><cell>0.1148</cell><cell>0.0987</cell><cell>0.0748</cell><cell>0.0630</cell><cell>0.0639</cell><cell>0.0453</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,77.00,167.09,439.02,185.07"><head>Table 4 :</head><label>4</label><figDesc>Mean average precision of various single searching strategies (Bulgarian &amp; Hungarian language)</figDesc><table coords="5,77.00,167.09,439.02,164.07"><row><cell>Query Model \ # of queries</cell><cell cols="2">Bulgarian T 49 queries 49 queries Bulgarian TD</cell><cell>Bulgarian TDN 49 queries</cell><cell>Hungarian TD 50 queries</cell><cell cols="2">Hungarian Hungarian TD-decomp TD-light 50 queries 50 queries</cell></row><row><cell>Prosit doc=Okapi, query=npn</cell><cell>0.2594 0.2307</cell><cell>0.2953 0.2704</cell><cell>0.2655 0.2459</cell><cell>0.3420 0.3501</cell><cell>0.3390 0.3391</cell><cell>0.3359 0.3410</cell></row><row><cell>doc=Lnu, query=ltc doc=dtu, query=dtn</cell><cell>0.2238 0.2255</cell><cell>0.2679 0.2551</cell><cell>0.2583 0.2364</cell><cell>0.3301 0.3401</cell><cell>0.3273 0.3341</cell><cell>0.3249 0.3280</cell></row><row><cell>doc=atn, query=ntc</cell><cell>0.2277</cell><cell>0.2605</cell><cell>0.2411</cell><cell>0.3215</cell><cell>0.3179</cell><cell>0.3199</cell></row><row><cell>doc=ltn, query=ntc</cell><cell>0.1650</cell><cell>0.1999</cell><cell>0.1870</cell><cell>0.2853</cell><cell>0.2820</cell><cell>0.2856</cell></row><row><cell>doc=ntc, query=ntc</cell><cell>0.1758</cell><cell>0.1940</cell><cell>0.2052</cell><cell>0.2208</cell><cell>0.2099</cell><cell>0.2245</cell></row><row><cell>doc=ltc, query=ltc</cell><cell>0.2008</cell><cell>0.2323</cell><cell>0.2372</cell><cell>0.2484</cell><cell>0.2423</cell><cell>0.2482</cell></row><row><cell>doc=lnc, query=ltc</cell><cell>0.2036</cell><cell>0.2485</cell><cell>0.2445</cell><cell>0.2395</cell><cell>0.2424</cell><cell>0.2421</cell></row><row><cell>doc=bnn, query=bnn</cell><cell>0.0918</cell><cell>0.0689</cell><cell>0.0309</cell><cell>0.1424</cell><cell>0.1457</cell><cell>0.1432</cell></row><row><cell>doc=nnn, query=nnn</cell><cell>0.0774</cell><cell>0.0660</cell><cell>0.0354</cell><cell>0.0875</cell><cell>0.0824</cell><cell>0.1047</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="5,80.00,467.09,430.00,226.07"><head>Table 5 :</head><label>5</label><figDesc>Mean average precision using blind-query expansion (Okapi model)</figDesc><table coords="5,80.00,467.09,430.00,226.07"><row><cell>Query TD Model</cell><cell>French 50 queries</cell><cell>Portuguese 50 queries</cell><cell>Bulgarian 49 queries</cell><cell>Hungarian 50 queries</cell></row><row><cell>Okapi</cell><cell>0.3754</cell><cell>0.3477</cell><cell>0.2704</cell><cell>0.3501</cell></row><row><cell>k doc. / m terms</cell><cell>3/10 0.3967</cell><cell>3/15 0.3656</cell><cell>3/10 0.2534</cell><cell>3/10 0.3545</cell></row><row><cell></cell><cell>5/15 0.4034</cell><cell>5/15 0.3668</cell><cell>5/10 0.2626</cell><cell>5/10 0.3513</cell></row><row><cell></cell><cell>10/15 0.4099</cell><cell>10/15 0.3626</cell><cell>5/20 0.2586</cell><cell>5/15 0.3490</cell></row><row><cell></cell><cell>10/20 0.4075</cell><cell>10/20 0.3601</cell><cell>10/15 0.2726</cell><cell>10/15 0.3492</cell></row><row><cell></cell><cell></cell><cell cols="2">Mean average precision</cell><cell></cell></row><row><cell>Query TD Model</cell><cell>French 50 queries</cell><cell>Portuguese 50 queries</cell><cell>Bulgarian 49 queries</cell><cell>Hungarian 50 queries</cell></row><row><cell>Prosit</cell><cell>0.3696</cell><cell>0.3438</cell><cell>0.2953</cell><cell>0.3420</cell></row><row><cell>k doc. / m terms</cell><cell>3/10 0.3898</cell><cell>3/20 0.3645</cell><cell>3/10 0.2897</cell><cell>3/50 0.3940</cell></row><row><cell></cell><cell>3/15 0.3959</cell><cell>5/30 0.3818</cell><cell>3/15 0.3026</cell><cell>5/20 0.3649</cell></row><row><cell></cell><cell>5/10 0.4004</cell><cell>5/50 0.3744</cell><cell>5/10 0.3091</cell><cell>5/50 0.3764</cell></row><row><cell></cell><cell>5/50 0.3987</cell><cell>10/30 0.3953</cell><cell>5/15 0.2966</cell><cell>10/20 0.3530</cell></row><row><cell></cell><cell>10/50 0.4225</cell><cell>10/50 0.3864</cell><cell>10/15 0.2852</cell><cell>10/30 0.3672</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="5,141.00,703.09,313.02,11.07"><head>Table 6 :</head><label>6</label><figDesc>Mean average precision using blind-query expansion (Prosit model)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="8,141.00,442.09,276.40,11.07"><head>Table 10 :</head><label>10</label><figDesc>Example of a query before (top) and after PoS processing</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="8,93.00,702.09,410.01,11.07"><head>Table 11 :</head><label>11</label><figDesc>Mean average precision of various machine translation systems (TD queries, Okapi model)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="9,74.17,486.09,448.87,242.07"><head>Table 13 :</head><label>13</label><figDesc>Mean average precision of various combined translation devices (TD queries, Okapi model)</figDesc><table coords="9,372.45,486.09,49.64,11.07"><row><cell>% of change)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" coords="10,137.00,267.09,322.02,11.07"><head>Table 14 :</head><label>14</label><figDesc>Description and mean average precision of our official bilingual runs</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" coords="10,142.00,394.09,289.03,281.07"><head></head><label></label><figDesc>.</figDesc><table coords="10,142.00,413.09,289.03,262.07"><row><cell></cell><cell>German</cell><cell>English</cell><cell>Russian</cell></row><row><cell>Size (in MB) # of documents # of distinct terms</cell><cell>326 MB 151,319 698,638</cell><cell>199 MB 151,319 151,181</cell><cell>65 MB 94,581 131,231</cell></row><row><cell cols="3">Number of distinct indexing terms / document Mean 70.83 107.9 Standard deviation 32.4 94.59 Median 68 77 Maximum 386 1,422 Minimum 2 2</cell><cell>18.86 26.8 9 567 2</cell></row><row><cell cols="2">Number of indexing terms / document Mean 89.61 Standard deviation 44.5 Median 84 Maximum 629 Minimum 4</cell><cell>142.1 139.84 95 4,984 2</cell><cell>23.79 41.48 9 1,111 3</cell></row><row><cell>Number of queries Number rel. items Mean rel./ request Standard deviation Median Maximum Minimum</cell><cell>25 2,682 107.28 91.654 75 318 (Q#150) 8 (Q#129)</cell><cell>25 2,105 84.2 69.109 54 242 (Q#150) 6 (Q#129)</cell><cell>25 831 33.24 41.95 12 138 (Q#139) 1 (Q#146)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13" coords="10,189.00,685.09,218.04,11.07"><head>Table 15 :</head><label>15</label><figDesc>CLEF 2005 GIRT test collection statistics</figDesc><table coords="11,77.00,77.09,437.96,231.07"><row><cell>&lt;DOC&gt; &lt;DOCNO&gt; GIRT-EN19901932 &lt;TITLE-EN&gt; The Socio-Economic Transformation of a Region : the Bergische Land from 1930 to 1960 &lt;AUTHOR&gt; Henne, Franz J. &lt;AUTHOR&gt; Geyer, Michael &lt;PUBLICATION-YEAR&gt; 1990 &lt;LANGUAGE-CODE&gt; EN &lt;CONTROLLED-TERM-EN&gt; Rhenish Prussia &lt;CONTROLLED-TERM-EN&gt; historical development &lt;CONTROLLED-TERM-EN&gt; regional development &lt;CONTROLLED-TERM-EN&gt; socioeconomic factors &lt;METHOD-TERM-EN&gt; historical &lt;METHOD-TERM-EN&gt; document analysis &lt;CLASSIFICATION-TEXT-EN&gt; Social History &lt;DOC&gt; &lt;DOCNO&gt; GIRT-EN19902732 &lt;TITLE-EN&gt; Ethnic Politicians in Congress: German-American Case Studies on the Interaction of Ethnicity, Nationality and Democratic Government 1865-1930 &lt;AUTHOR&gt; Adams, Willi Paul &lt;PUBLICATION-YEAR&gt; 1990 &lt;LANGUAGE-CODE&gt; EN &lt;CONTROLLED-TERM-EN&gt; ethnic group &lt;CONTROLLED-TERM-EN&gt; North America …</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14" coords="11,84.00,323.50,428.02,10.00"><head>Table 16 :</head><label>16</label><figDesc>Examples of two bibliographic notices written in English from originals available in German</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15" coords="11,162.00,739.09,272.02,11.07"><head>Table 17 :</head><label>17</label><figDesc>Original of two bibliographic notices written in German</figDesc><table coords="12,105.00,72.09,383.02,177.07"><row><cell></cell><cell></cell><cell cols="3">Mean average precision</cell><cell></cell></row><row><cell>Query TD Model \ # of queries</cell><cell>German all 25 queries</cell><cell>German TI &amp; AB 25 queries</cell><cell cols="2">English all 25 queries 25 queries English TI &amp; AB</cell><cell>Russian all 25 queries</cell></row><row><cell>Prosit</cell><cell>0.4249</cell><cell>0.3659</cell><cell>0.4645</cell><cell>0.2948</cell><cell>0.2270</cell></row><row><cell>doc=Okapi, query=npn</cell><cell>0.4353</cell><cell>0.3645</cell><cell>0.4604</cell><cell>0.2854</cell><cell>0.2742</cell></row><row><cell>doc=Lnu, query=ltc</cell><cell>0.3977</cell><cell>0.3307</cell><cell>0.4234</cell><cell>0.2712</cell><cell>0.2577</cell></row><row><cell>doc=dtu, query=dtn</cell><cell>0.3789</cell><cell>0.3236</cell><cell>0.3936</cell><cell>0.2738</cell><cell>0.3003</cell></row><row><cell>doc=atn, query=ntc</cell><cell>0.3914</cell><cell>0.3458</cell><cell>0.4102</cell><cell>0.2681</cell><cell>0.2695</cell></row><row><cell>doc=ltn, query=ntc</cell><cell>0.3724</cell><cell>0.3146</cell><cell>0.3448</cell><cell>0.2158</cell><cell>0.2636</cell></row><row><cell>doc=ntc, query=ntc</cell><cell>0.2765</cell><cell>0.2452</cell><cell>0.2859</cell><cell>0.2023</cell><cell>0.1393</cell></row><row><cell>doc=ltc, query=ltc</cell><cell>0.2926</cell><cell>0.2571</cell><cell>0.3095</cell><cell>0.1997</cell><cell>0.1248</cell></row><row><cell>doc=lnc, query=ltc</cell><cell>0.3364</cell><cell>0.2757</cell><cell>0.3446</cell><cell>0.1855</cell><cell>0.1416</cell></row><row><cell>doc=bnn, query=bnn</cell><cell>0.2025</cell><cell>0.1723</cell><cell>0.1790</cell><cell>0.0996</cell><cell>0.0826</cell></row><row><cell>doc=nnn, query=nnn</cell><cell>0.1373</cell><cell>0.1190</cell><cell>0.0951</cell><cell>0.0635</cell><cell>0.0984</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16" coords="12,122.00,259.09,351.22,11.07"><head>Table 18 :</head><label>18</label><figDesc>Mean average precision of various single searching strategies (GIRT corpus)</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17" coords="12,77.00,422.09,433.00,191.41"><head>Table 19 :</head><label>19</label><figDesc>Description and mean average precision (MAP) of our official GIRT runs</figDesc><table coords="12,77.00,422.09,433.00,170.07"><row><cell></cell><cell></cell><cell cols="2">Query Index</cell><cell>Model</cell><cell>Query expansion</cell><cell>Combined</cell><cell>MAP</cell></row><row><cell>UniNEgde1</cell><cell>German</cell><cell>TD TD</cell><cell>word word</cell><cell cols="3">Okapi Prosit 10 best docs / 125 terms Z-ScoreW 5 best docs / 10 terms</cell><cell>0.4921</cell></row><row><cell>UniNEgde2</cell><cell>German</cell><cell>TD</cell><cell>word</cell><cell>Prosit</cell><cell>10 best docs / 75 terms</cell><cell>N / A</cell><cell>0.4730</cell></row><row><cell>UniNEgde3</cell><cell>German</cell><cell>TD</cell><cell>word</cell><cell cols="2">Prosit 10 best docs / 150 terms</cell><cell>N / A</cell><cell>0.4597</cell></row><row><cell>UniNEgen1</cell><cell>English</cell><cell>TD TD</cell><cell>word word</cell><cell>Okapi Prosit</cell><cell>5 best docs / 10 terms 10 best docs / 50 terms</cell><cell>Z-ScoreW</cell><cell>0.5065</cell></row><row><cell>UniNEgen2</cell><cell>English</cell><cell>TD</cell><cell>word</cell><cell>Prosit</cell><cell>10 best docs / 60 terms</cell><cell>N / A</cell><cell>0.5043</cell></row><row><cell>UniNEgen3</cell><cell>English</cell><cell>TD</cell><cell>word</cell><cell>Prosit</cell><cell>5 best docs / 20 terms</cell><cell>N / A</cell><cell>0.4419</cell></row><row><cell>UniNEgru1</cell><cell>Russian</cell><cell>TD TD</cell><cell>word word</cell><cell>Okapi Prosit</cell><cell>5 best docs / 10 terms 10 best docs / 30 terms</cell><cell>Z-ScoreW</cell><cell>0.2491</cell></row><row><cell>UniNEgru2</cell><cell>Russian</cell><cell>TD</cell><cell>word</cell><cell>Okapi</cell><cell>5 best docs / 20 terms</cell><cell>N / A</cell><cell>0.2774</cell></row><row><cell>UniNEgru3</cell><cell>Russian</cell><cell>TD</cell><cell>word</cell><cell>Prosit</cell><cell>10 best docs / 50 terms</cell><cell>N / A</cell><cell>0.2477</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>The authors would like to also thank the CLEF-2005 task organizers for their efforts in developing various European language test-collections, and <rs type="person">C. Buckley</rs> from <rs type="affiliation">SabIR</rs> for giving us the opportunity to use the SMART system. The first author is not able to thank the computing services at <rs type="institution">UniNE</rs>, because they consistently made no effort to be cooperative during this project. This research was supported in part by the <rs type="funder">Swiss National Science Foundation</rs> under Grant #<rs type="grantNumber">21-66 742.01</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_PzkDnH3">
					<idno type="grant-number">21-66 742.01</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Official Results</head><p>Table <ref type="table" coords="7,110.34,269.09,5.00,11.07">9</ref> shows the exact specifications of our 12 official monolingual runs. These experiments were mainly based on the Okapi and the Prosit probabilistic models as well as the Z-Score data fusion operator. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Bilingual Information Retrieval</head><p>For the bilingual track, we chose English as the language for submitting queries to be automatically translated into four different languages, using nine different machine translation (MT) systems and four bilingual dictionaries ("Babylon", "Ectaco", "Medios", and "Kerekes"). When using the different bilingual dictionaries to translate an English request word-by-word, usually more than one translation is provided, in an unspecified order. We decided to pick only the first translation available (labeled "Babylon 1" or "Ectaco 1"), the first two terms (e.g., "Babylon 2" or "Medios 2") or the first three available translations (labeled "Babylon 3").</p><p>monolingual search for the Promt system, and 73.6% for FreeTranslation). Other good translation systems found were the BabelFish, Systran and AppliedLanguage which worked well for French. For Bulgarian and Hungarian languages, we found only a few translation tools, and unfortunately their overall performance levels were not very good. As depicted in Table <ref type="table" coords="9,243.55,104.09,8.35,11.07">12</ref>, we also found that lemmatizing the English queries (for both the Bulgarian or Hungarian languages at least) would improve mean average precision. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mean average precision</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix: Weighting Schemes</head><p>To assign an indexing weight wij that reflects the importance of each single-term tj in a document Di, we might use the various approaches shown in Table <ref type="table" coords="14,272.35,99.09,4.32,11.07">A</ref>.1, where n indicates the number of documents in the collection, t the number of indexing terms, dfj the number of documents in which the term tj appears, the document length (the number of indexing terms) of Di is denoted by nti, and avdl, b, k1, pivot and slope are constants. For the Okapi weighting scheme, K represents the ratio between the length of Di measured by li (sum of tfij) and the collection mean noted by avdl.  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="13,71.00,416.09,452.00,11.07;13,92.00,427.09,237.01,11.07" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,244.20,416.09,278.81,11.07;13,92.00,427.09,114.16,11.07">Probabilistic models of information retrieval based on measuring the divergence from randomness</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,215.77,427.09,42.78,11.07">ACM-TOIS</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="357" to="389" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,71.00,440.09,424.01,11.07;13,92.00,451.09,157.01,11.07" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,234.15,440.09,260.85,11.07;13,92.00,451.09,34.03,11.07">How effective is stemming and decompounding for German text retrieval</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Braschler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ripplinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,134.85,451.09,41.45,11.07">IR Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="291" to="316" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,71.00,464.09,416.01,11.07;13,92.00,475.09,322.01,11.07" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,307.84,464.09,159.77,11.07">New retrieval approaches using SMART</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<idno>#500-236</idno>
	</analytic>
	<monogr>
		<title level="m" coord="13,92.00,475.09,93.76,11.07">Proceedings of TREC-4</title>
		<meeting>TREC-4<address><addrLine>Gaithersburg</addrLine></address></meeting>
		<imprint>
			<publisher>NIST Publication</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="25" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,71.00,488.09,443.02,11.07;13,92.00,499.09,172.01,11.07" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,206.03,488.09,135.75,11.07">Combination of multiple searches</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Shaw</surname></persName>
		</author>
		<idno>#500-215</idno>
	</analytic>
	<monogr>
		<title level="m" coord="13,362.83,488.09,84.63,11.07">Proceedings TREC-2</title>
		<meeting>TREC-2<address><addrLine>Gaithersburg</addrLine></address></meeting>
		<imprint>
			<publisher>NIST Publication</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="243" to="249" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,71.00,512.09,377.35,11.07" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="13,150.50,512.09,272.31,11.07">The GIRT data i the evaluation of CLIR systems -from 1997 until</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kluck</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2004. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,454.14,512.09,59.87,11.07;13,92.00,523.09,413.02,11.07;13,92.00,534.09,262.01,11.07" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="13,260.34,523.09,244.68,11.07;13,92.00,534.09,30.32,11.07">Comparative Evaluation of Multilingual Information Access Systems</title>
	</analytic>
	<monogr>
		<title level="m" coord="13,129.49,534.09,51.52,11.07">LNCS #3237</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Kluck</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="376" to="390" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,71.00,547.09,416.95,11.07;13,92.00,558.09,224.01,11.07" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,286.51,547.09,196.26,11.07">Experimentation as a way of life: Okapi at TREC</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beaulieu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,92.00,558.09,158.51,11.07">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="95" to="108" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,71.00,571.09,412.00,11.07;13,92.00,582.09,120.01,11.07" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,144.60,571.09,223.56,11.07">Statistical inference in retrieval effectiveness evaluation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,377.39,571.09,105.61,11.07;13,92.00,582.09,49.85,11.07">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="495" to="512" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,71.00,595.09,431.01,11.07;13,92.00,606.09,103.01,11.07" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="13,149.42,595.09,334.14,11.07">Combining multiple strategies for effective monolingual and cross-lingual retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,492.48,595.09,9.54,11.07;13,92.00,606.09,29.69,11.07">IR Journal</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="121" to="148" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,71.00,619.09,435.03,11.07;13,92.00,630.09,427.01,11.07;13,92.00,641.09,407.01,11.07" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="13,150.51,619.09,355.52,11.07;13,92.00,630.09,86.14,11.07">Report on CLEF-2003 monolingual tracks: Fusion of probabilistic models for effective monolingual retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,418.61,630.09,100.40,11.07;13,92.00,641.09,234.00,11.07">Comparative Evaluation of Multilingual Information Access Systems</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Kluck</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2004">2004b. 2004</date>
			<biblScope unit="page" from="322" to="336" />
		</imprint>
	</monogr>
	<note>LNCS #3237</note>
</biblStruct>

<biblStruct coords="13,71.00,654.09,424.02,11.07;13,92.00,665.09,421.01,11.07;13,92.00,676.09,330.01,11.07" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="13,146.76,654.09,280.73,11.07">Data Fusion for effective European monolingual information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,364.47,665.09,148.54,11.07;13,92.00,676.09,157.43,11.07">Multilingual Information Access for Text, Speech and Images</title>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">J F</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Kluck</surname></persName>
		</editor>
		<editor>
			<persName><surname>Magnini</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="page" from="233" to="244" />
		</imprint>
	</monogr>
	<note>LNCS #3491</note>
</biblStruct>

<biblStruct coords="13,71.00,689.09,433.01,11.07;13,92.00,700.09,229.01,11.07" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="13,149.27,689.09,350.72,11.07">Bibliographic database access using free-text and controlled vocabulary: An evaluation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,92.00,700.09,158.48,11.07">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="873" to="890" />
			<date type="published" when="2005">2005b</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,71.00,713.09,439.01,11.07" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="13,224.83,713.09,167.16,11.07">Fusion via a linear combination of scores</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C</forename><surname>Vogt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">W</forename><surname>Cottrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,401.75,713.09,42.40,11.07">IR Journal</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="151" to="173" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
