<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,93.83,146.21,415.33,18.08;1,185.48,168.13,232.02,18.08">SINAI at CLEF 2005: Multi-8 Two-years-on and Multi-8 Merging-only tasks</title>
				<funder ref="#_7AuakzM">
					<orgName type="full">Spanish Government (MCYT)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,173.59,203.19,121.81,10.46"><forename type="first">Fernando</forename><surname>Martínez-Santiago</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Jaén</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,303.30,203.19,126.13,10.46"><forename type="first">Miguel</forename><forename type="middle">A</forename><surname>García-Cumbreras</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Jaén</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,93.83,146.21,415.33,18.08;1,185.48,168.13,232.02,18.08">SINAI at CLEF 2005: Multi-8 Two-years-on and Multi-8 Merging-only tasks</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CDBD45330B96287151EF33A0627F53A1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries Algorithms, Languages, Performance, Experimentation Information Retrieval, Cross Language Information Retrieval, Collection Fusion Problem</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This year, we have participated on multilingual two years on and Multi-8 merging-only CLEF task. Our main interest has been to test several usual CLIR tasks and investigate how they affect to the final performance of the multilingual system. Specifically, we have evaluated the information retrieval model used to obtain each monolingual result, the merging algorithm, the translation approach and the application of query expansion techniques. The obtained results show that by means of improving merging algorithms and translation resources we reach better results than improving other CLIR modules such as IR engines or the expansion of queries.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In order to evaluate the relevance of several usual CLIR modules, we have made a combination between the collection fusion algorithm 2-step RSV and several IR systems. 2-step RSV collection fusion algorithm is detailed in <ref type="bibr" coords="1,223.81,597.16,10.52,10.46" target="#b4">[4,</ref><ref type="bibr" coords="1,237.64,597.16,7.01,10.46" target="#b5">5]</ref>. We depict briefly this algorithm above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">The merging algorithm</head><p>In short, the basic 2-step RSV idea is straightforward: given a query term and their translations into the other languages, their document frequencies are grouped together. Therefore, the method requires recalculating the document score by changing the document frequency of each query term. Given a query term, the new document frequency will be calculated by means of the sum of the monolingual retrieved document frequency of the term and their translations. In the first step the query is translated and searched on each monolingual collection. This phase produces a T 0 vocabulary made up by "concepts". A concept consists of each term together with its corresponding translation. Moreover, we obtain a single multilingual collection D 0 of preselected documents as result of the union of the first 1000 retrieved documents for each language. The second step consists of creating a dynamic index by re-indexing the multilingual collection D 0 , but considering solely the T 0 vocabulary. Finally, a new query formed by concepts in T 0 is generated and this query is carried out against this dynamic index.</p><p>Thus, the first step of 2-step RSV consists of retrieving relevant documents for each language and the alignment of the query and its translations. This year we have tested the performance of the algorithm by testing several information retrieval engines, used for retrieving relevant documents for each monolingual collection, and then applying the second step of the merging algorithm over the retrieved documents. To sum up, we have tested ZPrise with OKAPI weighting function <ref type="bibr" coords="2,122.65,206.18,12.25,10.46" target="#b6">[6]</ref>, IRn passage system <ref type="bibr" coords="2,228.30,206.18,12.90,10.46" target="#b2">[2]</ref>, and several relevant documents list available from Multi-8 Merging-only task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Experimentation framework</head><p>The basic process is the following. In a first step each monolingual collection is preprocessed as usual (tokens extraction, stopper, stemmer). In addition, compound words are decompounded as possible to the German, Swedish, Finnish and Dutch languages. We use the decompounding algorithm depicted in <ref type="bibr" coords="2,188.49,308.77,9.96,10.46" target="#b3">[3]</ref>. The preprocessed collections have been indexed by using the passage retrieval system IRn and ZPrise. The IRn system has been modified in order to return a list of relevant documents, the documents that contain the relevant passages. Given a query and its translations into the other languages, each query is searched in the corresponding monolingual collection.</p><p>Since we have used machine translation for several languages, and 2-step RSV requires to group together the document frequency for each term and its own translations, and MT translates the whole of the phrase better than word-by-word, 2-step RSV merging algorithm is not directly feasible with MT (given a word of the original query, its translation to the rest of languages must be known). Thus, we propose in <ref type="bibr" coords="2,237.38,416.36,10.52,10.46" target="#b3">[3]</ref> an straightforward and effective algorithm in order to align the original query and its translation at term level. It aligns about 80-85% of non-empty words (Table <ref type="table" coords="2,124.58,440.28,3.87,10.46" target="#tab_0">1</ref>). In spite of the proposed algorithm to align phrases and translations at term level works fine, it does not obtain fully aligned queries. In order to improve the system performance when some terms of the query are not aligned, we make two subqueries. The first one is made up by the aligned terms only and the other one is formed with the non-aligned terms. Thus, for each query every retrieved document obtains two scores. The first score is obtained with 2-step RSV merging algorithm over the first subquery. On the other hand, the second subquery is used in a traditional monolingual system with the respective monolingual list of documents. Therefore, we have two scores for each query, the first one is calculated by using the dynamic and global index created by 2-step RSV for all languages and the other one is calculated locally for each language. Thus we have to integrate both values. As a way to deal with partially aligned queries (i.e. queries with some terms not aligned), we have implemented several ways to combine the aligned and non-aligned score in a only score per query and retrieved document: Versions two, three and four require training set (topics and their relevance assessments), and it must be available for each monolingual collection. We have used CLEF queries(140-160) relevance assessments available this year for training purposes. Thus, twenty first queries have been used as training and the other forty have been used for evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Expanding the queries</head><p>Some experiments based on ZPrise use pseudo-relevance feedback technique. We have adopted Robertson-Croft's approach <ref type="bibr" coords="3,215.24,364.56,10.52,10.46" target="#b1">[1]</ref> where the system expands the original query generally by 10-15 search keywords, extracted from the 10-best ranked documents. We have chosen this configuration because empirically we have obtained better results than with other configurations available at ZPrise system.</p><p>The second step of the merging method does not make use of automatic query expansion techniques such as relevance feedback (RF) or pseudo-relevance feedback (PRF) applied to monolingual queries. Since RF and PRF extend every monolingual query with collection-dependent words, the reindexing process (second step of 2-step RSV) will not take into account all of these words. Because such words are not the same for each monolingual collection, and the translation to the other languages is unknown, 2-step RSV method ignores these new terms for the second step. However, the overall performance will also improve since PRF and RF improve on monolingual experiments and usually some extended terms coincide with terms of the original query, and such terms will be aligned. Rest of expanded terms are integrated as non-aligned terms by using the approaches depicted in the section 2 for mixed 2-step RSV. Of course, the percentage of non-aligned words is increased because of the application of PRF. Table <ref type="table" coords="3,411.43,531.93,4.98,10.46" target="#tab_2">2</ref> shows the percentage of aligned words for expanded queries by using PRF and Machine Translation. • In spite of the very different performance of the bilingual experiments (Table <ref type="table" coords="5,455.98,313.18,3.87,10.46">6</ref>), final multilingual average precision is very similar independently of the selected documents for each IR system.</p><p>• Since the simultaneous application of PRF and Machine Translation decreases dramatically the percentage of aligned words, the application of PRF improves very slightly the final result.</p><p>• Good performance of raw-mixed 2-step RSV, obtaining a result very near to the result reached by means of logistic regression and neural networks. This result is counterintuitive since the method adds two values which are not directly comparable: the score obtained by both aligned and non-aligned terms. Some of the reasons for this good result are:</p><p>-α parameter limits the weight of the unaligned factor.</p><p>-Not all the terms to be added to the original query are new terms since some terms obtained by means of pseudo-relevance feedback are in the initial query. Thus, these terms are aligned terms. In the same way this explains the good performance of 2-step RSV original method with expanded queries.</p><p>-Only 20 queries available for training.</p><p>-CLEF document collections are highly comparable (news stories from the same period). The results might be different if collections have vastly different sizes and/or topics.</p><p>Thus, 2-step RSV reaches the same precision in spite of using different IR systems. This is a drawback if the IR system used for the first step implements a IR model more sophisticated than the IR model implemented for the second step of the algorithm. In such situation, the improvement is not fully exploited by 2-step RSV merging algorithm because 2-step RSV creates a dynamic index based on classic document retrieval models (more precisely the dynamic index is created by using a document-based OKAPI weighting schema). So, what should we do to improve these results?. Since the second step is basically an OKAPI IR engine, we could improve such engine by using better IR models, and improving the translation and alignment processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>In this work, we have tested the merging algorithm 2-step RSV in several ways. We have compared the CLEF 2003 and CLEF 2005 Multi-8 results, by using CLEF 160-200 queries. This year we have obtained better results than the 2003 edition. We think that the main reason is a better translation approach and a more refined version of the merging algorithm.</p><p>The obtained results show that the improvement of merging algorithms and translation resources are higher than the improvement obtained by expanding the query by means of pseudorelevance feedback.</p><p>In the same way, the improvement of the monolingual IR System used to retrieve each monolingual list of documents obtains very slightly better results in the final multilingual system. In order to evaluate the impact of the monolingual IR system, we have evaluated several lists of retrieved documents by using two IR systems and some of the retrieved documents available for the Multi-8 Merging-only task, but holding the same translation approach and merging algorithm. Results show that the precision is very similar independently of the monolingual IR engine. We conclude that improvements in the selection of documents by using some monolingual IR engine is not fully exploited by 2-step RSV merging algorithm since this algorithm creates a dynamic index based on classic document retrieval models.</p><p>When pseudo-relevance feedback and machine translation is applied in the same experiment, the percentage of aligned words is too low to apply optimally some mixed variant of 2-step RSV. Thus, a more effective word alignment algorithm must be developed, especially for the new terms added to the query by means of PRF.</p><p>Finally, we think that the overall performance of the CLIR system will be overcome if we develop better translation strategies and we improve the IR model used for the creation of the dynamic index for the second step of the algorithm.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,96.34,472.16,410.33,109.19"><head>Table 1 :</head><label>1</label><figDesc></figDesc><table coords="2,135.91,472.16,370.76,109.19"><row><cell cols="3">Percent of aligned non-empty words (CLEF2005 query set, Title+Description fields,)</cell></row><row><cell cols="3">Language Translation resource Alignment percent</cell></row><row><cell>Dutch</cell><cell>Prompt (MT)</cell><cell>85.4%</cell></row><row><cell>Finnish</cell><cell>FinnPlace (MDR)</cell><cell>100 %</cell></row><row><cell>French</cell><cell>Reverso (MT)</cell><cell>85.6%</cell></row><row><cell>German</cell><cell>Prompt (MT)</cell><cell>82.9 %</cell></row><row><cell>Italian</cell><cell>FreeTrans (MT)</cell><cell>83.8 %</cell></row><row><cell>Spanish</cell><cell>Reverso (MT)</cell><cell>81.5 %</cell></row><row><cell>Swedish</cell><cell>Babylon (MDR)</cell><cell>100 %</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,102.18,110.53,410.84,141.97"><head>1 .</head><label>1</label><figDesc>Raw mixed 2-step RSV. Combining the RSV value of the aligned words and not aligned words with the formula: 0.6 * &lt; RSV a ligned d oc &gt; +0.4 * &lt; RSV n ot a ligned &gt; 2. Mixed 2-step RSV by using Logistic Regression. The formula: e ( alpha * &lt; RSV a ligned d oc &gt; +beta * &lt; RSV n ot a ligned &gt;) 3. Mixed 2-step RSV by using Logistic Regression and local score. The last one also uses Logistic Regression but include a new component, the ranking of the doc. It applies the formula: e ( alpha * &lt; RSV a ligned d oc &gt; +beta * &lt; RSV n ot a ligned &gt; +gamma * &lt; ranking d oc &gt;) 4. Mixed 2-step RSV by using Bayesian Logistic Regression and local score. The last one is very similar to the previous approach, but it is based on bayesian logistic regression instead of logistic regression.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,90.00,575.21,423.01,121.14"><head>Table 2 :</head><label>2</label><figDesc>Percent of aligned non-empty words (CLEF2005 query set+PRF,</figDesc><table coords="3,434.46,575.21,78.54,10.46"><row><cell>Title+Description</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,90.00,244.25,423.01,168.96"><head>Table 3 :</head><label>3</label><figDesc>Multilingual experiments (I). Experiments with capital letters are official. The "main feature" is some particularity of such experiment respect of the case base experiment. The name of the experiments: UJA[UA][PRF]RSV2[RR][ 2003] means Univ. of Jaén[IRn system from Univ.</figDesc><table coords="4,90.00,280.11,423.01,133.10"><row><cell cols="3">of Alicante used][PRF used]2-step RSV merging algorithm[logistic regression used][CLEF 2003</cell></row><row><cell>results]</cell><cell></cell><cell></cell></row><row><cell>Experiment</cell><cell>Main feature</cell><cell>AvgP</cell></row><row><cell>UJARSV2</cell><cell>Case Base (OKAPI ZPrise IR, no PRF, MT, raw mixed</cell><cell>28.78</cell></row><row><cell></cell><cell>2-Step RSV)</cell><cell></cell></row><row><cell>ujaprfrsv2</cell><cell>UJARSV2+PRF</cell><cell>29.01</cell></row><row><cell>UJARSV2RR</cell><cell>different merging algorithm (see Table 4)</cell><cell>29.19</cell></row><row><cell cols="2">UJAPRFRSV2RR UJARSV2RR+PRF</cell><cell>29.57</cell></row><row><cell>ujarsv2 2003</cell><cell>it uses MDR instead of MT</cell><cell>24.18</cell></row><row><cell>ujauarsv2</cell><cell>it uses IRn IR engine</cell><cell>28.81</cell></row><row><cell cols="2">UJAUARSV2RR it uses IRn IR engine and a different merging algorithm</cell><cell>29.18</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,117.80,445.16,367.40,108.64"><head>Table 4 :</head><label>4</label><figDesc>Merging approaches. Experiments with capital letters are official.</figDesc><table coords="4,117.80,456.86,367.40,96.93"><row><cell>Experiment</cell><cell>2-step RSV approach</cell></row><row><cell>UJARSV2</cell><cell>Raw mixed 2-step RSV</cell></row><row><cell>ujaprfrsv2</cell><cell>Raw mixed 2-step RSV</cell></row><row><cell>UJARSV2RR</cell><cell>Mixed 2-step RSV by using Logistic Regression and local score</cell></row><row><cell cols="2">UJAPRFRSV2RR Mixed 2-step RSV by using Logistic Regression and local score</cell></row><row><cell>ujarsv2 2003</cell><cell>2-step RSV</cell></row><row><cell>ujauarsv2</cell><cell>Raw mixed 2-step RSV</cell></row><row><cell cols="2">UJAUARSV2RR Mixed 2-step RSV by using Logistic Regression and local score</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="4,90.00,585.75,423.01,154.12"><head>Table 5 :</head><label>5</label><figDesc>Multi-8 merging-only experiments. Experiments with capital letters are official. "Documents" are several sets of relevant documents available for the task from Neuchatel Bilingual Runs from CLEF 2003 .</figDesc><table coords="4,121.15,619.42,360.70,120.45"><row><cell>Experiment</cell><cell cols="2">Documents Merging algorithm</cell><cell>AvgP</cell></row><row><cell>ujamenepr</cell><cell>Prosit</cell><cell>Raw mixed 2-step RSV</cell><cell>28.40</cell></row><row><cell>ujameprrr</cell><cell>Prosit</cell><cell>Mixed 2-step RSV by using Logistic Re-</cell><cell>28.34</cell></row><row><cell></cell><cell></cell><cell>gression and local score</cell><cell></cell></row><row><cell>UJAMENEOK</cell><cell>Okapi</cell><cell>Raw mixed 2-step RSV</cell><cell>28.87</cell></row><row><cell>UJAMENEOKRR</cell><cell>Okapi</cell><cell>Mixed 2-step RSV by using Logistic Re-</cell><cell>28.87</cell></row><row><cell></cell><cell></cell><cell>gression and local score</cell><cell></cell></row><row><cell>UJAMENEDF</cell><cell cols="2">DataFusion Raw mixed 2-step RSV</cell><cell>29.42</cell></row><row><cell cols="3">UJAMENEDFRR DataFusion Mixed 2-step RSV by using Logistic Re-</cell><cell>30.37</cell></row><row><cell></cell><cell></cell><cell>gression and local score</cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6">Acknowledgments</head><p>Thank you very much to <rs type="person">Fernando LLopis</rs> and <rs type="person">Elisa Noguera</rs> from <rs type="affiliation">University of Alicante</rs> for their support with the IRn package.</p><p>Thank you very much to <rs type="person">Jacques Savoy</rs> and <rs type="person">Gareth Jones</rs> to supply the results of several bilingual experiments for the Multi-8 Merging-only task and the administration of the web place.</p><p>This work has been supported by <rs type="funder">Spanish Government (MCYT)</rs> with grant <rs type="grantNumber">TIC2003-07158-C04-04</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_7AuakzM">
					<idno type="grant-number">TIC2003-07158-C04-04</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,144.93,118.01,340.55,10.46;5,143.56,130.26,41.65,10.46;5,197.17,134.49,262.28,5.23;5,151.03,142.61,26.71,10.46;5,200.85,142.61,22.69,10.46;5,242.98,142.61,22.69,10.46;5,294.74,142.61,22.69,10.46;5,357.77,142.61,22.69,10.46;5,422.11,142.61,22.69,10.46;5,148.24,154.97,32.30,10.46;5,200.85,154.97,22.69,10.46;5,242.98,154.97,22.69,10.46;5,294.74,154.97,22.69,10.46;5,357.77,154.97,22.69,10.46;5,422.11,154.97,22.69,10.46;5,148.10,167.32,32.57,10.46;5,200.85,167.32,22.69,10.46;5,242.98,167.32,22.69,10.46;5,294.74,167.32,22.69,10.46;5,357.77,167.32,22.69,10.46;5,422.11,167.32,22.69,10.46;5,149.77,179.67,29.24,10.46;5,200.85,179.67,22.69,10.46;5,242.98,179.67,22.69,10.46;5,294.74,179.67,22.69,10.46;5,357.77,179.67,22.69,10.46;5,422.11,179.67,22.69,10.46;5,146.90,192.03,34.97,10.46;5,200.85,192.03,22.69,10.46;5,242.98,192.03,22.69,10.46;5,294.74,192.03,22.69,10.46;5,357.77,192.03,22.69,10.46;5,422.11,192.03,22.69,10.46;5,150.13,204.38,28.51,10.46;5,200.85,204.38,22.69,10.46;5,242.98,204.38,22.69,10.46;5,294.74,204.38,22.69,10.46;5,357.77,204.38,22.69,10.46;5,422.11,204.38,22.69,10.46;5,147.48,216.73,33.82,10.46;5,200.85,216.73,22.69,10.46;5,242.98,216.73,22.69,10.46;5,294.74,216.73,22.69,10.46;5,357.77,216.73,22.69,10.46;5,422.11,216.73,22.69,10.46;5,147.06,229.09,34.66,10.46;5,200.85,229.09,22.69,10.46;5,242.98,229.09,22.69,10.46;5,294.74,229.09,22.69,10.46;5,357.77,229.09,22.69,10.46" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="5,144.93,118.01,335.96,10.46">6: Some bilingual results (except English which is a monolingual experiment)</title>
		<idno>23.29 24.99 25.23 31.29</idno>
		<imprint>
			<date type="published" when="3540">53 Spanish 37.35 40.63 39.68 43.73 51</date>
		</imprint>
	</monogr>
	<note>Language UJARSV2 ujaprfrsv2 UJAUARSV2RR UJAMENEOKRR UJAMENEDFRR Dutch 30.94 38</note>
</biblStruct>

<biblStruct coords="6,105.50,495.04,407.50,10.46;6,105.50,507.00,407.51,10.46;6,105.50,518.95,406.20,10.46" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,174.74,495.04,122.38,10.46">Relevance feedback revisited</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,241.49,507.00,271.53,10.46;6,105.50,518.95,292.58,10.46">Proceedings of the 15th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR-92)</title>
		<editor>
			<persName><forename type="first">Nicholas</forename><forename type="middle">J</forename><surname>Belkin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Peter</forename><surname>Ingwersen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Annelise</forename><forename type="middle">Mark</forename><surname>Pejtersen</surname></persName>
		</editor>
		<meeting>the 15th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR-92)</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,538.87,407.51,10.46;6,105.50,550.83,407.51,10.46;6,105.50,562.78,407.51,10.46;6,105.50,574.74,407.50,10.46;6,105.50,586.70,22.69,10.46" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,152.85,538.87,134.32,10.46">University of Alicante at CLEF</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Llopis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,256.66,550.83,256.35,10.46;6,105.50,562.78,280.54,10.46">Advances in Cross-Language Information Retrieval, Third Workshop of the Cross-Language Evaluation Forum, CLEF 2002</title>
		<title level="s" coord="6,288.85,574.74,151.80,10.46">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Kluck</surname></persName>
		</editor>
		<meeting><address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002-09-19">2002. September 19-20, 2002. 2003</date>
			<biblScope unit="volume">2785</biblScope>
			<biblScope unit="page" from="103" to="110" />
		</imprint>
	</monogr>
	<note>Revised Papers</note>
</biblStruct>

<biblStruct coords="6,105.50,606.62,407.50,10.46;6,105.50,618.58,407.51,10.46;6,105.50,630.53,407.52,10.46;6,105.50,642.48,66.35,10.46" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,412.52,606.62,100.49,10.46;6,105.50,618.58,357.89,10.46">SINAI at CLEF 2004: Using Machine Translation Resources with Mixed 2-Step RSV Merging Algorithm</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Martínez-Santiago</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Miguel</forename><surname>García-Cumbreras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Ureña</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,473.00,618.58,40.01,10.46;6,105.50,630.53,174.58,10.46">Advances in Cross-Language Information Retrieval</title>
		<title level="s" coord="6,286.91,630.53,148.77,10.46">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>In press</note>
</biblStruct>

<biblStruct coords="6,105.50,662.41,407.51,10.46;6,105.50,674.37,407.51,10.46;6,105.50,686.33,407.51,10.46;6,105.50,698.28,407.50,10.46;6,105.50,710.23,319.50,10.46" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,333.54,662.41,179.47,10.46;6,105.50,674.37,79.35,10.46">SINAI at CLEF 2002: Experiments with merging strategies</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Martínez-Santiago</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Martín</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Ureña</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,142.69,686.33,370.32,10.46;6,105.50,698.28,174.73,10.46">Advances in Cross-Language Information Retrieval, Third Workshop of the Cross-Language Evaluation Forum, CLEF 2002</title>
		<title level="s" coord="6,174.41,710.23,152.09,10.46">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Kluck</surname></persName>
		</editor>
		<meeting><address><addrLine>Rome, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">September 19-20, 2002. 2003</date>
			<biblScope unit="volume">2785</biblScope>
			<biblScope unit="page" from="103" to="110" />
		</imprint>
	</monogr>
	<note>Revised Papers</note>
</biblStruct>

<biblStruct coords="6,105.50,730.16,407.50,10.46;6,105.50,742.11,298.65,10.46" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,339.37,730.16,173.63,10.46;6,105.50,742.11,124.85,10.46">A merging strategy proposal: two step retrieval status value method</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Martínez-Santiago</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Ureña</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Martín</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,239.88,742.11,93.25,10.46">Information Retrieval</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>In press</note>
</biblStruct>

<biblStruct coords="7,105.50,110.53,407.51,10.46;7,105.50,122.49,381.14,10.46" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,245.80,110.53,119.95,10.46">Okapi-Keenbow at TREC-8</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,392.07,110.53,120.94,10.46;7,105.50,122.49,128.11,10.46">Proceedings of the 8th Text Retrieval Conference TREC-8</title>
		<meeting>the 8th Text Retrieval Conference TREC-8</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="151" to="162" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
