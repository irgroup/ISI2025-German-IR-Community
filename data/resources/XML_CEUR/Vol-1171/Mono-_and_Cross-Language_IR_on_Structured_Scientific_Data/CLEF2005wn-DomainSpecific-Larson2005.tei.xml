<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,95.47,148.86,412.06,15.15;1,122.26,170.78,358.48,15.15">Fusion of Probabilistic Algorithms for the CLEF Domain Specific Task(Extended Abstract)</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,269.70,210.65,63.60,8.74"><forename type="first">Ray</forename><forename type="middle">R</forename><surname>Larson</surname></persName>
							<email>ray@sims.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Management and Systems</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,95.47,148.86,412.06,15.15;1,122.26,170.78,358.48,15.15">Fusion of Probabilistic Algorithms for the CLEF Domain Specific Task(Extended Abstract)</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F58055682E4FD33895BAD02E4EA932D8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing; H.3.3 Information Search and Retrieval Algorithms</term>
					<term>Performance</term>
					<term>Measurement Cheshire II</term>
					<term>Logistic Regression</term>
					<term>Data Fusion 1 Extended</term>
				</keywords>
			</textClass>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This extended abstract describes the Berkeley 1 participation in the Domain Specific task for CLEF 2005. This year we submitted the minumum number of entries for each subtask (3 monolingual runs, 6 bilingual runs, and 3 multilingual runs). In our runs we employed retrieval algorithms data fusion methods that have performed relatively well in some other retrieval contexts, but which will almost surely be abandoned in later attempts at CLEF. The main technique being tested is the fusion of multiple probabilistic searches against different XML components using both Logistic Regression (LR) algorithms and a version of the Okapi BM-25 algorithm. We also combine multiple translations of queries in cross-language searching. In the following paragraphs we will briefly describe the the indexing and term extraction methods used, followed by a description of the retrieval algorithms and data fusion methods. Since this is the first time that the Cheshire system has been used for CLEF, this approach can at best be considered a very preliminary base testing of some retrieval algorithms and approaches.</p><p>For both the monolingual and bilingual tasks we indexed the documents using the Cheshire II system. The document index entries and queries were stemmed using the Snowball stemmer. Text indexes were created for separate XML elements (such as document titles or dates) as well as for the entire document. The techniques and algorithms used for the DS task were essentially identical to those that we used for the GeoCLEF task, but without the special geographic indexes used for GeoCLEF (our GeoCLEF track paper describes the algorithms and approaches in detail).</p><p>For the bilingual and multilingual search tasks we used combinations of up to three different MT systems for query translation, using the L&amp;H PC-based system, SYSTRAN (via Babelfish), and PROMT. Each of these translations was combined into a single probabilistic query. The hope was to overcome the translation errors of a single system by including alternatives. However, for translation to Russian from German and English, only the PROMT MT system was available.</p><p>We tried only a single primary approach for searching, using only the topic text from the title and desc elements. In all cases the different indexes mentioned above were used, and probabilistic searches were carried out on each index with the results combined using the CombMNZ data fusion algorithm algorithm developed by Shaw and Fox <ref type="bibr" coords="2,342.07,147.89,9.97,8.74" target="#b0">[1]</ref>. The CombMNZ algorithm merges result lists, normalizing the scores in each list and increasing scores for items based on the number of result lists that they appear in, while penalizing items that appear in only a single list. For all searches we used both the Berkeley TREC3 and the Okapi BM-25 algorithms, with the results from each algorithm were also combined using the CombMNZ algorithm.</p><p>The results did not have very good performance. Relative to our German and English result, the Russian results look fairly good (we suspect that this may be due to the smaller number of participants). We consulted with the Berkeley2 group (who were using a different system and algorithms) to find what the primary differences were. Among the beneficial techniques used in those runs are 1) query expansion from the thesaurus, 2) automatic de-compounding of German words and 3) application of blind relevance feedback. We are conducting further tests adding these techniques and hope to have results to report at the meeting. The official submitted runs can be considered preliminary baselines that, we hope, will be improved upon in the future.</p><p>(*NOTE: Extended Abstract Only, additional comments in our GeoCLEF paper)</p></div>		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="2,105.50,358.07,407.50,8.74;2,105.50,370.02,407.51,8.74;2,105.50,381.98,216.21,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="2,279.40,358.07,146.52,8.74">Combination of multiple searches</title>
		<author>
			<persName coords=""><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Edward</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="2,450.76,358.07,62.24,8.74;2,105.50,370.02,195.59,8.74">Proceedings of the 2nd Text REtrieval Conference (TREC-2)</title>
		<title level="s" coord="2,309.68,370.02,203.33,8.74;2,105.50,381.98,81.61,8.74">National Institute of Standards and Technology Special Publication</title>
		<meeting>the 2nd Text REtrieval Conference (TREC-2)</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">500</biblScope>
			<biblScope unit="page" from="243" to="252" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
