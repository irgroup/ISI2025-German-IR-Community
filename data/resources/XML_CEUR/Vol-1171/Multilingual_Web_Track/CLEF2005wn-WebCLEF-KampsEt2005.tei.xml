<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,353.53,148.86,157.10,15.15">at WebCLEF 2005</title>
				<funder ref="#_8N2FsC9 #_zVqe8hV">
					<orgName type="full">Netherlands Organization for Scientific Research (NWO)</orgName>
				</funder>
				<funder ref="#_YjsWTEh #_7NCy3np #_94MSkC9 #_bv2FgTE #_gP3qBBb #_KnsA3VS #_gagdD3v #_W7fxSbv">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_a6bPSju">
					<orgName type="full">NWO</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,165.86,182.75,54.43,8.74"><forename type="first">Jaap</forename><surname>Kamps</surname></persName>
							<email>kamps@science.uva.nl</email>
							<affiliation key="aff1">
								<orgName type="department">Informatics Institute</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Archives and Information Studies</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,243.64,182.75,75.99,8.74"><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Informatics Institute</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,334.07,182.75,98.60,8.74"><forename type="first">Börkur</forename><surname>Sigurbjörnsson</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Informatics Institute</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">The University of Amsterdam</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,353.53,148.86,157.10,15.15">at WebCLEF 2005</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D77F45A58301E872798F0E72E7FBFD15</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries Measurement, Performance, Experimentation Web retrieval, Known-item retrieval, Multilingual retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe the University of Amsterdam's participation in the WebCLEF track at CLEF 2005. We submitted runs for both the mixed monolingual task and the multilingual task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In the CLEF 2005 WebCLEF track, we took part in two of the retrieval tasks. We took part in the WebCLEF mixed monolingual task. Our participation here was aimed at evaluating the effectiveness of standard ad hoc retrieval settings for a stream of topics in various languages. Our assumption was that this would shed new light on the robustness of modern information retrieval techniques.</p><p>We also took part in the WebCLEF multilingual task. Our participation here was aimed at evaluating the effectiveness of straightforwardly combining runs using a number of translations of the original English queries. Such methods have previously been used successfully at the CLEF multilingual ad hoc retrieval task <ref type="bibr" coords="1,238.45,602.63,10.51,8.74" target="#b4">[5,</ref><ref type="bibr" coords="1,252.28,602.63,7.01,8.74" target="#b5">6]</ref>.</p><p>This paper is structured as follows. In Section 2 we describe our retrieval system as well as the approaches used for the two WebCLEF tasks in which we participate. Section 3 describes our official retrieval runs for WebCLEF 2005, and Section 4 discusses the results we have obtained. Finally, in Section 5, we offer some conclusions regarding our multilingual web retrieval efforts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Description</head><p>Our retrieval system is based on the Lucene engine with a number of home-grown extensions <ref type="bibr" coords="1,489.18,705.22,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="1,502.49,705.22,7.01,8.74" target="#b7">8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Retrieval Approach</head><p>For our ranking, we used the default similarity measure in Lucene <ref type="bibr" coords="2,392.87,130.41,9.97,8.74" target="#b7">[8]</ref>, i.e., for a collection D, document d and query q containing terms t i :</p><formula xml:id="formula_0" coords="2,180.26,160.01,242.48,26.35">sim(q, d) = t∈q tf t,q • idf t norm q • tf t,d • idf t norm d • coord q,d • weight t ,</formula><p>where tf t,X = freq(t, X)</p><formula xml:id="formula_1" coords="2,90.00,230.33,278.97,126.19">idf t = 1 + log |D| freq(t, D) norm d = |d| coord q,d = |q ∩ d| |q| norm q = t∈q tf t,q • idf t 2 2.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Tokenization</head><p>We indexed the whole collection by simply extracting the full text from the documents. We did not apply any stemming nor did we use a stopword list. We applied case-folding and normalized marked characters to their unmarked counterparts, i.e., mapping ö to o, ae to ae, î to i, etc. The only language specific processing we did was a transformation of the multiple Russian encodings into an ASCII transliteration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Translation</head><p>We used the WorldLingo machine translation <ref type="bibr" coords="2,299.92,459.51,10.52,8.74" target="#b8">[9]</ref> for translating the English topic statements into eight languages: Dutch, French, German, Greek, Italian, Portuguese, Russian, and Spanish. Combined with the English source topic statements, this gave us short topic statements in nine European languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Combination</head><p>We combined various 'base' runs using the unweighted CombSUM function of Fox and Shaw <ref type="bibr" coords="2,499.72,541.28,9.96,8.74" target="#b1">[2]</ref>. The runs were combined after normalizing the retrieval status values (RSVs) to the interval [0,1] as suggested in <ref type="bibr" coords="2,158.79,565.19,9.97,8.74" target="#b6">[7]</ref>.</p><p>3 Runs</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Mixed-monolingual task</head><p>We submitted one run to the mixed-monolingual task. The run uses the short topic statement in the title field of the WebCLEF 2005 topics. Our run uses Lucene's standard ranking formula applied on our full-text index (as discussed in Section 2 above).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Multilingual task</head><p>We submitted four runs to the multilingual task. All runs use the English version of the short topic statement in the translation language="EN" field of the WebCLEF 2005 topics, and the translations mentioned in Section 2.3. We experimented along two dimensions. The first dimension is the number of topic languages: MRR S@1 S@5 S@10 All topics 0.3497 0.2523 0.4589 0.5576 Home pages 0.2263 0.1322 0.3347 0.4380 Named pages 0.4476 0.3475 0.5574 0.6525 Table <ref type="table" coords="3,117.40,168.71,3.88,8.74">1</ref>: Mixed Monolingual Task results by mean reciprocal rank (MRR) and success at rank 1, rank 5 and rank 10 (S@1, S@5, and S@10 respectively). We provide the scores over all topics, as well as a breakdown in home page finding and named page finding topics.</p><p>All translations Assuming that we have no knowledge of the language of the desired pages for each of the topics, it makes sense to use all available translations. That is, we use the topics in all nine languages available.</p><p>Five languages Based on knowledge of the languages in the WebCLEF topic set, we restrict the set of languages to those that occur frequently and for which we have reasonable translation methods. That is, we use the topics in the five languages: Dutch, English, German, Portuguese, and Spanish.</p><p>Recall that WebCLEF provides a stream of topics, with topics from arbitrary languages. For the multilingual task, we use the English short topic statement. The downside of this is, of course, that finding the targeted page in the source language becomes a formidable problem. The upside is that, at least, the topic language is known, and the same holds for the translations we obtained.</p><p>The second dimension we experiment with is trying to exploit this knowledge:</p><p>All results Topics in one language may likely retrieve pages in other languages as well. A case in point is WebCLEF topic WC0014, whose English topic statement ("Chancellery at the Spreebogen") could still allow us to retrieve German pages targeted by the German topic statement ("Bundeskanzleramt am Spreebogen"). Hence, we may simply use all pages retrieved by a topic of a particular, known language.</p><p>Language restricted Since we know the language of the topic in each of the translations, and the intention of the translated topic is to retrieve pages in that language, we may decide to restrict the pages returned by our retrieval system. We do this by restricting retrieved pages to the dominant domains. For example, for a run with the topics translated to Dutch, we restrict pages to come from either the .nl or the .eu.int domain.</p><p>Combining the two dimensions naturally suggests the four following cases:</p><p>1. using nine topic languages without restriction;</p><p>2. using nine topic languages and restricting pages to dominant domains;</p><p>3. using five topic languages without restriction; and 4. using five topic languages and restricting pages to dominant domains.</p><p>For each of the cases, we obtain five to nine different runs, which we combine using unweighted CombSUM. This results in the four runs submitted to WebCLEF 2005.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Mixed-monolingual task</head><p>We submitted a single no-thrills run for the mixed monolingual task, using standard ad hoc document retrieval setting (as discussed in Section 3). Table <ref type="table" coords="3,366.00,721.73,4.98,8.74">1</ref> reports the result of the mixed monolingual run. A number of observations present themselves. First, we see that, on average, the desired page is found in the top three. That is a reassuring result for the mixed monolingual All topics MRR S@1 S@5 S@10 Nine languages 0.0092 0.0055 0.0073 0.0165 Nine languages, restricted 0.0157 0.0091 0.0201 0.0219 Five languages 0.0109 0.0055 0.0091 0.0165 Five languages, restricted 0.0166 0.0091 0.0201 0.0238 Home pages MRR S@1 S@5 S@10 Nine languages 0.0072 0.0041 0.0083 0.0124 Nine languages, restricted 0.0157 0.0124 0.0165 0.0165 Five languages 0.0084 0.0041 0.0083 0.0124 Five languages, restricted 0.0163 0.0124 0.0165 0.0207 Named pages MRR S@1 S@5 S@10 Nine languages 0.0109 0.0066 0.0066 0.0197 Nine languages, restricted 0.0158 0.0066 0.0230 0.0262 Five languages 0.0129 0.0066 0.0098 0.0197 Five languages, restricted 0.0168 0.0066 0.0230 0.0262 Table <ref type="table" coords="4,117.38,314.96,3.88,8.74">2</ref>: Multilingual Task results by mean reciprocal rank (MRR) and success at rank 1, rank 5 and rank 10 (S@1, S@5, and S@10 respectively). We provide the scores over all topics (top), as well as a breakdown in home page finding (middle) and named page finding topics (bottom).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Restricted to language</head><p>All 547 topics # Topics MRR S@1 S@5 S@10 MRR S@1 S@5 S@10 Dutch 59 0.  <ref type="table" coords="4,117.40,503.65,3.88,8.74">3</ref>: Mixed Monolingual Task results by mean reciprocal rank (MRR) and success at rank 1, rank 5 and rank 10 (S@1, S@5, and S@10 respectively). We provide the scores over all topics for each of the topic translations (not submitted as official runs). We submitted runs based on all languages, or on the five languages with a .</p><p>task. Somewhat worrying is the success rate at rank 10, with no relevant page found for over 40% of the topics. Second, named page topics score somewhat higher than home page topics, on all measures. This is well-known from other web retrieval tasks <ref type="bibr" coords="4,372.23,595.25,9.96,8.74" target="#b0">[1]</ref>, which also suggests that the scores for home page finding can be substantially improved using specific web centric techniques such as various document representations and non-content priors <ref type="bibr" coords="4,376.35,619.16,9.96,8.74" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Multilingual task</head><p>We submitted four runs for the multilingual task (as discussed in Section 3). We will first look at the overall results, and then focus on the effectiveness for each of the languages in which we translated the English topics. Table <ref type="table" coords="4,132.22,701.31,4.98,8.74">2</ref> reports the result of the multilingual runs. Again, we make a number of observations. First, we see that scores are substantially lower than for the mixed monolingual task. The complexity of the multilingual task can hardly be overestimated: given an English query we have to guess what page in any language has to be returned the user. Obvious ways of limiting this wealth of options are the use of topic meta-fields, or of sophisticated techniques to extract target language cues. Second, our experiment with the number of translations to use, points conclusively to the smaller set of five language used frequently in the topic set. It is a reassuring fact that the improvement is moderate, and the extended set of translations is far from detrimental to the performance. Note that the extended set includes, for example, Italian, which is not used in any of the topics. Third, our experiment with restricting our intention to pages in the language of the topic translation is clearly successfull. It leads to substantial improvement of the score.</p><p>We now zoom in on the effectiveness of the individual translations. Table <ref type="table" coords="5,436.89,195.71,4.98,8.74">3</ref> lists the results of the translated queries, both evaluated against the whole topic set, as well as against all topics targeting a page in the language at hand. We see the following. First, when looking at the restricted topic sets, effectiveness varies from total failure (Greek) to perfection (French). The score for the five frequent languages is reasonable compared to those of the mixed monolingual task. Hence, one may conclude that the automatic topic translations are effective. Second, when looking at all topics, the scores are generally unimpressive and mirroring the frequency with which a topic of the given language appears in the topic set. This comes as no surprise, given that the topic set covers eleven languages, and each of the topic translations will dominantly target only one of them. Third, the translated topics pick up relevant pages in languages other than the target language. In particular, the Italian topics do pick up a relevant page for 35 of the topics. Fourth, the single topic language runs are still much more effective than the combined multilingual runs in Table <ref type="table" coords="5,154.49,339.17,3.88,8.74">2</ref>. This is a disappointing result, and clearly indicates that the straightforward run combination is ineffective. On a more positive note, however, the results for the individual translations strongly suggest that more sensible methods are possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>This paper documents the University of Amsterdam's participation in the CLEF 2005 WebCLEF track. The EuroGOV collection used at WebCLEF is based on a crawl of governmental information from a range of sites. Such a collection of web data is much noisier than traditional collections of newswire and newspaper data originating from a single source. Moreover, the linguistic variety in the collection makes it harder to apply language-specific processing methods such as stemming algorithms. Hence, we simply indexed the collection by extracting the full text from the documents.</p><p>For the mixed monolingual task, we submitted a single, standard ad hoc retrieval run. Our main finding is that such a straightforward approach is relatively effective, that uses no web specific settings. Considering the fact that we are dealing with a stream of topics in eleven languages, and with an even greater number of languages in the collection, this sheds new light on the robustness of modern information retrieval techniques.</p><p>For the multilingual task, we experimented with different numbers of translations of the English queries, and with restricting the returned pages to the now-known language of the query at hand. Our experiments show beneficial effects for restricting the number of translation to those occurring frequently in the topic set, as well as for limiting query translations to return only pages in the language of the query. In general, however, the combined results for the multilingual task are unimpressive. The individual query translations, however, seem relatively successful in targeting their share of relevant pages. This casts considerable doubt on the effectiveness of standard combination methods for this particular task.</p></div>		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6">Acknowledgments</head><p>We want to thank <rs type="person">Valentin Jijkoun</rs> for help with the Russian collection. <rs type="person">Jaap Kamps</rs> was supported by a grant from the <rs type="funder">Netherlands Organization for Scientific Research (NWO)</rs> under project numbers <rs type="grantNumber">612.066.302</rs> and <rs type="grantNumber">640.001.501</rs>. Maarten de Rijke was supported by grants from <rs type="funder">NWO</rs> under project numbers <rs type="grantNumber">017.001.190</rs>, <rs type="grantNumber">220-80-001</rs>, <rs type="grantNumber">264-70-050</rs>, <rs type="grantNumber">354-20-005</rs>, <rs type="grantNumber">612-13-001</rs>, <rs type="grantNumber">612.000.106</rs>, <rs type="grantNumber">612.000.207</rs>, <rs type="grantNumber">612.066.302</rs>, and <rs type="grantNumber">612.069.006</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_8N2FsC9">
					<idno type="grant-number">612.066.302</idno>
				</org>
				<org type="funding" xml:id="_zVqe8hV">
					<idno type="grant-number">640.001.501</idno>
				</org>
				<org type="funding" xml:id="_a6bPSju">
					<idno type="grant-number">017.001.190</idno>
				</org>
				<org type="funding" xml:id="_YjsWTEh">
					<idno type="grant-number">220-80-001</idno>
				</org>
				<org type="funding" xml:id="_7NCy3np">
					<idno type="grant-number">264-70-050</idno>
				</org>
				<org type="funding" xml:id="_94MSkC9">
					<idno type="grant-number">354-20-005</idno>
				</org>
				<org type="funding" xml:id="_bv2FgTE">
					<idno type="grant-number">612-13-001</idno>
				</org>
				<org type="funding" xml:id="_gP3qBBb">
					<idno type="grant-number">612.000.106</idno>
				</org>
				<org type="funding" xml:id="_KnsA3VS">
					<idno type="grant-number">612.000.207</idno>
				</org>
				<org type="funding" xml:id="_gagdD3v">
					<idno type="grant-number">612.066.302</idno>
				</org>
				<org type="funding" xml:id="_W7fxSbv">
					<idno type="grant-number">612.069.006</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,105.50,133.84,407.50,8.74;6,105.50,145.80,49.15,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,237.22,133.84,172.97,8.74">Overview of the TREC-2004 Web Track</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Craswell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hawking</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,431.53,133.84,81.48,8.74;6,105.50,145.80,18.51,8.74">Proceedings TREC 2004</title>
		<meeting>TREC 2004</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,165.72,407.50,8.74;6,105.50,177.68,407.50,8.74;6,105.50,189.63,149.30,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,223.70,165.72,145.91,8.74">Combination of multiple searches</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Shaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,393.65,165.72,119.35,8.74;6,105.50,177.68,93.66,8.74">The Second Text REtrieval Conference (TREC-2)</title>
		<imprint>
			<publisher>NIST Special Publication</publisher>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="500" to="215" />
		</imprint>
		<respStmt>
			<orgName>National Institute for Standards and Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,209.56,407.49,9.02;6,105.50,222.23,70.76,8.30" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="6,136.74,209.56,213.24,8.74">The ILPS extension of the Lucene search engine</title>
		<ptr target="http://ilps.science.uva.nl/Resources/" />
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>ILPS</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,241.44,407.50,8.74;6,105.50,253.39,407.50,8.74;6,105.50,265.35,22.70,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,156.02,241.44,125.70,8.74">Web-centric language models</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,304.95,241.44,208.06,8.74;6,105.50,253.39,254.59,8.74">Proceedings of the Fourteenth ACM Conference on Information and Knowledge Management (CIKM 2005)</title>
		<meeting>the Fourteenth ACM Conference on Information and Knowledge Management (CIKM 2005)<address><addrLine>New York NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,285.27,407.50,8.74;6,105.50,297.23,407.51,8.74;6,105.50,309.18,407.50,8.74;6,105.50,321.14,407.50,8.74;6,105.50,333.09,217.13,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,306.59,285.27,206.41,8.74;6,105.50,297.23,125.04,8.74">Effective translation, tokenization and combination for cross-lingual retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fissaha Adafre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,213.28,309.18,299.72,8.74;6,105.50,321.14,173.90,8.74">Multilingual Information Access for Text, Speech and Images: Results of the Fifth CLEF Evaluation Campaign</title>
		<title level="s" coord="6,356.64,321.14,152.00,8.74">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><forename type="middle">J F</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Kluck</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Magnini</surname></persName>
		</editor>
		<meeting><address><addrLine>Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3491</biblScope>
			<biblScope unit="page" from="123" to="134" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,353.02,407.50,8.74;6,105.50,364.97,407.51,8.74;6,105.50,376.93,407.50,8.74;6,105.50,388.88,407.50,8.74;6,105.50,400.84,86.40,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,358.89,353.02,154.11,8.74;6,105.50,364.97,231.47,8.74">Language-dependent and languageindependent approaches to cross-lingual text retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Monz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Sigurbjörnsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,281.83,376.93,231.17,8.74;6,105.50,388.88,64.48,8.74">Comparative Evaluation of Multilingual Information Access Systems</title>
		<title level="s" coord="6,305.01,388.88,152.79,8.74">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Kluck</surname></persName>
		</editor>
		<meeting><address><addrLine>CLEF</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003. 2004</date>
			<biblScope unit="volume">3237</biblScope>
			<biblScope unit="page" from="152" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,420.76,407.51,8.74;6,105.50,432.72,407.51,8.74;6,105.50,444.68,388.91,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,153.74,420.76,337.63,8.74">Combining multiple evidence from different properties of weighting schemes</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,105.50,432.72,407.51,8.74;6,105.50,444.68,140.59,8.74">Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="180" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,464.60,358.63,9.02" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="6,143.26,464.60,110.72,8.74">The Lucene search engine</title>
		<author>
			<persName coords=""><surname>Lucene</surname></persName>
		</author>
		<ptr target="http://jakarta.apache.org/lucene/" />
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,484.53,301.59,9.02" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="6,160.31,484.53,73.47,8.74">Online translator</title>
		<author>
			<persName coords=""><surname>Worldlingo</surname></persName>
		</author>
		<ptr target="http://www.worldlingo.com/" />
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
