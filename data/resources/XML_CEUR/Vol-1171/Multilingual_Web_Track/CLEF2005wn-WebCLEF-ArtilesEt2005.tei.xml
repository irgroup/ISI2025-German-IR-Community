<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,190.94,148.86,221.14,15.15">UNED at WebCLEF 2005</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,166.84,182.75,57.42,8.74"><forename type="first">Javier</forename><surname>Artiles</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Lenguajes y Sistemas Informáticos</orgName>
								<orgName type="institution">Universidad Nacional de Educación a Distancia c</orgName>
								<address>
									<addrLine>Juan del Rosal, 16, Ciudad Universitaria</addrLine>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,231.57,182.75,63.56,8.74"><forename type="first">Víctor</forename><surname>Peinado</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Lenguajes y Sistemas Informáticos</orgName>
								<orgName type="institution">Universidad Nacional de Educación a Distancia c</orgName>
								<address>
									<addrLine>Juan del Rosal, 16, Ciudad Universitaria</addrLine>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,303.13,182.75,64.19,8.74"><forename type="first">Anselmo</forename><surname>Penas</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Lenguajes y Sistemas Informáticos</orgName>
								<orgName type="institution">Universidad Nacional de Educación a Distancia c</orgName>
								<address>
									<addrLine>Juan del Rosal, 16, Ciudad Universitaria</addrLine>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,375.33,182.75,60.82,8.74"><forename type="first">Felisa</forename><surname>Verdejo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Lenguajes y Sistemas Informáticos</orgName>
								<orgName type="institution">Universidad Nacional de Educación a Distancia c</orgName>
								<address>
									<addrLine>Juan del Rosal, 16, Ciudad Universitaria</addrLine>
									<postCode>28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,190.94,148.86,221.14,15.15">UNED at WebCLEF 2005</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">ACD46D1193B3871DB6117B984650EB6C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing; H.3.3 Information Search and Retrieval Measurement</term>
					<term>Performance</term>
					<term>Experimentation Information Retrieval</term>
					<term>Cross-Language Information Retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes UNED NLP &amp; IR Group experiments at the Web CLEF track. The UNED NLP &amp; IR Group took part in the bilingual English-Spanish task. Our main attempt is to improve query translation by means of a non supervised approach to the translation of out-of-vocabulary words. Indexing is made preserving the information about the most relevant structural elements (title, metadata, headings, etc.). Search process is also explained and, finally, experimental results are presented.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>For the first participation in the Web CLEF track, the UNED NLP &amp; IR Group took part in the bilingual English-Spanish task. The main goal of the track is to test information retrieval systems in a cross-language environment settled at the Web. In all the proposed tasks there was a set of known item topics and a collection of web pages. The participant's systems had to find a particular page for each search topic.</p><p>The WebCLEF organization proposed to the participants an evaluation where the systems must return a ranked list of results (50 hits maximum) for each known item topic. The retrieved results should contain the target web page, in the first position of the ranking or as near as possible. In the case of the bilingual task, the set of 134 topics in English targets pages in Spanish that can be found at the Eurogov collection <ref type="bibr" coords="1,244.59,650.45,9.97,8.74" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Indexing</head><p>The EuroGov collection was indexed with Lucene 1.4.3. (http://lucene.apache.org). Each HTML document was reduced to plain text by removing the HTML tags. Given the wide range of languages at the collection, we decide to discard word normalization techniques and stopwords lists, both in documents and queries. We extracted from the HTML structure the following fields: title, metadata, headings (text tagged with h1, h2, etc), body, outgoing links and it's corresponding text anchors. The text present at each field was tokenized using Lucene's StandardAnalyzer and assigned to a document identified in the index by its URL and it's EuroGov ID.</p><p>The EuroGov collection is composed of 3,589,501 web pages from the European governmental sites (including 27 different web domains, as .uk, .gov, .fr, .es, etc.). The target Spanish page of a query could be hosted at any of these domains. In order to work with a smaller dataset we decided to index only the Spanish pages, according to the language detection output provided by the organization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Query Translation</head><p>The approach to the query translation has been synthesized in a very simple algorithm that performs a word-by-word translation. We translate the queries word-by-word using a bilingual dictionary. If the word can't be found in the dictionary we proceed to extract a candidate translation from the Web by means of an algorithm explained in this section.</p><p>In first place we have to decide which words of the query need to be translated to Spanish or must remain untranslated. Usually this step is implied by the use of a dictionary. Word out of the vocabulary of the dictionary are considered not translatable. In our case, in addition to the dictionary, we use a method to translate words out of the vocabulary. That's because it is important to decide if it is really necessary to translate a word. To confront this problem, we profited from the language detection output of the EuroGov collection provided by the Organization and we created separated collections by language. Our hypothesis is that a word which has its highest df /N (where df is the document frequency of the word and N the number of documents at the collection) in a collection of documents other than the English Collection is not an English word, and hence must not be translated. Furthermore, in that cases it is likely to find that the highest df /N corresponds to the Spanish Collection, given that the queries refer to documents in this language and may contain Spanish words or proper names.</p><p>The second steps consists simply in the translation of the words that can be found in our English-Spanish dictionary (a fusion of mainly tree dictionaries Vox-Harraps, FreeDict, EuroWordnet). Previously we lemmatize each word using a database of English lemmas.</p><p>Each one of the remaining words, that couldn't be translated using the dictionary, are passed as input to the following OOV translation method (based on <ref type="bibr" coords="2,351.73,489.58,10.29,8.74" target="#b1">[2]</ref>). Given an OOV English word, we search on Google for Spanish documents at the Web with that word. Our main assumption here is that in a document identified as mainly written in Spanish but that also contains the English word, the window of 20-25 terms around this word (approximately a snippet) might contain its Spanish translation. Taking the first 40 snippets we select the 10 more frequent words (removing stopwords and English words that might also appear). These frequent words are considered as translation hypothesis. To select the final translation we search on Google for English documents containing the transvaluation candidate. If the Spanish word co-occurs in the snippets of this search we count it's frequency and add it to the frequency of the candidate at the first search. This number is used to rank the translation hypothesis, and select the best one.</p><p>Finally, the resulting translations are passed as input for the searching process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Searching</head><p>In the search phase, we disposed of two ranking options based on the fields identified during the indexation. One possibility was to search over the whole contents of the documents and then rank the results according to this data. The other option was to use the fields identified during the preprocessing. The fields were ordered based on it's descriptiveness of the document [title, metadata, headings, body, outgoing links]. In this case, the ranked results are built by the consecutive searches, looking at just one field each time and disposing the results in the same order. At each iteration we remove the duplicated documents at the lower positions. Finally, the process is stopped when the results list arrives to 50 hits of when all the search fields have been explored. In both cases we first try a query with a AND boolean operator for all the words at each query. If the total results are less than 50, we search again with an OR boolean operator.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments and results</head><p>Our baseline experiment consisted of the query translation as described and searching over the body field. Our second experiment follows the same query translation method, and searches over the descriptive fields as explained in the Searching section. The Mean Reciprocal Rank shows poor results in both experiments, but with a minimum improvement when the descriptive fields are used. Two different factors may be also taken into account. One is the inherent difficulty of the proposed task, and the other is the election of a smaller (but faster) index, based on the language detection program, that possibly has excluded target webpages of the topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and future work</head><p>Our main conclusions are:</p><p>• The partial indexation of the EuroGov collection seem the first mistake in the design of these experiments. Full indexation should be performed in order to avoid the loss of relevant web pages.</p><p>• The strategy of search over the descriptive fields is the best option the known item task, but should also include anchor information to be really effective.</p><p>• The translation method for OOV words seems a very promising tool for the Cross-Language Information Retrieval task, but needs more study and a more careful selection of the translation hypothesis.</p><p>Our future work will be the improvement of the OOV translation method and its specific testing on different languages. We also will test the descriptive field search strategy adding anchor text from linking webpages. Finally we would like to evaluate the system at the Monolingual and Multilingual tasks of the WebCLEF 2005.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,194.20,118.94,214.60,92.62"><head>Table 1</head><label>1</label><figDesc></figDesc><table coords="3,194.20,118.94,214.60,92.62"><row><cell cols="2">: Evaluation results</cell><cell></cell></row><row><cell></cell><cell cols="2">baseline experiment</cell></row><row><cell>Average success at 1</cell><cell>0.0224</cell><cell>0.0821</cell></row><row><cell>Average success at 5</cell><cell>0.0672</cell><cell>0.1045</cell></row><row><cell>Average success at 10</cell><cell>0.1045</cell><cell>0.1194</cell></row><row><cell>Average success at 20</cell><cell>0.1716</cell><cell>0.1343</cell></row><row><cell>Average success at 50</cell><cell>0.2612</cell><cell>0.2090</cell></row><row><cell>MRR over 134 topics</cell><cell>0.0477</cell><cell>0.0930</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="3,105.50,687.92,407.50,8.74;3,105.50,699.88,315.71,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="3,337.96,687.92,175.04,8.74;3,105.50,699.88,39.75,8.74">Blueprint of a cross-lingual web retrieval collection</title>
		<author>
			<persName coords=""><forename type="first">Maarten</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rijke</forename><surname>Brkur Sigurbjrnsson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jaap</forename><surname>Kamps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="3,153.64,699.88,189.76,8.74">Journal of Digital Information Management</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="13" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,105.50,719.80,407.51,8.74;3,105.50,731.76,228.41,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="3,276.59,719.80,236.42,8.74;3,105.50,731.76,125.99,8.74">Mining translations of oov terms from the web through cross-lingual query expansion</title>
		<author>
			<persName coords=""><forename type="first">Stephan</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ying</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fei</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,252.93,731.76,50.33,8.74">SIGIR 2005</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
