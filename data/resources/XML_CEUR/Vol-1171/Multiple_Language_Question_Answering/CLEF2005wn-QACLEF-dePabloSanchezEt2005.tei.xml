<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,96.66,74.75,402.10,12.58">MIRACLE&apos;s 2005 Approach to Cross-Lingual Question Answering</title>
				<funder ref="#_wSe7863">
					<orgName type="full">Spanish R+D National Plan</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,86.70,102.18,96.75,9.02"><forename type="first">César</forename><surname>De Pablo-Sánchez</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universidad Carlos III de Madrid</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,191.33,102.18,96.40,9.02"><forename type="first">Ana</forename><surname>González-Ledesma</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Universidad Autónoma de Madrid</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,295.71,102.18,121.18,9.02"><forename type="first">José</forename><surname>Luis Martínez-Fernández</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universidad Carlos III de Madrid</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Decisions and Language</orgName>
								<orgName type="institution">DAEDALUS -Data</orgName>
								<address>
									<country>S.A</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,429.35,102.18,73.88,9.02"><forename type="first">José</forename><forename type="middle">Maria</forename><surname>Guirao</surname></persName>
							<email>jmguirao@ugr.es</email>
							<affiliation key="aff2">
								<orgName type="institution">Universidad de Granada</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,225.66,114.00,68.63,9.02"><forename type="first">Paloma</forename><surname>Martinez</surname></persName>
							<email>paloma.martinez@uc3m.es</email>
							<affiliation key="aff0">
								<orgName type="institution">Universidad Carlos III de Madrid</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,301.65,114.00,65.05,9.02"><forename type="first">Antonio</forename><surname>Moreno</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Universidad Autónoma de Madrid</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,96.66,74.75,402.10,12.58">MIRACLE&apos;s 2005 Approach to Cross-Lingual Question Answering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C300D94B7857BC8A82F469D5BDAF7448</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.2 Information Storage</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software. E.1 [Data Structures]</term>
					<term>E.2 [Data Storage Representations]. H.2 [Database Management] Linguistic Engineering, Information Retrieval, Question Answering, Cross-Lingual Information Retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the 2005 MIRACLE's team approach to CLEF QA with Spanish as a target task using miraQA system. The system is based on answer extraction and uses mainly syntactic patterns and semantic information. Six runs were submitted for Spanish, English and Italian as source languages using commercial translation software. The system performs reasonably well for Spanish factual questions if compared with other participants but its performance is lower with definition and temporally restricted questions. A thorough error analysis has been carried out to spot critical points for improvement. Comparison of cross-lingual runs shows that sometimes, for the cross-lingual task, answers are found that, for the monolingual tasks, cannot be located or do not appear as the first option.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Question answering systems localize and extract concrete answers to information needs expressed in natural language, usually in the form of questions. Information can be stored in different ways, from structured databases to unstructured document collections but still natural language is a convenient or preferred code for lots of users to access it. Besides, we do not need to assume that the information demanded by the user is in his or her own language, and therefore the issue of breaking the language barrier also arises. This seems an important issue in some applications of QA systems in domains like turism but also for accesing information in the web. This paper presents and analyzes the results of our second participation in the CLEF-QA task. We have submitted six runs with Spanish as a target language, but with different source languages, Spanish, English and Italian. Our system, miraQA, is mainly based on answer extraction and uses low level linguistic analysis. In contrast, we have incorporated some semantic resources for NE recognition. The approach and tools are different from last year <ref type="bibr" coords="1,130.56,625.02,11.67,9.02" target="#b8">[9]</ref> but we believe that both could be combined in a near future. Runs use different strategies for answer extraction and selection. Cross-lingual runs use direcct translation of the questions from source to target language. A further inspection of the errors made by the system in mono and cross-lingual runs has been carried out and, as a result, some ideas for further improvement and their priority are also presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Description of the MIRACLE Toolbox</head><p>MIRACLE's contribution to CLEF QA 2005 is an almost new development based on the experience acquired after last year initial contribution. The system, miraQA, uses different individual resources from MIRACLE's toolbox as well as open source components. Our aim is to achieve an architecture where we could easily plug in different resources for comparison and (semi) automatic evaluation of the system and their different parts. The number of resources produced by CLEF, especially MultiSix <ref type="bibr" coords="2,327.68,73.38,11.70,9.02" target="#b5">[6]</ref> and MultiEight corpora, allows us to put in practice an "agile" development methodology that help us to evaluate frequently.</p><p>The system is based on a classical pipelined architecture, what we call a "U" architecture as presented in Figure <ref type="figure" coords="2,70.92,120.66,3.77,9.02" target="#fig_0">1</ref>.</p><p>The resources that we have used in the system are:</p><p>• STILUS ©1 linguistic processors, in particular a morphosyntactic processor. This tool was initially developed for spell and grammar checking. It produces all possible morhopological analysis for a word and assigns all possible tags using a large dictionary of Spanish. The tool also contains a large dictionary of common collocations and recognizes and normalizes some usual complex tokens for commercial applications as dates, money and other numerical expressions and web addresses. Besides, it has been extended to recognize Named Entities of different kinds like person names (first and last), countries, cities and other geo-political entities, nationalities, organizations, etc. Recognized entities are tagged following Sekine´s taxonomy <ref type="bibr" coords="2,498.04,417.51,15.37,8.74" target="#b11">[12]</ref>.</p><p>• Xapian <ref type="bibr" coords="2,120.73,429.69,15.33,8.74" target="#b14">[15]</ref>. As last year we are using this probabilistic information retrieval engine to index and query the collection of EFE documents. Xapian provides ranks based on the Okapi BM25 model. • Machine translation. For the cross-lingual experiments we used Systran <ref type="bibr" coords="2,379.46,453.45,16.98,8.74" target="#b10">[11]</ref> to translate questions in Italian and English. Questions were passed to the Spanish miraQA system without any further processing.</p><p>Next sections describe the details of the logical components of the architecture. The same basic process is applied to the different types of questions and, in particular, temporal questions are considered as factual ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Question taxonomy</head><p>The Questions taxonomy in miraQA is determined by answer types. As most of the factoid questions are expecting some kind of named entity we initially consider Sekine's NE taxonomy, which contains more than a hundred NE types hierarchically linked. Most of the types are too specific for the tools and resources that we have available. So we actually prune the taxonomy to consider only NE types that could be extracted with some confidence. In contrast, we added some answer types like acronyms or a particular kind of definition (short descriptions that are often realized as appositives) that we called properties. The taxonomy preserves the hierarchy as we think that this could provide a way to back off to larger semantic classes of NE types if more specific answers are not found.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Question classification and query generation</head><p>Question classification is achieved using a set of linguistic rules produced after some deep study and generalization of CLEF 2004 Spanish data. Question classification aims to assign the correct answer type depending on the category of the question. Definition questions mainly ask for organization names or for short descriptions of persons or organization so this are the two types considered. For factual and temporal questions the taxonomy presented above is used. The classification proceeds in three steps, (1) question is analyzed using  </p><formula xml:id="formula_0" coords="3,88.80,100.39,158.71,74.84">• IsInterrogative • InterrogativeLemma • IsNounBeforeVerb • FirstNounLemma (Question focus) • MainContentVerbLemma • FirstEntityType</formula><p>Most of the interrogatives very often determine the type of the questions, while for Spanish, at least Qué y Cuál pronouns are used for almost every question type. For questions with this interrogatives the Question focus is the most determinant word and for that reason we have compiled lists of common question focuses for each type. The output from the processor is ambiguous and for that reason some simple rules to disambiguate verbs and nouns for feature extraction are used.</p><p>Rules that classify question have been manually generated from inspection of past CLEF campaign. So far, we have manually tagged the 200 hundred ES-ES questions with Sekine answer types and question form tags(affirmative/interrogative/relative) at the question level. Inside sentences we have tagged POS tags, Named Entitities, shallow syntactic structure and semantic arguments. Our objective is to achieve a multilevel tagged corpus of questions where deeper question structure could be inferred or tested. Our experience shows that available resources for Spanish are more inaccurate analyzing questions than typical sentences from documents.</p><p>After that step, queries to be passed to the search engine are directly formed with relevant terms extracted from the questions. Some terms are believed to harm retrieval effectivenes as they are too common in text and usually produce many noisy documents. A second specific stopword list, mainly composed of question focuses for the specific answer type, is applied to filter terms used in the query. In contrast, these terms are used later on for sentence filtering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Document and Sentence Retrieval</head><p>Documents are indexed off-line using Xapian to create indexes. The submitted runs used the typical text operations of stopword removal and stemming as provided by Xapian engine, so the Snowball <ref type="bibr" coords="3,455.94,625.08,16.69,9.02" target="#b9">[10]</ref> stemmer for Spanish was used.</p><p>At retrieval time, the first N results returned by the engine are analyzed using STILUS © tools and sentences are filtered and scored according to the number of content terms in common with the query. Sentences with less different content terms than a threshold are discarded although this threshold is 1 for queries that have fewer content terms. The results from our runs were produced from the first 100 retrieved documents, as we have experimentally tested that few documents contain candidate answers after this limit. Answers are extracted using rules depending on the answer type identified by the question classifier. An specialized answer recognizer is written for every category using a kind of automata that evaluates boolean predicates over annotated tokens. As the output from the STILUS © processor is not disambiguated, rules are robust enough to deal with some common problems. For most entity names these rules try to group recognized subunits in order to improve recall. Predicates used in the automata check for orthographic, morphological and syntactic and semantic features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Answer extraction and selection</head><p>For some answer types like MANNER and OTHER, it is difficult to establish a model of the answer and for that reason in our second run we tried an even simpler extractor. Candidates in this extractor are selected as chunks between content words.</p><p>After extraction, similar extracted answers are conflated using some simple rules that remove stopwords and some spurious content words from the query. For every group of answer the system picks as representative the answer with higher score, which will provide the source document.</p><p>MiraQA scores every answer in two steps. Runs 051 scored sentences according to the inverse frequency of relevant terms appearing in the query. Answer instances were given the same score than the sentence. Runs 052 used a weighted combination of tf*issf (inverted selected sentence frequency) terms and median distance from keywords to answers.</p><p>In a second step instances are conflated into groups and the answer with the best score is elected as representative. Redundancy is considered by computing the linear combination of the score and the ratio of documents that support an answer group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Basic experiments</head><p>We have submitted two runs for three language pairs. The target language for all of them is Spanish and the source languages are Spanish, English and Italian. The evaluation measures for the runs are presented in Table <ref type="table" coords="4,516.96,365.49,3.77,8.74" target="#tab_2">1</ref>.</p><p>Runs differ in the ranking function used to order answers and in the strategy used to answer OTHER questions.</p><p>For the runs numbered 051 OTHER questions extract mainly noun phrases while in 052 runs chunks of words between keywords are extracted.</p><p>Best results were achieved in mira051eses run but differences do not seem significant when only the first ranked answer is considered, while the runs contained a moderate number of different answers. In fact for English and Italian runs, the number of correct results are almost the same, being the figures of the weighted evaluation measures different. As could be expected, accuracy is lower for cross-lingual runs with a loss between 5% and 7%.</p><p>The system processes temporal questions in a similar way to factual questions and the accuracy obtained for the former ones is much lower than for the latter ones. The increasing effect in accuracy for English temporal questions is in fact due to answer with correct NILs. The system performs better for definition questions than for the rest of types in absolute numbers. In contrast, compared to other systems with Spanish as a source language, miraQA is answering better factual questions, in particular questions of the PERSON class. A deeper error analysis have been carried out in order to characterize the performance of the modules, detect problems and assign error rates. We have computed the classification accuracy according to our own question taxonomy. Results show that the accuracy for Spanish questions in CLEF 2005 test set is 80,50% being the main source of errors due to the lack of coverage of the words lists used to compare with question focus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>For English questions the accuracy is 77% while for Italian the accuracy is much lower (63,50%). While the source of problems for the English test set is mainly the same, some new errors are introduced by the translation engine changing the usual order of the question. The much lower performance in Italian is due to the incorrect translation of question word "Qué?" por "Cuál?" and the lack of appropiate rules.</p><p>The second point where we have measured error is after document retrieval and results are presented in Table <ref type="table" coords="5,517.09,102.90,3.76,9.02" target="#tab_3">2</ref>.</p><p>We have used the judgments for all of the systems to compute the number of questions for which a document with and answer is retrieved. We have used documents whose answers are assessed as correct (R) or inexact (X) to compute the number of questions that have a potential answer at a certain document cut. The measure should be taken as a lower bound as for the questions that none of the systems answers correctly, we do not have an associated document. Besides, some more documents could contain correct answers that are not identified. The loss in performance for cross-lingual experiments is mainly due to errors in the lexical construction selected by the automatic translator. Documents are ranked in the order provided by Xapian which reflects that is a reasonably good feature for answer ranking purposes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ES EN IT A@20</head><p>94 80 79 A@40 115 100 101 Table <ref type="table" coords="5,97.29,349.50,5.01,9.02" target="#tab_4">3</ref> shows the manual judgement of correct answers for run mira052eses at different numbers of possible answers. The conditions are the same than before so they should be taken as a lower bound. The results indicate that the maximum performance for questions with at least an answer, even with perfect ranking, would be of 55%. The ranking function works reasonably well but there is room for improvement.</p><p>Errors in a QA system cannot be assigned to only one subsystem, as there are usually complex interplays between the different parts. For example, a low precision in the answer extraction module will make the task of the answer selection module most difficult and therefore more prone to errors. Table <ref type="table" coords="5,421.83,426.12,5.01,9.02" target="#tab_6">4</ref> shows an estimation of the errors of the different modules based on the measures above.  Finally, we have detected that for some questions, the answer is found in cross-lingual runs while monolingual runs fail to provide a correct answer at least as a first choice. We have analyze judgements between mono and cross-lingual runs in order to quantify this performance. Changes from right to wrong in cross-lingual runs are mainly due to the incorrect translation of Named Entities, especially acronyms in definition questions. Another source of errors is the incorrect classification of questions and the incorrect translation of terms. In contrast, we believe the change from wrong to right is due to the use of different lexical alternatives at translation and their interplays with the retrieval and ranking systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Module</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>mono cross ES -&gt; IT ES -&gt; EN</head><formula xml:id="formula_1" coords="5,192.00,683.15,151.92,65.66">R U 0 1 R W 22 17 X W 6 5 X R 0 1 W X 5 2 W R 7 5</formula><p>Table <ref type="table" coords="6,169.86,87.45,5.01,8.74">5</ref> : Answer change between mono and cross lingual runs</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Future work</head><p>Results from the previous sections suggest that performance could be easily improved by means of using better answer selection techniques. Answers are found in 55% of the questions but only ranked in first position in half of them. We believe that better ranking functions and candidate answer filters in the style of our CLEF 2004 submission would help us in a future. Ranking functions should be suitable not only for ordering different candidate answers but also be informative enough for the user, reflecting the confidence that the system can assign to an answer.</p><p>Further work need also to be done in question classification in order to reduce their influence in later stages. We plan to include Wordnet and related Euro-Wordnet as well as the use of robust machine learning techniques in order to reduce the influence of incorrect translations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,203.70,309.33,183.03,8.74"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: miraQA "U" logical architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,115.20,560.25,124.78,8.74"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Question taxonomy</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,70.92,548.90,435.00,98.10"><head>R X U Acc. Acc(F) Acc(D) Acc(T) CWS K1 Corr Mira051eses 51 11 0 25,5 26,27</head><label></label><figDesc></figDesc><table coords="4,70.92,564.08,435.00,82.92"><row><cell></cell><cell></cell><cell>34</cell><cell cols="2">9,38 0,12372 -0,3021 0,3157</cell></row><row><cell>Mira052eses 46 14 0 23</cell><cell>22,03</cell><cell>34</cell><cell cols="2">9,38 0,10382 -0,3432 0,316</cell></row><row><cell cols="2">Mira051enes 39 7 1 19,5 16,95</cell><cell>28</cell><cell>15,62 0,09376 -0,3922</cell><cell>0,23</cell></row><row><cell cols="2">Mira052enes 39 8 2 19,5 16,95</cell><cell>28</cell><cell cols="2">15,62 0,08809 -0,3943 0,2278</cell></row><row><cell>Mira051ites 36 10 0 18</cell><cell>16,95</cell><cell>26</cell><cell cols="2">9,38 0,06829 -0,4379 0,2244</cell></row><row><cell cols="2">Mira052ites 35 11 0 17,5 16,95</cell><cell>24</cell><cell cols="2">9,38 0,07186 -0,4471 0,2192</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,70.92,650.85,155.75,8.74"><head>Table 1 : Statistics for assesed results</head><label>1</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,70.92,229.49,334.40,93.98"><head>Table 2 : Analysis of retrieved documents</head><label>2</label><figDesc></figDesc><table coords="5,335.16,229.49,70.16,93.98"><row><cell></cell><cell>ES</cell></row><row><cell>A@1</cell><cell>44</cell></row><row><cell>A@2</cell><cell>62</cell></row><row><cell>A@5</cell><cell>81</cell></row><row><cell>A@10</cell><cell>89</cell></row><row><cell>A@20</cell><cell>94</cell></row><row><cell>A@40</cell><cell>99</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,315.66,326.25,157.16,8.74"><head>Table 3 : Analysis of correct answers</head><label>3</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="5,178.92,539.25,180.91,8.74"><head>Table 4 : Estimation of error responsibility</head><label>4</label><figDesc></figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work has been partially supported by the <rs type="funder">Spanish R+D National Plan</rs>, by means of the project <rs type="projectName">RIMMEL Multilingual and Multimedia Information Retrieval, and its Evaluation</rs>), <rs type="grantNumber">TIN2004-07588-C03-01</rs>. Special mention to our colleagues of the MIRACLE team should be done (in alphabetical order): <rs type="person">Ana María García-Serrano</rs>, <rs type="person">José Carlos González-Cristóbal</rs>, <rs type="person">José Miguel Goñi-Menoyo</rs>, <rs type="person">Sara Lana-Serrano</rs>, <rs type="person">Ángel Martínez-González</rs> and <rs type="person">Julio Villena</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_wSe7863">
					<idno type="grant-number">TIN2004-07588-C03-01</idno>
					<orgName type="project" subtype="full">RIMMEL Multilingual and Multimedia Information Retrieval, and its Evaluation</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,97.92,405.00,426.61,9.02;6,97.92,416.76,210.31,9.02" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="6,201.13,405.00,266.31,9.02">page of resources for CLEF (Stopwords, transliteration, stemmers</title>
		<ptr target="http://www.unine.ch/info/clef/.[Visited13/07/2005" />
		<imprint/>
		<respStmt>
			<orgName>University of Neuchatel</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="6,97.92,434.52,321.07,9.02" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,252.63,434.52,72.20,9.02">Answer extraction</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Abney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,341.98,434.52,46.75,9.02">ANLP-2000</title>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,97.92,452.34,426.53,9.02;6,97.92,464.10,400.09,9.02" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,472.22,452.34,52.24,9.02;6,97.92,464.10,284.36,9.02">MIRACLE&apos;s Hybrid Approach to Bilingual and Monolingual Information Retrieval</title>
		<author>
			<persName coords=""><surname>Goñi-Menoyo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M;</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>González</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">José</forename><forename type="middle">L</forename><surname>Martínez-Fernández</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Villena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,391.80,464.10,99.25,9.02">CLEF 2004 proceedings</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,97.92,493.62,426.50,9.02;6,97.92,505.38,426.70,9.02;6,97.92,517.20,426.59,9.02;6,97.92,528.96,426.53,9.02;6,97.92,540.72,22.58,9.02" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,97.92,517.20,327.11,9.02">MIRACLE&apos;s hybrid approach to bilingual and monolingual Information Retrieval</title>
		<author>
			<persName coords=""><surname>Goñi-Menoyo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>González</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Martínez-Fernández</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julio</forename><forename type="middle">;</forename><surname>Villena-Román</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ana</forename><forename type="middle">;</forename><surname>García-Serrano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paloma</forename><forename type="middle">;</forename><surname>Martínez-Fernández</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>De Pablo-Sánchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">;</forename><surname>César</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alonso-Sánchez</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Javier</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,433.97,517.20,90.54,9.02;6,97.92,528.96,94.07,9.02">Working Notes for the CLEF 2004 Workshop</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Francesca</forename><surname>Borri</surname></persName>
		</editor>
		<meeting><address><addrLine>Bath, United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="141" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,97.92,558.48,426.73,9.02;6,97.92,570.24,426.56,9.02;6,97.92,582.06,115.77,9.02" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="6,512.39,558.48,12.26,9.02;6,97.92,570.24,246.95,9.02">An optimised trie index for natural language processing lexicons</title>
		<author>
			<persName coords=""><forename type="first">José</forename><surname>Goñi-Menoyo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">;</forename><surname>Miguel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">José</forename><surname>González-Cristóbal</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Carlos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jorge</forename><surname>Fombella-Mourelle</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>Universidad Politécnica de Madrid</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">MIRACLE Technical Report</note>
</biblStruct>

<biblStruct coords="6,97.92,599.82,426.51,9.02;6,97.92,611.58,426.67,9.02;6,97.92,623.34,426.54,9.02;6,97.92,635.10,109.26,9.02" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,508.84,599.82,15.59,9.02;6,97.92,611.58,426.67,9.02;6,97.92,623.34,63.43,9.02">The Multiple Language Question Answering Track at CLEF 2003. (see chapter &quot;Gold Standard for the Cross-Language Tasks</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Romagnoli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vallin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Peinado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Verdejo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,272.55,623.34,185.91,9.02">Working Notes for the CLEF 2003 Workshop</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Trondheim, Norway</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-08-22">21-22 August. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,97.92,652.92,426.57,9.02;6,97.92,664.68,426.72,9.02;6,97.92,676.44,426.58,9.02;6,97.92,688.20,426.62,9.02;6,97.92,699.96,61.99,9.02" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,177.15,664.68,347.49,9.02;6,97.92,676.44,327.86,9.02">MIRACLE Approaches to Multilingual Information Retrieval: A Baseline for Future Research. Comparative Evaluation of Multilingual Information Access Systems</title>
		<author>
			<persName coords=""><forename type="first">José</forename><forename type="middle">L</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julio</forename><forename type="middle">;</forename><surname>Villena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jorge</forename><surname>Fombella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">;</forename><forename type="middle">G</forename><surname>Serrano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ana</forename><forename type="middle">;</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paloma</forename><forename type="middle">;</forename><surname>Goñi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">José</forename><forename type="middle">M</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>José</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="6,260.66,688.20,152.33,9.02">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">C;</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Brascher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Kluck</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">3237</biblScope>
			<biblScope unit="page" from="210" to="219" />
			<date type="published" when="2004">2004</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,97.92,717.78,426.63,9.02;6,97.92,729.54,426.45,9.02;6,97.92,741.30,332.79,9.02" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,270.83,729.54,225.97,9.02">Evaluation of MIRACLE approach results for CLEF</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Villena-Román</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Fombella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>García-Serrano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Goñi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ed</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,97.92,741.30,181.55,9.02">Working Notes for the CLEF 2003 Workshop</title>
		<meeting><address><addrLine>Trondheim, Norway</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003. 21-22 August</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,97.92,73.38,426.56,9.02;7,97.92,85.14,426.64,9.02;7,97.92,96.90,426.48,9.02;7,97.92,108.66,22.58,9.02" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,201.07,85.14,170.77,9.02">Initial experiments in Question Answering</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>De Pablo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Martínez-Fernández</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Villena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>García-Serrano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Goñi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Miraqa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,382.03,85.14,142.53,9.02;7,97.92,96.90,39.29,9.02">Working Notes for the CLEF 2004 Workshop</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Francesca</forename><surname>Borri</surname></persName>
		</editor>
		<meeting><address><addrLine>Bath, United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="371" to="376" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,97.92,126.42,426.54,9.02;7,97.92,138.24,48.93,9.02" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="7,159.73,126.42,155.78,9.02">Snowball stemmers and resources page</title>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Porter</surname></persName>
		</author>
		<ptr target="http://www.snowball.tartarus.org" />
		<imprint>
			<date type="published" when="2005-07-13">13/07/2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,97.92,156.00,382.58,9.02" xml:id="b10">
	<monogr>
		<ptr target="http://www.systransoft.com" />
		<title level="m" coord="7,97.92,156.00,143.85,9.02">SYSTRAN 5.0 translation resources</title>
		<imprint>
			<date type="published" when="2005-07-13">13/07/2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,97.92,173.76,426.55,9.02;7,97.92,185.52,48.93,9.02" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="7,166.57,173.76,172.86,9.02">Sekine&apos;s Extended Name Entity Hierarchy</title>
		<author>
			<persName coords=""><forename type="first">Satoshi</forename><surname>Sekine</surname></persName>
		</author>
		<ptr target="http://nlp.cs.nyu.edu/ene/.[Visited18/08/2005" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,97.92,203.34,426.63,9.02;7,97.92,215.10,426.52,9.02;7,97.92,226.86,426.59,9.02;7,97.92,238.62,348.00,9.02" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,274.10,215.10,250.35,9.02;7,97.92,226.86,225.19,9.02">Image Retrieval: The MIRACLE Approach. Comparative Evaluation of Multilingual Information Access Systems</title>
		<author>
			<persName coords=""><forename type="first">Julio</forename><forename type="middle">;</forename><surname>Villena</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>José</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jorge</forename><surname>Fombella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">;</forename><forename type="middle">G</forename><surname>Serrano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ana</forename><forename type="middle">;</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alberto</forename><forename type="middle">;</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paloma</forename><forename type="middle">;</forename><surname>Goñi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">José</forename><forename type="middle">M</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>José</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="7,140.13,238.62,141.06,9.02">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">C;</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Brascher</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Kluck</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">3237</biblScope>
			<biblScope unit="page" from="621" to="630" />
			<date type="published" when="2004">2004</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,97.92,256.38,426.56,9.02;7,97.92,268.20,426.58,9.02;7,97.92,279.96,239.82,9.02" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="7,260.43,268.20,163.45,9.02">MIRACLE results for ImageCLEF 2003</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Villena-Román</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Fombella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>García-Serrano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Martínez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Goñi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ed</forename><surname>Peters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,431.70,268.20,92.80,9.02;7,97.92,279.96,88.68,9.02">Working Notes for the CLEF 2003 Workshop</title>
		<meeting><address><addrLine>Trondheim, Norway</addrLine></address></meeting>
		<imprint>
			<date>21-22 August</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,97.92,297.72,426.53,9.02;7,97.92,309.48,83.71,9.02" xml:id="b14">
	<monogr>
		<ptr target="http://www.xapian.org.[Visited13/07/2005" />
		<title level="m" coord="7,97.92,297.72,287.14,9.02">Xapian: an Open Source Probabilistic Information Retrieval library</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
