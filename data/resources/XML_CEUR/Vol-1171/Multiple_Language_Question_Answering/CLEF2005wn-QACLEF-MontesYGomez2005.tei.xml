<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,153.96,74.25,287.29,12.64;1,149.40,90.21,296.30,12.64">INAOE-UPV Joint Participation at CLEF 2005: Experiments in Monolingual Question Answering</title>
				<funder>
					<orgName type="full">SNI-Mexico</orgName>
				</funder>
				<funder>
					<orgName type="full">Human Language Technologies Laboratory of INAOE</orgName>
				</funder>
				<funder ref="#_84GMUws">
					<orgName type="full">CONACYT</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,161.76,119.52,87.62,8.96"><forename type="first">M</forename><surname>Montes-Y-Gómez</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Óptica y Electrónica (INAOE)</orgName>
								<orgName type="laboratory">Laboratorio de Tecnologías del Lenguaje</orgName>
								<orgName type="institution">Instituto Nacional de Astrofísica</orgName>
								<address>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,257.69,119.52,88.28,8.96"><forename type="first">L</forename><surname>Villaseñor-Pineda</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Óptica y Electrónica (INAOE)</orgName>
								<orgName type="laboratory">Laboratorio de Tecnologías del Lenguaje</orgName>
								<orgName type="institution">Instituto Nacional de Astrofísica</orgName>
								<address>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,354.32,119.52,76.02,8.96"><forename type="first">M</forename><surname>Pérez-Coutiño</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Óptica y Electrónica (INAOE)</orgName>
								<orgName type="laboratory">Laboratorio de Tecnologías del Lenguaje</orgName>
								<orgName type="institution">Instituto Nacional de Astrofísica</orgName>
								<address>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,178.56,131.04,90.95,8.96"><forename type="first">J</forename><forename type="middle">M</forename><surname>Gómez-Soriano</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Departamento de Sistemas Informáticos</orgName>
								<orgName type="institution">Computación</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Universidad Politécnica de Valencia (UPV)</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,277.89,131.04,72.81,8.96"><forename type="first">E</forename><surname>Sanchis-Arnal</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Departamento de Sistemas Informáticos</orgName>
								<orgName type="institution">Computación</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Universidad Politécnica de Valencia (UPV)</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,377.49,131.04,36.03,8.96"><forename type="first">P</forename><surname>Rosso</surname></persName>
							<email>prosso@dsic.upv.es</email>
							<affiliation key="aff1">
								<orgName type="department">Departamento de Sistemas Informáticos</orgName>
								<orgName type="institution">Computación</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">Universidad Politécnica de Valencia (UPV)</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,153.96,74.25,287.29,12.64;1,149.40,90.21,296.30,12.64">INAOE-UPV Joint Participation at CLEF 2005: Experiments in Monolingual Question Answering</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">13D678B21A04480F3616407495291946</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Recent works on question answering are based on complex natural language processing techniques: named entity extractors, parsers, chunkers, etc. While these approaches have proven to be effective they have the disadvantage of being targeted to a particular language. In this paper we present a full datadriven method that uses simple lexical pattern matching and statistical techniques in order to identify the relevant passages as well as the more probable candidate answers for factual and definition questions. The main quality of this method is that it can be applied to different languages without requiring major adaptation changes. Experimental results of the method in Spanish, Italian and French show that the approach can be a practical solution for monolingual and multilingual question answering applications.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The volume of online available documents is growing every day. As a consequence, better information retrieval methods are required to achieve the needed information. Question Answering (QA) systems are information retrieval applications whose aim is to provide inexperienced users with a flexible access to the information, allowing them writing a query in natural language and obtaining not a set of documents which contain the answer, but the concise answer itself <ref type="bibr" coords="1,193.09,399.84,82.01,8.96" target="#b8">(Vicedo et al, 2003)</ref>. That is, given a question like: "Where is the Popocatepetl located?", a QA system must respond "Mexico", instead of just returning a list of documents related to the volcano.</p><p>Recent developments in QA use a variety of linguistic resources to help in understanding the questions and the documents. The most common linguistic resources include: part-of-speech taggers, parsers, named entity extractors, dictionaries, and WordNet <ref type="bibr" coords="1,225.96,457.32,84.20,8.96" target="#b4">(Jijkoun et al., 2004;</ref><ref type="bibr" coords="1,313.20,457.32,78.01,8.96" target="#b0">Ageno et al., 2004;</ref><ref type="bibr" coords="1,394.20,457.32,107.97,8.96" target="#b5">Pérez-Coutiño et al., 2004)</ref>. Despite of the promising results of these approaches, they have two main inconveniences: (i) the construction of such linguistic resources is a very complex task; and (ii) these resources are highly binding to a specific language.</p><p>In this paper we present a QA system that allows answering factual and definition questions. This system is based on a full data-driven approach <ref type="bibr" coords="1,224.76,514.80,71.53,8.96" target="#b1">(Brill et al., 2001)</ref>, which requires minimum knowledge about the lexicon and the syntax of the specified language. Mainly, it is supported on the idea that the questions and their answers are commonly expressed using the same set of words, and therefore, it simply uses a lexical pattern matching method to identify relevant document passages and to extract the candidate answers.</p><p>The proposed approach has the advantage to be easily adapted to several different languages, in particular to moderately inflected languages such as Spanish, English, Italian and French. Unfortunately, this generality has its price. To obtain a good performance, the approach requires using a redundant target collection, that is, a collection in which the question answers occurs more than once. On the one hand, this redundancy increases the probability of finding a passage containing a simple lexical matching between the question and the answers. On the other hand, it enhances the answer extraction, since correct answers tend to be more frequent than incorrect responses.</p><p>The presented system also uses a set of heuristics that attempt to capture some regularities of language and some stylistic conventions of news letters. For instance, it considers that most named entities are written with an initial uppercase letter, and that most concept definitions are usually expressed using a very small number of fixed arrangements of noun phrases. This kind of heuristics guides the extraction of the candidate answers from the relevant passages.</p><p>In the rest of the paper we present the main architecture of our data-driven QA system. We also discuss the evaluation results on Spanish, Italian and French.</p><p>The figure <ref type="figure" coords="2,116.80,94.92,4.98,8.96" target="#fig_0">1</ref> shows the general architecture of our system. It is divided in two main modules. One of them focuses on answering factual questions. It considers the tasks of passage indexing, where documents are preprocessed, and a structured representation of the collection is built; passage retrieval, where the passages with more probability to contain the answer are recovered from the index; and answer extraction; where candidate answers are ranked and the final answer recommendation of the system is produced.</p><p>The other module concentrates on answering definition questions. It includes the tasks of definition extraction; where all possible pairs of acronym-meaning and referent-description are located and indexed; and definition selection, where the relevant data pair is identified and the final answer of the system is generated.</p><p>The following sections describe each of these modules and their main tasks.</p><p>3 Answering Factual Questions</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Passage Retrieval</head><p>The passage retrieval (PR) method is specially suited for the QA task (Gómez-Soriano et al., 2005). It allows retrieving the passages with the highest probability to contain the answer, instead of simply recover the passages sharing a subset of words with the question. Given a user question, the PR method finds the passages with the relevant terms (non-stopwords) using a classical information retrieval technique based on the vector space model. Then, it measures the similarity between the n-gram sets of the passages and the user question in order to obtain the new weights for the passages. The weight of a passage is related to the largest n-gram structure of the question that can be found in the passage itself. The larger the n-gram structure, the greater the weight of the passage. Finally, it returns to the user the passages with the new weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Similarity measure</head><p>The similarity between a passage d and a question q is defined by <ref type="bibr" coords="2,335.63,593.28,10.62,8.96" target="#b0">(1)</ref>.</p><formula xml:id="formula_0" coords="2,252.48,606.03,107.30,37.17">( ) (<label>)</label></formula><formula xml:id="formula_1" coords="2,237.96,607.96,279.67,57.85">( ) ∑ ∑ ∑ ∑ = ∈ ∀ = ∈ ∀ = n j Q x j n j Q x j j j Q j x h D j x h q d sim 1 1 ), ( ), ( ,<label>(1)</label></formula><p>Where sim(d, q) is a function which measures the similarity of the set of n-grams of the question q with the set of n-grams of the passage d. Q j is the set of j-grams that are generated from the question q and D j is the set of jgrams of the passage d. That is, Q 1 will contain the question unigrams whereas D 1 will contain the passage unigrams, Q 2 and D 2 will contain the question and passage bigrams respectively, and so on until Q n and D n . In both cases, n is the number of question terms. The result of ( <ref type="formula" coords="2,139.74,730.32,3.90,8.96" target="#formula_1">1</ref>) is equal to 1 if the longest n-gram of the question is in the set of passage n-grams. The function h(x(j), D j ) measures the relevance of the j-gram x(j) with respect to the set of passage j-grams, whereas the function h(x(j), Q j ) is a factor of normalization <ref type="foot" coords="3,307.32,84.30,3.00,5.40" target="#foot_0">1</ref> . The function h assigns a weight to every question ngram as defined in (2).</p><p>( )</p><formula xml:id="formula_2" coords="3,224.52,109.21,291.43,41.57">     ∈ = ∑ = otherwise D j x if w D j x h j j k x j k 0 ) ( ), ( 1 ) 1 ( ˆ (2)</formula><p>Where the notation ) 1 ( ˆk x indicates the k-th unigram included in the j-gram x, and ) 1 ( ˆk x w specifies the associated weight to this unigram. This weight gives an incentive to the terms -unigrams-that appear rarely in the document collection. Moreover, this weight should also discriminate the relevant terms against those (e.g. stopwords) which often occur in the document collection.</p><p>The weight of a unigram is calculated by (3):</p><p>( )</p><formula xml:id="formula_3" coords="3,255.24,223.19,259.63,27.32">( ) N n w k k x x log 1 log 1 ) 1 ( ) 1 ( ˆ+ - =<label>(3)</label></formula><p>Where , and N is the total number of passages in the collection. We assume that the stopwords occur in every passage (i.e., n takes the value of N). For instance, if the term appears once in the passage collection, its weight will be equal to 1 (the maximum weight), whereas if the term is a stopword, then its weight will be the lowest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Answer Extraction</head><p>This component aims to establish the better answer to the given question. In order to do that, it first determines a small set of candidate answers, and then, it selects the final unique answer taking into consideration the position of the candidate answers inside the retrieved passages.</p><p>The algorithm applied to extract the more probable answer from the given set of relevant passages is described below. For more detail refer to (Del-Castillo et al., 2004).</p><p>1. Extract all the unigrams that satisfy some given typographic criteria. These criteria depend on the type of expected answer. For instance, if the expected answer is a named entity, then we select the unigrams starting with an uppercase letter. But if the answer must be a quantity, then we select the unigrams expressing numbers. 2. Determine all the n-grams assembled from the selected unigrams. These n-grams can only contain the selected unigrams and some stopwords. 3. Rank the n-grams based on their compensated frequency. The compensated frequency of the n-gram x(n) is computed as follows:</p><formula xml:id="formula_4" coords="3,241.80,492.40,275.84,41.66">∑ ∑ ∑ = + - = ∈ ∀ = n i i n j G y i y i x n x i j f f n F 1 1 1 ) ( ) ( ) ( 1 (4)</formula><p>where G i indicates the set of i-grams, y(i) represents the i-gram y, ) ( ˆi x j is the j-th i-gram included in x(n), ) (i y f specifies the frequency of occurrence of the i-gram y, and F x(n) indicates the compen- sated frequency of x(n). 4. Select the top five n-grams as candidate answers. 5. Compute a ranking score for each candidate answer. This score is defined as the weight of the first retrieved passage (refer to formula 1) that contains the candidate answer. 6. Select as the final respond the candidate answer with the greatest ranking score. In the case that two or more of the candidate answers have the same ranking score, then we select the one with the greatest compensated frequency.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Answering Definition Questions</head><p>Our system uses an alternative method to answer definition questions. This method makes use of some regularities of language and some stylistic conventions of news letters to capture the possible answer for a given definition question. A similar approach was presented in <ref type="bibr" coords="4,276.12,117.84,108.82,8.96">(Ravichandran et al., 2001;</ref><ref type="bibr" coords="4,387.48,117.84,59.26,8.96" target="#b7">Saggion, 2004)</ref>.</p><p>The process of answering a definition question considers to main tasks. First, the definition extraction, which detects the text segments that contains the description or meaning of a term (in particular those related with the name of a person or an organization). Then, the definition selection, where the most relevant description for a given question term is identified and the final answer of the system is generated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Definition Extraction</head><p>The language regularities and the stylistic conventions of news letters are captured by two basic lexical patterns. These patterns allow constructing two different definition catalogs. The first one includes a list of pairs of acronym-meaning. The other one consists of a list of referent-description couples.</p><p>In order to extract the acronym-meaning pairs we use an extraction pattern based on the use of parentheses.</p><formula xml:id="formula_5" coords="4,240.00,258.84,277.64,9.77">w 1 &lt;meaning&gt; ( &lt;acronym&gt; )<label>(5)</label></formula><p>In this pattern, w 1 is a lowercase non stopword, &lt;meaning&gt; is a sequence of words starting with an uppercase letter (that can also include some stopwords), and &lt;acronym&gt; indicates a single word also starting with an uppercase letter.</p><p>By means of this pattern we could identify pairs like [PARM -Partido Auténtico de la Revolución Mexicana]. In particular this pair was catch from the following paragraph: "El Partido Auténtico de la Revolución Mexicana (PARM) nombró hoy, sábado, a Álvaro Pérez Treviño candidato presidencial de ese organismo para las elecciones federales del 21 de agosto de 1994".</p><p>In contrast, the extraction of referent-description pairs is guided by the occurrence of a special kind of appositive phrases. This information was encapsulated in the following extraction pattern.</p><formula xml:id="formula_6" coords="4,230.52,409.32,287.12,9.77">w 1 w 2 &lt;description&gt; , &lt;referent&gt; ,<label>(6)</label></formula><p>Where w 1 may represent any word, except for a preposition, w 2 is a determiner, &lt;description&gt; is a free sequence of words, and &lt;referent&gt; indicates a sequence of words starting with an uppercase letter or being in the stopwords list.</p><p>Applying this extraction pattern over the below paragraph we could find the pair [Alain Lombard -El director de la Orquesta Nacional de Burdeos].</p><p>"El director de la Orquesta Nacional de Burdeos, Alain Lombard, ha sido despedido por el Ayuntamiento de esta ciudad, que preside Alain Juppé, tras un informe que denuncia malos funcionamientos y gastos excesivos".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Definition Selection</head><p>The main quality of the above extraction patterns is their generality. They can be applied to different languages without requiring major adaptation changes. However, this generality causes the patterns to often extract non relevant information, i.e., information that does not indicate a relation acronym-meaning or referent-description. For instance, when using the extraction pattern <ref type="bibr" coords="4,263.16,596.88,11.71,8.96" target="#b4">(5)</ref> to analyze the following news we obtain the incorrect definition pair [Ernie Els -AFS]. In this case the resultant pair does not express an acronym-meaning relation; instead it indicates a person-nationality association.</p><p>Ernie Els (AFS) se mantiene en cabeza de la lista de ganancias de la "Orden de Mérito" de golf, con más de 17 millones de pesetas, mientras que el primer español es Miguel Angel Martín, situado en el puesto decimoséptimo, con 4.696.020.</p><p>Given that the catalogs contains a mixture of correct and incorrect relation pairs, it is necessary to do an additional process in order to select the most probable answer for a given definition question. The proposed approach is supported on the idea that, on the one hand, the correct information is more abundant than the incorrect one, and on the other hand, that the correct information is redundant.</p><p>Thus, the process of definition selection considers the following two criteria:</p><p>1. The more frequent definition in the catalog has the highest probability to be the correct answer.</p><p>2. The largest and therefore more specific definitions tend to be the more pertinent answers.</p><p>The following example illustrates the process. Assume that the user question is "who is Félix Ormazabal?", and that the definition catalog contains the records showed below. Then, the method selects the description "diputado general de Alava" as the most probable answer. This decision is based on the fact that this answer is the more frequent description in the catalog related to Félix Ormazabal.</p><p>Félix Ormazabal: Joseba Egibar: Félix Ormazabal: candidato alavés: Félix Ormazabal: diputación de este territorio: Félix Ormazabal: presidente del PNV de Alava y candidato a diputado general: Félix Ormazabal: nuevo diputado general Félix Ormazabal: diputado Foral de Alava Félix Ormazabal: través de su presidente en Alava Félix Ormazaba : diputado general de Alava Félix Ormazabal: diputado general de Alava Félix Ormazabal: diputado general de Alava</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation Results</head><p>We participate in the evaluation task on three different languages: Spanish, Italian and French. For each language we submitted two runs. The first group of them (tova051 runs) implements the system as described in the previous sections. The second group (tova052 runs) resolves some factual questions as if they were definition questions. The selected questions were those asking for the name of a personality or for the acronym of an organization.</p><p>Table <ref type="table" coords="5,107.61,371.88,4.98,8.96" target="#tab_0">1</ref> shows our global results on the three languages. It is noticed that the Spanish results were slightly better than the Italian and French ones. The following tables detail our results by question types. Table <ref type="table" coords="5,339.29,491.28,4.98,8.96" target="#tab_1">2</ref> shows the accuracy on factual questions; table <ref type="table" coords="5,86.74,502.80,4.98,8.96">3</ref> indicates the results on definition questions, and finally, table <ref type="table" coords="5,353.39,502.80,4.98,8.96">4</ref> shows the achieved results on temporal questions. Our general conclusion is that the method for answering factual questions is language independent. Unfortunately we can assert the same for our approach to answer definition questions.</p><p>On the other hand, it is important to mention that the temporal questions were treated as if they were factual questions. Currently we do not have a specific method for answering this kind of questions. As we mention in section 4, the definition catalogs have several erroneous registers. Also, they are incomplete, since they do not include all possible acronym-meaning and referent-description pairs. Nevertheless, they contain a large amount of registers and constitute a valuable information repository for answering definition questions. The tables 5 and 6 compare the catalogs that were extracted for each language. The above tables reveal an important association between the sizes of the document collection and the generated catalogs. This is of great relevance since our approach of answer selection is mainly based on the definition redundancy. However, the tables also seem indicate that the extraction patterns are not totally language independent. This assertion is based on the fact that we obtain fewer descriptions per referent for the French, even when the Italian collection is slightly smaller.</p><p>The tables 7 and 8 show our results on answering definition questions related to acronyms as well as to personality descriptions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>This paper presents a question answering system that allows answering factual and definition questions. This system is based on a full data-driven approach. The main idea behind the approach is that the questions and their answers are commonly expressed using the same set of words, and therefore, it simply uses a lexical pattern matching method to identify relevant document passages and to extract the candidate answers. The experiments on Spanish, Italian and French have shown the potential and portability of our approach. They also indicated that our method for answering factual question, which is based on the matching and counting of n-grams, is language independent. However, this method greatly depends on the redundancy of the answers in the target collection. This condition limited the method to a poor accuracy.</p><p>On the contrary, the method for answering definition questions is very precise. Nevertheless, we can not conclude about it language independence.</p><p>As future work we plan to improve the ranking score for the factual answers. This will help in reducing the dependence of our method to the data redundancy. We also consider to evaluate the quality of the definition catalogs in order to conclude something about the language independence of our approach.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,227.88,382.85,138.36,8.10"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Block diagram of the system</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,105.12,400.61,384.48,76.26"><head>Table 1 .</head><label>1</label><figDesc>Overall accuracy results</figDesc><table coords="5,105.12,414.53,384.48,62.34"><row><cell></cell><cell cols="6">tova051itit tova052itit tova051frfr tova052frfr tova051eses tova052eses</cell></row><row><cell>Right</cell><cell>53</cell><cell>55</cell><cell>69</cell><cell>70</cell><cell>82</cell><cell>77</cell></row><row><cell>Wrong</cell><cell>138</cell><cell>135</cell><cell>121</cell><cell>120</cell><cell>109</cell><cell>113</cell></row><row><cell>Inexact</cell><cell>9</cell><cell>10</cell><cell>10</cell><cell>10</cell><cell>7</cell><cell>8</cell></row><row><cell>Unsupported</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>2</cell><cell>2</cell></row><row><cell>Overall Accuracy</cell><cell>26.5%</cell><cell>27.5%</cell><cell>34.5%</cell><cell>35.0%</cell><cell>41.0%</cell><cell>38.5%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,102.72,566.09,389.40,171.42"><head>Table 2 .</head><label>2</label><figDesc>Accuracy on factual questions</figDesc><table coords="5,102.72,579.89,389.40,157.62"><row><cell></cell><cell cols="6">tova051itit tova052itit tova051frfr tova052frfr tova051eses tova052eses</cell></row><row><cell>Right</cell><cell>26</cell><cell>28</cell><cell>32</cell><cell>33</cell><cell>34</cell><cell>28</cell></row><row><cell>Wrong</cell><cell>89</cell><cell>86</cell><cell>84</cell><cell>83</cell><cell>77</cell><cell>82</cell></row><row><cell>Inexact</cell><cell>5</cell><cell>6</cell><cell>4</cell><cell>4</cell><cell>5</cell><cell>6</cell></row><row><cell>Unsupported</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>2</cell><cell>2</cell></row><row><cell>Accuracy</cell><cell>21.7%</cell><cell>23.3%</cell><cell>26.7%</cell><cell>27.5%</cell><cell>28.8%</cell><cell>23.7%</cell></row><row><cell></cell><cell></cell><cell cols="3">Table 3. Accuracy on definition questions</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="6">tova051itit tova052itit tova051frfr tova052frfr tova051eses tova052eses</cell></row><row><cell>Right</cell><cell>21</cell><cell>21</cell><cell>33</cell><cell>33</cell><cell>40</cell><cell>40</cell></row><row><cell>Wrong</cell><cell>26</cell><cell>26</cell><cell>12</cell><cell>12</cell><cell>9</cell><cell>9</cell></row><row><cell>Inexact</cell><cell>3</cell><cell>3</cell><cell>5</cell><cell>5</cell><cell>1</cell><cell>1</cell></row><row><cell>Unsupported</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Accuracy</cell><cell>42.0%</cell><cell>42.0%</cell><cell>66.0%</cell><cell>66.0%</cell><cell>80.0%</cell><cell>80.0%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,104.64,215.33,381.73,85.98"><head>Table 5 .</head><label>5</label><figDesc>Data of the acronym-meaning catalog</figDesc><table coords="6,104.64,229.13,381.73,72.18"><row><cell></cell><cell cols="3">Acronym-meaning catalog</cell><cell cols="2">Document collection</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>meanings</cell><cell></cell><cell></cell><cell>acronyms</cell><cell>meanings</cell></row><row><cell></cell><cell cols="2">#acronyms #meanings</cell><cell>per</cell><cell># sentences</cell><cell>#words</cell><cell>per</cell><cell>per</cell></row><row><cell></cell><cell></cell><cell></cell><cell>acronym</cell><cell></cell><cell></cell><cell>sentence</cell><cell>sentences</cell></row><row><cell>Spanish</cell><cell>14,921</cell><cell>263,388</cell><cell>17.65</cell><cell cols="2">5,636,945 151,553,838</cell><cell>0.0026</cell><cell>0.046</cell></row><row><cell>French</cell><cell>8,375</cell><cell>66,690</cell><cell>7.96</cell><cell>2,069,012</cell><cell>45,057,929</cell><cell>0.0040</cell><cell>0.032</cell></row><row><cell>Italian</cell><cell>4,588</cell><cell>21,606</cell><cell>4.71</cell><cell>2,282,904</cell><cell>49,343,596</cell><cell>0.0020</cell><cell>0.009</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,105.00,321.65,384.34,87.18"><head>Table 6 .</head><label>6</label><figDesc>Data of the referent-description catalog</figDesc><table coords="6,105.00,336.05,384.34,72.78"><row><cell></cell><cell cols="3">Referent-description catalog</cell><cell cols="2">Document collection</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>descriptions</cell><cell></cell><cell></cell><cell>referents</cell><cell>desriptions</cell></row><row><cell></cell><cell cols="2">#referents #descriptions</cell><cell>per</cell><cell>#sentences</cell><cell>#words</cell><cell>per</cell><cell>per</cell></row><row><cell></cell><cell></cell><cell></cell><cell>referent</cell><cell></cell><cell></cell><cell>sentence</cell><cell>sentence</cell></row><row><cell>Spanish</cell><cell>131,356</cell><cell>563,411</cell><cell>4.29</cell><cell cols="3">5,636,945 151,553,838 0.02330</cell><cell>0.09995</cell></row><row><cell>French</cell><cell>31,864</cell><cell>58,905</cell><cell>1.85</cell><cell cols="2">2,069,012 45,057,929</cell><cell>0.01540</cell><cell>0.02847</cell></row><row><cell>Italian</cell><cell>45,856</cell><cell>125,023</cell><cell>2.73</cell><cell cols="2">2,282,904 49,343,596</cell><cell>0.02009</cell><cell>0.05476</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,102.72,509.57,384.35,76.14"><head>Table 7 .</head><label>7</label><figDesc>Accuracy on questions about acronyms</figDesc><table coords="6,102.72,523.37,384.35,62.34"><row><cell></cell><cell cols="2">tova051eses tova052eses</cell><cell>tova051frfr</cell><cell>tova052frfr</cell><cell>tova051itit</cell><cell>tova052itit</cell></row><row><cell>Right</cell><cell>20</cell><cell>20</cell><cell>14</cell><cell>14</cell><cell>10</cell><cell>10</cell></row><row><cell>Wrong</cell><cell>8</cell><cell>8</cell><cell>11</cell><cell>11</cell><cell>22</cell><cell>22</cell></row><row><cell>ineXact</cell><cell>1</cell><cell>1</cell><cell>3</cell><cell>3</cell><cell>2</cell><cell>2</cell></row><row><cell>Unsopported</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Accuracy</cell><cell>69.0%</cell><cell>69.0%</cell><cell>50.0%</cell><cell>50.0%</cell><cell>29.4%</cell><cell>29.4%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,101.40,605.93,386.75,76.26"><head>Table 8 .</head><label>8</label><figDesc>Accuracy on questions about personality descriptions</figDesc><table coords="6,101.40,619.85,386.75,62.34"><row><cell></cell><cell>tova051eses</cell><cell>tova052eses</cell><cell>tova051frfr</cell><cell>tova052frfr</cell><cell>tova051itit</cell><cell>tova052itit</cell></row><row><cell>Right</cell><cell>20</cell><cell>20</cell><cell>19</cell><cell>19</cell><cell>11</cell><cell>11</cell></row><row><cell>Wrong</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>4</cell><cell>4</cell></row><row><cell>ineXact</cell><cell>0</cell><cell>0</cell><cell>2</cell><cell>2</cell><cell>1</cell><cell>1</cell></row><row><cell>Unsopported</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Acurracy</cell><cell>95.2%</cell><cell>95.2%</cell><cell>86.4%</cell><cell>86.4%</cell><cell>68.8%</cell><cell>68.8%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,76.18,743.93,381.47,8.10"><p>We introduce the notation x(n) for the sake of simplicity. In this case x(n) indicates the n-gram x of size n.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work was done under partial support of <rs type="funder">CONACYT</rs> (Project Grant <rs type="grantNumber">43990</rs>), <rs type="funder">SNI-Mexico</rs>, and the <rs type="funder">Human Language Technologies Laboratory of INAOE</rs>. We also like to thanks to the CLEF organization committee.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_84GMUws">
					<idno type="grant-number">43990</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,74.68,328.68,449.78,8.96;7,85.08,340.32,383.23,8.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,464.88,328.68,59.58,8.96;7,85.08,340.32,120.83,8.96">TALP-QA System for Spanish at CLEF-2004</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ageno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ferrés</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kanaan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Rodríguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Surdeanu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Turmo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,213.45,340.32,181.44,8.96">Working Notes for the CLEF 2004 Workshop</title>
		<meeting><address><addrLine>Bath, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,74.68,352.68,449.91,8.96;7,85.08,364.20,62.59,8.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,301.68,352.68,141.64,8.96">Data-intensive Question Answering</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Brill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Banko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Dumais</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,456.00,352.68,68.59,8.96;7,85.08,364.20,33.27,8.96">TREC 2001 Proceedings</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,74.68,376.68,449.83,8.96;7,85.08,388.08,439.19,8.96;7,85.08,399.72,92.61,8.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,358.44,376.68,166.07,8.96;7,85.08,388.08,69.83,8.96">QA on the web: A preliminary study for Spanish language</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Del-Castillo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y-Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Villaseñor-Pineda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,162.10,388.08,357.28,8.96">Proceedings of the 5th Mexican International Conference on Computer Science (ENC04)</title>
		<meeting>the 5th Mexican International Conference on Computer Science (ENC04)<address><addrLine>Colima, Mexico</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,74.68,412.08,449.78,8.96;7,85.08,423.60,439.25,8.96;7,85.08,435.24,278.38,8.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,393.12,412.08,131.33,8.96;7,85.08,423.60,132.72,8.96">A Passage Retrieval System for Multilingual Question Answering</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Gómez-Soriano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y-Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Sanchis-Arnal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,345.63,423.60,178.70,8.96;7,85.08,435.24,119.96,8.96">of the 8th International Conference on Text, Speech and Dialog, TSD 2005</title>
		<meeting><address><addrLine>Karlovy Vary, Czech Republic</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>To appear in the proceedings</note>
</biblStruct>

<biblStruct coords="7,74.68,447.60,449.63,8.96;7,85.08,459.24,339.35,8.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,405.60,447.60,118.71,8.96;7,85.08,459.24,57.24,8.96">The University of Amsterdam at QA@CLEF</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Jijkoun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Mishne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Schlobach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,169.91,459.24,181.32,8.96">Working Notes for the CLEF 2004 Workshop</title>
		<meeting><address><addrLine>Bath, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,74.68,471.60,449.77,8.96;7,85.08,483.12,439.06,8.96;7,85.08,494.76,42.07,8.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,490.44,471.60,34.01,8.96;7,85.08,483.12,217.92,8.96">The Use of Lexical Context in Question Answering for Spanish</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pérez-Coutiño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Solorio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y-Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>López-López</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Villaseñor-Pineda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,310.32,483.12,184.50,8.96">Working Notes for the CLEF 2004 Workshop</title>
		<meeting><address><addrLine>Bath, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,74.68,507.12,449.82,8.96;7,85.08,518.76,73.66,8.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,214.44,507.12,269.84,8.96">Learning Surface Text Patterns for a Question Answering System</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ravichandran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Hovy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,504.54,507.12,19.96,8.96;7,85.08,518.76,44.20,8.96">ACL Conference</title>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,74.68,531.24,382.49,8.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,135.00,531.24,264.48,8.96">Identifying Definitions in Text Collections for Question Answering</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Saggion</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,406.56,531.24,25.54,8.96">LREC</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,74.68,543.60,449.81,8.96;7,85.08,555.24,436.42,8.96" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,312.48,543.60,212.01,8.96;7,85.08,555.24,72.25,8.96">Los sistemas de Búsqueda de Respuestas desde una perspectiva actual</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Vicedo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Rodríguez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Massot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,163.78,555.24,306.15,8.96">Revista de la Sociedad Española para el Procesamiento del Lenguaje Natural</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
