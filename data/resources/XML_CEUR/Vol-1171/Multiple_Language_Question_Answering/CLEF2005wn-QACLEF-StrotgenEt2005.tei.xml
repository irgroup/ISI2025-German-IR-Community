<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,189.00,69.71,244.14,13.63;1,177.48,84.71,256.68,13.63">A Fast Forward Approach to Cross-lingual Question Answering for English and German</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,219.24,120.57,57.74,8.43"><forename type="first">Robert</forename><surname>Strötgen</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Hildesheim</orgName>
								<address>
									<addrLine>Information Science Marienburger Platz 22 -31141</addrLine>
									<postCode>D-31141</postCode>
									<settlement>Hildesheim, Hildesheim</settlement>
									<country>Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,283.08,120.57,54.31,8.43"><forename type="first">Thomas</forename><surname>Mandl</surname></persName>
							<email>mandl@uni-hildesheim.de</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Hildesheim</orgName>
								<address>
									<addrLine>Information Science Marienburger Platz 22 -31141</addrLine>
									<postCode>D-31141</postCode>
									<settlement>Hildesheim, Hildesheim</settlement>
									<country>Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,344.28,120.57,58.79,8.43"><forename type="first">René</forename><surname>Schneider</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Hildesheim</orgName>
								<address>
									<addrLine>Information Science Marienburger Platz 22 -31141</addrLine>
									<postCode>D-31141</postCode>
									<settlement>Hildesheim, Hildesheim</settlement>
									<country>Germany, Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,189.00,69.71,244.14,13.63;1,177.48,84.71,256.68,13.63">A Fast Forward Approach to Cross-lingual Question Answering for English and German</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A3F9DF212AC0A50E0127B3170C9A4BB6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software Measurement, Performance, Experimentation Question answering, Named entities</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the development of a question answering system for monolingual and cross-lingual tasks for the languages English and German. We developed the question answering system from a document and retrieval focused perspective. The system consists of question and answering taxonomies, named entity recognition, term expansion modules, a multi-lingual search engine based on Lucene and a passage extraction and ranking component. The overall architecture and heuristics applied during development are described. We discuss the results at CLEF 2005 and show potential future work.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The question answering (QA) system developed at the University of Hildesheim for the participation in this years' QA track at CLEF<ref type="foot" coords="1,192.84,495.40,3.04,5.48" target="#foot_0">1</ref> is mainly based on experience from multi-lingual retrieval in previous years. Our system can do mono-lingual QA and cross-lingual retrieval, both for German and English as topic and document language. The architecture of this basic QA system is based on a retrieval engine developed for multi-lingual adhoc retrieval <ref type="bibr" coords="1,143.04,529.89,70.09,8.43" target="#b0">(Hackl et al. 2005)</ref>. Further components necessary for a QA system <ref type="bibr" coords="1,401.88,529.89,117.11,8.43" target="#b1">(Harabagiu &amp; Moldovan 2003)</ref> and some for system improvement were developed additionally. As required components we implemented a question and answer taxonomy, a translation utility for automatically translating questions and a passage extraction and ranking passages from the documents. In addition, we integrated a tool for named entity recognition and term expansion. Many of the components were developed within a class for graduate students. All source code was developed with JAVA.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Query Processing</head><p>The query processing includes the assignment of a question and expected answer type, named entity recognition, translation and stopword removal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Question and Answer Taxonomies</head><p>A question taxonomy based on the questions of previous QA tracks <ref type="bibr" coords="2,362.76,89.73,83.87,8.43" target="#b3">(Magnini et al. 2005)</ref> was developed. It contains eleven question classes and several subclasses for the question types WHO, HOW, WHAT and WHERE and the corresponding answer classes. An evaluation based on the CLEF QA topics form the years 2003 and 2004 showed that overall, for 73% of the questions, the answer category was assigned correctly. For further 14%, the categorization was partly correct and for another14% of the questions, a wrong category was assigned. The taxonomy was most reliable for the question types WHEN, WITH WHAT and FOR WHAT. Questions starting with WHAT were categorized worst.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Named Entity Recognition</head><p>Previously, we analyzed the impact of named entities on query performance in ad-hoc retrieval and found, that queries are often solved better when named entities are present <ref type="bibr" coords="2,358.20,218.13,131.79,8.43" target="#b5">(Mandl &amp; Womser-Hacker 2005)</ref>. As a consequence, we included named entity recognition from the beginning. The goal was, to identify named entities and to create a separate index for them. An analysis of three named entity recognition systems on the CLEF topics showed that the performance is satisfying and can be improved by training <ref type="bibr" coords="2,396.84,250.53,70.21,8.43" target="#b5">(Mandl et a.. 2005)</ref>. LingPipe<ref type="foot" coords="2,126.72,259.24,3.04,5.48" target="#foot_1">2</ref> was used as a basic tool. Lingpipe applies a statistical machine learning approach to named entitiy recognition and categorization. For training LingPipe, we used one annotated corpus for each language:</p><p>• German: Frankfurter Rundschau with 36 Million word forms (Source: Linguistic Data Consortium, LDC<ref type="foot" coords="2,145.08,292.24,3.04,5.48" target="#foot_2">3</ref> ) • English: Reuters News (810.000 news texts)</p><p>An evaluation revealed a recognition rate of 60% for correct recognition and 42% for correct categorization into the following four classes: Person (PER), Organization (ORG), Place (LOC) und Miscellaneous (MISC). Named entity recognition was applied to the queries and to the document corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Query Translation</head><p>The key component for cross-lingual QA is a translation utility. As underlying systems, we used Babelfish, FreeTranslation and Linguatec<ref type="foot" coords="2,207.84,410.44,3.04,5.48" target="#foot_3">4</ref> . To avoid a large influence of wrongly translated named entities, we replaced all named entities found in the query except for the category MISC with a dummy which was not translated by the translation tools. In addition, the named entities were sent to the translation tool without context subsequently. All translated sentences and terms were collected and only stopwords were removed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Term Expansion</head><p>For retrieving German answers, the translated keywords were expanded using GermaNet<ref type="foot" coords="2,427.44,495.52,3.04,5.48" target="#foot_4">5</ref> . However, to avoid the addition of too many senses, the expansion was only carried out, when GermaNet included only one meaning of the word under question. For English, the synonym function of WordNet<ref type="foot" coords="2,380.28,517.24,3.04,5.48" target="#foot_5">6</ref> was used to expand all translated terms. The effect of term expansion has not been evaluated for our system yet.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Searching and Passage Retrieval</head><p>For stemming, indexing and retrieval we employed Lucene<ref type="foot" coords="2,324.12,589.36,3.04,5.48" target="#foot_6">7</ref> as it has been used in <ref type="bibr" coords="2,423.00,591.45,73.45,8.43" target="#b0">(Hackl et al. 2005)</ref>. The system searched with the keywords provided and first returned documents. These were split into passages of size of at least 200 including the remainder until the next punctuation mark.</p><p>These passages were again indexed as documents by Lucene and ranked according to a scoring algorithm which rewards the frequency of occurrence of keywords in the passage <ref type="bibr" coords="3,342.96,79.53,68.67,8.43" target="#b2">(Light et al. 2001)</ref>. The same set of keywords was used for retrieval and ranking. The top ranked passages are returned. A user interface which allows question input and which shows the top three passages has also been developed. A few heuristics were implemented to improve performance. We focused on named entities especially.</p><p>• If named entity is the expected answer type and there are documents in the answer set which contain named entities of the appropriate type, then only these documents are forwarded to the passage extraction. • If named entity is the expected answer type the most frequent named entities of the expected type within all passages are determined and the first passages containing these named entities are returned.</p><p>• If no answer with named entities is found, then the first 90 characters of the most highly ranked passage are returned. • Trivial answers are not returned. Answers are considered trivial if they contain only one word, if they consist in the name of a known news agency of if the answer string is a subset of the question string. • When the expected answer type is named entity, then all named entities in the first 20 passages are extracted and the most frequent named entity is returned. The confidence weight returned by the system is the retrieval status value returned by Lucene for the returned passage. NIL is returned when no document is found by Lucene and in this case, a confidence value of 1.0 is assigned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments and Results</head><p>The quality of the results was only satisfying for definition questions. For this first participation and considering the focus on named entities, this seems acceptable. The results are shown in table <ref type="table" coords="3,398.52,328.05,3.45,8.43" target="#tab_0">1</ref>. The weak performance is probably due to several reasons. The time and effort dedicated to evaluation was mainly aimed at system stability and the integration of all tools. Parameter tuning based on previous CLEF experiments were not carried out so far. In addition, this year CLEF required a very short answer. Our system returns passages of at least the length 200 and no further processing is done to extract a short answer. This was probably an advantage for our system for definition questions, where the performance was good.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Outlook</head><p>The system for QA can be improved by further integrating the question analysis and the search process. So far, the knowledge gained from the question in not fully exploited. Furthermore, the system needs to be evaluated more thoroughly.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,170.88,349.32,269.87,52.31"><head>Table 1 .</head><label>1</label><figDesc>Results for QA system of the University of Hildesheim in 2005</figDesc><table coords="3,180.24,360.60,220.91,41.03"><row><cell>Languages</cell><cell>Question Type</cell><cell>Accuracy</cell></row><row><cell>English -&gt; German</cell><cell>Definition</cell><cell>18.00%</cell></row><row><cell>English -&gt; German</cell><cell>Factoid</cell><cell>0.83%</cell></row><row><cell>English -&gt; German</cell><cell>All</cell><cell>5.00%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,98.28,702.57,70.16,8.43"><p>http://clef-qa.itc.it/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,98.28,648.57,121.52,8.43"><p>http://www.alias-i.com/lingpipe/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,98.28,659.37,99.68,8.43"><p>http://www.ldc.upenn.edu/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="2,98.28,670.17,400.16,8.43"><p>http://babelfish.altavista.com/, http://www.freetranslation.com/, http://www.linguatec.net/online/ptwebtext/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="2,98.28,680.97,157.76,8.43"><p>http://www.sfs.nphil.uni-tuebingen.de/lsd/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="2,98.28,691.77,121.75,8.43"><p>http://wordnet.princeton.edu/doc</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="2,98.28,702.57,92.00,8.43"><p>http://lucene.apache.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7" coords="3,98.28,702.57,218.96,8.43"><p>http://www.uni-hildesheim.de/~rschneid/psws04odqa.html</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to acknowledge the work of several students from the <rs type="institution">University of Hildesheim</rs> who implemented the components of the QA system as part of their course work 8 . We also want to thank <rs type="person">Maarten de Rijke</rs> for his comments on an earlier version of our QA approach.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="4,92.76,94.66,426.39,7.61;4,103.44,104.38,415.51,7.61;4,103.44,114.10,415.58,7.61;4,103.44,123.82,208.27,7.61" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,324.48,94.66,194.67,7.61;4,103.44,104.38,87.38,7.61">Mono-and Cross-lingual Retrieval Experiments at the University of Hildesheim</title>
		<author>
			<persName coords=""><forename type="first">René</forename><forename type="middle">;</forename><surname>Hackl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">;</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christa</forename><surname>Womser-Hacker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,157.20,114.10,361.82,7.61;4,103.44,123.82,32.28,7.61">Multilingual Information Access for Text, Speech and Images: Results of the Fifth CLEF Evaluation Campaign</title>
		<editor>
			<persName><forename type="first">Carol</forename><forename type="middle">;</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Paul</forename><forename type="middle">;</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><forename type="middle">;</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><forename type="middle">;</forename><surname>Kluck</surname></persName>
		</editor>
		<editor>
			<persName><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">;</forename><surname>Gareth</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Bernard</forename><surname>Magnini</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin et al.</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3491</biblScope>
			<biblScope unit="page" from="165" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,92.76,139.18,426.19,8.06;4,103.44,148.90,171.43,7.61" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,250.20,139.18,67.85,7.61">Question Answering</title>
		<author>
			<persName coords=""><forename type="first">Sanda</forename><forename type="middle">&amp;</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dan</forename><surname>Moldovan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,337.20,139.31,178.53,7.94">The Oxford Handbook of Computational Linguistics</title>
		<meeting><address><addrLine>Oxford; New York</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,92.76,164.38,426.38,7.61;4,103.44,173.98,378.79,7.61" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,334.56,164.38,184.58,7.61;4,103.44,173.98,34.86,7.61">Analyses for elucidating current question answering technology</title>
		<author>
			<persName coords=""><forename type="first">Marc</forename><forename type="middle">;</forename><surname>Light</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gideon</forename><forename type="middle">S</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ellen</forename><forename type="middle">;</forename><surname>Riloff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eric</forename><surname>Breck</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,154.92,173.98,136.22,7.61">Journal of Natural Language Engineering</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
	<note>Special Issue on Question Answering Fall-Winter 2001</note>
</biblStruct>

<biblStruct coords="4,92.76,189.34,426.19,7.61;4,103.44,199.06,415.81,7.61;4,103.44,208.78,415.58,7.61;4,103.44,218.50,349.61,7.61" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,249.96,199.06,269.29,7.61;4,103.44,208.78,160.88,7.61">Multiple Language Question Answering (QA@CLEF). Overview of the CLEF 2004 Multilingual Question Answering Track</title>
		<author>
			<persName coords=""><forename type="first">Bernardo</forename><forename type="middle">;</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alessandro</forename><surname>Vallin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christelle</forename><surname>Ayache</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gregor</forename><surname>Erbach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anselmo</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paulo</forename><surname>Rocha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kiril</forename><surname>Simov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Sutcliffe</surname></persName>
		</author>
		<ptr target="http://clef.isti.cnr.it/2004/working_notes/WorkingNotes2004/35.pdf" />
	</analytic>
	<monogr>
		<title level="m" coord="4,286.08,208.78,232.94,7.61;4,103.44,218.50,63.51,7.61">Working Notes 5th Workshop of the Cross-Language Evaluation Forum, CLEF 2004</title>
		<meeting><address><addrLine>Bath, England</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,92.76,233.98,426.39,7.61;4,103.44,243.58,415.51,7.61;4,103.44,253.30,190.14,7.61" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,396.48,233.98,122.67,7.61;4,103.44,243.58,223.29,7.61">Evaluierung von Systemen für die Eigennamenerkennung im cross-lingualen Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">;</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">René</forename><forename type="middle">;</forename><surname>Schneider</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pia</forename><forename type="middle">;</forename><surname>Schnetzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christa</forename><surname>Womser-Hacker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,348.72,243.58,170.23,7.61;4,103.44,253.30,120.60,7.61">Gesellschaft für linguistische Datenverarbeitung. Beiträge der GLDV-Frühjahrstagung</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2005">2005</date>
			<pubPlace>Bonn</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,293.58,253.30,115.57,7.61;4,92.76,268.66,426.39,7.61;4,103.44,278.38,415.58,7.61;4,103.44,288.10,337.15,7.61" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,275.64,268.66,243.51,7.61;4,103.44,278.38,112.07,7.61">The Effect of Named Entities on Effectiveness in Cross-Language Information Retrieval Evaluation</title>
		<author>
			<persName coords=""><forename type="first">.</forename><forename type="middle">M</forename><surname>Frankfurt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,235.92,278.38,283.10,7.61;4,103.44,288.10,111.94,7.61">Proceedings ACM SAC Symposium on Applied Computing (SAC). Information Access and Retrieval (IAR) Track</title>
		<meeting>ACM SAC Symposium on Applied Computing (SAC). Information Access and Retrieval (IAR) Track<address><addrLine>Santa Fe, New Mexico, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-03-13">2005. March 13.-17. 2005</date>
			<biblScope unit="page" from="1059" to="1064" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
