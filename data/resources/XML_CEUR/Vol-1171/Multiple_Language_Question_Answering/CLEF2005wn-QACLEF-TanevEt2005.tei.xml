<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,119.26,146.21,364.47,18.08;1,95.84,168.13,411.31,18.08;1,203.93,190.05,195.14,18.08">Exploiting Linguistic Indices and Syntactic Structures for Multilingual Question Answering: ITC-irst at CLEF 2005</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,118.47,225.11,54.69,10.46"><forename type="first">Hristo</forename><surname>Tanev</surname></persName>
							<email>tanev@itc.it</email>
						</author>
						<author>
							<persName coords="1,181.37,225.11,71.54,10.46"><forename type="first">Milen</forename><surname>Kouylekov</surname></persName>
							<email>kouylekov@itc.it</email>
						</author>
						<author>
							<persName coords="1,261.08,225.11,77.30,10.46"><forename type="first">Bernardo</forename><surname>Magnini</surname></persName>
							<email>magnini@itc.it</email>
						</author>
						<author>
							<persName coords="1,346.50,225.11,56.53,10.46"><forename type="first">Matteo</forename><surname>Negri</surname></persName>
							<email>negri@itc.it</email>
						</author>
						<author>
							<persName coords="1,430.11,225.11,49.86,10.46;1,479.95,224.04,1.36,7.32"><forename type="first">Kiril</forename><surname>Simov</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Bulgarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Centro per la Ricerca Scientifica e Technologica ITC</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,119.26,146.21,364.47,18.08;1,95.84,168.13,411.31,18.08;1,203.93,190.05,195.14,18.08">Exploiting Linguistic Indices and Syntactic Structures for Multilingual Question Answering: ITC-irst at CLEF 2005</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">BDF6CAD7A02C0AE359C852BE23F5FEB0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:09+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Managment]: Languages-Query Languages Algorithms, Measurement, Experimentation Question answering, Multlinguality, Syntactic index, Syntactic structures, Syntactic network, Tree edit distance, Dependency trees</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This year we participated at 4 Question Answering tasks at CLEF: the Italian monolingual (I), Italian-English (I/E), Bulgarian monolingual (B), and Bulgarian-English (B/E) bilingual task. While we did not change the approach in the Italian task (I), we experimented with several new approaches based on linguistic structures and statistics in the B, I/E, and B/E tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This year we participated at 4 QA tracks: the Italian monolingual (I), Italian-English (I/E), Bulgarian monolingual (B), and Bulgarian-English (B/E) bilingual task.</p><p>Regarding the Italian monolingual task (I) we did not modify our system with respect to the previous year.</p><p>In the task B we participate for the first time, therefore we had to build a new QA system for Bulgarian using some tools and resources from the on-line QA system "Socrates".</p><p>This year we augmented the role of the linguistic processing in our QA system DIOGENE. In particular we experimented in the cross-language tasks with two novel approaches: a tree edit distance algorithm for answer extraction and syntactic based Information Retrieval (IR). Although these syntactic based approaches did not bring improvements in terms of performance, we regard these experiments as a step towards strengthening the linguistic framework on which our QA system is based. Moreover, we tested a new model for indexing of syntactic structures.</p><p>The rest of the paper is structured as follows: section 2 provides a brief overview of the QA approaches based on syntactic structures, section 3 describes the syntactic tree edit distance algorithm which we used for answer extraction, section 4 introduces our syntactic indexing and Information Retrieval (IR) model, section 5 describes our new system for QA in Bulgarian "Socrates 2", section 6 provides overview of our CLEF results, and section 7 outlines our directions for research in the future.</p><p>2 Using the syntax in a Question Answering system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>State of the art</head><p>Two consecutive years we participated at the CLEF competition with a QA system which mostly relies on a multilingual statistical module which mines the Web to validate the answer (see <ref type="bibr" coords="2,90.00,266.89,59.94,10.46" target="#b7">[Magnini 2002</ref>] for details). This year we decided to augment the role of the linguistic knowledge in the process of answer extraction and validation. We carried out two experiments for considering the syntactic structure of the sentence. Our experiments were inspired by the fact that many QA systems consider the syntactic structures of the question and the sentences which may contain the candidate answer. For example, the top performing system of the last years in the TREC QA track <ref type="bibr" coords="2,182.04,326.67,58.09,10.46" target="#b15">[Vorhees 2004</ref>] -the LCC System <ref type="bibr" coords="2,329.39,326.67,97.70,10.46" target="#b8">[Moldovan et al. 2002]</ref> uses deep syntactic parsing and representation in logical form for answer extraction. Deep syntactic analysis is used also by the Shapaqa system <ref type="bibr" coords="2,213.23,350.57,64.24,10.46" target="#b0">[Buchholz 2001</ref>] and DIMAP-QA system <ref type="bibr" coords="2,394.13,350.57,64.77,10.46" target="#b6">[Litkowski 2001</ref>].</p><p>One of the best performing in the TREC 2004 track is a QA group from the university of Singapore <ref type="bibr" coords="2,137.58,374.49,69.38,10.46" target="#b2">[Cui et al. 2005]</ref>. They base the answer extraction module of their system on preextracted syntactic patterns and approximate dependency relation matching. The authors point that a weakness of the QA systems that incorporate parsing is that they rely on exact matching of relations. They claim that although this approach has high precision it has problems with recall. They propose a corpus based evaluation of similarities of the dependency relations using point wise mutual information (PMI) <ref type="bibr" coords="2,231.28,434.26,108.75,10.46" target="#b1">[Church and Hanks 1989]</ref>. In this way they calculate the cost of transforming the syntactic tree of the question to a candidate syntactic tree of the document.</p><p>In <ref type="bibr" coords="2,118.45,458.17,103.81,10.46" target="#b11">[Punyakanok et al. 2004</ref>] the authors build a QA system based on a mapping algorithm that is a modification of the edit distance algorithm presented in <ref type="bibr" coords="2,387.55,470.13,109.10,10.46" target="#b16">[Zhang and Shasha 1990]</ref> for syntactic trees. Their approach is handling the language variability problem by calculating the cost of missing or changed information. The authors propose the following cost operations: insert tree; delete tree; change tree. They make rough approximation of the operations cost. The authors prove, that with this approach they outperform the simple bag-of-word approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Answer extraction using Tree-Edit Distance</head><p>We carried out this experiment in the Italian-English cross-language task. First, we used AltaVista to translate the questions from Italian to English (we used also some pre-processing and postprocessing translation rules). Second, using sentence-level IR from our syntactic index SyntNet (see section 4.2), we acquired already parsed sentences which contain question keywords. Third, we used a tree edit distance between the affirmative form of the question and the candidate sentences to extract the answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Translation from Italian to English</head><p>We used the Altavista interface to Systran (http://translate.av.com) to translate the questions from Italian into English. A set of pre-processing and post-processing transformation rules was applied to correct some of the wrong output produced by the automatic translation. Example:</p><p>• Pre-processing rule -Dov e ... -&gt; Dove é ....</p><p>• Post-processing rule -Which thing .... -&gt; What .... We also used a Collins dictionary to translate the words that were not translated by Altavista.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Edit distance on dependency trees</head><p>After we extract candidate sentences which may contain the answer, we used a modification of the tree edit distance algorithm presented in <ref type="bibr" coords="3,269.62,168.40,103.81,10.46" target="#b11">[Punyakanok et al. 2004</ref>] and <ref type="bibr" coords="3,401.14,168.40,107.62,10.46" target="#b16">[Zhang and Shasha 1990]</ref>, in order to identify the sentence closest to the question in terms of edit distance and to extract the answer from it. We adapted our algorithm to use syntactic trees already indexed in our syntactic index (we used MiniPar <ref type="bibr" coords="3,197.04,204.27,38.77,10.46">[Lin 1998</ref>] to obtain the parse trees in the index).</p><p>Since the <ref type="bibr" coords="3,148.42,216.22,109.10,10.46" target="#b16">[Zhang and Shasha 1990]</ref> algorithm does not consider labels on edges, while dependency trees provide them, each dependency relation R from a node A to a node B has been re-written as a complex label B-R concatenating the name of the destination node and the name of the relation. All nodes except the root of the tree are relabeled in such way. The algorithm is directional: we aim to find the best (i.e. less costly) sequence of edit operations that transform the dependency tree of the candidate answer sentence into the dependency tree of the question affirmative form. According to the constraints described above, the following transformations are allowed:</p><p>• Insertion: insert a node from the dependency tree of question into the dependency tree of the candidate answer sentence.</p><p>• Deletion: delete a node N from the dependency tree of the answer sentence. When N is deleted all its children are attached to the parent of N. It is not required to explicitly delete the children of N as they are going to be either deleted or substituted on a following step.</p><p>• Substitution: change the label of a node N1 in the answer sentence tree into a label of a node N2 of the question tree. Substitution is allowed only if the two nodes share the same part-of-speech. In case of substitution the relation attached to the substituted node is changed with the relation of the new node.</p><p>To adapt the algorithm we addressed the following problems:</p><p>1. Transform the dependency tree of question into the dependency tree corresponding to it's affirmative form.</p><p>2. Reorder the tree nodes to create an order of the children.</p><p>3. Estimate the costs of the delete, insert and replace operations.</p><p>The dependency tree of the question is transformed into affirmative form using a set of hand written rules whcih are activated according to the question and answer types. For some answer types a simple hand-crafted pattern that represents the most frequent syntactic relations between the question focus and the answer of the question was used. Questions with such answer types are questions that have a measure as an answer (height, length, etc.)</p><p>The edit distance algorithm presented in <ref type="bibr" coords="3,277.84,598.87,103.81,10.46" target="#b11">[Punyakanok et al. 2004</ref>] and <ref type="bibr" coords="3,406.66,598.87,104.56,10.46" target="#b16">[Zhang and Shasha 1990</ref>] requires an ordering on the children of the syntactic tree. We imposed an order on the children of a node in the tree based on the label of the dependency relations and the lexicografic order of the words in the children nodes.</p><p>In <ref type="bibr" coords="3,117.77,646.69,103.81,10.46" target="#b11">[Punyakanok et al. 2004</ref>] the authors use add-hoc weights of the basic edit operations. In our approach we decided to use cost based on statistic measures. To estimate such cost, we define a weight of each single word representing its relevance through the inverse document frequency (idf ), a measure commonly used in Information Retrieval. If N is the number of documents in a text collection and N w is the number of documents of the collection that contain word w then the idf of this word is given by the formula:</p><formula xml:id="formula_0" coords="3,255.18,734.08,257.82,24.93">idf (w) = log N N w (1) G 1 G 2 SN (1,2) stop| 1 subj obj &amp; &amp; N N N N N N N N N N N stop| 4 by / / obj ' ' O O O O O O O O O O O O subj absorbing| 5 stop| 1,4 (1,2)(4,6) subj by(4,5) / / obj(1,3)(4,7) ) ) T T T T T T T T T T T T T T T T absorbing| 5 sunscreen| 2 cancer| 3 sunscreen| 6 cancer| 7 sunscreen| 2,6 cancer| 3,7</formula><p>Figure <ref type="figure" coords="4,211.81,215.20,3.87,10.46">1</ref>: Two parse trees and their Syntactic Network.</p><p>The weight of the insertion operation is the idf of the inserted word. The most frequent words (e.g. stop words) have a zero cost of insertion. In the current version of the system we are still not able to implement a good model that estimates the cost of the deletion operation. In the current experiments we set the cost of deletion to 0. To determine the cost of substitution we used a dependency based thesaurus available at http://www.cs.ualberta.ca/ lindek/downloads.htm. For each word, the thesaurus lists up to 200 most similar words and their similarities. The cost of a substitution is calculated by the following formula:</p><formula xml:id="formula_1" coords="4,197.56,350.98,315.44,11.36">subs(w 1 , w 2 ) = ins(w 2 ) * (1 -sim(w 1 , w 2 )) (2)</formula><p>where w 1 is the word from text that is being replaced by the word w 2 from hypothesis and sim(w 1 , w 2 ) is the similarity between w 1 and w 2 in the thesaurus multiplied by the similarity between the corresponding relations. The similarity between relations is stored in a database of relation similarities obtained by comparing dependency relations from a parsed local corpus. The similarities have values from 1 (very similar) to 0 (not similar). If there is no similarity, the cost of substitution is equal to the cost of inserting the word w2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Answer Extraction</head><p>All the sentences retrieved by the IR module of the system are sorted based on the edit distance between their syntactic trees and the affirmative form of the question. As candidate answers we extracted noun phrases part of the syntactic tree of the sentences with the lowest edit distance score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Syntactic Based Information Retrieval</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Syntactic Network</head><p>The Syntactic Network (SyntNet) is a formalism for representation of a set of dependancy syntactic graphs (input graph set) produced from a dependency parser. Equal sub-structures from the input graph set are merged in one structure in SyntNet. This property facilitates identification of repeating subs-structures, allows for efficient calculation of their frequency, and makes possible efficient mining of structures which span over certain words. This last property was extensively used in our syntactic based IR experiment.</p><p>SyntNet models an input graph set, in which each of the graphs represents the syntax of a sentence from a text corpus. In a dependency syntactic graph the vertices are labeled with words or word lemmas and part of speech. In the dependency graphs each two words w and w are connected with a directed arc if and only if w governs w . Arcs in the dependency graph are labeled with syntactic relations (see figure <ref type="figure" coords="4,277.02,708.29,3.87,10.46">1</ref>).</p><p>When the SyntNet is built from the input graph set, all vertices labeled with the same word and part of speech are merged in one vertex. Moreover, all equally labeled dependency arcs which connect equally labeled vertices in the same direction are merged in one arc. Therefore, in SyntNet each vertex and arc usually represents more than one vertex and arc from the input graph set. On figure <ref type="figure" coords="5,116.89,122.49,4.98,10.46">1</ref> two dependency graphs G 1 and G 2 are merged in one SyntNet SN (1, 2). Each vertex in G 1 and G 2 is labeled with an unique number (e.g. cancer |3 , cancer |7 ). Arcs are labeled with number pairs -the number of the vertex from which the arc begins and the number of the vertex in which the arc enters (e.g. the arc stop |4 → sunscreen |6 in G 2 is labeled with the pair (4,6)). When the vertices and arcs from G 1 and G 2 are merged in the SyntNet SN (1, 2) on figure 1 their numerical labels are also merged (e.g. cancer |3,7 ) in sets of numerical labels. These numerical labels in the SyntNet allow for tracing repeating structures and calculating their frequency. For example on figure 1 we may trace the numerical labels in the sub-structure sunscreen ← stop → cancer and we can see that two possible paths exist following the numerical labels on the arcs on SN (1, 2) :</p><p>(2 ← 1, 1 → 3) and (6 ← 4, 4 → 7). Each of these paths corresponds to one occurrence of the sub-structure in the input graph sequence, therefore the above mentioned substructure appears two times.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Indexing the English CLEF collection</head><p>We parsed the English CLEF collection of texts with MiniPar <ref type="bibr" coords="5,374.71,299.51,38.78,10.46">[Lin 1998</ref>] and built a SyntNet representation from the parsed sentences. The SyntNet model was implemented as a relational database under the MySQL platform.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Retrieving and Ranking Sentences</head><p>When the question keywords are translated from Italian or Builgarian to English (see <ref type="bibr" coords="5,452.42,368.94,74.36,10.46" target="#b9">[Negri et al. 2003</ref>] and <ref type="bibr" coords="5,109.18,380.89,91.37,10.46" target="#b10">[Osenova et al. 2004]</ref> for details) we use the syntactic index SyntNet to retrieve the best sentences.</p><p>The retrieving process begins with identification of the vertices in SyntNet which represent the question keywords. For example if the question is "What stops cancer?" and the SyntNet is SN (1, 2) on figure 1, we will take the vertices stop and cancer. We call them keyword vertices. Each keyword vertex has a weight assigned -derived from its IDF.</p><p>Tracing the SyntNet up from a keyword vertex kv we record for each vertex v we encounter on our way what is the distance between v and kv. This distance is calculated from the sum of the IDF of the vertices which stay between kv and v. We will call these vertices intermediate vertices.</p><p>Keyword vertices which appear as intermediate vertices contribute 0 to the distance. Moreover, if there is some similarity (we measure similarity between words using a syntactic distributional approach similar to <ref type="bibr" coords="5,177.77,512.40,47.66,10.46">[Lin 1998a]</ref>) between an intermediate vertex and any of the key vertices, this intermediate vertex contributes to the distance only a part of its IDF.</p><p>We will denote thus calculated distance by |kv v|. Obviously, as many informative vertices stay between kv and v, as bigger their distance is. As less informative these intermediate vertices are, as low the distance is. On the other hand, as similar the intermediate vertices are to the question keywords, as lower the distance is. Actually, |kv v| models the quantity of information in the path between kv and v which is not shared with the question.</p><p>For each vertex v from the SyntNet which is a root of a tree spanning over a set of question keywords kwQv 1 , kwQv 2 , ..., kwQv n we define:</p><formula xml:id="formula_2" coords="5,186.36,623.97,229.09,28.52">syntscore(v) = kwQv i IDF (kwQv i ) I(Q) + kwQv i |kwQv i v| + IDF (v)</formula><p>In this formula I(Q) is the sum of the IDF of all the question keywords. If v is a keyword vertex, IDF (v) in the above formula is considered to be 0. This score we call syntactic context score and it evaluates a tree spanning over some the question keywords and rooted in a vertex v. In this formula the distance between the keywords in the syntactic tree as well as the informativeness of the words are taken into consideration.</p><p>Finally, the score of a sentence S is calculated as:</p><formula xml:id="formula_3" coords="5,217.27,733.08,167.27,24.03">score(s) = max v∈S syntscore(v). I(Q ∩ S) I(Q)</formula><p>In this formula I(Q ∩ S) is the sum of the IDF of the question keywords which appear in the sentence. This formula combines the highest syntactic context score in the sentence and the relative quantity of the information that the question shares with that sentence.</p><p>For the next processing steps only the top ranked sentences are considered. As a last stage DIOGENE system performs answer extarction and Web based answer validation to choose the best answer <ref type="bibr" coords="6,144.38,170.31,59.94,10.46" target="#b7">[Magnini 2002</ref>] from the retrieved sentences. 5 A QA system for Bulgarian -"Socrates 2"</p><p>In order to participate in the monolingual Bulgarian task we decided to build a QA system for Bulgarian which uses certain templates from the "Socrates" on-line QA system <ref type="bibr" coords="6,436.76,237.03,49.63,10.46" target="#b12">[Tanev 2004</ref>], but also incorporates answer extraction techniques for questions for which no patterns exist. We call this system "Socrates 2". Moreover, we decided to build a linguistic index of the Bulgarian CLEF collection in which each word is represented with its lemma and part of speech. In this index the separate sentences were represented rather than whole documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Question processing</head><p>"Socrates 2" performs question classification on the basis of simple superficial templates. It classifies the question into one of the following categories: definition questions and questions which require person, location, organization, year, date, manner, reason, or generic name as an answer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Building Linguistic Index</head><p>Instead of relying on standard search engines, we developed our own sentence retrieval engine and linguistic index of the Bulgarian CLEF collection. The text collection was split into sentences and automatically annotated with part-of-speech tags and word lemmas using the LINGUA system <ref type="bibr" coords="6,90.01,437.19,107.28,10.46">[Tanev and Mitkov 2002]</ref>. This linguistic annotation and the IDF of each word were encoded in the linguistic index which backs up our sentence retrieval module.</p><p>We think that such an approach is more appropriate for the QA task than the traditional document indexing approaches since it leads to more focused IR. Moreover, a sentence usually provides enough context for answer justification, which makes reasonable to perform IR on this level. In this way, however, some phenomena like intrasententional anaphora are ignored which may potentially lead to the lost of some answers. Another shortcoming of the linguistic indexing model is the probability of errors in the part-of-speech tagging and the sentence splitting processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Sentence retrieval</head><p>All the sentences which contain at least one of the question keywords are taken into consideration. Sentences are ranked using the following formula:</p><formula xml:id="formula_4" coords="6,255.57,599.47,90.67,24.03">score(S) = I(Q ∩ S) I(Q)</formula><p>, where I(Q) is the quantity of the information in the question and I(Q ∩ S) is the quantity of the information which the question and the sentence share. The formula finds what percent of the question information content is found in the sentence. Information content of the question I(Q) is measured as a sum of the IDF of its keywords. The quantity of the shared information content I(Q ∩ S) is the sum of the IDF of the question keywords which appear in the sentence. This can be written in the following way:</p><formula xml:id="formula_5" coords="6,243.39,717.10,116.23,21.85">I(Q) = kwi∈kwQ IDF (kw i ) I(Q ∩ S) = kw i ∈kwQ∩wS IDF (kw i )</formula><p>, where kwQ are the question keywords and wS are the words from the sentence. A keyword from the question is considered to be equal to a word from the sentence if both words have the same lemma and part of speech. This sentence ranking approach turned out to work rather satisfactory in practice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Answer extraction</head><p>For definition questions we adapted and used templates and rules already implemented in the "Socrates" on-line demo. Since these templates were already tested and tuned using real on-line users questions submitted to the Socrates Web site (http://tanev.dir.bg/Socrat.htm), we did not make any significant improvements in the system of rules.</p><p>We did not develop any specific strategy for the temporal questions, rather they were treated as factoid ones. For identification of factoid answers we created rules for extraction of generic names (without specifying if the name designates location, person, organization, or other entity), dates, and numbers. All other answer candidates (for example noun phrases which are not names or verb phrases) were ignored.</p><p>When extacting candidate answers for factoid and temporal questions, "Socrates 2" considers the top 200 ranked sentences whose score is greater than 0.5 (score(S) &gt; 0.5). Moreover, only the sentences which have score greater than 0.1 of the score of the top ranked sentence are taken into consideration. In this way, we avoid to extract answers from sentences which does not contain enough question keywords.</p><p>Name identification In the general case our system for identification of names classifies as a candidate for a name each sequence of words which begin with capital letters. However, a capitalized word in the beginning of the sentence is considered a part of a name only if it is found in the dictionary of proper names integrated in the LINGUA morphological processor <ref type="bibr" coords="7,442.63,436.36,65.84,10.46" target="#b3">[Krushkov 1997</ref>] or it is an unknown word. Usually this strategy recognizes properly the names, however we noticed that often two names appear next to each other, which causes errors in the name recognition. For example, the above mentioned heuristics will extract from the text "poslanikat na Shvecia Sten Ask" ("the ambassador of Sweden Sten Ask") the name candidate "Shvecia Sten Ask" ("Sweden Sten Ask"), while "Shvecia"("Sweden") and "Sten Ask" are two separate names. To overcome this problem, we developed a name splitting strategy which is activated in cases we have a sequence of more than two capitalized names: N 1 N 2 N 3 ...N n . In such cases we check if N 1 is a part of the sequence or should be treated as a separate name. Although the sequence can be splitted in each point, we empirically observated that in most cases the sequence should be splitted after N 1 . Therefore, in order to simplify the task and augment the processing speed we checked only if the sequence can be splitted after N 1 or no. The test is based on the assumption that if P (N 1 |N 2 N 3 ) &lt; limit then a splitting after N 1 will take place, i.e. N 1 and N 2 N 3 ...N n will be treated as separate names. We set experimentally limit = 0.8. After we introduced this name splitting strategy the name recognizer became quite accurate and the number of errors was significally decreased.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Answer scoring and ranking</head><p>The score of a candidate answer A in a sentence S is calculated considering the distance in tokens between the candidate A and each of the question keywords (kw i ) which appear in the sentence and the IDF of the keywords:</p><formula xml:id="formula_6" coords="7,212.40,683.66,177.01,28.59">score(A, S) = kwi∈kwQ∩wS IDF (kw i ) 1 + |A kw i |</formula><p>This formula gives higher score to the candidate answers which appear close to the most important question keywords. When two candidate answers have equal score, the system prefers the one which appears more often in the top ranked sentences.</p></div>		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task</head><p>Overall accuracy Definition (%) Factoid (%) Temporal (%) We submitted one run at the monolilngual Bulgarian task using our new system "Socrates2". We produced two runs in the Italian monolingual task. In the first run the answer ranking for the factoids and temporal questions for which no answer-extraction patterns exist was delegated exclusively to the Web-based answer validation module. In the second run we considered the keyword density also. As in the previous year, it turned out that considering keyword density deteriorates the result. Regarding the Italian-Englisg task, we run the two experiments described in the previous sections. In the first run we used syntactic IR for factoid and temporal questions and in the second run we used tree edit distance algorithm for factoids. We used syntactic based IR also in the Bulgarian-English cross-language task.</p><p>In all the tasks we used the multilingual template-based approach for answering definition questions <ref type="bibr" coords="8,133.55,387.29,80.44,10.46" target="#b14">[Tanev et al. 2004]</ref>.</p><p>With respect to the previous year our overall accuraccy on the monolingual Italian task dropped from 28% to 22%. In particular, the performance on the factoid questions was decreased by about 7% while the accuracy on the definition questions dropped only by 2%. Since the monolingual Italian system is the same as the one used the previous year, the decrease of the performance may be due to increased difficulty of this year questions. For the monolingual Bulgarian task we have 27.5% overall accuracy (25% factoid questions, 40% definition, and 17,65% temporal questions). These results are promissing taking into account the scarce resources we used this year and the non-refined named-entity recognition we performed.</p><p>Regarding the Italian-English cross-language task, our experiments with linguistic indices and tree-distance did not bring the expected results in terms of performance. The first run in which syntactic based IR was used for factoids and temporal questions resulted in 19.83% accuracy for factoids and 13.79% for temporal questions. The accuracy on the factoid questions is decreased by 2% from the previous year. The accuracy on the factoids in the second run where we tested tree-edit distance algorithm was only 5.8%. We have further to study how the tree edit distance algorithm will be integrated in the overall QA process.</p><p>In the Bulgarian-English cross-language task we have some performance improvement for the factoid questions with respect to the previous year: 17.4% vs. 11.7%. In this task we used syntactic based IR. The translation Bulgarian-English dictionaries were also enriched with person names. We have further to study if the improvement in the performance is due to the new IR approach, the improved translation, or the difficulty of the questions in the B/E task is lower with respect to the previous year.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and future direction</head><p>This year we experimented with linguistic indices for Bulgarian and English. The Bulgarian QA system based on the linguistic index achieved promising results considering the simplicity of the QA approach. We tested two novel approaches based on the syntax: one for IR and one for answer extraction. Although the syntactic based approaches did not show high performance, we continue our research in the exploitation of syntactic structures in QA. We believe that the methods which use linguistic knowledge are potentially more accurate than superficial ones. However, our experience at CLEF 2005 showed that different problems have to be overcome when using syntax in QA: parsing errors, syntactic paraphrases, efficiency issues, etc.</p><p>In our future work we intend to study better the use of tree edit distance algorithms. We would like also to study deeper the potential of the SyntNet model: Building on this model, we intend to develop algorithms for pre-selection of the candidate answers. We intend also to use the SyntNet in different lexical acquisition experiments, which will support the development of our QA system.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="9,90.01,248.94,423.01,10.46;9,90.00,260.90,420.13,10.46" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,176.91,248.94,336.11,10.46;9,90.00,260.90,132.62,10.46">Using Grammatical Relations, Answer Frequencies and the World Wide Web for TREC Question Answering</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Buchholz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,245.95,260.90,171.01,10.46">Proceeding of the TREC-10 Conference</title>
		<meeting>eeding of the TREC-10 Conference</meeting>
		<imprint>
			<date type="published" when="2001">2001. 2001</date>
			<biblScope unit="page" from="496" to="503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,90.00,276.78,423.02,10.46;9,90.01,288.73,264.49,10.46" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,230.45,276.78,277.96,10.46">Word Association Norms, Mutual Information, and Lexicography</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Church</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Hanks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,103.00,288.73,96.69,10.46">Proceedings of ACL-89</title>
		<meeting>ACL-89<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1989">1989</date>
			<biblScope unit="page" from="76" to="83" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,90.00,304.63,423.02,10.46;9,90.01,316.58,278.11,10.46" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,330.84,304.63,182.18,10.46;9,90.01,316.58,137.18,10.46">University of Singapore at the TREC-13 Question Answering Main Task</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Chua</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,244.60,316.58,123.51,10.46">Proceedings of the TREC-13</title>
		<meeting>the TREC-13</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,90.00,332.47,423.02,10.46;9,90.01,344.42,220.23,10.46" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="9,177.93,332.47,335.09,10.46;9,90.01,344.42,10.18,10.46">Modelling and Building of Machine Dictionaries and Morphological processors Ph</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Krushkov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
		<respStmt>
			<orgName>University of Plovdiv</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">D. Thesis</note>
	<note>in Bulgarian</note>
</biblStruct>

<biblStruct coords="9,90.00,360.30,423.01,10.46;9,90.00,372.27,269.51,10.46" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,159.41,360.30,186.57,10.46">Dependency-based evaluation of MINIPAR</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,371.77,360.30,141.24,10.46;9,90.00,372.27,187.52,10.46">Proceedings of the Workshop on Evaluation of Parsing Systems at LREC-98</title>
		<meeting>the Workshop on Evaluation of Parsing Systems at LREC-98<address><addrLine>Granada, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,90.00,388.15,423.01,10.46;9,90.00,400.11,113.76,10.46" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,157.47,388.15,231.12,10.46">Automatic Retrieval and Clustering of Similar Words</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,405.14,388.15,107.86,10.46;9,90.00,400.11,30.72,10.46">Proceedings of COLING-ACL98</title>
		<meeting>COLING-ACL98<address><addrLine>Montreal, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,90.00,415.99,423.00,10.46;9,90.00,427.94,203.31,10.46" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,180.38,415.99,260.16,10.46">CL Research Experiments in TREC-10 Question Answering</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Litkowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,457.51,415.99,55.48,10.46;9,90.00,427.94,132.22,10.46">proceeding of the TREC-10 Conference 2001</title>
		<meeting>eeding of the TREC-10 Conference 2001</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="251" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,90.00,443.83,423.02,10.46;9,90.01,455.79,423.01,10.46;9,90.00,467.74,218.37,10.46" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,334.27,443.83,178.75,10.46;9,90.01,455.79,151.16,10.46">Is it the Right Answer? Exploiting Web Redundancy for Answer Validation</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Prevete</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Tanev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,250.91,455.79,262.10,10.46;9,90.00,467.74,78.14,10.46">Association for Computational Linguistics 40th Anniversary Meeting (ACL-02)</title>
		<meeting><address><addrLine>Pennsylvania, Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,90.00,483.63,423.01,10.46;9,90.01,495.58,423.00,10.46;9,90.00,507.54,114.69,10.46" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,492.39,483.63,20.62,10.46;9,90.01,495.58,125.40,10.46">LCC Tools for Question Answering</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Moldovan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Harabagiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Girju</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Morarescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Lacatsu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Novischi</surname></persName>
		</author>
		<idno>SP 500-251</idno>
	</analytic>
	<monogr>
		<title level="m" coord="9,392.71,495.58,120.30,10.46;9,90.00,507.54,48.01,10.46">The Eleventh Text Retrieval Conference</title>
		<imprint>
			<publisher>TREC</publisher>
			<date type="published" when="2002">2002. 2003. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,90.00,523.42,423.01,10.46;9,90.01,535.38,288.26,10.46" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,267.62,523.42,245.39,10.46;9,90.01,535.38,38.87,10.46">Bridging Languages for Question Answering: DIOGENE at CLEF</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Tanev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,169.54,535.38,113.20,10.46">Proceedings of CLEF-2003</title>
		<meeting>CLEF-2003<address><addrLine>Trondheim, Norway</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,90.00,551.27,423.02,10.46;9,90.01,563.22,386.46,10.46" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="9,392.65,551.27,120.37,10.46;9,90.01,563.22,335.35,10.46">Bulgarian-English Question Answering: Adaptation of Language Resources In Proceedings of CLEF-2004</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Osenova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Simov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Simov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Tanev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kouylekov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
			<pubPlace>Bath, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,90.00,579.11,423.02,10.46;9,90.01,591.06,229.30,10.46" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="9,297.13,579.11,215.88,10.46;9,90.01,591.06,205.38,10.46">Mapping Dependencies Trees: An Application to Question Answering Proceedings of AI &amp; Math</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Punyakanok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Roth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yih</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,90.00,606.95,423.00,10.46;9,90.00,618.91,423.00,10.46;9,90.00,630.86,78.18,10.46" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,169.44,606.95,343.55,10.46;9,90.00,618.91,141.42,10.46">Socrates: A Question Answering Prototype for Bulgarian Recent Advances in Natural Language Processing III</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Tanev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,239.16,618.91,229.72,10.46">Selected Papers from RANLP 2003 John Benjamins</title>
		<meeting><address><addrLine>Amsterdam/Philadelphia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,90.01,646.74,423.00,10.46;9,90.00,658.70,198.02,10.46" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="9,242.18,646.74,270.82,10.46;9,90.00,658.70,128.84,10.46">Shallow Language Processing Architecture for Bulgarian In Proceedings of COLING 2002</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Tanev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mikov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<pubPlace>Taipei, Taiwan</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,90.00,674.58,423.03,10.46;9,90.01,686.55,422.99,10.46;9,90.00,698.50,97.66,10.46" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,421.97,674.58,91.05,10.46;9,90.01,686.55,315.58,10.46">Multilingual Pattern Libraries for Question Answering : a Case Study for Definition Questions</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Tanev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kouylekov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Negri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Coppola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Magnini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,421.65,686.55,91.35,10.46;9,90.00,698.50,20.37,10.46">Proceedings of LREC 2004</title>
		<meeting>LREC 2004<address><addrLine>Lisbon, Portugal</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,90.00,714.38,320.60,10.46" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="9,168.24,714.38,218.42,10.46">Q&amp;A Track Guidelines In proceeding of TREC-13</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Vorhees</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,90.00,730.27,423.01,10.46;9,90.01,742.22,268.75,10.46" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,227.21,730.27,281.91,10.46">Fast algorithm for the unit cost editing distance between trees</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Shasha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,90.01,742.22,92.24,10.46">Journal of algorithms</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="1245" to="1262" />
			<date type="published" when="1990-12">1990. December 1990</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
