<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,309.31,91.43,182.62,12.58">to CLEF 2005, the CL-SR Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,196.68,126.96,52.39,9.02"><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
						</author>
						<author>
							<persName coords="1,255.84,126.96,63.92,9.02"><forename type="first">Muath</forename><surname>Alzghool</surname></persName>
							<email>alzghool@site.uottawa.ca</email>
						</author>
						<author>
							<persName coords="1,343.65,126.96,55.31,9.02"><forename type="first">Aminul</forename><surname>Islam</surname></persName>
							<email>mdislam@site.uottawa.ca</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of Ottawa&apos;s Contribution</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Ottawa</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,309.31,91.43,182.62,12.58">to CLEF 2005, the CL-SR Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5F89761631274E1364AD05F783563795</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3. [Information Storage and Retrieval] H.3.1 Content Analysis and Indexing; H.3.3 Information Search and Retrieval General terms: Measurement</term>
					<term>Performance</term>
					<term>Experimentation Cross-Language Information Retrieval</term>
					<term>Spoken Document Retrieval</term>
					<term>Machine Translation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present the participation of the University of Ottawa in the Cross-Language Spoken Document Retrieval task at CLEF 2005. In order to translate the queries, we combined the results of several online Machine Translation tools. For the Information Retrieval component we used the SMART system, with several weighting schemes for indexing the documents and the queries. One scheme in particular lead to better results than other combinations. We present the results of the submitted runs and of many unofficial runs. We compare the effect of several translations from each language. We present results on phonetic transcripts of the collection and queries and on the combination of text and phonetic transcripts. We also include the results when the manual summaries and keywords are indexed.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>This paper presents the first participation of the University of Ottawa group in CLEF, the Cross-Language Spoken Retrieval (CL-SR) track. We briefly describe the task. Then, we present our system, followed by results for the submitted runs and for many unofficial runs. We experiment with many possible weighting schemes for indexing the documents and the queries. We compare the effect of several translations of the queries and of combining the translations. We look at using phonetic transcriptions of the queries and documents instead of the original ASR-produced text, and at combining the phonetic transcripts with the text. At the end we present the best results when all available information in the collection is used.</p><p>The CLEF-2005 CL-SR test collection includes 8104 segments, 75 topics (queries), and 12359 Relevance Judgments to facilitate information retrieval experiments. Segments are the unit of retrieval in the CLEF CL-SR evaluation. Interviews with survivors of the Holocaust were manually segmented to form topically coherent segments by subject matter experts at the Survivors of the Shoah Visual History Foundation. See <ref type="bibr" coords="1,501.36,566.10,23.35,9.02;1,70.92,577.56,54.52,9.02" target="#b1">(Oard et. al., 2004)</ref> for more details. Only the ASRTEXT2004A field (and optionally the keywords automatically extracted from it) were allowed to be indexed for the competition. This field contains ASR transcripts of the audio segments, with 38% word error rate. For contrastive studies, metadata for each segment (manual summaries, thesaurus terms, and person names) were included as additional fields that can optionally be indexed.</p><p>As a baseline, indexing the ASRTEXT2004A field using Okapi BM 25 term weights and searching with Title queries yielded an uninterpolated mean average precision of 0.0551 when run at the University of Maryland with the freely available PSE vector space search engine. This was evaluated on the 38 training topics, not on the 25 test topics for which we report results in this paper.</p><p>The topics were created in English from actual user requests and then translated into Czech, German, French, and Spanish by native speakers. An example topic in English is the following: &lt;top&gt; &lt;num&gt;1159 &lt;title&gt;Child survivors in Sweden &lt;desc&gt;Describe survival mechanisms of children born in 1930-1933 who spend the war in concentration camps or in hiding and who presently live in Sweden. &lt;narr&gt;The relevant material should describe the circumstances and inner resources of the surviving children. The relevant material also describes how the wartime experience affected their post-war adult life.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>&lt;/top&gt;</head><p>The Spanish, German, and Czech topics provided by the CLEF organizers contained translations of all the fields (title, description, and narrative). For French the narrative field was not translated, due to lack of time. The French topic equivalent to the above English example is the following: &lt;top&gt; &lt;num&gt;1159 &lt;title&gt;Les enfants survivants en Suède &lt;desc&gt;Descriptions des mécanismes de survie des enfants nés entre 1930 et 1933 qui ont passé la guerre en camps de concentration ou cachés et qui vivent actuellement en Suède. &lt;/top&gt;</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">System Overview</head><p>The University of Ottawa Cross-Language IR system was built with off-the-shelf components. For translating the queries from French, Spanish, and German into English, several free online machine translation tools were used. Their output was merged in order to allow for variety in lexical choices. All the translations of a title made the title of the translated query; the same was done for the fields description and narrative. For the retrieval part, the SMART IR system <ref type="bibr" coords="2,165.60,356.46,87.21,9.02">(Buckley et al., 2000)</ref> was tested with many different weighting schemes for indexing the collection and the queries. The weighting schemes are combinations of term frequency, collection frequency, and length normalization components. One scheme in particular was used in the submissions because it proved to have much better performance than other combinations. For weighting document terms we used term frequency normalized by the maximum value and probabilistic collection frequency weighting with cosine normalization. For queries we used non-normalized term frequency and inverse document frequency weighting. For all languages involved in the task, this combination worked very well when all the fields of the query were used (title, description, and narrative); it worked well with title plus description, and not as well with title only.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Translation</head><p>For translating the topics into English we use several online MT tools. The idea behind using multiple translations is that they might provide more variety of words and phrases, therefore improving the retrieval performance. The seven online MT systems that we used for translating from Spanish, French, and German were:</p><p>1. http://www.google.com/language_tools?hl=en 2. http://www.babelfish.altavista.com 3. http://freetranslation.com 4. http://www.wordlingo.com/en/products_services/wordlingo_translator.html 5. http://www.systranet.com/systran/net 6. http://www.online-translator.com/srvurl.asp?lang=en 7. http://www.freetranslation.paralink.com For the Czech language topics we were able to find only one online MT system: http://intertran.tranexp.com/Translate/result.shtml We combined their outputs by simply concatenating all the translations. All seven translations of a title made the title of the translated query; the same was done for the description and narrative fields. An example of combined output, for the French example used above, is: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Retrieval</head><p>We used the SMART Information Retrieval (IR) system, originally developed at Cornell University in the 1960s. SMART is based on the vector space model of information retrieval <ref type="bibr" coords="3,352.87,388.68,56.06,9.02" target="#b4">(Salton, 1989)</ref>. It generates weighted term vectors for the document collection. SMART preprocesses the documents by tokenizing the text into words, removing common words that appear on its stop-list, and performing stemming on the remaining words to derive a set of terms. When the IR server executes a user query, the query terms are also converted into weighted term vectors. Vector inner-product similarity computation is then used to rank documents in decreasing order of their similarity to the user query.</p><p>The newest version of SMART (version 11) offers many state-of-the-art options for weighting the terms in the vectors. Each term-weighting scheme is described as a combination of term frequency, collection frequency, and length normalization components <ref type="bibr" coords="3,288.56,480.66,119.67,9.02" target="#b3">(Salton and Buckley, 1988)</ref>. The description of each component is:</p><p>• term frequency component Let tf denote the term frequency of a term t; then new_tf weights the terms according to the following schemes:</p><formula xml:id="formula_0" coords="3,70.92,549.27,268.30,81.23">none (n) : tf tf new = _ max-norm (m) : tf tf tf new max_ _ = augmented normalized (a): ) max_ ( * 5 . 0 5 . 0 _ tf tf tf new + =</formula><p>where max_ tf is the largest tf value in the vector. </p><formula xml:id="formula_1" coords="4,117.72,312.10,135.64,34.70">∑ = m wt new tf wt norm 2 _ _</formula><p>In this paper we employ the notation used in SMART to describe the combined schemes: xxx / xxx. The first three characters refer to the weighting scheme used to index the document collection and the last three characters refer to the weighting scheme used to index the query fields. For example, lpc/atc means that lpc was used for documents and atc for queries. lpc would apply log term frequency weighting (l) and probabilistic collection frequency weighting (p) with cosine normalization to the document collection (n). atc would apply augmented normalized term frequency (a) , inverse document frequency weight (t) with cosine normalization (c).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>Table <ref type="table" coords="4,96.88,470.94,5.01,9.02" target="#tab_1">1</ref> shows the results of the submitted results on test data. The evaluation measures we report are standard measures computed with the trec_eval script: map (Mean Average Precision) and bpref (Binary Preference, top R judged nonrelevant). The information about what fields of the topics that were indexed in given in the column named Fields: T for title only, TD for title + description, TDN for title + description + narrative. For each run we include an additional description of the experimental settings. For all the required runs we used the indexing scheme mpc/ntn, since it performed best. This weighting scheme worked better when all fields of the topics are indexed. The results for TDN are better than for TD or T. Table <ref type="table" coords="4,336.56,539.94,5.01,9.02" target="#tab_1">1</ref> does not present baseline results, but we can say that our submitted results was substantially better than the ones submitted by the other six team that participated in the task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Comparisons of indexing schemes</head><p>Table <ref type="table" coords="4,96.87,718.20,5.01,9.02" target="#tab_2">2</ref> presents results for various weighting schemes document/topics. There are 3600 possible combinations of weighting schemes: 60 schemes (5 x 4 x 3) for documents and 60 for queries. We tried 240 combinations and we present in the table the results for 15 combinations (the ones, plus some other ones to show the diversity of the results). mpc/ntn is still the best, but there are a few other weighting schemes that achieve similar performance. Some of the weighting schemes perform best when indexing all the fields of the queries (TDN), some on TD, and some on title only (T). npn/ntn was best for TD and lsn/ntn and lsn/atn are best for T. In all the presented experiments we use stemming when indexing the collection and translated topics (except Section 5.3). Pseudo-relevance feedback was enables in the SMART system. We don't present the results here, but when we tried using an English lemmatizer (to produce base forms of inflected words) instead of a stemmer, the results were slightly worse for all settings; when using no-stemming during indexing the performance was much worse. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>TDN</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Comparison of various translations</head><p>Table <ref type="table" coords="5,96.80,460.14,5.01,9.02" target="#tab_3">3</ref> presents results for each translation produced by the seven online MT tools, from Spanish, French, and German into English. The last column is for the combination of all translations, as explained in Section 3. All the results in the table are for mpc/ntn, TDN (except for French where only TD was available).</p><p>The translations from German and the one from Czech had many words that were not translated, they were kept unchanged into the English output of the MT tools. These would explain the lower performance for German and Czech. The MT tool number 6 for German seems to obtain better results on the test data than the combination, but this was not the training data. In general, the combination of all translations performs better than the individual translations. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Measure</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Results on phonetic transcriptions</head><p>In Table <ref type="table" coords="6,107.71,128.76,5.01,9.02" target="#tab_4">4</ref> we present results for an experiment where the text of the collection and the queries were transcribed into phonetic form and split into n-grams (groups of n sounds, n = 4 in our case) that we used for indexing (without stemming). The phonetic n-grams were produced by University of Waterloo's group. See their CLEF 2005 paper for more details.</p><p>The phonetic form might help compensate for the speech recognition errors made when the collection was produced. When the fields TD were indexed, the results are interesting. The map scores are higher than the previous results on the text form of the documents and queries (up to 28% for the translations from French), while the bpref scores are lower. When combining phonetic and text forms (by simply indexing both phonetic ngrams and text), the result are only slightly improved. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language map bpref</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Manual summaries and keywords</head><p>Table <ref type="table" coords="6,96.71,563.34,5.01,9.02">5</ref> presents the results when all the fields of the document collection were used: the manual keywords and manual summaries in addition to the ASR transcripts and the automatic keywords.  <ref type="table" coords="6,93.71,669.99,3.69,8.10">5</ref>.Results of indexing all the fields of the collections: the manual keywords and summaries, in addition to the ASR transcripts. Again we report results of mpc/ntn scheme because they are the best.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Language map bpref</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion</head><p>We obtained the best retrieval results among the seven teams that participated in this track. We believe that the improved performance is due to the choice of the weighting scheme used for indexing the document and query terms. Table <ref type="table" coords="7,123.46,87.42,5.01,9.02" target="#tab_2">2</ref> shows that performance varies a lot with the weighting scheme; it can be much lower for the some of the classic indexing schemes. The idea of using multiple translations proves to be good. More variety in the translations would be beneficial. The online MT systems that we used are rule-based system. Adding translations by statistical MT tools might help, since they produce radically different translations.</p><p>On the manual data, the best map score we obtained is 46%, for English topics. On automatic data the best result is 21% map score. This difference shows that the poor quality of the ASR transcripts severely hurts the performance of IR systems on this collection. In future work we plan to investigate methods of removing or correcting some of the speech recognition errors in the ASR transcripts using the method of <ref type="bibr" coords="7,444.46,179.40,80.04,9.02;7,70.92,190.86,25.08,9.02" target="#b2">Inkpen and Désilets (2005)</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,70.92,717.54,24.10,9.02;2,70.92,729.06,51.56,9.02;2,70.92,740.52,146.88,9.02;3,73.44,87.42,117.41,9.02;3,73.44,98.88,135.04,9.02;3,73.44,110.40,117.41,9.02;3,73.44,121.86,117.41,9.02;3,73.44,133.38,135.64,9.02;3,73.44,144.90,117.41,9.02;3,70.92,156.36,322.60,9.02;3,70.92,167.88,416.11,9.02;3,70.92,179.40,444.45,9.02;3,70.92,190.86,262.79,9.02;3,70.92,202.38,443.36,9.02;3,70.92,213.90,251.09,9.02;3,70.92,225.36,444.45,9.02;3,70.92,236.88,262.79,9.02;3,70.92,248.40,444.45,9.02;3,70.92,259.86,262.79,9.02;3,70.92,271.38,451.35,9.02;3,70.92,282.90,274.82,9.02;3,70.92,294.36,444.45,9.02;3,70.92,305.88,262.79,9.02;3,70.92,317.40,27.42,9.02;3,70.92,328.86,26.88,9.02"><head></head><label></label><figDesc>&lt;top&gt; &lt;num&gt; 1159 &lt;title&gt; surviving children in Sweden surviving children in Sweden The children survivors in Sweden surviving children in Sweden surviving children in Sweden The surviving children in Sweden surviving children in Sweden &lt;desc&gt; Descriptions of the mechanisms of survival of the children born between 1930 and 1933 who passed the war in concentration camps or hidden and who currently live in Sweden. Descriptions of the mechanisms of survival of the children born between 1930 and 1933 who passed the war in concentration camps or hidden and who currently live in Sweden. Descriptions of the survival mechanisms of the born children between 1930 and 1933 that passed the war in co ncentration camps or hidden and that live currently in Sweden. Descriptions of the mechanisms of survival of the children born between 1930 and 1933 who passed the war in concentration camps or hidden and who currently live in Sweden. Descriptions of the mechanisms of survival of the children born between 1930 and 1933 who passed the war in concentration camps or hidden and who currently live in Sweden. Descriptions of the mechanisms of survival of the children been born between 1930 and 1933 which crossed war in concentration camps or hidden and that live in Sweden nowadays. Descriptions of the mechanisms of survival of the children born between 1930 and 1933 who passed the war in concentration camps or hidden and who currently live in Sweden. &lt;narr&gt; &lt;/top&gt;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,70.92,654.51,453.62,93.28"><head></head><label></label><figDesc>Let m denote the number of entries in the vector, then norm_wt is defined as follows:</figDesc><table coords="3,70.92,654.51,134.60,32.90"><row><cell cols="3">none (n):</cell><cell cols="4">new</cell><cell cols="8">wt _ =</cell><cell cols="3">new</cell><cell>_</cell><cell>tf</cell></row><row><cell cols="18">inverse document frequency weight (t):</cell><cell>new</cell><cell>_</cell><cell>wt</cell><cell>=</cell><cell>new</cell><cell>_</cell><cell>tf</cell><cell>*</cell><cell>log(</cell><cell>coll</cell><cell>_ docs _ _ of freq num _</cell><cell>term</cell><cell>)</cell></row><row><cell cols="9">probabilistic (p):</cell><cell></cell><cell cols="5">new</cell><cell cols="2">_</cell><cell>wt</cell><cell>=</cell><cell>new</cell><cell>_</cell><cell>tf</cell><cell>*</cell><cell>log(</cell><cell>num</cell><cell>_</cell><cell>_ _ docs coll</cell><cell>freq coll</cell><cell>_</cell><cell>freq</cell><cell>)</cell></row><row><cell cols="5">squared (s):</cell><cell cols="5">new</cell><cell cols="2">_</cell><cell cols="3">wt</cell><cell></cell><cell cols="2">=</cell><cell>new</cell><cell>_</cell><cell>tf</cell><cell>*</cell><cell>(log(</cell><cell>coll</cell><cell>_ docs _ _ of freq num _</cell><cell>term</cell><cell>))</cell><cell>2</cell></row><row><cell cols="18">• Merging of vector normalization</cell></row><row><cell cols="3">none (n):</cell><cell cols="5">norm</cell><cell cols="3">_</cell><cell cols="3">wt</cell><cell cols="3">=</cell><cell>new</cell><cell>_</cell><cell>wt</cell></row><row><cell cols="2">sum (s):</cell><cell cols="5">norm</cell><cell cols="2">_</cell><cell cols="4">wt</cell><cell cols="2">=</cell><cell></cell><cell cols="2">∑</cell><cell>m</cell><cell>new tf</cell><cell>_</cell><cell>wt</cell></row><row><cell cols="4">cosine (c):</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>log (l):</cell><cell cols="4">new</cell><cell>_</cell><cell cols="2">tf</cell><cell></cell><cell cols="8">ln( = tf</cell><cell>)</cell><cell>+</cell><cell>0 . 1</cell></row><row><cell cols="4">square (s):</cell><cell cols="4">new</cell><cell cols="3">_</cell><cell cols="2">tf</cell><cell></cell><cell cols="2">=</cell><cell cols="2">tf</cell><cell>2</cell></row></table><note coords="3,70.92,701.17,203.66,12.26;3,70.92,715.80,453.62,9.02;3,70.92,727.32,453.62,9.02;3,70.92,738.78,191.59,9.02"><p>• Merging of collection frequency component Let num_docs, coll_freq_of_term, and coll _freq denote the number of documents in the collection, the number of documents in which term t occurs, and the total number of occurrences of the term t in the collection, respectively; then new_wt is defined as follows:</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,70.92,586.50,439.77,90.04"><head>Table 1 .</head><label>1</label><figDesc>Results of the five submitted runs, for topics in English, Spanish, French, and German. The required run (English, title + description) is in bold.</figDesc><table coords="4,84.42,586.50,376.42,68.90"><row><cell></cell><cell>Run</cell><cell>map</cell><cell>bpref</cell><cell cols="2">Fields Description</cell></row><row><cell>English</cell><cell>uoEnTDN</cell><cell>0.2176</cell><cell>0.2005</cell><cell>TDN</cell><cell>Weighting scheme: mpc/ntn</cell></row><row><cell>Spanish</cell><cell>uoSpTDN</cell><cell>0.1863</cell><cell>0.1750</cell><cell>TDN</cell><cell>Weighting scheme: mpc/ntn</cell></row><row><cell>French</cell><cell>uoFrTD</cell><cell>0.1685</cell><cell>0.1599</cell><cell>TD</cell><cell>Weighting scheme: mpc/ntn</cell></row><row><cell>English</cell><cell>uoEnTD</cell><cell>0.1653</cell><cell>0.1705</cell><cell>TD</cell><cell>Weighting scheme: mpc/ntn</cell></row><row><cell>German</cell><cell>uoGrTDN</cell><cell>0.1281</cell><cell>0.1331</cell><cell>TDN</cell><cell>Weighting scheme: mpc/ntn</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,85.68,193.80,423.57,222.40"><head>Table 2 .</head><label>2</label><figDesc>Results of the various weighting schemes, for English topics. In bold are the best scores for TDN, TD, and T.</figDesc><table coords="5,85.68,193.80,410.10,211.64"><row><cell></cell><cell>Weighting</cell><cell></cell><cell></cell><cell>TD</cell><cell></cell><cell>T</cell><cell></cell></row><row><cell></cell><cell>scheme</cell><cell>map</cell><cell>bpref</cell><cell>map</cell><cell>bpref</cell><cell>map</cell><cell>bpref</cell></row><row><cell>1</cell><cell>mpc/mts</cell><cell>0.2175</cell><cell>0.2004</cell><cell>0.1651</cell><cell>0.1707</cell><cell>0.1175</cell><cell>0.1374</cell></row><row><cell>2</cell><cell>mpc/nts</cell><cell>0.2175</cell><cell>0.2004</cell><cell>0.1651</cell><cell>0.1707</cell><cell>0.1175</cell><cell>0.1374</cell></row><row><cell>3</cell><cell>mpc/ntn</cell><cell>0.2176</cell><cell>0.2005</cell><cell>0.1653</cell><cell>0.1705</cell><cell>0.1174</cell><cell>0.1371</cell></row><row><cell>4</cell><cell>npc/ntn</cell><cell>0.2176</cell><cell>0.2005</cell><cell>0.1653</cell><cell>0.1705</cell><cell>0.1174</cell><cell>0.1371</cell></row><row><cell>5</cell><cell>mpc/mtc</cell><cell>0.2176</cell><cell>0.2005</cell><cell>0.1653</cell><cell>0.1705</cell><cell>0.1174</cell><cell>0.1371</cell></row><row><cell>6</cell><cell>mpc/ntc</cell><cell>0.2176</cell><cell>0.2005</cell><cell>0.1653</cell><cell>0.1705</cell><cell>0.1174</cell><cell>0.1371</cell></row><row><cell>7</cell><cell>mpc/mtn</cell><cell>0.2176</cell><cell>0.2005</cell><cell>0.1653</cell><cell>0.1705</cell><cell>0.1174</cell><cell>0.1371</cell></row><row><cell>8</cell><cell>npn/ntn</cell><cell>0.2116</cell><cell>0.1916</cell><cell>0.1681</cell><cell>0.1693</cell><cell>0.1181</cell><cell>0.1350</cell></row><row><cell>9</cell><cell>lsn/ntn</cell><cell>0.1195</cell><cell>0.1487</cell><cell>0.1233</cell><cell>0.1433</cell><cell>0.1227</cell><cell>0.1395</cell></row><row><cell cols="2">10 lsn/atn</cell><cell>0.0919</cell><cell>0.1456</cell><cell>0.1115</cell><cell>0.1355</cell><cell>0.1227</cell><cell>0.1395</cell></row><row><cell cols="2">11 asn/ntn</cell><cell>0.0912</cell><cell>0.1295</cell><cell>0.0923</cell><cell>0.1208</cell><cell>0.1062</cell><cell>0.1290</cell></row><row><cell cols="2">12 snn/ntn</cell><cell>0.0693</cell><cell>0.1327</cell><cell>0.0592</cell><cell>0.1305</cell><cell>0.0729</cell><cell>0.1113</cell></row><row><cell cols="2">13 sps/ntn</cell><cell>0.0349</cell><cell>0.0979</cell><cell>0.0377</cell><cell>0.1036</cell><cell>0.0383</cell><cell>0.0783</cell></row><row><cell cols="2">14 nps/ntn</cell><cell>0.0517</cell><cell>0.0940</cell><cell>0.0416</cell><cell>0.0791</cell><cell>0.0474</cell><cell>0.0761</cell></row><row><cell cols="2">15 mtc/atc</cell><cell>0.1138</cell><cell>0.1514</cell><cell>0.1151</cell><cell>0.1449</cell><cell>0.1108</cell><cell>0.1345</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,75.42,564.24,440.22,166.96"><head>Table 3 .</head><label>3</label><figDesc>Results on the output of each Machine Translation system. Spanish, French, and German. Czech.</figDesc><table coords="5,296.68,564.24,50.08,9.02"><row><cell>Translation</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="6,70.92,244.38,453.01,275.02"><head>Table 4 .</head><label>4</label><figDesc>Results on phonetic n-grams, and combination text plus phonetic transcripts for topics in English, and the translations from Spanish, French, German, and Czech. All the runs in this table use mpc/ntn.</figDesc><table coords="6,100.56,244.38,299.62,253.88"><row><cell></cell><cell></cell><cell></cell><cell cols="2">Fields Description</cell></row><row><cell>English</cell><cell>0.1276</cell><cell>0.1117</cell><cell>T</cell><cell>Phonetic, mpc/ntn</cell></row><row><cell>English</cell><cell>0.2550</cell><cell>0.1492</cell><cell>TD</cell><cell>Phonetic, mpc/ntn</cell></row><row><cell>English</cell><cell>0.1245</cell><cell>0.1198</cell><cell>T</cell><cell>Phonetic+Text, mpc/ntn</cell></row><row><cell>English</cell><cell>0.2590</cell><cell>0.1585</cell><cell>TD</cell><cell>Phonetic+Text, mpc/ntn</cell></row><row><cell>Spanish</cell><cell>0.1395</cell><cell>0.1050</cell><cell>T</cell><cell>Phonetic, mpc/ntn</cell></row><row><cell>Spanish</cell><cell>0.2653</cell><cell>0.1549</cell><cell>TD</cell><cell>Phonetic, mpc/ntn</cell></row><row><cell>Spanish</cell><cell>0.1443</cell><cell>0.1108</cell><cell>T</cell><cell>Phonetic+Text, mpc/ntn</cell></row><row><cell>Spanish</cell><cell>0.2669</cell><cell>0.1576</cell><cell>TD</cell><cell>Phonetic+Text, mpc/ntn</cell></row><row><cell>French</cell><cell>0.1251</cell><cell>0.1005</cell><cell>T</cell><cell>Phonetic, mpc/ntn</cell></row><row><cell>French</cell><cell>0.2726</cell><cell>0.1747</cell><cell>TD</cell><cell>Phonetic, mpc/ntn</cell></row><row><cell>French</cell><cell>0.1254</cell><cell>0.1023</cell><cell>T</cell><cell>Phonetic+Text, mpc/ntn</cell></row><row><cell>French</cell><cell>0.2833</cell><cell>0.1841</cell><cell>TD</cell><cell>Phonetic+Text, mpc/ntn</cell></row><row><cell>German</cell><cell>0.1163</cell><cell>0.1150</cell><cell>T</cell><cell>Phonetic, mpc/ntn</cell></row><row><cell>German</cell><cell>0.2356</cell><cell>0.1568</cell><cell>TD</cell><cell>Phonetic, mpc/ntn</cell></row><row><cell>German</cell><cell>0.1187</cell><cell>0.1159</cell><cell>T</cell><cell>Phonetic+Text, mpc/ntn</cell></row><row><cell>German</cell><cell>0.2324</cell><cell>0.1601</cell><cell>TD</cell><cell>Phonetic+Text, mpc/ntn</cell></row><row><cell>Czech</cell><cell>0.0776</cell><cell>0.0897</cell><cell>T</cell><cell>Phonetic, mpc/ntn</cell></row><row><cell>Czech</cell><cell>0.1647</cell><cell>0.1499</cell><cell>TD</cell><cell>Phonetic, mpc/ntn</cell></row><row><cell>Czech</cell><cell>0.0805</cell><cell>0.0951</cell><cell>T</cell><cell>Phonetic+Text, mpc/ntn</cell></row><row><cell>Czech</cell><cell>0.1695</cell><cell>0.1491</cell><cell>TD</cell><cell>Phonetic+Text, mpc/ntn</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,70.92,243.78,453.82,9.02;7,82.26,255.30,442.38,9.02;7,82.26,266.76,71.12,9.02" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,267.56,243.78,239.93,9.02">Automatic retrieval with locality information using SMART</title>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Buckley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gerard</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,82.26,255.30,251.72,9.02">Proceedings of the First Text REtrieval Conference (TREC-1)</title>
		<meeting>the First Text REtrieval Conference (TREC-1)</meeting>
		<imprint>
			<date type="published" when="1993-03">March 1993</date>
			<biblScope unit="page" from="500" to="207" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.92,284.28,453.70,9.02;7,82.26,295.80,442.44,9.02;7,82.26,307.26,334.37,9.02" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,357.02,295.80,167.69,9.02;7,82.26,307.26,201.94,9.02">Building an Information Retrieval Test Collection for Spontaneous Conversational Speech</title>
		<author>
			<persName coords=""><forename type="first">Douglas</forename><forename type="middle">W</forename><surname>Oard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dagobert</forename><surname>Soergel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Doermann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xiaoli</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">Craig</forename><surname>Murray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jianqiang</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bhuvana</forename><surname>Ramabhadran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Franz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Samuel</forename><surname>Gustman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,303.90,307.26,108.22,9.02">Proceedings of SIGIR 2004</title>
		<meeting>SIGIR 2004</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.92,324.78,453.62,9.02;7,82.26,336.24,355.82,9.02" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,242.56,324.78,281.98,9.02;7,82.26,336.24,74.97,9.02">Semantic Similarity for Detecting Recognition Errors in Automatic Speech Transcripts</title>
		<author>
			<persName coords=""><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alain</forename><surname>Désilets</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,173.94,336.24,116.02,9.02">Proceedings of EMNLP 2005</title>
		<meeting>EMNLP 2005<address><addrLine>Vancouver, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-10">2005. October 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.92,353.76,453.63,9.02;7,82.26,365.28,182.01,9.02" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,254.26,353.76,212.99,9.02">Term-weighting approaches in automatic retrieval</title>
		<author>
			<persName coords=""><forename type="first">Gerard</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chris</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,476.82,353.76,47.73,9.02;7,82.26,365.28,114.18,9.02">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="513" to="523" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,70.92,382.74,453.64,9.02;7,82.26,394.26,201.37,9.02" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="7,157.56,382.74,367.00,9.02;7,82.26,394.26,37.80,9.02">Automatic Text Processing: The Transformation, Analysis, and Retrieval of Information by Computer</title>
		<author>
			<persName coords=""><forename type="first">Gerard</forename><surname>Salton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Addison-Wesley Publishing Company</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
