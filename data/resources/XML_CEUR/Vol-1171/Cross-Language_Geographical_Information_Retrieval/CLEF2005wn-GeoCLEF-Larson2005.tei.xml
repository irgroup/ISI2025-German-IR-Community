<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,115.32,98.73,372.11,15.51;1,221.16,120.69,160.45,15.51">Cheshire II at GeoCLEF: Fusion and Query Expansion for GIR</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,269.76,154.07,63.65,9.96"><forename type="first">Ray</forename><forename type="middle">R</forename><surname>Larson</surname></persName>
							<email>ray@sims.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Management and Systems</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,115.32,98.73,372.11,15.51;1,221.16,120.69,160.45,15.51">Cheshire II at GeoCLEF: Fusion and Query Expansion for GIR</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7948703B8D737173C3436793242C09D2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.7 Digital Libraries Algorithms, Performance, Measurement Cheshire II, Logistic Regression, Data Fusion</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper I will describe the Berkeley (group 1) approach to the GeoCLEF task for CLEF 2005. The main technique we are testing is the fusion of multiple probabilistic searches against different XML components using both Logistic Regression (LR) algorithms and a version of the Okapi BM-25 algorithm. We also combine multiple translations of queries in cross-language searching. Since this is the first time that the Cheshire system has been used for CLEF this approach can, at best, be considered a very preliminary base testing of some retrieval algorithms and approaches. The primary geographically based approaches taken for GeoCLEF were to georeference proper nouns in the text using a gazetteer derived from the World Gazetteer with both English and German names for each place, and to expand place names for regions or countries in the queries by the names of the countries or cities in those regions or countries.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>For GeoCLEF 2005 the Berkeley IR research group split into two groups (Berkeley 1 and Berkeley 2). Berkeley 2 used the same technques as used in previous CLEF evaluations, while Berkeley 1 tried some alternative algorithms and fusion methods for both the GeoCLEF and Domain Specific task. This paper will focus on the techniques used by the Berkeley 1 group for GeoCLEF and the results of our official submissions, as well as some additional tests using versions of the algorithms employed by the Berkeley 2 group. The main technique being tested is the fusion of multiple probabilistic searches against different XML components using both Logistic Regression (LR) algorithms and a version of the Okapi BM-25 algorithm. We also combine multiple translations of queries in cross-language searching. Since this is the first time that the Cheshire II system has been used for CLEF, this approach can at best be considered a very preliminary base testing of some retrieval algorithms and approaches. This paper is organized as follows: In the next section we discuss the retrieval algorithms and fusion methods used for the submitted runs. We then discuss the specific approaches taken for indexing and retrieval in GeoCLEF and the results of the submitted runs. Then we compare our submitted results to some additional runs with alternate approaches conducted later. Finally we present conclusions and some discussion of the GeoCLEF task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Retrieval Algorithms and Fusion Operators</head><p>In <ref type="bibr" coords="2,102.96,164.03,10.55,9.96" target="#b7">[8]</ref> we conducted an analysis of the overlap between the result lists retrieved by our Logistic Regression algorithm and the Okapi BM-25 algorithm for the INEX XML Retrieval test collection. We found that, on average, over half of the result lists retrieved by each algorithm in these overlap tests were both non-relevant and unique to that algorithm, fulfilling the main criteria for effective algorithm combination suggested by Lee <ref type="bibr" coords="2,269.15,211.91,12.13,9.96" target="#b8">[9]</ref>: that the algorithms have similar sets of relevant documents and different sets of non-relevant. This section is largely a repetition of the material presented in <ref type="bibr" coords="2,147.56,235.79,9.98,9.96" target="#b7">[8]</ref>, with additional discussion of how these algorithms were applied for the CLEF GeoCLEF task.</p><p>In the remainder of this section we describe the Logistic Regression and Okapi BM-25 algorithms that were used for GeoCLEF and we also discuss the methods used to combine the results of the different algorithms. The algorithms and combination methods are implemented as part of the Cheshire II XML/SGML search engine <ref type="bibr" coords="2,299.00,295.55,10.43,9.96" target="#b5">[6,</ref><ref type="bibr" coords="2,313.87,295.55,7.79,9.96" target="#b6">7,</ref><ref type="bibr" coords="2,326.11,295.55,7.67,9.96" target="#b4">5]</ref> which also supports a number of other algorithms for distributed search and operators for merging result lists from ranked or Boolean sub-queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Logistic Regression Algorithm</head><p>The basic form and variables of the Logistic Regression (LR) algorithm used was originally developed by Cooper, et al. <ref type="bibr" coords="2,191.56,377.75,9.89,9.96" target="#b2">[3]</ref>. It provided good full-text retrieval performance in the TREC3 ad hoc task and in TREC interactive tasks <ref type="bibr" coords="2,250.89,389.63,10.55,9.96" target="#b3">[4]</ref> and for distributed IR <ref type="bibr" coords="2,366.62,389.63,9.98,9.96" target="#b4">[5]</ref>. As originally formulated, the LR model of probabilistic IR attempts to estimate the probability of relevance for each document based on a set of statistics about a document collection and a set of queries in combination with a set of weighting coefficients for those statistics. The statistics to be used and the values of the coefficients are obtained from regression analysis of a sample of a collection (or similar test collection) for some set of queries where relevance and non-relevance has been determined. More formally, given a particular query and a particular document in a collection P (R | Q, D) is calculated and the documents or components are presented to the user ranked in order of decreasing values of that probability. To avoid invalid probability values, the usual calculation of P (R | Q, D) uses the "log odds" of relevance given a set of S statistics, s i , derived from the query and database, such that:</p><formula xml:id="formula_0" coords="2,235.08,518.56,277.90,30.45">log O(R | Q, D) = b 0 + S i=1 b i s i (1)</formula><p>where b 0 is the intercept term and the b i are the coefficients obtained from the regression analysis of the sample collection and relevance judgements. The final ranking is determined by the conversion of the log odds form to probabilities:</p><formula xml:id="formula_1" coords="2,232.44,599.35,280.54,25.12">P (R | Q, D) = e log O(R|Q,D) 1 + e log O(R|Q,D)<label>(2)</label></formula><p>Based on the structure of XML documents as a tree of XML elements, we define a "document component" as an XML subtree that may include zero or more subordinate XML elements or subtrees with text as the leaf nodes of the tree. Thus, a component might be defined using any of the tagged elements in a document. However, not all possible components are likely to be useful in content-oriented retrieval (e.g., tags indicating that a word in the title should be in italic type, or the page number range) therefore we defined the retrievable components selectively, including the titles, dates, and document ids. Naturally, a full XML document may also be considered a "document component". As discussed below, the indexing and retrieval methods used in this research take into account a selected set of document components for generating the statistics used in the search process and for extraction of the parts of a document to be returned in response to a query. Because we are dealing with not only full documents, but also document components (which for some collections include elements such as sections and paragraphs or similar structures) derived from the documents, we will use C to represent document components in place of D. Therefore, the full equation describing the LR algorithm used in these experiments is:</p><formula xml:id="formula_2" coords="3,182.88,190.91,330.10,194.40">log O(R | Q, C) = b 0 +   b 1 •   1 |Q c | |Qc| j=1 log qtf j     + b 2 • |Q| +   b 3 •   1 |Q c | |Qc| j=1 log tf j     (3) + b 4 • √ cl +   b 5 •   1 |Q c | |Qc| j=1 log N -n tj n tj     + (b 6 • log |Q d |)</formula><p>Where:</p><p>Q is a query containing terms T , |Q| is the total number of terms in Q, |Q c | is the number of terms in Q that also occur in the document component, tf j is the frequency of the jth term in a specific document component, qtf j is the frequency of the jth term in Q, n tj is the number of components (of a given type) containing the jth term, cl is the document component length measured in bytes.</p><p>N is the number of components of a given type in the collection.</p><p>b i are the coefficients obtained though the regression analysis.</p><p>This equation, used in estimating the probability of relevance in this research, is essentially the same as that used in <ref type="bibr" coords="3,179.09,601.43,10.43,9.96" target="#b1">[2]</ref> for TREC3. The b i coefficients in the "Base" version of this algorithm were estimated using relevance judgements and statistics from the TREC/TIPSTER test collection. For GeoCLEF we used this Base version for our retrieval of all components with the addition of the component fusion methods described later. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Okapi BM-25 Algorithm</head><p>The version of the Okapi BM-25 algorithm used in these experiments is based on the description of the algorithm in Robertson <ref type="bibr" coords="4,228.37,91.79,14.58,9.96" target="#b10">[11]</ref>, and in TREC notebook proceedings <ref type="bibr" coords="4,416.14,91.79,14.58,9.96" target="#b9">[10]</ref>. As with the LR algorithm, we have adapted the Okapi BM-25 algorithm to deal with document components :</p><formula xml:id="formula_3" coords="4,232.20,125.11,280.78,31.73">|Qc| j=1 w (1) (k 1 + 1)tf j K + tf j (k 3 + 1)qtf j k 3 + qtf j<label>(4)</label></formula><p>Where (in addition to the variables already defined):</p><formula xml:id="formula_4" coords="4,90.00,188.63,125.66,30.57">K is k 1 ((1 -b) + b • dl/avcl) k 1 ,</formula><p>b and k 3 are parameters (1.5, 0.45 and 500, respectively, were used), avcl is the average component length measured in bytes w (1) is the Robertson-Sparck Jones weight:</p><formula xml:id="formula_5" coords="4,252.72,272.32,121.19,34.00">w (1) = log ( r+0.5 R-r+0.5 ) ( nt j -r+0.5 N -nt j -R-r+0.5 )</formula><p>r is the number of relevant components of a given type that contain a given term, R is the total number of relevant components of a given type for the query.</p><p>Our current implementation uses only the a priori version (i.e., without relevance information) of the Robertson-Sparck Jones weights, and therefore the w (1) value is effectively just an IDF weighting. The results of searches using our implementation of Okapi BM-25 and the LR algorithm seemed sufficiently different to offer the kind of conditions where data fusion has been shown to be be most effective <ref type="bibr" coords="4,181.84,408.47,9.89,9.96" target="#b8">[9]</ref>, and our overlap analysis of results for each algorithm (described in the evaluation and discussion section) has confirmed this difference and the fit to the conditions for effective fusion of results.</p><p>The system used supports searches combining probabilistic and (strict) Boolean elements, as well as operators to support various merging operations for both types of intermediate result sets. However, in GeoCLEF we did not use this capability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Result Combination Operators</head><p>The Cheshire II system used in this evaluation provides a number of operators to combine the intermediate results of a search from different components or indexes. With these operators we have available an entire spectrum of combination methods ranging from strict Boolean operations to fuzzy Boolean and normalized score combinations for probabilistic and Boolean results. These operators are the means available for performing fusion operations between the results for different retrieval algorithms and the search results from different different components of a document. We will only describe two of these operators here, because they were the only type used in the GEOCLEF runs reported in this paper.</p><p>The MERGE CMBZ operator is based on the "CombMNZ" fusion algorithm developed by Shaw and Fox <ref type="bibr" coords="4,156.07,622.07,15.46,9.96" target="#b11">[12]</ref> and used by Lee <ref type="bibr" coords="4,251.52,622.07,9.98,9.96" target="#b8">[9]</ref>. In our version we take the normalized scores, but then further enhance scores for components appearing in both lists (doubling them) and penalize normalized scores appearing low in a single result list, while using the unmodified normalized score for higher ranking items in a single list.</p><p>The MERGE PIVOT operator is used primarily to adjust the probability of relevance for one search result based on matching elements in another search result. It was developed primarily to adjust the probabilities of a search result consisting of sub-elements of a document (such as titles or paragraphs) based on the probability obtained for the same search over the entire document. It is basically a weighted combination of the probabilities based on a "DocPivot" fraction, such that:</p><formula xml:id="formula_6" coords="5,207.60,109.31,305.38,17.04">P n = DocP ivot * P d + (1 -DocP ivot) * P s<label>(5)</label></formula><p>where P d represents the document-level probability of relevance, P s represents the subelement probability, and P n representing the resulting new probability. The "DocP ivot" value used for all of the runs submitted was 0.64. Since this was the first year for GeoCLEF, this value was derived from experiments on 2004 data for other CLEF collections (which may have been inappropriate for the GeoCLEF data, which further testing will reveal). The basic operator can be applied to either probabilistic results, or non-probabilistic results or both (in the latter case the scores are normalized using MINMAX normalization to range between 0 and 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approaches for GeoCLEF</head><p>In this section we describe the specific approaches taken for our submitted runs for the GeoCLEF task. First we describe the indexing and term extraction methods used, and then the search features we used for the submitted runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Indexing and Term Extraction</head><p>For both the monolingual and bilingual tasks we indexed the documents using the Cheshire II system. The document index entries and queries were stemmed using the Snowball stemmer, and a new georeferencing indexing subsystem was used. This subsystem extracts proper nouns from the text being indexed and attempts to match them in a digital gazetteer. For GeoCLEF we used a gazetteer derived from the World Gazetteer (http://www.world-gazetteer.com) with 224698 entries in both English and German. The indexing subsystem provides three different index types: verified place names (an index of names which matched the gazetteer), point coordinates (latitude and longitude coordinates of the verified place name) and bounding box coordinates (bounding boxes for the matched places from the gazetteer). All three types were created, but due to time constraints we only used the verified place names in our tests. Text indexes were also created for separate XML elements (such as document titles or dates) as well as for the entire document. It is worth noting that, although the names are compared against the gazetteer, it is quite common for proper name of persons and places to be the same and this leads to potential false associations between articles mentioning persons with such name and particular places.  <ref type="table" coords="6,132.34,61.43,5.03,9.96" target="#tab_0">1</ref> lists the indexes created for the GeoCLEF database and the document elements from which the contents of those indexes were extracted. The "Used" column in Table <ref type="table" coords="6,464.94,73.43,5.03,9.96" target="#tab_0">1</ref> indicates whether or not a particular index was used in the submitted GeoCLEF runs.</p><p>Because there was no explicit tagging of location-related terms in the collections used for GeoCLEF, we applied the above approach to the "TEXT", "LD", and "TX" elements of the records of the various collections. The part of news articles normally called the "dateline" indicating the location of the news story was not separately tagged in any of the GeoCLEF collection, but often appeared as the first part of the text for the story. (In addition, we discovered when writing these notes that the "TX" and "LD" were not included in the indexing for some collections and elements, meaning that the SDA collection was not included in the German indexing for these types).</p><p>For all indexing we used English and German stoplists to exclude function words and very common words from the indexing and searching. For the runs reported here we also did not use any decompounding of German terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Search Processing</head><p>Searching the GeoCLEF collection used Cheshire II scripts to parse the topics and submit the title and description from the topics to one or more indexes. For monolingual search tasks we used the topics in the appropriate language (English or German), for bilingual tasks the topics were translated from the source language to the target language using three different machine translation (MT) systems, the L&amp;H PC-based system, SYSTRAN (via Babelfish at Altavista), and PROMT (also via their web interface). Each of these translations were combined into a single probabilistic query. The hope was to overcome the translation errors of a single system by including alternatives.</p><p>We tried two main approaches for searching, the first used only the topic text from the title and desc elements, the second included the spatialrelation and location elements as well. In all cases the different indexes mentioned above were used, and probabilistic searches were carried out on each index, and the results combined using the CombMNZ algorithm, and by a weighted combination of partial element and full document scores. For bilingual searching we used both the Berkeley TREC3 and the Okapi BM-25 algorithm, for monolingual we used only TREC3. For one submitted run in each task we did no query expansion and did not use the location elements in the topics. For the other runs each of the place names identified in the queries were expanded when that place was the name of a region or country. For example when running search against the English databases the name "Europe" was expanded to "Albania Andorra Austria Belarus Belgium Bosnia and Herzegovina Bulgaria Croatia Cyprus Czech Republic Denmark Estonia Faroe Islands Finland France Georgia Germany Gibraltar Greece Guernsey and Alderney Hungary Iceland Ireland Isle of Man Italy Jersey Latvia Liechtenstein Lithuania Luxembourg Macedonia Malta Moldova Monaco Netherlands Norway Poland Portugal Romania Russia San Marino Serbia and Montenegro Slovakia Slovenia Spain Svalbard and Jan Mayen Sweden Switzerland Turkey Ukraine United Kingdom Vatican City", while for searches against the German databases "Europa" was expanded to "Albanien Andorra sterreich Weirussland Belgien Bosnien und Herzegowina Bulgarien Kroatien Zypern Tschechische Republik Dnemark Estland Frer-Inseln Finnland Frankreich Georgien Deutschland Gibraltar Griechenland Guernsey und Alderney Ungarn Island Irland Man Italien Jersey Lettland Liechtenstein Litauen Luxemburg Mazedonien Malta Moldawien Monaco Niederlande Norwegen Polen Portugal Rumnien Russland San Marino Serbien und Montenegro Slowakei Slowenien Spanien Svalbard und Jan Mayen Schweden Schweiz Trkei Ukraine Grobritannien Vatikan". Example queries for monolingual searches are shown in Figure <ref type="figure" coords="6,446.46,621.83,5.03,9.96" target="#fig_2">3</ref> The indexes combined in searching included the headline, topic, and geotext indexes (as described in Table <ref type="table" coords="6,163.27,645.71,4.43,9.96" target="#tab_0">1</ref>) for searches that include the location element, and the headline and topic for the searches without the locations element. For the bilingual tasks, three sub-queries, one for each query translation were run and then the results were merged using the CombMNZ algorithm. For Monolingual tasks the title and topic results were combined with each other using CombMNZ and the final score combined with an expanded search for place names in the topic and geotext indexes. Examples of the queries used are shown in Figures <ref type="figure" coords="7,317.46,469.91,5.03,9.96" target="#fig_2">3</ref> and<ref type="figure" coords="7,346.00,469.91,5.03,9.96" target="#fig_3">4</ref> in Appendix A, as you may observe by close inspection there were some bugs in the scripts used to generate these queries some of which have been removed for this paper. These included things such as including "Kenya" in the expansion for Europe, and including two copies of all expansion names, when a single copy should have been used. We intend (time permitting) to rerun a number of the queries to see if, and how, these errors affected the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results for Submitted Runs</head><p>The summary results (as Mean Average Precision) for the submitted bilingual and monolingual runs for both English and German are shown in Table <ref type="table" coords="7,324.67,596.39,3.90,9.96" target="#tab_1">2</ref>, the Recall-Precision curves for these runs are also shown in Figures <ref type="figure" coords="7,204.14,608.39,79.89,9.96">1 (for monolingual</ref>) and 2 (for bilingual). In Figures <ref type="figure" coords="7,436.05,608.39,5.03,9.96">1</ref> and<ref type="figure" coords="7,463.87,608.39,5.03,9.96">2</ref> the name are abbrevated to the final letters and numbers of the full name in Table <ref type="table" coords="7,413.28,620.39,3.90,9.96" target="#tab_1">2</ref>, and those beginning with "POST" are unofficial runs described in the next section.</p><p>Table <ref type="table" coords="7,131.73,644.27,5.03,9.96" target="#tab_1">2</ref> indicates some rather curious results that warrant further investigation as to the cause. Notice that the result for all of the English monolingual runs exceed the rsults for bilingual German to English runs -this is typical for cross-langauge retrieval. However, in the case of German this expected pattern is reversed, and the German monolingual runs perform worse than either of the bilingual English to German runs. We haven't yet determined exactly why this might be the case, but there are number possible reasons (e.g., since a combination of Okapi and Logistic Regression searches are used for the bilingual task this may be an indication that Okapi is more effective for German). Also, in the monolingual runs, both English and German, use of the location tag and expansion of the query (runs numbered LOC02 and LOC03 respectively) did better than no use of the location tag or expansion. For the bilingual runs the results are mixed, with German to English runs showing an improvement with location use and expansion (LOC01) and English to German showing the opposite.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Additional Runs</head><p>After the official submission we used the same version of the Logistic Regression algorithm as the Berkeley2 group (the "TREC2" algorithm), which incorporates blind feedback (which is lacking in the LR algorithm described above). The parameters used for blind feedback were 13 documents and the top-ranked 16 terms from those documents added to the original query. We used essentially an identical algorithm to that defined by Cooper, Gey and Chen in <ref type="bibr" coords="8,399.26,423.83,9.98,9.96" target="#b0">[1]</ref>. The results from the bilingual and monolingual runs for both English and German are shown in Table <ref type="table" coords="8,453.36,435.71,3.90,9.96" target="#tab_2">3</ref>, the Recall-Precision curves for these runs are also shown in Figures 1 (for monolingual) and 2 (for bilingual).</p><p>In Figures <ref type="figure" coords="8,136.52,459.71,5.03,9.96">1</ref> and<ref type="figure" coords="8,162.91,459.71,5.03,9.96">2</ref> the names abbrevated to the final letters of the full name in  As can be seen by comparing Table <ref type="table" coords="8,273.59,675.23,5.03,9.96" target="#tab_2">3</ref> with Table <ref type="table" coords="8,336.42,675.23,3.90,9.96" target="#tab_1">2</ref>, all of the comparable runs for show improvement in results with the TREC2 algorithm with blind feedback. We have compared notes with the Berkeley2 group and with minor differences to be expected given the different indexing methods, stoplists, etc. used, these results are comparable to theirs.</p><p>The queries submitted in these unofficial runs were much simpler than those used in the official runs. For monolingual retrieval only the "topic" index was used and the geotext index was not used at all, for the bilingual runs the same pattern of using multiple query translations and combining the results was used as in our official runs. This may actually be detrimental to the performance, since the expanded queries perform worse than the unexpanded queries -the opposite behaviour observed in the official runs.</p><p>In the monolingual runs there appears to be similar behavior, The best using the topic titles and description along with the location tag provided the best results, but expanding the locations as in the official runs (the English ML run ending in EXP) performed considerably worse than the the unexpanded runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>Analysis of these results is still ongoing. There are a number of, as yet, unexplained behaviors in some of our results. We plan to continue working on the use of fusion, and hope to discover effective ways to combine highly effective algorithms, such as the TREC2 algorith, as well as work on adding the same blind feedback capability to the TREC3 Logistic Regression algorithm.</p><p>One obvious conclusion that can be drawn is that basic TREC2 is a highly effective algorithm for the GeoCLEF tasks, and the fusion approaches tried in these tests are most definitely NOT very effective (in sprite of their relatively good effectiveness in other retrieval tasks such as INEX).</p><p>Another conclusion is that, in some cases, query expansion of region names to a list of names of particular countries in that region is modestly effective (although we haven't yet been able to test for statistical significance). In other cases, however it can be quite detrimental. However we still need to determine if the problems with the expansion were due the nature of the expansion itself, or errors in how it was done.  PART QUERY1: search (topic @+ { shark attacks against australia and california the documents reports over attacks of sharks on people.}) !MERGE_CMBZ (topic @ { shark attacks against australia and california the documents reports over attacks of sharks on people.}) RESULTSETID SET1 PART QUERY2: search (topic @+ { shark fish attacks before australia and california the documents report?r attacks of shark fish on humans.}) !MERGE_CMBZ (topic @ { shark fish attacks before australia and california the documents report?r attacks of shark fish on humans.}) RESULTSETID SET2 PART QUERY3: search (topic @+ { shark fish attacks before australia and california the documents report about attacks about shark fishing on person.}) !MERGE_CMBZ (topic @ { shark fish attacks before australia and california the documents report about attacks about shark fishing on person.}) RESULTSETID SET3 FINAL QUERY: search SET1: !MERGE_CMBZ SET2: !MERGE_CMBZ SET3: RESULTSETID SET4 PART QUERY1: search (topic @+ { shark attacks against australia and california the documents reports over attacks of sharks on people. shark attacks australia : california}) !MERGE_CMBZ (topic @ { shark attacks against australia and california the documents reports over attacks of sharks on people. shark attacks australia : california}) !MERGE_CMBZ (topic @ { australien californien australien californien }) RESULTSETID SET1 PART QUERY2: search (topic @+ { shark fish attacks before australia and california the documents report?r attacks of shark fish on humans. shark fish attacks australia : california}) !MERGE_CMBZ (topic @ { shark fish attacks before australia and california the documents report?r attacks of shark fish on humans. shark fish attacks australia : california}) !MERGE_CMBZ (topic @ {australien californien australien californien}) RESULTSETID SET2 PART QUERY3: search (topic @+ {shark fish attacks before australia and california the documents report about attacks about shark fishing on person. shark fish attacks australia : california}) !MERGE_CMBZ (topic @ { shark fish attacks before australia and california the documents report about attacks about shark fishing on person. shark fish attacks australia : california}) !MERGE_CMBZ (topic @ {australien californien australien californien}) RESULTSETID SET3 FINAL QUERY: search SET1: !MERGE_CMBZ SET2: !MERGE_CMBZ SET3: RESULTSETID SET4 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Example</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,323.24,637.31,189.54,9.96;3,90.00,649.31,19.31,10.65;3,112.07,649.31,28.40,17.04;3,142.15,649.31,68.20,10.65;3,213.11,649.31,33.43,17.04;3,248.22,649.31,68.21,10.65;3,319.19,649.31,33.43,17.04;3,354.30,649.31,109.70,10.65"><head></head><label></label><figDesc>The coefficients for the Base version were b 0 = -3.70, b 1 = 1.269, b 2 = -0.310, b 3 = 0.679, b 4 = -0.021, b 5 = 0.223 and b 6 = 4.01.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,137.76,237.35,327.21,9.96"><head>Figure 1 :Figure 2 :</head><label>12</label><figDesc>Figure 1: Berkeley1 Monolingual Runs -English (left) and German (right)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="10,105.00,620.03,392.66,9.96"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Example Berkeley1 Monolingual Queries with, and without geographic elements</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="11,90.00,631.79,422.87,9.96;11,90.00,643.79,37.41,9.96"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Example Berkeley1 Bilingual (German to English) Queries with, and without geographic elements</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,129.60,503.00,343.70,167.43"><head>Table 1 :</head><label>1</label><figDesc>Cheshire II Indexes for GeoCLEF 2005</figDesc><table coords="5,129.60,503.00,343.70,144.95"><row><cell>Name</cell><cell>Description</cell><cell>Content Tags</cell><cell>Used</cell></row><row><cell>docno</cell><cell>Document ID</cell><cell>DOCNO</cell><cell>no</cell></row><row><cell>pauthor</cell><cell>Author Names</cell><cell>BYLINE, AU</cell><cell>no</cell></row><row><cell cols="2">headline Article Title</cell><cell>HEADLINE, TITLE, LEAD, LD, TI</cell><cell>yes</cell></row><row><cell>topic</cell><cell>Content Words</cell><cell>HEADLINE, TITLE, TI, LEAD</cell><cell>yes</cell></row><row><cell></cell><cell></cell><cell>BYLINE, TEXT, LD, TX</cell><cell>yes</cell></row><row><cell>date</cell><cell>Date of Publication</cell><cell>DATE, WEEK</cell><cell>yes</cell></row><row><cell>geotext</cell><cell>Validated place names</cell><cell>TEXT, LD, TX</cell><cell>yes</cell></row><row><cell cols="2">geopoint Validated coordinates</cell><cell>TEXT, LD, TX</cell><cell>no</cell></row><row><cell></cell><cell>for place names</cell><cell></cell><cell></cell></row><row><cell>geobox</cell><cell cols="2">Validated bounding boxes TEXT, LD, TX</cell><cell>no</cell></row><row><cell></cell><cell>for place names</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,148.20,61.28,306.17,158.31"><head>Table 2 :</head><label>2</label><figDesc>Submitted GeoCLEF Runs</figDesc><table coords="8,148.20,61.28,306.17,135.83"><row><cell>Run Name</cell><cell>Description</cell><cell>Location</cell><cell>MAP</cell></row><row><cell cols="3">BERK1BLDEENLOC01 Bilingual German⇒English yes</cell><cell>0.2753</cell></row><row><cell cols="3">BERK1BLDEENNOL01 Bilingual German⇒English no</cell><cell>0.2668</cell></row><row><cell cols="3">BERK1BLENDELOC01 Bilingual English⇒German yes</cell><cell>0.0725</cell></row><row><cell cols="3">BERK1BLENDENOL01 Bilingual English⇒German no</cell><cell>0.0777</cell></row><row><cell>BERK1MLDELOC02</cell><cell>Monolingual German</cell><cell>yes</cell><cell>0.0535</cell></row><row><cell>BERK1MLDELOC03</cell><cell>Monolingual German</cell><cell>yes</cell><cell>0.0533</cell></row><row><cell>BERK1MLDENOL01</cell><cell>Monolingual German</cell><cell>no</cell><cell>0.0504</cell></row><row><cell>BERK1MLENLOC02</cell><cell>Monolingual English</cell><cell>yes</cell><cell>0.2910</cell></row><row><cell>BERK1MLENLOC03</cell><cell>Monolingual English</cell><cell>yes</cell><cell>0.2924</cell></row><row><cell>BERK1MLENNOL01</cell><cell>Monolingual English</cell><cell>no</cell><cell>0.2794</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,90.00,459.71,422.68,169.04"><head>Table 3 ,</head><label>3</label><figDesc>prefixed by "POST". These are unofficial runs to test the difference in the algorithms in an identical runtime environment.</figDesc><table coords="8,155.88,505.40,290.84,123.35"><row><cell>Run Name</cell><cell>Description</cell><cell>Location</cell><cell>MAP</cell></row><row><cell cols="3">POSTBLDEENEXP Bilingual German⇒English yes</cell><cell>0.2636</cell></row><row><cell cols="3">POSTBLDEENNOL Bilingual German⇒English no</cell><cell>0.3205</cell></row><row><cell cols="3">POSTBLENDEEXP Bilingual English⇒German yes</cell><cell>0.0626</cell></row><row><cell cols="3">POSTBLENDENOL Bilingual English⇒German no</cell><cell>0.0913</cell></row><row><cell>POSTMLDELOC</cell><cell>Monolingual German</cell><cell>yes</cell><cell>0.0929</cell></row><row><cell>POSTMLDENOL</cell><cell>Monolingual German</cell><cell>no</cell><cell>0.0861</cell></row><row><cell>POSTMLENEXP</cell><cell>Monolingual English</cell><cell>yes</cell><cell>0.2892</cell></row><row><cell>POSTMLENLOC</cell><cell>Monolingual English</cell><cell>yes</cell><cell>0.3879</cell></row><row><cell>POSTMLENNOL</cell><cell>Monolingual English</cell><cell>no</cell><cell>0.3615</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,184.80,641.39,233.23,9.96"><head>Table 3 :</head><label>3</label><figDesc>Additional Post-Submission GeoCLEF Runs</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="10,90.00,279.18,417.91,318.80"><head></head><label></label><figDesc>Queries submitted</figDesc><table coords="10,90.00,313.75,417.91,284.24"><row><cell>search ((headline @ {vegetable exporters of europe what countries are</cell></row><row><cell>exporters of fresh, dried or frozen vegetables? })</cell></row><row><cell>!MERGE_CMBZ (topic @ {vegetable exporters of europe what countries</cell></row><row><cell>are exporters of fresh, dried or frozen vegetables? }))</cell></row><row><cell>!MERGE_PIVOT/64 (topic @ {vegetable exporters of europe what</cell></row><row><cell>countries are exporters of fresh, dried or frozen vegetables? })</cell></row><row><cell>search ((headline @ {vegetable exporters of europe what countries are</cell></row><row><cell>exporters of fresh, dried or frozen vegetables? vegetable exporters europe }</cell></row><row><cell>!MERGE_CMBZ (topic @ {vegetable exporters of europe what countries are</cell></row><row><cell>exporters of fresh, dried or frozen vegetables? vegetable exporters europe})</cell></row><row><cell>!MERGE_CMBZ ((geotext @ {vegetable exporters of europe what countries are</cell></row><row><cell>exporters of fresh, dried or frozen vegetables? vegetable exporters europe })</cell></row><row><cell>!MERGE_CMBZ (topic @ { Albania Andorra Austria Belarus Belgium</cell></row><row><cell>Bosnia and Herzegovina Bulgaria Croatia Cyprus Czech Republic Denmark</cell></row><row><cell>Estonia Faroe Islands Finland France Georgia Germany Gibraltar Greece</cell></row><row><cell>Guernsey and Alderney Hungary Iceland Ireland Isle of Man Italy Jersey</cell></row><row><cell>Latvia Liechtenstein Lithuania Luxembourg Macedonia Malta Moldova Monaco</cell></row><row><cell>Netherlands Norway Poland Portugal Romania Russia San Marino</cell></row><row><cell>Serbia and Montenegro Slovakia Slovenia Spain Svalbard and Jan Mayen</cell></row><row><cell>Sweden Switzerland Turkey Ukraine United Kingdom Vatican City }))</cell></row><row><cell>!MERGE_PIVOT/64 (topic @ {vegetable exporters of europe what countries are</cell></row><row><cell>exporters of fresh, dried or frozen vegetables? vegetable exporters europe })</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,110.51,433.79,358.77,9.96" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="9,167.71,433.79,190.12,9.96">Cross-language retrieval experiments at clef</title>
		<author>
			<persName coords=""><forename type="first">Aitao</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002. 2003</date>
			<biblScope unit="page" from="28" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.51,453.35,402.31,9.96;9,110.52,465.35,402.26,9.96;9,110.52,477.35,401.95,9.96;9,110.52,489.23,236.18,9.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,353.82,453.35,159.01,9.96;9,110.52,465.35,129.24,9.96">Experiments in the probabilistic retrieval of full text documents</title>
		<author>
			<persName coords=""><forename type="first">William</forename><forename type="middle">S</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aitao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fredric</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</author>
		<idno>500-225</idno>
	</analytic>
	<monogr>
		<title level="m" coord="9,390.27,465.35,122.51,9.96;9,110.52,477.35,138.75,9.96">Overview of the Third Text Retrieval Conference (TREC-3)</title>
		<editor>
			<persName><forename type="first">Donna</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</editor>
		<meeting><address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<publisher>NIST Special Publication</publisher>
			<date type="published" when="1994">1994</date>
		</imprint>
		<respStmt>
			<orgName>National Institute of Standards and Technology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.51,508.91,402.16,9.96;9,110.52,520.91,402.07,9.96;9,110.52,532.79,402.30,9.96;9,110.52,544.79,122.38,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,375.75,508.91,136.92,9.96;9,110.52,520.91,105.52,9.96">Probabilistic retrieval based on staged logistic regression</title>
		<author>
			<persName coords=""><forename type="first">William</forename><forename type="middle">S</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fredric</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><forename type="middle">P</forename><surname>Dabney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,235.67,520.91,276.91,9.96;9,110.52,532.79,185.25,9.96">15th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting><address><addrLine>Copenhagen, Denmark; New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1992">June 21-24. 1992</date>
			<biblScope unit="page" from="198" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.51,564.47,402.00,9.96;9,110.52,576.35,76.44,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,179.20,564.47,146.11,9.96">TREC interactive with cheshire II</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Larson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,332.31,564.47,174.91,9.96">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="485" to="505" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.51,596.03,401.97,9.96;9,110.52,608.03,402.08,9.96;9,110.52,619.91,395.33,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,179.80,596.03,203.46,9.96">A logistic regression approach to distributed IR</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Larson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,403.77,596.03,108.71,9.96;9,110.52,608.03,402.08,9.96;9,110.52,619.91,92.94,9.96">SIGIR 2002: Proceedings of the 25th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting><address><addrLine>Tampere, Finland</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">August 11-15, 2002. 2002</date>
			<biblScope unit="page" from="399" to="400" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.51,639.59,402.14,9.96;9,110.52,651.47,402.10,9.96;9,110.52,663.47,358.54,9.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,182.92,639.59,329.73,9.96;9,110.52,651.47,78.38,9.96">Cheshire II at INEX: Using a hybrid logistic regression and boolean model for XML retrieval</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Larson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,214.12,651.47,298.50,9.96;9,110.52,663.47,158.08,9.96;9,335.16,663.47,104.03,9.96">Proceedings of the First Annual Workshop of the Initiative for the Evaluation of XML retrieval (INEX)</title>
		<meeting>the First Annual Workshop of the Initiative for the Evaluation of XML retrieval (INEX)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="18" to="25" />
		</imprint>
	</monogr>
	<note>DELOS workshop series</note>
</biblStruct>

<biblStruct coords="9,110.51,683.15,402.26,9.96;9,110.52,695.03,353.73,9.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,179.80,683.15,329.10,9.96">Cheshire II at INEX 03: Component and algorithm fusion for XML retrieval</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Larson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,122.87,695.03,147.50,9.96">INEX 2003 Workshop Proceedings</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="38" to="45" />
		</imprint>
		<respStmt>
			<orgName>University of Duisburg</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.51,61.43,402.04,9.96;10,110.52,73.43,116.24,9.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,188.32,61.43,259.93,9.96">A fusion approach to XML structured document retrieval</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Larson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,460.64,61.43,51.92,9.96;10,110.52,73.43,37.21,9.96">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="601" to="629" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.51,93.35,402.02,9.96;10,110.52,105.35,402.09,9.96;10,110.52,117.23,359.44,9.96" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,178.97,93.35,188.60,9.96">Analyses of multiple evidence combination</title>
		<author>
			<persName coords=""><forename type="first">Joon</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lee</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,394.10,93.35,118.44,9.96;10,110.52,105.35,402.09,9.96;10,110.52,117.23,92.94,9.96">SIGIR &apos;97: Proceedings of the 20th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting><address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1997">July 27-31, 1997. 1997</date>
			<biblScope unit="page" from="267" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.50,137.15,402.17,9.96;10,110.52,149.15,402.10,9.96;10,110.52,161.03,224.35,9.96" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,465.80,137.15,46.87,9.96;10,110.52,149.15,226.86,9.96">OKAPI at TREC-7: ad hoc, filtering, vlc and interactive track</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Micheline</forename><forename type="middle">M</forename><surname>Hancock-Beauliee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,359.67,149.15,152.95,9.96;10,110.52,161.03,8.07,9.96">Text Retrieval Conference (TREC-7)</title>
		<imprint>
			<date type="published" when="1998">Nov. 9-1 1998. 1998</date>
			<biblScope unit="page" from="152" to="164" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.50,180.95,402.26,9.96;10,110.52,192.95,402.07,9.96;10,110.52,204.95,321.50,9.96" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,302.11,180.95,210.65,9.96;10,110.52,192.95,28.47,9.96">On relevance weights with little relevance information</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steven</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,159.81,192.95,352.78,9.96;10,110.52,204.95,177.43,9.96">Proceedings of the 20th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 20th annual international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="16" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.50,224.87,402.15,9.96;10,110.52,236.75,401.81,9.96;10,110.52,248.75,216.08,9.96" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,272.98,224.87,142.64,9.96">Combination of multiple searches</title>
		<author>
			<persName coords=""><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Shaw</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Edward</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,435.46,224.87,77.19,9.96;10,110.52,236.75,183.47,9.96">Proceedings of the 2nd Text REtrieval Conference (TREC-2)</title>
		<title level="s" coord="10,304.00,236.75,208.33,9.96;10,110.52,248.75,81.26,9.96">National Institute of Standards and Technology Special Publication</title>
		<meeting>the 2nd Text REtrieval Conference (TREC-2)</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="volume">500</biblScope>
			<biblScope unit="page" from="243" to="252" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
