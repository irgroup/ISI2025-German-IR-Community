<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,123.60,146.03,355.77,18.08;1,479.39,144.26,5.98,12.55">University of Alicante in ImageCLEF2005 *</title>
				<funder ref="#_ARRZRzG">
					<orgName type="full">Spanish Government</orgName>
				</funder>
				<funder ref="#_D8ZEBt6">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2005-08-15">August 15, 2005</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,114.12,181.09,98.27,10.46"><forename type="first">Rubén</forename><surname>Izquierdo-Beviá</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamentos de Lenguajes y Sistemas Informáticos</orgName>
								<address>
									<settlement>Alicante</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,220.14,181.09,55.31,10.46"><forename type="first">David</forename><surname>Tomás</surname></persName>
							<email>dtomas@dlsi.ua.es</email>
							<affiliation key="aff0">
								<orgName type="department">Departamentos de Lenguajes y Sistemas Informáticos</orgName>
								<address>
									<settlement>Alicante</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,283.98,181.09,106.28,10.46"><forename type="first">Maximiliano</forename><surname>Saiz-Noeda</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamentos de Lenguajes y Sistemas Informáticos</orgName>
								<address>
									<settlement>Alicante</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,412.94,181.09,40.25,10.46"><forename type="first">José</forename><surname>Luis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Departamentos de Lenguajes y Sistemas Informáticos</orgName>
								<address>
									<settlement>Alicante</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,123.60,146.03,355.77,18.08;1,479.39,144.26,5.98,12.55">University of Alicante in ImageCLEF2005 *</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2005-08-15">August 15, 2005</date>
						</imprint>
					</monogr>
					<idno type="MD5">3DAD5ACF040F1B0DE2DFC55B3F38CCDA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries Streams, Combination, Ontology, Feedback Text-based image retrieval, Stream combination, Automatic extracted ontology</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the participation of the University of Alicante (UA) in CLEF 2005 image retrieval task. For this purpose we used an image retrieval system based on probabilistic information combined with ontological information and a feedback technique. Several information streams are created using different sources: stems, words and bigrams; the final result is obtained combining them. Also a voting-based strategy has been developed joining three different systems of participant Universities.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Nowadays it's well known the development of the information society and the huge amount of documents it produces. All sorts of documents are generated: plain text, images, videos, source code. . . This amount of documents makes necessary the use of automatic techniques when trying to access them. Specifically, information retrieval (IR) techniques are related to the task of retrieving relevant documents from user queries and a large set of documents. One subtask of IR is multimedia retrieval, where documents are images, videos, or any kind of multimedia document. Multimedia-based applications are very important in many fields such as medical applications, multimedia databases <ref type="bibr" coords="1,187.80,655.72,9.96,10.46" target="#b0">[1]</ref>, . . . Within the ImageCLEF task we have developed an image retrieval system. An image retriever is an IR system that recovers relevant images. Mainly, there are two approaches to Image Retrieval <ref type="bibr" coords="1,90.01,691.58,9.96,10.46" target="#b5">[6]</ref>. On the one hand we have Content-Based Image Retrieval (CBIR). This approach deals with primitive features of the image using artificial vision techniques. On the other hand there are techniques based on the text that describes the image. Moreover, there are hybrid ones that combine both approaches.</p><p>There are two main techniques for text-based systems: probabilistic and natural language processing (NLP) <ref type="bibr" coords="2,154.78,146.22,9.96,10.46" target="#b1">[2]</ref>. The former use probabilistic information to make the retrieval while the other exploit the use of NLP techniques such as taggers, parsers, chunkers, named entity recognizers, etc.</p><p>Our system combines probabilistic and automatic extracted knowledge from text that describes the image. We have initially used a probabilistic information retrieval system: Xapian <ref type="bibr" coords="2,476.69,194.04,9.96,10.46" target="#b6">[7]</ref>. The main idea consists on creating three information streams, each one with different information and combine them to reach the final result.</p><p>Furthermore, an ontology has been created using St. Andrews Corpus <ref type="bibr" coords="2,428.13,229.91,9.96,10.46">[8]</ref>. The idea is to know the category related to a query. In this way we can select from the final retrieved list those documents with the same category than the query.</p><p>In order to deal with the multilingual view we have made an analysis with the ImageCLEF 2004 queries set and several automatic translators. Topics in different languages are first translated into English and then retrieval is performed.</p><p>This paper is structured as follows. Section 2 presents the system in depth. Section 3 explains the development of the image ontology. Section 4 provides the result of our participation in ImageCLEF 2005. Section 5 describes the joint participation. Some conclusions and future work close the document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System</head><p>The system implements an approach based on probabilistic information and knowledge extracted from the corpus. The system uses Xapian <ref type="bibr" coords="2,280.97,404.23,9.96,10.46" target="#b6">[7]</ref>, a probabilistic and boolean information retrieval system and the process is divided into two phases: indexing and retrieval. During the indexing phase three indexes with different information are created. When we have a query, we make a retrieval in each index and then combine the results to get the final goal. Figure <ref type="figure" coords="2,458.33,440.10,4.98,10.46">1</ref> shows this process.</p><p>Figure <ref type="figure" coords="2,262.99,669.66,3.87,10.46">1</ref>: Generation of streams</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Indexing</head><p>In this step we create three indexes, each one with different information: words, stems and stem bigrams. The first to do is to process the image text to extract relevant information. All the text that follows the image is relevant, but each field will have a weight depending on its relevance. This is done by means of a set of manually developed patterns, which are regular expressions proposed in the image retrieval system presented at the ImageCLEF 2004 campaign <ref type="bibr" coords="3,465.16,134.27,9.96,10.46" target="#b4">[5]</ref>. In this way we have more information and can distinguish between useful and useless information. Figure <ref type="figure" coords="3,90.01,158.18,4.98,10.46">2</ref> shows an example of the use of the patterns. From the &lt;TEXT&gt; field and by means of the patterns the fields extracted are: shtitle, description, date, photographer, location and notes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2: Example of pattern application</head><p>With the information of the fields, and depending on the upper or lowercase in the first letter of the token (word, stem or bigram), a weight to each of this tokens is assigned<ref type="foot" coords="3,435.79,509.32,3.97,7.32" target="#foot_0">1</ref> (see Table <ref type="table" coords="3,487.63,510.40,3.87,10.46">1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FIELD WEIGHT Headline 5 Shtitle 4 Description 1 Data 3 Photo 3 Location 3</head><p>Notes 0 Categories 8 Table <ref type="table" coords="3,215.76,650.26,3.87,10.46">1</ref>: Weights assigned to each field in image file Finally, the weight assigned to each token is:</p><formula xml:id="formula_0" coords="3,173.05,713.26,250.72,22.41">W token = 100 * f ield weight if 1st letter is uppercase 50 * f ield weight if 1st letter is lowercase</formula><p>Using this weighting scheme, we create three indexes and the indexing phase finishes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Retrieval</head><p>In this phase the query topics are processed and a list of relevant documents to each query is given. The main idea is to perform three independent retrievals, one in each index and then combine them to get a unique list of retrieved images. The first step prepares the query to be posed to the retrieval system. Given a topic, stop words are removed and then each word is transformed to have three queries, one for each index.</p><p>Once we have the three queries, a first retrieval in each index is performed. The second step is applies the relevance feedback. Xapian allows us to use feedback in a simple way: we must only select those documents which we consider relevant. Some experiments over ImageCLEF 2004 query set reveal that the number of documents to get the better results is twenty three.</p><p>In the next step the ontology is used. With this ontology we know both the categories related to the query and the categories of each retrieved document. Using this information the relevance of the documents having any category in common with the query can be increased. This process is done separately in the three retrieved lists.</p><p>The last step combines the three lists to get a global result. We believe that each stream gives a different kind of information, and thus, each stream must have a different weight. We made an analysis to make the best weight tuning considering the contribution of each information flow.</p><p>• Stem flow: It can increase the recall because with the stemming, same words but morphologically different can be matched.</p><p>• Word flow: It can increase the precision. Only words exactly equal are matched.</p><p>• Bigram flow: It can increase the precision. Word pairs, such as compound noun phrases.</p><p>So, the weights selected to do the combination are<ref type="foot" coords="4,324.54,424.07,3.97,7.32" target="#foot_2">2</ref> :</p><p>-Stem flow: 0.5 -Word flow: 0.1 -Bigram flow: 0.3</p><p>In the combination, each document has as score the sum of its flow scores multiplied by their corresponding weight.</p><formula xml:id="formula_1" coords="4,188.67,531.34,225.14,11.35">W Doc = 0.5 * W F low + 0.1 * W W ord + 0.3 * W Bigram</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Multilingual view</head><p>In order to deal with multilingual features we have decided to make an analysis of several online translators. Among different well-known translators such as Babel [9], Reverso [12], WordLingo [13], Epals [10] and Prompt [11], WordLingo was selected due to its the best average result for the treated languages according to the ImageCLEF 2004 query set and the St. Andrews corpus. The test languages for the system are Dutch, French, German, Greek, Italian, Japanese, Portuguese, Russian, Chinese and Spanish.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The image ontology</head><p>In this section we are going to describe how the ontology is created and how the system uses this information in the retrieval process. This ontology represents a knowledge base, and it is an approach to use knowledge resources in information retrieval. The idea is to extract the categories related with a query and then retrieve documents with the same categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Ontology building</head><p>The ontology has been automatically built using the St. Andrews corpus. Each image caption has a field called &lt;CATEGORIES&gt; (see figure <ref type="figure" coords="5,268.30,140.70,3.87,10.46">2</ref>). For each image in the corpus the categories and the words of the &lt;TITLE&gt; field are extracted. The ontology is used to create an "ontology-document" database that relate each category with the corresponding words. The process is shown in figure <ref type="figure" coords="5,90.01,176.56,3.87,10.46" target="#fig_0">3</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Ontology use</head><p>Queries are posed to the ontology index in order to retrieve a ranked list of "ontology-documents". The score of the category document 'C' indicates the probability of a query to require a document of this category 'C'. The category ranking results will be used for document re-ranking using the lists of relevant documents (one for each stream) obtained from first step image retrieval process. When we make the retrieval in each of the index created (stem, word and bigram), we have a list of documents. Each of these documents has several categories, so if we know the categories related to the query, we can increase the weight of those documents having some category in common with the query. Figure <ref type="figure" coords="5,168.64,519.49,4.98,10.46">4</ref> shows this process, where weights extracted from the category database (wc1, wc2 and wc3) are added to the total weight of the image according to their common categories.</p><p>Figure <ref type="figure" coords="5,270.00,699.01,3.87,10.46">4</ref>: Using the ontology Four experiments have been proposed for the evaluation. In each one we combine different techniques in order to discover how these techniques help in the retrieval process. The features that have been merged in different experiments are:</p><p>• Uses of stems, words or bigrams(tokens) adjusting their weights.</p><p>• Use of correct fields adjusting their weights.</p><p>• Selection of different flow weights when combining the results.</p><p>• Use of categories (ontology).</p><p>• Use of automatic feedback.</p><p>Combining all these features, over 100 experiments have been performed, but we have only selected the best four in order to participate in ImageCLEF 2005. Experiments selected and their features are shown in next table: As we can see in the previous table, Experiment3 provides the best performance. Experiment3 uses stems, words and bigrams, and also implements feedback and categories knowledge.</p><formula xml:id="formula_2" coords="6,148.76,347.77,305.49,58.67">STEM WORD BIGRAM CATS. FEEDBACK Baseline X Experiment1 X X X Experiment2 X X X X Experiment3 X X X X X</formula><p>According to Baseline, Experiment1 and Experiment2 comparison it seems that word and bigram adding do not improive the results <ref type="foot" coords="6,274.51,637.78,3.97,7.32" target="#foot_3">3</ref> .</p><p>The improvement related to he use of the knowledge ontology can observed when comparing Experiment2 and Experiment3. This increase could be greater with a more sophisticated ontology, for example, use a more general ontology that combines more general concepts and specific domain terms. Apart from the system described, we have made a joint participation within the R2D2 project<ref type="foot" coords="7,508.53,131.10,3.97,7.32" target="#foot_4">4</ref> framework integrating our system and the ones belonging to UNED group from Madrid and SINAI group from Jaén. We have developed a voting among them. A combination between UA and SINAI has been done for English, Dutch, French, German, Italian, Russian and Spanish. The three systems have been only combined for Spanish. The systems selected for the combination implement feedback and use query titles and automatic translation.</p><p>The voting has been developed using the weights of each document in each retrieved list. The first step makes a normalization of the weights for each document list dividing each weight by the maximum weight of all the documents in the list. Then the different weights of each document in each list are summed. In this way, documents that appear in the three lists are more relevant than those appearing in just two lists. Finally the documents are sorted according to the calculated weight and a final document list is generated.</p><p>MAP results obtained from the collaborative experiments are shown in the It can be observed that this voting system improves the results of the individual separated systems in the most of the languages: English, Dutch, German, Italian and Spanish (lat).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and future work</head><p>This paper has presented the approach used by the University of Alicante in the ImageCLEF 2005 adhoc retrieval task. This image retrieval system implements a combination of probabilistic and knowledge-based approaches. The implementation and tuning of the method have been shown and results have been explained.</p><p>To continue improving the system there are several ways that can be taken in account. One of them is to consider the use of NLP to improve the information retrieval <ref type="bibr" coords="7,427.11,599.68,9.96,10.46" target="#b3">[4]</ref>. For example, a chunker or parser or even better a named entity recognizer can be used to detect noun phrases or entities. In this way we could create a noun phrase stream to be combined with the existing ones.</p><p>Another work to be developed is the creation and management of the ontology, that is, the use of knowledge in the retrieval process <ref type="bibr" coords="7,250.15,647.51,9.96,10.46" target="#b2">[3]</ref>. A more complex ontology can be created considering the possibility of changing the knowledge representation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,226.40,375.64,150.20,10.46;5,188.50,202.09,224.70,161.70"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Creation of the ontology</figDesc><graphic coords="5,188.50,202.09,224.70,161.70" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="3,155.55,188.51,298.20,272.58"><head></head><label></label><figDesc></figDesc><graphic coords="3,155.55,188.51,298.20,272.58" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,104.94,417.45,318.64,140.67"><head>Table 2 :</head><label>2</label><figDesc>Feature selection for each retrieval experiment.</figDesc><table coords="6,104.94,477.18,317.12,80.94"><row><cell>The results of the monolingual system over ImageCLEF05 query set are:</cell></row><row><cell>EXPERIMENT MAP</cell></row><row><cell>Baseline 0.3944</cell></row><row><cell>Experiment1 0.3942</cell></row><row><cell>Experiment2 0.3909</cell></row><row><cell>Experiment3 0.3966</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,139.79,569.11,323.43,10.46"><head>Table 3 :</head><label>3</label><figDesc>Results for UA monolingual adhoc retrieval in ImageCLEF 2005.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,90.00,275.64,423.01,150.73"><head>Table 4 .</head><label>4</label><figDesc>Ranking positions are shown in brackets.</figDesc><table coords="7,112.04,319.87,378.92,106.50"><row><cell>LANGUAGE UA</cell><cell>JAEN</cell><cell>UNED</cell><cell cols="2">UA-JAEN UA-JAEN-UNED</cell></row><row><cell cols="3">English 0.3966(14) 0.3727(30) -</cell><cell cols="2">0.4080(7) -</cell></row><row><cell>Dutch 0.2765(8)</cell><cell>0.3397(2)</cell><cell>-</cell><cell cols="2">0.3435(1) -</cell></row><row><cell>French 0.2621(6)</cell><cell>0.2864(1)</cell><cell>-</cell><cell>0.2630(5)</cell><cell>-</cell></row><row><cell>German 0.2854(7)</cell><cell>0.3004(4)</cell><cell>-</cell><cell cols="2">0.3375(1) -</cell></row><row><cell>Italian 0.2230(4)</cell><cell cols="2">0.1805(11) -</cell><cell cols="2">0.2289(2) -</cell></row><row><cell>Russian 0.2683(3)</cell><cell cols="2">0.2229(11) -</cell><cell>0.2665(5)</cell><cell>-</cell></row><row><cell cols="2">Spanish (eur) 0.2105(12) 0.2416(5)</cell><cell>0.3175(1)</cell><cell>0.2668(4)</cell><cell>0.3020(2)</cell></row><row><cell>Spanish (lat) 0.3179(2)</cell><cell>0.2967(8)</cell><cell cols="3">0.2585(17) 0.3447(1) 0.3054(4)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,159.49,447.34,284.01,10.46"><head>Table 4 :</head><label>4</label><figDesc>Comparing results in voting-based collaborative system.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,105.24,745.67,298.39,8.37"><p>The weights have been adjusted to have the best performance over Image CLEF</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2004" xml:id="foot_1" coords="3,426.21,745.67,36.29,8.37"><p>query set.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_2" coords="4,105.24,745.67,407.87,8.37"><p>These weights have been adjusted doing an analysis over ImageCLEF 2004 topics to get the best performance.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_3" coords="6,105.24,704.00,407.88,8.37"><p>During the experiments over ImageCLEF 2004 dataset, word and bigram adding provided a slight improvement.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_4" coords="7,105.24,678.73,407.87,8.37;7,90.00,688.19,423.12,8.37;7,90.01,697.65,423.11,8.37;7,90.00,707.11,198.21,8.37"><p>R2D2 project: Question Answering in Digital Documents. Reference TIC2003-07158-C04 financed by the Science Technology Department 2003-2006 of the Spanish Government. The main goal of the project is the evaluation and development of Question Answering and Document Retrieval systems in multilingual scenarios. See http://gplsi.dlsi.ua.es/r2d2/indexEn for more details.</p></note>
		</body>
		<back>

			<div type="funding">
<div> *   <p>This work has been developed in the framework of the project <rs type="projectName">CICYT R2D2</rs> (<rs type="grantNumber">TIC2003-07158-C04</rs>) and it has been partially funded by the <rs type="funder">Spanish Government</rs> through the grant <rs type="grantNumber">BES-2004-3935</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_ARRZRzG">
					<idno type="grant-number">TIC2003-07158-C04</idno>
					<orgName type="project" subtype="full">CICYT R2D2</orgName>
				</org>
				<org type="funding" xml:id="_D8ZEBt6">
					<idno type="grant-number">BES-2004-3935</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,110.48,132.18,362.86,10.46" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="8,245.46,132.18,223.18,10.46">Benchmarks for storage and retrieval in multimedia</title>
		<imprint>
			<publisher>Databases Forsyth Computer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,152.11,356.26,10.46" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="8,172.83,152.11,263.67,10.46">Image information retrieval: An overview of current research</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Goodrum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,172.03,402.52,10.46;8,110.48,183.99,402.54,10.46;8,110.48,195.94,257.61,10.46" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,169.45,172.03,343.56,10.46;8,110.48,183.99,398.11,10.46">Design and creation of ontologies for environmental information retrieval, proceedings of the 12th workshop on knowledge acquisition, modeling and management (kaw&apos;99)</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kashyap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,250.53,195.94,86.95,10.46">KAW&apos;99 Conference</title>
		<meeting><address><addrLine>banff, canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-10">october 1999. 1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,215.86,402.53,10.46;8,110.48,227.82,252.68,10.46" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,301.68,215.86,211.33,10.46;8,110.48,227.82,26.42,10.46">Natural language processing for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karen</forename><forename type="middle">Sparck</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,145.09,227.82,124.13,10.46">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="92" to="101" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,247.74,402.53,10.46;8,110.48,259.70,402.52,10.46;8,110.48,271.65,234.03,10.46" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,403.16,247.74,109.85,10.46;8,110.48,259.70,275.55,10.46">Pattern-based Image Retrieval with Constraints and Preferences on ImageCLEF 2004</title>
		<author>
			<persName coords=""><forename type="first">Maximiliano</forename><surname>Saiz-Noeda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">José</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luis</forename><surname>Vicedo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rubén</forename><surname>Izquierdo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,412.17,259.70,100.83,10.46;8,110.48,271.65,96.33,10.46">Working Notes for the CLEF 2004 WorkShop</title>
		<meeting><address><addrLine>Bath, United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,291.58,402.53,10.46;8,110.48,303.54,402.52,10.46;8,110.48,315.49,101.56,10.46" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,361.76,291.58,151.25,10.46;8,110.48,303.54,130.22,10.46">The CLEF Cross Language Image Retrieval Track (imageCLEF)</title>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,283.28,303.54,196.98,10.46">Working Notes for the CLEF 2004 WorkShop</title>
		<meeting><address><addrLine>Bath, United Kingdom</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,335.42,228.63,10.46" xml:id="b6">
	<monogr>
		<ptr target="http://www.xapian.org/" />
		<title level="m" coord="8,139.25,335.42,82.18,10.46">The xapian project</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
