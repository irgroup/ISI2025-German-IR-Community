<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,116.54,146.04,370.00,18.08;1,486.46,144.26,5.98,12.55">CUHK Experiments with ImageCLEF 2005 *</title>
				<funder ref="#_Kjr75tk">
					<orgName type="full">Innovation and Technology Fund</orgName>
				</funder>
				<funder ref="#_pFffnDS">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,193.92,181.09,69.12,10.46"><forename type="first">Steven</forename><forename type="middle">C H</forename><surname>Hoi</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong Shatin</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<region>N.T</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,270.86,181.09,48.04,10.46"><forename type="first">Jianke</forename><surname>Zhu</surname></persName>
							<email>jkzhu@cse.cuhk.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong Shatin</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<region>N.T</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,341.59,181.09,67.54,10.46"><forename type="first">Michael</forename><forename type="middle">R</forename><surname>Lyu</surname></persName>
							<email>lyu@cse.cuhk.edu.hk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<orgName type="institution">The Chinese University of Hong Kong Shatin</orgName>
								<address>
									<settlement>Hong Kong</settlement>
									<region>N.T</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,116.54,146.04,370.00,18.08;1,486.46,144.26,5.98,12.55">CUHK Experiments with ImageCLEF 2005 *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CD4A9D9F208C28E75428EA4039C1A71F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Managment]: Languages-Query Languages Measurement, Performance, Experimentation Language Models, Text Based Image Retrieval, Multimodal Image Retrieval, Cross-Language Retrieval, Cross-Media Retrieval, Smoothing Strategy</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the empirical studies of cross-language and cross-media retrieval for the ImageCLEF competition in 2005. It reports the empirical summary of the work of CUHK (The Chinese University of Hong Kong) at ImageCLEF 2005. This is the first participation of our group at ImageCLEF. The task we participated this year is the "Bilingual ad hoc retrieval" task. There are three major focuses and contributions in our participation. The first is the empirical evaluations of language models and the smoothing strategies for cross-language image retrieval. The second is the evaluations of cross-media image retrieval, i.e., combining text and visual content for image retrieval. The last one is the evaluation of the bilingual image retrieval between English and Chinese. We provide empirical analysis on the experimental results. From the official testing results of the Bilingual ad hoc retrieval task, we achieve the highest MAP result (0.4135) in the monolingual query among all organizations.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.27" lry="841.82"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.27" lry="841.82"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.27" lry="841.82"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.27" lry="841.82"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.27" lry="841.82"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.27" lry="841.82"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.27" lry="841.82"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.27" lry="841.82"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.27" lry="841.82"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Visual information retrieval has been an active research topic for many years. Although contentbased image retrieval (CBIR) has been received considerable studies in the community <ref type="bibr" coords="1,474.00,681.10,9.97,10.46" target="#b6">[9]</ref>, there is so far few benchmark image dataset available. The CLEF (Cross Language Evaluation Forum) organization <ref type="bibr" coords="1,147.70,705.01,10.52,10.46" target="#b4">[7]</ref> began the ImageCLEF campaign from 2003 for benchmark evaluation of crosslanguage image retrieval <ref type="bibr" coords="1,196.54,716.96,9.97,10.46" target="#b1">[4]</ref>. ImageCLEF 2005 offers four different tasks: bilingual ad hoc retrieval, interactive search, medical image retrieval and automatic image annotation task. This is the first participation of our CUHK group (The Chinese University of Hong Kong) at ImageCLEF. The task we participated this year is the "Bilingual ad hoc retrieval".</p><p>In the past decade, traditional information retrieval mainly focused on the document retrieval problems <ref type="bibr" coords="2,132.68,158.18,9.97,10.46" target="#b0">[3]</ref>. Along with more and more attentions in multimedia information retrieval in recent years, the cross-language and cross-media retrieval have been put forward as an important research topic in the community <ref type="bibr" coords="2,198.61,182.09,9.97,10.46" target="#b1">[4]</ref>. The cross-language image retrieval is to tackle the multimodal information retrieval task by unifying the techniques from traditional information retrieval, natural language processing (NLP), and traditional CBIR solutions.</p><p>In this participation, we offer the main contributions in three aspects. The first is the empirical evaluation of language models and the smoothing strategies for cross-language image retrieval. The second is the evaluation of cross-media image retrieval, i.e., combining text and visual content for image retrieval. The last one is the methodology and empirical evaluation of the bilingual image retrieval between English and Chinese.</p><p>The rest of this paper is organized as follows. Section 2 introduces the TF-IDF retrieval model and the language model based retrieval methods. Section 3 describes the details of our implementation for this participation, and outlines our empirical study on the cross-language and cross-media retrieval system. Finally section 4 concludes our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Language Models for Text Based Image Retrieval</head><p>In this participation, we conducted extensive experiments to evaluate the performance of Language Models and the influences of different smoothing strategies. More specifically, two kinds of retrieval models are studied in our experiments: (1) The TF-IDF retrieval model (2) The KL-divergence language models based method. The smoothing strategies for Language Models are evaluated in our experiments <ref type="bibr" coords="2,162.42,416.18,14.62,10.46" target="#b8">[11]</ref>: (1) Jelinek-Mercer (JM), (2) Dirichlet prior (DIR), (3) Absolute discounting (ABS).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">TF-IDF Similarity Measure for Information Retrieval</head><p>We incorporate the Language Models (LM) with the TF-IDF similarity measure <ref type="bibr" coords="2,443.33,474.41,13.31,10.46" target="#b0">[3]</ref>. TF-IDF is widely used in information retrieval, which is a way of weighting the relevance of a query to a document. The main idea of TF-IDF is to represent each document by a vector in the size of the overall vocabulary. Each document D i is then represented as a vector (w i1 , w i2 ), • • • , w in if n is the size of the vocabulary. The entry w i,j is calculated as:</p><formula xml:id="formula_0" coords="2,248.93,546.15,264.08,11.36">w ij = T F ij × log(IDF j ) (1)</formula><p>where T F ij is the term frequency of the j th word in the vocabulary in the document D i , i.e. the number of occurrences. IDF j is the inverse document frequency of the j th term, given as</p><formula xml:id="formula_1" coords="2,198.93,596.76,314.07,24.93">IDF j = #documents #documents containing the j th term (2)</formula><p>The similarity between two documents is then defined as the cosine of the angle between the two vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Language Modeling for Information Retrieval</head><p>A statistical language model, or more simply a language model, is a probabilistic mechanism for generating text. The first serious statistical language modeler was Claude Shannon <ref type="bibr" coords="2,483.58,700.34,9.97,10.46" target="#b5">[8]</ref>. In exploring the application of his newly founded theory of information to human language, thought of purely as a statistical source, Shannon measured how well simple n-gram models did at predicting, or compressing, natural text. In the past several years there has been significant interest in the use of language modeling methods for a variety of text retrieval and natural language processing tasks <ref type="bibr" coords="3,115.29,122.31,14.62,10.46" target="#b7">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">The KL-divergence Measure</head><p>Given two probability mass functions p(x) and q(x), D(p||q), the Kullback-Leibler (KL) divergence (or relative entropy) between p and q is defined as</p><formula xml:id="formula_2" coords="3,244.82,196.60,268.19,28.06">D(p||q) = x p(x)log p(x) q(x)<label>(3)</label></formula><p>One can show that D(p||q) is always non-negative and is zero if and only if p = q. Even though it is not a true distance between distributions (because it is not symmetric and does not satisfy the triangle inequality), it is still often useful to think of the KL-divergence as a "distance" between distributions <ref type="bibr" coords="3,148.27,267.63,9.97,10.46" target="#b2">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">The KL-divergence based Retrieval Model</head><p>For the language modeling approach, we assume a query q is generated by a generative model p(q|θ Q ), where θ Q denotes the parameters of the query unigram language model. Similarly, we assume that a document d is generated by a generative model p(q|θ D ), where θ Q denotes the parameters of the document unigram language model. Let θQ and θD be the estimated query and document language models respectively. The relevance value of d with respect to q can be measured by the following negative KL-divergence function <ref type="bibr" coords="3,351.81,372.71,14.62,10.46" target="#b7">[10]</ref>:</p><formula xml:id="formula_3" coords="3,145.63,391.53,367.37,23.95">-D( θQ || θD ) = w p(w| θQ )logp(w| θD ) + (- w p(w| θQ )logp(w| θQ ))<label>(4)</label></formula><p>In the above formula, the second term on the right-hand side of the formula is a querydependent constant, i.e., the entropy of the query model θQ . It can be ignored for the ranking purpose. In general, we consider the smoothing scheme for the estimated document model as follows:</p><formula xml:id="formula_4" coords="3,197.97,474.78,315.03,23.31">p(w| θD ) = p s (w|d) if word w is seen α d p(w|C) otherwise<label>(5)</label></formula><p>where p s (w|d) is the smoothed probability of a word seen in the document, p(w|C) is the collection language model, and α d is a coefficient controlling the probability mass assigned to unseen words, so that all probabilities sum to one <ref type="bibr" coords="3,246.87,530.21,14.62,10.46" target="#b7">[10]</ref>. In the subsequent section, we discuss several smoothing techniques in details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Several Smoothing Techniques</head><p>A smoothing method may be as simple as adding an extra count to every word, or words of different count are treated differently. In order to solve the problem efficiently, we select three representative methods that are popular and relatively efficient. The three methods are described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Jelinek-Mercer (JM)</head><p>This method involves a linear interpolation of the maximum likelihood model with the collection model, using a coefficient λ to control the influence of each model.</p><formula xml:id="formula_5" coords="3,220.60,703.61,292.40,11.36">p λ (ω|d) = (1 -λ)p ml (ω|d) + λp(ω|C) (6)</formula><p>Thus, this is a simple mixture model (but we preserve the name of the more general Jelinek-Mercer method which involves deleted-interpolation estimation of linearly interpolated n-gram models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Dirichlet prior (DIR)</head><p>A language model is a multinomial distribution, for which the conjugate prior for Bayesian analysis is the Dirichlet distribution with parameters (µ(ω 1 |C), µp(ω 2 |C), . . . , µp(ω n |C)). Thus, the model is given by</p><formula xml:id="formula_6" coords="4,239.19,173.08,273.81,26.43">p µ (ω|d) = c(ω; d) + µp(ω|C) ω c(ω; d) + µ (7)</formula><p>The Laplace method is a special case of the technique.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">Absolute discounting (ABS)</head><p>The idea of the absolute discounting method is to lower the probability of seen words by subtracting a constant from their counts. It is similar to the Jelinek-Mercer method, but differs in that it discounts the seen word probability by subtracting a constant instead of multiplying it by 1 -λ.</p><p>The model is given by</p><formula xml:id="formula_7" coords="4,214.21,294.09,294.55,26.43">p δ (ω|d) = max(c(ω; d) -δ, 0) ω c(ω; d) + δp(ω|C) (<label>8</label></formula><formula xml:id="formula_8" coords="4,508.76,300.83,4.24,10.46">)</formula><p>where δ ∈ [0, 1] is a discount constant and σ = δ|d| µ /|d|, so that all probabilities sum to one.</p><p>Here |d| µ is the number of unique terms in document d, and |d| is the total count of words in the documents, so that |d| = ω c(ω; d).  The three methods are summarized in Table <ref type="table" coords="4,300.99,490.79,4.98,10.46" target="#tab_0">1</ref> in terms of p s (ω|d) and α d in the general form. It is easy to see that a larger parameter value means smoothing in all cases. Retrieval using any of the three methods can be very efficiently, when the smoothing parameter is given in advance. It is as efficient as scoring using a TF-IDF model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Cross-Language and Cross-Media Image Retrieval</head><p>In this section, we describe the experimental setup and our experimental development at the ImageCLEF 2005. In addition, we analyze the results of our submission.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Setup</head><p>The bilingual ad hoc retrieval task is to find as many relevant images as possible for each given topic. The St. Andrew collection is used as the benchmark dataset in the campaign. The collection consists of 28,133 images, all of which associate with textual captions written in British English (the target language). The caption consists of 8 fields including title, photographer, location, date, and one or more pre-defined categories (all manually assigned by domain experts). In the ImageCLEF 2005 campaign, there are totally 28 queries for each language. For each query, two image samples are given.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Overview of Our Development</head><p>For the Bilingual ad hoc retrieval task, we studied the query tasks in English and Chinese (simplified). Both text and visual information are used in our experiments. To study the language models, we employ the Lemur toolkit [2] in our experiments. A list of standard stopwords is used in the parsing step.</p><p>To evaluate the influence on the performance by different schemes, we produced the results by using different configurations. Tables 2 shows the configurations and the experimental results in detail. In total, 36 runs with different configurations are submitted in our submission.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Analysis on the Experimental Results</head><p>In this part, we empirically analyze the experimental results of our submission. The goal of our evaluation is to check whether the language model is effective for cross-language image retrieval and what kinds of smoothing techniques achieve better performance. Moreover, we like to know the performance comparison between the Chinese query and the monolingual query.  LM denotes Language Model, KL denotes Kullback-Leibler divergence based, DIR denotes the smoothing using the Dirichlet priors, ABS denotes the smoothing using Absolute discounting, JM denotes the Jelinek-Mercer smoothing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Empirical Analysis of Language Models</head><p>Figure <ref type="figure" coords="7,122.49,128.75,4.98,10.46" target="#fig_4">2</ref> and Figure <ref type="figure" coords="7,184.75,128.75,4.98,10.46" target="#fig_5">3</ref> plot the curves of Precision vs. Recall and the curves of Precision vs. Number of Returned Documents respectively. From the experimental results in Figure <ref type="figure" coords="7,487.20,140.70,4.98,10.46" target="#fig_4">2</ref> and Figure <ref type="figure" coords="7,121.40,152.66,4.98,10.46" target="#fig_5">3</ref> as well as Table <ref type="table" coords="7,201.60,152.66,3.88,10.46" target="#tab_1">2</ref>, one can observe that the KL-divergence language model outperforms the simple TF-IDF retrieval model importantly (around 5%). In evaluation of the smoothing techniques, we observe that the Jelinek-Mercer smoothing and Absolute Discounting Smoothing yield better results than the Dirichlet prior (DIR). To deal with the Chinese queries for retrieving English documents, we first adopt a Chinese segmentation tool from the Linguistic Data Consortium (LDC) [1], i.e., the "LDC Chinese segmenter"<ref type="foot" coords="7,128.74,489.95,3.97,7.32" target="#foot_0">1</ref> , to extract the Chinese words from the given query sentences. The segmentation step is important toward effective query translation. Figure <ref type="figure" coords="7,332.62,502.98,4.98,10.46" target="#fig_6">4</ref> shows the Chinese segmentation results of part queries. We can see that the results can still be improved.</p><p>For the bilingual query translation, the second step is to translate the extracted Chinese words into English words using a Chinese-English dictionary. In our experiment, we employ the LDC Chinese-to-English Wordlist [1] for the translations. The final translated queries are obtained by combining the translation results.</p><p>From the experimental results shown in Table <ref type="table" coords="7,301.86,574.71,3.88,10.46" target="#tab_1">2</ref>, we can observe that the mean average precision of Chinese-To-English Queries is about the half of the monolingual queries. There are a lot of ways to improve the performance. One is to improve the Chinese segmentation algorithm. Some post-processing tricks may be effective for improving the performance. Moreover, the translation results can be further refined. One can tune better results by adopting some Natural Language Processing techniques <ref type="bibr" coords="7,188.02,634.48,9.97,10.46" target="#b3">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Cross-Media Retrieval: Re-Ranking Scheme with Text and Visual Content</head><p>In this participation, we study the combination of text and visual content for cross-media image retrieval. In our development, we suggest the re-ranking scheme in combination with text and visual content. For a given query, we first rank the images by using the language modeling techniques. On the top ranking images, we then re-rank the images by measuring the visual similarity to the query.  In our experiment, two kinds of visual features are used: texture and color features. For the texture feature, the discrete cosine transform (DCT) is engaged to calculate coefficients that multiply the basis functions of the DCT. Applying the DCT to an image yields a set of coefficients to represent the texture of the image. In our implementation, a block-DCT (block size 8x8) is applied on the normalized input images which generate a 256-dimensional DCT feature. For the color feature, 9-dimensional color moment is extracted for each image. In total, each image is represented by a 265-dimensional feature vector.</p><formula xml:id="formula_9" coords="8,303.17,118.73,196.06,253.22">上 的 飞机 演奏 台 旁 聚集 的 群众 狗 的 坐 姿 靠 码头 的 蒸汽 船 动物 雕像 小 帆船 在 船上 的 渔夫 们 被 雪 覆盖 的 建筑物 马拉 动 运 货车 或 四 轮 车 的 图片 苏格兰 的 太阳</formula><p>As shown in Table <ref type="table" coords="8,188.01,528.61,3.88,10.46" target="#tab_1">2</ref>, the MAP of query results using only the visual information is about 6%, which is much lower than the text information with over 40%. From the experimental results, we can observe the re-ranking scheme only produce a marginal improvement compared with the text only approaches. Some reasons can be explained for the results. One is the engaged visual features not effective enough to discriminate the images. Another possible reason is that the ground truth images in the given query may not be quite different in visual content. It is interesting to study more effective features and learning methods for improving the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.4">Query Expansion for Information Retrieval</head><p>From the experimental results in Table <ref type="table" coords="8,268.10,644.62,3.88,10.46" target="#tab_1">2</ref>, we observe that all the queries are greatly enhanced by adopting Query Expansion<ref type="foot" coords="8,228.84,655.50,3.97,7.32" target="#foot_1">2</ref> (QE). The average improvement for all the queries is around 1.71% which accounts %4.12 of the maximum MAP of 41.35%. It is interesting to find that the QE especially benefits a lot for the Jelinek-Mercer smoothing method, the mean gain with QE is about 2.49% which accounts %6.02 of the maximum MAP of 41.35%.</p><p>In this paper, we reported our empirical studies of cross-language and cross-media image retrieval at the ImaegCLEF 2005 campaign. We addressed three major focuses and contributions in our participation. The first is the empirical evaluations of Language Models and the smoothing strategies for Cross-Language image retrieval. The second one is the evaluation of Cross-Media image retrieval, i.e., combining text and visual content for image retrieval. The last one is the evaluation of the Bilingual image retrieval between English and Chinese. We conducted empirical analysis on the experimental results and provided the empirical summary of our participation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,249.70,454.85,4.41,5.23;4,256.16,449.42,32.42,7.32;4,373.96,439.76,29.01,7.32;4,374.29,454.85,4.41,5.23;4,380.74,449.42,32.42,7.32;4,445.48,442.05,6.01,10.46;4,138.27,460.90,20.07,10.46;4,177.14,460.90,5.01,10.46;4,182.15,464.94,3.62,7.32;4,186.52,460.90,32.77,10.46;4,223.26,458.61,58.39,7.32;4,243.76,473.70,4.41,5.23;4,250.22,468.27,21.46,7.32;4,285.07,460.90,25.49,10.46;4,310.56,464.94,4.85,7.32;4,315.90,460.90,34.73,10.46;4,379.73,458.39,16.99,7.32;4,384.03,466.88,8.88,7.32;4,446.08,460.90,4.42,10.46"><head></head><label></label><figDesc>ω c(ω;d)+µ µp(ω|C) ω c(ω;d)+µ µ ABS p δ (ω|d) = max(c(ω;d)-δ,0) ω c(ω;d) + δ|d| µ δp(ω|C) δ|d|µ |d| δ</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,202.59,711.38,310.44,10.46;4,90.00,723.34,61.44,10.46"><head></head><label></label><figDesc>Figure 1. shows a query example of images, title and narrative texts in the campaign.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,246.90,120.45,24.54,9.19;5,246.90,144.97,111.40,9.19;5,246.90,169.57,151.72,9.19;5,246.90,194.09,193.05,9.19;5,246.90,206.31,207.40,9.19;5,246.90,218.61,217.89,9.19;5,246.90,230.91,197.23,9.19;5,246.90,243.13,221.30,9.19;5,246.90,255.43,216.71,9.19;5,246.90,267.74,68.85,9.19;5,246.90,292.26,27.45,9.19"><head></head><label></label><figDesc>&lt;top&gt; &lt;num&gt; Number: 1 &lt;/num&gt; &lt;title&gt; aircraft on the ground &lt;/title&gt; &lt;narr&gt; Relevant images will show one or more airplanes positioned on the ground. Aircraft do not have to be the focus of the picture, although it should be possible to make out that the picture contains aircraft. Pictures of aircraft flying are not relevant and pictures of any other flying object (e.g. birds) are not relevant. &lt;/narr&gt; &lt;/top&gt;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,164.62,316.99,273.78,10.46;5,132.61,236.22,94.42,66.25"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: A query example in the ImageCLEF 2005 campaign.</figDesc><graphic coords="5,132.61,236.22,94.42,66.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="5,122.24,737.22,358.57,10.46"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Experimental Result of Precision vs. Recall with Selected Configuration</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="7,90.00,399.65,423.05,10.46;7,90.00,411.60,59.83,10.46"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Experimental Result of Precision vs. Number of Returned Documents with Selected Configuration</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="8,137.66,403.08,327.72,10.46"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Chinese segmentation results of part Chinese (Simplified) queries</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,127.75,380.83,347.56,71.68"><head>Table 1 :</head><label>1</label><figDesc>Summary of three primary smoothing methods used in our submission</figDesc><table coords="4,131.42,404.09,339.23,48.42"><row><cell>Method</cell><cell>p s (ω|d)</cell><cell>α d</cell><cell>parameter</cell></row><row><cell>JM DIR</cell><cell>(1 -λ)p ml (ω|d) + λp(ω|C) c(ω;d)+µp(ω|C)</cell><cell>λ</cell><cell>λ</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,104.74,172.78,390.91,476.46"><head>Table 2 :</head><label>2</label><figDesc>The configurations and testing results of our submission</figDesc><table coords="6,104.74,196.03,390.91,453.20"><row><cell>Run ID</cell><cell>Language</cell><cell>QE</cell><cell>Modality</cell><cell>Method</cell><cell>MAP</cell></row><row><cell>CUHK-ad-eng-t-kl-ab1</cell><cell>english</cell><cell>without</cell><cell>text</cell><cell>KL-LM-ABS</cell><cell>0.3887</cell></row><row><cell>CUHK-ad-eng-t-kl-ab2</cell><cell>english</cell><cell>with</cell><cell>text</cell><cell>KL-LM-ABS</cell><cell>0.4055</cell></row><row><cell>CUHK-ad-eng-t-kl-ab3</cell><cell>english</cell><cell>with</cell><cell>text</cell><cell>KL-LM-ABS</cell><cell>0.4082</cell></row><row><cell>CUHK-ad-eng-t-kl-jm1</cell><cell>english</cell><cell>without</cell><cell>text</cell><cell>KL-LM-JM</cell><cell>0.3844</cell></row><row><cell>CUHK-ad-eng-t-kl-jm2</cell><cell>english</cell><cell>with</cell><cell>text</cell><cell>KL-LM-JM</cell><cell>0.4115</cell></row><row><cell>CUHK-ad-eng-t-kl-di1</cell><cell>english</cell><cell>without</cell><cell>text</cell><cell>KL-LM-DIR</cell><cell>0.382</cell></row><row><cell>CUHK-ad-eng-t-kl-di2</cell><cell>english</cell><cell>with</cell><cell>text</cell><cell>KL-LM-DIR</cell><cell>0.3999</cell></row><row><cell>CUHK-ad-eng-t-tf-idf1</cell><cell>english</cell><cell>without</cell><cell>text</cell><cell>TF-IDF</cell><cell>0.351</cell></row><row><cell>CUHK-ad-eng-t-tf-idf2</cell><cell>english</cell><cell>with</cell><cell>text</cell><cell>TF-IDF</cell><cell>0.3574</cell></row><row><cell>CUHK-ad-eng-tn-kl-ab1</cell><cell>english</cell><cell>without</cell><cell>text</cell><cell>KL-LM-ABS</cell><cell>0.3877</cell></row><row><cell>CUHK-ad-eng-tn-kl-ab2</cell><cell>english</cell><cell>with</cell><cell>text</cell><cell>KL-LM-ABS</cell><cell>0.3838</cell></row><row><cell>CUHK-ad-eng-tn-kl-ab3</cell><cell>english</cell><cell>with</cell><cell>text</cell><cell>KL-LM-ABS</cell><cell>0.4083</cell></row><row><cell>CUHK-ad-eng-tn-kl-jm1</cell><cell>english</cell><cell>without</cell><cell>text</cell><cell>KL-LM-JM</cell><cell>0.3762</cell></row><row><cell>CUHK-ad-eng-tn-kl-jm2</cell><cell>english</cell><cell>with</cell><cell>text</cell><cell>KL-LM-JM</cell><cell>0.4018</cell></row><row><cell>CUHK-ad-eng-tn-kl-di1</cell><cell>english</cell><cell>without</cell><cell>text</cell><cell>KL-LM-DIR</cell><cell>0.3921</cell></row><row><cell>CUHK-ad-eng-tn-kl-di2</cell><cell>english</cell><cell>with</cell><cell>text</cell><cell>KL-LM-DIR</cell><cell>0.399</cell></row><row><cell>CUHK-ad-eng-tn-tf-idf1</cell><cell>english</cell><cell>without</cell><cell>text</cell><cell>TF-IDF</cell><cell>0.3475</cell></row><row><cell>CUHK-ad-eng-tn-tf-idf2</cell><cell>english</cell><cell>with</cell><cell>text</cell><cell>TF-IDF</cell><cell>0.366</cell></row><row><cell>CUHK-ad-eng-v</cell><cell>english</cell><cell>without</cell><cell>vis</cell><cell>Moment-DCT</cell><cell>0.0599</cell></row><row><cell>CUHK-ad-eng-tv-kl-ab1</cell><cell>english</cell><cell>without</cell><cell>text+vis</cell><cell>KL-LM-ABS</cell><cell>0.3941</cell></row><row><cell>CUHK-ad-eng-tv-kl-ab3</cell><cell>english</cell><cell>with</cell><cell>text+vis</cell><cell>KL-LM-ABS</cell><cell>0.4108</cell></row><row><cell>CUHK-ad-eng-tv-kl-jm1</cell><cell>english</cell><cell>without</cell><cell>text+vis</cell><cell>KL-LM-JM</cell><cell>0.3878</cell></row><row><cell>CUHK-ad-eng-tv-kl-jm2</cell><cell>english</cell><cell>with</cell><cell>text+vis</cell><cell>KL-LM-JM</cell><cell>0.4135</cell></row><row><cell>CUHK-ad-eng-tnv-kl-ab2</cell><cell>english</cell><cell>with</cell><cell>text+vis</cell><cell>KL-LM-ABS</cell><cell>0.3864</cell></row><row><cell>CUHK-ad-eng-tnv-kl-ab3</cell><cell>english</cell><cell>with</cell><cell>text+vis</cell><cell>KL-LM-ABS</cell><cell>0.4118</cell></row><row><cell>CUHK-ad-eng-tnv-kl-jm1</cell><cell>english</cell><cell>without</cell><cell>text+vis</cell><cell>KL-LM-JM</cell><cell>0.3787</cell></row><row><cell>CUHK-ad-eng-tnv-kl-jm2</cell><cell>english</cell><cell>with</cell><cell>text+vis</cell><cell>KL-LM-JM</cell><cell>0.4041</cell></row><row><cell>CUHK-ad-chn-t-kl-ab1</cell><cell>chinese</cell><cell>without</cell><cell>text</cell><cell>KL-LM-ABS</cell><cell>0.1815</cell></row><row><cell>CUHK-ad-chn-t-kl-ab2</cell><cell>chinese</cell><cell>with</cell><cell>text</cell><cell>KL-LM-ABS</cell><cell>0.1842</cell></row><row><cell>CUHK-ad-chn-t-kl-jm1</cell><cell>chinese</cell><cell>without</cell><cell>text</cell><cell>KL-LM-JM</cell><cell>0.1821</cell></row><row><cell>CUHK-ad-chn-t-kl-jm2</cell><cell>chinese</cell><cell>with</cell><cell>text</cell><cell>KL-LM-JM</cell><cell>0.2027</cell></row><row><cell>CUHK-ad-chn-tn-kl-ab1</cell><cell>chinese</cell><cell>without</cell><cell>text</cell><cell>KL-LM-ABS</cell><cell>0.1758</cell></row><row><cell>CUHK-ad-chn-tn-kl-ab2</cell><cell>chinese</cell><cell>with</cell><cell>text</cell><cell>KL-LM-ABS</cell><cell>0.1527</cell></row><row><cell>CUHK-ad-chn-tn-kl-ab3</cell><cell>chinese</cell><cell>with</cell><cell>text</cell><cell>KL-LM-ABS</cell><cell>0.1834</cell></row><row><cell>CUHK-ad-chn-tn-kl-jm1</cell><cell>chinese</cell><cell>without</cell><cell>text</cell><cell>KL-LM-JM</cell><cell>0.1843</cell></row><row><cell>CUHK-ad-chn-tn-kl-jm2</cell><cell>chinese</cell><cell>with</cell><cell>text</cell><cell>KL-LM-JM</cell><cell>0.2024</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="7,105.24,745.67,306.18,8.37"><p>It can be downloaded from: http://www.ldc.upenn.edu/Projects/Chinese/seg.zip .</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="8,105.24,710.32,407.63,8.37;8,90.00,719.79,52.03,8.37"><p>Query expansion refers to adding further terms to a text query (e.g. through PRF or thesaurus) or images to a visual query</p></note>
		</body>
		<back>

			<div type="funding">
<div> *   <p>The work described in this paper was fully supported by two grants: <rs type="funder">Innovation and Technology Fund</rs> <rs type="grantNumber">ITS/105/03</rs>, and the <rs type="grantName">Research Grants Council Earmarked Grant</rs> <rs type="grantNumber">CUHK4205/04E</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Kjr75tk">
					<idno type="grant-number">ITS/105/03</idno>
					<orgName type="grant-name">Research Grants Council Earmarked Grant</orgName>
				</org>
				<org type="funding" xml:id="_pFffnDS">
					<idno type="grant-number">CUHK4205/04E</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="9,110.48,298.53,402.54,10.46;9,110.48,310.48,58.16,10.46" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="9,333.75,298.53,131.60,10.46">Modern Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Ricardo</forename><surname>Baeza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">-</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Berthier</forename><surname>Ribeiro-Neto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>Addison Wesley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,330.41,402.59,10.46;9,110.48,342.36,402.55,10.46;9,110.48,354.32,134.01,10.46" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,310.76,330.41,202.32,10.46;9,110.48,342.36,48.64,10.46">The clef cross language image retrieval track (imageclef)</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,213.95,342.36,299.08,10.46;9,110.48,354.32,59.98,10.46">the Fifth Workshop of the Cross-Language Evaluation Forum (CLEF 2004) (LNCS)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,374.24,344.84,10.46" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="9,253.76,374.24,138.98,10.46">Elements of Information Theory</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991">1991</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,394.17,402.52,10.46;9,110.48,406.12,74.99,10.46" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="9,243.91,394.17,241.21,10.46">Foundations of Statistical Natural Language Processing</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>The MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,426.05,402.52,10.46;9,110.48,438.00,80.86,10.46" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,152.28,426.05,287.45,10.46">Report on clef-2001 experiments (cross language evaluation forum)</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,460.25,426.05,26.38,10.46">LNCS</title>
		<imprint>
			<biblScope unit="volume">2406</biblScope>
			<biblScope unit="page" from="27" to="43" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,457.93,402.52,10.46;9,110.48,469.88,22.70,10.46" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,183.37,457.93,180.52,10.46">Prediction and entropy of printed english</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">E</forename><surname>Shannon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,373.44,457.93,91.09,10.46">Bell Sys. Tech. Jour</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="51" to="64" />
			<date type="published" when="1951">1951</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,489.81,402.63,10.46;9,110.48,501.76,402.51,10.46;9,110.48,513.72,159.56,10.46" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,421.46,489.81,91.65,10.46;9,110.48,501.76,160.69,10.46">Content-based image retrieval at the end of the early years</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">W M</forename><surname>Smeulders</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Worring</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Santini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,279.60,501.76,233.39,10.46;9,110.48,513.72,48.17,10.46">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1349" to="1380" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,533.64,402.59,10.46;9,110.48,545.60,402.53,10.46;9,110.48,557.55,153.00,10.46" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,282.30,533.64,230.77,10.46;9,110.48,545.60,24.21,10.46">Model-based feedback in the kl-divergence retrieval model</title>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,173.01,545.60,340.01,10.46;9,110.48,557.55,53.50,10.46">Tenth International Conference on Information and Knowledge Management (CIKM2001)</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="403" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,577.48,402.58,10.46;9,110.48,589.43,402.53,10.46;9,110.48,601.39,292.09,10.46" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,279.96,577.48,233.10,10.46;9,110.48,589.43,168.51,10.46">A study of smoothing methods for language models applied to ad hoc information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,299.94,589.43,213.07,10.46;9,110.48,601.39,193.19,10.46">ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR&apos;01)</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="334" to="342" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
