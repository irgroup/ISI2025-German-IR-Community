<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,187.52,148.86,227.97,15.15;1,98.74,170.78,405.53,15.15;1,174.41,192.69,254.20,15.15">FIRE in ImageCLEF 2005: Combining Content-based Image Retrieval with Textual Information Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,101.61,226.59,77.10,8.74"><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Lehrstuhl für Informatik VI</orgName>
								<orgName type="institution">RWTH Aachen University</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,186.35,226.59,64.14,8.74"><forename type="first">Tobias</forename><surname>Weyand</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Lehrstuhl für Informatik VI</orgName>
								<orgName type="institution">RWTH Aachen University</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,259.19,226.59,63.26,8.74"><forename type="first">Daniel</forename><surname>Keysers</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Lehrstuhl für Informatik VI</orgName>
								<orgName type="institution">RWTH Aachen University</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,330.31,226.59,82.89,8.74"><forename type="first">Wolfgang</forename><surname>Macherey</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Lehrstuhl für Informatik VI</orgName>
								<orgName type="institution">RWTH Aachen University</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,440.76,226.59,60.63,8.74"><forename type="first">Hermann</forename><surname>Ney</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Lehrstuhl für Informatik VI</orgName>
								<orgName type="institution">RWTH Aachen University</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,187.52,148.86,227.97,15.15;1,98.74,170.78,405.53,15.15;1,174.41,192.69,254.20,15.15">FIRE in ImageCLEF 2005: Combining Content-based Image Retrieval with Textual Information Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B776867B05089D0B930959AF68D39681</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.3 Information Search and Retrieval I.5 [Pattern Recognition]: I.5.4 Applications content-based image retrieval</term>
					<term>object recognition</term>
					<term>textual information retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe the methods we used in the 2005 ImageCLEF content-based image retrieval evaluation. For the medical retrieval task, we combined several low-level image features with textual information retrieval. Combining these two information sources, clear improvements over using one of these sources alone are possible.</p><p>Additionally we participated in the automatic annotation task, where we used FIRE, our content-based image retrieval system, on the one hand and a subimage based method for object classification on the other hand.</p><p>The results achieved are very good. In particular, we obtained the first and the third rank in the automatic annotation task out of 44 submissions from 12 groups.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>It is known that in content-based image retrieval (CBIR) benchmarking of systems is a major problem. ImageCLEF, as part of the Cross language evaluation forum, is one major step in the direction of creating standard benchmarking tasks and setting up competitions to compare content-based image retrieval systems. One of the main conclusions that can be drawn from the 2004 ImageCLEF image retrieval evaluation is that textual information and user feedback can strongly improve the results if available. Especially if the queries are of semantic nature it is intrinsically difficult to solve them using visual information alone.</p><p>Especially in real life applications, as e.g. in medicine, where textual information is available and pictures alone are not sufficient to describe a medical case, any information available should be used. If, for example, the query image is a microscopic photo of a bacteria culture, a standard image retrieval system will easily find other pictures of bacteria cultures, but it will hardly be able to distinguish between different kinds of bacteria. With additional, textual query information, like "E. Coli bacteria", the query, and thus the result, is more precise.</p><p>As we obtained the best score in the category "visual information only, no user interaction" in the 2004 ImageCLEF evaluation, it was an interesting challenge to extend our FIRE system 1 towards using textual information.</p><p>Other groups already proposed their approaches of combining textual information retrieval and content-based image retrieval, e.g. <ref type="bibr" coords="2,242.04,135.93,15.50,8.74" target="#b21">[22,</ref><ref type="bibr" coords="2,260.86,135.93,12.73,8.74" target="#b18">19,</ref><ref type="bibr" coords="2,276.91,135.93,7.75,8.74" target="#b0">1,</ref><ref type="bibr" coords="2,287.98,135.93,11.63,8.74" target="#b27">28]</ref>.</p><p>In this paper, we describe the techniques we used for the 2005 ImageCLEF evaluation, in particular how we combine textual information retrieval and content-based image retrieval.</p><p>In 2005 ImageCLEF, four tasks were available: a) automatic annotation, b) medical image retrieval, c) bilingual information retrieval, and d) interactive retrieval. We participated in the automatic annotation task and the medical image retrieval task. Our approach to the medical retrieval task is described in Section 2, the two approaches to the automatic annotation task are described in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Medical Retrieval Task</head><p>For the medical retrieval task in the 2005 ImageCLEF Image Retrieval Evaluation, 25 queries were given. Each query was defined by a short textual query description and one to three example images. One query contained a negative example image, all other example images were positive. A more detailed description of the task and an overview on the results can be found in <ref type="bibr" coords="2,469.26,310.11,9.96,8.74" target="#b2">[3]</ref>. In the following we describe our setup of FIRE for the medical retrieval task in the 2005 ImageCLEF Image Retrieval Evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Decision Rule</head><p>Given a set of positive example images Q + and a (possibly empty) set of negative example images Q -a score S(Q + , Q -, X) is calculated for each image X from the database:</p><formula xml:id="formula_0" coords="2,179.43,413.15,224.21,22.68">S(Q + , Q -, X) = q∈Q + S(q, X) + q∈Q - (1 -S(q, X)).</formula><p>(</p><formula xml:id="formula_1" coords="2,504.51,415.22,8.49,8.74">)<label>1</label></formula><p>where S(q, X) is the score of database image X with respect to query q and is calculated as S(q, X) = e -γD(q,X) with γ = 1.0. D(q, X) is a weighted sum of distances calculated as</p><formula xml:id="formula_2" coords="2,218.12,480.06,294.88,30.20">D(q, X) := M m=1 w m • d m (q m , X m ).<label>(2)</label></formula><p>Here, q m and X m are the mth feature of the query image q and the database image X, respectively. d m is the corresponding distance measure and w m is a weighting coefficient. For each d m ,</p><formula xml:id="formula_3" coords="2,100.52,544.09,235.49,11.15">X∈B d m (Q m , X m ) = 1 is enforced by re-normalization.</formula><p>Given a query (Q + , Q -), the images are ranked according to descending score and the K images X with highest scores S(Q + , Q -, X) are returned by the retriever.</p><p>Due to the lack of suitable training data, weights w m were chosen heuristically based on experiences from earlier experiments with other data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Textual Information Retrieval</head><p>To incorporate textual information in FIRE, we decided to use an existing textual information retrieval engine <ref type="bibr" coords="2,160.07,650.00,14.62,8.74" target="#b19">[20]</ref>.</p><p>To incorporate textual information in FIRE, we decided to use an existing textual information retrieval engine that was developed at Lehrstuhl für Informatik VI. The text retrieval engine implements a variant of the Smart-2 retrieval metric, which is based on the well-known term frequency inverse document frequency (tf-idf) metric. First, the textual information is preprocessed by removing function words that are considered to be of no importance for the actual retrieval process (so called stopping). The stop word list used for this purpose comprises 319 of the most frequently occurring function words in the English language. Subsequent to the stopping process, the remaining words are reduced to their stems using Porter's stemming algorithm <ref type="bibr" coords="2,469.39,745.64,14.61,8.74" target="#b22">[23]</ref>. The stemmed words form the index terms that are used in order to index the text documents provided with the image data. In our implementation of the Smart-2 retrieval metric we use the following definition of the inverse document frequency:</p><formula xml:id="formula_4" coords="3,249.23,153.27,263.77,22.31">idf(t) := log K n(t)<label>(3)</label></formula><p>Here, t denotes an index term, and K is the number of text documents. Due to the floor operation in Eq. ( <ref type="formula" coords="3,124.42,196.04,4.24,8.74" target="#formula_4">3</ref>) a term weight will be zero if it occurs in more than half of the documents. According to <ref type="bibr" coords="3,102.19,208.00,9.96,8.74" target="#b1">[2]</ref>, each index term t in a document d is associated with a weight g(t, d) that depends on the ratio of the logarithm of the term frequency n(t, d) to the logarithm of the average term frequency n(d)</p><formula xml:id="formula_5" coords="3,172.71,250.90,340.30,25.87">g(t, d) := 1 + log n(t, d) 1 + log n(d) if t ∈ d 0 if t / ∈ d<label>(4)</label></formula><p>with log 0 := 0 and</p><formula xml:id="formula_6" coords="3,249.87,296.97,263.13,25.41">n(d) = t∈T n(t, d) t∈T :n(t,d)&gt;0 1 (5)</formula><p>The logarithms in Eq. ( <ref type="formula" coords="3,194.81,328.46,4.24,8.74" target="#formula_5">4</ref>) prevent documents with high term frequencies from dominating those with low term frequencies. In order to obtain the final term weights, g(t, d) is divided by a linear combination between a pivot element c and the number of singletons n 1 (d) in document d:</p><formula xml:id="formula_7" coords="3,231.94,370.00,281.06,23.26">ω(t, d) := g(t, d) (1 -λ) • c + λ • n 1 (d)<label>(6)</label></formula><p>with λ = 0.2 and</p><formula xml:id="formula_8" coords="3,204.83,409.51,308.16,30.94">c = 1 K K k=1 n 1 (d k ) and n 1 (d) := t∈T :n(t,d)=1 1<label>(7)</label></formula><p>Unlike tf-idf, only query terms are weighted with the inverse document frequency idf(t):</p><formula xml:id="formula_9" coords="3,231.83,466.14,281.17,8.77">ω(t, q) = 1 + log n(t, q) • idf(t)<label>(8)</label></formula><p>The Smart-2 retrieval function is then defined as the product over the document and query specific index term weights:</p><formula xml:id="formula_10" coords="3,239.26,510.14,273.75,20.09">f (q, d) = t∈T ω(t, q) • ω(t, d)<label>(9)</label></formula><p>To use the textual information for image retrieval, each image has to be attached to at least one (possibly empty) text document. These text documents are used in the above described image retrieval process. To determine the distance d text (q m , X m ) between a query image q with query text q m and a database image X with attached text X m , first the textual information retriever is queried using the query text. Then, the textual information retriever returns the list of all relevant documents from the database. These documents are ranked by the retrieval status values (RSV) R which is is high for documents similar to the query and low for dissimilar documents. The distance d(q m , X m ) is then calculated as</p><formula xml:id="formula_11" coords="3,128.87,640.05,379.71,23.08">d text (q m , X m ) = R max -R X if X is in the list of relevant documents ρ otherwise (<label>10</label></formula><formula xml:id="formula_12" coords="3,508.57,646.85,4.43,8.74">)</formula><p>where R max is the maximum of all returned RSVs, R X is the RSV attached to image X, q m and X m are the query text and the text attached to image X, respectively, and ρ is a constant chosen sufficiently large to make sure that images whose texts do not appear in the list of relevant objects have high distances. Note, the case where ρ = R max corresponds to assigning RSV of 0 to all non-relevant texts.</p><p>The resulting distances d text (q m , X m ) are used in the retrieval process described in the previous section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Image Features</head><p>In the following we describe the image features we used in the evaluation, these features are extracted offline from all database images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Appearance-based Image Features</head><p>The most straight-forward approach is to directly use the pixel values of the images as features. For example, the images might be scaled to a common size and compared using the Euclidean distance. In optical character recognition and for medical data improved methods based on image features usually obtain excellent results <ref type="bibr" coords="4,265.17,222.52,15.50,8.74" target="#b14">[15,</ref><ref type="bibr" coords="4,283.99,222.52,12.73,8.74" target="#b15">16,</ref><ref type="bibr" coords="4,300.04,222.52,11.63,8.74" target="#b16">17]</ref>.</p><p>In this work, we used 32 × 32 versions of the images, these were compared using Euclidean distance. It has been observed, that for classification and retrieval of medical radiographs, this method saves as a not-top-bad baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Color Histograms</head><p>Color histograms are widely used in image retrieval <ref type="bibr" coords="4,321.68,302.67,10.52,8.74" target="#b3">[4,</ref><ref type="bibr" coords="4,336.01,302.67,12.73,8.74" target="#b9">10,</ref><ref type="bibr" coords="4,352.54,302.67,12.73,8.74" target="#b23">24,</ref><ref type="bibr" coords="4,369.08,302.67,11.63,8.74" target="#b25">26]</ref>. Color histograms are one of the most basic approaches and to show performance improvements, image retrieval systems often are compared to a system using only color histograms. The color space is partitioned and for each partition the pixels with a color within its range are counted, resulting in a representation of the relative frequencies of the occurring colors. In accordance with <ref type="bibr" coords="4,365.65,350.49,14.61,8.74" target="#b23">[24]</ref>, we use the Jeffrey divergence to compare histograms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">Tamura Features</head><p>In <ref type="bibr" coords="4,101.94,406.73,15.50,8.74" target="#b26">[27]</ref> the authors propose six texture features corresponding to human visual perception: coarseness, contrast, directionality, line-likeness, regularity, and roughness. From experiments testing the significance of these features with respect to human perception, it was concluded that the first three features are very important. Thus in our experiments we use coarseness, contrast, and directionality to create a histogram describing the texture <ref type="bibr" coords="4,343.10,454.55,10.52,8.74" target="#b3">[4]</ref> and compare these histograms using the Jeffrey divergence <ref type="bibr" coords="4,187.31,466.50,14.62,8.74" target="#b23">[24]</ref>. In the QBIC system <ref type="bibr" coords="4,300.36,466.50,15.50,8.74" target="#b9">[10]</ref> histograms of these features are used as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.4">Global Texture Descriptor</head><p>In <ref type="bibr" coords="4,102.99,510.79,10.52,8.74" target="#b3">[4]</ref> a texture feature consisting of several parts is described: Fractal dimension measures the roughness or the crinkliness of a surface. In this work the fractal dimension is calculated using the reticular cell counting method <ref type="bibr" coords="4,223.09,534.70,14.61,8.74" target="#b12">[13]</ref>. Coarseness characterizes the grain size of an image. Here it is calculated depending on the variance of the image. Entropy is used as a measure of disorderedness or information content in an image. The Spatial gray-level difference statistics (SGLD) describes the brightness relationship of pixels within neighborhoods. It is also known as co-occurrence matrix analysis <ref type="bibr" coords="4,161.09,582.52,14.62,8.74" target="#b13">[14]</ref>. . The Circular Moran autocorrelation function measures the roughness of the texture. For the calculation a set of autocorrelation functions is used <ref type="bibr" coords="4,411.49,594.47,14.61,8.74" target="#b11">[12]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.5">Invariant Feature Histograms</head><p>A feature is called invariant with respect to certain transformations if it does not change when these transformations are applied to the image. The transformations considered here are translation, rotation, and scaling. In this work, invariant feature histograms as presented in <ref type="bibr" coords="4,480.29,662.67,15.50,8.74" target="#b24">[25]</ref> are used. These features are based on the idea of constructing features invariant with respect to certain transformations by integration over all considered transformations. The resulting histograms are compared using the Jeffrey divergence <ref type="bibr" coords="4,277.72,698.54,14.61,8.74" target="#b23">[24]</ref>. Previous experiments have shown that the characteristics of invariant feature histograms and color histograms are very similar and that invariant feature histograms often outperform color histograms <ref type="bibr" coords="4,324.93,722.45,9.96,8.74" target="#b4">[5]</ref>. Thus, in this work color histograms are not used. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Automatic Annotation Task</head><p>In the automatic annotation task, the objective was to classify 1,000 images into one of 57 classes using 9,000 training images. We participated in this using two different methods. Method A is identical to the approach we have chosen for the medical retrieval task, except that here no textual information was available, and that we used appearance-based image features and Tamura Texture Features only, as we know from earlier experiments that these features perform good on medical radiographs <ref type="bibr" coords="5,144.36,282.37,14.61,8.74" target="#b17">[18]</ref>. Method B is a general object recognition method using histograms of image patches and discriminative training of log-linear models <ref type="bibr" coords="5,280.59,306.28,10.51,8.74" target="#b5">[6,</ref><ref type="bibr" coords="5,294.43,306.28,7.01,8.74" target="#b6">7]</ref>.</p><p>The parameters of method A were optimized using 1,000 images from the 9,000 training images as development set and the remaining 8,000 images for training. The parameters of method B were chosen as they work best on the Caltech Database <ref type="bibr" coords="5,336.16,342.15,15.50,8.74" target="#b10">[11,</ref><ref type="bibr" coords="5,354.98,342.15,7.75,8.74" target="#b7">8,</ref><ref type="bibr" coords="5,366.04,342.15,7.01,8.74" target="#b6">7]</ref>.</p><p>A more detailed description of the task and a detailed analysis of the results can be found in <ref type="bibr" coords="5,101.63,366.06,9.96,8.74" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Method A: Image Distortion Model</head><p>Method A uses our CBIR system FIRE, and a subset of the above described features consisting of thumbnails of the images of the sizes 32×32 and X × 32 and Tamura Texture Histograms. Error rates for using these features alone are given in Table <ref type="table" coords="5,326.39,436.25,3.88,8.74" target="#tab_0">1</ref>.</p><p>Some experiments with different weightings of Tamura features and thumbnails on our development corpus have shown that using the image distortion model alone outperforms the combinations. In particular the combination of image distortion model (weighted 5) and Tamura texture features (weighted 2) is interesting, as this performed best in previous experiments on smaller versions of the IRMA database <ref type="bibr" coords="5,230.94,496.02,14.62,8.74" target="#b17">[18]</ref>. In our experiments, this combination yielded an error rate of 13.5% on the development corpus, and it achieves a very good error rate of 13.2% on the test data. Based on these results we decided to use the image distortion model for our submission.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Method B: Object Recognition with Subimages and Discriminative Training</head><p>For method B we used the object recognition and classification approach using histograms of image patches and maximum Entropy training to classify the 1000 test images as described in <ref type="bibr" coords="5,475.00,592.11,10.51,8.74" target="#b5">[6,</ref><ref type="bibr" coords="5,488.84,592.11,7.01,8.74" target="#b6">7]</ref>.</p><p>To reduce the time and memory requirements for the clustering process, we used only 4000 images for estimating the Gaussian mixture model and created the histograms for the remaining 5000 training images using this mixture model. For the discriminative training of the log-linear model, we used all training histograms.</p><p>The model submitted used multi-scale features where the first PCA component was discarded to account for brightness changes and 4096-dimensional histograms. This combination was reported to work best on the Caltech database <ref type="bibr" coords="5,251.79,675.80,15.50,8.74" target="#b10">[11]</ref> and in the PASCAL Visual Object Classes Challenge <ref type="bibr" coords="5,499.71,675.80,9.97,8.74" target="#b8">[9]</ref>. The model achieved an error rate of 13.9% and thus is slightly better than the model by Raphaël Marée who follows a similar approach <ref type="bibr" coords="5,257.90,699.71,14.61,8.74" target="#b20">[21]</ref>.</p><p>In the following we describe the exact setup of the submitted runs to the automatic annotation task and the medical retrieval task and discuss the results. Furthermore, we discuss our methods, points to errors we made, and present results with errors corrected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Automatic Annotation Task</head><p>Our submission using model A obtained the first rank in the automatic annotation task. The submission following the object recognition approach obtained the third rank. In total, 44 runs were submitted by 12 groups. The second rank was obtained by the IRMA group<ref type="foot" coords="6,442.28,225.61,3.97,6.12" target="#foot_1">2</ref> using a similar approach to our model A and the fourth rank was obtained by University of Liège, Belgium using an approach with image patches and boosted decision trees. A clear improvement over the baseline result of 36.8% error rate cam be observed. This baseline results is obtained by a nearest neighbor classifier using 32x32 thumbnails of the images and Euclidean distance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Medical Retrieval Task</head><p>For the medical retrieval task, we used the features described in Section 2.3 with different weightings in combination with text features. In total, we submitted 10 runs which are shortly described here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Runs using textual information only:</head><p>We submitted two full-automatic runs, where only textual information was used. These runs were labelled En and EnDeFr. In En only the English texts were used, for EnDeFr the English, the German, and the French texts were used and combined with equal weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Runs using visual information only:</head><p>We submitted three full-automatic runs, where only visual information was used. The runs 5000215, 0010003, and 1010111 only differ in the weighting of the image features. The exact weightings can be seen in Table <ref type="table" coords="6,461.37,439.94,3.88,8.74">2</ref>. The run labelled 5000215 uses exactly the same setting as our submission to the 2004 ImageCLEF evaluation which had the best score from all 23 submissions in the category "visual features only, no user interaction". From the bad score of 0.06, it can be seen that this years tasks differ strongly from last year's task.</p><p>Runs using visual and textual information: We submitted three full-automatic runs and two runs with relevance feedback where textual and visual information was used. For the run i6-3010210111, the features were combined in exactly the way described above. For the runs i6-3(1010111-min(111)) and i6-3(3030333)-min(111) before combining the textand the visual features, first the minimum distance of all three text distances was taken for each image, to better account for images that have texts in one language only.</p><p>The runs i6-vistex-rfb1 and i6-vistex-rfb2 used relevance feedback from the first 20 results of the automatic run i6-3(1010111-min(111)) and differ only in the user feedback.</p><p>In both cases the feedback was given by a computer scientist familiar to the FIRE system with little background in medicine. Furthermore, the textual information was not available for the user feedback, thus the feedback is based on visual information only.</p><p>Table <ref type="table" coords="6,131.63,646.14,4.98,8.74">2</ref> gives an overview of all runs we submitted to the medical retrieval runs. Unfortunately, in advance to the competition we were unable to test our combination of textual-and visual information retrieval, which led to a very unlucky choice of ρ in Eq. 10, such that any combination with textual information retrieval was strongly disturbed. Furthermore Table <ref type="table" coords="6,438.56,682.00,4.98,8.74">2</ref> gives results of experiments we performed after the evaluation where ρ was chosen properly and it can clearly be seen that the results are much better. In particular, using English textual information retrieval only we could reach a MAP of 0.25 which would have been a third rank in the 2005 ImageCLEF evaluation in the category "textual and visual information, no relevance feedback".</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,104.02,118.94,394.97,56.70"><head>Table 1 :</head><label>1</label><figDesc>Error rates obtained using different features on the IRMA 10000 Validation data.</figDesc><table coords="5,156.59,130.64,286.50,45.00"><row><cell>feature</cell><cell>distance</cell><cell cols="2">dev corpus test corpus</cell></row><row><cell>32×32 thumbnails</cell><cell>Euclidean</cell><cell>25.3</cell><cell>36.8</cell></row><row><cell>X×32 thumbnails</cell><cell>IDM</cell><cell>13.0</cell><cell>12.6</cell></row><row><cell cols="2">tamura texture histogram JSD</cell><cell>33.1</cell><cell>46.0</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,105.24,746.31,256.57,7.91"><p>http://www-i6.informatik.rwth-aachen.de/ ∼ deselaers/fire.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="6,105.24,747.58,114.82,6.64"><p>http://www.irma-project.org</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Table <ref type="table" coords="7,119.11,118.94,3.88,8.74">2</ref>: Runs submitted to the medical retrieval task together with feature weightings and achieved MAP with wrongly chosen ρ and with properly chosen ρ. * means that the minimum among all lines marked with * in this column was taken and weighted by 1.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion and Outlook</head><p>In this paper we presented the methods we used in the 2005 ImageCLEF CBIR evaluation. We participated in the automatic annotation task, where we obtained the first and the third rank, and we participated in the medical image retrieval task, where our results were quite bad due to wrong settings, results with correct settings are presented in this work, and it can be seen that the method of combining textual information retrieval and content-based image retrieval performs very well. In particular, the result obtained would have been ranked 3rd in the medical retrieval task in the category "full automatic runs using textual and visual information".</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="7,110.48,538.22,402.52,8.74;7,110.48,550.18,402.53,8.74;7,110.48,562.13,402.52,8.74;7,110.48,574.09,333.01,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,386.29,538.22,126.71,8.74;7,110.48,550.18,125.79,8.74;7,259.30,550.18,253.71,8.74;7,110.48,562.13,17.11,8.74">Multilingual Information Access for Text, Speech and Images</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Alvarez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">I</forename><surname>Oumohmed</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mignotte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-Y</forename><surname>Nie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,134.91,562.13,373.47,8.74">Proceedings of the 5th Workshop of the Cross-Language Evaluation Forum. CLEF 2004</title>
		<meeting>the 5th Workshop of the Cross-Language Evaluation Forum. CLEF 2004<address><addrLine>Bath, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004-09">September 2004</date>
			<biblScope unit="volume">3491</biblScope>
			<biblScope unit="page" from="676" to="687" />
		</imprint>
	</monogr>
	<note>Toward Cross-Language and Cross-Media Image Retrieval</note>
</biblStruct>

<biblStruct coords="7,110.48,593.07,402.51,8.74;7,110.48,605.02,402.52,8.74;7,110.48,616.98,402.52,8.74;7,110.48,628.93,133.36,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,210.06,605.02,237.31,8.74">An Overview of the AT&amp;T Spoken Document Retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hindle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hirschberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Magrin-Changnolleau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Nakatani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pereira</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Singhal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Whittaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,466.93,605.02,46.08,8.74;7,110.48,616.98,299.34,8.74">Proc. 1998 DARPA Broadcast News Transcription and Understanding Workshop</title>
		<meeting>1998 DARPA Broadcast News Transcription and Understanding Workshop<address><addrLine>Lansdowne, Va, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998-02">February 1998</date>
			<biblScope unit="page" from="182" to="188" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,647.91,402.52,8.74;7,110.48,659.87,402.52,8.74;7,110.48,671.82,137.10,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,465.81,647.91,47.19,8.74;7,110.48,659.87,192.56,8.74">The CLEF 2005 Cross-Language Image Retrieval Track</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mueller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,326.58,659.87,164.64,8.74">CLEF 2005 Workshop Working notes</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-09">September 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,690.80,402.52,8.74;7,110.48,702.76,272.25,8.74" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="7,175.35,690.80,125.70,8.74">Features for Image Retrieval</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003-12">December 2003</date>
			<pubPlace>Aachen, Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Lehrstuhl für Informatik VI, RWTH Aachen University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Diploma thesis</note>
</biblStruct>

<biblStruct coords="7,110.48,721.73,402.51,8.74;7,110.48,733.69,402.52,8.74;7,110.48,745.64,232.93,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,274.90,721.73,238.10,8.74;7,110.48,733.69,15.99,8.74">Features for Image Retrieval -A Quantitative Comparison</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,147.14,733.69,257.31,8.74">DAGM 2004, Pattern Recognition, 26th DAGM Symposium</title>
		<meeting><address><addrLine>Tübingen, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>LNCS</publisher>
			<date type="published" when="2004-09">September 2004</date>
			<biblScope unit="volume">3175</biblScope>
			<biblScope unit="page" from="228" to="236" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,112.02,402.52,8.74;8,110.48,123.98,355.68,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,280.45,112.02,232.56,8.74;8,110.48,123.98,61.26,8.74">Discriminative Training for Object Recognition using Image Patches</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,193.13,123.98,40.76,8.74">CVPR 05</title>
		<meeting><address><addrLine>San Diego, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-06">jun 2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="157" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,143.90,402.52,8.74;8,110.48,155.86,402.53,8.74;8,110.48,167.81,108.29,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,295.25,143.90,217.75,8.74;8,110.48,155.86,144.43,8.74">Improving a Discriminative Approach to Object Recognition using Image Patches</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,279.16,155.86,53.79,8.74">DAGM 2005</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<publisher>LNCS</publisher>
			<date type="published" when="2005-09">August/September 2005</date>
		</imprint>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct coords="8,110.48,187.74,402.51,8.74;8,110.48,199.69,402.52,8.74;8,110.48,211.65,189.57,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,325.50,187.74,187.50,8.74;8,110.48,199.69,55.98,8.74">Gesture Recognition Using Image Comparison Methods</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Dreuw</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,188.55,199.69,324.45,8.74;8,110.48,211.65,64.46,8.74">GW 2005, 6th Int. Workshop on Gesture in Human-Computer Interaction and Simulation</title>
		<meeting><address><addrLine>Vannes, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-05">May 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,231.57,402.51,8.74;8,110.48,243.53,364.37,8.74" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="8,383.06,231.57,129.93,8.74;8,110.48,243.53,76.19,8.74">Pascal Visual Ob ject Classes Challenge Results</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">V</forename><surname>Gool</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005-04">April 2005</date>
			<pubPlace>Oxford, UK</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Oxford</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="8,110.48,263.45,402.51,8.74;8,110.48,275.41,402.52,8.74;8,110.48,287.36,116.09,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,499.85,263.45,13.14,8.74;8,110.48,275.41,206.84,8.74">Efficient and Effective Querying by Image Content</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Faloutsos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Barber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Flickner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hafner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Niblack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Petkovic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Equitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,325.67,275.41,182.66,8.74">Journal of Intelligent Information Systems</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page" from="231" to="262" />
			<date type="published" when="1994-07">July 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,307.29,402.51,8.74;8,110.48,319.24,402.53,8.74;8,110.48,331.20,135.87,8.74" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,297.36,307.29,215.63,8.74;8,110.48,319.24,78.73,8.74">Object Class Recognition by Unsupervised Scale-Invariant Learning</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Perona</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zissermann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,209.39,319.24,245.43,8.74">Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>Blacksburg, VG</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003-06">June 2003</date>
			<biblScope unit="page" from="264" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,351.12,402.52,8.74;8,110.48,363.08,402.52,8.74;8,110.48,375.03,387.91,8.74" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,143.05,363.08,369.95,8.74;8,110.48,375.03,115.70,8.74">Comparison of Techniques for Measuring Cloud Texture in Remotely Sensed Satellite Meteorological Image Data</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><forename type="middle">Q</forename><surname>Gu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">N</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Renshaw</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Mugglestone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">F N</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">M</forename><surname>Grant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,235.44,375.03,122.69,8.74">Radar and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">136</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="236" to="248" />
			<date type="published" when="1989-10">October 1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,394.96,402.52,8.74;8,110.48,406.91,131.49,8.74" xml:id="b12">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Haberäcker</surname></persName>
		</author>
		<title level="m" coord="8,183.57,394.96,262.93,8.74">Praxis der Digitalen Bildverarbeitung und Mustererkennung</title>
		<meeting><address><addrLine>München, Wien</addrLine></address></meeting>
		<imprint>
			<publisher>Carl Hanser Verlag</publisher>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,426.84,402.52,8.74;8,110.48,438.79,375.29,8.74" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,329.50,426.84,179.47,8.74">Texture Features for Image Classification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Dinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,110.48,438.79,236.37,8.74">IEEE Transactions on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="610" to="621" />
			<date type="published" when="1973-11">November 1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,458.72,402.51,8.74;8,110.48,470.67,402.53,8.74;8,110.48,482.63,22.69,8.74" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,273.76,458.72,239.23,8.74;8,110.48,470.67,62.10,8.74">Classification of Medical Images using Non-linear Distortion Models</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gollan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,193.93,470.67,138.14,8.74">Bildverarbeitung für die Medizin</title>
		<meeting><address><addrLine>Berlin, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-03">March 2004</date>
			<biblScope unit="page" from="366" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,502.56,402.52,8.74;8,110.48,514.51,402.52,8.74;8,110.48,526.47,245.61,8.74" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="8,277.51,502.56,235.50,8.74;8,110.48,514.51,157.10,8.74">Local Context in Non-linear Deformation Models for Handwritten Character Recognition</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gollan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,293.52,514.51,215.10,8.74">International Conference on Pattern Recognition</title>
		<meeting><address><addrLine>Cambridge, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-08">August 2004</date>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="511" to="514" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,546.39,402.51,8.74;8,110.48,558.35,402.52,8.74;8,110.48,570.30,131.65,8.74" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="8,330.36,546.39,182.63,8.74;8,110.48,558.35,112.70,8.74">Adaptation in Statistical Pattern Recognition using Tangent Vectors</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dahmen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,230.24,558.35,278.75,8.74">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="269" to="274" />
			<date type="published" when="2004-02">February 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,590.23,402.52,8.74;8,110.48,602.18,402.52,8.74;8,110.48,614.14,314.24,8.74" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="8,152.22,602.18,360.78,8.74;8,110.48,614.14,28.70,8.74">Automatic Categorization of Medical Images for Content-based Retrieval and Data Mining</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">M</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-O</forename><surname>Güld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Spitzer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Wein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,148.38,614.14,193.59,8.74">Computerized Medical Imaging and Graphics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct coords="8,110.48,634.06,402.52,8.74;8,110.48,646.02,402.53,8.74;8,110.48,657.97,402.53,8.74;8,110.48,669.93,264.10,8.74" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="8,295.72,634.06,217.28,8.74;8,110.48,646.02,66.69,8.74;8,196.44,646.02,259.20,8.74">From Text to Image: Generating Visual Query for Image Retrieval</title>
		<author>
			<persName coords=""><forename type="first">W.-C</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H.-H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,463.34,646.02,49.66,8.74;8,110.48,657.97,328.22,8.74">Proceedings of the 5th Workshop of the Cross-Language Evaluation Forum. CLEF 2004</title>
		<meeting>the 5th Workshop of the Cross-Language Evaluation Forum. CLEF 2004<address><addrLine>Bath, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004-09">September 2004</date>
			<biblScope unit="volume">3491</biblScope>
			<biblScope unit="page" from="664" to="675" />
		</imprint>
	</monogr>
	<note>Multilingual Information Access for Text, Speech and Images</note>
</biblStruct>

<biblStruct coords="8,110.48,689.85,402.52,8.74;8,110.48,701.81,402.52,8.74;8,110.48,713.76,360.24,8.74" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="8,322.69,689.85,190.32,8.74;8,110.48,701.81,37.76,8.74">Probabilistic Aspects in Spoken Document Retrieval</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H.-J</forename><surname>Viechtbauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,157.84,701.81,355.16,8.74;8,110.48,713.76,247.03,8.74">EURASIP Journal on Applied Signal Processing, Special Issue on &quot;Unstructured Information Management from Multimedia Data Sources</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2003-02">February 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,112.02,402.51,8.74;9,110.48,123.98,402.52,8.74;9,110.48,135.93,402.52,8.74;9,110.48,147.89,22.69,8.74" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="9,337.51,112.02,175.48,8.74;9,110.48,123.98,56.41,8.74">Random Subwindows for Robust Image Classification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Marée</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Geurts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Piater</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Wehenkel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,379.65,123.98,133.35,8.74;9,110.48,135.93,137.25,8.74">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Schmid</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Soatto</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</editor>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2005-06">June 2005</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="34" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,167.81,402.51,8.74;9,110.48,179.77,402.52,8.74;9,110.48,191.72,402.53,8.74;9,110.48,203.68,264.10,8.74" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="9,243.63,167.81,269.36,8.74;9,110.48,179.77,345.48,8.74">How to Visually Retrieve Images from the St. Andrews Collection Using GIFT. In Multilingual Information Access for Text, Speech and Images</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Geissbühler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,463.34,179.77,49.65,8.74;9,110.48,191.72,328.22,8.74">Proceedings of the 5th Workshop of the Cross-Language Evaluation Forum. CLEF 2004</title>
		<meeting>the 5th Workshop of the Cross-Language Evaluation Forum. CLEF 2004<address><addrLine>Bath, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004-09">September 2004</date>
			<biblScope unit="volume">3491</biblScope>
			<biblScope unit="page" from="633" to="642" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,223.60,308.85,8.74" xml:id="b22">
	<monogr>
		<title level="m" type="main" coord="9,173.07,223.60,140.77,8.74">An algorithm for suffix stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980-07">July 1980</date>
		</imprint>
	</monogr>
	<note>Programm</note>
</biblStruct>

<biblStruct coords="9,110.48,243.53,402.52,8.74;9,110.48,255.48,402.52,8.74;9,110.48,267.44,216.35,8.74" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="9,349.37,243.53,163.64,8.74;9,110.48,255.48,135.54,8.74">Empirical Evaluation of Dissimilarity Measures for Color and Texture</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Puzicha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Rubner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Buhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,266.27,255.48,197.72,8.74">International Conference on Computer Vision</title>
		<meeting><address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-09">September 1999</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1165" to="1173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,287.36,402.52,8.74;9,110.48,299.32,305.56,8.74" xml:id="b24">
	<monogr>
		<title level="m" type="main" coord="9,170.95,287.36,235.94,8.74">Feature Histograms for Content-Based Image Retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Siggelkow</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<pubPlace>Freiburg, Germany</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Freiburg, Institute for Computer Science</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="9,110.48,319.24,402.51,8.74;9,110.48,331.20,402.53,8.74;9,110.48,343.15,205.94,8.74" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="9,419.13,319.24,93.86,8.74;9,110.48,331.20,163.18,8.74">Content-Based Image Retrieval: The End of the Early Years</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">W M</forename><surname>Smeulders</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Worring</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Santini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,281.75,331.20,231.25,8.74;9,110.48,343.15,48.17,8.74">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1349" to="1380" />
			<date type="published" when="2000-12">December 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,363.08,402.52,8.74;9,110.48,375.03,348.09,8.74" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="9,278.99,363.08,229.54,8.74">Textural Features Corresponding to Visual Perception</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Tamura</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Yamawaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,110.48,375.03,232.30,8.74">IEEE Transaction on Systems, Man, and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="460" to="472" />
			<date type="published" when="1978-06">June 1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,394.96,402.52,8.74;9,110.48,406.91,402.53,8.74;9,110.48,418.87,402.53,8.74;9,110.48,430.82,161.42,8.74" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="9,259.60,394.96,253.40,8.74;9,110.48,406.91,240.54,8.74">Multi-model Information Retrieval Using FINT. In Multilingual Information Access for Text, Speech and Images</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Van Zaanen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>De Croon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,359.38,406.91,153.62,8.74;9,110.48,418.87,223.93,8.74">Proceedings of the 5th Workshop of the Cross-Language Evaluation Forum. CLEF 2004</title>
		<meeting>the 5th Workshop of the Cross-Language Evaluation Forum. CLEF 2004<address><addrLine>Bath, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004-09">September 2004</date>
			<biblScope unit="volume">3491</biblScope>
			<biblScope unit="page" from="728" to="739" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
