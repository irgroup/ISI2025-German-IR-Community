<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,190.44,148.73,222.04,15.51;1,111.60,170.69,379.46,15.51">Combining global features for content-based retrieval of medical images</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,136.92,204.07,56.99,9.96"><forename type="first">Mark</forename><forename type="middle">O</forename><surname>Güld</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">RWTH Aachen</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,202.26,204.07,65.95,9.96"><forename type="first">Christian</forename><surname>Thies</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">RWTH Aachen</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,275.89,204.07,72.00,9.96"><forename type="first">Benedikt</forename><surname>Fischer</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">RWTH Aachen</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,374.70,204.07,91.26,9.96"><forename type="first">Thomas</forename><forename type="middle">M</forename><surname>Lehmann</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">RWTH Aachen</orgName>
								<address>
									<settlement>Aachen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,190.44,148.73,222.04,15.51;1,111.60,170.69,379.46,15.51">Combining global features for content-based retrieval of medical images</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2BBB569546C9D69160699EA10E62D745</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>Measurement, Performance, Experimentation image retrieval, classifier combination, hierarchical filtering, prototype selection</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A combination of several classifiers using global features for the content description of medical images is proposed. Beside well known texture histogram features, downscaled representations of the original images are used, which preserve spatial information and utilize distance measures which are robust regarding common variations in radiation dose, translation, and local deformation. These features were evaluated for the annotation task and the interactive query task in ImageCLEF 2005 without using additional textual information or query refinement mechanisms. For the annotation task, a categorization rate of 86.7% was obtained, which ranks second among all submissions. When applied in the interactive query task, the image content descriptors yielded a mean average precision (MAP) of 0.0751, which is rank 14 of 28 submitted runs. As the image deformation model is not fit for interactive retrieval tasks, two mechanisms are evaluated regarding the trade-off between loss of accuracy and speed increase: hierarchical filtering and prototype selection.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>ImageCLEFmed 2005 consists of several challenges for content-based retrieval <ref type="bibr" coords="1,431.72,633.91,11.57,9.96" target="#b0">[1]</ref> on medical images. For the retrieval task, the reference set was expanded to over 50,000 images, compared to 8,725 medical images in 2004. A newly introduced annotation task poses a classification problem of mapping 1,000 query images with no additional textual information onto one of 57 pre-defined categories. The mapping is to be learned based on a ground truth of 9,000 categorized reference images. These tasks reflect the real-life constraints of content-based image retrieval in medical applications, as image corpora are large, heterogeneous and additional textual information about an image, especially its content, is not always reliable due to improper configuration of the imaging devices, ambiguous naming schemes, and both inter-and intra-observer variability.</p><p>The annotation task consists of 9,000 images grouped into 57 categories and 1,000 images to be automatically categorized. It should be noted that the category definition is based solely on the aspects of 1. imaging modality, i.e. identification of the imaging device (three different device types) 2. imaging direction, i.e. relative position of the body part towards the imaging device 3. anatomy of the body part examined, and 4. biological system, which encodes certain contrast agents and a coarse description of the diagnostic motivation for the imaging.</p><p>Thus, the category definition does not incorporate any diagnosis information, e.g. the detection of pathologies or their quantitative analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Image features and their comparison</head><p>Based on earlier experiments conducted on a similar image set, three types of features and similarity measures were employed <ref type="bibr" coords="2,218.20,338.95,13.46,9.96" target="#b1">[2]</ref>. Tamura et al. proposed a set of texture features to capture global texture properties of an image, namely coarseness, contrast, and directionality <ref type="bibr" coords="2,325.45,362.83,11.79,9.96" target="#b2">[3]</ref>. This information is stored in a threedimensional histogram, which is quantized into M = 6 × 8 × 8 = 384 bins. To capture this texture information at a comparable scale, the extraction is performed on downscaled images of size 256×256, ignoring their aspect ratio. Two images q (query) and r (reference) are compared by applying Jensen-Shannon divergence <ref type="bibr" coords="2,260.68,410.71,12.89,9.96" target="#b3">[4]</ref> on their histograms H(q) and H(r):</p><formula xml:id="formula_0" coords="2,132.72,432.48,380.26,30.45">d JSD (q, r) = 1 2 M m=1 H m (q) log 2H m (q) H m (q) + H m (r) + H m (r) log 2H m (r) H m (q) + H m (r)<label>(1)</label></formula><p>To keep spatial information about the image content, down-scaled representations of the original images are used and the accompanying distance measures work directly on intensity values. It is therefore possible to incorporate a priori knowledge into the distance measure by modelling typical variability in the image data, which does not alter the category that the image belongs to. The cross-correlation function (CCF) from signal processing determines the maximum correlation between two 2D image representations, each one of size h × h:</p><formula xml:id="formula_1" coords="2,90.48,552.66,422.50,48.97">s CCF (q, r) = max |m|,|n|≤d    h x=1 h y=1 (r(x -m, y -n) -r) • (q(x, y) -q) h x=1 h y=1 (r(x -m, y -n) -r) 2 h x=1 h y=1 (q(x -m, y -n) -q) 2    (2)</formula><p>Here, q(x, y) and r(x, y) refer to intensity values at a pixel position on the scaled representations of q and r, respectively. Note that s CCF is a similarity measure and the values lie between 0 and 1. CCF includes robustness regarding two very common variabilites among the images: translation, which is explicitly tested within the search window of size 2d + 1, and radiation dose, which is normalized by subtracting the average intensity values q and r. For the experiments, downscaling to 32 × 32 pixels and a translation window of size d = 4 was used, i.e. translation can vary from -4 to +4 pixels in both x-and y-direction.</p><p>While s CCF considers global displacements, i.e. translations of entire images, pathologies, implants and normal inter-patient variability suggest to model local deformations for medical images. This can be done with an image distortion model (IDM) <ref type="bibr" coords="2,331.58,711.19,13.79,9.96" target="#b4">[5]</ref>:</p><formula xml:id="formula_2" coords="3,93.00,129.54,419.98,47.17">d IDM (q, r) = X x=1 Y y=1 min |x |,|y |≤W1    |x |,|y |≤W2 ||r(x + x + x , y + y + y ) -q(x + x , y + y )|| 2    (3)</formula><p>Again, q(x, y) and r(x, y) refer to intensity values of the scaled representations. Note that each pixel of q must be mapped on some pixel in r, whereas not all pixels of r need to be target of a mapping. Two parameters steer d IDM : W 1 defines the size of the neighborhood when searching for a corresponding pixel. To prevent a totally unordered pixel mapping, it is useful to incorporate the local neighborhood as context when evaluating a correspondence hypothesis. The size of the context information is controlled by W 2 . For the experiments, W 1 = 2, i.e. a 5 × 5 pixel search window, and W 2 = 1, i.e. a 3 × 3 context patch are used. Also, better results are obtained if the gradient images are used instead of the original images, because the correspondence search will then focus on contrast and be robust to global intensity differences due to radiation dose. It should be noted that this distance measure is computationally expensive as each window size influences the computation time in quadratic manner. The images were scaled to a fixed height of 32 pixels, i.e. the original aspect ratio was preserved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Nearest-neighbor classifier</head><p>To obtain a decision q → c ∈ {1 . . . C} for a query image q, a nearest neighbor classifier evaluating k nearest neighbors according to a distance measure is used (k-NN). It simply votes for the category which accumulated the most votes among the k reference images closest to q. This classifier also allows visual feedback in interactive queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Classifier combination</head><p>Prior experiments showed that the performance of the single classifiers can be improved significantly if their single decisions are combined <ref type="bibr" coords="3,282.37,450.55,13.64,9.96" target="#b1">[2]</ref>. This is especially the case for classifiers which model different aspects of the image content, such as the global texture properties with no spatial information and the scaled representations, which keep spatial information. The easiest way is a parallel combination scheme, since it can be performed as a post-processing step after the single classifier stage <ref type="bibr" coords="3,166.18,498.43,11.83,9.96" target="#b5">[6]</ref>. Also, no assumptions are required for the application, whereas a serial or sieve-like combination require an explicit construction.</p><p>For comparability, the distance values (d Tamura , d IDM ) are normalized at first over all distances d(q, r i ), i = 1 . . . N between sample q and each reference r i :</p><formula xml:id="formula_3" coords="3,240.25,555.19,272.74,27.25">d (q, r i ) = d(q, r i ) N n=1 d(q, r n ) (4)</formula><p>Afterwards, a new distance measure can be obtained by a weighted sum of distance measures</p><formula xml:id="formula_4" coords="3,90.00,591.43,423.00,35.29">d 1 , d 2 . d c (q, r) = λ • d 1 (q, r) + (1 -λ) • d 2 (q, r), λ ∈ [0; 1]<label>(5)</label></formula><p>For a similarity measure s, d(q, r) := 1 -s(q, r) is used and the normalization is performed afterwards. Thus, the parallel combination of the three classifiers results in</p><formula xml:id="formula_5" coords="3,210.24,667.15,302.72,41.29">d combined (q, r) = λ Tamura • d Tamura (q, r) + λ CCF • d CCF (q, r)) + λ IDM • d IDM (q, r)<label>(6)</label></formula><p>with λ Tamura , λ CCF , λ IDM ≥ 0 and λ Tamura + λ CCF + λ IDM = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Training and evaluation on the reference set</head><p>The combined classification process relies on three parameters: λ Tamura , λ CCF and k for the number of nearest neighbors to be evaluated (λ IDM is linear dependent). To obtain suitable values for them, the reference set of 9,000 images was split at random into a training set of 8,000 images and a test set of 1,000 images. The best parameter values found for this configuration are then applied to the 1,000 query images. For practical reasons, the matrices D Tamura = (d Tamura (q i , r j )) ij , S CCF = (s CCF (q i , r j )) ij , and D IDM = (d IDM (q i , r j )) ij are computed once. Afterwards, all combination experiments can be performed rather quickly by processing the matrices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Use of class prototypes</head><p>Since the distance computations for the scaled representations are rather expensive, there is -in general-great interest for prototype selection which allows to save computation time, storage space and might even improve the categorization rate by removing possible outliers in the reference set. Prototype sets can be obtained in various ways <ref type="bibr" coords="4,321.76,283.51,9.98,9.96" target="#b6">[7]</ref>. For simplicity, only random prototype selection and KCentres for K=1 and a simplified variation of it were used. Based on the empirically optimized d combined , a set of category prototypes is computed by using KCentres: R prototypes ⊂ R = c=1...C R c , with R c being the set of all references belonging to class c, can be determined:</p><formula xml:id="formula_6" coords="4,179.28,339.42,333.70,34.42">R prototypes = c=1...C    arg min r∈Rc    q ∈Rc d combined (r, r )       (7)</formula><p>These elements {r c }, c = 1..C yield the smallest sum of distances to all members of their respective category.</p><p>The prototypes are used to obtain a dissimilarity-space representation of the reference images and the unknown images:</p><formula xml:id="formula_7" coords="4,219.12,435.72,293.86,14.37">r → (d(r, r 1 ), . . . , d(r, r C )) tr ∈ IR C<label>(8)</label></formula><p>q → (d(q, r 1 ), . . . , d(q, r C ))</p><formula xml:id="formula_8" coords="4,348.12,452.04,164.86,12.91">tr ∈ IR C<label>(9)</label></formula><p>For the classification, two representations are compared using Euclidian distance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The retrieval task</head><p>The retrieval task uses 50,024 images for reference and consists of 25 queries, which are given as a combination of text information and query images, with some queries specifying both positive and negative example images. While the image data for the annotation task only contains grayscale images from mostly x-ray modalities (plain radiography, fluoroscopy, and angiography), the image material in this task is much more heterogeneous: It also contains photographs, ultrasonic imaging and even scans of illustrations used for teaching. Note that the interactive task demands a higher level of image understanding, since several of the 25 queries directly refer to the diagnosis of medical images, which is often based on local image details, e.g. bone fractures or the detection of emphysema in computed tomography images (CT) of the lungs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Image features and their comparison</head><p>The content representations described in the previous section only use grayscale information, i.e. color images are converted into grayscale by using standard color weighting:</p><formula xml:id="formula_9" coords="4,222.60,702.79,290.37,23.52">Y = 6969 • R + 23434 • G + 2365 • B 32768<label>(10)</label></formula><p>In general, however, color is the single most important discriminate feature type on stock-house media and the image corpus used for the interactive query task contains many photographs, color scans of teaching material, and microscopic imaging. Therefore, a basic color feature was employed to compute mean, variance and third order moments for each color channel red, green, and blue. This yields a 9-dimensional feature vector. Euclidean distance with equal weights for each color component is used to compute the distance between two vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Summation scheme for queries consisting of multiple images</head><p>Some of the queries do not consist of a single example image, but use several images as a query pool Q: positive and negative examples. For such queries, a simple summation scheme is used to obtain an overall distance:</p><formula xml:id="formula_10" coords="5,142.80,359.19,365.74,31.73">d(Q, r) = |Q| i=1 w i • d (q i , r), Q = i {(q i , w i )}, w i = 1 : q i positive ex. -1 : q i negative ex. (<label>11</label></formula><formula xml:id="formula_11" coords="5,508.54,370.27,4.43,9.96">)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>All results were obtained non-interactively, i.e. without relevance feedback by a human user, and without using textual information for the interactive query task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Annotation task</head><p>Table <ref type="table" coords="5,118.90,489.07,5.03,9.96" target="#tab_0">1</ref> shows the categorization results obtained for the 1,000 unknown images using single classifiers. As IDM is very expensive (see running times below), a serial combination with a faster, but more inaccurate classifier as a filter was also tested. For this, Euclidian distance on 32 × 32 scaled representations was used and only the 500 closest references were passed to IDM. This cuts computation time down to 1/18, as the costs for the filtering step are neglectable.</p><p>To obtain the optimal empirical weighting coefficients λ for the parallel combination, an exhaustive search would have been necessary. Instead, a more time-efficient two-step process was employed: First, a combination of the two spatial representations was considered. Afterwards, a combination of the combined spatial representations with the Tamura texture feature was investigated. Both runs tested values for λ increasing at a stepsize of 0.1. The results for these two steps on the testing set, i.e. 1,000 images of the 9,000 original reference images, are shown in Tab. 2.</p><p>This results in the parameter configuration shown in Tab.3. When using this parameter set for the classification of the 1,000 images to be categorized, a categorization rate of 86.7% for the 1-NN is obtained.</p><p>Using the 57 prototypes obtained via (7) as a representation set, a dissimilarity-space representation for the reference set and the unknown set was computed. The dissimilarity representations were then compared using a Euclidian distance. In addition, not only the elements with minimum sum of distances were used, but also the ones with the best n, n = 2 . . . 5 elements per category. This yields 114, 171, 228, and 285 components for the representation vectors. For comparison, experiments were also done for a random pick of 1 . . . 5 elements per category, resulting in representation vectors of the same size. The results are shown in Fig. <ref type="figure" coords="5,403.77,728.11,4.14,9.96" target="#fig_0">1</ref>.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Weights</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Retrieval task</head><p>Since no ground truth for the automatical optimization of the parameters is available, only a short visual inspection was done and two runs were submitted. The results are listed in Tab.4. The result quality is measured by mean average precision (MAP). These results are 19th and 14th place among 28 submitted runs in the "visual only, automatic" category of this task, reaching half the MAP of the leading competitor in this category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Running times</head><p>Table <ref type="table" coords="7,118.90,425.35,5.03,9.96" target="#tab_5">5</ref> lists the computation times of the algorithms for the annotation task on a standard Pentium 4 PC running at 2.6 GHz. For the retrieval task, extraction times per image are identical and query time is 5.5 times higher as there are 50,000 references compared to 9,000.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>Concerning running times, texture features by Tamura and CCF are fit for interactive use. By prefiltering with a computationally inexpensive distance measure, computation time can be severly reduced without sacrificing too much accuracy. In the experiments, pre-filtering clearly outperformed dissimilarity space approaches for both random prototype selection and 1centres. However, further evaluation of algorithms for prototype selection is necessary. The parallel combination of single classifiers proved very useful, as it improves the categorization results considerably and can also be performed as an easy post-processing step on the distance matrices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Annotation task</head><p>The results obtained for the annotation task verify the results obtained on a smaller corpus using leaving-one-out <ref type="bibr" coords="7,152.84,634.03,12.57,9.96" target="#b1">[2]</ref>.</p><p>Note that the rather high weight λ Tamura overemphasizes the role of the texture features in the experiments, as the actual improvement of the categorization rate is statistically insignificant for the 1-NN. It marginally improves the quality of the next nearest neighbors a bit as seen in the results for the 5-NN, which produces slightly better results for interactive queries which list a set of nearest neighbors. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Interactive query task</head><p>While results were satisfactory for queries based on grayscale radiographs, other queries, especially from photograpy imaging, had rather poor results. It should also be noted that several queries demand a high level of image content understanding, as they aim at diagnosis-related information, which is often derived from local details in the image (see Tab.6).</p><p>The methods used in this work to describe the image content either preserve no spatial information at all (texture features by Tamura) or capture it at very large scale, omitting local details important for diagnosis-relevant questions. Using only the image information, such queries cannot be processed with satisfactory quality of the results with a one-level approach. Refering to the concepts described in <ref type="bibr" coords="8,185.69,429.31,9.98,9.96" target="#b7">[8]</ref>, the methods employed in this paper work on the categorization layer of the content abstraction chain. For a better query completion, subsequent image abstraction steps are required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgment</head><p>This work is part of the IRMA project, which is funded by the German Research Foundation, grant Le 1108/4.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,146.40,730.63,310.06,9.96"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Results for single classifiers using dissimilarity representation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,131.04,109.87,340.89,92.04"><head>Table 1 :</head><label>1</label><figDesc>Results for single classifiers.</figDesc><table coords="5,387.72,109.87,84.14,9.96"><row><cell>Categorization rate</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,90.00,112.39,422.57,257.76"><head>Table 2 :</head><label>2</label><figDesc>Results on the testing subset, combination of IDM, CCF (left), combination of IDM, CCF, and Tamura texture (right).</figDesc><table coords="6,114.60,112.39,373.64,257.76"><row><cell></cell><cell></cell><cell cols="2">Categorization rate</cell><cell></cell><cell cols="2">Weights</cell><cell cols="2">Categorization rate</cell></row><row><cell cols="3">λ IDM λ CCF k=1</cell><cell>k=5</cell><cell></cell><cell cols="3">λ IDM,CCF λ Tamura k=1</cell><cell>k=5</cell></row><row><cell>0.0</cell><cell>1.0</cell><cell>82.5</cell><cell>80.9</cell><cell></cell><cell>0.0</cell><cell>1.0</cell><cell>70.8</cell><cell>69.0</cell></row><row><cell>0.1</cell><cell>0.9</cell><cell>84.0</cell><cell>82.0</cell><cell></cell><cell>0.1</cell><cell>0.9</cell><cell>78.1</cell><cell>76.9</cell></row><row><cell>0.2</cell><cell>0.8</cell><cell>84.8</cell><cell>83.5</cell><cell></cell><cell>0.2</cell><cell>0.8</cell><cell>81.4</cell><cell>80.7</cell></row><row><cell>0.3</cell><cell>0.7</cell><cell>85.6</cell><cell>84.1</cell><cell></cell><cell>0.3</cell><cell>0.7</cell><cell>83.5</cell><cell>83.1</cell></row><row><cell>0.4</cell><cell>0.6</cell><cell>85.6</cell><cell>84.3</cell><cell></cell><cell>0.4</cell><cell>0.6</cell><cell>84.6</cell><cell>84.0</cell></row><row><cell>0.5</cell><cell>0.5</cell><cell>85.5</cell><cell>84.5</cell><cell></cell><cell>0.5</cell><cell>0.5</cell><cell>85.5</cell><cell>84.6</cell></row><row><cell>0.6</cell><cell>0.4</cell><cell>86.2</cell><cell>84.2</cell><cell></cell><cell>0.6</cell><cell>0.4</cell><cell>86.7</cell><cell>85.2</cell></row><row><cell>0.7</cell><cell>0.3</cell><cell>86.6</cell><cell>84.5</cell><cell></cell><cell>0.7</cell><cell>0.3</cell><cell>86.7</cell><cell>85.1</cell></row><row><cell>0.8</cell><cell>0.2</cell><cell>85.9</cell><cell>84.0</cell><cell></cell><cell>0.8</cell><cell>0.2</cell><cell>86.6</cell><cell>85.1</cell></row><row><cell>0.9</cell><cell>0.1</cell><cell>85.5</cell><cell>82.8</cell><cell></cell><cell>0.9</cell><cell>0.1</cell><cell>86.6</cell><cell>84.9</cell></row><row><cell>1.0</cell><cell>0.0</cell><cell>84.7</cell><cell>82.6</cell><cell></cell><cell>1.0</cell><cell>0.0</cell><cell>86.6</cell><cell>84.5</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="4">λ IDM λ CCF λ Tamura k</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>0.42</cell><cell>0.18</cell><cell>0.4</cell><cell>1</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,158.88,382.15,284.99,9.96"><head>Table 3 :</head><label>3</label><figDesc>Empirical weighting parameters for the annotation task.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,218.40,110.23,166.32,34.32"><head>λ</head><label></label><figDesc>IDM λ IDM λ IDM λ RGB MAP</figDesc><table coords="7,218.40,122.59,166.32,21.96"><row><cell>0.4</cell><cell>0.4</cell><cell>0.2</cell><cell>0.0</cell><cell>0.0659</cell></row><row><cell>0.36</cell><cell>0.36</cell><cell>0.18</cell><cell>0.1</cell><cell>0.0751</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,107.76,156.43,387.37,102.72"><head>Table 4 :</head><label>4</label><figDesc>Results for the interactive query task.</figDesc><table coords="7,107.76,189.07,387.37,70.08"><row><cell>Content Representation</cell><cell>Extraction [s]</cell><cell>Query [s]</cell></row><row><cell></cell><cell cols="2">(per reference) (per sample)</cell></row><row><cell>Tamura texture histogram, Jensen-Shannon divergence</cell><cell>5</cell><cell>¡1</cell></row><row><cell>32×32, CCF (9 × 9 translation window)</cell><cell>3</cell><cell>6</cell></row><row><cell>X×32, IDM (gradients, 5 × 5 window, 3 × 3 context)</cell><cell>3</cell><cell>190</cell></row><row><cell>X×32, IDM (as above, 32x32 Euclid 500-NN as filter)</cell><cell>6</cell><cell>9</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,196.32,271.03,210.19,9.96"><head>Table 5 :</head><label>5</label><figDesc>Running times for the annotation task.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,122.64,109.87,357.62,175.68"><head>Table 6 :</head><label>6</label><figDesc>Queries in the interactive retrieval task which directly refer to diagnoses.</figDesc><table coords="8,158.04,109.87,286.92,153.84"><row><cell cols="2">Query Semantic constraint</cell></row><row><cell>2</cell><cell>fracture of the femur</cell></row><row><cell>10</cell><cell>emphysema in lung CT</cell></row><row><cell>12</cell><cell>enlarged heart in PA chest radiograph</cell></row><row><cell>15</cell><cell>gross pathologies of myocardial infarction</cell></row><row><cell>16</cell><cell>osteoarthritis in hand</cell></row><row><cell>17</cell><cell>micro nodules in lung CT</cell></row><row><cell>18</cell><cell>tuberculosis in chest radiograph</cell></row><row><cell>19</cell><cell>Alzheimer's desease in microscopic pathologies</cell></row><row><cell>20</cell><cell>chronic myelogenous leukemia in microscopic pathologies</cell></row><row><cell>21</cell><cell>bone fracture(s) in radiograph</cell></row><row><cell>23</cell><cell>differentiate between malignant and benign melanoma</cell></row><row><cell>24</cell><cell>right middle lobe pneumonia</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,105.47,573.91,407.21,9.96;8,100.56,585.79,412.20,9.96;8,100.56,597.79,106.89,9.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,368.83,573.91,143.86,9.96;8,100.56,585.79,114.02,9.96">Content-based image retrieval at the end of the early years</title>
		<author>
			<persName coords=""><forename type="first">Awm</forename><surname>Smeulders</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Worring</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Santini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,222.73,585.79,290.03,9.96">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1349" to="1380" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.47,616.63,407.43,9.96;8,100.56,628.63,405.77,9.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,460.63,616.63,52.27,9.96;8,100.56,628.63,290.11,9.96">Comparison of global features for categorization of medical images Proceedings</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">O</forename><surname>Güld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Leisten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">M</forename><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,393.67,628.63,22.78,9.96">SPIE</title>
		<imprint>
			<biblScope unit="volume">5371</biblScope>
			<biblScope unit="page" from="211" to="222" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.47,647.47,407.40,9.96;8,100.56,659.47,327.29,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,253.67,647.47,227.22,9.96">Textural features corresponding to visual perception</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Tamura</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Yamawaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,488.78,647.47,24.10,9.96;8,100.56,659.47,236.60,9.96">IEEE Transactions on Systems, Man, and Cybernetics; SMC</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="460" to="472" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.47,678.31,407.34,9.96;8,100.56,690.31,412.52,9.96;8,100.56,702.31,22.88,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,310.78,678.31,202.03,9.96;8,100.56,690.31,88.17,9.96">Empirical evaluation of dissimilarity measures for color and texture</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Puzicha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Rubner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Buhmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,196.23,690.31,252.14,9.96">Proceedings International Conference on Computer Vision</title>
		<meeting>International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1165" to="1173" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.47,721.15,407.17,9.96;8,100.56,733.15,412.09,9.96;8,100.56,745.03,62.07,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,233.03,721.15,279.62,9.96;8,100.56,733.15,10.43,9.96">Classification of medical images using non-linear distortion models</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gollan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,118.79,733.15,257.90,9.96">Proceedings BVM 2004, Bildverarbeitung für die Medizin</title>
		<meeting>BVM 2004, Bildverarbeitung für die Medizin<address><addrLine>Berlin</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2004">2004. 2004</date>
			<biblScope unit="page" from="366" to="370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,105.47,111.43,407.16,9.96;9,100.56,123.43,265.06,9.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,236.77,111.43,172.19,9.96">Statistical pattern recognition: a review</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">K</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rpw</forename><surname>Duin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,416.60,111.43,96.03,9.96;9,100.56,123.43,184.76,9.96">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="36" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,105.47,143.35,407.28,9.96;9,100.56,155.35,164.71,9.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,263.26,143.35,245.64,9.96">Prototype selection for dissimilarity-based classification</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Pekalska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rpw</forename><surname>Duin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Paclik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,100.56,155.35,86.22,9.96">Pattern Recognition</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct coords="9,105.47,175.27,407.35,9.96;9,100.56,187.15,412.22,9.96;9,100.56,199.15,143.25,9.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,177.06,187.15,227.41,9.96">Content-based image retrieval in medical applications</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">M</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">O</forename><surname>Güld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Thies</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Spitzer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kohnen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schubert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">B</forename><surname>Wein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,410.86,187.15,101.92,9.96;9,100.56,199.15,50.49,9.96">Methods of Information in Medicine</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="354" to="361" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
