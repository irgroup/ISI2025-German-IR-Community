<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,107.52,75.59,380.32,12.58">NCTU_DBLAB@ImageCLEF 2005: Automatic annotation task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,147.90,112.68,70.84,9.02"><forename type="first">Pei-Cheng</forename><surname>Cheng</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer &amp; Information Science</orgName>
								<orgName type="institution">National Chiao Tung University</orgName>
								<address>
									<addrLine>1001 Ta Hsueh Rd</addrLine>
									<postCode>30050</postCode>
									<settlement>Hsinchu</settlement>
									<region>O.C</region>
									<country>TAIWAN, R</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,227.02,112.68,74.19,9.02"><forename type="first">Been-Chian</forename><surname>Chien</surname></persName>
							<email>bcchien@mail.nutn.edu.tw</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Science and Information Engineering</orgName>
								<orgName type="institution">National University of Tainan</orgName>
								<address>
									<addrLine>33, Sec. 2, Su-Lin Street</addrLine>
									<postCode>700</postCode>
									<settlement>Tainan</settlement>
									<country>Taiwan, R.O</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,309.43,112.68,50.29,9.02"><forename type="first">Hao-Ren</forename><surname>Ke</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Institute of Information Management</orgName>
								<orgName type="institution" key="instit1">University Library</orgName>
								<orgName type="institution" key="instit2">National Chiao Tung University</orgName>
								<address>
									<addrLine>1001 Ta Hsueh Rd</addrLine>
									<postCode>30050</postCode>
									<settlement>Hsinchu</settlement>
									<region>O.C</region>
									<country>TAIWAN, R</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,384.84,112.68,64.16,9.02"><forename type="first">Wei-Pang</forename><surname>Yang</surname></persName>
							<email>wpyang@cis.nctu.edu.tw</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer &amp; Information Science</orgName>
								<orgName type="institution">National Chiao Tung University</orgName>
								<address>
									<addrLine>1001 Ta Hsueh Rd</addrLine>
									<postCode>30050</postCode>
									<settlement>Hsinchu</settlement>
									<region>O.C</region>
									<country>TAIWAN, R</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Information Management</orgName>
								<orgName type="institution">National Dong Hwa University</orgName>
								<address>
									<addrLine>1, Sec. 2, Da Hsueh Rd., Shou-Feng</addrLine>
									<settlement>Hualien</settlement>
									<country>Taiwan, R.O</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,107.52,75.59,380.32,12.58">NCTU_DBLAB@ImageCLEF 2005: Automatic annotation task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">10D1BDACC873DD03FA3CCEB566F82886</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>ACM Categories and Subject Descriptors: Pattern Recognition</term>
					<term>Computer Vision</term>
					<term>Medical Image Classification</term>
					<term>Support Vector Machine</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we use Support Vector Machine (SVM) to learn image feature characteristics for assisting the task of image classification. The ImageCLEF 2005 evaluation offers a superior test bed for medical image content retrieval. Several image visual features (including histogram, spatial layout, coherence moment and gabor features) have been employed in this paper to categorize the 1,000 test images into 57 classes. Based on the SVM model, we can examine which image feature is more promising in medical image retrieval. The result shows that the spatial relationship of pixels is a very important feature in medical image data, because medical image data always have similar anatomic regions (lung, liver, head, and so on); therefore image features emphasizing spatial relationship have better result than others.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Image retrieval techniques are essentially required due to the enormous amount of digital images produced day by day. Content-based image retrieval using primitive image features is promising in retrieving visually similar images. The QBIC system <ref type="bibr" coords="1,186.71,493.56,50.07,9.02" target="#b1">[Flickner95]</ref> is one of the well-known content-based systems, and other famous systems are Blob World <ref type="bibr" coords="1,170.96,505.08,43.59,9.02" target="#b2">[Carson99]</ref> <ref type="bibr" coords="1,214.55,505.08,52.31,9.02" target="#b3">[Belongie98]</ref>, VIPER/GIFT <ref type="bibr" coords="1,323.27,505.08,45.27,9.02">[Squire 99</ref>], and SIMPLIcity <ref type="bibr" coords="1,447.01,505.08,35.94,9.02">[Wang 01</ref>]. Various image features and similarity metrics have already been proposed for general images; however, before the ImageCLEF forum, a prime problem is the lack of benchmarks to evaluate which features are suitable for a specific application.. The ImageCLEF forum offers an image test bed to compare and evaluate different visual features and distance metrics. In the automatic annotation task, a database of 9,000 fully classified radiographs in 57 classes taken randomly from medical routine is made available and can be used to train a classification system. One thousand radiographs whose classification labels are not available to the participants have to be classified. The aim is to find out how well current techniques can identify image modality, body orientation, body region, and biological system examined based on the images. In this paper, we use the Support Vector Machine (SVM) to learn image feature characteristics. Based on the SVM model, several image features that consider, from the viewpoint of human, the invariance in image rotation, shift and illumination are employed in our system. Using these image features, the support vector machine plays as a classifier to categorize the 1,000 test images into 57 classes.</p><p>The experiment result shows that in a medical image application, an image feature with strong spatial descriptor is more significant for representing an image. The rest of this paper is organized as follows. In Section 2, the employed image features are described. Section 3 illustrates the SVM model that is used to classify the training data. In Section 4, the submissions are discussed. Finally, Section 5 provides concluding remarks and future directions for medical image retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Image features</head><p>This section describes the features used in this paper for the ImageCLEF 2005 evaluation. In an image retrieval system, image features are extracted from pixels. The extracted features are then used for similarity comparison. For fast response, image features must be concise, and for precision, image features must contain meaningful information to represent the image itself. Image features will directly affect the retrieval result. In this paper we examine several image features to understand which features will have good performance in medical image application. When designing the image features, to emphasize the contrast of an image and handle images with little illuminative influence, we normalize the value of a pixel before quantization. In <ref type="bibr" coords="2,412.36,180.72,42.41,9.02">[Cheng 04</ref>] we proposed a relative normalization method. First, we cluster a whole image into four clusters by the K-means clustering method <ref type="bibr" coords="2,103.84,203.76,31.31,9.02" target="#b6">[Han01]</ref>. We sort the four clusters ascendantly according to their mean values. We shift the mean of the first cluster to the value 50 and the fourth cluster to 200; then, each pixel in a cluster is multiplied by a relative weight to normalize. Let m c1 be the mean value of cluster 1 and m c4 is the mean value of cluster 4. The normalization formula of pixel p(x,y) is defined in Eq. (1).</p><formula xml:id="formula_0" coords="2,179.39,256.19,198.56,24.73">) ( 200 )) 50 ( ) , ( ( ) , ( 1 4 1 c c c normal m m m y x p y x p - × - - =</formula><p>.</p><p>(1)</p><p>After normalization, we scale an image into common 128*128 pixels and extract image features.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Facade scale image feature</head><p>The pixel values of an image are a straight-forward feature. For computational efficiency, images are always scaled to a common small size and compared using the Euclidean distance. <ref type="bibr" coords="2,392.48,352.02,48.91,9.02" target="#b7">[Keysers04]</ref> has shown that the Facade image feature performs very well in optical character recognition and medical image retrieval. In this paper we scale down an image into 8×8 pixels to form a 64 feature vectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Fuzzy Histogram layout</head><p>Histogram <ref type="bibr" coords="2,115.89,414.24,41.74,9.02" target="#b8">[Swain91]</ref> is a prime image feature for image retrieval. Histogram is invariant in image rotation. It is easy to implement and has good results in color image indexing. Because a radiotherapy medical image only consists of gray-level pixels, spatial relationship becomes very important. Medical images always contain particular anatomic regions (lung, liver, head, and so on); therefore, similar images have similar spatial structures. We divide an image into nine sections and calculate their histogram respectively. After normalization, gray values are quantized into 16 levels for computational efficiency.</p><p>In the fuzzy histogram layout, a gray value may be quantized into several bins to improve the similarity between adjacent bins. We set an interval range δ to extend the similarity of each gray value. The fuzzy histogram layout estimates the probability of each gray level that appears in a particular area. The probability equation is defined in Eq. ( <ref type="formula" coords="2,101.01,519.23,3.54,9.02" target="#formula_8">2</ref>), where δ is set to 10, p j is a pixel of a given image, and m is the total number of pixels in this image. In our implementation, we use a total of 144 bins for the fuzzy histogram layout.</p><formula xml:id="formula_1" coords="2,213.06,545.09,140.45,52.58">m c p p I h m j i j j c i ∑ = ∩ + - = 1 ] 2 , 2 [ ) ( δ δ δ .</formula><p>(2)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Coherence Moment</head><p>One of the problems to devise an image representation is the semantic gap. The state-of-the-art technology still cannot reliably identify objects. The coherence moment feature attempts to describe the features from the human's viewpoint in order to reduce the semantic gap. We cluster an image into four classes by the K-means algorithm. After clustering an image into four classes, we calculate the number of pixels (COH κ ), mean value of the gray values (COH μ ) and standard variance of the gray values (COH ρ ) in each class. For each class, we group connected pixels in the eight directions as an object. If an object is bigger than 5% of the whole image, we denote it as a big object; otherwise it is a small object. We count how many big objects (COH ο ) and small objects (COH ν ) are in each class, and use COH ο and COH ν as parts of image features. Since we intend to know the reciprocal effects among pixels, so we use the smoothing method on the image. If the spatial distribution of the pixels in two images is similar, they will also be similar after smoothing. If their spatial distributions are quite different, they may have a different result after smoothing. After smoothing, we cluster an image into four classes and calculate the number of big objects (COH τ ) and small objects (COH ω ). Each pixel will be influenced by its neighboring pixels. Two close objects of the same class may be merged into one object. Then, we can analyze the variation between the two images before and after smoothing. The coherence moment of each class forms a seven-feature vector, (COH κ , COH μ , COH ρ , COH ο , COH ν , COH τ , COH ω ). The coherence moment of an image is a 56-feature vector that combines the coherence moments of the four classes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Gray Correlogram.</head><p>The contour of a medical image contains rich information. In this task we are going to find similar medical images. A broken bone in the contour may be different from a healthy one. Thus we choose a representation that can estimate the partial similarity of two images and can be used to calculate their global similarity. We analyze the image pixels by our modified correlogram algorithm. The definition of the correlogram [18,19] is in Eq. (3). Let D denote a set of fixed distances {d 1 , d 2 , d 3 ,…, d n }. The correlogram of an image I is defined as the probability of a color pair (ci, cj) at a distance d.</p><formula xml:id="formula_2" coords="3,196.02,270.14,258.95,20.06">} | | { Pr ) ( 2 1 2 , , 2 1 d p p c p I j I p c p d c c i j i = - ∈ = ∈ ∈ γ . (<label>3</label></formula><formula xml:id="formula_3" coords="3,454.97,276.72,3.89,9.02">)</formula><p>For computational efficiency, the autocorrelogram is defined in Eq. ( <ref type="formula" coords="3,346.46,305.46,3.89,9.02" target="#formula_4">4</ref>)</p><formula xml:id="formula_4" coords="3,199.32,327.70,255.66,20.61">} | | { Pr ) ( 2 1 2 , 2 1 d p p c p I i I p c p d c i i = - ∈ = ∈ ∈ λ . (<label>4</label></formula><formula xml:id="formula_5" coords="3,454.98,334.52,3.90,9.06">)</formula><p>The contrast of a gray image dominates human perception. If two images have different gray levels they still may be visually similar. Thus the correlogram method cannot be used directly.</p><p>Our modified correlogram algorithm works as follows. First, we sort the pixels in descending order. Then, we order the results of the preceding sorting by ascendant distances of pixels to the center of the image. The distance of a pixel to the image center is measured by the L2 distance. After sorting by gray value and distance to the image center, we select the top 20 percent of pixels and the gray values higher than a threshold to estimate the autocorrelogram histogram. We set the threshold zero in this task. Any two pixels have a distance, and we estimate the probability that the distance falls within an interval. The distance intervals we set are {(0,2), (2,4), (4,6), (6,8), (8,12), (12,16), (16,26), (26,36), (36,46), (46,56), (56,76), (76,100)}.We calculate the probability of each interval to form the correlogram vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Gabor texture features</head><p>Gabor filter is widely adopted to extract texture features from images for image retrieval <ref type="bibr" coords="3,440.57,507.32,58.03,9.06">[Manjunath 96</ref>], and has been shown to be very efficient. Gabor filters are a group of wavelets, with each wavelet capturing energy at a specific frequency and a specific direction. Expanding a signal using this basis provides a localized frequency description, therefore capturing local features/energy of the signal. Texture features can then be extracted from this group of energy distributions. The scale (frequency) and orientation tunable property of Gabor filter makes it especially useful for texture analysis. The Gabor wavelet transformation W mn of Image I(x,y) derived from Gabor filters according to <ref type="bibr" coords="3,454.80,576.32,58.10,9.06">[Manjunath 96</ref>] is defined in Eq. ( <ref type="formula" coords="3,142.89,587.84,3.90,9.06" target="#formula_6">5</ref>) . ) , ( ) , ( ) , (</p><formula xml:id="formula_6" coords="3,185.98,603.68,274.82,22.19">1 1 1 1 ∫ - - = * dy dx y y x x g y x I y x W mn mn . (<label>5</label></formula><formula xml:id="formula_7" coords="3,460.80,611.12,3.90,9.06">)</formula><p>The mean μ mn and standard deviation σ mn of the magnitude |W mn | are used for the feature vector, as shown in Eq.</p><p>(6).  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Classification method</head><p>In this work, we use Support Vector Machine (SVM) <ref type="bibr" coords="4,291.72,145.76,38.61,9.06">[Boser 92</ref>] to learn image feature characteristics. SVM is an effective classification method. Its basic idea is to map data into a high dimensional space and find a separating hyperplane with the maximal margin. Given a training set of instance-label pairs (x i , y i ), i=1,…,k where x i ∈R n and y∈{1,-1} k , the support vector machine optimizes the solution of the following problem:</p><formula xml:id="formula_8" coords="4,166.74,199.94,297.95,29.77">i i T i k i i T b w b x w y C w w Min φ ψ φ φ - ≥ + + ∑ = 1 ) ) (<label>( and ) 2 1 ( 1 , , , 0 ≥ i φ (8)</label></formula><p>Training vectors x i are mapped into a higher dimensional space by the function ψ. Then SVM finds a linear separating hyperplane with the maximal margin in this higher dimensional space. C&gt;0 is the penalty parameter of the error term. Furthermore, K(x i ,x j )≡ is called the kernel function. In this paper we use LIBSVM [Lin 01] to classify the training data with a radial basis function or a polynomial function as the kernel function. The radial basis function (RBF) and the polynomial function used is defined in Eq. ( <ref type="formula" coords="4,463.74,299.38,3.89,9.04">8</ref>) and Eq. ( <ref type="formula" coords="4,513.87,299.38,3.54,9.04">9</ref>), respectively, . whereγ, r, and d are kernel parameters.</p><formula xml:id="formula_9" coords="4,206.10,268.14,261.10,147.49">) ( ) ( j T i x x ψ ψ . 0 ), || || exp( ) , ( 2 &gt; - - = γ γ j i j i x x x x K (9) . 0 , ) ( ) , ( &gt; + = γ γ d j T i j i r x x x x K (10)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Submissions to the ImageCLEF 2005 Evaluation</head><p>In the ImageCLEF 2005 Automatic Annotation Task, we have submitted five SVM-based runs. Table <ref type="table" coords="4,483.38,485.98,5.02,9.04" target="#tab_0">1</ref> gives an overview of the features and the error rates of submit runs. The error rate is noted that each .1% corresponds to 1 misclassification, because this task has a total of one thousand images to be classified. The first run, Facade scale feature with 64-feature vectors is used and the radial basis function is chosen as the kernel function of SVM. Both of the second run and the third run use all 324 features, but they use different kernel functions for the SVM. The fourth run uses two kind of features, Façade scale and fuzzy histogram layout, and contains 208 features. The fifth run uses the coherence moment feature only and the radial basis kernel function for SVM.</p><p>In the image features used in our experiment, the facade scale feature that directly scales down an image contains the most spatial relationship. The fuzzy histogram layout feature divides an image into nine sections, which result in less spatial information than the facade scale feature; however, this feature is more invariant in image shift. The coherence moment considers the image rotation and shift, but cannot carry much spatial information.</p><p>In our experiments, the first run has the best result, with error rate 24.7%. The second run, which has error rate 24.9%, uses all image features but does not have better result than the first run, because the first run contain the most spatial information. Others image features do not improve the description of spatial relationship. In medical image data, the spatial distribution of pixels is the most significant. The fifth run contains the least spatial information, thus it has the worst result.</p><p>In the ImageCLEF 2005, one experiment for a nearest neighbor classifier that scales down images to 32*32 pixels and use the Euclidean distance for comparison has error rate 36.8%, which means that 368 images are misclassified. This experiment uses a feature very similar to the façade features; however the facade image feature scales down an image to only 8 x 8 pixels., It can be observed that the representation of the facade image feature is more concise and has better result than the 32x32-pixel features.; furthermore, the SVM method has better performance than the Euclidean distance metric. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusions and future work</head><p>In this paper, several image features are examined for medical image data. The medical image application is unlike general-propose images. In general propose images, the representation always consider the invariance in image rotation, zooming and shift. Medical images have more stable camera settings than general propose images; therefore, the spatial information becomes very important in medical images, and we must improve the representation regarding spatial relation in this kind of images. We use the support vector machine as a classifier; it is very efficient, but it seems that the SVM lacks the ability of feature selection. The fourth run also contains Facade scale feature but the result is worse than the first run. In the future, we plan to develop the feature selection technology for the SVM to improve the performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,427.56,688.78,2.53,9.12;3,399.18,688.78,3.37,9.12;3,374.53,688.78,2.03,9.12;3,369.37,688.78,3.37,9.12;3,359.71,688.78,2.53,9.12;3,351.12,688.78,3.37,9.12;3,326.76,688.78,5.40,9.12;3,261.78,688.78,2.53,9.12;3,238.62,688.78,2.03,9.12;3,233.47,688.78,3.37,9.12;3,223.80,688.78,2.53,9.12;3,215.22,688.78,3.37,9.12;3,194.10,688.78,2.03,9.12;3,169.68,688.78,3.37,9.12;3,160.01,688.78,2.53,9.12;3,151.43,688.78,3.37,9.12;3,403.08,686.30,3.55,6.38;3,183.60,682.23,9.96,22.32;3,315.75,682.23,9.96,22.32;3,378.60,685.52,5.55,12.40;3,300.84,685.52,5.55,12.40;3,175.44,685.52,5.55,12.40;3,407.82,689.05,19.13,8.83;3,384.06,689.05,5.07,8.83;3,364.50,689.05,4.50,8.83;3,355.20,689.05,4.50,8.83;3,333.17,689.05,8.44,8.83;3,283.98,689.05,4.70,8.83;3,266.16,689.05,15.20,8.83;3,242.70,689.05,19.13,8.83;3,228.60,689.05,4.50,8.83;3,219.24,689.05,4.50,8.83;3,197.27,689.05,8.44,8.83;3,164.81,689.05,4.50,8.83;3,155.45,689.05,4.50,8.83;3,389.40,693.57,8.67,6.18;3,341.34,693.57,8.67,6.18;3,288.66,693.57,8.67,6.18;3,205.44,693.57,8.67,6.18;3,141.66,693.57,8.67,6.18;3,135.42,684.94,5.84,13.11;3,455.10,689.24,11.69,9.06;3,70.92,716.86,157.48,13.03;3,228.30,724.81,7.92,5.65;3,239.40,716.86,23.65,13.03;3,263.04,724.81,7.92,5.65;3,274.08,720.68,250.35,9.06;3,70.92,734.90,427.17,9.06"><head></head><label></label><figDesc>image feature is constructed by μ mn and σ mn of different scales and orientations. Our experiment uses four (S=4) as the scale and six (K=6) as the orientation to construct a 48 feature vectors f , as shown in Eq. (7).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,118.56,76.66,353.21,124.67"><head>Table 1 :</head><label>1</label><figDesc>Features for the different submissions and the evaluation result.</figDesc><table coords="5,118.56,91.41,353.21,109.92"><row><cell>Submission runs</cell><cell cols="2">Image features</cell><cell>SVM</cell><cell>error rate</cell></row><row><cell></cell><cell></cell><cell></cell><cell>kernel function</cell><cell>%</cell></row><row><cell>nctu_mc_result_1.txt</cell><cell cols="2">Facade scale: 64 vectors</cell><cell>radial basis function</cell><cell>24.7</cell></row><row><cell>nctu_mc_result_2.txt</cell><cell cols="2">All features: 324 vectors</cell><cell>radial basis function</cell><cell>24.9</cell></row><row><cell>nctu_mc_result_3.txt</cell><cell cols="2">All features: 324 vectors</cell><cell>polynomial</cell><cell>31.8</cell></row><row><cell>nctu_mc_result_4.txt</cell><cell>Facade layout: 208 vectors scale,</cell><cell>Histogram</cell><cell>radial basis function</cell><cell>28.5</cell></row><row><cell>nctu_mc_result_5.txt</cell><cell cols="3">Coherence Moment: 56 vectors radial basis function</cell><cell>33.8</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,138.46,372.10,385.82,9.04;5,70.92,383.62,456.07,9.04;5,70.92,395.08,136.46,9.04" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,281.76,372.10,242.52,9.04;5,70.92,383.62,16.91,9.04">Texture features for browsing and retrieval of large image data</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">S</forename><surname>Manjunath</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,94.68,383.62,408.38,9.04">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="837" to="842" />
			<date type="published" when="1996-08">August 1996</date>
		</imprint>
	</monogr>
	<note>Special Issue on Digital Libraries)</note>
</biblStruct>

<biblStruct coords="5,123.53,406.60,403.46,9.04;5,70.92,418.12,456.88,9.04;5,70.92,429.58,54.98,9.04" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,210.51,418.12,219.33,9.04">Query by Image and Video Content: The QBIC system</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Flickner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Sawhney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Niblack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ashley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Dom</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gorkani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hafner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Petkovic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Steele</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yanker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,436.62,418.37,64.33,8.78">IEEE Computer</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="23" to="32" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,123.80,441.10,400.67,9.04;5,70.92,452.62,453.50,9.04;5,70.92,464.08,453.54,9.04;5,70.92,475.60,270.43,9.04" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,420.59,441.10,103.88,9.04;5,70.92,452.62,168.80,9.04">Blobworld: A system for region-based image indexing and retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Carson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Hellerstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,446.58,452.87,77.84,8.78;5,70.92,464.08,241.44,9.04">Third International Conference On Visual Information Systems (VISUAL&apos; 99)</title>
		<title level="s" coord="5,372.94,464.08,147.32,9.04">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Huijsmans</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">W M</forename><surname>Smeulders</surname></persName>
		</editor>
		<meeting><address><addrLine>Springer{Verlag, Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="509" to="516" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,129.42,487.12,394.97,9.04;5,70.92,498.58,453.60,9.04;5,70.92,510.10,269.98,9.04" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,344.49,487.12,179.89,9.04;5,70.92,498.58,250.96,9.04">Color and texture based image segmentation using EM and its application to content-based image retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Carson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Greenspan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,342.54,498.83,181.98,8.78;5,70.92,510.35,122.63,8.78">Proceedings of the International Conference on Computer Vision (ICCV&apos;98)</title>
		<meeting>the International Conference on Computer Vision (ICCV&apos;98)<address><addrLine>Bombay, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="675" to="682" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,123.29,521.62,401.13,9.04;5,70.92,533.08,453.53,9.04;5,70.92,544.60,402.39,9.04" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,344.42,521.62,180.00,9.04;5,70.92,533.08,434.82,9.04">Content-Based Query of Image Databases, Inspirations from Text Retrieval: Inverted Files, Frequency-Based Weights and Relevance Feedback</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Squire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Raki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,70.92,544.85,177.87,8.78">Scandinavian Conference on Image Analysis</title>
		<meeting><address><addrLine>Kangerlussuaq, Greenland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999-06">June 1999</date>
			<biblScope unit="page" from="143" to="149" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,119.86,556.12,404.54,9.04;5,70.92,567.58,453.48,9.04;5,70.93,579.10,22.59,9.04" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,285.81,556.12,238.59,9.04;5,70.92,567.58,66.69,9.04">SIMPLIcity: Semantics-Sensitive Integrated Matching for Picture Libraries</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Wiederhold</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,145.14,567.83,265.20,8.78">IEEE Transaction on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="947" to="963" />
			<date type="published" when="2001-09">September 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,107.46,590.62,417.48,9.04;5,70.92,602.08,26.69,9.04" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kamber</surname></persName>
		</author>
		<title level="m" coord="5,199.47,590.62,159.39,9.04">Data Mining: Concepts and Techniques</title>
		<meeting><address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,123.60,613.60,400.92,9.04;5,70.92,625.06,453.51,9.04;5,70.92,636.58,61.13,9.04" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,340.51,613.60,184.00,9.04;5,70.92,625.06,93.53,9.04">Adaptation in Statistical Pattern Recognition using Tangent Vectors</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Macherey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Dahmen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,174.18,625.31,280.50,8.78">IEEE transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="269" to="274" />
			<date type="published" when="2004-02">February 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,115.82,648.10,408.57,9.04;5,70.92,659.56,63.34,9.04" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,248.57,648.10,59.96,9.04">Color Indexing</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Swain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">H</forename><surname>Ballard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,320.22,648.35,168.70,8.78">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="11" to="32" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,122.15,671.08,402.36,9.04;5,70.92,682.60,453.51,9.04;5,70.92,694.06,94.26,9.04" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="5,437.12,671.33,87.39,8.78;5,70.92,682.85,203.54,8.78">KIDS&apos;s evaluation in medical image retrieval task at ImageCLEF 2004</title>
		<author>
			<persName coords=""><forename type="first">Pei-Cheng</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Been-Chian</forename><surname>Chien</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Hao-Ren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei-Pang</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,287.34,682.60,188.72,9.04">Working Notes for the CLEF 2004 Workshop</title>
		<meeting><address><addrLine>Bath,UK</addrLine></address></meeting>
		<imprint>
			<date>September</date>
			<biblScope unit="page" from="585" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,117.91,705.58,406.55,9.04;5,70.92,717.35,318.83,8.78" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="5,301.56,705.58,207.53,9.04">A training algorithm for optimal margin classifiers</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,70.92,717.35,314.44,8.78">Proceedings of the Fifth Annual Workshop on Computational Learning Theory</title>
		<meeting>the Fifth Annual Workshop on Computational Learning Theory</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,118.34,728.56,406.20,9.04;5,70.92,740.08,166.14,9.04" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="5,295.47,728.56,224.60,9.04">LIBSVM: a library for support vector machines</title>
		<author>
			<persName coords=""><forename type="first">C.-C</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://www.csie.ntu.edu.tw/~cjlin/libsvm" />
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
