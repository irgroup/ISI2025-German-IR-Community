<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,131.76,99.12,339.32,15.12;1,121.56,121.08,360.04,15.12;1,247.44,142.92,108.07,15.12">Using Ontology Dimensions and Negative Expansion to solve Precise Queries in CLEF Medical Task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,168.24,176.78,93.65,8.78"><forename type="first">Jean-Pierre</forename><surname>Chevallet</surname></persName>
						</author>
						<author>
							<persName coords="1,358.44,176.78,62.54,8.78"><forename type="first">Joo-Hwee</forename><surname>Lim</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">IPAL-CNRS Institute for Infocomm Research</orgName>
								<address>
									<addrLine>21 Heng Mui Keng Terrace</addrLine>
									<postCode>119613</postCode>
									<settlement>Singapore</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Institute for Infocomm Research</orgName>
								<address>
									<addrLine>21 Heng Mui Keng Terrace</addrLine>
									<postCode>119613</postCode>
									<settlement>Singapore</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Saïd Radhouani Centre universitaire d&apos;informatique</orgName>
								<address>
									<addrLine>24, rue Général-Dufour CH</addrLine>
									<postCode>1211</postCode>
									<settlement>Genève 4</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">CLIPS-IMAG France</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,131.76,99.12,339.32,15.12;1,121.56,121.08,360.04,15.12;1,247.44,142.92,108.07,15.12">Using Ontology Dimensions and Negative Expansion to solve Precise Queries in CLEF Medical Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">96720F8FDC57B60A5C9E4D4518AD9809</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Managment]: Languages-Query Languages Measurement, Performance, Experimentation Ontology Dimensions, Negative Weight, Text and Visual Fusion</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present here the method we have used for indexing multilingual text part of the Image Medical CLEF Collection. The result of the textual querying is then mixed with the image matching. We show by our results that a fusion of two media are of a great benefice because the combination of text and image returns clear better results than the two separately. We focus in this paper on the textual indexing part using a medical ontology to filter the document collection. At first, we use the notion of ontology dimensions, which corresponds the split of the ontology into sub ontology. In our experiment we just use the first tree level of the MESH ontology. We have modelled and experimented two different approaches of the use of the ontology: the first one is an ontology filtering that can force some terms of one dimension to be present in the final document. We have noticed a strong improvement using this technique over the classic Vector Space Model. The second technique manages the preference of some terms among other in the same dimension. Our hypothesis is that precise document should emphasis only few terms of a given dimension. To compute this new constraint, we have set up a negative weight query expansion. Finally, the combination of the two methods produces the overall best results. To our opinion, it shows that for a given domain, adding explicit knowledge stored into an ontology tree, enable to classify the importance of terms used in the query and enhance the finale average precision.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The text part of the image CLEF 2005 medical collection is in three languages: English, French and German. This forms an unusual IR test collection because of the great variation of documents length and the use of very precise terms. On the query side, it seems clear that some regularity appears. Each query roughly deals with anatomy, modality of the image and pathology. We call these "dimensions" of the query. Hence we have made the obvious assumption that a relevant document to a query with dimensions, is the one that fulfils correctly to these dimensions. To precise this notion, we decide to refer dimension to ontology. For example, here are the first levels of the MESH ontology. We call dimension the sub tree of the hierarchy of an ontology. For the CLEF medical queries, we have only used the dimensions Anatomy [A], Diseases [C] and Analytical, Diagnostic and Therapeutic Techniques and Equipment <ref type="bibr" coords="2,298.96,498.44,13.93,8.35">[E]</ref>. The question we face for this experiment is the way to take into account these dimensions into an Information Retrieval System. In the next section we present the way we have include these dimensions into the classical Vector Space Model. We have used a filtering Boolean method on ontology dimensions, combined with a negative weight terms vector expansion based also on ontology dimensions. We can classify this sort of task as "precise information retrieval", which could be in-between classical thematic IR and question answering. In the following sections we detail models and methods used for the use of these dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Using Ontology dimensions</head><p>When we want to take into account the notion of dimension relative to an ontology, it means that the query usually focuses to one instance or possible value in one dimension and exclude all others. For example, if we are searching one image about one special body region of the dimension Anatomy from the ontology, the choice of a body region explicitly exclude other body region. If the query is about "Abdomen" then all documents which are about an other body region are irrelevant. It is then clear that the use of dimension of an ontology leads to express the notion of term exclusion at the query level. Unfortunately, there is no way for the Vector Space Model to express such term exclusions. In the next part, we discuss such extensions to this model.</p><p>We present two different ways to take into account dimensions. The first one maps the initial query to ontology dimensions. This method produces one query vector per ontology dimension. The second is simpler and still uses only one vector but add negative weight to exclude terms belonging to the same dimension. We present at first the mapping of the query to ontology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Filtering corpus by ontology dimensions</head><p>Our aim is to take into account dimensions present in query to build a precise Information Retrieval System. The basic idea is to split the initial query Q into several sub queries, each addressing one ontology dimension. Our goal is to give some terms priority depending the ontology dimension they belong to. For that purpose, we use Boolean expressions on the sub query. It is a Boolean pre filtering technique on top of Vector Space Model system.</p><p>At first, we extract dimension term sets from query. It means that we dispatch query terms to sub dimension queries. We use the ontology to determine the correct dimension of a term. We do not solve yet any ambiguity because the query belongs to a precise domain. We call this split a mapping between the query Q and each ontology dimension O i . For a given ontology O, we define as O i to be the set of terms under this dimension. The mapping is just a term set intersection:</p><formula xml:id="formula_0" coords="3,90.00,287.05,253.81,10.66">Q i = Q ∩ O i , where Q i is a sub query for the dimension i.</formula><p>Once, sub query dimensions Q i are extracted we build a Boolean query by the disjunction of all terms and we query the whole document collection. The result is a sub set D i of the collection where each document D ∈ D i contains at least one term of the query dimension Q i . These sets of document are precise because they contain explicitly dimensions terms that are in the query.</p><p>In order to solve the original multidimensional query, we have finally to combine these dimensions. It is done by a Boolean expression on the dimensions. In that way, a conjunction forces dimensions to be present together. We can reduce this constraint using a disjunction. We compute this Boolean dimension constraint formula using all sub sets {D i }.</p><p>We obtain a final sub set of document D that has been filtered by the ontology in two ways: first having at least one term from the query from a given dimension, and second by selecting some dimension to appears together in the selected document. For example, for an initial query Q containing three dimensions regarding the ontology O, sub query Q 1 , Q 2 and Q 3 are build, and D 1 , D 2 , D 3 are obtained after a disjunction Boolean retrieval. If we decide that a relevant document must include dimension 1 and dimension 2 or only dimension 3, we compute the sub document set by the boolean formula</p><formula xml:id="formula_1" coords="3,256.08,466.45,90.37,10.65">D = (D 1 ∩ D 2 ) ∪ D 3 .</formula><p>After this filtering, the next step is to query this sub set D using the full original query Q using the classical Vector Space Model, that gives us the final document ranking. A similar approach based on term pre-filtering before Vector Space Model querying has been apply in multilingual CLEF <ref type="bibr" coords="3,120.01,514.94,10.00,8.78" target="#b2">[3]</ref>. Another method to combine VSM querying and dimension filtering can be to perform the filtering after the vector querying (post filtering). Doing the other way just reduces the number of documents to deal with for the final ranking.</p><p>In the following sections, we detail the other use of ontology dimensions by negative vector extension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Negative weight for VSM</head><p>Vector Space Model (VSM) for Information Retrieval basically uses the inner product on term weight to compute the matching between document and query. In the case of a binary weighting, the inner product is the size of the intersection term set between document and query. If fact, even with non binary weighting, and for example with a normalisation of weight that leads the inner product to be the cosine value of the angle between the two vectors, the paradigm in use is still a sort of weighted term intersection.</p><p>Each vector dimension is associated to an indexing term. A non null value associated to a term (i.e. to its dimension) means that this term is relevant for the document indexed by this vector. In practice, this notion of relevance is closely related to the presence of this term into the document after some transformation like stemming. It follows that for large collection and for small document, most of the dimensions of a given vector are null. It means also that only query terms that participate to the intersection are effective for the computation of the Relevance Status Value (RSV or matching score) that ranks the document. A longer query may have no effect on the RSV.</p><p>As the underlying meaning of the matching process is term intersection, only positive weights are used in this model. Our idea is to exploit the fact that in a general vector space, the value of a weight can be negative. Using negative weight just enhances the expressivity of this model and enables to reuse both indexing technique and software. Negative weights can appear <ref type="bibr" coords="4,470.18,169.82,10.57,8.78" target="#b3">[4]</ref> during the relevance feedback process. As mention by Harman: "Generally a negative weight reflect the fact that a term has much higher distribution in non-relevant documents than in relevant ones [...]". Other approach to IR based from logic like in <ref type="bibr" coords="4,323.78,205.70,10.45,8.78" target="#b6">[7]</ref> suggests that negative weights could be an interesting way of explicitly expresses the notion of "non relevance". However, in this approach negative weighting is still related to relevance feedback.</p><p>We want to use ontology dimensions, and then to express term exclusion. Logic modelling is one way to achieve this goal by more powerful query expression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Logical negation</head><p>Beside the basic Boolean model which enables query to be any logical expression, some author promote the fact that the matching in Information Retrieval is closely related to a logical deduction <ref type="bibr" coords="4,90.00,323.66,10.01,8.78" target="#b8">[9]</ref>. For example, in <ref type="bibr" coords="4,178.92,323.66,10.57,8.78" target="#b1">[2]</ref> the closed world assumption is adopted.</p><p>In the logical IR model, a query matches a document if there is a deduction link from the document d to the query q. This can be modelled by the entailment d |= q. In this case, the matching is obtained when all models<ref type="foot" coords="4,252.36,357.45,3.97,6.97" target="#foot_0">1</ref> of the logic formula associated with d are included in those associated with q.</p><p>The more obvious choice for document associated formula is a model with only one interpretation. In IR, logical interpretations are easy to understand: a term t is associated to the true value for a document d (i.e. in the interpretation of the logic formula of the document d) if it is a relevant index term to d. Choosing only one logical interpretation to model a document, leads to unique interpretation for every term in the logic language and leads to a sort of close world assumption. In fact either a term is relevant (or a good index) for a document, either it is not. For d |= q example, given the set of possible index terms {a, b, c, d, e}, a document d indexed with a, b will have the following associated logic formula: a ∧ b ∧ ¬c ∧ ¬d ∧ ¬e. Then the set of terms {a, b, c, d, e} is then associate to only one interpretation: {t, t, f, f, f }.</p><p>On the query side, every logical formula can be used. The meaning is different from documents. We use direct terms (i.e. not negated) to describe the fact we want a term to be an indexing term of the document. We use a negated term to explicitly discard a term from being into the indexing set of the retrieved document. The conjunction is used to force two situations to be valid for the relevant document, and disjunctions are alternatives. If a term does not appear in the query it means that user has no particular needs concerning this term. It may or may not appear in a relevant document.</p><p>The query is associated to a set of logical interpretation. Adding a negated term reduces<ref type="foot" coords="4,491.52,572.61,3.97,6.97" target="#foot_1">2</ref> the set of interpretation and then reduces the set of relevant document.</p><p>This is exactly what we would like to use for expressing our query with ontology dimensions. For each ontology dimension, we would like to select on term and exclude all the others. Unfortunately the Vector Space Model does not enable logical negation in a query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Negation as negative weighed terms</head><p>The common way to introduce negation to VSM is to perform a post matching filtering. To our point of view, this solution is too strict because of the Boolean interpretation of the formula. If we keep the matching schema of the VSM with inner product, the evolution choices are limited. We could choose for example the Belief revision operator in <ref type="bibr" coords="5,328.57,116.42,10.55,8.78" target="#b5">[6]</ref> that seems to be a good extension VSM. But for these experiments, we finally decided to test a more simplistic extension. We propose to explore another possibility.</p><p>We would like to use the same paradigm as the logical modelling: adding a term to a query tends to reduce the matching possibilities. As we have seen earlier, this paradigm is false for the VSM. For example, there is no differences between a query a ∧ b ∧ c and the query a ∧ b for a document indexed only by {a, b}.</p><p>For that we refer to the logical modelling for IR and we add a second stage that transforms some interpretation set to a three valued vector the following ways: the true value t is associated to the value 1, the false value f is associated to -1. If there exists several interpretations in the set that are identical except for one value then we associated this interpretation to the value 0. In this way, we are not able to interpret every logical formulae but only conjunction of direct and inverse variables.</p><p>For example, given the term set {a, b, c, d, e}, a document indexed by the formula a ∧ b ∧ ¬c ∧ ¬d ∧ ¬e is associated to the vector {1, 1, -1, -1, -1}. The query a ∧ b ∧ ¬c is associated to the interpretation set: {{t, t, f, f, f }, {t, t, f, f, t}, {t, t, f, t, f }, {t, t, f, t, t}} and hence associated to the vector {1, 1, -1, 0, 0}.</p><p>Starting for this new modelling, we propose to still use the inner product V d × V q to compute the RSV. This matching is no more based on one term set intersection, but on the combination of four term set intersection (see formula above). In fact, the matching is the sum of the intersection of term within the same sign, minus the intersection of terms that are in opposition. In the following formula, we note V + the positive vector obtained from the positive of null value, and V -the positive vector obtained from the negatives or null values, so that</p><formula xml:id="formula_2" coords="5,184.44,377.37,296.17,47.41">V = V + -V -. RSV (d, q) = V d × V q = (V + d -V - d ) × (V + q -V - q ) = V + d V + q + V - d V --(V + d V - q + V - d V + q )</formula><p>With this model we have the following new properties compared to normal VSM:</p><p>• Adding a term to a query always change the RSV;</p><p>• For a given document the maximum RSV is obtained when the query has only one interpretation which is equal to the one of the document;</p><p>• A null RSV is possible event if document and query share common indexing terms.</p><p>It is then trivial to extend this model using fuzzy matching values for the weight of the vectors. In the following we present how we simplify and apply it to the CLEF experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Negative expansion on VSM using ontology</head><p>We make the two following assumptions: first we suppose terms are organized into an ontology hierarchy. Second, we suppose that a term in a query includes all other sub-term of the hierarchy but also excludes terms of other branches of the ontology. It is also a sort of close world assumption.</p><p>With this new model, one can then express queries with negated element to constraint and focus on some terms. This has been used for building a query that explicitly excludes indexing terms that are on the same ontology dimension. For example, if terms {a, b, c} and {d, e, f } belongs to the same ontology dimension, one build the query: (a ∧ ¬b ∧ ¬c) ∧ (d ∧ ¬e ∧ ¬f ).</p><p>Our extension has one implementation problem: every document have a full sized non null dimension. It means that the traditional inverse file is no more half empty. One second drawback is that one must complete document vector at indexing time with terms from the ontology.</p><p>For this first experiment we have then simplify the formula to:</p><formula xml:id="formula_3" coords="6,230.04,78.09,142.43,14.17">RSV (d, q) = V + d V + q -V + d V - q</formula><p>This simplify the problem and enables to test our approach for CLEF experiments but still have the drawback of having very large queries, because a lot of terms have then a non null value. For CLEF experiments, we have work on a reduced set of ontology dimensions terms to limit this problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Details of the indexing process</head><p>In this part we detail the indexing process and the use of the two models. For this experiment, we have decided to index all texts after a minimum of Natural Language Treatment. We have computed the part of speech (POS) of all documents of this collection. The simple treeTager <ref type="bibr" coords="6,500.04,213.62,12.95,8.78" target="#b7">[8]</ref> has been used for this task. For the indexing part, we have use the XIOTA experimental system <ref type="bibr" coords="6,90.00,237.50,10.00,8.78" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Basic sequence of document treatments</head><p>The first treatment that has been applied to the collection is some XML correction and some retagging actions. The XML correction is just the transformation of some characters (like '&lt;'), that should not appear in XML documents. For the MIR collection we have noticed a strong regularity in the document framework, and we have decided to reconstruct a documents framework by replacing some regular texts like "Brief history" into XML tags.</p><p>The second step on text treatment is the part of speech tagging. We think that for a precise information retrieval system, it is better to perform a filtering on POS tag than using a dictionary. We have used TreeTagger for this phase. Before the tagging we have selected the fields we think are worth value to be indexed. This step is very important because putting all the document fields could results on noise into the index, as avoiding some could lead to silence. In the following, we list the tag that has been retained: Starting from the part of speech tagging, all documents from the same language are following a parallel processing path. It means that we have in fact three sets of indexing for each of the three languages: French, English and German.</p><p>The next step is the selection of indexing terms. We have used a filtering on POS tags instead a classical stop words method. We have keep only nouns, adjectives and abbreviations<ref type="foot" coords="6,457.68,569.85,3.97,6.97" target="#foot_2">3</ref> . We finally obtain a term vector for each document in a given language. Documents in a given language from all collection are merged in the same indexing matrix. We have used the classical ltc indexing scheme of the vector space model for both query and document vectors.</p><p>Each query language is used to query the corresponding index matrix. The result is a set of documents IDF which are unique throughout the whole collection.</p><p>We finally make the fusion for all three languages by selecting only the best matching value when same document is retrieved from several languages in the same time. Taking the maximum value between languages just emphasis the language where the matching is more efficient to compute.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Negative dimension query expansion</head><p>In order to increase the precision of the system, we make a sort of closed word assumption relatively to a given ontology. We suppose that one term that appears in a query will exclude all other terms that could replace this term in the same level of the ontology.</p><p>We make the hypothesis that given a dimension (say Anatomy), only the term associate to the concept that appears in the query should be kept and all other should be avoid. We illustrate here some part of the MESH ontology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Body Regions [A01]</head><p>Abdomen For example, if in the query we have the term "Head", then every terms not under this concept should be set as irrelevant and will have a negative weight in the query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Results for CLEF 2005</head><p>For this test, we have limited ourselves to only two actual dimensions: anatomy and modality for all three languages. Also we have used a reduced term set for query negative expansion. The Boolean pre-filtering<ref type="foot" coords="7,180.00,431.61,3.97,6.97" target="#foot_3">4</ref> that has been used is only to force at least one ontology dimension to be present into the relevant document. Using this filter we obtain 20,75% of MAP (run IPALI2R_T) which is not an absolute good value but it is the second best value of all CLEF tests for this year.</p><p>We have then test the use of the negative query expansion. As this technique was new, we have decide limit the impact of this extension by using only two dimension, reducing the size of the ontology and by distributing the positive weight to the negative value so that the sum of all negative expansion of a term is equal in absolute value to the positive term weight. We show in the following a query example and the negative expansion of this query.</p><p>&lt;vector id="11" size="5"&gt; &lt;c id="head" w="0.4149327576"/&gt; &lt;c id="image" w="0.4474848211"/&gt; &lt;c id="mri" w="0.3636860549"/&gt; &lt;c id="sagittal" w="0.6271265149"/&gt; &lt;c id="view" w="0.3194260299"/&gt; &lt;/vector&gt; &lt;c id="abdominal" w="-0.0345777298"/&gt; &lt;c id="chest" w="-0.0345777298"/&gt; &lt;c id="liver" w="-0.0345777298"/&gt; &lt;c id="head" w="0.4149327576"/&gt; &lt;c id="image" w="0.4474848211"/&gt; &lt;c id="sagittal" w="0.6271265149"/&gt; &lt;c id="skin" w="-0.0345777298"/&gt; &lt;c id="abdomen" w="-0.0345777298"/&gt; &lt;c id="infarction" w="-0.0345777298"/&gt; &lt;c id="mri" w="0.3636860549"/&gt; &lt;c id="kidney" w="-0.0345777298"/&gt; &lt;c id="aorta" w="-0.0345777298"/&gt; &lt;c id="femur" w="-0.0345777298"/&gt; &lt;c id="brain" w="-0.0345777298"/&gt; &lt;c id="view" w="0.3194260299"/&gt; &lt;c id="heart" w="-0.0345777298"/&gt; With the combination of the two methods we have obtained the overall best text CLEF results of 20,84% of MAP (run IPALI2R_Tn). The increase of average precision using negative query expansion with an ontology is then encouraging. We explain this results by the fact document that are focus more clearly on one concept in one dimension are more precise and tend to be rank in better position than document that mixes different concept into the same ontology dimension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Results analysis</head><p>In this part, we detail some intermediate results we have done on the collection to better understand the influence of our model on the quality of the results. For these tests, the query dimensions are: Anatomy, Modality, and Pathology. Using the Vector Space Model on documents tagged with the POS analyzer, without taking into account the query dimensions, we obtain 17.25% of MAP. Using the negative query expansion, we then obtain 17.32% of MAP. It is a small improvement about 0.4%. The distribution of the weight of the positive term among the negative one, strongly limit the change in the RSV, and explain also the limitation of improvement. In fact we have made the following implicit hypothesis :</p><p>A document containing many different terms from the same ontology dimension is less relevant than a document containing terms from different ontology dimensions.</p><p>The negative terms expansion is a consequence of this hypothesis. The improvment obtained show that this hypothesis is valid for this particular test collection. In the following runs, we now always use the negative query expansion technique. To take into account the query dimensions, we have tested several assumptions, that leads to several Boolean dimension combinations.</p><p>Relevant documents must include at least one of the three query dimensions (if they exist) <ref type="foot" coords="8,495.60,496.17,3.97,6.97" target="#foot_4">5</ref>For this case, documents that contain anatomy, modality or pathology dimensions in the query, are relevant. For this run, the map is about 19.64%. So the improvement of the result is about 13.4%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relevant documents must include all the three query dimensions (if they exist).</head><p>For this case, the result has decrease. We think that it is due to the fact that the CLEF documents do not usually contain terms describing the modality. For this reason, we prefer the following assumption:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relevant documents must contain the anatomy and the pathology dimensions terms of the query.</head><p>In this case, our system provides a MAP of 21.39%. So the improvement, compare to the result of the previous run, is about 8.9%.</p><p>In the previous cases, we have supposed that all dimensions have the same importance in the query. This is assumption is not valid in all cases. Indeed, terms describing modality in the query are not discriminative. For example, a CT can be an image of a liver or emphysema, etc. We think also that the terms describing the pathology are, sometimes, non discriminative. For example, a lesion can be a lesion of a skin or a lesion of a nerve. For these reasons, we suppose that the anatomy is the most discriminative dimension. We also do the following assumption:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relevant documents must includes anatomy dimension terms of the query</head><p>For this run, the result is about 20.85%. Compare to the previous run, the result has decrease about 2.6%. But compare to the first run (only with negative query expansion), the result has increase about 20.4%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Mixing textual and visual index</head><p>Textual index has been merged with visual indexing. Visual medical indexing leaning based is described in <ref type="bibr" coords="9,145.31,220.10,10.55,8.78" target="#b4">[5]</ref> Text content is supposed to be closer to semantics, as image contains information that cannot be fully transcript into text. Our goal in this experiment is to show that combination of image and text index can give better results than separate results.</p><p>To compute the new raking list from image and text, as we are working on the same corpus (image ID), we have the hypothesis that the absolute relevance status value should be the same in the two list. In practice of course they differs. We have then to rescale the RSV of the two lists using a linear transformation so that the RSV of the top document is always equal to 1.</p><p>We have then proposed two simple merging techniques: for each document in both ranked list, either we keep the best (max) ranking value, either we compute an average value. Keeping the best value, follows the hypothesis that either one media (text or image) is best to answer a query, as computing the average supposes that both are always equally participating to the ranking. We have obtained the following results: Results show clearly that both visual and textual participate to the ranking. It is finally very interesting to notice that this combination outperforms both text only and image only by a large amount: from text using image increase 35% of MAP. In the same time, from image using text we measure an increase of 291% ! We can also notice that this combination outperforms all other methods used to index this collection this year. We can finally conclude that for this collection, the quality of text indexing seems to have a greater influence than expected. It can be explain by the fact that query are related to a focused domain, where a term is not really ambiguous and is related to a strong and precise meaning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">conclusion</head><p>The results we have obtained for this participation are very encouraging and tend to show the interest of the use of explicit knowledge when solving precise queries. Benefits of mixing text and image are also very clear. The use of an ontology seems useful either a final filtering and as a negative query expansion.</p><p>This work has been done under the IPAL I2R laboratory, a joint lab founded by CNRS from the French side and A-STAR from the Singaporean side. This work has also been done in relation with the French CLIPS IMAG laboratory and the Centre Universitaire d'Informatique of Switzerland.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,95.28,286.40,57.56,8.35;2,95.28,298.28,68.00,8.35;2,95.28,310.28,62.84,8.35;2,95.28,322.28,120.33,8.35;2,95.28,334.16,350.42,8.35;2,95.28,346.16,151.78,8.35;2,95.28,358.16,120.33,8.35;2,95.28,370.04,109.89,8.35;2,95.28,382.04,308.65,8.35;2,95.28,393.92,193.55,8.35;2,95.28,405.92,73.28,8.35;2,95.28,417.92,120.33,8.35;2,95.28,429.80,57.56,8.35;2,95.28,441.80,78.45,8.35;2,95.28,453.80,125.61,8.35"><head></head><label></label><figDesc>Anatomy [A] Organisms [B] Diseases [C] Chemicals and Drugs [D] Analytical, Diagnostic and Therapeutic Techniques and Equipment [E] Psychiatry and Psychology [F] Biological Sciences [G] Physical Sciences [H] Anthropology, Education, Sociology and Social Phenomena [I] Technology and Food and Beverages [J] Humanities [K] Information Science [L] Persons [M] Health Care [N] Geographic Locations [Z]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,90.00,420.09,435.38,8.95;6,114.96,432.14,115.16,8.78;6,90.00,450.69,272.51,8.95;6,90.00,469.29,278.18,8.95;6,90.00,487.89,169.56,8.95;6,90.00,506.61,131.09,8.95"><head></head><label></label><figDesc>CasImage: CASIMAGE_CASE ID Description Diagnosis ClinicalPresentation KeyWords Anatomy Chapter Department Title PathoPic (en): IMAGE ID Diagnosis Synonyms Description PathoPic (ge): IMAGE ID Diagnose Synonyme Beschreibung MIR: CASE ID IMAGES FINDINGS Peir: IMAGE ID Description</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,105.24,641.46,407.70,7.01;4,90.00,650.94,295.33,7.01"><p>We recall that a logical interpretation is a Boolean function that associates each term to a logical value. A model for a logic formula is an interpretation that turns the formula to be true.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,105.24,660.42,79.63,7.01"><p>In fact divide by two.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="6,105.24,697.14,332.24,7.01"><p>In the TreeTager notation is it the list NOM,ADJ,ABR,JJ,NN,NNS,NP,ADJD,ADJA,NE</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="7,105.24,684.66,407.69,7.01;7,90.00,694.14,182.52,7.01"><p>We have technically in fact a post filtering which is equivalent to pre-filtering and is here possible due to the small number of documents in this test collection</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="8,105.24,697.14,160.98,7.01"><p>We have manually discarded "image" term.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,105.49,84.02,407.46,8.78;10,105.48,96.02,407.57,8.78;10,105.48,107.90,257.20,8.78" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,206.69,84.02,306.26,8.78;10,105.48,96.02,237.18,8.78">X-iota: An open xml framework for ir experimentation application on multiple weighting scheme tests in a bilingual corpus</title>
		<author>
			<persName coords=""><forename type="first">Jean-Pierre</forename><surname>Chevallet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,354.96,96.02,158.09,8.77;10,105.48,107.90,162.86,8.77">Lecture Notes in Computer Science (LNCS), AIRS&apos;04 Conference Beijing</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">3211</biblScope>
			<biblScope unit="page" from="263" to="280" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,105.49,127.82,407.52,8.78;10,105.48,139.82,128.56,8.78" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,304.17,127.82,137.70,8.78">About retrieval model and logic</title>
		<author>
			<persName coords=""><forename type="first">Yves</forename><surname>Chiaramella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean</forename><surname>Pierre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chevallet</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,449.88,127.82,63.13,8.77;10,105.48,139.82,31.40,8.77">The Computer Journal</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="233" to="242" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,105.49,159.74,407.57,8.78;10,105.48,171.74,407.71,8.78;10,105.48,183.62,72.22,8.78" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,347.72,159.74,165.33,8.78;10,105.48,171.74,55.33,8.78">Ontology-based multilingual information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Jacques</forename><surname>Guyot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Saïd</forename><surname>Radhouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gilles</forename><surname>Falquet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,181.68,171.74,221.72,8.77">CLEF Workhop, Working Notes Multilingual Track</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-09-23">21-23 September 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,105.46,203.54,407.58,8.78;10,105.48,215.54,407.41,8.77;10,105.48,227.54,228.72,8.78" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,180.78,203.54,123.22,8.78">Relevance feedback revisited</title>
		<author>
			<persName coords=""><forename type="first">Donna</forename><surname>Harman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,325.80,203.54,187.23,8.77;10,105.48,215.54,403.58,8.77">SIGIR &apos;92: Proceedings of the 15th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,105.49,247.46,407.63,8.78;10,105.48,259.34,407.49,8.78;10,105.48,271.34,138.70,8.78" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,293.68,247.46,219.43,8.78;10,105.48,259.34,97.07,8.78">A structured learning approach for medical image indexing and retrieval</title>
		<author>
			<persName coords=""><forename type="first">Joo-Hwee</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean-Pierre</forename><surname>Chevallet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,228.72,259.34,240.12,8.77">CLEF Workhop, Working Notes Medical Image Track</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-09-23">21-23 September 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,105.49,291.26,407.49,8.78;10,105.48,303.26,407.57,8.78;10,105.48,315.14,407.52,8.78;10,105.48,327.14,153.15,8.78" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,272.17,291.26,240.81,8.78;10,105.48,303.26,108.17,8.78">Using a belief revision operator for document ranking in extended boolean models</title>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alvaro</forename><surname>Barreiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,236.40,303.26,276.65,8.77;10,105.48,315.14,320.06,8.77">SIGIR &apos;99: Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="66" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,105.49,347.06,407.70,8.78;10,105.48,358.94,407.37,8.78;10,105.48,370.94,243.58,8.78" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,272.61,347.06,240.57,8.78;10,105.48,358.94,51.89,8.78">Rating the impact of logical representations on retrieval performance</title>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alvaro</forename><surname>Barreiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,181.92,358.94,330.92,8.77;10,105.48,370.94,33.01,8.77">DEXA-2001 Workshop on Logical and Uncertainty Models for Information Systems</title>
		<meeting><address><addrLine>LUMIS-</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-09">2001. September 2001</date>
			<biblScope unit="page" from="247" to="253" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,105.47,390.86,407.49,8.78;10,105.48,402.86,339.23,8.78" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,182.73,390.86,244.85,8.78">Probabilistic part-of-speech tagging using decision trees</title>
		<author>
			<persName coords=""><forename type="first">Helmut</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,450.96,390.86,61.99,8.77;10,105.48,402.86,287.51,8.77">Proceedings of International Conference on New Methods in Language Processing</title>
		<meeting>International Conference on New Methods in Language Processing</meeting>
		<imprint>
			<date type="published" when="1994">sept 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,105.49,422.78,407.36,8.78;10,105.48,434.66,383.55,8.78" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,200.87,422.78,232.28,8.78">A new theoretical framework for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Van Rijsbergen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,453.24,422.78,59.60,8.77;10,105.48,434.66,259.67,8.77">ACM Conference on Research and development in Information Retrieval</title>
		<meeting><address><addrLine>Pisa</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1986">1986</date>
			<biblScope unit="page" from="194" to="200" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
