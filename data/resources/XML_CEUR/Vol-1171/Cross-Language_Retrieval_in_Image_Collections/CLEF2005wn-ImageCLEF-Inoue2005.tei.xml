<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,102.28,148.86,398.45,15.15;1,107.11,170.78,388.85,15.15">Recovering translation errors in cross-language image retrieval using word association models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,270.16,204.68,62.66,8.74"><forename type="first">Masashi</forename><surname>Inoue</surname></persName>
							<email>m-inoue@nii.ac.jp</email>
							<affiliation key="aff0">
								<orgName type="institution">National Institute of Informatics</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,102.28,148.86,398.45,15.15;1,107.11,170.78,388.85,15.15">Recovering translation errors in cross-language image retrieval using word association models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">FF4778D6CA0B5365853694A18DF8EC65</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.3 Information Search and Retrieval Model</term>
					<term>Learning</term>
					<term>Algorithm</term>
					<term>Effectiveness Image retrieval</term>
					<term>word association</term>
					<term>sparse data</term>
					<term>translation error</term>
					<term>model combination</term>
					<term>result merge</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Connecting short queries and short titles of relevant images is difficult. Different lexical expressions may be used in queries and captions that refer to the same concept. In the ImageCLEF2005 ad hoc task, we investigated the use of learned word association models that represent how pairs of words are related. We compared a precision-oriented simple word-matching retrieval model and a recall-oriented retrieval model with word association models, and we also investigated combinations of models. Experimental results on English and German topics are rather discouraging, as the use of word association models degraded performance. On the other hand, word association models help in retrieval for Japanese topics. Considering the relatively low quality of Japaneseto-English machine translation, this result may indicate that word association could play some role in recovering translation errors at the retrieval stage.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Retrieval of too many or too few documents for a query causes problems for the users of information retrieval (IR) systems. If given too many documents, they may experience difficulties in finding relevant documents among the results. On the other hand, if given too few documents, there will be little chance of finding relevant information. Of the above two problems, we consider the latter problem: insufficient retrieved results. More precisely, this problem can be divided into two sub-problems: 1) there are not enough relevant documents stored in the database, or 2) relevant documents are not retrieved by the system. We concentrate on the second sub-problem.</p><p>Typically in text retrieval, a shortage of retrieved documents is often caused by the problem of term-mismatch: the words in a query do not appear in most documents even though they are relevant to the query. This is essentially the same in ad hoc image retrieval when captions are used as the target of query matching. The difference is that sometimes the number of words in image captions is quite small and term-mismatches are likely to occur more often. One way to mitigate such mismatches is to use an enlarged query word set instead of the small query word set supplied by users. A typical technique is query expansion where some alternative query words are added to the original query from the document set based on relevance or pseudorelevance judgements.</p><p>In ImageCLEF2005, we studied the effects of word association models by employing a kind of probabilistic word-by-word query translation model structure <ref type="bibr" coords="2,374.00,510.25,9.97,8.74" target="#b3">[4]</ref>, although in our models, the actual translation took place by the MT system outside of the retrieval model. That is, the translation in the model is, in effect, the monolingual word expansion <ref type="bibr" coords="2,366.68,534.16,9.97,8.74" target="#b2">[3]</ref>. We tested our approach in the setting where both queries and annotations were short, which are frequently observed characteristics of text-based image retrieval. Concerning the differences between langages, we only considered the influence of machine translation (MT). Monolingual English-to-English, cross-lingual Germanto-English, and cross-lingual Japnanese-to-English image retrievals were compared. One finding from our experimental runs was that when the simple word matching strategy failed to retrieve relevant images because of erroneous translations, the use of word association models could improve the word matching. The conceptual process of translation error recovery by word association is depicted in Figure <ref type="figure" coords="2,184.88,629.80,3.88,8.74" target="#fig_0">1</ref>. In our runs, a recovery effect was observed only in Japanese-to-English translation, an example of translation between disparate languages.</p><p>In the following, we first introduce the ImageCLEF2005 image collection and the pre-processing applied to it. Second, we describe the run conditions and retrieval models used. Third, we show the retrieval results on the submitted runs. Finally, we conclude the paper with some discussion. 2 Data Preparation</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Test Collection</head><p>The test collection of ImageCLEF2005 consists of 28133 images and their captions in English from the St Andrews Library photographic collection <ref type="bibr" coords="3,329.47,311.38,9.97,8.74" target="#b0">[1]</ref>. Each caption has nine fields assigned by experts. These are 'Record ID', 'Short title', 'Long title', 'Location', 'Description', 'Date', 'Photographer', 'Categories', and 'Notes'. Such well-annotated images can be found in places such as digital museums and commercial photo collections but are rare in other cases. That is because casual annotators do not have enough knowledge to annotate images systematically, nor they do have any desire to spend time on annotations. For this reason, we are motivated to retrieve less carefully annotated images. Of the fields in the test collection, 'short titles' are considered to be the simplest form of annotation. Therefore, we used only short titles for indexing. The mean length of the short titles was 3.43 words . The distribution of lengths had a heavy tail on the short side. The size of the vocabulary was 9883 words for the documents, and 9945 for both documents and queries . The vocabulary contained three irregular words: 'null', 'untitled', and 'φ', where φ is introduced to represent empty titles. Topics of retrieval were described in three fields: short descriptions (titles), long descriptions (narratives), and example images. In our experiment, we used only short descriptions (titles), which can be regarded as typical queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Run Conditions</head><p>The main characteristics of our runs are summarized in Table <ref type="table" coords="3,364.78,525.03,3.88,8.74" target="#tab_0">1</ref>. The most notable point is that we used only the short title field. We were interested more in the exploitation of short text than in utilization of structured and multi-faceted text. Although we were also interested in the use of visual images, we were unable to advance to that level.</p><p>Another point we should mention is the use of 'Feedback/Expansion'. We used only expansion and not feedback. That is, we employed neither manual relevance feedback nor pseudo-relevance feedback. The models for the soft word expansion were built prior to querying and no candidate word selection process was used at the querying stage. The retrieval model we used is explained in 3.1.</p><p>The last factor is the query language. We examined English, German, and Japanese. We considered English topics as the baseline, German topics as the relatively 'easy' task, and Japanese topics as the relatively 'hard' task. Here, by 'easy' we mean that the current state-of-the art accuracy of machine translation is high and retrieval can be conducted in nearly the same fashion as with the source language. Similarly, by 'hard', we mean that queries differ substantially from the original ones after going through the machine translation process. According to the results of ImageCLEF2004 that consists of the same image dataset as ImageCLEF2005 but different topics, German topics yielded the highest average MAP score after English, and Japanese topics yielded the lowest average MAP scores for the top five systems <ref type="bibr" coords="3,333.78,728.27,9.97,8.74" target="#b0">[1]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Translation and Pre-Processing</head><p>The pre-processing we conducted to prepare data is summarized in Figure <ref type="figure" coords="4,413.42,411.48,3.88,8.74" target="#fig_1">2</ref>. As mentioned in the previous section, we used only the title fields of topics and short title fields of captions. Therefore, the initial step was the extraction of those fields from the collection. For topics, titles were surrounded by &lt;title&gt; tags; these tags were removed and the bodies of the titles were translated.</p><p>Although translation is part of the retrieval process, we explain the procedure of translation here because we carried out translations within the process of data preparation. Our approach to cross-language retrieval is query translation. According to previous experiments on ImageCLEF ad hoc data, query translation generally outperforms document translation <ref type="bibr" coords="4,421.95,495.16,9.97,8.74" target="#b1">[2]</ref>. We thought that the combination of query translation and document translation might be promising. However, as the starting point, we only consider query translation here. German and Japanese topics were translated into English, the document language, using the Babelfish web-based MT system<ref type="foot" coords="4,484.23,529.45,3.97,6.12" target="#foot_0">1</ref> . The translation was done manually: we entered queries in a web form and their respective translations were returned, and punctuation and extra white spaces were removed. The results of translation are shown in Appendix A. Punctuation in the short titles was also removed. Finally, all upper case letters were converted to lower case, and both queries (titles) and documents (short titles) were indexed together.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Qualitative Analysis of Translation Errors</head><p>The results of machine translation usually contain errors that may affect the performance of IR at a subsequent stage, but the relationship is not straightforward. For example, when a word is translated into 'photographs' when it should be translated to 'pictures', this difference has little effect in understanding sentences that contain the word. Therefore, it may not be considered an error. However, for IR, and image retrieval in particular where only short text descriptions are available, such a difference may change the results of retrieval drastically. For instance, when all relevant images are annotated as 'pictures', a query translated as 'photographs' cannot retrieve them. On the other hand, when all relevant images are annotated as 'photographs', the mistrans-lation benefits the retrieval process. Here, we analyse the results of machine translation of queries from the point of view of their effect on IR. First, we examine the overall quality of the translations. Translation from German to English was performed well. Among 28 topics (titles), four topics were translated exactly as in the original English -topic numbers 3, 5, 6, and 18 in A.2. This result confirms the relatively high accuracy of German-English MT. Notable errors in German-to-English translation were related to prepositions. For example, 'at' in topic 1 should be 'on', 'of' in topic 12 should be 'from', and 'on' in topic 14 should be 'at'. Other typical errors were inappropriate assignment of imprecise synonyms. For example, in topic 1 'ground' is replaced by 'soil', and in topics 10 and 28 'picture' is replaced by 'photographs'. Despite these errors, in most translation results from German, the basic meanings of topics were similar to the original English. More problematic was that three words were not translated into English: 'Fischer' in topic 7, 'puttet' in topic 15, and 'Portraitaunahmen' in topic 26. For simplicity, we treated them as if they were English words. Additionally, the MT system did not translate 'kutsche' into any word.</p><p>For Japanese-to-English translation, the quality of translation was apparently worse (see A.3). Some of the Japanese words could not be translated at all. Untranslated words were 'aiona (Iona)', 'nabiku (waving)', and 'sentoandoryusu (St Andrews)'. The problem here is that the untranslated words were often proper nouns, which might be useful for distinguishing relevant documents from irrelevant documents. Ideally, such out-of-vocabulary words should be translated by using other external sources, such as larger and more up-to-date dictionaries or by transliteration. In this experiment, however, we simply eliminated such untranslated non-ASCII characters from the translation results.</p><p>In German-to-English translation, the above two proper names (Iona and St Andrews) could be translated with no problem. This difference can be understood easily by the fact that, in German topics, the words were spelled in the same way as in English. Therefore, no translation was necessary. On the other hand, in Japanese topics, the translator had phonetically converted them from the original English topics to katakana characters. Therefore, untranslated words could not be used as is. Another factor to be considered is that phonetic transcription is not unique. Therefore, even if there was an entry for the word in the dictionary, the back translation by MT systems might not find a relevant entry because of the phonetic ambiguities.</p><p>In addition to the above out-of-vocabulary word problems in the MT system, the Japaneseto-English translations contained errors in prepositions similar to those in the German-to-English translations. Errors that were peculiar to the Japanese-to-English translations were the excessive use of definite articles and relative pronouns. We hypothesize that such translations were derived from the design of the MT system, which was designed not for the translation of short phrases such as titles, but for larger units of text such as paragraphs. Thus, the MT system tried to produce natural sentences by adding definite articles and relative pronouns to fill the gaps between grammatically disparate languages. Short query translations may require choosing either a sophisticated MT system or simple word-by-word translation, depending on the difficulties of translation.</p><p>So far, we have discussed the quality of the topic translations assuming that both German and Japanese topics are equivalent to the English topics in terms of their contents. However, it may be noteworthy that they are the translations from the original English topics. Since relationships between expressions in different languages are not one-to-one, a non-English topic used here was one of many possible translations. Moreover, the expressions in translated queries might not be typical as the queries in that language even if they were correct translations of typical English queries. Therefore, the translation errors analysed above were possibly caused by both machine translation at retrieval stage and by translation ambiguities at topic preparation stage. Although this is not negligible, because it is too involved a subject to be treated here in detail and we can expect the translations by experts were far better than machine translation, we do not consider the influence by the translations when topics were created.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Retrieval Models</head><p>We introduce retrieval models based on the unigram language model and word association model. The baseline model is the simple keyword matching document model denoted by diag. For the query q = {q 1 , ..., q K }, the probability of q is</p><formula xml:id="formula_0" coords="6,272.27,198.48,58.34,30.55">K k=1 P (q k |d n ),</formula><p>where d n indicates the nth document or image. For the word association model, we estimated the following transitive probabilities from the jth word to the ith word in the vocabulary:</p><formula xml:id="formula_1" coords="6,280.01,271.81,42.83,16.37">P (w i |w j ).</formula><p>When the above two models are combined, the following model represents the process of query generation:</p><formula xml:id="formula_2" coords="6,244.62,324.58,113.55,30.56">K k=1 V i=1 P (q k |w i )P (w i |d n ).</formula><p>Here, we assume independence between query words: P (q) = K k=1 P (q k ), although this is not always true for the ImageCLEF2005 topics, where titles are sometimes sentential and word orders have meaning.</p><p>The word association models can be estimated in various ways, disregarding the statistical justification. We tried three methods. In all three methods, we regarded the frequencies cooccurrence of two words as the measure of word association. If two words co-occurred, they were assumed to be related. The first method counts self co-occurrences, where a word is regarded as co-occurring with itself, as well as co-occurrences. Values for each term pair are estimated as follows:</p><formula xml:id="formula_3" coords="6,181.71,480.99,96.77,23.27">P (w i |w j ) = #(w i , w j ) #(w j )</formula><p>where i ̸ = j and #(w j ) &gt; 0,</p><formula xml:id="formula_4" coords="6,181.83,508.90,133.66,23.24">P (w i |w i ) = #(w i , w i ) + #(w i ) #(w i )</formula><p>where #(w i ) &gt; 0.</p><p>Here, #(w i , w j ) represents the frequency of co-occurrence of w i and w j (appearance of the two words in the same image caption), and #(w j ) represents the frequency of occurrence of w j . This procedure strengthens self-similarities in the model and is termed cooc. The second method counts purely co-occurring pairs and is named coocp. Values for each term pair are estimated as follows:</p><formula xml:id="formula_5" coords="6,251.01,598.11,100.85,23.24">P (w i |w j ) = #(w i , w j ) #(w j ) .</formula><p>The third method normalizes the frequencies of co-occurrences (w i and w j ) by the frequencies of the word w j :</p><formula xml:id="formula_6" coords="6,245.23,664.42,112.44,23.23">P (w i |w j ) = #(w i , w j ) #(w i )#(w j ) .</formula><p>This method is termed cooct. The baseline model that does not use word association models can be interpreted as using a diagonal word association model with non-zero elements that are all one. This is why we denoted it as diag.</p><p>Note that these models were estimated prior to the arrival of queries and the computation at query time focused on score calculation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Scoring Functions</head><p>Our runs were divided into two groups according to the scoring function employed. In the first group, documents were ranked according to the query-log likelihood of document models. As we used unigram language models for each document, the scoring function for the nth document given the query q is written as:</p><formula xml:id="formula_7" coords="7,247.76,186.97,107.45,30.55">log L = K k=1 log P (q k |d n ),</formula><p>where K is the length of the query. When a word association model is used, the function becomes</p><formula xml:id="formula_8" coords="7,220.11,248.90,162.68,30.56">log L = K k=1 log V i=1 P (q k |w i )P (w i |d n ),</formula><p>where V is the vocabulary size. Runs based on these functions were marked with log_lik.</p><p>In the second group of runs, documents were ranked according to the accumulated information for all matched words. First, we transform the variable for the probability of query word q k , P (q), to F q = e (log P (q)) -1 where P (q) is either P (q|d n ) or V i=1 P (q|w i )P (w i |d n ) and is considered only when P (q) ̸ = 0. Then, the new scoring function can be defined as:</p><formula xml:id="formula_9" coords="7,257.14,360.72,88.40,30.55">log L ′ = K k=1 log 1 F q k .</formula><p>We regard log 1</p><p>Fq k as the information on query word q. A document with a higher score is assumed to have more information on the query. In general, when an expansion method is involved, the number of terms matched between queries and documents increases. Consequently, the scores of documents given by the first scoring measure log_lik are larger in models with expansion than in those without. Thus, the first scoring measure is not suited for the comparison of output scores between different models. The second measure was derived heuristically and is intended to allow combining the outputs of different models. Runs based on this measure were marked with vt_info.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Model Output Combination</head><p>When the vt_info measure is used, the combination of different models at the output level is simple because their scores are directly comparable. First, two sets of document scores and corresponding document indices from two models are merged. Then, they are sorted in descending order of scores. For each document, the higher score is retained. This assumes that lower scores usually correspond to lack of knowledge about the documents and are thus less reliable. From the eventual rank, the top M documents will be extracted as the final result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimental Results</head><p>We submitted 16 runs (files), consisting of eight for English, four for German, and four for Japanese topics. We used wam as the group name. The names of submission were formed as the concatenation of group name, scoring function, word association model, and query language. Regarding the word association model, dc represents the combination of diag and cooc using the method described in 3.3. For English topics, the following runs were submitted: wam_log_lik_diag_e wam_log_lik_cooc_e wam_log_lik_coocp_e Each file contained 980 scores (the 35 top scores for each of 28 topics). We made a mistake when creating the submission files and could not obtain any meaningful official results for these submissions. The figures of mean average precision (MAP) scores in Table <ref type="table" coords="8,429.24,537.35,4.98,8.74" target="#tab_1">2</ref> are based on the runs we intended to submit. They were calculated after we received the list of relevant images for each topic (qrel file). Overall, our retrieval performances were insufficient. For comparison, we included the MAP scores of the best runs from other participants, as shown at the bottom of Table <ref type="table" coords="8,118.00,585.17,3.88,8.74" target="#tab_1">2</ref>. They are CUHK-ad-eng-tv-kl-jm2 for English topics, R2D2vot2Ge for German topics, and AlCimg05Exp3Jp for Japanese topics. For English runs, we also cited the MAP score of an example run imirt0baset0enen with run conditions similar to ours (title query and short title index).</p><p>Having observed the difference between our runs and others, we may now turn to the analysis of our own runs. In English, our best run was actually the diag model, which we had considered as the simplest baseline. In contrast, all models with word association underperformed. There are two possible explanations for this result. First, there was no need to relax the limitation of exact term matching. Some relevant documents could be retrieved by word-by-word correspondence and other relevant documents could never be reached by word-level expansion. Second, the word association models were not learned adequately, so they could not help with connecting query words and document words. To clarify which of these two reasons led to this result, we must analyse the data set further. This relationship between the diag model and other cooc-type models was the same for the German topics. When the vt_info scoring function was used, an important observation is that the MAP scores for cooc and cooct were the same and those for diag and dc were nearly the same. By analysing the performances for individual topics, we found that cooc and cooct behaved in the same way.</p><p>Further analysis is required to understand this phenomenon. For dc, by analysing the influences of the two models, we observed that the diag model dominated the top scores. We had expected this tendency, because an exact-matching scheme should have higher confidence in its outputs when queries can find their counterparts. What was unexpected was that the dominance of the diag model often ranged from the top rank to about the 1000th rank, and scores given by cooc models appeared only in lower ranks. Even though the ranking was determined by the interlaced ranks from both models, because we had submitted only the top 35 ranks, the resulting MAP scores were determined almost solely by the diag model. This outcome was not desirable. For topics 2 and 18, the cooc models worked better than the diag models. Nevertheless, as explained above, the benefit of the cooc models was not taken into account in the final results of the dc method. We must consider a better way of rank merging so as not to miss such opportunities.</p><p>As we can see in Table <ref type="table" coords="9,205.59,279.40,3.88,8.74" target="#tab_1">2</ref>, the trends of model discrepancy were similar in English and German topics. However, in Japanese topics, the use of word association models (cooc) improved performance in both scoring functions. For an explanation of this reversal effect, we can consider the quality of translation. In the diag model, when English and Japanese topics were compared, the retrieval performance simply degraded as the translation quality degraded. In contrast, the word association models might provide some improvement. It may be considered as recovering from the translation errors that caused mismatches in the retrieval process. However, the relationship between translation quality and the positive effects of word association models was not simple because it was not monotonic. When comparing diag and cooc in English and German topics, even though German topics contained some translation errors, the degradation of performance by using cooc was severer in German than in English. This problem may be better understood by considering additional languages with varying translation difficulties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head><p>In our runs, we observed that the use of word association models might help recover query translation errors given by MT systems. However, because our system performed quite poorly in terms of MAP scores, it is difficult to generalize this finding. We need to improve the baseline models to some reasonable level. In the pre-processing and the retrieval models we employed, we did not consider the following three factors that are important to IR performance: 1) idf, 2) stop words, and 3) document length. Incorporation of these factors into the modelling may be the first step towards obtaining a reasonable performance.</p><p>If the use of word association models in cross-language retrieval is beneficial for mitigating the effect of translation errors, a similar effect should be observed in other types of expansion techniques. Although we do not know the details of expansion techniques used by other participants, it seems that the use of 'Expansion/Feedback' techniques improved performance in most languages. We would like to see if these expansion techniques at query time serve as a more powerful component of retrieval when translation is erroneous than when translation is error free.</p><p>Another direction of interest lies in the design of MT systems. In our runs, we used an MT system with a single output. If we had used an MT system with multiple candidate outputs with their confidence scores, the system would have performed the soft expansion by itself. It is not clear whether using such MT systems with our models will improve or degrade the retrieval results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Future Work</head><p>Text-based image retrieval that relies on short descriptions such as titles is considered to be less robust to translation errors. In the experiments on the ad hoc task in ImageCLEF2005, word association models helped with the retrieval of Japanese topics when translation into English using the machine translation system was quite erroneous. We hypothesize that this could be explained by the recovery effect given by word expansion. The above argument might be verified by comparing various languages with different degree of difficulties in English translation.</p><p>Two important extensions we could not investigate were the utilization of visual information and the exploitation of training data sets. We are particularly interested in how the use of these will help retrieval for difficult topics in which visual or contextual information plays a vital role.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,90.00,408.63,423.05,8.74;2,90.00,420.58,30.21,8.74"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Schematic diagram for the process of recovering translation errors using word association models</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,117.50,360.71,363.59,8.74"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Data pre-processing for documents (image captions) and queries (topics).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,185.79,118.94,231.42,103.18"><head>Table 1 :</head><label>1</label><figDesc>Summary of run conditions</figDesc><table coords="3,185.79,139.24,231.42,82.88"><row><cell>Query Language</cell><cell>English/German/Japanese</cell></row><row><cell>Initial Query</cell><cell>title</cell></row><row><cell>Query Type</cell><cell>automatic</cell></row><row><cell>Feedback/Expansion</cell><cell>with</cell></row><row><cell>Modality</cell><cell>text</cell></row><row><cell>Document Type</cell><cell>short titles</cell></row><row><cell>Translation</cell><cell>machine translation</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,90.00,118.94,375.15,383.60"><head>Table 2 :</head><label>2</label><figDesc>Summary of mean average precision scores for the submitted runs</figDesc><table coords="8,90.00,139.27,370.19,363.27"><row><cell></cell><cell></cell><cell></cell><cell cols="2">Scoring Function</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>log-lik</cell><cell></cell><cell></cell><cell>vt-info</cell><cell></cell></row><row><cell>Method</cell><cell cols="6">English German Japanese English German Japanese</cell></row><row><cell>diag</cell><cell>0.0263</cell><cell>0.0160</cell><cell>0.0062</cell><cell>0.0108</cell><cell>0.0082</cell><cell>0.0057</cell></row><row><cell>cooc</cell><cell>0.0161</cell><cell>0.0045</cell><cell>0.0085</cell><cell>0.0089</cell><cell>0.0032</cell><cell>0.0088</cell></row><row><cell>coocp</cell><cell>0.0049</cell><cell>N.A.</cell><cell>N.A.</cell><cell>0.0010</cell><cell>N.A.</cell><cell>N.A.</cell></row><row><cell>cooct</cell><cell>N.A.</cell><cell>N.A.</cell><cell>N.A.</cell><cell>0.0089</cell><cell>N.A.</cell><cell>N.A.</cell></row><row><cell>dc</cell><cell>N.A.</cell><cell>N.A.</cell><cell>N.A.</cell><cell>0.0107</cell><cell>N.A.</cell><cell>N.A.</cell></row><row><cell></cell><cell></cell><cell cols="3">Runs by other participants</cell><cell></cell><cell></cell></row><row><cell cols="2">Highest submitted 0.4135</cell><cell>0.3375</cell><cell>0.2811</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Similar setting</cell><cell>0.1798</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>wam_vt_info_diag_e</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>wam_vt_info_cooc_e</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">wam_vt_info_coocp_e</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">wam_vt_info_cooct_e</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>wam_vt_info_dc_e</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>For German topics:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>wam_log_lik_diag_g</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>wam_log_lik_cooc_g</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>wam_vt_info_diag_g</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>wam_vt_info_cooc_g</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>For Japanese topics:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>wam_log_lik_diag_j</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>wam_log_lik_cooc_j</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>wam_vt_info_diag_j</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>wam_vt_info_cooc_j</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,105.23,747.00,110.59,6.99"><p>http://babelfish.altavista.com</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,105.49,226.57,407.59,8.74;10,105.50,238.52,270.23,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,301.45,226.57,211.62,8.74;10,105.50,238.52,60.74,8.74">The CLEF cross language image retrieval track (ImageCLEF)</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mueller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,209.12,238.52,135.97,8.74">ImageCLEF2004 Working Note</title>
		<imprint>
			<date type="published" when="2004">2004. 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,105.49,258.44,407.51,8.74;10,105.50,270.39,140.37,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,171.96,258.44,285.44,8.74">Caption vs. query translation for cross-language image retrieval</title>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,483.18,258.44,29.82,8.74;10,105.50,270.39,109.73,8.74">Image-CLEF2004 Working Note</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,105.49,290.31,407.57,8.74;10,105.50,302.26,407.48,8.74;10,105.49,314.22,101.32,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,253.80,290.31,255.41,8.74">Retrieving lightly annotated images using image similarities</title>
		<author>
			<persName coords=""><forename type="first">Masashi</forename><surname>Inoue</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Naonori</forename><surname>Ueda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,117.27,302.26,314.12,8.74">SAC &apos;05: Proceedings of the 2005 ACM symposium on Applied computing</title>
		<meeting><address><addrLine>NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-03">March 2005</date>
			<biblScope unit="page" from="1031" to="1037" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,105.48,334.14,407.51,8.74;10,105.48,346.10,137.24,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,275.40,334.14,103.37,8.74">Transitive CLIR models</title>
		<author>
			<persName coords=""><forename type="first">Wessel</forename><surname>Kraaij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Franciska</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jong</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,401.43,334.14,22.94,8.74">RIAO</title>
		<meeting><address><addrLine>Vaucluse, France</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">April 26-28 2004</date>
			<biblScope unit="page" from="69" to="81" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
