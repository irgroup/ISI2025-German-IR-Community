<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,161.11,115.90,293.14,12.90;1,235.96,133.83,143.43,12.90;1,223.43,153.68,168.50,10.75">The Encoplot Similarity Measure for Automatic Detection of Plagiarism Notebook for PAN at CLEF 2011</title>
				<funder ref="#_ZMrCkda">
					<orgName type="full">European Commission -Capacities Area -Research Infrastructures</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,227.87,190.08,62.80,8.64"><forename type="first">Cristian</forename><surname>Grozea</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Fraunhofer Institute FIRST</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,319.09,190.08,63.92,8.64"><forename type="first">Marius</forename><surname>Popescu</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Bucharest</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,161.11,115.90,293.14,12.90;1,235.96,133.83,143.43,12.90;1,223.43,153.68,168.50,10.75">The Encoplot Similarity Measure for Automatic Detection of Plagiarism Notebook for PAN at CLEF 2011</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4A1F1B792ED61FCA756239D9BB6DF11A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the evolution of our method Encoplot for automatic plagiarism detection and the results of the participation to the PAN'11 competition. The main novelties are the introduction of a new similarity measure and of a new ranking method, which cooperate to rank much better the sourcesuspicious document pairs when selecting the candidates for the detailed analysis phase. We have obtained excellent results in the competition, ranking 1 st on the manually paraphrased cases, 2 nd overall in the external plagiarism detection task, and getting the best recall on the non-translated corpus.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Encoplot is an automatic method for plagiarism detection developed by the authors. It was first introduced in the PAN'09 competition, where it has outperformed all other competing methods <ref type="bibr" coords="1,215.69,416.68,10.58,8.64" target="#b2">[3]</ref>. It has been since then enhanced, parallelized and used also for detecting the direction of plagiarism <ref type="bibr" coords="1,281.69,428.64,10.58,8.64" target="#b5">[6]</ref>.</p><p>For this year's competition a new similarity measure for the candidate documents retrieval phase has been introduced, aiming to increase the quality of the ranking and implicitly allowing for an increased recall. Apart from the improvement of the recall, this new similarity measure increases the consistency of the encoplot method, the same strategy being now used both in the candidate documents retrieval phase and in the detailed analysis phase, making thus more probable that a correct find in the first phase will not be missed by the second phase and the other way around.</p><p>All details omitted here for brevity are given in the extended version of this paper, available online <ref type="bibr" coords="1,200.17,536.23,10.58,8.64" target="#b3">[4]</ref>, along with figures suitable for viewing without rescaling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods: Encoplot</head><p>Encoplot is both the name of the plagiarism detection system we have developed and used, and the name of the pairwise document comparison algorithm at its core. For the sake of completion, we describe these again here to the extent the available space allows for, marking also the changes to the version described in <ref type="bibr" coords="1,396.21,626.13,10.58,8.64" target="#b2">[3]</ref>, where optimized C-language code is included. corresponding author -cristian.grozea@brainsignals.de</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The Core Encoplot Algorithm for Comparing Two Documents</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Input:</head><p>-A and B, two strings of length l A and respectively l B over some alphabet Σ.</p><p>-N , a natural number -the length of the N-grams.</p><p>Output: E ⊆ {1 . . . l A } × {1 . . . l B }, such that:</p><p>-For each (u, v) ∈ E the N-grams A(u. . . u+N-1) and B(v. . . v+N-1) coincide.</p><p>-Each index appears at most once: Algorithm:</p><formula xml:id="formula_0" coords="2,141.74,227.39,338.85,33.20">(u, v) ∈ E, (u, v ) ∈ E ⇒ v = v ; (u, v) ∈ E, (u , v) ∈ E ⇒ u = u . -For each N-gram w ∈ Σ N , let n w A, n w B</formula><p>1. Extract and sort the N-grams in A, let the result be denoted by S A ⊆ {1 . . . l A } × Σ N . The serial implementation produces a sorting index with a radix sort specialized in sorting N-grams. 2. Do the same for B, let the result be denoted by S B ⊆ {1 . . . l B } × Σ N . 3. Intersect with a merging procedure the projections of S A and S B on their second component, while reporting the values in the first component for the matches.</p><p>Note that the set produced by encoplot for two documents is a subset of the set of "dots" produced by the well-known method dotplot <ref type="bibr" coords="2,342.33,425.21,10.58,8.64" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The Clustering Heuristic</head><p>The heuristic employed for clustering the "dots" produced by the encoplot core algorithm into passages is ommited here for brevity, being included in the extended version of this paper, available online <ref type="bibr" coords="2,254.56,496.07,10.58,8.64" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">The Encoplot Plagiarism Detection System</head><p>A run of the whole system consists in the following steps:</p><p>1. Preprocess the text, text normalization (including translation when needed). 2. Compute a similarity matrix with one value for each (source document, suspicious document) pair. 3. Rank the document pairs based on their similarity. <ref type="bibr" coords="2,139.25,607.89,3.74,8.64" target="#b3">4</ref>. Analyze the highest ranked pairs in detail, with the following sub-steps:</p><p>-Apply the core encoplot algorithm described above on the two texts and obtain the encoplot data. -Cluster the matches of N-grams into matches of passages, using the heuristic algorithm mentioned above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Changes to the System</head><p>Translation and text normalization are new features for our system.For selecting the candidate pairs for detailed analysis, we have introduced both a new similarity measure and a new ranking method.</p><p>The new similarity measure leverages the ideas of core encoplot algorithm, by computing the encoplot set for the pair of documents of which the similarity is evaluated, followed by a projection of it on the source axis, and a counting of in how many positions a moving window of fixed size (256 characters) contains a number of N-grams matches above a fixed threshold (64). This count is taken to be the similarity of the two documents.</p><p>Once the similarity measure matrix is obtained (11093x11093 in this case), we need to rank the pairs based on those values. In the previous years we have considered and contrasted ranking all sources for a given suspicious document and ranking all suspicious documents for a given source. Which one is best, depends much on the dataset ( <ref type="bibr" coords="3,185.20,295.07,10.37,8.64" target="#b4">[5]</ref>), therefore we have decided to combine the two rankings into a single ranking that guarantees that whichever pair was selected by either one of those, will be selected by the combined ranking as well. For this we built the min ranking r min (pair) = min(r sources (pair), r suspicious (pair)), where r sources (pair) is the rank of the pair in its column in the similarity matrix and r suspicious (pair) is its rank in the row containing it in the same matrix.</p><p>The detailed analysis remained almost unchanged, still we have had to do a change related to a serious problem the 2010 competition corpus had, namely some of the passages from the source were copied multiple times into the destination suspicious document -a substantial amount: out of 55723 external plagiarism instances, 10694 (&gt; 19%) had the multiplicity at least 2, 3483 multiplicity at least 3. The maximum multiplicity of a single passage was 17 (!).</p><p>This probably explains our suspiciously low recall in the 2010 competition on the non-obfuscated cases (and other subcorpora). As a side effect of the speed and space optimizations the core encoplot algorithm offers over dotplot, for the simple case when there is no obfuscation at all and just verbatim copying multiple times, only the first copy of a passage is matched. To understand why, remember that each position in the source is paired with at most one position in the suspicious document. Therefore a full match of the source passage fully "consumes" it, and it cannot match any of the subsequent copies. Having a second copy of the same passage in the source would allow for a second match and so on. To cope with that, we have concatenated each source with itself 4 times before analyzing the pair in detail with our heuristic, creating thus 4 copies in the source of each passage previously there. The number 4 has been chosen as a compromise, balancing the effort and the expected increase in recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Software Infrastructure</head><p>For parallelizing the computation of the similarity matrix we have switched from OpenMP to the framework StarSs <ref type="bibr" coords="3,231.62,632.53,10.58,8.64" target="#b6">[7]</ref>, developed at the Barcelona Supercomputing Center (BSC). The advantage of this task-based parallelization framework is that with simple annotations, tasks can be defined that are executed then in parallel on different execution threads. The necessary tasks dependency detection, locking and thread-to-thread communication and data transfers are performed automatically by the framework. We have developed this version of the code during a HPC Europa2 virtual visit to the BSC, where the first author had the chance to work together on this with Jesus Labarta, Rosa M. Badia and Aislan Gomide Foina and to run the code on machines with up to 256 cores (article in preparation).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Processing Speed</head><p>The main machine used was a 12-core machine: 2xAMD 6-core Opteron 2427 64bit 2200 MHz in our multi-core lab.</p><p>Translation was prohibitively slow, and there was not enough time for it (just 48h), see the Discussion section in <ref type="bibr" coords="4,250.69,291.92,11.62,8.64" target="#b3">[4]</ref> for more. Other preprocessing took less than 1 hour on this machine. The computation of the similarity matrix took 24h on the same machine. Ranking took a few minutes. The detailed analysis took 24h on the local Condor cluster (34 cores).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Dataset</head><p>This year's competition test data consisted of 11093 source documents in English, German (about 500) and Spanish (about 200).</p><p>There were 49621 plagiarism cases, more than 10% of which involved translation. The distribution of their types is given in Table <ref type="table" coords="4,324.03,414.32,3.74,8.64" target="#tab_0">1</ref>.</p><p>At document level, out of all 120 million document pairs, only 17674 contained plagiarism cases.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Analysis</head><p>As our method consists of two distinct phases, ranking the document pairs followed by detailed analysis of the selected ones, it is useful to measure the performance in each phase, in order to be able to contrast the alternative approaches.</p><p>The purpose of the ranking is to identify the pairs of documents for which there is a high chance that there is at least one plagiated passage from the source to the suspicious document. An ideal ranking should put first the pairs where such a relation exists and last the other pairs. A good ranking should be an approximation of this. It should enable the achievement of a good recall at document level without having to select too many document pairs. Note that all rankings (even a random one) will achieve a recall of 100%, the latest after selecting all pairs. What is important is how fast the recall is increasing when the selection is extended to include more and more of the document pairs, as ranked.</p><p>For examining the performance of the ranking, we have considered two types of graphs: effort versus recall -where the recall is shown together with the number of pairs needed to achieve that recall -and a standard precision versus recall. On the 2010 competition data, the effect of the new similarity ranking is impressive. Both on the "effort versus recall" plots (Figure <ref type="figure" coords="5,320.85,367.69,15.49,8.64" target="#fig_1">1(a)</ref>) and in the "precision versus recall" plots (Figure <ref type="figure" coords="5,187.48,379.64,10.92,8.64" target="#fig_1">1(c</ref>)), the new similarity method outperforms the standard one consistently by a great margin.</p><p>On the 2011 competition data, while it still dominates in the "affordable effort" range, it is eventually outperformed by the standard kernel coupled with min rank, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Results</head><p>The results on the 2011 competition data are summarized in Table <ref type="table" coords="5,400.43,491.77,3.74,8.64" target="#tab_0">1</ref>. Our team has ranked 2 nd on the external plagiarism detection task.</p><p>We have had the best score among all teams on the category that mimics best the real human plagiarism: manual paraphrasing. Also we have had the best recall values on manual paraphrasing and on both subcategories of automatic paraphrasing.</p><p>By using the annotations provided we have been able to compute for all teams the recall on the non-translated cases subcorpus. We lead also there, with 0.3512, followed by the team that ranked first with 0.3468. It was impossible to compute the precision on the same subcorpus without having access to the answer files of the other teams.</p><p>We have tested the new method also on the 2010 competition data, on which it had a plagdet score 0.72, with recall 66% and precision 86%. These results are very encouraging, they would have ranked our method on the second place, without even handling the translated cases (14%) -whereas the team which ranked first in 2010 did handle those too.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>The distribution of the plagiarism types in this year's test data is far from matching their distribution in the training corpus, PAN-PC-10 [9]. Most notably, the amount of passages copied without changes (no obfuscation, no translation) was heavily reduced, from 40% to less than 2%. Therefore, tuning on the training corpus could have been to the disadvantage of the participants. We were consistent with our previous approach of not tuning our method to a particular and still mostly artificial training corpus. This may explain to some extent our top performance in the cases of human plagiarism, which is the only one of practical interest. We expect that the next corpora will contain more and more such human and manually simulated plagiarism to the detriment of the artificially generated using questionable choices (see the repeated insertion of the same passage from one source into a single destination suspicious document mentioned above).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">The Issue with the Translation</head><p>Automatic translation is a rather separate problem in NLP. The idea to translate first, followed by the same language plagiarism detection is neither a scientific contribution, nor a distinguishing feature for a plagiarism detection system. In the extended version of this paper <ref type="bibr" coords="6,186.61,511.27,11.62,8.64" target="#b3">[4]</ref> you can find our entire treatment of this issue, including an example of how much obfuscation is introduced by a mismatch of the translation engines employed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">The Issue with the Granularity Correction in the Plagdet Score</head><p>The granularity has been introduced for plagiarism detection in <ref type="bibr" coords="6,386.19,572.75,10.58,8.64" target="#b7">[8]</ref>. It was meant to correct the standard F-score for excessive splitting of the plagiarized passages retrieved. It is an ad-hoc correction that divides the F-score by log 2 (1 + granularity). It exhibits unwanted behavior in certain cases. For example, let's assume we compare with plagdet two methods, one having recall 33.33%, precision 100% and granularity 1 with another method having both precision and recall 100% and granularity 3. The two methods will obtain the very same plagdet score, 0.5, as a result of applying the granularity correction, although the second method is obviously to be preferred. It has 100% recall and precision, it finds everything and nothing more and even the splitting is very far from excessive. No user will ever prefer a software that fails to find two thirds of the cases to a software that finds them all and even displays each as one block (when colouring text blocks, the adjacent parts will visually join).</p><p>More thought should be spent in finding a reasonable plagiarism detection score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper the newest changes to the plagiarism detection method Encoplot have been presented, as well as the results in the competition PAN'11. The main change was replacing the standard, kernel based pairwise document similarity measure by a new similarity measure that includes some of the encoplot core ideas. We have shown that this new similarity measure is to be preferred when only a small part of the whole set of document pairs can be analyzed in detail, as the recall at document level increases much faster with the here proposed similarity measure. The results in the competition were excellent, our team obtained the best scores for the manual paraphrasing subcorpus and ranked 2nd overall on the external plagiarism detection task, obtaining also the best recall on the subcorpus of non-translated plagiarism cases.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,331.57,251.26,149.02,8.64;2,151.70,262.90,328.89,8.96;2,151.70,274.85,328.89,9.65;2,151.70,286.81,328.89,9.65;2,151.70,298.76,345.29,9.65"><head></head><label></label><figDesc>be the number of the occurrences of w in A and B, respectively. Then |{(u, v) ∈ E; A(u . . . u + N -1) = w}| = min(n w A, n w B), where |X| denotes the cardinal of the set X. Further more, if a w (i) i=1...nwA are the ascendingly ordered positions on which w occurs in A and b w (i) i=1...nwB the ones for B, then (a w (i), b w (i)) ∈ E, for i = 1 . . . min(n w A, n w B).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,134.77,253.06,345.82,8.12;5,134.77,264.37,345.82,7.77;5,134.77,275.33,345.82,7.77;5,134.77,286.29,345.82,7.77;5,134.77,297.25,345.82,7.77;5,134.77,308.20,345.82,7.77;5,134.77,319.16,108.58,7.77"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. (a) Comparative recall at document level on the 2010 competition corpus of the newly introduced encoplot similarity measure and of the two ranking variants we have employed in 2010, based on a standard string kernel. The encoplot similarity measure graph ends when all document pairs with non-null similarity values are included. (b) Same for the 2011 competition corpus, using the ranking which performed best for the standard string kernel. (c) Precision-Recall plots for several ranking types for the standard and the encoplot based similarity measures, on the 2010 competition corpus data.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="5,463.98,416.82,16.61,8.64;5,134.77,428.78,34.30,8.64"><head></head><label></label><figDesc>Figure 1(b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,146.00,525.71,314.24,99.50"><head>Table 1 .</head><label>1</label><figDesc>Results on 2011 Competition Data</figDesc><table coords="5,146.00,546.24,314.24,78.97"><row><cell>Subset</cell><cell>Size Recall</cell><cell>Precision</cell><cell>F-score</cell><cell>Granularity</cell><cell>Plagdet score</cell></row><row><cell>Entire corpus</cell><cell>49,621 0.34</cell><cell>0.81</cell><cell>0.48</cell><cell>1.22</cell><cell>0.42</cell></row><row><cell>No paraphrasing</cell><cell>976 0.90</cell><cell>0.84</cell><cell>0.86</cell><cell>1.02</cell><cell>0.85</cell></row><row><cell>Manual paraphrasing</cell><cell>4,609 0.36</cell><cell>0.96</cell><cell>0.53</cell><cell>1.06</cell><cell>0.50</cell></row><row><cell>Automatic paraphrasing</cell><cell>19,779 0.58</cell><cell>0.90</cell><cell>0.71</cell><cell>1.27</cell><cell>0.60</cell></row><row><cell>low obfuscation</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Automatic paraphrasing</cell><cell>19,115 0.08</cell><cell>0.64</cell><cell>0.14</cell><cell>1.19</cell><cell>0.13</cell></row><row><cell>high obfuscation</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Manual translation</cell><cell>433 0.08</cell><cell>0.25</cell><cell>0.12</cell><cell>1.01</cell><cell>0.12</cell></row><row><cell>Automatic translation</cell><cell>4,709 0.23</cell><cell>0.40</cell><cell>0.29</cell><cell>1.07</cell><cell>0.28</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgment: The parallelization of Encoplot has been performed under the <rs type="projectName">HPC-EUROPA2</rs> project (project number: <rs type="grantNumber">228398</rs>) with the support of the <rs type="funder">European Commission -Capacities Area -Research Infrastructures</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_ZMrCkda">
					<idno type="grant-number">228398</idno>
					<orgName type="project" subtype="full">HPC-EUROPA2</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,138.13,417.98,333.00,7.77;7,146.47,428.94,183.26,7.77" xml:id="b0">
	<analytic>
	</analytic>
	<monogr>
		<title level="m" coord="7,307.97,417.98,121.32,7.77">CLEF 2010 LABs and Workshops</title>
		<title level="s" coord="7,435.77,417.98,35.36,7.77;7,146.47,428.94,22.30,7.77">Notebook Papers</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Harman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Pianta</surname></persName>
		</editor>
		<meeting><address><addrLine>Padua, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-09">September 2010. 2010</date>
			<biblScope unit="page" from="22" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.13,439.68,333.87,7.77;7,146.47,450.63,88.65,7.77" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="7,188.32,439.68,206.45,7.77">Old and new challenges in automatic plagiarism detection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<publisher>National Plagiarism Advisory Service</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.13,461.37,324.91,7.77;7,146.47,472.33,299.42,7.77;7,146.47,483.29,304.66,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,273.48,461.37,189.57,7.77;7,146.47,472.33,135.20,7.77">ENCOPLOT: Pairwise Sequence Matching in Linear Time Applied to Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grozea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gehl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Popescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,299.82,472.33,146.07,7.77;7,146.47,483.29,51.52,7.77">UNCOVERING PLAGIARISM</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page">10</biblScope>
		</imprint>
	</monogr>
	<note>3rd PAN WORKSHOP</note>
</biblStruct>

<biblStruct coords="7,138.13,494.02,320.13,7.77;7,146.47,504.98,145.55,7.77;7,146.47,515.94,232.12,7.77" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="7,238.86,494.02,219.40,7.77;7,146.47,504.98,141.74,7.77">The Encoplot Similarity Measure for Automatic Detection of Plagiarism -Extended Technical Report</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grozea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Popescu</surname></persName>
		</author>
		<ptr target="http://brainsignals.de/encsimTR.pdf" />
		<imprint>
			<date type="published" when="2011-08">Aug 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.13,526.67,326.10,7.77;7,146.47,537.63,292.28,7.77" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="7,238.86,526.67,225.37,7.77;7,146.47,537.63,186.45,7.77">Encoplot -Performance in the Second International Plagiarism Detection Challenge -Lab Report for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grozea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Popescu</surname></persName>
		</author>
		<editor>Braschler et al.</editor>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.13,548.36,308.91,7.77;7,146.47,559.32,331.40,7.77;7,146.47,570.28,106.34,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,238.86,548.36,208.18,7.77;7,146.47,559.32,36.91,7.77">Who&apos;s the Thief? Automatic Detection of the Direction of Plagiarism</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grozea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Popescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="7,273.09,559.32,162.84,7.77">CICLing. Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">F</forename><surname>Gelbukh</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">6008</biblScope>
			<biblScope unit="page" from="700" to="710" />
			<date type="published" when="2010">2010</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.13,581.01,338.22,7.77;7,146.47,591.97,334.12,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,323.45,581.01,152.90,7.77;7,146.47,591.97,21.57,7.77">Hierarchical task based programming with StarSs</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Planas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Badia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Ayguadé</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Labarta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,173.86,591.97,194.95,7.77">International Journal of High Performance Computing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="284" to="299" />
			<date type="published" when="2009-08">August 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.13,602.70,306.44,7.77;7,146.47,613.66,333.45,7.77;7,146.47,624.62,307.60,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,340.50,602.70,104.06,7.77;7,146.47,613.66,71.70,7.77">An evaluation framework for plagiarism detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,236.13,613.66,243.80,7.77;7,146.47,624.62,69.22,7.77">Proceedings of the 23rd International Conference on Computational Linguistics: Posters</title>
		<meeting>the 23rd International Conference on Computational Linguistics: Posters</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="997" to="1005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.13,635.35,314.07,7.77;7,146.47,646.31,258.26,7.77" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="7,378.61,635.35,73.60,7.77;7,146.47,646.31,180.34,7.77">Overview of the 2nd International Competition on Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Eiselt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<editor>Braschler et al.</editor>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
