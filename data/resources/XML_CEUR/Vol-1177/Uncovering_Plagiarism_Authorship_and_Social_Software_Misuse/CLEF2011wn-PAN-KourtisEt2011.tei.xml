<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,150.14,151.61,306.33,12.71;1,216.50,170.44,162.32,10.91">Author Identification Using Semi-supervised Learning Notebook for PAN at CLEF 2011</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,219.44,207.46,61.90,9.11"><forename type="first">Ioannis</forename><surname>Kourtis</surname></persName>
							<email>ikourtis@aegean.gr</email>
							<affiliation key="aff0">
								<orgName type="institution">University of the Aegean</orgName>
								<address>
									<addrLine>-Karlovassi</addrLine>
									<postCode>83200</postCode>
									<settlement>Samos</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,300.82,207.46,86.35,9.11"><forename type="first">Efstathios</forename><surname>Stamatatos</surname></persName>
							<email>stamatatos@aegean.gr</email>
							<affiliation key="aff0">
								<orgName type="institution">University of the Aegean</orgName>
								<address>
									<addrLine>-Karlovassi</addrLine>
									<postCode>83200</postCode>
									<settlement>Samos</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,150.14,151.61,306.33,12.71;1,216.50,170.44,162.32,10.91">Author Identification Using Semi-supervised Learning Notebook for PAN at CLEF 2011</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9965EE890C36E3AC54CBEAEA06D2895C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Author identification models fall into two major categories according to the way they handle the training texts: profile-based models produce one representation per author while instance-based models produce one representation per text. In this paper, we propose an approach that combines two well-known representatives of these categories, namely the Common n-Grams method and a Support Vector Machine classifier based on character ngrams. The outputs of these classifiers are combined to enrich the training set with additional documents in a repetitive semi-supervised procedure inspired by the co-training algorithm. The evaluation results on closed-set author identification are encouraging, especially when the set of candidate authors is large.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Nowadays, there is a rapid growth of text in electronic form in blogs, social media, forums, etc. Most of this content is provided anonymously or under unverified names. In the framework of forensic applications it is needed to group texts written by the same author or track texts written under different names but belonging to the same person. Moreover, there are numerous copyright dispute cases where multiple people claim the authorship of texts. Authorship identification supported by computational analysis of texts attracts increasing attention since it may offer quick answers to these problems <ref type="bibr" coords="1,164.42,538.32,15.40,9.11" target="#b11">[12]</ref>.</p><p>The vast majority of approaches to author identification consider this problem as a closed-set classification task. That is the training set includes samples for all possible authors and each text of unknown authorship has to be assigned to one candidate author. However, in many practical applications it is not possible to know a priori all the candidate authors or it is not possible to have sample texts for all of them. Therefore, a more practical but less studied setting is the open-set classification where the classifier is allowed to answer -I don't know‖ for some texts of unknown authorship <ref type="bibr" coords="1,170.00,630.24,10.65,9.11" target="#b5">[6]</ref>. In addition, the vast majority of author identification methods assume that the only available information for building a classification model comes from a fixed and stable training set. However, there are many cases where we need to decide about the authorship of groups of texts. Alternatively, a long text (a book) of unknown authorship can be segmented into multiple parts. In such cases, it is possible to use the test sets as unlabeled examples and use some information from them to improve the classification models. An attempt to this direction was proposed by Guzman et al. <ref type="bibr" coords="2,186.05,172.66,11.76,9.11" target="#b1">[2]</ref> where unlabeled examples from the Web were used to enrich the training set. Although semi-supervised learning which is based on both labeled and unlabeled examples is very popular in text categorization <ref type="bibr" coords="2,359.07,195.64,10.61,9.11" target="#b8">[9]</ref>, it has not yet examined in the framework of authorship analysis tasks.</p><p>In automated author identification we need a set of candidate authors and text samples for each one of them. Since we care more about style rather than topic, one main task is to adequately measure the stylistic choices of the authors. To this end, several text representation methods have been proposed <ref type="bibr" coords="2,374.56,253.06,16.66,9.11" target="#b11">[12]</ref> related to lexical information (e.g., function word frequencies), character information (e.g., character ngrams), syntactic information (e.g., part-of-speech frequencies), and semantic information (e.g., synonyms). In addition, application-specific features can be used when all texts are of the same type, format, or topic. A number of independent studies have found that character n-grams are very effective in author identification <ref type="bibr" coords="2,436.41,310.54,11.42,9.11" target="#b5">[6,</ref><ref type="bibr" coords="2,447.83,310.54,7.61,9.11" target="#b7">8,</ref><ref type="bibr" coords="2,455.44,310.54,11.42,9.11" target="#b9">10]</ref>. Moreover, they are language-independent features and their extraction requires minimal text processing.</p><p>Author identification methods fall into two major categories <ref type="bibr" coords="2,379.38,344.98,15.60,9.11" target="#b11">[12]</ref>:  The profile-based paradigm attempts to capture the style of authors. It disregards the differences between training texts by the same author and produces one single representation (i.e., profile) per author. Each text of unknown authorship is then compared with the profile of each author and is assigned to the most likely one.  The instance-based paradigm attempts to capture the style of texts. It produces one representation per training text and builds a classification model that can estimate the most likely author of a text of unknown authorship. The machine learning algorithms used in this paradigm (e.g. SVM, neural networks, etc.) usually require multiple instances per class, so in case there is only one training text for one author it should be segmented into smaller pieces. Each of these paradigms has its strengths and weaknesses. Profile-based approaches are more robust when there is an uneven distribution of training texts in the candidate authors (i.e., the class imbalance problem) <ref type="bibr" coords="2,370.28,518.82,10.71,9.11" target="#b7">[8]</ref>. On the other hand, instance-based approaches are more accurate when there are enough training texts for all the candidate authors. Profile-based approaches can better handle very short texts since they concatenate all the texts by the same author. On the other hand, in instancebased approaches it is easier to combine different text representation features and they are more robust when the candidate authors set size is large.</p><p>In this paper we propose an algorithm that combines two well-known representatives of these paradigms: the Common N-Grams (CNG) method <ref type="bibr" coords="2,429.10,599.22,11.80,9.11" target="#b3">[4]</ref> and an SVM classifier using character n-grams <ref type="bibr" coords="2,287.05,610.74,15.40,9.11" target="#b10">[11]</ref>. The main idea is to combine the outputs of these classifiers in the test set and augment the training set with additional documents. Therefore it is a semi-supervised approach since it uses both labeled and unlabeled examples. The idea of using a couple of independent classifiers in a repetitive semi-supervised procedure is inspired by the co-training algorithm <ref type="bibr" coords="2,433.87,656.70,10.68,9.11" target="#b0">[1]</ref>.</p><p>The rest of this paper is organized as follows. The next section describes in detail the proposed algorithm. In Section 3 we report evaluation results based on the PAN-11 training corpus. In Section 4 the main conclusions drawn by this study are described and future work directions are given.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Proposed Method</head><p>In this paper, we describe an author identification method that can be applied to closed-set tasks and is based on semi-supervised learning. Our approach combines two well-known approaches: the CNG model and the SVM model. Both models use character 3-grams to represent the stylistic properties of texts. We first describe these models and then the proposed semi-supervised algorithm is presented.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Common n-grams</head><p>CNG <ref type="bibr" coords="3,149.83,328.36,11.75,9.11" target="#b3">[4]</ref> is a profile-based method, that is, first all the available training texts per author are concatenated into one file and, then, a single representation is extracted for each author. The representation (profile) is based on the L most frequent character ngrams of the file. The same representation is used for each individual text of unknown authorship. The classification model is based on the distance (dissimilarity) of the profile of the text from each of the profiles of the candidate authors. This procedure is illustrated in Figure <ref type="figure" coords="3,206.18,397.32,5.01,9.11" target="#fig_0">1</ref> (for just one candidate author). This method has two significant parameters that should be tuned: n, that is the order of n-grams, and L, that is the size of profile. According to previous studies <ref type="bibr" coords="3,454.67,590.70,15.99,9.11" target="#b9">[10,</ref><ref type="bibr" coords="3,124.76,602.16,11.91,9.11" target="#b10">11]</ref>, we selected n=3 since it provided good results in authorship attribution and it is less likely to capture thematic information in comparison with longer n-grams. On the other hand, character 3-grams cannot easily capture contextual information (i.e., sequences of words). The profile length L should be selected carefully and in combination with the dissimilarity function since previous studies have shown that CNG may be unstable when the profile of one candidate author is shorter than L. This may happen when there are very limited training texts for one candidate author (i.e., the class imbalance problem). In this study, we used the following dissimilarity function <ref type="bibr" coords="4,160.62,161.14,16.68,9.11" target="#b9">[10]</ref> that is stable when L increases:</p><formula xml:id="formula_0" coords="4,221.42,172.65,162.76,30.53">             ) ( 2 1 ) ( ) ( )) ( ) ( ( 2 )) ( ), ( ( x P g T x T x a g f g f g f g f T P x P d a a</formula><p>where P(x) and P(T a ) are the profile of the text of unknown authorship and the profile of the candidate author a, respectively, while f x (g) and f Ta (g) are the normalized frequencies of the n-gram g in the text of unknown authorship and the concatenated training texts of candidate author a. Since the sum is defined over the n-grams that belong to the profile of the text of unknown authorship, the dissimilarity function will contain the same number of terms for each candidate author, so it will be more stable in case of class imbalance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Support Vector Machines</head><p>SVM is one of the most effective machine learning algorithms for text categorization.</p><p>In authorship attribution, it has been used in combination with character n-grams providing very good results <ref type="bibr" coords="4,237.79,354.22,15.40,9.11" target="#b10">[11]</ref>. Essentially, it is an instance-based method that is for each individual training text a representation is produced, usually based on the frequencies of the d most frequent character n-grams of the training corpus. Then, the SVM algorithm can be used to learn the boundaries between classes (i.e., authors). The learned model can then be used to guess the author of another text. This procedure is demonstrated in Figure <ref type="figure" coords="4,291.02,411.72,3.77,9.11" target="#fig_1">2</ref>. In this paper, we used the LIBSVM implementation of this algorithm. Since the dimensionality is high (several thousands of features), the linear kernel has been used. Moreover, we used character 3-grams as in the case of CNG. One crucial decision when using this method is about d, the dimensionality. It has been proved that the most frequent character n-grams are good style markers <ref type="bibr" coords="4,447.73,649.32,10.93,9.11" target="#b2">[3,</ref><ref type="bibr" coords="4,462.28,649.32,8.38,9.11" target="#b4">5]</ref> but it is not clear how many character n-grams should be used. In this paper, we propose the use of the intrinsic dimension as a criterion to define the appropriate dimensionality of the text representation. More specifically, in many cases high-dimensional datasets can be efficiently summarized in a space of much lower dimension without losing much information. This is especially true for text representation since many features correlate. Intrinsic dimension provides an estimation of the variables we need to represent the high-dimensional data. Therefore, intrinsic dimension can be used to indicate the richest representation. That is, the higher the intrinsic dimension, the better the representation of texts (it captures more hints about their properties). So, given a training corpus, we sort the character ngrams in decreasing frequency of appearance and then a frequency threshold can be applied to select the features of the representation. By varying this threshold, we get varying sizes of d. For each threshold value, we measure the intrinsic dimension and the representation that corresponds to the maximal intrinsic dimension value is selected. The maximum likelihood estimator <ref type="bibr" coords="5,305.84,276.04,11.74,9.11" target="#b6">[7]</ref> was used for the intrinsic dimension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">The Semi-supervised Learning Algorithm</head><p>The main idea of the proposed algorithm is inspired by co-training <ref type="bibr" coords="5,411.33,332.02,11.69,9.11" target="#b0">[1]</ref> where two independent classifiers are used and help each other with their predictions on the set of unlabeled examples. Given a set of training documents (labeled examples) and a set of test documents (unlabeled examples) our algorithm repetitively selects some members of the test set and adds them to the training set. In each step, the CNG and the SVM methods are trained based on the training set and the acquired models are used to predict the labels of the test set. Then, the test documents that both classification models agree on their predicted label are selected. Moreover, the text size of these documents should be larger than a threshold since in general it is hard to capture the stylistic properties of very short texts. In other words, we consider that even when CNG and SVM agree on their predictions, these predictions are unreliable when the text length is very short. When at least one test text is selected and added to the training set using the predicted label as its true label, the procedure is repeated. When this repetitive procedure stops and the test set is not empty, one of the classifiers can be used to predict the labels of the rest of the texts of test set. In this paper, we used the SVM as this default classifier since it is more reliable when there are enough training data. In other words, it is expected that after a few repetitions the training set will be enriched with new documents. If this is not true, and the training set still under-represents some of the candidate authors, the CNG classifier would be a better choice.</p><p>The proposed algorithm is shown in Figure <ref type="figure" coords="5,330.93,561.84,3.76,9.11">3</ref>. Note that there are important differences with the co-training algorithm. First, the original co-training algorithm used the same classification method and two distinct subsets of the feature set to produce the two independent classifiers. In the proposed algorithm, we use the same feature types (i.e., character 3-grams) and use two different classification models representing the two basic families of author identification methods (i.e., profilebased and instance-based). Moreover, the proposed algorithm uses the unlabeled cases where the outputs of the two classifiers agree. In co-training a fixed number of the most confident answers from each classifier are considered. In the proposed algorithm the whole test set is examined. On the other hand, co-training examines a subset of the test set in each repetition. As a result, co-training needs more repetitions.  The final parameter is the text size threshold used to select files that will be added in the training set according to our semi-supervised algorithm. Figure <ref type="figure" coords="7,420.26,572.58,5.01,9.11" target="#fig_5">7</ref> shows the distribution of text-size of the validation corpus of PAN11-AA-Large where the predictions of CNG and SVM agree and they correspond to the true author of the texts. Also, it shows the cases where the common predictions do not correspond to the true authors. It is evident that a size threshold of 500 bytes excludes most of the cases where the two models agree but the predicted author is not the correct answer.  For the PAN11-AA-Small corpus, using the initial training set CNG and SVM models achieved 49.2% and 64.7% microaverage accuracy on the validation corpus, respectively. During the semi-supervised learning procedure 57 files were moved from the validation set to the training set. For these files both CNG and SVM agreed on their predictions (94.7% accuracy). For the rest of the validation files and using the enriched training set, the performance of CNG and SVM models was 43.6% and 61.2% accuracy, respectively. It is obvious that SVM is far better than CNG in this dataset so it was used as the default classifier.</p><p>For the PAN11-AA-Large corpus, the CNG and SVM models were trained based on the initial training set and their performance (microaverage accuracy) on the validation corpus was 37.8% and 60.9%, respectively. Again, SVM seems to be the best choice. One reason for this big difference is that the distribution of the validation set is similar to the distribution of training set over the authors. So, an author with many training texts will also have many validation texts. SVM can take advantage of this fact but CNG cannot. A total of 108 files were moved from the validation set to the training set. For this file the accuracy in the predictions of both classifiers was 88%. For the remaining files of the validation set the accuracy of CNG and SVM was 32.7% and 52.1%, respectively.</p><p>In the framework of the participation of the presented method to the PAN-11 author identification competition, the provided training and validation corpora were jointly used to form the labeled examples while the unlabeled examples comprised the competition test corpus. The final performance results are shown in the Table <ref type="table" coords="9,445.92,241.60,3.76,9.11" target="#tab_0">1</ref>. For PAN11-AA-Large our approach won the first place indicating that the proposed method is effective for large candidate author sets. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>Most of the studies in author identification consider the training corpus as fixed and stable. In this paper we presented a semi-supervised learning approach to author identification that attempts to enrich the training corpus with unlabeled examples taken from the test corpus. Two well-known author identification models work together and their predictions are used to transfer texts from the test corpus to the training corpus. This method can be used when there are multiple texts of unknown authorship or when a single long text can be segmented into multiple parts. Preliminary results show that the proposed method is effective especially when the candidate author set is large. It can be extended to also handle open-set classification tasks by taking the degree of certainty of the two classifiers into account. This will also allow us to apply a semi-supervised learning procedure that will have more similarities with the original co-training algorithm since the most confident predictions of both classifiers will be transferred to the training set.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,161.36,562.54,272.60,8.18;3,147.63,406.54,300.05,148.00"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Overview of the CNG method (only one candidate author is shown).</figDesc><graphic coords="3,147.63,406.54,300.05,148.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,228.80,621.16,137.71,8.18;4,143.66,455.39,309.50,157.80"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Overview of the SVM method.</figDesc><graphic coords="4,143.66,455.39,309.50,157.80" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,157.82,338.36,281.95,8.18"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Distribution of the training/validation corpus of the PAN11-AA-Small.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,157.82,544.48,281.97,8.18"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Distribution of the training/validation corpus of the PAN11-AA-Large.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="8,124.76,274.10,345.91,8.18;8,124.76,284.42,84.47,8.18"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Intrinsic dimension of PAN11-AA-Small (left) and PAN11-AA-Large (right) for varying freq. threshold.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="8,124.76,512.98,345.74,8.18;8,124.76,523.30,63.94,8.18;8,161.18,330.98,273.83,174.04"><head>Fig. 7 .</head><label>7</label><figDesc>Fig. 7. Text-size distribution of PAN-11-AA-Large validation corpus where CNG and SVM predictions agree.</figDesc><graphic coords="8,161.18,330.98,273.83,174.04" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="9,133.82,287.72,322.93,68.52"><head>Table 1 .</head><label>1</label><figDesc>The performance of our approach in the PAN-11 competition.</figDesc><table coords="9,133.82,311.92,322.93,44.33"><row><cell>Corpus</cell><cell>MacroAvg</cell><cell>MacroAvg</cell><cell>MacroAvg</cell><cell>MicroAvg</cell></row><row><cell></cell><cell>Prec.</cell><cell>Recall</cell><cell>F1</cell><cell>accuracy</cell></row><row><cell>PAN11-AA-Small</cell><cell>0.476</cell><cell>0.374</cell><cell>0.38</cell><cell>0.638</cell></row><row><cell>PAN11-AA-Large</cell><cell>0.549</cell><cell>0.532</cell><cell>0.52</cell><cell>0.658</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="6,130.04,686.22,328.79,8.18"><p>http://www.uni-weimar.de/medien/webis/research/events/pan-11/author-identification.html</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head><p>For the evaluation of the proposed method we used the corpora released in 2011 for the evaluation campaign on author identification in the framework of PAN-2011 1 . In more detail, we used 2 parts of these corpora that correspond to the closed-set evaluation setting, namely, PAN11-AA-Small and PAN11-AA-Large. The former includes 3,519 texts from 26 candidate authors (roughly, 85% in the training corpus and 15% in the validation corpus) while the latter comprises 10,635 texts from 72 candidate authors (roughly, 88% in the training corpus and 12% in the validation corpus). All the texts are parts of email messages and therefore can be short and messy. The size of the messages varies from 23B to 23KB. Both training corpora are highly imbalanced as can be seen in Figures <ref type="figure" coords="6,303.62,547.62,5.01,9.11">4</ref> and<ref type="figure" coords="6,328.10,547.62,3.74,9.11">5</ref>.</p><p>The CNG parameters used for these corpora were n=3 and L=3,000. For the SVM method we used n=3 (character 3-grams) and d (dimensionality) is determined by the maximal value of the intrinsic dimension. Figure <ref type="figure" coords="6,336.20,582.12,5.01,9.11">6</ref> shows the intrinsic dimension values we get with different frequency threshold values for PAN11-AA-Small and PAN11-AA-Large. In the former case, the intrinsic dimension is maximized for frequency threshold=80 (meaning that all character 3-grams appearing at least 80 times in the training corpus are included in the feature set). In the latter case, the intrinsic dimension is maximized for threshold=20. Therefore, the feature set of PAN11-AA-Large is significantly larger than the feature set of PAN11-AA-Small.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="9,128.14,616.72,342.46,8.18;9,138.98,627.10,331.69,8.18;9,138.98,637.42,66.51,8.18" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,234.08,616.72,220.67,8.18">Combining Labeled and Unlabeled Data with Co-training</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Blum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,138.98,627.10,245.65,8.18">Proceedings of the Workshop on Computational Learning Theory</title>
		<meeting>the Workshop on Computational Learning Theory</meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="92" to="100" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,128.14,647.80,342.50,8.18;9,138.98,658.12,331.76,8.18;9,138.98,668.46,44.25,8.18" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,434.50,647.80,36.13,8.18;9,138.98,658.12,194.85,8.18">Using the Web as Corpus for Self-training Text Categorization</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Guzmán-Cabrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y-Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Villaseñor-Pineda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,340.93,658.12,78.07,8.18">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="400" to="415" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,128.14,149.36,342.41,8.18;10,138.98,159.68,331.53,8.18;10,138.98,170.00,186.45,8.18" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,253.34,149.36,203.07,8.18">N-gram Feature Selection for Authorship Identification</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Houvardas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,138.98,159.68,331.53,8.18;10,138.98,170.00,79.02,8.18">Proceedings of the 12th International Conference on Artificial Intelligence: Methodology, Systems, Applications</title>
		<meeting>the 12th International Conference on Artificial Intelligence: Methodology, Systems, Applications</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="77" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,128.14,180.38,342.46,8.18;10,138.98,190.70,331.57,8.18;10,138.98,201.02,119.49,8.18" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,337.46,180.38,133.14,8.18;10,138.98,190.70,84.50,8.18">N-gram-based Author Profiles for Authorship Attribution</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Keselj</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Cercone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Thomas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,245.03,190.70,225.52,8.18;10,138.98,201.02,38.73,8.18">Proceedings of the Pacific Association for Computational Linguistics</title>
		<meeting>the Pacific Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="255" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,128.14,211.40,342.41,8.18;10,138.98,221.72,331.67,8.18;10,138.98,232.04,99.03,8.18" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,266.60,211.40,203.95,8.18;10,138.98,221.72,49.81,8.18">Feature Instability as a Criterion for Selecting Potential Style Markers</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Akiva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Dagan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,195.88,221.72,270.64,8.18">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1519" to="1525" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,128.14,242.42,342.39,8.18;10,138.98,252.74,174.51,8.18" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,290.54,242.42,135.33,8.18">Authorship Attribution in the Wild</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Argamon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,435.04,242.42,35.49,8.18;10,138.98,252.74,92.01,8.18">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="83" to="94" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,128.14,263.12,342.42,8.18;10,138.98,273.44,267.47,8.18" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,237.68,263.12,216.15,8.18">Maximum Likelihood Estimation of Intrinsic Dimension</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Levina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Bickel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,138.98,273.44,190.07,8.18">Advances in Neural Information Processing Systems</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="777" to="784" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,128.14,283.76,342.32,8.18;10,138.98,294.14,60.03,8.18" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="10,189.74,283.76,166.06,8.18">Scalability Issues in Authorship Attribution</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Luyckx</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
		<respStmt>
			<orgName>University of Antwerp</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct coords="10,128.14,304.46,337.30,8.18;10,138.98,314.78,318.71,8.18" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,289.04,304.46,171.11,8.18">Semi-Supervised Text Classification Using EM</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,290.78,314.78,94.59,8.18">Semi-Supervised Learning</title>
		<editor>
			<persName><forename type="first">O</forename><surname>Chapelle</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Zien</surname></persName>
		</editor>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,132.26,325.16,338.42,8.18;10,138.98,335.48,331.54,8.18;10,138.98,345.80,61.47,8.18" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,198.98,325.16,256.35,8.18">Author Identification Using Imbalanced and Limited Training Texts</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,138.98,335.48,313.23,8.18">Proceedings of the 4th International Workshop on Text-based Information Retrieval</title>
		<meeting>the 4th International Workshop on Text-based Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="237" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,132.26,356.18,338.26,8.18;10,138.98,366.50,287.27,8.18" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,196.40,356.18,274.12,8.18;10,138.98,366.50,28.66,8.18">Author Identification: Using Text Sampling to Handle the Class Imbalance Problem</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,174.01,366.50,146.37,8.18">Information Processing and Management</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="790" to="799" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,132.26,376.82,338.23,8.18;10,138.98,387.20,319.91,8.18" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,200.48,376.82,206.51,8.18">A Survey of Modern Authorship Attribution Methods</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,415.96,376.82,54.53,8.18;10,138.98,387.20,211.52,8.18">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="538" to="556" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
