<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,148.44,151.46,310.07,12.59;1,218.16,190.55,170.28,10.76">Using Clustering to Identify Outlier Chunks of Text Notebook for PAN at CLEF 2011</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,277.68,226.19,51.22,9.02"><forename type="first">Navot</forename><surname>Akiva</surname></persName>
							<email>navot@cs.biu.ac.il</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution" key="instit1">Bar</orgName>
								<orgName type="institution" key="instit2">Ilan University</orgName>
								<address>
									<settlement>Ramat Gan</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,148.44,151.46,310.07,12.59;1,218.16,190.55,170.28,10.76">Using Clustering to Identify Outlier Chunks of Text Notebook for PAN at CLEF 2011</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7A014B778B086C2690C9965396B80E43</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Intrinsic plagiarism</term>
					<term>clustering</term>
					<term>outlier detection</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Intrinsic plagiarism detection is a sub-task of authorship identification in which outlier chunks must be detected solely on the basis of stylistic differences from the main body of the text. We present a first attempt at utilizing words that appear infrequently in a text as stylistic markers for distinguishing outlier chunks in the text. In the first phase of our method we cluster chunks of text represented by usage of infrequent words. In the second phase, we use a training corpus to identify cluster properties of outlier chunks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>One of the main difficulties in any plagiarism task is identifying the boundaries of plagiarized text <ref type="bibr" coords="1,186.40,475.19,10.92,9.02" target="#b0">[1]</ref>. In the case of intrinsic plagiarism detection, we face the additional difficulty that no source text is available for comparison. We thus need to automatically identify sudden shifts in writing style.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Outlier Chunks Identification</head><p>Our approach consists of two phases: chunks clustering and cluster properties detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Chunks Clustering Phase</head><p>Chunking: For a given text, we first divide the text into chunks consisting of 1000 characters. We then identify the 100 rarest words that appear in at least 5% of the chunks. (Thus we have a set of words that are infrequent in the text but not so infrequent as to be useless. These parameters were not optimized and no doubt can be significantly improved.) Each chunk is now represented by a numerical vector of length 100 corresponding to the presence or absence of each of the rare words in the chunk. We measure the similarity of pairs of chunks using cosine.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Clustering:</head><p>We then use a spectral clustering method called n-cut <ref type="bibr" coords="2,401.76,184.07,11.71,9.02" target="#b1">[2]</ref> to cluster the chunks. We cluster the texts into only two clusters, which we hope will correspond to the true text and the plagiarized text, respectively. This hope is often unrealistic because there is no guarantee that the plagiarized material is taken from a single source. It might be that different plagiarized sections are not similar to each other; it might also be that there is little or no plagiarized material and the clustering will be along lines that are unrelated to plagiarism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Cluster Properties Detection</head><p>We thus use a second phase to identify clusters that really do consist of plagiarized text. To do this, we run our clustering method on the training corpus and we measure a variety of properties of each cluster and each chunk in each cluster. These properties include the relative and absolute size of each cluster, the similarity of each chunk to its own cluster, to the other cluster and to the whole document and so forth. The intuition is that plagiarized chunks are those that are close to the centroid of the small cluster and very far from the centroid of the whole document.</p><p>We represent each chunk in the training set as a numerical vector recording each of the above values and we label each chunk as including plagiarized material or not. We then use supervised learning methods to learn decision trees using WEKA <ref type="bibr" coords="2,442.92,413.99,11.71,9.02" target="#b2">[3]</ref> for distinguishing plagiarized chunks from non-plagiarized chunks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation Results</head><p>We found it was best to learn separate classifiers for short (up to 20K), medium (20K to 250K) and long (above 250K) documents.</p><p>We used ten-fold cross-validation to optimize parameter settings and to estimate accuracy results. For reasons of efficiency, we did not use the full training set. In particular, we ignored all documents with more than 40% plagiarism. We also randomly selected chunks from among the remaining documents.</p><p>Our cross-validation results are shown in Table <ref type="table" coords="2,338.04,582.83,3.76,9.02" target="#tab_0">1</ref>. Unfortunately, these numbers turned out to be optimistic. On the PAN-2011 evaluation set, we achieved precision 12.7% and recall of 6.6%. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions and Future Work</head><p>Despite the poor evaluation results, we believe that our overall method is promising. We should significantly increase the number of training examples on our future experiments. There are a number of parameters that first need to be optimized, including the choice of rare words and the size of the chunks (which need not be constant). There are a number of other considerations that might improve results, including using the full training set and clustering into k&gt;2 clusters.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,124.80,161.30,345.90,131.99"><head>Table 1 .</head><label>1</label><figDesc>Cross validation result.</figDesc><table coords="3,124.80,185.21,345.90,108.08"><row><cell>Training Group</cell><cell>Best</cell><cell cols="2">Precision Recall</cell><cell>F-</cell><cell># Plag.</cell><cell># Non-Plag.</cell></row><row><cell></cell><cell>Algorithm</cell><cell></cell><cell></cell><cell>Measure</cell><cell>Chunks</cell><cell>Chunks</cell></row><row><cell></cell><cell>Applied</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Up to 20K chars.</cell><cell>JRip</cell><cell>48%</cell><cell>14%</cell><cell>21.6%</cell><cell>2000</cell><cell>3700</cell></row><row><cell>20K-250K chars.</cell><cell>J48</cell><cell>62%</cell><cell>32%</cell><cell>42.2%</cell><cell>9000</cell><cell>17,000</cell></row><row><cell>Above 250K chars.</cell><cell>J48</cell><cell>72%</cell><cell>76%</cell><cell>74%</cell><cell>3000</cell><cell>6,000</cell></row><row><cell cols="7">Analysis of the results indicates that the method achieved especially poor precision</cell></row><row><cell>on short documents.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="3,128.20,495.17,342.35,8.15;3,142.80,505.49,178.53,8.15" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="3,286.93,495.17,102.50,8.15">Intrinsic plagiarism analysis</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Lipka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="3,399.60,495.17,70.96,8.15;3,142.80,505.49,37.61,8.15">Lang. Resources &amp; Evaluation</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="82" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,128.20,526.25,342.40,8.15;3,142.80,536.57,327.93,8.15;3,142.80,546.89,72.12,8.15" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="3,266.04,526.25,201.21,8.15">Kernel kmeans: spectral clustering and normalized cuts</title>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">S</forename><surname>Dhillon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Guan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Kulis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,142.80,536.57,323.31,8.15">Proc. ACM International Conference on Knowledge Discovery and Data Mining (KDD)</title>
		<meeting>ACM International Conference on Knowledge Discovery and Data Mining (KDD)</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="551" to="556" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,128.20,567.65,342.57,8.15;3,142.80,577.97,314.51,8.15" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="3,427.08,567.65,43.69,8.15;3,142.80,577.97,122.86,8.15">The WEKA Data Mining Software: An Update</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Reutemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="3,272.04,577.97,80.84,8.15">SIGKDD Explorations</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
