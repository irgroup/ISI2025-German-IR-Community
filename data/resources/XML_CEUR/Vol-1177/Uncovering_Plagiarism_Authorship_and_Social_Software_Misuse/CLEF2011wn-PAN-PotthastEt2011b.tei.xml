<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,154.11,115.90,307.14,12.90;1,210.83,133.83,193.70,12.90">Overview of the 2nd International Competition on Wikipedia Vandalism Detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,237.75,171.88,61.72,8.64"><forename type="first">Martin</forename><surname>Potthast</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Web Technology &amp; Information Systems Bauhaus</orgName>
								<orgName type="institution">Universität Weimar</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,318.83,171.88,58.78,8.64"><forename type="first">Teresa</forename><surname>Holfeld</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Web Technology &amp; Information Systems Bauhaus</orgName>
								<orgName type="institution">Universität Weimar</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,154.11,115.90,307.14,12.90;1,210.83,133.83,193.70,12.90">Overview of the 2nd International Competition on Wikipedia Vandalism Detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4BBF9C5EFCE9D9FF5BE61D58D0FB85B8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The paper overviews the vandalism detection task of the PAN'11 competition. A new corpus is introduced which comprises about 30 000 Wikipedia edits in the languages English, German and Spanish as well as the necessary crowdsourced annotations. Moreover, the performance of three vandalism detectors is evaluated and compared to those of the PAN'10 competition.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Changing a Wikipedia article with malicious intent is called vandalism. Since most of the vandalism in Wikipedia is corrected manually, automatic vandalism detectors are subject to active research and development. To support this endeavor we have organized the 2nd International Competition on Vandalism Detection, which was held in conjunction with the 2011 CLEF conference. This paper overviews the submitted detectors and evaluates their performances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Vandalism Detection</head><p>We define an edit e as the transition of a given Wikipedia article revision to another revision; the set E denotes the set of all Wikipedia edits. The task of a vandalism detector is to decide whether a given edit e has been done in bad faith or not. To address this task with machine learning requires three elements: a training corpus E train ⊂ E of pre-classified edits, an edit model α : E → E, and a classifier c : E → {0, 1}. The edit model maps an edit e onto a vector e of numerical features, whereas each feature quantifies a certain characteristic of e that may indicate vandalism. The classifier maps the feature vectors onto {0, 1}, where 0 denotes a regular edit and 1 a vandalism edit. Similarly, some classifiers map onto [0, 1] instead, where values between 0 and 1 denote the classifier's confidence. To obtain a binary decision a threshold τ ∈ [0, 1] is applied to map confidence values onto {0, 1}. In both cases the mapping of c is trained with a learning algorithm that uses the edits in E train as examples. If c captures the concept of vandalism based on α and E train , then a previously unseen edit e ∈ (E \ E train ) can be checked for vandalism by testing c(α(e)) &gt; τ .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Evaluating Vandalism Detectors</head><p>Evaluating a vandalism detector c, τ, α, E train requires an additional test corpus E test with E train ∩ E test = ∅ along with detection performance measures. E test is fed into the detector while counting its correct and false decisions: TP is the number of edits that are correctly identified as vandalism (true positives), and FP is the number of edits that are untruly identified as vandalism (false positives). Likewise, TN and FN count true negatives and false negatives. Important performance measures, such as precision and recall or the TP-rate and the FP-rate, are computed from these values:</p><formula xml:id="formula_0" coords="2,148.10,229.08,316.52,19.74">precision = TP TP + FP recall ≡ TP-rate = TP TP + FN FP-rate = FP FP + TN</formula><p>Choosing different thresholds τ yields different performances. Notice that in practice the choice of τ depends on the preferred performance characteristic. In order to quantify the performance of a detector independent of τ , precision values are plotted over recall values, and, analogously, TP-rate values are plotted over FP-rate values-for all sensible choices of τ ∈ [0, 1]. The resulting curves are called precision-recall curve and receiver operating characteristic (ROC) curve. By measuring the area under a curve (AUC), a single performance value is obtained by which classifiers can be ranked <ref type="bibr" coords="2,455.02,338.63,10.79,8.64" target="#b2">[3,</ref><ref type="bibr" coords="2,467.80,338.63,7.19,8.64" target="#b4">5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Webis Wikipedia Vandalism Corpus</head><p>We have compiled two corpora of Wikipedia edits both of which have been annotated manually: the PAN Wikipedia vandalism corpus 2010 (PAN-WVC-10) and this year's successor, PAN-WVC-11. The former comprises English edits only, while the latter for the first time also comprises German and Spanish edits. The edits of both corpora have been sampled randomly from the Wikipedia edit logs of the three languages which have been recorded for about a week. This way, the two corpora comprise a representative distribution of vandalism versus regular edits, and reflect the article importance at the time of sampling.</p><p>Both corpora have been annotated via crowdsourcing using Amazon's Mechanical Turk. We followed the annotation process that is detailed in <ref type="bibr" coords="2,386.78,502.01,10.79,8.64" target="#b7">[7]</ref>: first, each edit has been reviewed by three workers, and for those edits upon which the reviewers did not fully agree, the number of reviewers was doubled until a two-thirds agreement was reached. After the third iteration, the least required agreement was lowered to half of the reviewers. To ensure quality, edits known to be vandalism were used as check instances. While this procedure works fine for English edits, the German edits and particularly the Spanish edits were annotated at a much slower rate. For the German edits, only one iteration was finished in time, whereas none could be finished for the Spanish edits. Hence we have also recruited reviewers at our site to annotate the German and Spanish edits. The PAN-WVC-10 comprises 32 452 English edits on 28 468 different articles of which 2 391 edits were found to be vandalism. The PAN-WVC-11 comprises 29 949 edits (9 985 English, 9 990 German, 9 974 Spanish) on 24 351 articles of which 2 813 edits (1 143 English, 589 German, 1 081 Spanish) are vandalism.</p><p>During the competition, the PAN-WVC-10 was used as training corpus E train while the PAN-WVC-11 served as test corpus E test . Since the PAN-WVC-10 corpus does not contain German and Spanish edits, two additional training sets have been compiled for each of these languages. These training sets comprise 1000 edits each, 300 of which are vandalism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Overview and Evaluation of Detection Approaches</head><p>This section briefly overviews the three submitted vandalism detectors and reports on their evaluation. Moreover, their performances are compared to those of last year's participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Features and Classifier</head><p>There are two novelties in this year's vandalism detection task that led to the development of new features: the multilingual corpora of edits and the permission to use a-posteriori knowledge about an edit. One of the detectors implements 65 features, tackling all three languages and incorporating a-posteriori knowledge <ref type="bibr" coords="3,399.97,323.97,10.58,8.64" target="#b9">[9]</ref>, one implements 25 features, tackling only the English portion of the test corpus <ref type="bibr" coords="3,384.71,335.93,10.58,8.64" target="#b3">[4]</ref>, and one implements 4 features, tackling the two non-English languages <ref type="bibr" coords="3,340.90,347.88,10.58,8.64" target="#b1">[2]</ref>. Most of the employed features have already been described in previous work and last year's competition <ref type="bibr" coords="3,426.98,359.84,10.58,8.64" target="#b8">[8]</ref>, hence we omit a detailed description.</p><p>West and Lee <ref type="bibr" coords="3,209.71,383.75,11.62,8.64" target="#b9">[9]</ref> develop new resources, such as vulgarity dictionaries for German and Spanish, and they describe a set of 6 features that exploit a-posteriori knowledge. Moreover, an in-depth study of the impact of language-independent, languagedependent, and a-posteriori features on detection performance is conducted. They find that language-independent features might suffice to achieve a certain performance, while the a-posteriori features significantly improve performance.</p><p>The classifiers employed were an ADTree <ref type="bibr" coords="3,321.80,455.48,10.58,8.64" target="#b9">[9]</ref>, an SVM <ref type="bibr" coords="3,375.43,455.48,10.58,8.64" target="#b3">[4]</ref>, and a handmade decision tree <ref type="bibr" coords="3,171.29,467.43,10.58,8.64" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation</head><p>Figure <ref type="figure" coords="3,164.31,512.97,4.98,8.64">1</ref> shows the detection performances of the vandalism detectors. Over all languages the detector of West and Lee <ref type="bibr" coords="3,287.54,524.93,11.62,8.64" target="#b9">[9]</ref> outperforms the other detectors by far. This detector's performance with regard to area under the precision-recall curve (PR-AUC) is highest on English edits, while German and particularly Spanish vandalism edits are less well detected. The plots indicate that the classifier for English edits can be adjusted so that it can operate without human supervision: at 0.99 precision, the detector still achieves 0.2 recall. However, this cannot be done for German and Spanish edits since the detector never achieves much more than 0.8 precision on these languages. Nevertheless, the detector has a remarkably stable precision on German edits: the drop of precision from 0.0 recall to 0.7 recall is only about 0.1. The ROC curves show a slightly different picture than the precision-recall curves since the performance of West and Lee's detector appears to be better on German edits than on English ones; the rate of false positives begins to increase comparably late at 0.8 true positive rate (recall). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Comparison to PAN 2010</head><p>In Figure <ref type="figure" coords="5,173.94,378.68,4.98,8.64">2</ref> the detection performances of the top vandalism detectors <ref type="bibr" coords="5,413.62,378.68,10.79,8.64" target="#b0">[1,</ref><ref type="bibr" coords="5,426.84,378.68,8.30,8.64" target="#b5">6]</ref> of PAN'10 are compared to the top detector of PAN'11. To allow for such a comparison, we have retrained West and Lee's detector as if it had been submitted to the PAN'10 competition.</p><p>Using their detector's edit model α for the edits of the PAN-WVC-10, we have retrained an ADTree classifier with 30 boosting iterations on the 50% portion of the corpus that was used as PAN'10 training corpus. The trained classifier was then tested against the remainder of the PAN-WVC-10 that was used as PAN'10 test corpus. As can be seen, West and Lee's detector outperforms those of Mola Velasco and Adler et al. both in terms of precision-recall AUC and ROC-AUC.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>The results of the 2nd international competition on vandalism detection can be summarized as follows: three vandalism detectors have been developed, which employ a total of 65 features to quantify vandalism characteristics of an edit, 10 more than last year. One detector achieves outstanding performance and allows for its practical use on English edits. The same detector also performs best on German and Spanish edits, but its performance characteristics on these languages forecloses practical application at the moment. Moreover, we have introduced the first multilingual corpus of Wikipedia vandalism edits, the PAN Wikipedia vandalism corpus 2011 (PAN-WVC-11). Lessons learned from the competition include that crowdsourcing annotations on non-English edits cannot be done as well via Amazon's Mechanical Turk. In the light of this observation the development of language-independent features for vandalism detection as well as features that exploit a-posteriori knowledge about an edit are of particular importance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,134.77,127.29,345.82,519.96"><head></head><label></label><figDesc>Performances of the top 2 vandalism detectors of PAN'10 compared to the best performing detector of PAN'11: the left plot shows precision-recall curves, the right plot ROC curves. The area under each curve (AUC) is given.</figDesc><table coords="4,134.77,127.29,345.82,519.96"><row><cell></cell><cell>1 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.8 0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.8 0.8</cell><cell></cell><cell></cell><cell cols="2">West and Lee (ROC-AUC 0.94812)</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">West and Lee</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">West and Lee</cell><cell></cell></row><row><cell>Precision Precision</cell><cell>0.4 0.6 0.4 0.6</cell><cell cols="3">(PR-AUC 0.66522) (PR-AUC 0.82230) Dragusanu et al. (PR-AUC 0.42464) West and Lee (PR-AUC 0.75385) Mola Velasco</cell><cell></cell><cell>TP-rate TP-rate</cell><cell>0.4 0.6 0.4 0.6</cell><cell></cell><cell></cell><cell cols="3">(ROC-AUC 0.95313) Dragusanu et al. (ROC-AUC 0.82963) Mola Velasco (ROC-AUC 0.92236) Adler et al. (ROC-AUC 0.90351)</cell></row><row><cell></cell><cell>0.2 0.2</cell><cell cols="2">Adler et al. (PR-AUC 0.49263)</cell><cell></cell><cell></cell><cell></cell><cell>0.2 0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0 0</cell><cell cols="3">0 English 0.2 0 0.2 English, PAN-WVC-10 0.4 0.6 Recall Recall 0.4</cell><cell>0.8 0.8</cell><cell>1 1</cell><cell>0 0</cell><cell>0 0</cell><cell>0.2 0.2</cell><cell cols="3">0.4 FP-rate 0.6 FP-rate 0.4 0.6 English, PAN-WVC-10 0.8 English 0.8</cell><cell>1 1</cell></row><row><cell cols="3">1 Figure 2.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Precision</cell><cell>0.4 0.6</cell><cell></cell><cell cols="2">West and Lee (PR-AUC 0.70591) Aksit (PR-AUC 0.18978)</cell><cell></cell><cell>TP-rate</cell><cell>0.4 0.6</cell><cell></cell><cell></cell><cell cols="3">West and Lee (ROC-AUC 0.96938) Aksit (ROC-AUC 0.74063)</cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>0 German 0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8 German</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Recall</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">FP-rate</cell><cell></cell></row><row><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">West and Lee</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">(PR-AUC 0.48938)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0.8</cell><cell></cell><cell>Aksit</cell><cell></cell><cell></cell><cell></cell><cell>0.8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">(PR-AUC 0.22077)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Precision</cell><cell>0.4 0.6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>TP-rate</cell><cell>0.4 0.6</cell><cell></cell><cell></cell><cell cols="3">West and Lee (ROC-AUC 0.86829) Aksit (ROC-AUC 0.72947)</cell></row><row><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>0</cell><cell>0 Spanish 0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>0.2</cell><cell>0.4</cell><cell>0.6</cell><cell>0.8 Spanish</cell><cell>1</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Recall</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">FP-rate</cell><cell></cell></row><row><cell cols="14">Figure 1. Performances of the vandalism detectors of PAN'11: the left column shows precision-</cell></row><row><cell cols="14">recall curves, the right column ROC curves; the first row shows English edits, the second and</cell></row><row><cell cols="12">third row German and Spanish edits. The area under each curve (AUC) is given.</cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,151.36,187.06,318.66,8.64;6,151.36,199.01,325.00,8.64;6,151.36,210.79,327.29,8.82;6,151.36,222.75,267.24,8.82;6,151.36,234.88,80.52,8.64" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,343.14,187.06,126.88,8.64;6,151.36,199.01,186.79,8.64">Detecting Wikipedia Vandalism using WikiTrust: Lab Report for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">Thomas</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luca</forename><surname>De Alfaro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ian</forename><surname>Pye</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,309.63,210.79,169.02,8.59;6,151.36,222.75,41.26,8.59">Notebook Papers of CLEF 2010 LABs and Workshops</title>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Donna</forename><surname>Harman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Emanuele</forename><surname>Pianta</surname></persName>
		</editor>
		<meeting><address><addrLine>Padua, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-09">2010. 22-23 September. September 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,151.36,246.83,317.28,8.64;6,151.36,258.61,304.50,8.82;6,151.36,270.57,311.97,8.59;6,151.36,282.70,67.52,8.64" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,215.03,246.83,253.61,8.64;6,151.36,258.79,186.97,8.64">An Empirical Research: &quot;Wikipedia Vandalism Detection using VandalSense 2.0&quot;: Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">Gediz</forename><surname>Aksit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,377.61,258.61,78.25,8.59;6,151.36,270.57,132.04,8.59">Notebook Papers of CLEF 2011 LABs and Workshops</title>
		<meeting><address><addrLine>Amsterdam, Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-09">2011. 19-22 September. September 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,151.36,294.66,323.52,8.64;6,151.36,306.43,318.59,8.82;6,151.36,318.39,308.11,8.82;6,151.36,330.52,193.70,8.64" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,283.95,294.66,190.92,8.64;6,151.36,306.61,46.87,8.64">The Relationship Between Precision-Recall and ROC curves</title>
		<author>
			<persName coords=""><forename type="first">Jesse</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Goadrich</surname></persName>
		</author>
		<idno type="DOI">10.1145/1143844.1143874</idno>
	</analytic>
	<monogr>
		<title level="m" coord="6,216.66,306.43,253.30,8.59;6,151.36,318.39,71.89,8.59">ICML&apos;06: Proceedings of the 23rd International Conference on Machine Learning</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="233" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,151.36,342.48,308.06,8.64;6,151.36,354.43,327.14,8.64;6,151.36,366.21,299.81,8.82;6,151.36,378.16,171.20,8.82" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,420.69,342.48,38.73,8.64;6,151.36,354.43,322.66,8.64">Detecting Wikipedia Vandalism using Machine Learning: Notebook for PAN at CLEF 2011</title>
		<author>
			<persName coords=""><forename type="first">Cristian-Alexandru</forename><surname>Drǎguşanu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marina</forename><surname>Cufliuc</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrian</forename><surname>Iftene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,162.15,366.21,212.78,8.59">Notebook Papers of CLEF 2011 LABs and Workshops</title>
		<meeting><address><addrLine>Amsterdam, Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-09">19-22 September. September 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,151.36,390.30,321.39,8.64;6,151.36,402.25,165.05,8.64" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="6,209.20,390.30,259.34,8.64">ROC Graphs: Notes and Practical Considerations for Researchers</title>
		<author>
			<persName coords=""><forename type="first">Tom</forename><surname>Fawcett</surname></persName>
		</author>
		<idno>HPL-2003-4</idno>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>HP</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="6,151.36,414.21,312.82,8.64;6,151.36,426.16,329.23,8.64" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="6,263.14,414.21,201.04,8.64;6,151.36,426.16,304.40,8.64">Wikipedia Vandalism Detection Through Machine Learning: Feature Review and New Proposals: Lab Report for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">Mola</forename><surname>Santiago</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Velasco</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,151.36,437.94,308.66,8.82;6,151.36,449.89,301.79,8.59;6,151.36,462.03,176.81,8.64" xml:id="b6">
	<monogr>
		<title level="m" coord="6,421.84,437.94,38.19,8.59;6,151.36,449.89,172.10,8.59">Notebook Papers of CLEF 2010 LABs and Workshops</title>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Donna</forename><surname>Harman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Emanuele</forename><surname>Pianta</surname></persName>
		</editor>
		<meeting><address><addrLine>Padua, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-09">22-23 September. September 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,151.36,473.98,308.15,8.64;6,151.36,485.94,300.89,8.64;6,151.36,497.71,315.51,8.82;6,151.36,509.85,262.19,8.64;6,151.36,521.80,109.87,8.64" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,219.16,473.98,185.54,8.64">Crowdsourcing a Wikipedia Vandalism Corpus</title>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<idno type="DOI">10.1145/1835449.1835617</idno>
	</analytic>
	<monogr>
		<title level="m" coord="6,281.87,497.71,180.64,8.59">Annual International ACM SIGIR Conference</title>
		<editor>
			<persName><forename type="first">Hsin-Hsi</forename><surname>Chen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Efthimis</forename><forename type="middle">N</forename><surname>Efthimiadis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jaques</forename><surname>Savoy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Fabio</forename><surname>Crestani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Stéphane</forename><surname>Marchand-Maillet</surname></persName>
		</editor>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010-07">July 2010</date>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="789" to="790" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,151.36,533.76,280.86,8.64;6,151.36,545.71,329.23,8.64;6,151.36,557.49,322.50,8.82;6,151.36,569.62,176.81,8.64" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,353.76,533.76,78.46,8.64;6,151.36,545.71,243.16,8.64">Overview of the 1st International Competition on Wikipedia Vandalism Detection</title>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Teresa</forename><surname>Holfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,266.46,557.49,202.82,8.59">Notebook Papers of CLEF 10 LABs and Workshops</title>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Donna</forename><surname>Harman</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2010-09">September 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,151.36,581.58,290.87,8.64;6,151.36,593.53,316.03,8.64;6,151.36,605.31,325.82,8.82;6,151.36,617.27,171.20,8.82" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,282.55,581.58,159.68,8.64;6,151.36,593.53,316.03,8.64;6,151.36,605.49,17.93,8.64">Multilingual Vandalism Detection using Language-Independent &amp; Ex Post Facto Evidence: Notebook for PAN at CLEF 2011</title>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><forename type="middle">G</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Insup</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,188.15,605.31,212.78,8.59">Notebook Papers of CLEF 2011 LABs and Workshops</title>
		<meeting><address><addrLine>Amsterdam, Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011-09">19-22 September. September 2011</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
