<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,158.14,115.90,299.09,12.90;1,201.66,133.83,212.04,12.90;1,223.43,154.03,168.50,10.75">External Plagiarism Detection using Information Retrieval and Sequence Alignment Notebook for PAN at CLEF 2011</title>
				<funder ref="#_ZpktR7x">
					<orgName type="full">COMSATS Institute of Information Technology, Islamabad, Pakistan</orgName>
				</funder>
				<funder>
					<orgName type="full">(FDP)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,176.78,190.77,66.69,8.64"><forename type="first">Rao</forename><surname>Muhammad</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,245.96,190.77,51.66,8.64"><forename type="first">Adeel</forename><surname>Nawab</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,305.19,190.77,64.63,8.64"><forename type="first">Mark</forename><surname>Stevenson</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,389.18,190.77,49.39,8.64"><forename type="first">Paul</forename><surname>Clough</surname></persName>
							<email>p.d.clough@sheffield.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,158.14,115.90,299.09,12.90;1,201.66,133.83,212.04,12.90;1,223.43,154.03,168.50,10.75">External Plagiarism Detection using Information Retrieval and Sequence Alignment Notebook for PAN at CLEF 2011</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3C310EC5B1B2B02337A6829253FF2CC8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>external plagiarism detection</term>
					<term>information retrieval</term>
					<term>greedy string tiling</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the University of Sheffield entry for the 3rd International Competition on Plagiarism Detection which attempted the monolingual external plagiarism detection task. A three stage framework was used: preprocessing and indexing, candidate document selection (using an Information Retrieval based approach) and detailed analysis (using the Running Karp-Rabin Greedy String Tiling algorithm). The submitted system obtained an overall performance of 0.0804, precision of 0.2780, recall of 0.0885 and granularity of 2.18 in the formal evaluation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In recent years, plagiarism and its detection has received significant attention within both academia and industry <ref type="bibr" coords="1,252.28,447.38,10.79,8.64" target="#b0">[1,</ref><ref type="bibr" coords="1,263.07,447.38,7.19,8.64" target="#b2">3]</ref>. The task of plagiarism detection itself can be divided into two main categories: (1) external plagiarism detection and (2) intrinsic plagiarism detection. The goal of external plagiarism detection is to identify the source (or original) document(s) that have been used to plagiarise a suspicious document. On the other hand, in intrinsic plagiarism detection the source documents are not available and plagiarised text is identified by looking for stylistic inconsistencies or text which is different from the rest.</p><p>In the 2011 PAN competition the University of Sheffield entry attempted the monolingual external plagiarism detection task. Our system did not attempt translated or multilingual plagiarism detection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Related Work</head><p>The field of plagiarism detection has been a well-studied area over the years. However, direct comparison of performance using different existing approaches was hampered by the lack of a standard evaluation resource. Since 2009, PAN has been organising an international competition on plagiarism detection to evaluate the performance of different approaches using a common data set.</p><p>The systems that participated in 1st and 2nd PAN competitions <ref type="bibr" coords="2,402.38,119.31,11.45,8.64" target="#b8">[9,</ref><ref type="bibr" coords="2,413.83,119.31,7.64,8.64" target="#b7">8]</ref> normally used a multi-stage process for plagiarism detection: pre-processing, candidate retrieval, detailed analysis and post-processing. The pre-processing step normally involved stemming, stop word removal, sorting word n-grams etc. The aim of applying different preprocessing techniques was to normalize the effect of obfuscation. The majority of the systems used an IR based approach (with and without hashing) for candidate document selection. Using this approach the entire source collection is converted to fixed length word n-grams or fingerprints and indexed. Each word n-gram or fingerprint in a suspicious document is queried in the index and source documents with word n-grams or fingerprints above some pre-defined threshold are marked as potential candidates. For the detailed analysis stage, heuristic sequence alignment algorithms are often used to extract suspicious-source section pairs. Portions of text that match exactly are used as seeds to identify longer passages using match merging heuristics. In the post-processing step, passages shorter than a pre-defined length or whose similarity score was less than given threshold under a retrieval model were discarded. In addition, passages that are ambiguous (could have been derived from multiple source documents) were discarded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">External Plagiarism Detection</head><p>Our proposed system consists of three stages: 1) pre-processing and indexing, 2) candidate document selection and 3) detailed analysis using Running Karp-Rabin Greedy String Tiling (RKR-GST).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preprocessing and Indexing</head><p>Each document in the source and suspicious collections was split into sentences using the NLTK sentence detector <ref type="bibr" coords="2,253.69,439.54,10.58,8.64" target="#b1">[2]</ref>. The text was converted into lower case and all the non-alphanumeric characters removed. Documents in the source collection were then indexed with the Terrier IR system <ref type="bibr" coords="2,275.44,463.45,10.58,8.64" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Candidate Document Selection</head><p>The aim of candidate document selection stage is to identify the source documents for each suspicious document. This is an important part of the process in a multi-stage approach to external plagiarism detection since source documents missed at this stage cannot be retrieved in a later stage. As many of the source documents as possible should be obtained at this stage, however, the total number of documents that are identified is limited by the processing required for the detailed analysis stage. Our system uses Information Retrieval for Candidate Document Selection.</p><p>The process of candidate document retrieval works as follows. A suspicious document is split into sentences which are used as queries. The index is queried against each sentence to retrieve a set of source (or original) document(s) and the top K documents selected for each query. Results of multiple queries are merged using a score-based fusion approach to generate final list of ranked source documents. A linear combination of the scores based on the CombSUM approach was used <ref type="bibr" coords="2,390.74,656.44,10.58,8.64" target="#b3">[4]</ref>. In the CombSUM method, the final score, S f inalscore , is obtained by adding the scores obtained against each query q:</p><formula xml:id="formula_0" coords="3,258.04,151.70,222.56,31.28">S f inalscore = Nq q=1 S q (d)<label>(1)</label></formula><p>where N q is the total number of queries to be combined and S q (d) is the similarity score of a document d for a query q .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Detailed Analysis</head><p>For the detailed analysis stage, we used the same sequence alignment algorithm, Running Karp-Rabin Greedy String Tiling (GST), as our entry for last year's competition (see <ref type="bibr" coords="3,153.30,273.92,11.62,8.64" target="#b4">[5]</ref> for a detailed description).</p><p>The suspicious and candidate source document pairs identified in the candidate selection stage are each represented as a sequence of tokens. The sequences are aligned using the GST algorithm after which aligned tokens are merged using match merging heuristics to generate longer aligned sections. In post-processing, sections whose length is less than a certain threshold are discarded and a final set of source-suspicious section pairs are reported.</p><p>The behavior of the detailed analysis stage can be changed by adjusting various parameters: 1) length of longest match (α length ) filters candidate documents for further analysis. If α length between a pair of aligned documents was greater than a certain threshold then it is analysed to identify suspicious-source section pairs, 2) minimum match length (mml) defines the minimum length of a match in aligning two sequences of tokens, 3) length of gap (α merge ) defines the distance between pairs of aligned passages which are merged into a single passage and 4) discard length (α discard ) defines the minimum length for a merged section, any shorter than this are discarded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">System Development</head><p>The system was developed using the test corpus from the 2010 PAN competition (PAN-PC-10) <ref type="bibr" coords="3,166.04,524.93,10.58,8.64" target="#b6">[7]</ref>.</p><p>Candidate Document Selection (Section 2.2): Results of the candidate document selection stage for different types of obfuscations are shown in Table <ref type="table" coords="3,423.93,548.84,3.74,8.64">1</ref>. The top 10 documents were selected, retrieving any more leads to difficulties in processing the documents in the detailed analysis stage.</p><p>The recall for source documents is over 0.55 over the whole corpus but the type of obfuscation effects the recall. The best recall is obtained for simulated obfuscation but the results for the none, low and high types are much lower. We analysed the number of source documents were used to plagiarise each suspicious document and found the results varied by obfuscation type. All the suspicious documents that used simulated plagiarism were derived from fewer than 10 source documents. However, more documents were used for other types of obfuscation and 23.86% of none, 30.72% of low  <ref type="table" coords="4,181.18,189.35,3.36,8.06">1</ref>. Performance for top 10 candidate documents using the PAN-PC-10 corpus and 31.11% of high documents were plagiarised using 10 or more source documents. A large number of source documents adversely effects our approach to candidate document selection and effects performance for the none, low and high obfuscation types.</p><p>Detailed Analysis Stage (Section 2.3): Parameters for Greedy String Tiling algorithm were selected using a small number of documents from the PAN-PC-10 corpus. The values of α length , α merge and α discard were varied and it was observed that a change in one parameter's value effects the system's performance. The best performance was observed with α length &gt; 5, α merge ≤ 35 characters and α discard ≤ 230 characters. The computational effort required by Greedy String Tiling made it difficult to tune all the parameters on a large dataset.  <ref type="table" coords="4,158.30,426.71,3.36,8.06">2</ref>. Performance of proposed system for detailed analysis stage on subset of 60 documents randomly selected from PAN-PC-10 corpus A set of 60 documents was created by randomly selecting 15 suspicious documents for each obfuscation type: none, low, high and simulated. These were used to extract suspicious-source section pairs by choosing 10 candidate documents for each suspicious document. Table <ref type="table" coords="4,227.60,516.29,4.98,8.64">2</ref> shows the results when length of mml was changed from 2 to 5 using the best parameter values observed for a very small set of documents. Best results are obtained with mml = 3, indicating that a minimum match of three words gives good performance. The system gets good precision but recall is low and granularity is high. The reason for low recall is that only 10 documents were selected as candidates. GST algorithm can only detect exact matches and fails to detect paraphrasing. Cases of plagiarism created with high obfuscation might be increasing the granularity while merging exact matches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">System Performance</head><p>Our system achieved an overall performance of 0.0804, precision of 0.2780, recall of 0.0885 and granularity of 2.18 in the formal evaluation. Candidate Document Selection (Section 2.2): Table <ref type="table" coords="5,368.12,300.07,4.98,8.64" target="#tab_2">3</ref> shows the document level results on the test corpus for the top 10 candidate documents before and after applying the detailed analysis stage. Performance is shown both for the entire corpus and for each type of obfuscation. After the candidate document selection stage the recall score for the entire corpus is 0.5596 (for the top 10 candidate documents). This figure drops to 0.2827 after the detailed analysis stage. The drop in recall varies by obfuscation type. There is no reduction for the none obfuscation but the difference increases for more obfuscated texts. Large reductions in recall are observed for the high and simulated types.</p><p>Detailed Analysis Stage (Section 2.3): The GST algorithm is best suited to detect verbatim copy and fails to detect rewritten text. However, a major portion of test corpus is composed of low, high and simulated obfuscations. Therefore, the sequence alignment algorithm did not work correctly to align a pair of suspicious and candidate document. The poor performance of the GST algorithm for these types of obfuscation explains why the recall decreases so severely for these types after the detailed analysis stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Sources of Error</head><p>Detailed Analysis Stage (Section 2.3): The system's performance for this stage is worst. Several parameters α length , α merge and α discard and mml were set using a small set of documents due to processing limitations. Using a larger corpus may lead to more suitable values for these parameters being identified. In addition, GST fails to align rewritten text (cases of simulated, low and high obfuscations). If the algorithm is adapted to identify rewritten text then it will also improve the overall performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This paper described the University of Sheffield entry to the 3rd international PAN plagiarism detection competition which attempted to identify monolingual external plagiarism. Our system did not attempt to identify translation/multilingual plagiarism. A three stage approach was used: preprocessing and indexing, candidate selection and detailed analysis. The proposed approach achieved an overall performance of 0.0804, precision of 0.2780, recall of 0.0885 and granularity of 2.18 in the formal evaluation in which monolingual and multilingual external plagiarism cases were evaluated together.</p><p>The main source of error occurred in the detailed analysis stage. The approach used did not perform well for the low, high and simulated classes of obfuscation. In future, we plan to adapt the GST algorithm to identify correspondences between texts. However, care must be taken to ensure that the algorithm does not become too complex to be applied to the large amounts of data in the PAN corpus.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,134.77,118.07,345.83,178.69"><head>Table 3 .</head><label>3</label><figDesc>Document level performance using top 10 candidate documents before and after detailed analysis on PAN-PC-11 test corpus Our analysis shows that the test corpus<ref type="bibr" coords="5,317.35,264.21,11.62,8.64" target="#b6">[7]</ref> contains 555 (10%) documents plagiarised with translated, 105 (1.89%) with simulated, 2404 (43.33%) with high, 2369 (42.70%) with low and 114 (2.05%) with none obfuscation.</figDesc><table coords="5,181.42,118.07,252.51,91.26"><row><cell cols="4">Document level performance before and after Detailed Analysis</cell></row><row><cell></cell><cell cols="3">Top 10 Candidate Documents After Detailed Analysis</cell></row><row><cell cols="2">Obfuscation Precision Recall</cell><cell>F1</cell><cell>Precision Recall F1</cell></row><row><cell cols="2">Entire corpus 0.1313 0.5596</cell><cell>0.195</cell><cell>0.3316 0.2827 0.3052</cell></row><row><cell>None</cell><cell cols="2">0.1807 0.7280 0.2895</cell><cell>0.6808 0.7280 0.7036</cell></row><row><cell>Low</cell><cell cols="2">0.1642 0.6890 0.2652</cell><cell>0.6547 0.5803 0.6153</cell></row><row><cell>High</cell><cell cols="2">0.1091 0.5223 0.1805</cell><cell>0.0643 0.0422 0.0510</cell></row><row><cell>Simulated</cell><cell cols="2">0.2648 0.1675 0.2052</cell><cell>0.5361 0.0859 0.1481</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p><rs type="person">Rao Muhammad Adeel Nawab</rs> thanks the <rs type="funder">COMSATS Institute of Information Technology, Islamabad, Pakistan</rs> for funding this work under the <rs type="programName">Faculty Development Program</rs> <rs type="funder">(FDP)</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_ZpktR7x">
					<orgName type="program" subtype="full">Faculty Development Program</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,138.13,350.10,342.46,7.77;6,146.47,361.06,48.56,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,233.24,350.10,77.52,7.77">Plagiarism on the rise</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Boisvert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Irwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,328.48,350.10,103.52,7.77">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="23" to="24" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.13,372.02,342.46,7.77;6,146.47,382.97,334.12,7.77;6,146.47,393.93,156.91,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,219.79,372.02,140.11,7.77">NLTK: The Natural Language ToolKit</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,379.69,372.02,100.90,7.77;6,146.47,382.97,334.12,7.77;6,146.47,393.93,89.40,7.77">Proceedings of the ACL-02 Workshop on Effective tools and methodologies for teaching natural language processing and computational linguistics</title>
		<meeting>the ACL-02 Workshop on Effective tools and methodologies for teaching natural language processing and computational linguistics</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="63" to="70" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.13,404.89,342.46,7.77;6,146.47,415.85,334.12,7.77;6,146.47,426.81,106.58,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,300.90,404.89,179.69,7.77;6,146.47,415.85,179.35,7.77">Academic Dishonesty in Graduate Business Programs: Prevalence, Causes, and Proposed Action</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mccabe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Butterfield</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Trevino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,333.03,415.85,147.57,7.77;6,146.47,426.81,36.36,7.77">Academy of Management Learning and Education</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="294" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.13,437.77,342.46,7.77;6,146.47,448.73,164.12,7.77" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="6,327.95,437.77,152.64,7.77;6,146.47,448.73,101.39,7.77">ImageCLEF -Experimental Evaluation of Visual Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.13,459.69,342.46,7.77;6,146.47,470.65,334.12,7.77;6,146.47,481.60,151.84,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,293.52,459.69,82.79,7.77">University of Sheffield</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nawab</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Stevenson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,396.57,459.69,84.02,7.77;6,146.47,470.65,334.12,7.77;6,146.47,481.60,125.69,7.77">Proceedings of the 4th International Workshop on Uncovering Plagiarism, Authorship, and Social Software Misuse. Lab Report for PAN at CLEF 2010</title>
		<meeting>the 4th International Workshop on Uncovering Plagiarism, Authorship, and Social Software Misuse. Lab Report for PAN at CLEF 2010</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.13,492.56,342.46,7.77;6,146.47,503.52,334.12,7.77;6,146.47,514.48,57.03,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,374.69,492.56,105.90,7.77;6,146.47,503.52,29.89,7.77">Terrier Information Retrieval Platform</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,196.52,503.52,228.88,7.77">Proceedings of the 27th European Conference on IR Research</title>
		<meeting>the 27th European Conference on IR Research</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="517" to="519" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.13,525.44,342.46,7.77;6,146.47,536.40,334.12,7.77;6,146.47,547.36,182.05,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,350.92,525.44,129.67,7.77;6,146.47,536.40,63.49,7.77">An Evaluation Framework for Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,230.05,536.40,250.55,7.77;6,146.47,547.36,100.49,7.77">Proceedings of the 23rd International Conference on Computational Linguistics (COLING 2010)</title>
		<meeting>the 23rd International Conference on Computational Linguistics (COLING 2010)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="997" to="1005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.13,558.32,342.46,7.77;6,146.47,569.28,334.12,7.77;6,146.47,580.23,279.70,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,356.59,558.32,124.00,7.77;6,146.47,569.28,132.21,7.77">Overview of the 2nd International Competition on Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Eiselt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,296.79,569.28,183.80,7.77;6,146.47,580.23,204.59,7.77">Proceedings of the CLEFŠ10 Workshop on Uncovering Plagiarism, Authorship and Social Software Misuse</title>
		<meeting>the CLEFŠ10 Workshop on Uncovering Plagiarism, Authorship and Social Software Misuse<address><addrLine>Padua, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.13,591.19,342.46,7.77;6,146.47,602.15,334.12,7.77;6,146.47,613.11,275.68,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,362.78,591.19,117.81,7.77;6,146.47,602.15,201.11,7.77">3rd PAN Workshop on Uncovering Plagiarism, Authorship and Social Software Misuse</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Agirre</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,367.21,602.15,113.39,7.77;6,146.47,613.11,211.46,7.77">25th Annual Conference of the Spanish Society for Natural Language Processing (SEPLN)</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1" to="77" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
