<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,160.26,115.96,294.84,12.62;1,165.52,133.89,284.31,12.62">Overview of the International Authorship Identification Competition at PAN-2011</title>
				<funder ref="#_KXhu9eC">
					<orgName type="full">National Science Foundation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,225.00,171.56,75.58,8.74"><forename type="first">Shlomo</forename><surname>Argamon</surname></persName>
							<email>argamon@iit.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="laboratory">Linguistic Cognition Lab</orgName>
								<orgName type="institution">Illinois Institute of Technology</orgName>
								<address>
									<postCode>60616</postCode>
									<settlement>Chicago</settlement>
									<region>IL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,327.74,171.56,58.15,8.74"><forename type="first">Patrick</forename><surname>Juola</surname></persName>
							<email>juola@mathcs.duq.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Mathematics and Computer Science</orgName>
								<orgName type="institution">Duquesne University</orgName>
								<address>
									<postCode>15282</postCode>
									<settlement>Pittsburgh</settlement>
									<region>PA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,160.26,115.96,294.84,12.62;1,165.52,133.89,284.31,12.62">Overview of the International Authorship Identification Competition at PAN-2011</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">50B25CA1B431C1024651B4200B494561</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper gives an overview of the evaluation methodology applied to authorship identification solutions as part of PAN 2011. The two variations of authorship identification that were explored were authorship attribution, determining which of a known set of authors wrote a text, and authorship verification, determining if a specific authors did or did not write a text. We summarize the methods used by the various participants, which were quite varied, and present the overall results of the evaluation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>There has been much interest in recent years in research on automatic methods for determining the authorship of anonymous documents based on internal evidence <ref type="bibr" coords="1,175.11,432.53,10.52,8.74" target="#b7">[7,</ref><ref type="bibr" coords="1,187.28,432.53,12.73,8.74" target="#b16">16,</ref><ref type="bibr" coords="1,201.67,432.53,7.01,8.74" target="#b9">9]</ref>. Indeed, accurate automatic authorship attribution of anonymous documents is of increasing importance for many applications, including homeland security, criminal and civil law, computer forensics, and humanities scholarship. However, despite the growing need for effective and reliable methods, research has been hampered by the lack of any canonical testbed for authorship attribution. Combined with the interdisciplinary nature of the field, this has often led to redundant and unsound research. The purpose of this authorship competition, held as part of the 2011 PAN Lab on Uncovering Plagiarism, Authorship, and Social Software Misuse, is to start redressing this problem, by advancing a standardized evaluation framework for authorship attribution and related problems.</p><p>A total of 13 different research groups submitted results for 7 different tasks within this evaluation framework, eight of which submitted papers describing their systems. In this paper we describe the evaluation framework, and report on evaluation of the different authorship analysis methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">The problem</head><p>In the basic form of the authorship attribution problem, we are given examples of the writing of a number of candidate authors and are asked to determine which of them authored a given anonymous text. In this straightforward form, the authorship attribution problem fits the standard modern paradigm of a text categorization problem <ref type="bibr" coords="2,237.61,142.90,14.61,8.74" target="#b15">[15]</ref>. The components of text categorization systems are by now fairly well-understood: documents are represented as numerical vectors that capture statistics of potentially relevant features of the text and machine learning methods are used to find classifiers that separate documents that belong to different classes.</p><p>However, real-life authorship identification problems are rarely as elegant as straightforward "research-type" text categorization problems, in which we have a small closed set of candidate authors and essentially unlimited training text for each. One important issue that arises in the real world is the existence of an open candidate set, that is, the actual author might be an author we don't know about at all. In this case, the problem is to assign the document either to one of the authors we know of, or to "Someone Else".</p><p>The most reduced version of this open-candidate case is that where there is no candidate set at all, but just a single suspect. In this case, the challenge is to determine if the suspect is or is not the author. This is called the authorship verification problem. As a categorization problem, verification is significantly more difficult than basic attribution and less work has been done on it, but see, e.g., <ref type="bibr" coords="2,134.77,347.27,15.50,8.74" target="#b18">[18,</ref><ref type="bibr" coords="2,151.93,347.27,7.75,8.74" target="#b8">8,</ref><ref type="bibr" coords="2,161.33,347.27,12.73,8.74" target="#b11">11,</ref><ref type="bibr" coords="2,175.72,347.27,7.01,8.74" target="#b5">5]</ref>. If, say, we just need to know if a text was written by Shakespeare or by Marlowe, we could just compare the candidate against their respective known texts. If, however, we needed to know if the text was written by Shakespeare or anyone else, it would be difficult to assemble a sufficiently representative sample of non-Shakespeare texts to compare against, and something more sophisticated would be required.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Corpus</head><p>A corpus was developed, based on the Enron email corpus<ref type="foot" coords="2,380.26,489.68,3.97,6.12" target="#foot_0">3</ref> , to account for several different common attribution and verification scenarios. The corpus contains five separate training collections, and seven test collections, as follows. Two training sets are provided for authorship attribution, a "Large" set containing 9337 documents by 72 different authors and a "Small" set containing 3001 documents by 26 different authors (the author sets are disjoint). For each attribution problem, two test sets are provided, one containing texts only written by the authors in the training set, and one also containing texts written by around 20 other authors each.</p><p>The other three training sets are for verification, and so contain only emails from a single author (different from those in other training sets). The verification training sets contain 42, 55, and 47 documents, respectively. Each has an associated test set comprising a mixture of documents written by the training author and written by others (some of these are from the Enron corpus, and some are not).</p><p>As the tasks are intended to reflect a natural task environment, there are some texts, both in training and in testing sets, that are not in English, or that are automatically generated.</p><p>Personal names and email addresses in the corpus have been automatically redacted, and replaced (on a token-by-token basis) by ¡NAME/¿ and ¡EMAIL/¿ tags, respectively. This redaction is admittedly imperfect, but random spotchecking was applied to reduce the likelihood of missing occurrences. Other than this redaction, each text is typographically identical to the original electronic text, so systems could, in principle, rely on line length, punctuation, and the like.</p><p>Finally, authorship was determined based on From: email headers; this necessitated determining, in some cases, that multiple email addresses corresponded to the same individual. Manual spot-checking was applied here as well to ensure quality, though some errors were let through and discovered during the evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Metrics</head><p>For evaluating authorship identification, we used the standard information retrieval metrics of precision, recall, and F1. Precision, for a particular author A, is defined as the fraction of attributions that a system makes to A that are correct:</p><formula xml:id="formula_0" coords="3,260.01,399.83,94.14,22.31">P A = correct(A) attributions(A)</formula><p>Recall, for a particular author A, is defined as the fraction of test documents written by A that are (correctly) attributed to A: R A = correct(A) documents-by(A) F 1 is defined as the harmonic mean of recall and precision:</p><formula xml:id="formula_1" coords="3,274.85,513.30,63.97,23.23">F 1 = 2P A R A P A + R A</formula><p>For the authorship attribution tasks, we need to aggregate these measures over all the different test authors. We applied two methods with different properties, macro-averaging and micro-averaging. For a given metric M , set of n authors {A i }, with a total of k test documents, these are defined as:</p><formula xml:id="formula_2" coords="3,234.03,598.61,146.30,37.43">macro-avg M ({A i }) = 1 n i M Ai micro-avg M ({A i }) = 1 k i k i M Ai</formula><p>where k i is the number of test documents written by author A i . Micro-averaging will give more credit to accuracy on authors with more test documents, while macro-averaging gives the same credit to all authors, even if they wrote just one test document.</p><p>For authorship verification, the author set contains just one author, so averaging is not necessary.</p><p>Finally, to achieve an overall ranking for each task, we ranked system performances for each of the measures-six for attribution (macro-and micro-averaged P , R, and F 1 ) and three for verification, and summed the ranks for each entry in each task. The lower the rank sum, the better (overall) the performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Survey of Submissions</head><p>All documented submissions, within their diversity, followed classic methodology for authorship identification, and (a) identified a set of features that were calculated from the texts, whose values then (b) served as input to some classification algorithm. In this section, we summarize the submissions in terms of what features they used and what algorithms they used. We note that, as in any such summary of varied systems, we inevitably must oversimplify, so please see the full papers describing each system for more information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Features</head><p>There were a number of different kinds of features used by participants, some traditional, some quite novel.</p><p>The first type of feature are those derived from the word usage in the texts, which we term lexical features. Simplest, are the frequencies of the various words and word n-grams that appear in the text. Also relevant, based on previous studies, are the relative frequencies of function words (or stopwords) and of specific classes of words: pronouns, modal verbs, discourse linking words/phrases (such as "however", "on the other hand"), slang terms, contractions, and emoticons (or smileys). Also considered were frequencies of US vs. UK variants (a dialect indicator), various types of spelling errors, different types of named entities (people, organizations, dates, etc.), and semantic features of words (polysemy, specificity of meaning, etc.).</p><p>The second type of feature are those at the character level, and include character n-grams (usually for n = 3), frequent suffixes, and punctuation usage.</p><p>The third type of feature considered relate to the format of the text, including various length-related features (lengths of lines, words, sentences), overall formatting of the text (e.g., fraction of empty lines), orthographic features (e.g., capitalization, frequency of non-alphanumeric characters), and a novel feature, Intro/Outro that looked for common beginnings and endings of texts, and noted their presence/absence as cues to authorship.</p><p>The fourth type of feature were syntax related features, both part-of-speech n-grams and phrase types (or dependency link types).</p><p>Additionally, two of the submissions used forms of complexity measures over sentences and words, by measuring such things as perplexity and morphological complexity. The last, perhaps most novel, kind of feature used was one used by Solorio et al., based on clustering the training data and measuring the distance of various texts from the cluster centroids, using those distances as features for learning.</p><p>The types of features and the submissions using each are listed in Figure <ref type="figure" coords="5,471.11,544.86,3.87,8.74" target="#fig_0">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Algorithms</head><p>A wide variety of algorithmic approaches were taken by the participants. Several used different forms of linear classifiers. Support vector machines <ref type="bibr" coords="5,423.80,606.23,10.52,8.74" target="#b4">[4]</ref> were used by Solorio et al., and a variant for multiclass problems, SVM multiclass <ref type="bibr" coords="5,446.08,620.25,15.50,8.74" target="#b17">[17]</ref> was used by Luyckx. Vilariño compared three approaches: the linear Rocchio <ref type="bibr" coords="5,446.59,632.21,15.50,8.74" target="#b14">[14]</ref> and Naive Bayes <ref type="bibr" coords="5,192.20,644.16,15.50,8.74" target="#b10">[10]</ref> methods, and 100-nearest neighbor <ref type="bibr" coords="5,369.65,644.16,9.96,8.74" target="#b3">[3]</ref>. Mikros and Perifanos used the RLR logistic regression algorithm <ref type="bibr" coords="5,324.22,656.12,9.96,8.74" target="#b6">[6]</ref>.</p><p>Other machine learning approaches were also applied. Tanguy et al. applied maximum entropy learning <ref type="bibr" coords="6,256.11,130.95,15.50,8.74" target="#b12">[12]</ref> for attribution, and decision trees <ref type="bibr" coords="6,425.54,130.95,15.50,8.74" target="#b13">[13]</ref> and rule learning <ref type="bibr" coords="6,172.61,142.90,10.52,8.74" target="#b1">[2]</ref> for verification. Kouris and Stamatatos used a co-training approach, combining a kind of nearest-neighbor classifier with a support vector machine approach, to label unlabeled data to improve training. Escalante used a unique form of ensemble learning, EPSMS <ref type="bibr" coords="6,293.78,178.77,9.96,8.74" target="#b5">[5]</ref>. Finally, Kern et al. applied a complex multi-level learning scheme using base classifiers which were either bagged decision forests <ref type="bibr" coords="6,186.33,202.68,10.52,8.74" target="#b0">[1]</ref> or support vector machines, depending on the feature types, and a probabilistic metaclassifier to integrate base classifications. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Attribution</head><p>Authorship attribution results, for the four attribution tasks, are given in Tables <ref type="table" coords="6,134.77,552.70,51.20,8.74">2 through 5</ref>. As the tables show, the authorship attribution approach of Tanguy et al. was very highly ranked across all the attribution tasks. It was beaten only once significantly by the approach of Kourtis and Stamatatos on the Large task. The approach of Kern et al. achieved very high precision on the Small attribution tasks, but paid for it in reduced recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Verification</head><p>Verification results are given in  authorship verification is considerably more difficult than authorship attribution. High precision evidently is easier to achieve than high recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>With the great variety of feature sets and classification methods applied, it is difficult to form any overall conclusions from the basic results; more nuanced understanding will have to emerge from discussion among researchers and follow-on studies. One thing that is clear, however, is the need to decouple, to the extent possible, feature choice from classification method, so that the separate advantages and deficiencies of different feature types and algorithms can be understood, as well as their interactions. As well, one characteristic of all the better methods seems to be a preference for precision over recall (which is probably preferred in real-world applications), as in the more difficult open tasks, precision generally stayed high, while recall declined.</p><p>Regarding the different methods, the best method overall for attribution was that of Tanguy et al., who applied the largest and most diverse feature set to the problem, which may indicate the usefulness to find ways of profitably learning classifiers from very large numbers of features with diverse characters.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,205.57,475.46,204.22,7.89"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. Feature types and submissions using them.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="8,166.23,653.55,282.91,7.89"><head>Fig. 6 .</head><label>6</label><figDesc>Fig. 6. Results for Verification test sets (with extraneous documents).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,158.44,246.43,295.40,215.46"><head></head><label></label><figDesc>Results for the Large test set without extraneous documents.</figDesc><table coords="6,158.44,246.43,295.40,215.46"><row><cell></cell><cell cols="4">Macro-averaged Micro-averaged Rank</cell></row><row><cell>Run</cell><cell cols="2">Prec Recall F1</cell><cell cols="2">Prec Recall F1</cell><cell>Sum</cell></row><row><cell cols="5">kourtis-2011-06-08-1000 0.549 0.532 0.52 0.658 0.658 0.658</cell><cell>12</cell></row><row><cell>kern-2011-06-08-1500</cell><cell cols="4">0.615 0.442 0.465 0.642 0.642 0.642</cell><cell>17</cell></row><row><cell cols="5">tanguy-2011-06-07-1600 0.62 0.444 0.459 0.594 0.594 0.594</cell><cell>17</cell></row><row><cell cols="5">tanguy-2011-06-07-1700 0.62 0.444 0.459 0.594 0.594 0.594</cell><cell>17</cell></row><row><cell>snider-2011-06-08-1548</cell><cell cols="4">0.714 0.321 0.384 0.7 0.482 0.571</cell><cell>30</cell></row><row><cell>mikros-2011-06-08-2245</cell><cell cols="4">0.391 0.356 0.353 0.519 0.519 0.519</cell><cell>41</cell></row><row><cell>luyckx-2011-06-10-1640</cell><cell cols="4">0.391 0.344 0.342 0.522 0.522 0.522</cell><cell>41</cell></row><row><cell cols="5">escalante-2011-06-07-0934 0.608 0.294 0.303 0.508 0.508 0.508</cell><cell>48</cell></row><row><cell>luyckx-2011-06-10-1635</cell><cell cols="3">0.348 0.345 0.34 0.5 0.5</cell><cell>0.5</cell><cell>53</cell></row><row><cell cols="5">vilarino-2011-05-31-1456 0.364 0.337 0.364 0.428 0.428 0.428</cell><cell>55</cell></row><row><cell cols="5">vilarino-2011-05-31-1455 0.534 0.095 0.103 0.238 0.238 0.238</cell><cell>69</cell></row><row><cell>ryan-2011-06-08-2331</cell><cell>0.186 0.19</cell><cell cols="3">0.172 0.255 0.255 0.255</cell><cell>70</cell></row><row><cell cols="3">eriksson-2011-06-13-0920 0.508 0.094 0.1</cell><cell cols="2">0.221 0.221 0.221</cell><cell>75</cell></row><row><cell cols="5">vilarino-2011-05-31-1454 0.232 0.139 0.147 0.219 0.219 0.219</cell><cell>79</cell></row><row><cell>solorio-2011-06-08-1217</cell><cell cols="4">0.171 0.084 0.066 0.148 0.148 0.148</cell><cell>91</cell></row><row><cell cols="5">noecker-2011-06-08-2356 0.231 0.041 0.057 0.035 0.035 0.035</cell><cell>94</cell></row><row><cell>Fig. 2.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,134.77,644.16,345.83,20.69"><head>Table 6 .</head><label>6</label><figDesc>Snider et al. achieved the best precision performance overall, though not the highest recall. It should be mentioned that Results for the Large+ test set with extraneous documents. Results for the Small+ test set with extraneous documents.</figDesc><table coords="7,158.44,152.06,295.40,476.55"><row><cell></cell><cell cols="4">Macro-averaged Micro-averaged Rank</cell></row><row><cell>Run</cell><cell>Prec Recall F1</cell><cell cols="2">Prec Recall F1</cell><cell>Sum</cell></row><row><cell cols="4">tanguy-2011-06-07-1700 0.688 0.267 0.321 0.779 0.471 0.587</cell><cell>9</cell></row><row><cell>snider-2011-06-08-1548</cell><cell cols="3">0.654 0.227 0.258 0.627 0.405 0.492</cell><cell>20</cell></row><row><cell>kern-2011-06-08-1500</cell><cell cols="3">0.673 0.179 0.226 0.802 0.383 0.518</cell><cell>21</cell></row><row><cell cols="4">tanguy-2011-06-07-1600 0.806 0.148 0.208 0.924 0.299 0.451</cell><cell>26</cell></row><row><cell cols="4">escalante-2011-06-07-0934 0.53 0.203 0.191 0.446 0.446 0.446</cell><cell>29</cell></row><row><cell cols="4">vilarino-2011-05-31-1456 0.347 0.245 0.263 0.368 0.368 0.368</cell><cell>32</cell></row><row><cell>mikros-2011-06-08-2245</cell><cell cols="3">0.398 0.183 0.209 0.499 0.292 0.369</cell><cell>36</cell></row><row><cell cols="4">vilarino-2011-05-31-1455 0.488 0.084 0.088 0.222 0.222 0.222</cell><cell>50</cell></row><row><cell>ryan-2011-06-08-2331</cell><cell cols="3">0.19 0.154 0.132 0.216 0.216 0.216</cell><cell>53</cell></row><row><cell cols="4">eriksson-2011-06-13-0920 0.432 0.064 0.062 0.201 0.201 0.201</cell><cell>59</cell></row><row><cell cols="4">vilarino-2011-05-31-1454 0.153 0.092 0.089 0.175 0.175 0.175</cell><cell>63</cell></row><row><cell cols="4">noecker-2011-06-08-2356 0.227 0.054 0.06 0.037 0.037 0.037</cell><cell>70</cell></row><row><cell cols="2">noecker-2011-06-08-2337 0.001 0.011 0</cell><cell cols="2">0.001 0.001 0.001</cell><cell>78</cell></row><row><cell cols="5">Fig. 3. Macro-averaged Micro-averaged Rank</cell></row><row><cell>Run</cell><cell>Prec Recall F1</cell><cell cols="2">Prec Recall F1</cell><cell>Sum</cell></row><row><cell cols="4">tanguy-2011-06-07-1600 0.662 0.451 0.475 0.717 0.717 0.717</cell><cell>8</cell></row><row><cell cols="4">tanguy-2011-06-07-1700 0.662 0.451 0.475 0.717 0.717 0.717</cell><cell>8</cell></row><row><cell cols="4">escalante-2011-06-07-0934 0.676 0.381 0.387 0.709 0.709 0.709</cell><cell>19</cell></row><row><cell>mikros-2011-06-08-2245</cell><cell cols="3">0.529 0.419 0.424 0.659 0.659 0.659</cell><cell>28</cell></row><row><cell>kern-2011-06-08-1500</cell><cell cols="3">0.79 0.345 0.348 0.685 0.685 0.685</cell><cell>29</cell></row><row><cell>luyckx-2011-06-10-1635</cell><cell cols="3">0.435 0.378 0.371 0.642 0.642 0.642</cell><cell>39</cell></row><row><cell cols="4">kourtis-2011-06-08-1000 0.476 0.374 0.38 0.638 0.638 0.638</cell><cell>40</cell></row><row><cell>snider-2011-06-08-1548</cell><cell cols="2">0.644 0.323 0.343 0.66 0.6</cell><cell>0.629</cell><cell>45</cell></row><row><cell>luyckx-2011-06-10-1640</cell><cell cols="2">0.444 0.356 0.343 0.62 0.62</cell><cell>0.62</cell><cell>50</cell></row><row><cell>solorio-2011-06-08-1217</cell><cell cols="2">0.415 0.205 0.185 0.44 0.44</cell><cell>0.44</cell><cell>64</cell></row><row><cell cols="4">vilarino-2011-05-31-1456 0.236 0.284 0.358 0.432 0.432 0.432</cell><cell>65</cell></row><row><cell cols="4">vilarino-2011-05-31-1455 0.359 0.141 0.157 0.374 0.374 0.374</cell><cell>75</cell></row><row><cell>ryan-2011-06-08-2331</cell><cell cols="3">0.257 0.238 0.216 0.311 0.311 0.311</cell><cell>78</cell></row><row><cell cols="4">eriksson-2011-06-13-0920 0.304 0.158 0.144 0.372 0.372 0.372</cell><cell>80</cell></row><row><cell cols="4">noecker-2011-06-08-2356 0.305 0.187 0.144 0.232 0.232 0.232</cell><cell>84</cell></row><row><cell cols="4">vilarino-2011-05-31-1454 0.15 0.061 0.098 0.091 0.091 0.091</cell><cell>96</cell></row><row><cell cols="5">Fig. 4. Results for the Small test set without extraneous documents.</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="2,144.73,656.80,130.12,7.86"><p>http://www.cs.cmu.edu/ enron/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to thank the organizers of CLEF 2011 and PAN 2011 for their support which enabled this competition to take place. Thanks are also due all the participants who made this effort such a success.</p><p>Development of this competition was funded in part by <rs type="funder">National Science Foundation</rs> grant <rs type="grantNumber">CRI-CRD-0751198</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_KXhu9eC">
					<idno type="grant-number">CRI-CRD-0751198</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="9,142.96,492.97,274.18,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,203.76,492.97,61.96,7.86">Random forests</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,273.37,492.97,68.24,7.86">Machine learning</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,503.83,337.64,7.86;9,151.52,514.79,267.42,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,263.94,503.83,154.01,7.86">A simple, fast, and effective rule learner</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,434.71,503.83,45.88,7.86;9,151.52,514.79,202.64,7.86">Proceedings of the National Conference on Artificial Intelligence</title>
		<meeting>the National Conference on Artificial Intelligence</meeting>
		<imprint>
			<biblScope unit="page" from="335" to="342" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,421.04,514.79,59.55,7.86;9,151.52,525.75,82.94,7.86" xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Sons Ltd</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>JOHN WILEY</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,536.62,337.63,7.86;9,151.52,547.58,168.99,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,240.52,536.62,151.93,7.86">Nearest neighbor pattern classification</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Hart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,398.91,536.62,77.26,7.86;9,151.52,547.58,88.55,7.86">IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="27" />
			<date type="published" when="1967">1967</date>
		</imprint>
	</monogr>
	<note>Information Theory</note>
</biblStruct>

<biblStruct coords="9,142.96,558.44,337.63,7.86;9,151.52,569.40,306.52,7.86" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="9,300.60,558.44,179.99,7.86;9,151.52,569.40,158.99,7.86">An introduction to Support Vector Machines and other kernel-based learning methods</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Cristianini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,580.27,337.64,7.86;9,151.52,591.23,329.07,7.86;9,151.52,602.19,189.20,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,328.64,580.27,151.95,7.86;9,151.52,591.23,80.01,7.86">Particle swarm model selection for authorship verification</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Escalante</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Villaseñor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,239.51,591.23,241.09,7.86;9,151.52,602.19,98.10,7.86">Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="563" to="570" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,613.05,337.63,7.86;9,151.52,624.01,329.07,7.86;9,151.52,634.97,45.05,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,402.59,613.05,77.99,7.86;9,151.52,624.01,111.82,7.86">Liblinear: A library for large linear classification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><forename type="middle">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,270.85,624.01,172.36,7.86">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,645.84,337.63,7.86;9,151.52,656.80,108.74,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,195.40,645.84,92.29,7.86">Authorship attribution</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,299.00,645.84,181.59,7.86;9,151.52,656.80,24.37,7.86">Foundations and Trends in information Retrieval</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="233" to="334" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,119.67,337.63,7.86;10,151.52,130.63,329.07,7.86;10,151.52,141.59,102.60,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,254.33,119.67,226.26,7.86;10,151.52,130.63,12.67,7.86">Authorship verification as a one-class classification problem</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,183.75,130.63,296.84,7.86;10,151.52,141.59,11.09,7.86">Proceedings of the twenty-first international conference on Machine learning</title>
		<meeting>the twenty-first international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">62</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.96,152.55,337.63,7.86;10,151.52,163.51,329.07,7.86;10,151.52,174.47,99.41,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,322.81,152.55,157.78,7.86;10,151.52,163.51,42.73,7.86">Computational methods in authorship attribution</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Argamon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,204.01,163.51,276.58,7.86;10,151.52,174.47,23.77,7.86">Journal of the American Society for information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="26" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,185.43,337.98,7.86;10,151.52,196.39,233.70,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,197.07,185.43,283.52,7.86;10,151.52,196.39,32.07,7.86">Naive (bayes) at forty: The independence assumption in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,191.24,196.39,115.45,7.86">Machine Learning: ECML-98</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="4" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,207.34,337.98,7.86;10,151.52,218.30,329.07,7.86;10,151.52,229.26,329.07,7.86;10,151.52,240.22,104.16,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,278.04,207.34,202.55,7.86;10,151.52,218.30,102.10,7.86">Authorship attribution and verification with many authors and limited data</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Luyckx</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,277.58,218.30,203.02,7.86;10,151.52,229.26,127.69,7.86">Proceedings of the 22nd International Conference on Computational Linguistics</title>
		<meeting>the 22nd International Conference on Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="513" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,251.18,337.98,7.86;10,151.52,262.14,329.07,7.86;10,151.52,273.10,154.75,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,325.12,251.18,155.47,7.86;10,151.52,262.14,34.95,7.86">Using maximum entropy for text classification</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Nigam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,209.17,262.14,268.08,7.86">IJCAI-99 workshop on machine learning for information filtering</title>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="61" to="67" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,284.06,328.10,7.86" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="10,210.13,284.06,149.73,7.86">C4. 5: programs for machine learning</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Quinlan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<publisher>Morgan Kaufmann</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,295.02,337.98,7.86;10,151.52,305.98,62.12,7.86" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="10,205.09,295.02,168.04,7.86">Relevance feedback in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Rocchio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971">1971</date>
			<publisher>Prentice-Hall</publisher>
			<pubPlace>Englewood Cliffs NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,316.93,337.98,7.86;10,151.52,327.89,139.66,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,208.98,316.93,199.72,7.86">Machine learning in automated text categorization</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Sebastiani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,415.57,316.93,65.03,7.86;10,151.52,327.89,62.93,7.86">ACM computing surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="47" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,338.85,337.98,7.86;10,151.52,349.81,321.55,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,213.76,338.85,204.00,7.86">A survey of modern authorship attribution methods</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,425.24,338.85,55.36,7.86;10,151.52,349.81,231.84,7.86">Journal of the American Society for information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="538" to="556" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,360.77,337.98,7.86;10,151.52,371.73,329.07,7.86;10,151.52,382.69,326.22,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="10,386.18,360.77,94.41,7.86;10,151.52,371.73,233.45,7.86">Support vector machine learning for interdependent and structured output spaces</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Tsochantaridis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Altun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,407.32,371.73,73.27,7.86;10,151.52,382.69,229.96,7.86">Proceedings of the twenty-first international conference on Machine learning</title>
		<meeting>the twenty-first international conference on Machine learning</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">104</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.62,393.65,337.97,7.86;10,151.52,404.61,329.07,7.86;10,151.52,415.56,288.90,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="10,226.04,393.65,236.25,7.86">Linguistic profiling for author recognition and verification</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Van Halteren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,151.52,404.61,329.07,7.86;10,151.52,415.56,28.62,7.86">Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 42nd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page">199</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
