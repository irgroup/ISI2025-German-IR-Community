<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,163.44,150.51,279.84,14.64;1,172.92,167.91,249.58,14.64;1,211.32,187.96,172.58,10.63">Improved implementation for finding text similarities in large collections of data Notebook for PAN at CLEF 2011</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,244.56,224.80,43.50,8.96"><forename type="first">Ján</forename><surname>Grman</surname></persName>
							<email>grman@svop.sk</email>
							<affiliation key="aff0">
								<orgName type="institution">SVOP Ltd</orgName>
								<address>
									<settlement>Bratislava</settlement>
									<country key="SK">Slovak Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,307.57,224.80,54.64,8.96"><forename type="first">Rudolf</forename><surname>Ravas</surname></persName>
							<email>ravas@svop.sk</email>
							<affiliation key="aff0">
								<orgName type="institution">SVOP Ltd</orgName>
								<address>
									<settlement>Bratislava</settlement>
									<country key="SK">Slovak Republic</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,163.44,150.51,279.84,14.64;1,172.92,167.91,249.58,14.64;1,211.32,187.96,172.58,10.63">Improved implementation for finding text similarities in large collections of data Notebook for PAN at CLEF 2011</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5415529E6BFB2321DF3132065DACFDE9</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this article we describe a new algorithm method for the detection of plagiarism. The method removes numerous limitations of our older method, which has been used as part of a complex information system for the detection of plagiarism. The method has been tested using multiple corpora mainly in Slovak language. With the PAN-09 and PAN-10 corpora it was of great advantage that we could compare our results with the results of other methods. The very good initial results gave us motivation to implement multiple algorithm and parameter improvements.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The issue of plagiarism is very serious in all areas, however, it is the most vivid in the field of education. In 2008 the Ministry of Education initiated the establishment of a Central Register of Thesis and Dissertations of the Slovak Republic, which serves as a central repository for all academic institutions. In 2010 a subsystem for comparison of documents and detection of plagiarism was added. As a producer and supplier of a library information system, we had long experience in the field of document and metadata collection.</p><p>Our first experiments with plagiarism detection solutions began in the spring of 2009. By the end of the year, our results were sufficient to allow the creation of a commercial system. We did not make it to the PAN-10 competition due to our busy work schedule related to the introduction of a system for the complex evaluation of thesis and dissertations of all 33 universities in the Slovak Republic.</p><p>The core of both methods is basically language independent. Detection quality, however, depends to a large extent on text pre-processing which is language dependent. We have been working with documents in the following languages: Slovak, Czech, Ukrainian, Hungarian and English.</p><p>For the PAN competition we also had to take into consideration Spanish, German and Greek. Because of this motivation, we succeeded in implementing a significant portion of the English WordNet. To translate texts from other languages into English we have used Google API. We've been dividing texts into smaller units and interpolating the translated word offsets with the original text offsets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Overview of related work</head><p>Computer (machine) implementation of an anti-plagiarism system is very specific, because many excellent ideas and methods need to be implemented using the means offered by the computers (existing hardware and software equipment). The functioning of an actual anti-plagiarism system, as well as the competition in plagiarism detection, requires that a huge amount of data be processed within a "reasonable" time. The huge amount of data implies high demands on computer and memory subsystem performance. Our reflections about existing solutions will be based on methods and concepts which lead to algorithms (programs) which demonstrably and within a relatively short time produce very good results in the detection of plagiarised text sections. Contributions of workshop participants describe procedures and ideas, the efficiency of which is comparable with the score achieved within the competitions at the PAN WorkShop <ref type="bibr" coords="2,318.24,303.92,10.68,8.96" target="#b5">[6]</ref>.</p><p>Having analysed the methods successful in individual PAN competitions, it is possible to divide the basic problems into several groups, namely: a. Editing of suspicious and source texts, which currently requires the comparison of multi-lingual texts, which when machine processed require language detection, machine translation, as precise a determination of word position in the original and translated text as possible <ref type="bibr" coords="2,237.59,372.89,10.69,8.96" target="#b3">[4]</ref>, use of lexical semantics (synonyms, antonyms and similar), use of stop-words and unification of word representation b.Transformation of text for representation, which allows the detection of matches within a certain part of text. Detection of plagiarised text passages based on short subsequences is only possible on the basis of the detection of matching parts of suitable representations of suspicious and source text. A method, which is currently very popular and backed by analyses, is the N-gram method <ref type="bibr" coords="2,352.91,441.89,10.68,8.96" target="#b4">[5]</ref>, which can be defined by the number of subtext characters <ref type="bibr" coords="2,272.25,453.42,10.70,8.96" target="#b1">[2]</ref>, or the number of subtext words <ref type="bibr" coords="2,436.88,453.42,10.70,8.96" target="#b2">[3]</ref>, <ref type="bibr" coords="2,456.58,453.42,10.59,8.96" target="#b6">[7]</ref>. Normally, overlapping N-grams are generated. Methods usually differ in the value of N. The representation using N-grams can also be applied to transformed texts <ref type="bibr" coords="2,437.13,476.34,10.69,8.96" target="#b0">[1]</ref>.</p><p>c.Detection of matching and similar passages in suspicious and source files. The passage (similarity) detection is usually based on heuristics which define the minimum number of consecutive positive representation matches or the minimum frequency of matches within an passage (window) (according to b.) <ref type="bibr" coords="2,404.76,522.62,12.80,9.94" target="#b1">[2]</ref> through <ref type="bibr" coords="2,455.28,522.62,11.59,9.94" target="#b3">[4]</ref>. Suitable (optimum) values are usually obtained and verified by experiments.</p><p>d.Extraction of relevant passages in suspicious and source files. This stage is usually the most complicated because it not only requires division and exclusion, but also the merging of passages from a phrase (c.). This is either done by heuristic methods <ref type="bibr" coords="2,161.28,580.97,10.68,8.96" target="#b2">[3]</ref>, or methods of segmentation (extraction) which can be visualized in a 2D plane. The visualizations of non-plagiarized, non-obfuscated or obfuscated suspicious passages and source passages show certain typical patterns <ref type="bibr" coords="2,362.40,604.22,11.59,9.94" target="#b1">[2]</ref>, <ref type="bibr" coords="2,380.40,604.22,11.50,9.94" target="#b0">[1]</ref>, [10].</p><p>e.Post-processing. Some methods in stage (d.) produce overlapping significant passages in the suspicious text for a certain document pair <ref type="bibr" coords="2,372.96,628.34,11.50,9.94" target="#b1">[2]</ref>, or "false" passages which can be caused, for example, by attempts to hide similarities in suspicious documents with the aim to increase precision or decrease the granularity of detection results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>f.Reducing analysis time</head><p>There are basically two possible approaches. The first is to parallelise the process of finding suspicious passages using a suitable representation <ref type="bibr" coords="3,376.56,218.78,12.92,9.94" target="#b2">[3]</ref> in the form of hash tables. The second is to reduce the number of files to be compared by quantifying the degree of file similarity (usually by means of statistical methods), whereby a set of N most "similar" documents is selected (10 to 50 source files for each suspicious file).</p><p>. Comparing all suspicious and all source documents between each other is a task of quadratic computational complexity. That is why, before comparing documents, many of the more demanding methods focus on how to detect plagiarised extracts in PAN within a "reasonable time" by reducing the number of source texts to be compared with a particular suspicious document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Method principle</head><p>In principle, the anti-plagiarism system we developed can be divided into three main parts, namely: pre-processing of input data (in this case plain-text pre-processing), detection of passage pairs (plagiarism candidates) and post-processing (removal of overlapping passages, merging of passages, and exclusion of uncertain passage pairs)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Pre-processing</head><p>In real life the first stage of document pre-processing is its conversion to plain text. In the case of the PAN corpus this phase can be ignored. We continue working with the text on the level of individual words.</p><p>The unit we are interested in is the word and its variations (synonyms, basic forms, abbreviations and similar). Our objective during this stage is to transform the text to a form with the following properties: reduces the amount of data which needs to be processed and allows for efficient comparison</p><p>The result is a mapping function which allows streaming text processing, saving text into a more efficient, reduced, and morphology invariant data structure. The steps are: text translation into English (if needed), word extraction (chars, offset and length), and word normalization (stemming, synonym normalization). Original text consisting of words is transformed into binary file of word invariants (codes). of words while taking into account all their versions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Suspicious passage detection</head><p>Our objective was to create a method for detecting similar or matching passages in a suspicious reference text so that the detection is invariant against a change of word order, against the occurrence of changed words, against omissions or additions of words in the passage in a suspicious document, whereby no passage length limits will be set (neither minimum nor maximum length). We assume that passage lengths don't have to be the same.</p><p>The method is based on quantification of the degree of concordance between tested passages. The quantification is based on a quick calculation (measurement) of the number of matching words in a pair of passages. The degree of concordance or similarity is defined as the number of elements in an intersection of sets of words from passages in a suspicious and reference text.</p><formula xml:id="formula_0" coords="4,233.03,149.80,237.56,11.67">| | ) , ( R S R S MW I I I I N ∩ =<label>(1)</label></formula><p>where N MW is the number of matching words, I S and I R are the passages of the suspicious and reference text. The detector selects the area in which the value of N MW exceeds the threshold N MWT .Choice of threshold value N MWT depends mainly on the nature of the compared files which determine the required minimum length of the detected match as expressed by the number of matching words. A pair of passages may be represented by area. For all pairs of representations of suspicious and references documents, which were divided into non-overlapping passages (subintervals) with constant number of words were calculated number of matching words and were thresholded so that it can detect at least 15 words consistently. In the first stage, if the detected areas are adjacent, then they are merged into a single area.</p><p>After that, the areas are divided into disjunct areas (pair of passages) so that the resulting passages have the following property. Let's mark the sub-passages I Si and I Rj of passages I S and I R , which either start or end in a word belonging to the set (1). If the ratios min min ) , (</p><formula xml:id="formula_1" coords="4,197.14,343.70,272.98,24.65">) , ( ) , ( ) , ( q I I N I I N q q I I N I I N q Rj Rj MW Rj S MW Rj Si Si MW R Si MW Si ≥ = ∧ ≥ = (2)</formula><p>exceed the selected threshold q min , then the pair I Si , I Rj becomes plagiarism candidate passages for the validity of the assumption (3) 1 ) , (</p><formula xml:id="formula_2" coords="4,250.60,395.56,219.99,11.84">MWT Rj i S MW N I I N ≥<label>(3)</label></formula><p>where N MWT1 is the minimum matching words of the detected passage. We used q min =0. <ref type="bibr" coords="4,153.91,424.12,4.54,8.96" target="#b4">5</ref> and N MWT1 =15.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Post-processing</head><p>In our case, two tasks were solved: removal of overlapping passages in suspicious document, if source text was the same and increasing of global score by reducing granularity and by increasing precision using methods described in next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis of anti-plagiarism system properties</head><p>The system was tested on the PAN-10 corpus on files created from plain texts using synonyms acquired from WordNet. Testing was done using transformed data with and without stop-words. Table <ref type="table" coords="4,286.32,539.21,4.98,8.96" target="#tab_0">1</ref> shows the results of suspicious passage detection for data without stop-words. Row one shows the score for results without post-processing. The rows below show the score after post-processing, whereby the final results were thresholded to three monitored quantities -the T 1 threshold to t 1 share of word number (1) in all words of passages in the suspicious and reference text, the T 2 threshold to t 2 share of word number (1) in all words of passages in the suspicious and reference text, whereby the words were expressed by the number of characters, and T 3 was the threshold to t 3 minimum length of passages expressed by the number of characters. Conditions for the refusal of detected passages are specified in (4).</p><formula xml:id="formula_3" coords="4,126.20,654.58,342.48,30.98">1 1 100 . | | | | ) , ( * 2 T I I I I N t R S R S MW &lt; + = 2 ) ( 2 100 . | | | | ) 1 | (| * 2 T I I w t R S I I w i R S i &lt; + + = ∑ ∩ ∈ 3 3 | | | | T I T I R S ≤ ∨ ≤<label>(4)</label></formula><p>where |x| means the length of word or passage expressed in the number of characters. The best score was achieved with the following threshold settings: T 1 =70, T 2 =60 a T 3 =200. Row one shows the score for results without post-processing (marked **). The plagiarism detection results in the PAN-11 corpus can be described using two statements: satisfaction with the achieved rank and dissatisfaction with the achieved score. The options of our system are described by the results in table 2. With known correct results it is easy to set suitable system parameters. In our case we have used the post-processing settings which produced the best results for PAN-10 (Table <ref type="table" coords="5,445.08,398.10,3.59,8.96" target="#tab_0">1</ref>).</p><p>It is apparent that the PAN-11 corpus was prepared with more precision. The number of incorrect detections with a relatively high percentage of similarity was significantly lower, which we could have expected considering the trend between PAN-09 and PAN-10, but we did not dare to apply this assumption to PAN-11 by decreasing the parameter values for post-processing (Table <ref type="table" coords="5,363.35,455.60,3.63,8.96" target="#tab_1">2</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>Each plagiarism detection method faces one basic problem -a huge amount of data. That means only methods that are capable of processing a certain amount of data within a reasonable time limit are usable. Even though the performance of computers increases day by day, the biggest impact is the efficiency of the method used.</p><p>In our case we only needed one mainstream server to run the complex plagiarism detection system and collect data for the whole of Slovakia (two years of data collection). The PAN-11 was equally processed using a single server and even several times within the given short period of time. The main advantages of the new method are better opportunity of detecting paraphrased text, extended support for different word forms significantly improved detection reliability for texts translated into foreign languages (translation through individual paragraphs, offset alignment of paragraphs -original and translated).</p><p>Of course, there are some issues that all creators of complex systems face. The basic one is the definition of plagiarism. How much identical and/or similar text can already be considered plagiarism. Should the computer decide, or should it just be a tool that helps decide?</p><p>There are also issues with the automatic recognition of citation marks or citation links in general. A specific question is the use of laws and standards in texts. These questions, however, become relevant only in the last stage of processing, which goes beyond the scope of this competition.</p><p>Our systems are currently used to compare thesis and dissertations with Internet, yet this is just one of the possible applications. There are plans to extend the system to process documents published by scientists, documents related to projects funded from the state budget or European projects, and documents from published monographs and university textbooks. In some cases it's not so much about looking for matches as indexing a document and thereby protecting it and the copyright of the author.</p><p>We would like to thank the competition organizers and the authors of the test corpus for the excellent opportunity to obtain a relatively objective and independent view of the detection capabilities of our solution. A great deal of development and work can be seen in the corpora PAN-09 through PAN-11. Some examples are not very realistic, we could even say marginal, yet this allows the testing of how robust the algorithms really are.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,124.79,207.05,345.80,130.75"><head>Table 1 .</head><label>1</label><figDesc>Plagiarism detection score in PAN-10 (with synonyms and without stopwords) for different threshold settings for parameters T 1 , T 2 and T 3 .</figDesc><table coords="5,139.80,234.04,313.25,103.77"><row><cell>PlagDet</cell><cell>Recall</cell><cell>Precision</cell><cell cols="2">Granularity T 1</cell><cell>T 2</cell><cell>T 3</cell></row><row><cell>0.433957</cell><cell>0.737183</cell><cell>0.312248</cell><cell>1.015155</cell><cell>**</cell><cell></cell><cell></cell></row><row><cell>0.811796</cell><cell>0.733454</cell><cell>0.910356</cell><cell>1.001009</cell><cell>50</cell><cell>50</cell><cell>150</cell></row><row><cell>0.812908</cell><cell>0.733206</cell><cell>0.913456</cell><cell>1.000951</cell><cell>60</cell><cell>50</cell><cell>150</cell></row><row><cell>0.82334</cell><cell>0.730341</cell><cell>0.944667</cell><cell>1.000761</cell><cell>70</cell><cell>50</cell><cell>150</cell></row><row><cell>0.823852</cell><cell>0.729678</cell><cell>0.947132</cell><cell>1.000762</cell><cell>70</cell><cell>60</cell><cell>150</cell></row><row><cell>0.824488</cell><cell>0.726819</cell><cell>0.953666</cell><cell>1.000746</cell><cell>70</cell><cell>60</cell><cell>200</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,124.78,478.64,345.68,67.60"><head>Table 2 .</head><label>2</label><figDesc>Plagiarism detection score in PAN-11 (using synonyms without stop-words) for different threshold settings for parameters T 1 , T 2 and T 3 .</figDesc><table coords="5,129.60,505.60,330.41,40.65"><row><cell>PlagDet</cell><cell>Recall</cell><cell>Precision Granularity</cell><cell>T 1</cell><cell>T 2</cell><cell>T 3</cell><cell>Cases</cell></row><row><cell>0.5569</cell><cell cols="2">0.396916 0.938023 1.002249</cell><cell>70</cell><cell>60</cell><cell>200</cell><cell>22108</cell></row><row><cell cols="3">0.615389 0.473128 0.892744 1.006975</cell><cell>50</cell><cell>50</cell><cell>150</cell><cell>28781</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,144.59,448.70,326.15,8.96;6,144.59,460.22,325.84,8.96;6,144.59,471.62,264.69,8.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,464.98,448.70,5.76,8.96;6,144.59,460.22,325.84,8.96;6,144.59,471.62,33.77,8.96">A plagiarism detection procedure in three steps: Selection, Matches and &quot;Squares</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Basile</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Benedetto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Caglioti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Cristadoro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">D</forename><surname>Esposti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,203.88,471.62,63.15,8.96">Proc. SEPLN&apos;09</title>
		<meeting>SEPLN&apos;09<address><addrLine>Donostia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="19" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,144.58,483.15,325.98,8.96;6,144.58,494.67,326.02,8.96;6,144.58,506.20,93.69,8.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,300.74,483.15,169.82,8.96;6,144.58,494.67,188.83,8.96">ENCOPLOT: Pairwise sequence matching in linear time applied to plagiarism detection</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Grozea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gehl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Popescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,357.72,494.67,65.06,8.96">Proc. SEPLN&apos;09</title>
		<meeting>SEPLN&apos;09<address><addrLine>Donostia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="10" to="18" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,144.57,517.72,325.98,8.96;6,144.57,529.24,315.21,8.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,330.06,517.72,140.50,8.96;6,144.57,529.24,89.17,8.96">Finding Plagiarism by Evaluating Document Similarities</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kasprzak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brandejs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kripac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,254.13,529.24,63.27,8.96">Proc. SEPLN&apos;09</title>
		<meeting>SEPLN&apos;09<address><addrLine>Donostia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="24" to="28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,144.57,540.65,325.95,8.96;6,144.57,552.17,325.85,8.96;6,144.57,563.69,197.49,8.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,281.72,540.65,188.80,8.96;6,144.57,552.17,203.14,8.96">Improving the Reliability of the Plagiarism Detection System -Lab Report for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kasprzak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brandejs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,376.65,552.17,93.77,8.96;6,144.57,563.69,166.87,8.96">Proceedings of the 2nd Competition on Plagiarism Detection PAN</title>
		<meeting>the 2nd Competition on Plagiarism Detection PAN</meeting>
		<imprint>
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,144.56,575.22,326.13,8.96;6,144.56,586.98,325.95,8.96;6,144.56,598.38,120.92,8.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,306.70,575.22,163.99,8.96;6,144.56,586.98,24.46,8.96">Plagiarism Is Easy, But Also Easy To Detect</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lyon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Barrett</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Malcolm</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,179.00,586.98,291.51,8.96;6,144.56,598.38,48.67,8.96">Plagiary: Cross-Disciplinary Studies in Plagiarism, Fabrication, and Falsification</title>
		<imprint>
			<biblScope unit="page" from="57" to="65" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,144.55,609.91,325.86,8.96;6,144.55,621.43,325.91,8.96;6,144.55,632.96,325.86,8.96;6,144.55,644.48,60.68,8.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,386.83,609.91,83.58,8.96;6,144.55,621.43,213.51,8.96">Overview of the 2nd international competition on plagiarism detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Eiselt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">B</forename><surname>Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,387.20,621.43,83.26,8.96;6,144.55,632.96,325.86,8.96;6,144.55,644.48,26.82,8.96">Proceedings of the CLEF&apos;10 Workshop on Uncovering Plagiarism, Authorship and Social Software Misuse</title>
		<meeting>the CLEF&apos;10 Workshop on Uncovering Plagiarism, Authorship and Social Software Misuse</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,144.54,656.00,326.10,8.96;6,144.54,667.41,325.88,8.96;6,144.54,678.93,197.49,8.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,316.97,656.00,153.67,8.96;6,144.54,667.41,186.26,8.96">A Cluster-Based Plagiarism Detection Method -Lab Report for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">Zou</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Long</forename><surname>Wei-Jiang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ling</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,366.55,667.41,103.87,8.96;6,144.54,678.93,166.87,8.96">Proceedings of the 2nd Competition on Plagiarism Detection PAN</title>
		<meeting>the 2nd Competition on Plagiarism Detection PAN</meeting>
		<imprint>
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
