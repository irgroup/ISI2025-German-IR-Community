<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,155.18,151.67,296.34,12.54;1,160.22,169.07,274.82,12.54">UNT at ImageCLEF 2011: Relevance Models and Salient Semantic Analysis for Image Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,190.10,207.20,61.24,9.05"><forename type="first">Miguel</forename><forename type="middle">E</forename><surname>Ruiz</surname></persName>
							<email>meruiz@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Library and Information Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,259.73,207.20,41.22,9.05"><forename type="first">Wee</forename><surname>Chee</surname></persName>
						</author>
						<author>
							<persName coords="1,303.61,207.20,25.47,9.05"><surname>Leong</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<address>
									<addrLine>1155 Union Circle 311068</addrLine>
									<postCode>76203</postCode>
									<settlement>Denton</settlement>
									<region>Texas</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,351.55,207.20,61.93,9.05"><forename type="first">Samer</forename><surname>Hassan1</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Library and Information Sciences</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Department of Computer Science and Engineering</orgName>
								<address>
									<addrLine>1155 Union Circle 311068</addrLine>
									<postCode>76203</postCode>
									<settlement>Denton</settlement>
									<region>Texas</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">University of North Texas</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,155.18,151.67,296.34,12.54;1,160.22,169.07,274.82,12.54">UNT at ImageCLEF 2011: Relevance Models and Salient Semantic Analysis for Image Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">743DCBE4017D6FDAC9F92E91131D43AC</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Image Retrieval</term>
					<term>Query Expansion</term>
					<term>Salient Semantic Analysis</term>
					<term>Language Models</term>
					<term>Relevance Models</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the result of the team of the University of North Texas in the ImageCLEF 2011 Wikipedia and Medical Image Retrieval tasks. For Wikipedia image retrieval we compare the two query expansion methods: relevance models and query expansion using Wikipedia and flicker as external sources. The relevance models use a classic relevance feedback mechanism for Language models as proposed by Levrenko. The external query expansion mechanism uses an unsupervised two steps method that takes advantage of Salient Semantic Analysis (SSA) using Wikipedia and estimates the "picturability" of terms using Flicker tags. Our results show that SSA and Flickr picturability can be used effectively to create very competitive runs that capture the semantic context of the original query. For Medical Image Retrieval we also use relevance models and query expansion using terms generated by MetaMap.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Image retrieval is becoming an common user activity on the web as well as in the medical domain. Despite the many advances in image retrieval research there are still some serious problems that need to be further explored such as the well known "semantic gap". This makes the ImageCLEF initiative very relevant to foster research in this area. In this paper we present the results of the University of North Texas (UNT) team in the Wikipedia image retrieval and the adhoc medical image retrieval tasks. This year we were inspired by the idea of exploring unsupervised techniques that can help to close the semantic gap in image retrieval. Our work focused on using relevance models and query expansion using semantic salient analysis and trying to predict the picturability of terms in the query using Filckr tags.</p><p>For our participation in the Wikipedia image retrieval task we used the standard 2011 Wikipedia image collection, which is described in more detail in the overview paper of this task <ref type="bibr" coords="2,171.50,200.24,10.78,9.05" target="#b0">[1]</ref>. Our goal for this year focused on using corpus based methods to build a query expansion that could capture semantic meaning and identify terms that are more likely to describe images. For this purpose we use Semantic Salient Analysis and Flickr picturability.</p><p>Salient Semantic Analysis (SSA) <ref type="bibr" coords="2,264.65,257.75,11.60,9.05" target="#b1">[2]</ref> is a method that computes semantic similarity between words based on salient content links from a corpus such as Wikipedia. The meaning of each word is represented by links of salient concepts defined in wikipedia. For example, given the following text from Wikipedia: "Plants are living organisms belonging to the kingdom Plantae. Precise definitions of the kingdom vary, but as the term is used here, plants include familiar organisms such as trees, flowers, herbs, bushes, grasses, vines, ferns, mosses, and green algae."</p><p>The semantic meaning for the word "plants" is represented by a weighted vector of the salient links: living organisms, kingdom, trees, flowers, herbs, bushes, grasses, vines, ferns, mosses, and green algae.</p><p>To measure the semantic association between two terms or between two pieces of text SSA uses a similarity value computed on the co-occurrence with in a window of size k in a given corpus. The similarity value is controlled by a parameter (λ) that represents a threshold of the semantic gap between terms that are perfect synonyms (e,g, tiger-tiger) and near synonyms (e.g., tiger-feline) .</p><p>Flickr picturability is a method based on rewarding terms that match tags assigned to images in Flickr. For this purpose the method builds a corpus with the top Flickr tags most related to the query terms and weights them according to the co-occurrence of the term in the contexts of other query terms.</p><p>The reader can find the complete details about these methods in our short paper in CLEF 2011 which is available in the conference proceedings <ref type="bibr" coords="2,371.23,556.69,10.69,9.05" target="#b2">[3]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Collection Preparation</head><p>We decided to solve the cross language issue by translating all documents (image captions) from French and German into English using the Bing Translation service. This basically converts the cross-language retrieval problem into an English monolingual retrieval problem. We used not only the captions but also the full text of the Wikipedia article that includes the image. The collection was indexed using Indri (available at http://www.lemurproject.org/ ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Query Expansion</head><p>Query expansion was performed using a two step process that first generates a list of possible candidate words by retrieving the top m Wikipedia articles that are more relevant to the original query Q. Then the process adds the SSA scores over all individual concept vectors of each term in Q. After discarding stop words in the titles, remaining words are ranked using a fusion formula that incorporates the Flickr pictutability :</p><formula xml:id="formula_0" coords="3,195.02,311.92,275.80,10.50">Weight(wi) = tf (wi) * 1/rank(wi) * flickr(wi) (1)</formula><p>Where tf (wi) is the term frequency wi across all m Wikipedia titles, rank(wi) is the highest rank of the title (in descending order) that contains the word wi, and flickr(wi) is the Flickr picturability score computed on the corpus. The second step is the candidate selection. In this step the top W words (ranked in reversed order) by the weight computed using (1) are used as a working set. If the SSA similarity Sim(Q,w) ≥ α, then the word is added to the expanded query. This approach basically tries to add picturable terms that are semantically related to the original query.</p><p>For our experiments we used the following parameter values that were determined empirically using the ImageCLEF 2010 queries. The number of tokens in the corpus used to compute SSA was set to m=1000, two values for the number of top Wikipedia articles retrieved for candidate selection W=50 and W=150. When measuring similarity, our SSA model was set to γ = 1.2 and λ= 0.02</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Retrieval model</head><p>We use a standard unigram language model with Dirichlet smoothing, Krovetz stemming and a list of English stopwords. We also use a weighted query with parameter β such that</p><formula xml:id="formula_1" coords="3,174.38,655.12,296.44,9.17">Weighted_query = β Q_original + (1-β) Q_expansion (2)</formula><p>In our experiments the value was set to β=0.5 based on the parameters set for Lavrenko's relevance model <ref type="bibr" coords="4,241.13,160.88,10.69,9.05" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Results</head><p>We submitted 7 official runs which are presented on Table <ref type="table" coords="4,386.47,237.92,3.71,9.05" target="#tab_0">1</ref>. All our runs used textual features only. French and German text in the documents was translated to English and use only the English queries.</p><p>The first run listed is an unofficial baseline run using language models on the original query terms with no expansion. Surprisingly this baseline achieves a quite competitive MAP of 0.2621 and quite high values for P10 and P20. All runs labeled with SSA use the expanded queries with terms selected based on Salient Semantic Analysis and Flickr picturability scores. The label W indicates whether the run uses the weighted query scheme. Runs labeled with rf use a relevance model to perform pseudo relevance feedback.</p><p>From Table <ref type="table" coords="4,186.57,364.43,4.98,9.05" target="#tab_0">1</ref> we can see that just using the top 50 expanded query terms selected with SSA and Flickr picturability is our lowest performing run (2011_SSA50) even significantly below our baseline. However, when we use the weighted query and retrieval feedback (UNTESU_SSA50Wrf) the performance improves to 0.2794 (6.6% above the baseline). This indicates that to improve retrieval performance with the query expansion method we must use an appropriate weighted query. Selecting the top 150 terms with a weighted query and relevance feedback shows the highest performance of our SSA runs with 0.2820 (7.6%) above the our baseline. We also submitted a run that uses Lavrenko's relevance model <ref type="bibr" coords="4,414.55,669.88,11.72,9.05" target="#b3">[4]</ref> for query expansion (which performs pseudo-relevance feedback on language models). This run (UNTESU_BLRF) was our highest performing run with MAP=0.2866 (9.3% above our baseline). Overall this run was ranked as the 3 rd best textual run in the Wikipedia task. However it seems clear from the results of other teams that a mixed approach using textual and visual features could yield a much higher performance for the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Medical Image Retrieval Task</head><p>For the medical image retrieval task we participated only in the adhoc retrieval task <ref type="bibr" coords="5,124.82,260.75,10.69,9.05" target="#b4">[5]</ref>. We indexed the data using Indri with standard parameters. We used an approach that expands queries using MetaMap <ref type="bibr" coords="5,286.01,272.27,11.70,9.05" target="#b5">[6]</ref> and identifies whether a specific image modality (e.g. x-rays image) is requested in the query. We added a field to each document with the image modality predicted type provided by the organizers of the medical image classification task <ref type="bibr" coords="5,259.73,306.71,10.78,9.05" target="#b4">[5]</ref>.</p><p>We created structured queries that used the phrase operator to ensure that the multiword terms generated by MetaMap where matched as a single term instead of individual words. We also use a weighted formulation that included three components: the original query terms, the image modality requested in the query, and the expanded terms generated by MetaMap.</p><p>Our official results for the ad-hoc medical retrieval runs are presented in Table <ref type="table" coords="5,463.13,410.27,3.71,9.05" target="#tab_1">2</ref>. The results show clearly that query expansion using the structured queries actually decreased performance slightly. Relevance feedback models have the same effect of decreasing performance slightly. Although we still have to do a more thorough analysis of the results it seems that the large number of expansion terms generated by MetaMap is affecting the focus of the query. We probably will need to use a similar technique like the SSA presented in our Wikipedia retrieval task to do a more focused term expansion and rank the terms generated by MetaMap. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,158.42,479.41,278.60,161.16"><head>Table 1 .</head><label>1</label><figDesc>Official results in the Wikipedia Image Retrieval task.</figDesc><table coords="4,158.42,503.89,278.60,136.68"><row><cell>Run name</cell><cell cols="2">FB/QE MAP P10</cell><cell>P20 Rprec Bpref</cell></row><row><cell>Baseline (unofficial)</cell><cell></cell><cell cols="2">0.2621 0.5493 0.4434 0.2900 0.2522</cell></row><row><cell>2011_SSA50</cell><cell>QE</cell><cell cols="2">0.2143 0.3260 0.2900 0.2438 0.2027</cell></row><row><cell>UNTESU_SSA150rf</cell><cell cols="3">QEFB 0.2292 0.3120 0.2810 0.2476 0.2050</cell></row><row><cell>2011_SSA50_FB</cell><cell>FB</cell><cell cols="2">0.2327 0.3160 0.2860 0.2543 0.2113</cell></row><row><cell cols="2">UNTESU_SSA150W QE</cell><cell cols="2">0.2577 0.4060 0.3510 0.2835 0.2401</cell></row><row><cell cols="4">UNTESU_SSA50Wrf QEFB 0.2794 0.4240 0.3630 0.3107 0.2647</cell></row><row><cell cols="2">UNTESU_SSA150Wrf FB</cell><cell cols="2">0.2820 0.4200 0.3610 0.3190 0.2679</cell></row><row><cell>UNTESU_BLRF</cell><cell>FB</cell><cell cols="2">0.2866 0.4220 0.3650 0.3276 0.2821</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,168.86,513.73,257.72,103.44"><head>Table 2 .</head><label>2</label><figDesc>Official results in the Wikipedia Image Retrieval task.</figDesc><table coords="5,168.86,538.21,257.72,78.96"><row><cell>Run name</cell><cell cols="2">FB/QE MAP P10</cell><cell>P20 Rprec Bpref</cell></row><row><cell>ESU_Ib_bl</cell><cell></cell><cell cols="2">0.1590 0.2670 0.2070 0.1940 0.1890</cell></row><row><cell>ESU-Ib_blRF</cell><cell>FB</cell><cell cols="2">0.1560 0.2430 0.2100 0.1760 0.1870</cell></row><row><cell>ESU_Ib_Struc</cell><cell></cell><cell cols="2">0.1540 0.2800 0.2300 0.1870 0.1910</cell></row><row><cell cols="2">ESU_Ib_StrucRF FB</cell><cell cols="2">0.1350 0.2300 0.2000 0.1610 0.1870</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="3">Conclusions</head><p>We presented in these paper experiments that focus on query expansion methods using external resources as well as using collection based query expansion with pseudo relevance feedback.</p><p>In the case of Wikipedia retrieval our results show that query expansion using SSA and Flickr picturability are equivalent to using traditional collection based relevance model for relevance feedback.</p><p>For the Medical image retrieval our results are mixed and do not show improvements when using structured queries and query expansion using MetaMap. However, we still need to do a more thorough analysis to try to understand what is hurting performance in these runs.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="6,128.53,368.99,341.91,9.05;6,142.82,380.51,327.81,9.05;6,142.82,392.03,97.91,9.05" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,327.03,368.99,143.40,9.05;6,142.82,380.51,137.18,9.05">Overview of the wikipedia image retrieval task at ImageCLEF 2011</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kludas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,302.45,380.51,111.47,9.05">CLEF 2011 Working Notes</title>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,128.53,403.55,341.79,9.05;6,142.82,415.07,282.02,9.05" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,252.49,403.55,213.97,9.05">Semantic relatedness using salient semantic analysis</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,158.75,415.07,237.10,9.05">Proceedings of AAAI Conference on Artificial Intelligence</title>
		<meeting>AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,128.53,426.47,341.79,9.05;6,142.82,438.01,327.73,9.05;6,142.82,449.53,326.54,9.05" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,341.97,426.47,128.34,9.05;6,142.82,438.01,188.54,9.05">Improving query expansion for image retrieval via saliency and picturability</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Leong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ruiz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,355.87,438.01,114.68,9.05;6,142.82,449.53,243.33,9.05">CLEF 2011 Conference on Multilingual and Multimodal Information Access Evaluation</title>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,128.53,461.05,341.83,9.05;6,142.82,472.57,327.43,9.05;6,142.82,483.97,141.42,9.05" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,244.55,461.05,142.22,9.05">Relevance-Based Language Models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,410.58,461.05,59.77,9.05;6,142.82,472.57,327.43,9.05;6,142.82,483.97,35.05,9.05">Proceedings of the ACM SIGIR 2001 Conference on Research and Development in Information Retrieval</title>
		<meeting>the ACM SIGIR 2001 Conference on Research and Development in Information Retrieval<address><addrLine>New Orleans, LA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,128.53,495.49,341.98,9.05;6,142.82,507.01,327.82,9.05;6,142.82,518.53,240.93,9.05" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,155.42,507.01,267.69,9.05">The CLEF 2011 medical image retrieval and classification tasks</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Eggel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,446.16,507.01,24.48,9.05;6,142.82,518.53,81.97,9.05">CLEF 2011 Working Notes</title>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,128.53,530.05,341.96,9.05;6,142.82,541.57,324.49,9.05" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,198.08,530.05,272.40,9.05;6,142.82,541.57,91.18,9.05">Effective Mapping of biomedical text to the UMLS metathesaurus: The MetaMap program</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Aronson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,257.11,541.57,106.32,9.05">AMIA Annual Symposium</title>
		<meeting><address><addrLine>Washington, DC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
