<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,140.55,116.95,334.26,12.62">RMIT at ImageCLEF 2011 Plant Identification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,221.86,154.93,79.29,8.74"><forename type="first">Rahayu</forename><forename type="middle">A</forename><surname>Hamid</surname></persName>
							<email>rahayu.ahamid@student.rmit.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Information Technology</orgName>
								<orgName type="institution">RMIT University</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,323.84,154.93,69.66,8.74"><forename type="first">James</forename><forename type="middle">A</forename><surname>Thom</surname></persName>
							<email>james.thom@rmit.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science and Information Technology</orgName>
								<orgName type="institution">RMIT University</orgName>
								<address>
									<settlement>Melbourne</settlement>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,140.55,116.95,334.26,12.62">RMIT at ImageCLEF 2011 Plant Identification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">08961C69583F5CFEE42DA77DA27E731A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Plant identification</term>
					<term>Image feature extraction</term>
					<term>Classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the contribution of the ISAR group at RMIT University to the ImageCLEF 2011 Plant identification task. The task involves identifying various different species of trees based on images of their leaves. Our main objective is to investigate the performance of two classification algorithms in associating the correct tree species to each test image. We extracted visual features from the data set using the feature extraction module in GIFT. From all the features extracted, we selected 166 features of the colour histogram. The classification algorithms used are instance based learning and decision trees. Both algorithms were implemented using the Weka 3 data mining toolkit. Classifiers for both algorithms were evaluated by a 10 folds cross-validation. Based on the official results, our runs did not perform well due to three main reasons namely, feature selection, training data and classifier parameters.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper presents the participation of the ISAR group (Information Storage Analysis and Retrieval) at RMIT University in the ImageCLEF 2011 Plant Identification task. The task was motivated by the need to accurately gather knowledge of the identity, geographic distribution and uses of plants in ensuring advancement in agriculture and safeguarding its diversity.</p><p>The main goal of the task is to correctly associate tree species to each test image. The task is treated as a supervised classification problem with tree species used as class labels. Our objective in the task, however, is to investigate the performance of two classification algorithms in classifying the test images to the tree species.</p><p>The pilot task dataset contains approximately 5400 pictures of leaves from 71 tree species from French Mediterranean area. Further details regarding the general setup of the dataset are available in the task description <ref type="bibr" coords="1,425.92,621.25,9.96,8.74" target="#b0">[1]</ref>. The rest of this paper is organised as follows: Section 2 describes the experiment carried out, Section 3 the results we obtained at ImageCLEF 2011, then we conclude the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Experiments Description</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Feature Extraction</head><p>Classification can be done by either using textual features (from the XML files), visual features (from the jpg files) or combination of both textual and visual features. Our work is based on visual features only. We extracted the visual feature from the data set using the feature extraction module in the GNU Image-Finding Tool (GIFT) <ref type="bibr" coords="2,233.35,208.53,9.96,8.74" target="#b1">[2]</ref>. The total number of features extracted by GIFT is approximately 80,000 features. From these features, we selected only 166 colour histogram features. GIFT uses a palette of 166 colours derived by quantising the HSV colour space into 18 hues, 3 saturations, 3 values and 4 grey levels <ref type="bibr" coords="2,467.30,244.40,9.96,8.74" target="#b2">[3]</ref>. Histogram intersection is used to measure the distance/similarity between colour in the images. Colour histogram was chosen because each image has its own colour distribution in the colour histogram, which will be able to distinguish it from other images. Furthermore, as we are experimenting with basic classification algorithms, using colour histogram features seems reasonable <ref type="bibr" coords="2,404.00,304.17,9.96,8.74" target="#b3">[4]</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Classification Algorithms</head><p>Our classification algorithms were implemented using the Weka 3 data mining toolkit <ref type="bibr" coords="2,167.41,609.29,9.96,8.74" target="#b4">[5]</ref>. Prior to deciding which classification algorithms to use, we trained several different classification algorithms that are available in Weka. The purpose of this acticity is to identify classifier(s) that produces the highest classification rate. Five types of classifier were trained, namely Bayesian, decision tree, instance-based learning, rules and functions.</p><p>The classifiers were trained using all the training data together, without separating them according to the type of image acquisition. In order to reduce variability and estimate how accurately the classifier will perform, they were evaluated by a 10-folds cross validation. Note that Weka support several instance based algorithms namely IB1 and IBk whereby k = 2,....,n. Table <ref type="table" coords="3,429.17,167.81,4.98,8.74" target="#tab_0">1</ref> shows the classification rate for the different classifiers trained. From the table, we can see that decision tree and instance based learning classifier performs better than the rest. Although IBk performed slightly better than J48, we selected IB1 and J48 so as to compare between the two different classifiers.</p><p>The IB1 algorithm is identical to the nearest neighbours algorithm. It is considered as a statistical learning algorithm and is simple to implement. When asked to make a prediction about an unknown point, the nearest-neighbour classifier finds the closest training-point to the unknown point and predicts the category of that training-point accordingly to some distance metric <ref type="bibr" coords="3,431.38,429.97,9.96,8.74" target="#b5">[6]</ref>.</p><p>A decision tree partitions the input space of a data set into mutually exclusive regions, each of which is assigned a label, a value or an action to characterise its data points. It is used to classify a case by starting at the root of the tree and moving through it until a leaf is encountered. At each non-leaf decision node, the case's outcome for the test at the node is determined and attention shifts to the root of the sub-tree corresponding to this outcome. When this process finally leads to a leaf, the class of the case is predicted to be that recorded at the leaf.</p><p>The decision tree mechanism is transparent and we can follow a tree structure easily to see how the decision is made. However, many decision tree construction algorithms involve a two-step process. First, a very large decision tree is grown. Then, to reduce its large size and over-fitting the data, in the second step, the given tree is pruned <ref type="bibr" coords="3,225.47,585.38,9.96,8.74" target="#b6">[7]</ref>. The pruned decision tree that is used for classification purposes is called the classification tree.</p><p>The Weka 3 implementation of IB1 classifier uses normalised Euclidean distance to find the training instance closest to the given test instance, and predicts the same class as this training instance. If multiple instances have the same distance (closest) to the test instance, the first instance found is used. The difference between IB1 and IBk is that there are no parameters that could be changed.</p><p>As for the decision tree classifier, J48 is Weka's implementation of the C4.5 algorithm. The C4.5 decision tree can be either a pruned or unpruned tree. In our experiment, we created a pruned decision tree. We did not use binary splits when building the trees. The confidence factor used for pruning the tree was 0.25 with the minimum number of instance per leaf set as 2. In determining the amount of data used for pruning (number of folds), we used the default value 3. We considered the subtree raising operation when pruning and did not smooth the object counts at the leaves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>The objective of our experiment is to evaluate the effectiveness of both our classifiers in classifying tree species based on images of its leaves. We submitted two runs, one for each classifier. RMIT run1 used the instance based learning IB1 classifier while RMIT run2 used the decision tree classifier J48. As shown in Table <ref type="table" coords="4,162.04,300.46,3.87,8.74" target="#tab_1">2</ref>, our first run, RMIT run1 performed slightly better in terms of average images identified for each type of image acquisition. However, it was unable to identify images of the scan-like type. The overall results of participating groups that had submitted runs for the task are in the task description <ref type="bibr" coords="4,273.91,443.47,9.96,8.74" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>Our group submitted two runs in our first participation in the ImageCLEF 2011 Plant identification task. The results obtained by our runs were poor. This is due to three main reasons. The first is poor selection of features. We only used visual features which is the colour histogram and it was not suitable in identifying images based on the type of image acquisition used in the task. Next, we used all the training data together to train the classifier instead of dividing them according to the type of image acquisition. Finally, we did not exhaust all the parameters used in training both of the classifiers. We hope to further improve our experiment in future tasks.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,156.86,530.14,301.63,7.89;2,145.67,335.37,324.02,180.00"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Example of a free natural photo of a tree with its colour histogram</figDesc><graphic coords="2,145.67,335.37,324.02,180.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,134.77,208.53,345.83,96.81"><head>Table 1 .</head><label>1</label><figDesc>Classification rate of different types of classifier on a 10-folds cross validation</figDesc><table coords="3,195.65,229.33,224.07,76.01"><row><cell>Type</cell><cell cols="2">Classifier Classification rate</cell></row><row><cell>Bayesian</cell><cell>NaiveBayes</cell><cell>33.03%</cell></row><row><cell>Decision tree</cell><cell>J48</cell><cell>53.20%</cell></row><row><cell>Instance based learning</cell><cell>IB1</cell><cell>60.01%</cell></row><row><cell></cell><cell>IBk (k =2)</cell><cell>55.61%</cell></row><row><cell>Rules</cell><cell>JRip</cell><cell>46.95%</cell></row><row><cell>Functions</cell><cell>SMO</cell><cell>34.51%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,162.23,354.16,290.91,51.23"><head>Table 2 .</head><label>2</label><figDesc>Results of our submitted runs for the Plant identification task</figDesc><table coords="4,209.85,373.22,195.65,32.17"><row><cell>Runs</cell><cell cols="3">Scan Scan like Photograph Mean</cell></row><row><cell cols="2">RMIT run1 0.071 0.000</cell><cell>0.098</cell><cell>0.056</cell></row><row><cell cols="2">RMIT run2 0.061 0.032</cell><cell>0.043</cell><cell>0.045</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,138.35,635.88,342.24,7.86;4,146.91,646.84,333.68,7.86;4,146.91,657.79,261.97,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,292.10,646.84,184.64,7.86">The CLEF 2011 plant image classification task</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Barthelemy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J.-F</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Birnbaum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Mouysset</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,146.91,657.79,103.78,7.86">CLEF 2011 working notes</title>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,120.67,291.07,8.11" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="5,178.85,120.67,121.02,7.86">The GNU Image-Finding Tool</title>
		<author>
			<persName coords=""><surname>Gift</surname></persName>
		</author>
		<ptr target="http://www.gnu.org/s/gift/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,131.63,342.24,7.86;5,146.91,142.59,333.68,7.86;5,146.91,153.55,47.11,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,356.74,131.63,123.85,7.86;5,146.91,142.59,168.90,7.86">Content-based query of image databases: inspirations from text retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Squire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Thierry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,322.80,142.59,112.27,7.86">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1193" to="1198" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,164.51,342.24,7.86;5,146.91,175.46,215.01,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,297.78,164.51,182.81,7.86;5,146.91,175.46,43.82,7.86">Features for image retrieval: an experimental comparison</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,198.19,175.46,85.63,7.86">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="77" to="107" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,186.42,339.58,8.11" xml:id="b4">
	<monogr>
		<ptr target="http://www.cs.waikato.ac.nz/ml/weka/" />
		<title level="m" coord="5,146.91,186.42,154.36,7.86">Weka 3: Data Mining Software in Java</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,197.38,342.25,7.86;5,146.91,208.34,103.06,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,301.74,197.38,138.15,7.86">Instance-based learning algorithms</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">W</forename><surname>Aha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kibler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">K</forename><surname>Albert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,446.80,197.38,33.80,7.86;5,146.91,208.34,33.81,7.86">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="37" to="66" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,219.30,212.89,7.86" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="5,200.12,219.30,146.89,7.86">C4.5: Programs for Machine Learning</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Quinlan</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="5,353.40,219.30,127.20,7.86;5,146.91,230.26,42.24,7.86" xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Morgan</forename><surname>Kaufmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993">1993</date>
			<pubPlace>San Mateo, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
