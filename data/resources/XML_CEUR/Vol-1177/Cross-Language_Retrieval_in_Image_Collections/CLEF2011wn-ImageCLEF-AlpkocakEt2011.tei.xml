<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,136.94,151.67,332.94,12.54;1,144.38,169.07,306.56,12.54;1,249.77,186.47,95.99,12.54">DEMIR at ImageCLEFMed 2011: Evaluation of Fusion Techniques for Multimodal Content-based Medical Image Retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,190.58,225.42,56.90,8.96"><forename type="first">Adil</forename><surname>Alpkocak</surname></persName>
							<email>alpkocak@cs.deu.edu.tr</email>
						</author>
						<author>
							<persName coords="1,254.59,225.42,84.65,8.96"><forename type="first">Okan</forename><surname>Ozturkmenoglu</surname></persName>
							<email>okan.ozturkmenoglu@deu.edu.tr</email>
						</author>
						<author>
							<persName coords="1,348.93,225.42,51.59,8.96"><forename type="first">Tolga</forename><surname>Berber</surname></persName>
							<email>tberber@cs.deu.edu.tr</email>
						</author>
						<author>
							<persName coords="1,183.02,237.30,97.65,8.96"><forename type="first">Ali</forename><forename type="middle">Hosseinzadeh</forename><surname>Vahid</surname></persName>
							<email>ali_h_vahid@yahoo.com</email>
						</author>
						<author>
							<persName coords="1,300.29,237.30,111.92,8.96"><forename type="first">Roghaiyeh</forename><surname>Gachpaz Hamed</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Dokuz</orgName>
								<orgName type="institution">Eylul University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Department of Computer Engineering DEMIR Dokuz Eylul Multimedia Information Retrieval Research Group Tinaztepe</orgName>
								<address>
									<postCode>35160</postCode>
									<settlement>Izmir</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,136.94,151.67,332.94,12.54;1,144.38,169.07,306.56,12.54;1,249.77,186.47,95.99,12.54">DEMIR at ImageCLEFMed 2011: Evaluation of Fusion Techniques for Multimodal Content-based Medical Image Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8DDBCE735F7FCADB14DB8CF6A8B01ECD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Information Retrieval</term>
					<term>Weighting-schemes</term>
					<term>Re-ranking</term>
					<term>Medical Imaging</term>
					<term>Content-based Image Retrieval</term>
					<term>Medical Image Retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper present the details of participation of DEMIR (Dokuz Eylul University Multimedia Information Retrieval) research team to the context of our participation to the ImageCLEF 2011 Medical Retrieval task. This year, we evaluated fusion and re-ranking method which is based on the best low level feature of images with best text retrieval result. We improved results by examination of different weighting models for retrieved text data and low level features. We tested multi-modality image retrieval in ImageCLEF 2011 medical retrieval task and obtained the best seven ranks in mixed retrieval, which includes textual and visual modalities. The results clearly show that proper fusion of different modalities improve the overall retrieval performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper we present the experiments performed by Dokuz Eylul University Multimedia Information Retrieval (DEMIR) Group, Turkey, in the context of our participation to the ImageCLEF 2011 Medical Image retrieval task <ref type="bibr" coords="1,411.57,585.47,10.66,8.96" target="#b0">[1]</ref>. The main focus of this work is to improve results by evaluation of different weighting models in text retrieval and then choose the best low-level feature of images for fusion with text only results. During the combination of text and low-level features, we check the variation of methods to gain the best result. On the other hand, we performed the experiments for narrowing down the data collection by defining and filtering out of irrelevant documents. Also we checked the weighted querying system performance in retrieval systems by weighting the special words in queries.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adil</head><p>Alpkocak, Okan Ozturkmenoglu, Tolga Berber, Ali Hosseinzadeh Vahid and Roghaiyeh Gachpaz Hamed After analyze the visual and textual features set we used (Section 2), we describe the multimodal fusion techniques for multimodal information (Section 3). After we present experiments on ImageCLEF 2010 Medical and Wikipedia Retrieval tracks data (Section 4), then Section 5 concludes the paper by pointing out the open issues and possible avenues of further research in the area of multimodal re-ranking and fusion techniques for content-based image retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Feature Set</head><p>The data collection of ImageCLEF 2011 Medical retrieval has textual and visual information. Participants will be given a set of 30 textual queries with 2-3 sample images for each query. The queries will be classified into textual, visual and mixed, based on the methods that are expected to yield the best results. <ref type="bibr" coords="2,379.23,462.45,11.00,8.96" target="#b0">[1]</ref> We performed our experiments using ImageCLEF 2010 Medical and Wikipedia Retrieval track's text and image data. We check the variation of retrieval methods on textual and visual information to gain the best result.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Textual Features</head><p>Since the choice of the weighting model may crucially affect the performance of any information retrieval system, first of all we decided to work on evaluating the relative merits and drawbacks of different weighting models using Terrier IR Platform <ref type="bibr" coords="2,456.01,572.51,10.98,8.96" target="#b1">[2]</ref>, open source search engine written in Java and is developed at the School of Computing Science, University of Glasgow. We performed our experiments on textual features using ImageCLEF 2010 Medical track collection. We started from a traditional bag-of-words representation of pre-processed texts that pre-processing includes stemming (Porter stemmer <ref type="bibr" coords="2,442.62,632.51,11.69,8.96" target="#b2">[3]</ref> for English) and stop words removal. DFR-BM25 model's MAP score is not the best one, but the all weighting model's number of relevant retrieved score results are close to each other and considering achievements of this model <ref type="bibr" coords="2,374.83,668.54,15.31,8.96" target="#b10">[11]</ref>, we submitted our textual base point run using this model on ImageCLEF 2011 Medical retrieval task data collection as RUN_1 .  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Visual Features We Used</head><p>Selection of low-level features is one of the major aspects of a typical content-based information retrieval (CBIR) system. We call these low-level features because most This feature contains results from the combination of 3 fuzzy systems including histogram, color and texture information. FCTH size is limited to 72 bytes per image, and also suitable for use in large image databases <ref type="bibr" coords="4,365.06,456.21,10.66,8.96" target="#b4">[5]</ref>.  BTDH: This feature is very similar to FCTH feature. The main difference from FCTH feature is using brightness instead of color histogram. This feature is originally developed for radiology images which do not contain color data <ref type="bibr" coords="4,435.92,492.23,10.58,8.96" target="#b5">[6]</ref>.</p><p>After extracting features, we gain an n-dimensional feature space per feature. For query processing, we had to map all of the objects in the database and the query onto this space and then evaluate the similarity difference between the vector corresponding to the query and the vectors representing the data. We selected the Euclidean distance, one of commonly used similarity and distance functions for measuring distances between points in the 3D space, as distance/similarity function and based on obtained similarity scores; we found that CEDD and FCTH are the best descriptors for image retrieval based on low level features only. Therefore we submitted our visual only base point run for CEDD feature. Moreover we use these features for multimodal fusion in next experiments. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Fusion Techniques in Multimodal Information Retrieval</head><p>Multimedia fusion is referred to as integration of multiple media, their associated features, or the intermediate decisions in order to perform an analysis task, has gained much attention of many researchers in recent times. The fusion of multiple modalities can provide complementary information and increase the accuracy of the overall decision making process <ref type="bibr" coords="5,225.51,478.07,10.66,8.96" target="#b7">[8]</ref>.</p><p>The fusion of different modalities is generally performed at two levels: feature level or early fusion and decision level or late fusion. Some researchers have also followed a hybrid approach by performing fusion at the feature as well as the decision level. In the feature level or early fusion approach, the features, some distinguishable properties of a media stream, extracted from input data are first combined and then sent as input to a single analysis unit that performs the analysis task. In the decision level or late fusion approach, the analysis units first provide the local decisions D1 to Dn that are obtained based on individual features F1 to Fn. Then a decision fusion unit combines local decisions to make a fused decision vector that is analyzed further to obtain a final decision D about the task or the hypothesis. To achievement the advantages of both the feature level and the decision level fusion strategies, several researchers have opted to use a hybrid fusion strategy, which is a combination of both feature and decision level strategies.</p><p>The decision level fusion strategy has many advantages over feature fusion. For instance, the decisions (at the semantic level) usually have the same representation. Therefore, the fusion of decisions becomes easier. Moreover, the decision level fusion strategy offers scalability (i.e. graceful upgrading or degradation) in terms of the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adil</head><p>Alpkocak, Okan Ozturkmenoglu, Tolga Berber, Ali Hosseinzadeh Vahid and Roghaiyeh Gachpaz Hamed modalities used in the fusion process, which is difficult to achieve in the feature level fusion. Another advantage of late fusion strategy is that it allows us to use the most suitable methods for analyzing each single modality and this provides much more flexibility than the early fusion.</p><p>Because of these profits, we exerted Linear Weighted Fusion, one of the simplest and most widely used methods on our extracted CEDD and FCTH similarity scores and similarity scores that gained from text retrieval as explained in previous chapters. We applied Fagin's Combination Algorithms <ref type="bibr" coords="6,316.08,234.18,11.75,8.96" target="#b8">[9]</ref> for Ranked Input Sets putting on two score aggregation function defined as "Average" and "Weighted Average". The average function is applied by taking mean of individual similarity scores of any object.</p><p>On the other hand, the weighted average function is applied in the same manner but differing on multiplying each individual similarity with a weight value. The weight assignment to individual scores provides an importance level for each feature defined in a whole query <ref type="bibr" coords="6,235.01,318.21,15.50,8.96" target="#b9">[10]</ref>. After comparison of several studies we decided to multiply textual feature by 3 and CEDD feature by 2 to gain the best fusion result based on weighted average combination method.</p><p>Before fusion operation takes place, normalization should be applied to get accurate and correct results since different modalities results a different ranges of similarity values <ref type="bibr" coords="6,194.96,378.21,15.39,8.96" target="#b11">[12]</ref>. Here, we applied Min-Max normalization on similarity values to ensure that the range of these features is between 0 and 1. The following equations will ensure the range of this feature from 0 to 1.</p><p>Suppose the range for a feature is from to . Then the normalized feature is defined as follows:</p><p>(1) Min-Max normalization is a process of taking data measured in its units and transforming it to a value between 0.0 and 1.0. The lowest (min) value is set to 0.0 and the highest (max) value is set to 1.0. This provides an easy way to compare values that are measured using different scales (i.e., textual, shape, visual, density etc.) or different units of measure (i.e., Euclidean or non-metric space values). After normalization of the similarity values, we combined the different modalities in ranked results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimentations</head><p>We submitted 10 runs to ImageCLEF Medical Retrieval task, in three different categories. The first category includes the runs for baseline retrieval in single modality, numbered as 1 and 3 are baseline retrievals for textual-only and visual-only retrieval, respectively. The second groups of runs to evaluate re-ranking affects to base line, numbered as 8 is re-indexed the baseline retrieval result and re-ranked in textual modality. The last group includes mixed retrieval experiments with fusion of different modalities, numbered as 2, 4, 5, 6, 7, 9 and 10. As illustrated in Table <ref type="table" coords="6,445.07,668.30,3.76,8.96" target="#tab_1">1</ref>, it is obvious that results of mixed runs are better than textual or visual only. Moreover results of weighted average combination method are better than normal average method in all approach. Below, we provide a short description of each runs, shortly.</p><p> RUN_1: This run is our baseline retrieval result for textual modality. In this run, we removed the stop words, applied Porter stemmer algorithm and used the DFR_BM25 weighting model on text retrieval engine system, Terrier. Let the subscript indicates the arbitrary run ID, the similarity of first run, S 1 , is defined as follows:</p><p>(</p><p> RUN_3: Our baseline retrieval result is this run for visual modality. We used the CEDD feature in visual modality because its performance is better than other features, also you can see in Figure <ref type="figure" coords="7,279.21,288.21,3.76,8.96" target="#fig_3">4</ref>.</p><p>(</p><p> RUN_8: This run of our group on textual feature is based on our proposed a twolevel re-ranking approach in for move relevant documents upward. Re-ranking is a method to reorder the initially retrieved documents with the aim to increase precision. Basically, relevant documents with low similarity scores are re-weighted and reordered. In this run, we propose a new re-ranking approach which includes the narrowing-down phase of search space. Result sets of each query and corresponding base similarity scores are inputs for re-ranking operation. Firstly, we selected relevant documents using initial similarity scores. In other word, we filtered out non-relevant documents based on initial similarity scores. For this we selected first 1000 relevant documents if it existed. Then we constructed a new VSM using this small document sets. This operation drastically reduced both the number of documents and the number of terms. In short, this level shrinks down the initial VSM data into more manageable size. Then we calculated similarity score of new VSM and submitted the results as RUN_8. As illustrated in Table <ref type="table" coords="7,463.39,480.23,3.71,8.96" target="#tab_1">1</ref>, unlike the achievements of this approach in ImageCLEF 2010 Wikipedia retrieval task, all factors of retrieval system decline in contrast to our textual base line run.</p><p> RUN_2: Another narrowing down approach that we examine this year is based on medical image modality classification. Result sets of each query and corresponding base similarity scores and their class based on any classification algorithm are inputs for this approach. We also expanded query structure by assignment a type for example images of each query. A query can have a more than one type. In the narrowing down phase we filtered out non relevant images that its class was not the same as corresponding query type. We applied this method filtering the modality classification using GIFT system and 1NN approach and submitted RUN_2 as results. As obtained from Table <ref type="table" coords="7,268.79,636.23,3.76,8.96" target="#tab_1">1</ref>, although MAP in this method is decreased but there are a considerable improvement in P@10 and P@ 20 values in contrast to textual base line.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Adil</head><p>Alpkocak, Okan Ozturkmenoglu, Tolga Berber, Ali Hosseinzadeh Vahid and Roghaiyeh Gachpaz Hamed <ref type="bibr" coords="8,459.07,162.18,11.75,8.96" target="#b4">(5)</ref>  RUN_5: In this run, we combined the multiplied textual feature by 3 with the multiplied visual retrieval result using CEDD feature by 2, divided total score with the rated value 5.</p><p> RUN_4: We combined the baseline textual retrieval result with visual retrieval result using CEDD feature and get average score.</p><p> RUN_7: Another approach that we experimented in text retrieval this year is evaluation of effects of weighting to special words in queries. For this purpose we selected the medical modality names in queries (i.e., CT, PET, X-RAY, MRI etc.) and weighted them by 2.5 using query language of Terrier. Although result of this approach decline in compare to baseline too, but they are better than result of reranking methods. Due to limitation of submitted runs of participant, we did not submitted weighted text retrieval results as a new run but we fused them with low level feature of images to obtain better performance. In this run, we combined the multiplied weighted textual feature by 3 with the multiplied visual retrieval result using CEDD feature by 2, divided total score with the rated value 5.</p><p> RUN_10: After we combined the multiplied RUN_8 result by 3 with the multiplied visual retrieval result using CEDD feature by 2 and divided total score with the rated value 5.</p><p> RUN_6: After we combined the weighted textual retrieval result with visual retrieval result using CEDD feature and get average score.</p><p>RUN_9: After we combined the RUN_8 result with visual retrieval result using CEDD feature and get average score.</p><p>( </p><formula xml:id="formula_8" coords="8,458.23,570.23,12.59,8.96">)<label>11</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this year, we examined effects of different weighting models on text retrieval and found that the role of proper weighting model selection is to improve the performance of text retrieval systems. Also, we compare MAP of different extracted low-level features normalized similarity scores and due to this comparison we select CEDD and FCTH descriptors as suitable features to utilize for fusion to textual results. Also due to analogy of combination methods in our previous studies, we acquire choosing a suitable combination method for fusion improved the results. The results clearly show that combining text-based and content-based image retrieval results with a proper fusion technique improves the performance.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,211.97,287.30,171.20,8.10;2,124.77,147.40,345.75,131.25"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Basic block diagram of retrieval system.</figDesc><graphic coords="2,124.77,147.40,345.75,131.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,189.38,384.50,216.49,8.10;3,137.52,183.40,320.20,192.40"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. MAP scores of weighting models for textual features</figDesc><graphic coords="3,137.52,183.40,320.20,192.40" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="3,139.22,611.44,316.65,8.10;3,283.49,622.48,28.44,8.10;3,133.65,404.80,327.94,197.05"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Number of relevant retrieved document in different weighting models for textual features</figDesc><graphic coords="3,133.65,404.80,327.94,197.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,126.02,363.86,343.01,8.10;5,289.37,374.78,16.65,8.10;5,124.77,147.40,345.75,207.75"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Comparison of low level feature performance on ImageCLEF 2010 Wikipedia Retrieval task.</figDesc><graphic coords="5,124.77,147.40,345.75,207.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="9,131.06,149.99,338.29,262.26"><head>Table 1 .</head><label>1</label><figDesc>Runs of DEMIR group in ImageCLEFMed 2011.</figDesc><table coords="9,131.06,173.22,338.29,239.03"><row><cell cols="2">RunID Rank</cell><cell>Type</cell><cell>MAP</cell><cell>P10</cell><cell>P20</cell><cell>Rprec</cell><cell>bpref</cell><cell>rel_ret</cell></row><row><cell>5</cell><cell>1</cell><cell cols="6">Mixed 0.2372 0.3933 0.3550 0.2881 0.2738</cell><cell>1597</cell></row><row><cell>4</cell><cell>2</cell><cell cols="6">Mixed 0.2307 0.3967 0.3400 0.2706 0.2606</cell><cell>1595</cell></row><row><cell>7</cell><cell>3</cell><cell cols="6">Mixed 0.2014 0.3400 0.3233 0.2587 0.2481</cell><cell>1455</cell></row><row><cell>10</cell><cell>4</cell><cell cols="6">Mixed 0.1983 0.4067 0.3350 0.2397 0.2428</cell><cell>1349</cell></row><row><cell>6</cell><cell>5</cell><cell cols="6">Mixed 0.1972 0.3367 0.3083 0.2489 0.2383</cell><cell>1443</cell></row><row><cell>9</cell><cell>6</cell><cell cols="6">Mixed 0.1853 0.3667 0.3283 0.2309 0.2230</cell><cell>1338</cell></row><row><cell>2</cell><cell>7</cell><cell cols="6">Mixed 0.1645 0.3967 0.3350 0.2340 0.2198</cell><cell>890</cell></row><row><cell>1</cell><cell>15</cell><cell>Text</cell><cell cols="5">0.1942 0.3400 0.2933 0.2242 0.2215</cell><cell>1444</cell></row><row><cell>8</cell><cell>49</cell><cell>Text</cell><cell cols="5">0.1452 0.3033 0.2633 0.1683 0.1859</cell><cell>1288</cell></row><row><cell>3</cell><cell>12</cell><cell cols="6">Visual 0.0174 0.1067 0.0833 0.0434 0.0602</cell><cell>569</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,128.58,617.27,316.74,8.96" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="9,136.22,617.27,121.19,8.96">Medical Image Retrieval Task</title>
		<ptr target="http://www.imageclef.org/2011/medical" />
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,128.58,629.27,224.07,8.96" xml:id="b1">
	<monogr>
		<ptr target="http://terrier.org/docs/v2.2.1/" />
		<title level="m" coord="9,136.22,629.27,93.89,8.96">The Terrier IR Platform</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,128.58,641.27,342.02,8.96;9,136.22,653.27,225.61,8.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,194.18,641.27,137.39,8.96">An algorithm for suffix stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,339.91,641.27,130.69,8.96;9,136.22,653.27,79.41,8.96">Program: electronic library and information systems</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,128.58,665.30,341.94,8.96;9,136.22,677.30,334.40,8.96;10,175.22,121.67,16.41,8.10;10,208.93,121.67,39.19,8.10;10,265.40,121.67,21.43,8.10;10,304.14,121.67,63.15,8.10;10,401.85,121.67,22.01,8.10;10,441.07,121.67,29.23,8.10;10,124.82,132.71,206.19,8.10;10,136.22,150.18,39.97,8.96;10,216.66,150.18,253.79,8.96;10,136.22,162.18,77.63,8.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,337.12,665.30,133.40,8.96;9,136.22,677.30,169.78,8.96">Img(Rummager): An Interactive Content Based Image Retrieval System</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Chatzichristofis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Boutalis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,334.27,677.30,136.35,8.96;10,175.22,121.67,16.41,8.10;10,208.93,121.67,39.19,8.10;10,265.40,121.67,21.43,8.10;10,304.14,121.67,63.15,8.10;10,401.85,121.67,22.01,8.10;10,441.07,121.67,29.23,8.10;10,124.82,132.71,206.19,8.10;10,136.22,150.18,39.97,8.96;10,216.66,150.18,70.60,8.96">2nd International Workshop on Adil Alpkocak, Okan Ozturkmenoglu, Tolga Berber, Ali Hosseinzadeh Vahid and Roghaiyeh Gachpaz Hamed Similarity and Applications</title>
		<meeting><address><addrLine>Washington</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="151" to="153" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,128.58,174.18,342.11,8.96;10,136.22,186.18,230.91,8.96;10,367.39,183.99,5.04,5.83;10,375.19,186.18,95.36,8.96;10,136.22,198.18,334.61,8.96;10,136.22,210.18,107.03,8.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,288.77,174.18,181.93,8.96;10,136.22,186.18,205.36,8.96">FCTH: Fuzzy Color and Texture Histogram -A Low Level Feature for Accurate Image Retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Chatzichristofis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Boutalis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,362.15,186.18,4.98,8.96;10,367.39,183.99,5.04,5.83;10,375.19,186.18,95.36,8.96;10,136.22,198.18,231.65,8.96">9 th International Workshop on Image Analysis for Multimedia Interactive Services</title>
		<meeting><address><addrLine>Klagenfurt, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="191" to="196" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,128.58,222.18,341.80,8.96;10,138.98,234.18,331.62,8.96;10,138.98,246.18,195.35,8.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,299.45,222.18,170.93,8.96;10,138.98,234.18,230.13,8.96">Content based radiology image retrieval using a fuzzy rule based scalable composite descriptor</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">A</forename><surname>Chatzichristofis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Boutalis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,377.71,234.18,92.89,8.96;10,138.98,246.18,49.34,8.96">Multimedia Tools and Applications</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="493" to="519" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,128.58,258.18,342.11,8.96;10,136.22,270.18,188.51,8.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,289.37,258.18,181.33,8.96;10,136.22,270.18,40.62,8.96">Efficient Use of MPEG-7 Edge Histogram Descriptor</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">S</forename><surname>Won</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">K</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">J</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,183.50,270.18,52.57,8.96">ETRI Journal</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,128.58,282.21,341.84,8.96;10,138.98,294.21,198.73,8.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,295.73,282.21,170.85,8.96">Multimodal fusion for multimedia analysis</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Pradeep</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anwar</forename><surname>Atrey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hossain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,138.98,294.21,80.32,8.96">Multimedia Systems</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="345" to="379" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,128.58,306.21,341.99,8.96;10,138.98,318.21,287.84,8.96" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,259.73,306.21,192.03,8.96">Optimal aggregation algorithms for middleware</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Fagin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lotem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Naor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,138.98,318.21,167.16,8.96">Journal of Computer and System Sciences</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="614" to="656" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,133.20,330.21,337.42,8.96;10,138.98,342.21,185.67,8.96" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,194.90,330.21,200.67,8.96">Combining Approaches to Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,419.23,330.21,51.39,8.96;10,138.98,342.21,85.36,8.96">Advances in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,133.20,354.21,337.38,8.96;10,138.98,366.21,307.93,8.96" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,208.13,354.21,262.45,8.96;10,138.98,366.21,26.26,8.96">Iadh: Term Frequency Normalisation Tuning for BM25 and DFR Models</title>
		<author>
			<persName coords=""><forename type="first">Ben</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ounis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,176.54,366.21,137.39,8.96">Advances in Information Retrieval</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3408</biblScope>
			<biblScope unit="page" from="200" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,133.20,378.21,337.29,8.96;10,138.98,390.11,331.45,9.06;10,138.98,402.21,138.65,8.96" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="10,179.90,378.21,290.59,8.96;10,138.98,390.21,23.01,8.96">Analysis and comparison of combination algorithms for joining ranked inputs</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ulker</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
			<pubPlace>Izmir, Turkey</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Dokuz Eylül University Department of Computer Engineering</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">MSc Thesis</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
