<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,178.29,148.72,71.48,15.51;1,277.74,148.72,147.04,15.51;1,424.71,145.56,5.98,11.96">SZTAKI</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,175.82,182.52,65.62,9.62"><forename type="first">Bálint</forename><surname>Daróczy</surname></persName>
							<email>daroczyb@ilab.sztaki.hu</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,254.72,182.52,62.34,9.62"><forename type="first">Róbert</forename><surname>Pethes</surname></persName>
							<email>rpethes@ilab.sztaki.hu</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,330.36,182.52,83.55,9.62"><forename type="first">András</forename><forename type="middle">A</forename><surname>Benczúr</surname></persName>
							<email>benczur@ilab.sztaki.hu</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,178.29,148.72,71.48,15.51;1,277.74,148.72,147.04,15.51;1,424.71,145.56,5.98,11.96">SZTAKI</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A343F449E1162B48925DB21C7830761F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Managment]: Languages-Query Languages Measurement, Performance, Experimentation SIFT, Color moments, Gaussian mixtures, Fisher vector, kernel methods, SVM</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We participated in the ImageCLEF 2011 Photo Annotation and Wikipedia Image Retrieval Tasks. Our approach to the ImageCLEF 2011 Photo Annotation is based on a kernel weighting procedure using visual Fisher kernels and a Flickr-tag based Jensen-Shannon divergence based kernel. We trained a Gaussian Mixture Model (GMM) to define a generative model over the feature vectors extracted from the image patches. To represent each image with high-level descriptors we calculated Fisher vectors from different visual features of the images. These features were sampled at various scales and partitions such as Harris-Laplace detected patches, scale and spatial pyramids. We calculated distance matrices from the descriptors of train images to combine different high-level descriptors and the tag based similarity matrix. With this uniform representation we had the possibility to learn the natural weights for each category over the different type of descriptors. This re-weightning resulted 0.01838 MAP increase over the average kernel results. We used the weighted kernels for learning linear SVM models for each of the 99 concepts independently. For the Wikipedia Image Retrieval Task we used the search engine of the Hungarian Academy of Sciences as our information retrieval system that is based on Okapi BM25 ranking. We calculated light Fisher vectors to represent the content of the images and performed nearest-neighbour search on them.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper we describe our approach to the ImageCLEF 2011 Photo Annotation an Wikipedia Image Retrieval evaluation campaigns <ref type="bibr" coords="1,260.00,719.96,10.51,9.62" target="#b5">[6,</ref><ref type="bibr" coords="1,274.15,719.96,7.01,9.62" target="#b6">7]</ref>. Our image classification is based on a combination of visual and textual (Flickr tag) information defining uniform kernel matrices. We measured the similarity between the set of image tags using the Jensen-Shannon divergence. We extracted normalized Fisher vectors to calculate the distance kernel for the content of the images. In Wikipedia Image Retrieval Task we used the search engine of the Hungarian Academy of Sciences <ref type="bibr" coords="2,472.55,147.66,10.53,9.62" target="#b1">[2]</ref> as our information retrieval system that is based on Okapi BM25 <ref type="bibr" coords="2,349.19,159.61,9.96,9.62" target="#b7">[8]</ref>. We extracted light Fisher vectors for each image to measure image similarity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Photo Annotation Task</head><p>To reduce the effect of noise on codebook generation and bag-of-words modeling, we smoothed the images. Although the images are not of the same resolution, we did not rescale them. One of the reasons was to avoid adding noise. In addition, with a properly normalized bag-of-words modeling we did not need to calculate fixed number of samples per image. We used feature vectors to describe the visual content of an image by approximately 13000 descriptors per image per modality. We sampled the patches with dense multi-scale grid and Harris-Laplace point detection. We calculated SIFT (Scale Invariant Feature Transform <ref type="bibr" coords="2,265.54,298.07,13.69,9.62" target="#b4">[5]</ref>) and RGB color descriptors for each patch. For each type of low-level descriptor we trained a Gaussian Mixture Model (GMM) with 256 Gaussians. The training of GMM models with about 3 million training points took 20 minutes per descriptor with our open-source CUDA GMM implementation <ref type="bibr" coords="2,315.73,333.93,9.96,9.62" target="#b2">[3]</ref>. For the SIFT descriptors the training was performed after reducing the dimension of descriptors to 80 by PCA. By the Color moments the dimension reduction resulted performance loss so we did not adopted PCA for it. The normalized Fisher gradient vector computed from GMM of SIFT descriptors is a well known technique to represent an image with only one vector per pooling (we used 1x1, 1x3 and 2x2 spatial pyramids <ref type="bibr" coords="2,90.00,393.71,10.52,9.62" target="#b8">[9]</ref> ). We also calculated Fisher vectors on the Harris-Laplacian detected corner descriptors. Our overall procedure is shown in Fig. <ref type="figure" coords="2,240.35,405.66,3.87,9.62" target="#fig_0">1</ref>.</p><p>Our GMM procedure is based on the standard expectation maximization (EM) algorithm with a non-hierarchical structure. We resolved the well known vulnerability of EM algorithm to underflow especially computing the conditional probabilities with large (50+) codebooks in fp32/fp64 precision. This is a limitation of GPGPU cards, additionally in fp64 they are usually more than twice as slow as in fp32. Since it is not sufficient enough to use logarithm instead of values we implemented a magnitude summation algorithm. Read the details in our paper <ref type="bibr" coords="2,496.15,477.39,12.65,9.62" target="#b2">[3]</ref>. Our source code along with preprocessed GMM models and codes for Fisher vector calculation is available free for research use at http://datamining.sztaki.hu/?q=en/GPU-GMM.</p><p>The Fisher vectors can also be computed parallel in k • D independent calculations where D is the dimension of the low-level features and k is the number of Gaussians. If neither the dimension nor the number of clusters is more than the maximal number of threads for a GPU block, the computational time depends only on the number of low-level features. Our implementation with calculating all the gradients of the sampling points is seven-times faster than a well-tuned locally optimal Fisher vector implementation on a fast CPU and 44-times faster if we calculate the same algorithm on the CPU <ref type="bibr" coords="2,179.20,584.99,14.89,9.62" target="#b2">[3]</ref>. The calculation of Fisher vectors took about 1.5 hours per modality. We extracted 9 Fisher vectors per image for each pooling: one Fisher vector for all the patches, one for the Harris-Laplace detected points, three for the 1x3 and four for the 2x2 spatial partitions. We normalized the resulted vectors with Fisher information matrix, power and L2 normalization. Worth to mention, as our feature extraction methods eventuated high number of descriptors for each part of the image and our Fisher calculation method is not cutting the lower probabilities, the resulted Fisher vectors were highly non-sparse without any normalization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Pre-Calculated kernel combination for linear SVM</head><p>Learning linear SVM models on Bag-of-Words models is a widely used technique <ref type="bibr" coords="2,445.72,703.00,17.54,9.62" target="#b9">[10,</ref><ref type="bibr" coords="2,467.07,703.00,7.01,9.62" target="#b0">1]</ref>. One of the main problem is to define the kernel function between the training instances. We used precomputed normalized distance kernels instead of Fisher kernels because our preliminary experiments showed better annotation performance with different training sets. Beside the classification performance gain the dimension of the kernels are less than the dimension of a regular Fisher vector (dimension of the kernel = #training images = 8k vs. dimension of F isher vector = 40k -49k) . In addition, with pre-computed kernels we had the ability to combine textual and visual kernels without increasing the dimension of the learning problem. We averaged the corresponding basic kernels of the spatial pyramids. This resulted four kernels per low-level descriptor per image (Harris-Laplace, full image, 1x3 and 2x2 spatial pyramid). Additionally we measured the distance between two image according to their tags with Jensen-Shannon divergence. Our choice was inspired by the similarity properties of Jensen-Shannon against Kullback-Leibler divergence.</p><p>To learn the weights of the different basic kernels we splitted the training set into two parts on account of sparse annotation. We trained SVM models per category ( <ref type="bibr" coords="4,397.06,219.39,10.96,9.62" target="#b3">[4]</ref>) on the two part of the data and evaluated it on the other half of the training set. We used the independently evaluated predictions for the basic kernels and determined a combination between them for each category. We used the existing Flickr tags to create probability distributions. If an image had no tag we set its similarity to be zero if measured against itself and one if measured against the other images. We assumed that the specified weights are linked to the ideal combination of the basic kernels. Our final weighted kernel for each category c between images X and Y was</p><formula xml:id="formula_0" coords="4,193.26,322.02,319.74,30.76">K(X, Y ) c = 1 |K| K k=1 α ck T t=1 K k (X, I t ) * K k (Y, I t ).<label>(1)</label></formula><p>The K k (X, I t ) denotes the basic kernels, I t is the tth training image and T is the number of training images of the collection. For the visual Fisher vectors we measured the similarity between two vectors with Manhattan distance. For the Flickr tag based probability distributions we adopted the Jensen-Shannon divergence as similarity measure.</p><formula xml:id="formula_1" coords="4,199.21,429.91,313.79,61.23">K k visual (X, I t ) = dist M anhattan (F k (X), F k (I t )) max * X arg max t K k (X, I t ) (2) K k textual (X, I t ) = dist Jensen-Shannon (X, I t )<label>(3)</label></formula><p>where F k (X) denotes the Fisher vector of X for the kth pooling. Since the output of our classifier was a summarized values of the weighted dot-products of the support vectors and the test instances, we used the sigmoid function to map the output of the SVM classifier to a floating point prediction between zero and one.</p><formula xml:id="formula_2" coords="4,218.15,567.60,294.85,23.20">P rediction f loat = 1 1 + exp -1 * svmoutput (4)</formula><p>Our method gained 1.8 % increase in MAP over the average sum of the basic kernels if we also included a textual based kernel beside the visual kernels. As seen in Table <ref type="table" coords="4,426.56,613.50,4.98,9.62" target="#tab_0">1</ref> if we adopted the kernel weighting only to the basic visual kernels we measured a 0.3 % increase.</p><p>For the example-based evaluation we needed to define a mapping from the floating point predictions into a binary annotation. We applied two strategies. In the first method we shifted the borderline between the positive and the negative samples till the annotation on the training set had the highest precision and recall. In the second method we assumed that the relative occurrence of a category in the training and the test set were similar and shifted the borderline according to it. The previous had much higher F-score (0.545341 vs. 0.593088) and higher Semantic R-Precision (0.70853 vs. 0.71928). Worth to mention, from our submissions the averaged visual kernel had the highest Semantic R-Precision (0.72902450). We used the Hungarian Academy of Sciences search engine <ref type="bibr" coords="5,348.01,256.30,10.52,9.62" target="#b1">[2]</ref> as our information retrieval system based on Okapi BM25 ranking <ref type="bibr" coords="5,226.65,268.25,9.96,9.62" target="#b7">[8]</ref>. We applied the English, German and French annotations and articles independently for indexing. We made no differentiation between the title and the body of the annotation. Since file names often contain relevant keywords and also often as substring, we gave score proportional to the length of the matching substring. Since the indexing of all substrings is infeasible, we only performed this step for those documents that already matched at least one query term in their body.</p><p>For the WikipediaMM task we also deployed query expansion by an online WordNet<ref type="foot" coords="5,484.78,350.83,3.97,4.77" target="#foot_1">1</ref> . We added groups of synonyms with reduces weight so that only the score of the first few best performing synonym was added to the final score to avoid overscoring long lists of synonyms.</p><p>Nearest neighbor search was performed over light Fisher vector. We call it light Fisher vectors because we calculated descriptors only on a dense grid (16 pixel step sampling) and we did not extracted different poolings. We used the same Gaussian Mixture Model for the RGB color moment descriptors as in the Photo Annotation task.</p><p>Our Relevance Feedback method used the first 10 results of the aggregated score of the three language query results. We calculated the Jensen-Shannon distance from the first 10 hits to the lower ranked hits with weight according to their rank. For the documents ranked lower (i &gt; 9) the new score was</p><formula xml:id="formula_3" coords="5,186.25,490.44,326.75,30.26">score i = 1 i + 1 * 9 j=0 (1 -dist Jensen-Shannon (D i , D j ))<label>(5)</label></formula><p>where D i and D j denotes the probability distribution of the ith and jth document. We found the text based score more accurate. Therefore we adopted our Relevance Feedback procedure using the visual similarity of the first hundred hits to re-rank the documents. This resulted 0.3 % increase in MAP (0.2167 vs. 0.2136).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>For Photo Annotation Task, we successfully applied visual and textual kernel matrices as instance matrices for SVM learning. We used our own implementations for Low-level feature extraction, to train GMM models and calculate Fisher vectors. Our kernel weightning procedure resulted 1.8 % improvement over the average combination of the textual and visual kernels. We are planning to including new pre-computed kernels in the system and applying generative models to improving the determination of weights for kernel aggregation.</p><p>For image retrieval task, our Relevance Feedback method improved the baseline Okapi BM25 based textual system. We also plan to strengthen our retrieval results by using more sophisticated methods for text and image retrieval fusion.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,132.63,636.74,337.76,9.62"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Feature extraction and classification procedure (Photo Annotation)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,90.00,118.71,402.38,125.78"><head>Table 1 :</head><label>1</label><figDesc>Photo Annotation results</figDesc><table coords="5,90.00,128.47,402.38,116.02"><row><cell></cell><cell>Kernel aggregation</cell><cell>MAP</cell><cell>EER</cell><cell>AUC</cell></row><row><cell>visual + textual run3</cell><cell>weighted</cell><cell cols="3">0.438744 0.243574 0.827621</cell></row><row><cell>visual + textual run2 (we cssj)</cell><cell>weighted</cell><cell cols="3">0.436294 0.241691 0.827747</cell></row><row><cell>visual + textual run1 (avg cssj)</cell><cell>average</cell><cell cols="3">0.420406 0.243885 0.828322</cell></row><row><cell>visual run2</cell><cell>weighted</cell><cell cols="3">0.369688 0.263449 0.806691</cell></row><row><cell>visual run1 (avg cns)</cell><cell>average</cell><cell cols="3">0.367054 0.264328 0.805142</cell></row><row><cell>textual run1 (jensen)</cell><cell>only one</cell><cell cols="3">0.345616 0.338127 0.717966</cell></row><row><cell cols="3">3 The Wikipedia Image Retrieval Task</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0" coords="1,102.20,739.48,378.03,7.68"><p>*   This work was supported by the EU FP7 Projects LAWA (Large-Scale Longitudinal Web Analytics).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_1" coords="5,105.25,737.82,122.62,7.30"><p>http://wordnet.princeton.edu/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,110.48,133.61,402.50,9.62;6,110.47,145.57,22.68,9.62" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="6,327.04,133.61,160.07,9.62">XRCEs Participation in ImageCLEF</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ah-Pine</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clinchant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,165.50,402.50,9.62;6,110.47,177.45,402.53,9.62;6,110.47,189.40,391.52,9.62" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,248.74,177.45,243.83,9.62">Searching a small national domain-preliminary report</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>András</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Károly</forename><surname>Benczúr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eszter</forename><surname>Csalogány</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dániel</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tamás</forename><surname>Fogaras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Máté</forename><surname>Sarlós</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eszter</forename><surname>Uher</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Windhager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,110.47,189.40,268.56,9.62">Proceedings of the 12th World Wide Web Conference (WWW)</title>
		<meeting>the 12th World Wide Web Conference (WWW)<address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,209.33,402.51,9.62;6,110.47,221.29,303.58,9.62" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Bodzsár</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Daróczy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Petrás</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">András</forename><forename type="middle">A</forename><surname>Benczúr</surname></persName>
		</author>
		<ptr target="http://datamining.sztaki.hu/?q=en/GPU-GMM" />
		<title level="m" coord="6,373.43,209.33,139.56,9.62;6,110.47,221.29,74.96,9.62">GMM based fisher vector calculation on GPGPU</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,241.20,402.51,9.62;6,110.47,253.17,305.82,11.34" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="6,279.92,241.20,202.59,9.62">LIBSVM: a library for support vector machines</title>
		<author>
			<persName coords=""><forename type="first">Chih-Chung</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chih-Jen</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://www.csie.ntu.edu.tw/~cjlin/libsvm" />
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,273.09,402.51,9.62;6,110.47,285.04,241.25,9.62" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,161.73,273.09,225.23,9.62">Object recognition from local scale-invariant features</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,405.40,273.09,107.60,9.62;6,110.47,285.04,87.34,9.62">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1150" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,304.97,402.53,9.62;6,110.47,316.92,314.46,9.62" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,238.72,304.97,274.29,9.62;6,110.47,316.92,124.03,9.62">New strategies for image annotation: Overview of the photo annotation task at imageclef</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Huiskes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,264.94,316.92,102.10,9.62">Working notes of CLEF</title>
		<imprint>
			<date type="published" when="2010">2010. 2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,336.85,402.49,9.62;6,110.47,348.81,188.90,9.62" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,285.88,336.85,227.09,9.62">Overview of the wikipedia retrieval task at imageclef</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Popescu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kludas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,137.59,348.81,103.90,9.62">Working Notes of CLEF</title>
		<imprint>
			<date type="published" when="2010">2010. 2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,368.73,402.53,9.62;6,110.47,380.69,193.59,9.62" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,332.22,368.73,159.59,9.62">Relevance weighting of search terms</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karen</forename><forename type="middle">Sparck</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,110.47,380.69,119.26,9.62">Document retrieval systems</title>
		<imprint>
			<biblScope unit="page" from="143" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,412.57,402.53,9.62;6,110.47,424.52,402.53,9.62;6,110.47,436.48,266.80,9.62" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,271.36,412.57,241.65,9.62;6,110.47,424.52,163.71,9.62">Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,295.35,424.52,217.65,9.62;6,110.47,436.48,136.01,9.62">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-06">June 2006, 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,456.40,402.51,9.62;6,110.47,468.36,402.51,9.62;6,110.47,480.31,99.07,9.62" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,348.78,456.40,164.21,9.62;6,110.47,468.36,94.26,9.62">Evaluating color descriptors for object and scene recognition</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">E A</forename><surname>Van De Sande</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gevers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">G M</forename><surname>Snoek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,216.58,468.36,292.40,9.62">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1582" to="1596" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
