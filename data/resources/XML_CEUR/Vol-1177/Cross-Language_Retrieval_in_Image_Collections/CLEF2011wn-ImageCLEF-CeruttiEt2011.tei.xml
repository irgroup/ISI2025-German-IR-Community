<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,170.57,115.96,274.22,12.62;1,191.77,133.89,225.58,12.62">Guiding Active Contours for Tree Leaf Segmentation and Identification</title>
				<funder ref="#_g8Cq8gj">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,144.44,171.69,79.80,8.74"><forename type="first">Guillaume</forename><surname>Cerutti</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université de Lyon</orgName>
								<orgName type="institution" key="instit2">CNRS (</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Université Lyon 2</orgName>
								<orgName type="institution" key="instit2">LIRIS</orgName>
								<address>
									<postCode>UMR5205, F-69676</postCode>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,241.13,171.69,60.22,8.74"><forename type="first">Laure</forename><surname>Tougne</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université de Lyon</orgName>
								<orgName type="institution" key="instit2">CNRS (</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Université Lyon 2</orgName>
								<orgName type="institution" key="instit2">LIRIS</orgName>
								<address>
									<postCode>UMR5205, F-69676</postCode>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,318.24,171.69,51.34,8.74"><forename type="first">Julien</forename><surname>Mille</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Université de Lyon</orgName>
								<orgName type="institution" key="instit2">CNRS (</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Université Lyon 1</orgName>
								<orgName type="institution" key="instit2">LIRIS</orgName>
								<address>
									<postCode>UMR5205, F-69622</postCode>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,386.47,171.69,77.21,8.74"><forename type="first">Antoine</forename><surname>Vacavant</surname></persName>
							<email>antoine.vacavant@iut.u-clermont1.fr</email>
							<affiliation key="aff3">
								<orgName type="institution" key="instit1">Clermont Université</orgName>
								<orgName type="institution" key="instit2">Université d&apos;Auvergne</orgName>
								<orgName type="institution" key="instit3">ISIT</orgName>
								<address>
									<postCode>F-63001</postCode>
									<settlement>Clermont-Ferrand</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,274.50,183.64,61.88,8.74"><forename type="first">Didier</forename><surname>Coquin</surname></persName>
							<email>didier.coquin@univ-savoie.fr</email>
							<affiliation key="aff4">
								<orgName type="institution">LISTIC</orgName>
								<address>
									<addrLine>Domaine Universitaire</addrLine>
									<postCode>F-74944</postCode>
									<settlement>Annecy le Vieux</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,170.57,115.96,274.22,12.62;1,191.77,133.89,225.58,12.62">Guiding Active Contours for Tree Leaf Segmentation and Identification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B41866D481081DABA726F56DE8111F46</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the process of tree identification from pictures of leaves in a natural background, retrieving an accurate contour is a challenging and crucial issue. In this paper we introduce a method designed to deal with the obstacles raised by such complex images, for simple and lobed tree leaves. A first segmentation step based on a light polygonal leaf model is first performed, and later used to guide the evolution of an active contour. Combining global shape descriptors given by the polygonal model with local curvature-based features, the leaves are then classified over nearly 50 tree species.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In our everyday more urbanized and artificial world, the knowledge of plants, that used to constitute our most immediate environment, has somehow been lost, except for a handful of specialists. What is allegedly seen as unquestionable progress also scattered away the names and uses of so many trees, flowers and herbs. But nowadays, with a certain resurgence of the idea that plant resources and diversity ought to be treasured, the will to regain some touch with nature feels more and more tangible. And making it possible, for whoever feels the need, to identify a plant species, to learn its history and properties, is as much a way to transmit a vanished knowledge, as to allow people to get a glance at nature's unfathomable richness.</p><p>The identification of species is the first and essential key to understand the plant environment. Botanists traditionally rely on the aspect and composition of fruits, flowers and leaves to identify species. But in the context of a widespread non-specialist-oriented application, the predominant use of leaves, which are possible to find almost all year long, simple to photograph, and easier to analyze from two-dimensional images, is the most sensible and widely used approach in image processing. Considering the shape of a leaf is then the obvious choice to try to recognize the species. Our system intends then to classify a photograph of a leaf, which should be roughly centered and vertically-oriented as shown in Figure <ref type="figure" coords="2,166.20,142.90,3.87,8.74" target="#fig_0">1</ref>, over around 50 different tree species.</p><p>In this paper we present a method to classify simple and lobed leaves, using a polygonal modeling of leaf shapes and geometric botany-inspired descriptors. In Section 2 we will present related publications. Section 3 expounds the first segmentation step using a parametric active polygon, and Section 4 the refinement leading to the actual segmentation. The process of classification is then detailed in Section 5 and Section 6 relates the results of experiments both on white-background leaf images and natural scenes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related work</head><p>Plant recognition has recently been a subject of interest for various works. Few of them though consider acquiring images of leaves or flowers in a complex, natural environment, thus eluding most of the hard task of segmentation.</p><p>Nilsback and Zisserman <ref type="bibr" coords="2,259.50,307.78,10.52,8.74" target="#b0">[1]</ref> adressed the problem of segmenting flowers in natural scenes, by using a geometric model, and classifying them over a large number of classes. Saitoh and Kaneko <ref type="bibr" coords="2,297.53,331.69,10.52,8.74" target="#b1">[2]</ref> focus also on flowers, but in images with hard constraints on out-of-focus background. Such approaches are convenient for flowers, but lose much of their efficiency with leaves.</p><p>Many works on plant leaf recognition tend to avoid the problem by using a plain sheet of paper to make the segmentation easy as pie. Their recognition systems are then based on either statistical or geometric features: Centroid-Contour Distance (CCD) curve <ref type="bibr" coords="2,278.49,403.97,9.96,8.74" target="#b2">[3]</ref>, moments <ref type="bibr" coords="2,339.55,403.97,10.52,8.74" target="#b3">[4,</ref><ref type="bibr" coords="2,350.07,403.97,7.01,8.74" target="#b2">3]</ref>, histogram of gradients, or SIFT points <ref type="bibr" coords="2,191.68,415.92,9.96,8.74" target="#b0">[1]</ref>. Some more advanced statistical descriptors, such as the Inner Distance Shape Context <ref type="bibr" coords="2,247.77,427.88,9.96,8.74" target="#b4">[5]</ref>, or the Curvature Scale Space representation <ref type="bibr" coords="2,470.08,427.88,10.52,8.74" target="#b5">[6]</ref> that allows taking self-intersections into account, have also been applied to the context of leaf classification, while developed in a general purpose.</p><p>As a matter of fact, isolating green leaves in an overall not less green environment seems like a much tougher issue, and only some authors have designed algorithms to overcome the difficulties posed by a natural background. Teng, Kuo and Chen <ref type="bibr" coords="2,203.37,500.16,10.52,8.74" target="#b6">[7]</ref> used 3D points reconstruction from several different images to perform a 2D/3D joint segmentation using 3D distances and color similarity. Wang <ref type="bibr" coords="2,163.39,524.07,10.52,8.74" target="#b3">[4]</ref> performed an automatic marker-based watershed segmentation, after a first thresholding-erosion process. All these approaches are complex methods that seem hardly reachable for a mobile application. In the case of weed leaves, highly constrained deformable templates have been used <ref type="bibr" coords="2,377.26,559.93,10.52,8.74" target="#b7">[8]</ref> to segment one single species, providing good results even with occlusions and overlaps.</p><p>The concept of active contours, or snakes, have been introduced by Kass, Witkin and Terzopulos <ref type="bibr" coords="2,239.52,596.34,10.52,8.74" target="#b8">[9]</ref> as a way to solve problems of edge detection. They are splines that adjust to the contours in the image by minimizing an energy functional. This energy is classically composed of two terms, an internal energy term considering the regularity and smoothness of the desired contour, and an external or image energy accounting for its adequation with the actual features in the image, based on the intensity gradient.</p><p>To detect objects that are not well defined by gradient, Chan and Vese <ref type="bibr" coords="3,450.79,118.99,15.50,8.74" target="#b9">[10]</ref> for instance based the evolution of their active contour on the color consistency of the regions, by using a level set formulation. Another region-based approach, relying this time on texture information, was proposed by Unal, Yezzi and Krim <ref type="bibr" coords="3,465.09,154.86,15.50,8.74" target="#b10">[11]</ref> who also introduced a polygonal representation of the contour.</p><p>But to include some knowledge about complex objects, a deformable template <ref type="bibr" coords="3,158.91,190.72,15.50,8.74" target="#b11">[12]</ref> can be used, with the asset of lightening the representation and storage space of the contour by the use of parameters. Felzenszwalb <ref type="bibr" coords="3,388.39,202.68,15.50,8.74" target="#b12">[13]</ref> represents shapes by deformable triangulated polygons to detect precisely described objects, including maple leaves, and Cremers <ref type="bibr" coords="3,286.66,226.59,15.50,8.74" target="#b13">[14]</ref> includes shape priors into level set active contours to segment a known object, but both approaches lack the flexibility needed to include knowledge about the shape of any possible leaf. In our case, the similarity between the background and the object of interest, and the difficulty to avoid adjacent and overlapping leaves constitute a prohibitive obstacle to the use of unconstrained active contours (Figure <ref type="figure" coords="3,448.62,384.52,3.87,8.74" target="#fig_0">1</ref>). The idea of using a template to represent the leaves is complicated by the fact that there is much more variety in shapes than for eyes or mouths. The only solution to overcome the aforementioned problems is however to take advantage of the prior knowledge we may have on leaf shapes to design a very flexible time-efficient model to represent leaves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Parametric Polygonal Leaf Model</head><p>Even when considering trees only, leaves show an impressively wide variety in shapes. It is however necessary to come up with a representation of what a leaf is, that is accurate enough to be fitted to basically any kind of leaf. In a first time, we consider only simple leaves, including lobed and palmate ones, which covers already 90% of French broad-leaved tree species <ref type="bibr" coords="3,370.38,525.03,15.50,8.74" target="#b14">[15]</ref> and roughly the same proportion in all European species.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">A polygon to describe leaf shapes</head><p>The general shape of a leaf is a key component of the process of identifying a leaf. Botanists have a whole set of terms describing either the shape of a simple leaf, of the lobes of a palmate leaf, or of the leaflets of a compound leaf. Examples of such shapes are diplayed in Figure <ref type="figure" coords="3,306.46,608.30,3.87,8.74">3</ref>. The problem being that the borders between the different terms are not well defined, since leaves can naturally have non-canonical, intermediate shapes.</p><p>To sketch the shapes used in botany, we propose a light polygonal model based on a set of 4 parameters <ref type="bibr" coords="3,278.12,656.12,15.50,8.74" target="#b15">[16]</ref> The idea of defining a simple parametric model to represent all these various shapes has the double advantage of turning an imprecise, blurry and quite subjective classification into numerical parameter values, and producing in the same time some descriptors accounting for the general shape of the leaf.</p><p>The chosen model relies on two points, base B and tip T , that define the main symmetry axis of the leaf. From this axis, we construct the 10 points defining the polygon, as displayed in Figure <ref type="figure" coords="4,291.12,190.72,3.87,8.74" target="#fig_1">2</ref>, using 4 numeric integer parameters:</p><p>α B , the opening angle at the base α T , the opening angle at the tip w, the relative maximal width p, the relative position where this width is reached This model is then able to cover correctly, with a very concise set of parameters, almost every shape used in botany. Figure <ref type="figure" coords="4,349.96,357.85,4.98,8.74">3</ref> illustrates how, by changing manually the values of the parameters, it is possible to create shapes that visibly correspond to the different canonical shapes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 3. Main leaf shapes and their corresponding hand-tuned models</head><p>The case of palmately lobed leaves is slightly more complex, but our hypothesis is that a palmate leaf can be seen as a superposition of several identical simple leaf shapes, joining at the base of the leaf. This is justified by the descriptions that can be found in flora books, where palmate leaves are characterized by the shape of their lobes using the same previously mentioned terms.</p><p>Concretely, we model a palmate leaf by overlaying an odd number of simple polygonal models, symmetrically arranged in pairs, and varying only in length and angle: a main lobe whose axis is defined by the points B and T , and several symmetric pairs of secondary lobes, whose axes all radiate from the actual base of the main lobe, the point B B . Such representation implies the addition of a number of new parameters to make the construction represented in Figure <ref type="figure" coords="4,475.61,619.24,4.98,8.74">4</ref> possible. In addition to the 4 parameters determining the shape of the lobes, we have to introduce:</p><p>n L , the number of pairs of lobes (1 means simple, 2 means 3-lobed)</p><p>for each pair of lobes, L(l), the relative length of the two symmetric lobes for each pair of lobes, α(l), the angle of the lobes with the main axis</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 4. Construction of the palmately lobed leaf model</head><p>The idea is then to apply a deformable template approach on this model, using the variations of the different parameters as elementary deformations, to make it fit best the leaf in the image. This has the major advantage of encapsulating some prior knowledge on the shape of the object, in the very definition of the model. The final polygon we obtain can later be used as a shape prior for a refined segmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Color representation</head><p>A polygonal model inevitably being an approximation of the actual contour of the leaf, it is not relevant to base its evolution on the edge information, contained in the gradient. This is why we use only the color information to make the model fit the leaf in the image.</p><p>It is however impossible to come up with an a priori model for what the color of a leaf is, that would be accurate whatever the leaf, season and lighting. It is then absolutely necessary to estimate, for each new leaf we want to segment, the particular color model, which can only be performed with some rough idea of where the leaf lies in the image, implying constraints on its position. In the following, we assume that the leaf is roughly centered and vertically-oriented, so that an initialization of our template in the middle of the image contains almost only leaf pixels. Typically, a leaf in the image taken on purpose by a user will be large enough to ensure the correctness of the initialization.</p><p>We considered then that the color of a leaf can be modelled by a 2-component GMM estimated in the initial region, accounting for shaded and lighted or shiny areas, and defined by the parameters (µ 1 , σ 2  1 , α 1 ) and (µ 2 , σ 2 2 , α 2 ), respectively the mean, variance and weight of each gaussian distribution. Then the distance of a pixel x to the color model, in a 3-dimensional colorspace, is defined by a normalized 1-norm distance, written as following:</p><formula xml:id="formula_0" coords="5,217.46,571.06,263.13,30.32">d(x, µ 1,2 , σ 1 , µ 2 , σ 2 ) = min g=1,2 3 i=1 |x i -µ g,i | σ g,i<label>(1)</label></formula><p>Based on this formulation, we can compute for every pixel in the image its distance to the color model, resulting in a map that measures the dissimilarity of pixels to the leaf, and where leaf pixels should appear in black and background pixels in gray-white. Based on the aspect of this map for different leaves and different color spaces, we chose to work in the L*a*b* colorspace, for which leaves were standing out best in distance maps.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Parametric Active Polygon</head><p>With an iterative process similar to active contours, the initial model will undergo a series of deformations, whose goal is to minimize an energy functional based on the afore described leaf dissimilarity map. The internal energy term that traditionnally appears in the energy formulation can be considered as implicit here, as it is included in the construction rules of our model. The remaining external term is then expressed as:</p><formula xml:id="formula_1" coords="6,221.36,211.23,259.24,20.06">E(Ω) = x∈Ω (d(x, µ 1 , σ 1 , µ 2 , σ 2 ) -d max ) (2)</formula><p>The value d max actually represents a balloon force, that will push the model to grow as much as possible. It can also be seen as a threshold, the distance to the color model for which a pixel will be costly to add into the polygon. The expected outcome is to produce the biggest region with as little leaf-dissimilar pixels as possible.</p><p>At each step, all the possible elementary variations of the parameters and of the base and tip points are examined, and the one leading to the greatest decrease of the energy is applied, until no deformation can bring it any lower. As such, this method presents the risk of getting stuck in local energy minima, this is why a heuristic close to simulated annealing is used. It is also necessary to constrain the model, that is basically flexible enough to take shapes that are not likely to ever be reached by leaves. To achieve that, actual leaf shapes were learned, and at every moment, the model has to remain within a certain distance to one of these reference shapes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Collapsing lobes</head><p>The only parameter that has to be treated separately is the number of lobes n L . Considering it on the same level as the other parameters does not make much sense, given the drastic changes in shape a modification of its value would induce. A way to solve the problem could have been to estimate in a preliminary step the number of lobes, and have this parameter fixed for the evolution of the model. But such an estimation, that would ultimately require some equivalent of a segmentation to be accurate, would just seem like going round in circles.</p><p>The method we kept treats the number of lobes in the same optimization process that fits the model to the leaf, but in a different way. After the color model has been estimated on the simple polygonal initalization shown in Figure <ref type="figure" coords="6,475.61,632.21,4.98,8.74" target="#fig_2">5</ref> an excessive number of lobes is added to the model, typically resulting in a 11lobed leaf model. The deformable template algorithm runs then freely on all the parameters, except for the number of lobes. The expected result is that lobes will group together inside the actual lobes of the leaf. The key is then to eliminate the overlapping lobes until there remains only as many lobes as necessary.</p><p>This elimination step is performed between two temperature rises in the simulated annealing process. For each secondary pair of lobes, we evaluate an overlapping ratio with the previous one, expressed as:</p><formula xml:id="formula_2" coords="7,242.35,190.29,98.99,24.77">r(l) = w 2 .L(l -1) sin(θ) . 1 L(l)</formula><p>. cos(θ)</p><p>where θ = α(l) -α(l -1). Figure <ref type="figure" coords="7,291.98,224.90,4.98,8.74">6</ref> illustrates the origin of this formula where polygonal models are approximated by rectangles. This value can be seen as the ratio between the blue area (estimating the overlapped part of the considered lobe) and the whole lobe, weighed by a cosinus to favour more large angles between lobes. The actual result is the ratio between the lengths of the two red lines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 6. Estimating the overlapping ratio between two lobes</head><p>Lobes that have a overlapping ratio greater than a given threshold (typically, 70%) are eliminated. In addition, a second pass is performed to ensure that the remaining lobes have a plausible repartition, which could correspond to a leaf. If a lobe makes a naturally unlikely angle with its predecessor (typically, more than 60 degrees) it is suppressed too. The result is that the perceived number of lobes will emerge from the very process that approximates the leaf by a model (as in Figure <ref type="figure" coords="7,194.69,501.13,4.43,8.74">7</ref>) and this even for the case of simple leaves, where all the lobes should eventually collapse into one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 7. Sample result of lobe suppression, before suppression and after evolution</head><p>The resulting model gives a good clue of what the shape of the leaf is, but it is not enough to carry out species identification, and the first resulting contour has to be later enhanced to hug the boundary of the leaf.</p><p>As initially mentioned, unconstrained active contours applied to the complex natural images we aim at dealing with would produce unsatisfying contours, that would try and make their way through every possible gap and flaw in the border of the leaf. The solution we propose is to use the polygonal model obtained after the first step not only as an initial leaf contour but also as a shape prior that will guide its evolution towards the real leaf boundary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Energy formulation</head><p>We chose to use the active contour model defined by Kass et al. <ref type="bibr" coords="8,415.99,232.56,9.96,8.74" target="#b8">[9]</ref>, including a guiding constraint and using leaf dissimilarity, both under the form of additional terms in the energy functional the contour strives to minimize. The general energy term, for a contour Γ delineating a region Ω(Γ ), can be expressed as:</p><formula xml:id="formula_4" coords="8,134.77,285.59,345.83,20.69">E(Γ ) = αE Leaf (Γ )+βE Shape (Γ )+γE Gradient (Γ )+δE Smooth (Γ )-ωE Balloon (Γ )<label>(4</label></formula><p>) Instead of having an external energy term based on color consistency, or distance to a mean, we decided to reuse the dissimilarity map from the previous step, considering we have already an efficient measure of how well a pixel should fit in the leaf, in terms of color. The corresponding energy term is then based on the dissimilarity function d detailed in Section 3 and can be written as:</p><formula xml:id="formula_5" coords="8,223.21,373.44,168.95,11.70">E Leaf (Γ ) = Ω(Γ ) d(x, µ 1 , σ 1 , µ 2 , σ 2 )dx</formula><p>The guiding constraint term relies on a so-called stencil function K Shape increasing with the distance to the polygonal contour Π, which is explicited in 4.2. It guarantees that contour points that are distant from the polygon that will be pushed back towards it, when neither the color nor the gradient would be strong enough to retain it. It has then the following form:</p><formula xml:id="formula_6" coords="8,230.76,454.74,153.83,11.70">E Shape (Γ ) = Γ K Shape (Γ (s), Π)ds</formula><p>However this is obviously not enough, and the contribution of the gradient computed on the image I is here essential, as it may allow the contour to stick to the actual boundaries of the leaf (which is ultimately the main objective) even when the color information would not be relevant enough. The gradient energy is expressed in order to penalize curve points located on pixels with low gradient magnitude and is simply formulated as:</p><formula xml:id="formula_7" coords="8,232.00,546.75,151.35,11.70">E Gradient (Γ ) = Γ -∇I(Γ (s)) ds</formula><p>Although the final contour has to be precise, to capture points and teeth on the leaf margin essentially, some moderate smoothing is still necessary to prevent the contour from being too noisy. And finally the balloon energy is here to counterbalance and stabilize the other energies by adding a constant force towards the outside of the contour:</p><formula xml:id="formula_8" coords="8,183.86,624.92,247.63,13.58">E Smooth (Γ ) = Γ dΓ ds 2 ds E Balloon (Γ ) = Ω(Γ ) dx</formula><p>The final variation of E is determined using calculus of variations, and the resulting evolution equation is implemented on a parametric curve following <ref type="bibr" coords="8,462.32,656.12,14.61,8.74" target="#b16">[17]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Guided by a stencil</head><p>The function we use is asymmetric with respect to the polygonal contour Π, as shown in Figure <ref type="figure" coords="9,207.97,151.00,3.87,8.74" target="#fig_3">8</ref>. The reason is that, our basic energy already using a balloon force, we want the force pushing the contour to the polygon to be stronger on the outside of the polygon, where it has to compete with the balloon, than on the inside, where the two resulting forces will push towards the same direction. We also introduce a margin ∆ around the polygon where the contour should be free to evolve, i.e. where the shape energy is equal to 0. For a given pixel, located at a distance d from the polygonal contour, the cost function is then:</p><formula xml:id="formula_9" coords="9,179.68,240.75,96.68,15.53">k(d) = max(d -∆, 0</formula><p>) on the inside of the polygon max((d -∆) 2 , 0) on the outside of the polygon (5)</p><p>A small improvement to this basic formulation is a slight elongation of the polygonal contour at the base and the tip of the leaf before the evaluation of the distance, resulting in the two round black areas on the map of Figure <ref type="figure" coords="9,440.23,294.43,3.87,8.74" target="#fig_3">8</ref>. This is justified by the fact that the shape of the leaf in these areas is really discriminant, and the contour absolutely has to be able to reach such determinant parts of the leaf. Since the polygonal model is by definition not well suited to account for local particular shapes, the contour needs a larger freedom around those crucial points. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Ebb and flow</head><p>As such however, the various energies, though having all their role to play, are hard to harmonize into a coherent whole, efficient regardless of the image. Some of them may have conflicting interactions, the leaf dissimilarity term impeding for instance that the contour reaches the edge where the gradient term would make it stay. This is the reason why, rather than trying to find the optimal way of making those disparate forces cooperate smoothly, we decided to split the process into two phases where each will be able to express freely.</p><p>Starting from a contracted version of the polygon, to try to make sure that most of the points are located inside the leaf, the contour will undergo a first expansion step, where the coefficients of the balloon and gradient are preeminent, and the margin ∆ is rather tolerant. The contour should swell with no concern for the color, sometimes getting outside of the leaf, but constrained to be blocked when it crosses strong gradients or when it gets quite far from the reference polygon.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 9. Initial polygon, contour after expansion, and final contour after contraction</head><p>The second phase has for purpose to bring back the contour from non-leaf areas where it might have wandered, with at the same time hanging on to the strong edges and not going back inside the leaf even when the dissimilarity would claim so. The coefficient of the leaf dissimilarity energy is this time very high while the balloon is reduced and enough gradient preserved to stick to the boundary of the leaf. The distance map to the polygon is recomputed with a smaller ∆, again in this perspective of shrinking the contour to the leaf and no further. Those two steps and the final contour we obtain are illustrated in Figure <ref type="figure" coords="10,166.20,422.02,3.87,8.74">9</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Geometric Features and Classification</head><p>Our purpose is then to classify new leaf images into one of the 50 species of non-compound-leaved trees of the ImageCLEF Plant Images Classification task database <ref type="bibr" coords="10,169.54,486.84,17.39,8.74" target="#b17">[18]</ref>. We made the choice of basing our classification on explicit morphological descriptors inspired by those used by botanists. These geometric criteria are those used to build the determination keys that have proved some skills when it comes to helping with species identification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Global shape features</head><p>As stated earlier, the global shape of a leaf is one of the most relevant characteristics for its identification, even if it has to be completed by local details. We already presented a way of dealing with global shape features, by means of the parametric polygonal described in 3.1. As a matter of fact, the parameters resulting from the final evolution of polygon can directly be used as descriptors accounting for the global shape of the leaf, since it is actually the very purpose they were designed for.</p><p>Among them, we chose to keep only those who appeared to be the most discriminating ones: the four simple shape parameters w, p, α B and α T , and the two lobe parameters for the first pair of secondary lobes L(1) and α(1), these two being respectively set to 100 and 0 when the number of lobes is 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Contour characterization</head><p>The margin of the leaf is also a very important feature to spot. Its shape can be determining when trying to discriminate two species that have more or less the same global shape. It may consist of teeth of various sizes and frequencies, regularly arranged or not, from large spiny points, to small regular saw-like teeth, or even to a smooth entire border.</p><p>In order to cover these numerous possibilities, we based our contour descriptors by a measure of the curvature, using the osculating circle method <ref type="bibr" coords="11,452.36,246.52,16.13,8.74" target="#b18">[19,</ref><ref type="bibr" coords="11,468.49,246.52,12.10,8.74" target="#b19">20]</ref> estimated at 1, 3, 5, and 10 points, for each point of the contour. Then we simply computed the means and variances of the resulting vectors, and used those 8 values to characterize how large and how regular the teeth of the margin are.</p><p>There is however a lot more to do to measure this crucial feature accurately, and if the descriptors we use are visibly performing satisfyingly, they are still very correlated, and do not account efficiently for the regularity of the teeth, or for doubly serrated leaves. Such basic measures also fail in representing the local shape at the base and the tip of the leaf, which are both essential elements for species identification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Normalized classification</head><p>The learning base was built by extracting the aforementioned descriptors on 2101 white-background images of non-compound leaves of the ImageCLEF training database. Once computed, the base was normalized by adjusting all the values for each parameter, in order that their mean becomes 0 and their variance 1. Then for the k-th species among the 50 we treat, the specific mean and variance of each parameter are computed resulting in a model Φ k = (µ k , σ k ) representing the species.</p><p>For a new image, the parameters extracted during and after the segmentation form a feature vector φ that has to be compared with every of the 50 species models. For each one of them we compute a normalized Euclidean distance in the parameters space, with the only particularity that the features are weighted differently, by a constant coefficient denoted by w i for the i-th feature. The formulation of the distance is then:</p><formula xml:id="formula_10" coords="11,291.26,547.15,133.15,15.67">d(φ, Φ k ) = i w i (φ(i)-µ k (i)) 2 σ k (i) 2</formula><p>The species corresponding to the model Φ * achieving the smallest distance is the one that is picked if we have to give one single answer. But when multiple answers are possible, we associate them with a confidence score, measuring how probable the species are. The only species that are to be displayed in a final list are the ones with a confidence score not equal to zero. If we designate by Φ * * the model corresponding to the second best distance, our recipe of a confidence measure is given by: C</p><formula xml:id="formula_11" coords="11,231.33,636.15,165.86,14.38">(φ, Φ k ) = max 1 - d(φ,Φ k ) d(φ,Φ * )+d(φ,Φ * * ) , 0</formula><p>Our final classification result presents a list of species, in decreasing order with respect to the confidence we allow to each species.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Segmentation results</head><p>To measure the accuracy of our segmentation process, we compare the binary mask representing the final contour with a hand-made binary segmentation of the same image. Segmentations were hand-performed on more than 200 photographs of the ImageCLEF Database <ref type="bibr" coords="12,294.81,190.15,18.03,8.74" target="#b17">[18]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Scan and pseudoscan images</head><p>As said previously, the training of our classifier was performed on these easier plain-background images. We used cross-validation during the learning base, by using 30% of the base as a testing base to get a reliable performance measure. Our typical classification scores for scan and pseudoscan images over 50 classes lie around 70% on the training base and 67% on the testing base, with respectively 97% and 94% of presence of the real class in the 5 first answers.</p><p>On the plant identification task proposed for ImageCLEF 2011 <ref type="bibr" coords="12,445.41,578.98,15.50,8.74" target="#b17">[18]</ref> our method achieved a classification score of 53.8 ± 0.8% on scan images and 52.6 ± 1.8% on scan-like images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Natural background images</head><p>When using the same classifier for the photograph images of the training base, that contained only 26 of the 50 species, we reach only a score of 29%, with the good answer being in the top 5 species in 63% of cases. This can of course be explained by the fact that returning one of 50 possible classes when there are actually only 26 increases the risk of making bad choices.</p><p>There is also the fact that we use the plain-background images as our reference, considering that the contours we obtained on these easier cases would be more trustworthy. However, by making this choice, we prevent our system from learning the defaults it may have on more complicated images, and consequently adapting to them, making it extremely less robust to the noisy, sometimes inaccurate contours obtained on such difficult pictures.</p><p>On the ImageCLEF pland identification task, we performed a score of 18.7 ± 6.4 % on such natural scene photographs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Perspectives</head><p>We have presented a method designed to perform the segmentation of a leaf in a natural scene, based on the optimization of a polygonal leaf model used as a shape prior for an exact active contour segmentation. It also provides a set of global geometric descriptors that, later combined with local curvature-based fatures extracted on the final contour, make the classification into tree species possible.</p><p>The segmentation process is based on a color model that is robust to uncontrolled lighting conditions. But a global color model for a whole image may sometimes not be enough, for leaves that are not well defined by color only. The use of an additional texture model, or of an adaptive color model could lead to a good improvement.</p><p>There is also a need for better local contour descriptors, always keeping in mind what years of botany have found to be the most discriminative places to look at. These descriptors would also have to be more robust to the change from white-background images to real natural scenes, or to little flaws in the contour natural objects inevitably carry.</p><p>Nevertheless, it constitutes already a promising way of dealing with images of leaves in a complex background, giving promising results in terms of segmentation correctness, and proposing interesting descriptors relying on the criteria used by botanists to discriminate leaves.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,140.76,340.17,333.85,8.77;3,180.12,267.70,255.05,57.39"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Segmentation issues with unconstrained region-based active contours</figDesc><graphic coords="3,180.12,267.70,255.05,57.39" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,201.83,328.76,211.69,8.77;4,180.12,251.11,255.12,62.56"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Building the simple leaf model in 4 steps</figDesc><graphic coords="4,180.12,251.11,255.12,62.56" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,134.77,480.53,345.83,8.77;6,165.95,407.70,283.47,57.74"><head>Fig. 5 .</head><label>5</label><figDesc>Fig. 5. Initialization, distance map and resulting polygon on two natural images</figDesc><graphic coords="6,165.95,407.70,283.47,57.74" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="9,145.40,472.25,324.55,8.77;9,180.12,385.68,255.12,71.49"><head>Fig. 8 .</head><label>8</label><figDesc>Fig. 8. Polygonal model, modified polygon, cost function, and stencil map</figDesc><graphic coords="9,180.12,385.68,255.12,71.49" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="12,134.77,375.32,345.82,8.77;12,134.77,387.31,29.34,8.74;12,149.71,406.21,330.88,8.74;12,134.77,418.16,345.82,8.74;12,134.77,430.12,345.83,8.74;12,134.77,442.07,345.82,8.74;12,134.77,454.03,345.83,8.74;12,134.77,465.98,312.08,8.74;12,222.64,241.24,170.08,119.00"><head>Fig. 10 .</head><label>10</label><figDesc>Fig. 10. Overlap curves for the polygonal model (dotted) and the final contour (plain) Figure 10 displays the results for 226 segmentations, showing for each overlapping factor value the percentage of images in the database for which this score is reached. Both the polygonal model (dotted line) and the active contour result (plain line) are presented. The results show a mean overlap of 80,3% for the polygonal model and 85,8% for the final contour, with an overlapping score of 80% being reached for more than 78% of the images in the database.</figDesc><graphic coords="12,222.64,241.24,170.08,119.00" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to thank <rs type="person">Hung Duong Viet</rs> for the work on leaf segmentation he performed during his Master internship.</p></div>
			</div>
			<div type="funding">
<div><p>This work has been supported by the <rs type="funder">French National Agency for Research</rs> with the reference <rs type="grantNumber">ANR-10-CORD-005</rs> (<rs type="projectName">REVES</rs> project).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_g8Cq8gj">
					<idno type="grant-number">ANR-10-CORD-005</idno>
					<orgName type="project" subtype="full">REVES</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="13,142.96,624.18,337.64,7.86;13,151.52,635.13,250.38,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,278.89,624.18,182.38,7.86">Delving into the whorl of flower segmentation</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Nilsback</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,151.52,635.13,138.60,7.86">British Machine Vision Conference</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="570" to="579" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,645.84,337.64,7.86;13,151.52,656.77,204.77,7.89" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,249.78,645.84,170.52,7.86">Automatic recognition of blooming flowers</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Saitoh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Kaneko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,428.35,645.84,52.24,7.86;13,151.52,656.80,141.62,7.86">International Conference on Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="27" to="30" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,119.67,337.64,7.86;14,151.52,130.63,329.07,7.86;14,151.52,141.59,131.08,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="14,315.22,119.67,161.58,7.86">Leaf image retrieval with shape features</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Chi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,166.83,130.63,166.62,7.86">Advances in Visual Information Systems</title>
		<imprint>
			<biblScope unit="page" from="41" to="52" />
			<date type="published" when="1929">1929. 2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,152.55,337.63,7.86;14,151.52,163.51,329.07,7.86;14,151.52,174.44,79.91,7.89" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="14,392.44,152.55,88.15,7.86;14,151.52,163.51,162.17,7.86">Classification of plant leaf images with complicated background</title>
		<author>
			<persName coords=""><forename type="first">X</forename><forename type="middle">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">X</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Huan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Heutte</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,321.38,163.51,159.22,7.86">Applied Mathematics and Computation</title>
		<imprint>
			<biblScope unit="volume">205</biblScope>
			<biblScope unit="page" from="916" to="926" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,185.43,337.63,7.86;14,151.52,196.39,329.07,7.86;14,151.52,207.34,329.07,7.86;14,151.52,218.30,100.16,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="14,358.48,196.39,122.11,7.86;14,151.52,207.34,200.76,7.86">Searching the world&apos;s herbaria: A system for visual identication of plant species</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Belhumeur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Feiner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kress</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ramamoorthi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sheorey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,379.13,207.34,101.46,7.86;14,151.52,218.30,67.50,7.86">European Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,229.26,337.63,7.86;14,151.52,240.20,325.68,7.89" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="14,268.69,229.26,211.91,7.86;14,151.52,240.22,78.21,7.86">Matching shapes with self-intersections: Application to leaf classification</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Mokhtarian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Abbasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,237.37,240.22,162.02,7.86">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="653" to="661" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,251.18,337.64,7.86;14,151.52,262.14,329.07,7.86;14,151.52,273.10,329.07,7.86;14,151.52,284.06,60.92,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="14,298.63,251.18,181.96,7.86;14,151.52,262.14,261.03,7.86">Leaf segmentation, its 3d position estimation and leaf classification from a few images with very close viewpoints</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>Teng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">T</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">S</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,432.52,262.14,48.07,7.86;14,151.52,273.10,329.07,7.86">Proceedings of the 6th International Conference on Image Analysis and Recognition. ICIAR &apos;09</title>
		<meeting>the 6th International Conference on Image Analysis and Recognition. ICIAR &apos;09</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="937" to="946" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,295.02,337.63,7.86;14,151.52,305.95,329.07,7.89;14,151.52,316.93,32.25,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="14,360.66,295.02,119.93,7.86;14,151.52,305.98,98.66,7.86">Weed leaf image segmentation by deformable templates</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G</forename><surname>Manh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rabatel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Assemat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Aldon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,260.05,305.98,177.09,7.86">Journal of agricultural engineering research</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="page" from="139" to="146" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.96,327.89,337.63,7.86;14,151.52,338.83,211.33,7.89" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="14,315.58,327.89,122.88,7.86">Snakes: Active contour models</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Witkin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Terzopoulos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,448.32,327.89,32.27,7.86;14,151.52,338.85,138.96,7.86">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="321" to="331" />
			<date type="published" when="1988">1988</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,349.81,337.98,7.86;14,151.52,360.74,120.29,7.89" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="14,233.44,349.81,121.21,7.86">Active contours without edges</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Vese</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,363.44,349.81,117.15,7.86;14,151.52,360.77,42.49,7.86">IEEE Transactions on Image Processing</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="266" to="277" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,371.73,337.98,7.86;14,151.52,382.66,329.07,7.89;14,151.52,393.65,32.25,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="14,276.85,371.73,203.75,7.86;14,151.52,382.69,107.34,7.86">Information-theoretic active polygons for unsupervised texture segmentation</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Unal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Yezzi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Krim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,268.17,382.69,169.44,7.86">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="page" from="199" to="220" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.62,404.61,337.98,7.86;14,151.52,415.54,281.54,7.89" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="14,293.12,404.61,187.48,7.86;14,151.52,415.56,37.38,7.86">Feature extraction from faces using deformable templates</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Yuille</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Hallinan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,197.13,415.56,168.18,7.86">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="99" to="111" />
			<date type="published" when="1992">1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,426.50,337.98,7.89;14,151.52,437.48,60.92,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="14,225.63,426.52,206.74,7.86">Representation and detection of deformable shapes</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Felzenszwalb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,442.19,426.52,24.19,7.86">PAMI</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="208" to="220" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,448.44,337.98,7.86;14,151.52,459.40,329.07,7.86;14,151.52,470.33,193.09,7.89" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="14,374.50,448.44,106.09,7.86;14,151.52,459.40,266.91,7.86">Diffusion snakes: introducing statistical shape knowledge into the mumford-shah functional</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Cremers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Tischhäuser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Weickert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schnörr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,428.35,459.40,52.24,7.86;14,151.52,470.36,115.41,7.86">International Journal Of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="295" to="313" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,481.32,337.98,7.86;14,151.52,492.28,77.37,7.86" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="14,198.12,481.32,282.47,7.86;14,151.52,492.28,43.72,7.86">Flore descriptive et illustrée de la France de la Corse et des contrées limitrophes</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Coste</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1906">1906</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,503.24,337.98,7.86;14,151.52,514.19,329.07,7.86;14,151.52,525.15,104.75,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="14,364.12,503.24,116.47,7.86;14,151.52,514.19,173.40,7.86">A parametric active polygon for leaf segmentation and shape estimation</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Cerutti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Tougne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vacavant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Coquin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,348.46,514.19,132.13,7.86;14,151.52,525.15,71.31,7.86">7th International Symposium on Visual Computing</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,536.11,337.98,7.86;14,151.52,547.04,319.32,7.89" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="14,193.92,536.11,286.67,7.86;14,151.52,547.07,51.33,7.86">Narrow band region-based active contours and surfaces for 2d and 3d segmentation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Mille</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,211.21,547.07,176.52,7.86">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="946" to="965" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,558.03,337.98,7.86;14,151.52,568.99,329.07,7.86;14,151.52,579.95,25.60,7.86" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="14,298.55,568.99,178.20,7.86">The clef 2011 plant images classification task</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Barthelemy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Birnbaum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Mouysset</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Picard</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,590.91,337.98,7.86;14,151.52,601.84,329.07,7.89;14,151.52,612.82,32.25,7.86" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="14,319.59,590.91,161.00,7.86;14,151.52,601.87,199.47,7.86">A framework for dynamic implicit curve approximation by an irregular discrete approach</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vacavant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Coeurjolly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Tougne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,363.18,601.87,72.56,7.86">Graphical Models</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="113" to="124" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,623.78,337.98,7.86;14,151.52,634.74,329.07,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="14,259.33,623.78,199.65,7.86">A comparative study on 2d curvature estimators</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Hermann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Klette</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,151.52,634.74,262.02,7.86">International Conference on Computing: Theory and Applications</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="584" to="589" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
