<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,141.49,115.90,332.39,12.90;1,164.82,133.83,285.72,12.90;1,256.72,151.77,101.92,12.90">The joint submission of the TU Berlin and Fraunhofer FIRST (TUBFI) to the ImageCLEF2011 Photo Annotation Task</title>
				<funder ref="#_vFt8sqw">
					<orgName type="full">Federal Ministry of Economics and Technology of Germany (BMWi)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,158.94,190.31,70.95,8.64"><forename type="first">Alexander</forename><surname>Binder</surname></persName>
							<email>alexander.binder@tu-berlin.de@wojciech.samek.tu-berlin.de</email>
							<affiliation key="aff0">
								<orgName type="department">Machine Learning Group</orgName>
								<orgName type="institution">Berlin Institute of Technology (TU Berlin)</orgName>
								<address>
									<addrLine>Franklinstr. 28/29</addrLine>
									<postCode>10587</postCode>
									<settlement>Berlin</settlement>
									<country>Germany, www</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,239.34,190.31,66.99,8.64"><forename type="first">Wojciech</forename><surname>Samek</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Machine Learning Group</orgName>
								<orgName type="institution">Berlin Institute of Technology (TU Berlin)</orgName>
								<address>
									<addrLine>Franklinstr. 28/29</addrLine>
									<postCode>10587</postCode>
									<settlement>Berlin</settlement>
									<country>Germany, www</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Fraunhofer Institute FIRST</orgName>
								<address>
									<addrLine>Kekuléstr. 7</addrLine>
									<postCode>12489</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,322.12,190.31,51.75,8.64"><forename type="first">Marius</forename><surname>Kloft</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Machine Learning Group</orgName>
								<orgName type="institution">Berlin Institute of Technology (TU Berlin)</orgName>
								<address>
									<addrLine>Franklinstr. 28/29</addrLine>
									<postCode>10587</postCode>
									<settlement>Berlin</settlement>
									<country>Germany, www</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,383.32,190.31,66.14,8.64"><forename type="first">Christina</forename><surname>Müller</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Machine Learning Group</orgName>
								<orgName type="institution">Berlin Institute of Technology (TU Berlin)</orgName>
								<address>
									<addrLine>Franklinstr. 28/29</addrLine>
									<postCode>10587</postCode>
									<settlement>Berlin</settlement>
									<country>Germany, www</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,208.44,202.26,83.29,8.64"><forename type="first">Klaus-Robert</forename><surname>Müller</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Machine Learning Group</orgName>
								<orgName type="institution">Berlin Institute of Technology (TU Berlin)</orgName>
								<address>
									<addrLine>Franklinstr. 28/29</addrLine>
									<postCode>10587</postCode>
									<settlement>Berlin</settlement>
									<country>Germany, www</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,318.06,202.26,78.05,8.64"><forename type="first">Motoaki</forename><surname>Kawanabe</surname></persName>
							<email>motoaki.kawanabe@first.fraunhofer.de</email>
							<affiliation key="aff0">
								<orgName type="department">Machine Learning Group</orgName>
								<orgName type="institution">Berlin Institute of Technology (TU Berlin)</orgName>
								<address>
									<addrLine>Franklinstr. 28/29</addrLine>
									<postCode>10587</postCode>
									<settlement>Berlin</settlement>
									<country>Germany, www</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Fraunhofer Institute FIRST</orgName>
								<address>
									<addrLine>Kekuléstr. 7</addrLine>
									<postCode>12489</postCode>
									<settlement>Berlin</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,141.49,115.90,332.39,12.90;1,164.82,133.83,285.72,12.90;1,256.72,151.77,101.92,12.90">The joint submission of the TU Berlin and Fraunhofer FIRST (TUBFI) to the ImageCLEF2011 Photo Annotation Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">68B28385D357AF5021437087997F4CEF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>ImageCLEF</term>
					<term>Photo Annotation</term>
					<term>Image Classification</term>
					<term>Bag-of-Words</term>
					<term>Multi-Task Learning</term>
					<term>Multiple Kernel Learning</term>
					<term>THESEUS</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we present details on the joint submission of TU Berlin and Fraunhofer FIRST to the ImageCLEF 2011 Photo Annotation Task. We sought to experiment with extensions of Bag-of-Words (BoW) models at several levels and to apply several kernel-based learning methods recently developed in our group. For classifier training we used non-sparse multiple kernel learning (MKL) and an efficient multi-task learning (MTL) heuristic based on MKL over kernels from classifier outputs. For the multi-modal fusion we used a smoothing method on tag-based features inspired by Bag-of-Words soft mappings and Markov random walks. We submitted one multi-modal run extended by the user tags and four purely visual runs based on Bag-of-Words models. Our best visual result which used the MTL method was ranked first according to mean average precision (MAP) within the purely visual submissions. Our multi-modal submission achieved the first rank by MAP among the multi-modal submissions and the best MAP among all submissions. Submissions by other groups such as BPACAD, CAEN, UvA-ISIS, LIRIS were ranked closely.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Our goals were to experiment with extensions of Bag-of-Words (BoW) models at several levels and to combine them with several kernel-based learning methods recently developed in our group while working within the THESEUS project. For this purpose we generated a submission to the annotation task of the ImageCLEF2011 Photo Annotation Challenge <ref type="bibr" coords="1,213.13,608.62,15.27,8.64" target="#b13">[14]</ref>. This task required the annotation of 10000 images in the provided test corpus according to the 99 pre-defined categories. Note that this year's Im-ageCLEF Photo-based task provides additionally another challenging competition <ref type="bibr" coords="1,461.50,632.53,15.27,8.64" target="#b13">[14]</ref>, a concept-based retrieval task. In the following we will focus on the firstly mentioned annotation task over the 10000 images. The ImageCLEF photo corpus is challenging due to its heterogeneity of classes. It contains classes based on concrete tangible objects such as female, cat and vehicle as well as more abstractly defined classes such as technical, boring or Esthetic Impression. As a result our visual submission and our multi-modal submission achieved both first ranks by MAP measure among the purely visual and multi-modal submissions, respectively. We will describe our methods in a concise manner here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Bag-of-Words Features</head><p>All our submissions were based on discriminatively trained classifiers over kernels using BoW features. The BoW feature pipeline can be decomposed into the following steps: generating sampling regions, computing local features, mapping local features onto visual words. The coarse layout of our approach is influenced by the works of the Xerox group on Bag-of-Words in Computer Vision <ref type="bibr" coords="2,345.00,417.11,10.58,8.64" target="#b2">[3]</ref>, the challenge submissions by INRIA groups <ref type="bibr" coords="2,196.46,429.06,16.60,8.64" target="#b10">[11]</ref> and the works on color descriptors by the University of Amsterdam <ref type="bibr" coords="2,154.68,441.02,15.27,8.64" target="#b16">[17]</ref>. For that reason we computed for each set of parameters three BoW features based on regular spatial tilings 1 × 1, 2 × 2, 3 × 1 (vertical × horizontal). Preliminary experiments with an additional spatial tiling 3 × 3 showed merely minor performance gains. Furthermore we used vectors of quantile estimators along the established SIFT feature <ref type="bibr" coords="2,165.60,488.84,16.60,8.64" target="#b9">[10]</ref> as local feature. Table <ref type="table" coords="2,277.78,488.84,4.98,8.64" target="#tab_0">1</ref> shows the computed BoW features. Information about the sampling method is given in Section 2.1. We used color channel combinations red-green-blue (RGB), grey (Gr), grey-opponentcolor1-opponentcolor2 (Opp in Table <ref type="table" coords="2,134.77,524.71,4.15,8.64" target="#tab_0">1</ref>) and a grey-value normalized version of the last combination (N-Opp in Table <ref type="table" coords="2,452.06,524.71,3.60,8.64" target="#tab_0">1</ref>). The total number of kernels is large however their computation is a fairly automatized task which requires little human intervention.</p><p>In this years submission, we incorporated the following new extensions described in Sections 2.1 and 2.2 into our BoW modeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Extensions on Sampling level</head><p>In addition to BoW features created from known grid sampling we tried biased random sampling <ref type="bibr" coords="2,173.79,632.53,15.27,8.64" target="#b20">[21]</ref>. In contrast to <ref type="bibr" coords="2,250.41,632.53,16.60,8.64" target="#b20">[21]</ref> we resorted to probability maps computed from edge detectors. Such sampling approaches offer two potential advantages over Harris Laplace detectors: Firstly, we get keypoints located on edges rather than corners. A motivating example can be seen in Figure <ref type="figure" coords="3,262.23,119.31,4.98,8.64" target="#fig_0">1</ref> -the bridge contains corner points but the essential structures are lines. Similar examples are smooth borders of buildings, borders between mountains and sky, or simply a circular structure. Secondly, we did adjust the number of local features to be extracted per image as a function of the image size instead of using the typical corner detection thresholds. The reference is the number of local features extracted by grid sampling, in our case 6 pixels. This comes from the idea that some images can be more smooth in general. Furthermore <ref type="bibr" coords="3,173.52,530.77,16.60,8.64" target="#b12">[13]</ref> showed that too sparse sampling of local features leads to reduced classification performance. The opposite extreme end of this is documented in <ref type="bibr" coords="3,436.81,542.73,16.60,8.64" target="#b17">[18]</ref> where quite large improvements using sampling each pixel are reported. As a consequence we can tune the trade-off between computational cost and performance compared to the dense sampling baseline. In practice we chose to extract approximately one half as much local features using biased random sampling. We tried four detectors:</p><p>-bias3 was a simplified version of an attention based detector <ref type="bibr" coords="3,395.65,608.62,10.58,8.64" target="#b6">[7]</ref>. However this detector requires to set scale parameters. The highly varying scales of motifs in the images makes it difficult to find a globally optimal set of scales without expensive optimizations. This inspired us to try detectors which depend less on scale parameters:</p><p>-bias1 computes an average of gradient responses over pixel-wise images of the following color channels: grey, red minus green, green minus blue and blue minus red. -bias2 is like bias1 except for dropping the grey channel. Thus it will fail on grey images but detects strong local color variations. On the other hand such differences between RGB color channels are more prominent on bright regions. This allows to use features over normalized color channels more safely on color images. -bias4 takes the same set of color channels as the underlying SIFT descriptor and computes the entropy of the gradient orientation histogram on the same scale as the SIFT descriptor. Regions with low entropy are preferred in the probability map used for biased random sampling. This detector is adapted closely to the SIFT feature. The question behind this detector is whether the focus on peaky low entropy histograms constitutes an advantage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Extensions on Bag-of-Words Mapping Level</head><p>As we used k-means for generating a set of visual words, the usual approach to generate soft BoW mappings <ref type="bibr" coords="4,218.67,318.14,11.62,8.64" target="#b4">[5]</ref> which is adapted to radius-based clustering and relies on one global width parameter may become inappropriate when the density of clusters varies strongly in the space of local features. K-means results in clusters of varying size depending on the local density of the local features. To resolve this issue we resorted to rank-based BoW mapping where the vote of a local feature is the 2.4-based power of the negative rank. Be RK d (l) the rank of the distances between the local feature l and the visual word corresponding to BoW dimension d, sorted in increasing order. Then the BoW mapping m d for dimension d is defined as:</p><formula xml:id="formula_0" coords="4,226.21,420.49,250.51,24.88">m d (l) = 2.4 -RK d (l) if RK d (l) ≤ 8 0 else. (<label>1</label></formula><formula xml:id="formula_1" coords="4,476.72,429.18,3.87,8.64">)</formula><p>Initially we performed experiments with several alternative soft mappings. Shortly summarized, these experiments revealed that it is necessary to achieve a sufficiently fast decay of soft mapping weights as a function of the distance of a local feature to distant visual words in order to achieve a better performance than simple hard mapping.</p><p>Our second attempt after using the mapping from <ref type="bibr" coords="4,360.54,504.00,11.62,8.64" target="#b4">[5]</ref> was to introduce a cutoff constant K. Only distances below rank K + 1 are considered. Be V a visual vocabulary, and w d the visual word from it corresponding to BoW feature dimension d, l a local feature. Then the cut-off mapping is given by:</p><formula xml:id="formula_2" coords="4,147.42,556.73,333.17,29.71">m d (l) = exp(-σw d dist(l,w d )) P v∈V|Rank(dist(l,v))≤K exp(-σvdist(l,v)) if Rank(dist(l, w d )) ≤ K 0 otherwise<label>(2)</label></formula><p>where the width parameter σ was estimated for each visual word locally as the inverse of quantile estimators of distances to all local features from an image which had w d as the nearest visual word. This experiment led to the conclusion that quantiles leading to large values for σ and thus fast decay of weights yielded better performances.</p><p>Note that the rank-based voting ensures exponential drop-off per se.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Kernels</head><p>We used χ 2 -Kernels. The width was set to be the mean of the inner distances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Used Resources</head><p>For feature and kernel computations we resorted to a cluster with 40 mostly AMD Opterons 275 Core Units with up to 2.4 GHz which had according to cpubenchmark.net a speed rank of 134 in August 2011. The OS was a 32bit which limited usable memory resources during feature computation, in particular during visual word generation to 3 GByte.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Heuristically down-scaled non-sparse Multiple Kernel Learning</head><p>Due to limited resources on a 64 bit cluster which we employed for classifier training we decided to try out a down-scaled version of MKL based on 25 kernels which are the averages of the 75 kernels over the spatial tilings. Instead of evaluating many pairs of sparsity parameters and regularization constants the idea was to run non-sparse MKL <ref type="bibr" coords="5,160.87,346.99,11.62,8.64" target="#b8">[9]</ref> once for each class for merely one sparsity parameter tuned towards low kernel weight regularization (p = 1.2) and one choice of the regularization constant tuned towards high SVM regularization (C = 0.1). The obtained kernel weights can be used afterwards in SVMs with fixed-weighted kernels and several weaker SVM regularizations and powers applied to the kernel weights simulating higher sparsity. This consumes substantially less memory and allows in practice to use more cores in parallel. For each class one can choose via cross-validation the optimal regularization and power on the initially obtained MKL weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Output Kernel based MKL/MTL</head><p>By considering the set of semantic concepts in the ImageCLEF Photo one can expect weak relations between many of them. Some of them can be established deterministically such as season labels like Spring necessarily require the photo to be an outdoor shot. Others might be present in a statistical sense: photos showing Park Garden tend to be rather calm instead of active, however the latter is possible. The extent of activity might depend on the dataset. The total number of concepts is however prohibitive for manual modeling of all relations. One principled approach for exploiting such relations is multi-task learning <ref type="bibr" coords="5,255.95,572.75,10.79,8.64" target="#b3">[4,</ref><ref type="bibr" coords="5,268.40,572.75,13.28,8.64" target="#b18">19]</ref> which attempts to transfer information between concepts. Classical Multi-Task Learning (MTL) has two shortcomings: firstly, it often scales poorly with the number of concepts and samples. Secondly, kernel-based MTL leads to symmetric solutions, which implies that poorly recognized concepts can spoil classification rates of better performing classes. The work in <ref type="bibr" coords="5,373.08,620.57,16.60,8.64" target="#b15">[16]</ref> tackles both problems. It formulates a decomposable approximation which can be solved as a set of separate MKL problems. Thus it shares the scalability limits of MKL approaches. Secondly, the formulation as an approximation permits asymmetric information transfer between classes. The approach uses kernels computed from SVM predictions for the information transfer. We picked 12 concepts under the constraints to use general concepts and to have rather high MAP values under cross-validation for the kernels (animals, food, no persons, outdoor, indoor, building sights, landscape nature, single person, sky, water, sea, trees) and combined them with the average kernel which has been used in the TUBFI 1 submission as inputs for the non-sparse MKL algorithm resulting in 13 kernels. Here we applied as a consequence of lack of computation time the same downscaled MKL strategy as for the BoW kernels alone described in Section 3 with MKL regularization parameter p = 1.125 and SVM regularization constant C = 0.75, however without applying sparsifying powers on the kernel weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Smoothing textual Bag-of-Words</head><p>In the field of image classification it is known that soft mappings improve the performance of BoW features substantially <ref type="bibr" coords="6,289.43,297.89,10.79,8.64" target="#b4">[5,</ref><ref type="bibr" coords="6,301.89,297.89,11.83,8.64" target="#b19">20]</ref>. The soft mapping relies on a notion of distance between the local features. Similar approaches have been also used for Fisher vectors <ref type="bibr" coords="6,166.18,321.80,15.77,8.64" target="#b11">[12,</ref><ref type="bibr" coords="6,183.61,321.80,13.28,8.64" target="#b14">15]</ref> where the non-sparsity of features does not require a distance. For tag based BoW features one can derive analogously a notion of similarity without resorting to external sources via co-occurrence. We applied for our multi-modal submission TUBFI 3 the method from <ref type="bibr" coords="6,248.61,357.66,11.62,8.64" target="#b7">[8]</ref> which uses derived similarity to achieve a soft mapping for textual bags of words. The set of visual words has been selected by choosing the 0.2% most frequent tags as in <ref type="bibr" coords="6,273.76,381.57,10.58,8.64" target="#b5">[6]</ref>. Experiments on the cross-validated training set confirmed performance improvements using smoothed tags over unsmoothed tags.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>For the detailed results of all submissions we refer to the overview given in <ref type="bibr" coords="6,450.79,452.55,15.27,8.64" target="#b13">[14]</ref>. A small excerpt can be seen in Table <ref type="table" coords="6,273.53,464.51,3.74,8.64" target="#tab_1">2</ref>. While optimization of complex measures, particularly hierarchically representable ones is feasible <ref type="bibr" coords="6,198.77,488.74,11.62,8.64" target="#b0">[1]</ref> we did not do any optimization for the example-based measures as we were not fully aware of their structure. In particular, each classifier had a different threshold due to a simple linear mapping of minimal and maximal outputs onto boundaries of the required interval [0, 1] which leaves the targeted MAP values unchanged. This across-concept variation in the classifier threshold explains the limited results for the example-based measures.</p><p>Considering the targeted MAP score, we can see in Table <ref type="table" coords="6,389.99,560.80,4.98,8.64" target="#tab_1">2</ref> that the pure textual runs perform worst although one can expect them to be very efficient in terms of time consumption versus ranking performance difference to visual ones. Multi-modal approaches perform best with a considerable margin of 0.06 MAP (16% over TUBFI 1 baseline) over visual ones which indicates that the information in tags and images is fairly non-redundant. The improvement over pure textual runs is substantial. When considered as an absolute number, an MAP of 44 shows much space for improvements. When looking at AUC values which allow better comparison between concepts, only 31 out of 99 classes had AUC values above 0.9 in our best submission. The first purely visual submission (TUBFI 1 in Table <ref type="table" coords="7,354.80,344.12,4.15,8.64" target="#tab_1">2</ref>) was an average kernel SVM over all sets but the second BoW feature set from Table <ref type="table" coords="7,360.08,356.07,3.74,8.64" target="#tab_0">1</ref>. Its performance was almost identical to the best submission of the CAEN group which, however, used a completely different methodology, namely Fisher-Kernels. For all other submissions we selected for each class separately the best classifier from a set of classifiers by MAP values obtained on 12-fold cross-validation on the training data. The idea was to counter the heterogeneity of concept classes in the ImageCLEF data by a bag of methods. However, this mixture does not allow to judge the impact of the separate methods precisely. Table <ref type="table" coords="7,134.77,439.76,4.98,8.64" target="#tab_2">3</ref> shows for each submission applied the number of classes using particular method. Selection was based on cross-validated MAP.</p><p>The pool for the second purely visual submission (TUBFI 2 in Table <ref type="table" coords="7,422.39,464.17,4.15,8.64" target="#tab_1">2</ref>) consisted of average kernels computed over several combinations of the sets from Table <ref type="table" coords="7,433.27,476.12,3.74,8.64" target="#tab_0">1</ref>. Hypothesis testing using a Wilcoxon's signed rank test on the cross-validation results showed no improvement in MAP over the first pure visual submission. Nevertheless we submitted it for the sake of scientific curiosity -using average kernel SVMs over varying sets of kernels is a computationally very efficient method. On the test data we observed a drop in performance. Table <ref type="table" coords="7,224.05,535.90,4.98,8.64" target="#tab_2">3</ref> shows for each submission applied the number of classes using particular method.</p><p>The pool for the fourth purely visual submission (TUBFI 5 in Table <ref type="table" coords="7,421.91,560.30,4.15,8.64" target="#tab_1">2</ref>) consisted of the classifiers from the second submission combined with a MKL heuristic (see Section 3). Statistical testing revealed that a small improvement in MAP could be expected. Indeed, the result on test data was marginally better than the first and the second submission despite it contained some classifiers from the flawed second submission and used a heuristically down-scaled variant of MKL.</p><p>The pool for the third and a posteriori best purely visual submission (TUBFI 4 in Table <ref type="table" coords="7,158.90,644.48,4.15,8.64" target="#tab_1">2</ref>) consisted of the classifiers from the second submission, the MKL heuristic and the output kernel MKL/MTL (see Section 4). Statistical testing revealed more classes with significant gains over the baseline (TUBFI 1 in Table <ref type="table" coords="8,383.35,119.31,3.60,8.64" target="#tab_1">2</ref>). In 42 categories the chosen classifier belongs to the output kernel MKL/MTL. The result on test data was the only purely visual run which showed a larger improvement over the baseline TUBFI 1. Therefore we attribute its gains to the influence of the output kernel MKL procedure.</p><p>The only multi-modal submission (TUBFI 3 in Table <ref type="table" coords="8,361.62,167.23,4.15,8.64" target="#tab_1">2</ref>) used kernels from the baseline (TUBFI 1 in Table <ref type="table" coords="8,229.12,179.18,4.15,8.64" target="#tab_1">2</ref>) combined with smoothed textual Bag-of-Words (see Section 5). </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,134.77,426.66,345.82,7.77;3,134.77,437.62,345.83,7.77;3,134.77,448.58,281.45,7.77;3,150.66,293.87,155.62,116.71"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: Upper Left: The essential structures of the bridge are lines rather than corners (author's own work). Upper Right: Harris Laplace keypoints. Lower Left: bias1 keypoints. Lower Right: bias4 keypoints with same number of keypoints as detected by Harris Laplace.</figDesc><graphic coords="3,150.66,293.87,155.62,116.71" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,137.27,117.67,340.81,110.80"><head>Table 1 :</head><label>1</label><figDesc>BoW Feature Sets. See text for explanation.</figDesc><table coords="2,137.27,143.59,340.81,84.88"><row><cell cols="3">Sampling Type Local Feature Color Channels</cell><cell cols="2">BoW Mapping No. of Features</cell></row><row><cell>grid</cell><cell cols="2">Color Quantiles RGB, Opp,Gr</cell><cell>Rank</cell><cell>9</cell></row><row><cell>grid</cell><cell>SIFT</cell><cell>RGB, Opp,Gr, N-Opp</cell><cell>0-1</cell><cell>12</cell></row><row><cell>grid</cell><cell>SIFT</cell><cell>RGB, Opp,Gr, N-Opp</cell><cell>Rank</cell><cell>12</cell></row><row><cell>bias1</cell><cell>SIFT</cell><cell>RGB, Opp,Gr</cell><cell>Rank</cell><cell>9</cell></row><row><cell>bias2</cell><cell>SIFT</cell><cell cols="2">RGB, Opp,Gr, N-Opp,N-RGB Rank</cell><cell>15</cell></row><row><cell>bias3</cell><cell>SIFT</cell><cell>RGB, Opp</cell><cell>Rank</cell><cell>6</cell></row><row><cell>bias4</cell><cell>SIFT</cell><cell>RGB, Opp,Gr</cell><cell>Rank</cell><cell>9</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,134.77,117.67,273.67,209.05"><head>Table 2 :</head><label>2</label><figDesc>Results by MAP for the best three submissions.</figDesc><table coords="7,134.77,143.59,244.35,183.14"><row><cell cols="3">Submission Modality MAP on test data</cell></row><row><cell>BPACAD 3</cell><cell>T</cell><cell>34.56</cell></row><row><cell>IDMT 1</cell><cell>T</cell><cell>32.57</cell></row><row><cell>MLKD 1</cell><cell>T</cell><cell>32.56</cell></row><row><cell>TUBFI 1</cell><cell>V</cell><cell>38.27</cell></row><row><cell>TUBFI 2</cell><cell>V</cell><cell>37.15</cell></row><row><cell>TUBFI 4</cell><cell>V</cell><cell>38.85</cell></row><row><cell>TUBFI 5</cell><cell>V</cell><cell>38.33</cell></row><row><cell>CAEN 2</cell><cell>V</cell><cell>38.24</cell></row><row><cell>ISIS 3</cell><cell>V</cell><cell>37.52</cell></row><row><cell>TUBFI 3</cell><cell>V&amp;T</cell><cell>44.34</cell></row><row><cell>LIRIS 5</cell><cell>V&amp;T</cell><cell>43.70</cell></row><row><cell cols="2">BPACAD 5 V&amp;T</cell><cell>43.63</cell></row><row><cell cols="2">7 Discussion of Submission Outcomes</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,147.93,224.08,319.50,89.28"><head>Table 3 :</head><label>3</label><figDesc>number of classes using a particular method shown for each submission.submission TUBFI 1 kernels other kernel sets MKL heur. Output MKL heur. tag kernels</figDesc><table coords="8,151.79,261.36,300.62,52.01"><row><cell>TUBFI 1</cell><cell>99</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>TUBFI 2</cell><cell>35</cell><cell>64</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>TUBFI 5</cell><cell>5</cell><cell>27</cell><cell>67</cell><cell>0</cell><cell>0</cell></row><row><cell>TUBFI 4</cell><cell>1</cell><cell>16</cell><cell>40</cell><cell>42</cell><cell>0</cell></row><row><cell>TUBFI 3</cell><cell>6</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>93</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments We like to thank <rs type="person">Shinichi Nakajima</rs>, <rs type="person">Roger Holst</rs>, <rs type="person">Dominik Kuehne</rs>, <rs type="person">Malte Danzmann</rs>, <rs type="person">Stefanie Nowak</rs>, <rs type="person">Volker Tresp</rs> and <rs type="person">Klaus-Robert Müller</rs>. This work was supported in part by the <rs type="funder">Federal Ministry of Economics and Technology of Germany (BMWi)</rs> under the project <rs type="projectName">THESEUS</rs> (<rs type="grantNumber">01MQ07018</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_vFt8sqw">
					<idno type="grant-number">01MQ07018</idno>
					<orgName type="project" subtype="full">THESEUS</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.61,448.22,337.98,7.77;8,150.95,459.18,329.64,7.77;8,150.95,470.98,179.03,6.31" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,302.95,448.22,177.64,7.77;8,150.95,459.18,12.95,7.77">On taxonomies for multi-class image categorization</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">R</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kawanabe</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11263-010-0417-8</idno>
		<ptr target="http://dx.doi.org/10.1007/s11263-010-0417-8" />
	</analytic>
	<monogr>
		<title level="j" coord="8,170.90,459.18,153.94,7.77">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2011-01">January 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,481.19,337.98,7.77;8,150.95,492.15,183.26,7.77" xml:id="b1">
	<analytic>
	</analytic>
	<monogr>
		<title level="m" coord="8,315.36,481.19,122.98,7.77">CLEF 2010 LABs and Workshops</title>
		<title level="s" coord="8,445.23,481.19,35.36,7.77;8,150.95,492.15,22.30,7.77">Notebook Papers</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Harman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Pianta</surname></persName>
		</editor>
		<meeting><address><addrLine>Padua, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-09">September 2010. 2010</date>
			<biblScope unit="page" from="22" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,503.20,337.98,7.77;8,150.95,514.16,329.64,7.77;8,150.95,525.12,67.24,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,303.27,503.20,160.83,7.77">Visual categorization with bags of keypoints</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bray</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Dance</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,150.95,514.16,218.69,7.77">Workshop on Statistical Learning in Computer Vision, ECCV</title>
		<meeting><address><addrLine>Prague, Czech Re</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004-05">May 2004</date>
			<biblScope unit="page" from="1" to="22" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,536.17,337.98,7.77;8,150.95,547.13,192.73,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,300.14,536.17,156.28,7.77">Learning multiple tasks with kernel methods</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">A</forename><surname>Micchelli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,462.34,536.17,18.25,7.77;8,150.95,547.13,124.00,7.77">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="615" to="637" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,558.18,337.98,7.77;8,150.95,569.14,117.41,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,378.57,558.18,102.02,7.77;8,150.95,569.14,49.38,7.77">Kernel codebooks for scene categorization</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Van Gemert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Geusebroek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Veenman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Smeulders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,218.30,569.14,23.91,7.77">ECCV</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,580.19,337.98,7.77;8,150.95,591.15,329.64,7.77;8,150.95,602.11,303.60,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,305.51,580.19,175.08,7.77;8,150.95,591.15,40.69,7.77">Multimodal semi-supervised learning for image classication</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Guillaumin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Verbeek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<ptr target="http://lear.inrialpes.fr/pubs/2010/GVS10" />
	</analytic>
	<monogr>
		<title level="m" coord="8,209.64,591.15,229.99,7.77">Proc. of IEEE Int. Conf. on Comp. Vis. &amp; Pat. Rec. (CVPR &apos;10)</title>
		<meeting>of IEEE Int. Conf. on Comp. Vis. &amp; Pat. Rec. (CVPR &apos;10)<address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,613.16,337.98,7.77;8,150.95,624.12,272.24,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,262.71,613.16,217.88,7.77;8,150.95,624.12,27.67,7.77">A model of saliency-based visual attention for rapid scene analysis</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Itti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Niebur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,184.33,624.12,141.74,7.77">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1254" to="1259" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,635.17,337.98,7.77;8,150.95,646.13,329.64,7.77;8,150.95,657.08,203.80,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,356.96,635.17,123.63,7.77;8,150.95,646.13,191.43,7.77">Multi-modal visual concept classification of images via markov random walk over tags</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kawanabe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Wojcikiewicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,360.63,646.13,119.96,7.77;8,150.95,657.08,29.29,7.77">Applications of Computer Vision (WACV)</title>
		<imprint>
			<date type="published" when="2011">2011. 2011</date>
			<biblScope unit="page" from="396" to="401" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,119.96,337.98,7.77;9,150.95,130.92,201.20,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,328.74,119.96,119.51,7.77">Lp-norm multiple kernel learning</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kloft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Brefeld</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sonnenburg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,454.19,119.96,26.40,7.77;9,150.95,130.92,110.80,7.77">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="953" to="997" />
			<date type="published" when="2011-03">Mar 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,141.88,338.35,7.77;9,150.95,152.84,140.67,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,188.87,141.88,201.95,7.77">Distinctive image features from scale invariant keypoints</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,396.64,141.88,83.95,7.77;9,150.95,152.84,61.48,7.77">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,163.80,338.35,7.77;9,150.95,174.76,329.64,7.77;9,150.95,186.56,118.36,6.31" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="9,265.94,163.80,214.65,7.77;9,150.95,174.76,19.86,7.77">Learning representations for visual object class recognition</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Marszalek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<ptr target="http://pascallin.ecs.soton.ac.uk/challenges/VOC/voc2007/workshop/marszalek.pdf" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,196.67,338.35,7.77;9,150.95,207.63,275.17,7.77" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="9,388.30,196.67,92.29,7.77;9,150.95,207.63,171.58,7.77">Lear and xrce&apos;s participation to visual concept detection task -imageclef</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Verbeek</surname></persName>
		</author>
		<editor>Braschler et al.</editor>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,218.59,338.35,7.77;9,150.95,229.55,329.64,7.77;9,150.95,240.51,144.52,7.77" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,265.80,218.59,211.52,7.77">Sampling strategies for bag-of-features image classification</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Jurie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,312.18,229.55,35.19,7.77">ECCV (4)</title>
		<title level="s" coord="9,352.29,229.55,124.53,7.77">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">A</forename><surname>Leonardis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Bischof</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Pinz</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">3954</biblScope>
			<biblScope unit="page" from="490" to="503" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,251.47,338.35,7.77;9,150.95,262.43,244.76,7.77" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,283.89,251.47,196.70,7.77;9,150.95,262.43,41.51,7.77">The clef 2011 photo annotation and concept-based retrieval tasks</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Nagel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Liebetrau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,210.28,262.43,94.02,7.77">CLEF 2011 working notes</title>
		<meeting><address><addrLine>The Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,273.39,338.35,7.77;9,150.95,284.34,329.64,7.77;9,150.95,295.30,224.21,7.77" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,299.60,273.39,180.99,7.77;9,150.95,284.34,45.79,7.77">Improving the fisher kernel for large-scale image classification</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,387.39,284.34,36.20,7.77">ECCV (4)</title>
		<title level="s" coord="9,429.52,284.34,51.07,7.77;9,150.95,295.30,73.69,7.77">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">K</forename><surname>Daniilidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Maragos</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Paragios</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6314</biblScope>
			<biblScope unit="page" from="143" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,306.26,338.35,7.77;9,150.95,317.22,128.49,7.77" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,297.16,306.26,183.43,7.77;9,150.95,317.22,28.11,7.77">Multi-task learning via non-sparse multiple kernel learning</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Samek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Binder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kawanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,197.02,317.22,20.43,7.77">CAIP</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>accepted</note>
</biblStruct>

<biblStruct coords="9,142.24,328.18,338.35,7.77;9,150.95,339.14,245.58,7.77" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,339.41,328.18,141.18,7.77;9,150.95,339.14,76.84,7.77">Evaluating color descriptors for object and scene recognition</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">E A</forename><surname>Van De Sande</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gevers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">G M</forename><surname>Snoek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,233.62,339.14,136.76,7.77">IEEE Trans. Pat. Anal. &amp; Mach. Intel</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,350.10,338.35,7.77;9,150.95,361.06,147.66,7.77" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="9,276.60,350.10,203.99,7.77;9,150.95,361.06,44.07,7.77">The university of amsterdam&apos;s concept detection system at imageclef</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">E A</forename><surname>Van De Sande</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gevers</surname></persName>
		</author>
		<editor>Braschler et al.</editor>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,372.02,396.68,7.77;9,150.95,382.97,219.82,7.77" xml:id="b18">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Sheldon</surname></persName>
		</author>
		<ptr target="http://agbs.kyb.tuegingen.mpg.de/wikis/bg/siso2008/Sheldon.pdf" />
		<title level="m" coord="9,197.20,372.02,103.24,7.77">Graphical multi-task learning</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>nIPS workshop on strictured input -structured output</note>
</biblStruct>

<biblStruct coords="9,142.24,393.93,338.35,7.77;9,150.95,404.89,329.64,7.77;9,150.95,415.85,275.07,7.77" xml:id="b19">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tahir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Van De Sande</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Uijlings</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gevers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Smeulders</surname></persName>
		</author>
		<ptr target="http://pascallin.ecs.soton.ac.uk/challenges/VOC/voc2008/workshop/tahir.pdf" />
		<title level="m" coord="9,358.03,404.89,118.40,7.77">SurreyUVA SRKDA method</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.24,426.81,338.35,7.77;9,150.95,437.77,172.04,7.77" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="9,342.65,426.81,137.94,7.77;9,150.95,437.77,49.38,7.77">A biased sampling strategy for object categorization</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,218.30,437.77,22.51,7.77">ICCV</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1141" to="1148" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
