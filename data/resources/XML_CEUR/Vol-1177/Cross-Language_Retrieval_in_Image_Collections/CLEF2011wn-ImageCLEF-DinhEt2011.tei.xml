<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,135.36,116.93,344.51,12.90">IRIT at ImageCLEF 2011: medical retrieval task</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,251.40,154.37,41.01,9.62"><forename type="first">Duy</forename><surname>Dinh</surname></persName>
							<email>duy.dinh@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">IRIT laboratory</orgName>
								<orgName type="institution">University of Toulouse</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>31062</postCode>
									<settlement>Toulouse</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,300.72,154.37,63.22,9.62"><forename type="first">Lynda</forename><surname>Tamine</surname></persName>
							<email>lynda.tamine@irit.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">IRIT laboratory</orgName>
								<orgName type="institution">University of Toulouse</orgName>
								<address>
									<addrLine>118 route de Narbonne</addrLine>
									<postCode>31062</postCode>
									<settlement>Toulouse</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,135.36,116.93,344.51,12.90">IRIT at ImageCLEF 2011: medical retrieval task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2F129415D80EC82C30B3BA6249DC850A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Biomedical information retrieval</term>
					<term>Term weighting models</term>
					<term>Query expansion</term>
					<term>Model fusion</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper, we reported some experiments conducted by our members in the SIG team at the IRIT laboratory in the University of Toulouse within the context of the medical information retrieval (IR) task. As in our previous participation in ImageCLEF, in 2011, our research focuses on the case-based retrieval task. We compared the performance of different state-of-the-art term weighting models for retrieving patient cases that might best suit the clinical information need. Furthermore, we also combined term scores obtained by two state-of-the-art weighting models using a particular data fusion technique. Finally, a state-of-the-art query expansion (QE) technique is used for improving biomedical IR performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper describes the contribution of the SIG team (Generalized Information Systems) at the IRIT<ref type="foot" coords="1,228.12,436.80,3.97,6.64" target="#foot_0">1</ref> (Institute for Research in Informatics of Toulouse) laboratory in its second year participation at the medical retrieval track. We focused in particular on the case-based retrieval task, where patient demographics, limited symptoms and test results are provided to answer the medical professionals' information need <ref type="bibr" coords="1,212.04,485.93,9.99,9.62" target="#b0">[1]</ref>.</p><p>We first investigate the effectiveness of two different state-of-the-art term weighting models that have been shown to work well in the past: LGD (a log logistic model) <ref type="bibr" coords="1,194.28,533.81,9.99,9.62" target="#b1">[2]</ref>, In expB2 (Inverse Expected Document Frequency model with the Bernoulli ratio normalisation) <ref type="bibr" coords="1,285.84,545.81,9.99,9.62" target="#b2">[3]</ref>. These models are then combined using a particular data fusion technique <ref type="bibr" coords="1,276.00,557.69,9.99,9.62" target="#b3">[4]</ref>. Next, we experiment with a state-of-the-art pseudo or blind feedback query expansion algorithm implemented in the DFR framework <ref type="bibr" coords="1,183.84,581.57,9.99,9.62" target="#b2">[3]</ref>.</p><p>The rest of this paper is organized as follows: Section 2 describes our indexing and retrieval framework. Experimental results will be presented and discussed in section 3. We conclude the paper in section 4 and outline some perspectives for our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Indexing and retrieval framework</head><p>The indexing aims to organize, structure and store statistical and/or linguistic information about terms and documents in the collection allowing a rapid and efficient search. We use the Terrier IR platform for indexing documents <ref type="bibr" coords="2,467.28,172.97,9.99,9.62" target="#b4">[5]</ref>: stop-words are removed from documents and queries before stemming using the Porter algorithm <ref type="bibr" coords="2,211.08,196.85,9.99,9.62" target="#b5">[6]</ref>.</p><p>The document retrieval aims to match the user query and document representations in order to retrieve a list of results that may satisfy the user information need. In our work, a document D containing terms used for formulating query Q is weighted by summing the score of each term figuring in document D:</p><formula xml:id="formula_0" coords="2,239.76,270.91,240.87,21.22">RSV (D, Q) = t∈Q score(t ∈ D)<label>(1)</label></formula><p>where score(t ∈ D) is the query term weight calculated using a particular term weighting model. In this section, we first describe two different term weighting models used in our experiments, namely LGD <ref type="bibr" coords="2,332.64,330.05,10.56,9.62" target="#b6">[7]</ref> and In expB2 <ref type="bibr" coords="2,406.56,330.05,9.99,9.62" target="#b2">[3]</ref>. These models are fused to obtain a combined score for each query term figuring in documents.</p><p>We then applied a state-of-the-art pseudo-relevance feedback technique in order to improve the information retrieval (IR) performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">The LGD model</head><p>In the LGD model, query terms are weighted using the log logistic distribution <ref type="bibr" coords="2,134.76,438.41,9.99,9.62" target="#b6">[7]</ref>. Formally:</p><formula xml:id="formula_1" coords="2,186.60,461.92,294.03,22.63">score LGD (t ∈ D) = qtf × log 2 ( N t N + tf n ) -log 2 ( N t N )<label>(2)</label></formula><p>where t is a query term occurring in document D, -N t is the document frequency (i.e., number of documents containing term t), -N is the total number of documents in the collection, -qtf is the query term frequency, -tf n is the normalised within-document term frequency, given by:</p><formula xml:id="formula_2" coords="2,247.44,608.44,233.19,22.63">tf n = tf × log 2 (1 + c × avg dl dl )<label>(3)</label></formula><p>where avg dl is the average document length (in tokens), dl is the document length (in tokens) and c is a multiplying factor or tuning parameter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">The In expB2 model</head><p>For the In expB2 model, query terms are weighted using the Inverse Expected Document Frequency model with Bernoulli after-effect and term frequency normalisation <ref type="bibr" coords="3,183.00,163.85,9.99,9.62" target="#b2">[3]</ref>. Formally:</p><formula xml:id="formula_3" coords="3,139.80,193.99,340.83,25.80">score In expB2 (t ∈ D) = qtf × (tf + 1) × tf n 2 N t × (tf n 2 + 1) × ln2 ×log 2 N + 1 N × (1 -e -tf N ) + 0.5<label>(4)</label></formula><p>where t is a query term occurring in document D, -N t is the document frequency, -N is the total number of documents in the collection, -qtf is the query term frequency, -tf is the within-document term frequency, -tf n 2 is the normalised within-document term frequency, given by:</p><formula xml:id="formula_4" coords="3,237.84,331.48,242.79,22.63">tf n 2 = tf ln2 × log 2 1 + c × avg dl dl<label>(5)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Model fusion</head><p>In the context of information retrieval, data fusion refers to the task of combining the output of multiple ranking strategies into a single list of objects (documents, concepts, etc.) <ref type="bibr" coords="3,199.92,417.77,11.04,9.62" target="#b3">[4,</ref><ref type="bibr" coords="3,210.96,417.77,7.36,9.62" target="#b7">8]</ref>. Objects in different lists can be merged together by using a variety of aggregate functions such as MIN, MAX, SUM, AVERAGE, MEDIAN, MNZ, etc. The combination technique based on each of those functions can be referred to as CombXXX, where 'XXX' stands for the name of the aggregate function. For example, using the SUM operator for two ranking algorithms A1 and A2, scores are summed to obtain a final score, which is the sum of the term score obtained by ranking algorithm A1 and the one obtained by ranking algorithm A2. CombSUM and CombMNZ have been widely studied and have demonstrated state-of-the-art performance <ref type="bibr" coords="3,321.84,513.41,9.99,9.62" target="#b8">[9]</ref>. Such techniques are important in distributed IR where results obtained from several corpora or IR ranking strategies must be coordinated. Authors in <ref type="bibr" coords="3,295.44,537.29,15.60,9.62" target="#b9">[10]</ref> distinguished two classes of data fusion techniques : one has access to query-document score (term weighting model), and one does not, with access only to system rankings (document relevance scoring).</p><p>With the development of information technology and communication, especially in the IR field, a large number of IR models have been developed and integrated into the Terrier IR platform <ref type="bibr" coords="3,314.76,597.17,9.99,9.62" target="#b4">[5]</ref>. We study here the impact of using data fusion technique on the performance of term weighting model. More specifically, we combine term scores obtained by summing the scores obtained by the two state-of-the-art term weighting models described earlier, i.e., LGD and In expB2 model. Given a query term t, its combined score is computed as follows:</p><formula xml:id="formula_5" coords="4,156.24,141.55,324.39,66.46">score(t ∈ D) = score LGD (t ∈ D) + score In expB2 (t ∈ D) = qtf × log 2 ( N t N + tf n ) -log 2 ( N t N ) + qtf ln2 × (tf + 1) × tf n 2 N t × (tf n 2 + 1) × log 2 N + 1 N × (1 -e -tf /N ) + 0.5<label>(6)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Query expansion</head><p>The DFR framework employs a query expansion (QE) mechanism that is a generalisation of Rocchio's method <ref type="bibr" coords="4,265.68,259.25,14.69,9.62" target="#b10">[11]</ref>: terms in the top-ranked documents retrieved in the first stage are weighted using a particular DFR term weighting model. In general, the weight of a term of the expanded query q * derived from the original query q is obtained as follows:</p><formula xml:id="formula_6" coords="4,222.60,315.28,258.03,22.63">weight(t ∈ q * ) = qtf n + β * Inf o DF R M axInf o<label>(7)</label></formula><p>where qtf n is the normalised within-query term frequency,</p><formula xml:id="formula_7" coords="4,141.00,381.17,164.52,22.44">-M axInf o = arg t∈q * max Inf o DF R , -Inf o DF R</formula><p>is the term frequency in the expanded query induced by using a DFR model, that is:</p><formula xml:id="formula_8" coords="4,210.12,427.03,266.26,11.61">Inf o DF R = -log 2 P rob(F req(w|K)|F req(w|C)) (<label>8</label></formula><formula xml:id="formula_9" coords="4,476.38,427.37,4.25,9.62">)</formula><p>where Prob is the probability of obtaining a given within-query term frequency from the top-ranked documents retrieved in the first stage. In the DFR framework, several measures are used to compute this probability such as: Bose-Einstein (Bo) statistics and Kullback-Leibler (KL) measure <ref type="bibr" coords="4,447.48,485.33,9.99,9.62" target="#b2">[3]</ref>. The former gives the following term frequency normalisation: </p><formula xml:id="formula_10" coords="4,215.64,518.47,264.99,24.57">Info Bo = -log 2 Prob(Freq(w|K)|Freq(w|C)) = -log 2 ( 1 1+λ ) -Freq(w|K) * log 2 ( 1 1+λ )<label>(9)</label></formula><p>3 Experimental evaluation  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation metrics</head><p>Retrieval performance was evaluated using standard measures: P@10, P@20, and MAP. P@10, P@20 represent respectively the mean precisions at the top 10, 20 returned documents. MAP (Mean Average Precision) is the average precision of a query which is computed by averaging the precision values computed for each relevant retrieved document of rank x ∈ (1..K), where K = 1000 is the number of retrieved documents. Our results are generated by the trec eval standard tool<ref type="foot" coords="6,476.16,142.32,3.97,6.64" target="#foot_1">2</ref> used by the TREC community for evaluating ad hoc retrieval runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Run description</head><p>We submitted ten official runs to the case-based medical retrieval track <ref type="bibr" coords="6,447.00,205.61,9.99,9.62" target="#b0">[1]</ref>. Our submitted runs are divided into two groups: the first one (6 runs) includes terms with low inverse document frequency (IDF) while the second one (4 runs) excludes them from the document index. In table 2, runs without query expansion are distinguished by an asterisk (*). For the first group of runs, we used the two state-of-the-art weighting models namely LGD <ref type="bibr" coords="6,358.80,265.37,10.56,9.62" target="#b6">[7]</ref> (run 1) and In expB2 <ref type="bibr" coords="6,470.04,265.37,10.56,9.62" target="#b2">[3]</ref> (run 2). The CombSU M technique <ref type="bibr" coords="6,290.40,277.37,10.56,9.62" target="#b3">[4]</ref> is used in run 3 at the level of term scoring instead of document re-ranking, i.e. the fusion technique modifies directly the scores obtained by retrieval models and not the final scores of output documents. Runs 4, 5 and 6 are combined with a blind feedback query expansion based on the Kullback-Leibler (KL) statistics. Runs in the second group <ref type="bibr" coords="6,457.56,325.13,11.64,9.62" target="#b6">(7,</ref><ref type="bibr" coords="6,472.80,325.13,7.80,9.62" target="#b7">8,</ref><ref type="bibr" coords="6,134.76,337.13,7.80,9.62" target="#b8">9,</ref><ref type="bibr" coords="6,145.92,337.13,13.95,9.62" target="#b9">10)</ref> are submitted with the exclusion of low IDF terms using each of the two state-of-the-art weighting models, the CombSU M fusion technique <ref type="bibr" coords="6,432.84,349.13,10.56,9.62" target="#b3">[4]</ref> and the KL QE technique. For QE, a maximum number of twenty terms are extracted from the top twenty returned documents. All runs are submitted with the default configuration in Terrier: c=1.0, stopword removal, Porter stemmer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Results and discussion</head><p>According to the results presented in table 2, we see that ignoring low IDF terms does not help and even harms the IR performance. Normally, low IDF terms are not useful for describing the semantics of the document and can be ignored from the document index <ref type="bibr" coords="6,226.80,470.81,15.60,9.62" target="#b11">[12,</ref><ref type="bibr" coords="6,243.96,470.81,11.70,9.62" target="#b12">13]</ref>. However, in the biomedical domain, especially in medical records retrieval, low IDF terms may be used to mention or distinguish medical concepts such as 'low', 'high', 'right', 'left', ... (e.g., low back pain vs. high back pain, right lung vs. left lung), etc.</p><p>Here, we compare the performance of the two mentioned state-of-the-art models LGD and In expB2. We notice that the LGD model is better than the In expB2 model in terms of MAP with an improvement of +17.36%. In terms of P@10, the two models yield the same performance, but in terms of P@20, the former is better than the latter with an improvement of +22.2%. For this reason, we chose the IRIT LGDc1.0 run as our strong baseline to compare to other runs.</p><p>The CombSU M method combining term scores obtained by those models outperforms the In expB2 model and similar to the LGD model (baseline) in terms of MAP. In terms of P@10, the CombSU M fusion technique outperforms the baseline with an improvement of +29.97%. However, in terms of P@20, the Table <ref type="table" coords="7,165.24,116.88,4.47,8.95">2</ref>. Official results of submitted runs in the case-based retrieval task. Runs with an asterisk are without using pseudo relevance feedback. CombSU M technique gives the same performance as the In expB2, which is lower than the baseline. We conclude that combining term scores at the level of weighting models can be useful for improving the search precision (P@10), without losing the MAP performance.</p><p>At this level, we present the results of submitted runs obtained using query expansion. The In expB2 model in combination with the KL QE method shows a small improvement in terms of MAP (+03.90%), a decrease in terms of precision P@10 (-10.00%) and no effect in terms P@20 compared to the In expB2 model without QE. This is probably due to the fact that the clinical query length is long (about 30 in average) and the number of extracted terms for QE is smaller than or equal to 20; therefore extracted terms may be observed as in the original terms or also they can be different from the latter but the top-ranked documents do not or slightly change after expansion. The LGD model in combination with the KL QE method (run IRIT LGDc1.0 KLbf ree d 20 t 20 1) outperforms the baseline with an improvement rate of +17.85% in terms of MAP, +40.05% in terms of P@10 and +4.58% in terms of P@20. This proves that query expansion is only effective if it is based on an underlying effective ranking model. Indeed, the In expB2 model in combination with the KL QE method performs worse than the baseline. This also explains why the CombSU M method in combination with the KL QE gives no improvement compared to the baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this work, we have compared and evaluated the IR performance of two stateof-the-art term weighting models, a state-of-the-art query expansion approach. In our empirical studies, we proposed to combine term scores obtained by different term weighting models to improve the retrieval performance, especially the search precision.</p><p>Within the case-based retrieval task, we noticed that low IDF terms are also useful for indexing and retrieval because they can be used to mention or distinguish medical concepts. The LGD model proposed by <ref type="bibr" coords="8,401.16,143.69,10.56,9.62" target="#b1">[2]</ref> shows the best performance on the case-based retrieval task and consistently outperforms the In expB2 model with or without query expansion. The combination of the LGD model, which is based on the log logistic distribution, and the KL query expansion method gives the best results. We conclude that an effective ranking model in conjunction with a appropriate query expansion strategy could be combined together to improve the IR performance.</p><p>Since documents in the case-based collection contains a lot of medical concepts, in our future work, we aim to extract concepts from documents for better representing the document's semantics. In addition, we'll also focus on adjusting query by expanding the query with related terms denoting concepts in ontologies or removing non informative terms from the query.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,151.68,553.13,25.54,9.62;4,158.64,565.15,321.97,9.96;4,168.60,577.37,172.46,9.62;4,158.64,590.71,40.38,10.65;4,202.92,588.48,35.51,6.64;4,217.68,596.76,5.88,6.64;4,242.88,591.05,49.74,10.31;4,296.52,588.48,85.79,6.64;4,316.44,596.76,45.71,6.64;4,158.64,603.91,42.18,9.96;4,151.68,628.49,285.24,9.62;4,206.52,651.77,39.18,10.31;4,255.36,649.08,39.47,6.65;4,249.72,657.36,50.63,6.65;4,303.84,651.43,19.98,9.96;4,324.00,656.40,3.97,6.64;4,331.32,649.08,93.23,6.65;4,331.32,657.36,93.23,6.65"><head>2 F</head><label>2</label><figDesc>where• F req(w|K) (resp. F req(w|C)) is the the term frequency within the top ranked documents (resp. the collection) • λ Bo1 = Freq(w|C) N and λ Bo2 = TotalFreq(K) * Freq(w|C) TotalFreq(C)• β = 0.4 while the latter gives the following term frequency normalisation:Info KL = F req(w|K)T otalF req(K) * log req(w|K) * T otalF req(C) F req(w|C) * T otalF req(K)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,190.32,557.57,234.73,9.62;5,211.51,350.80,192.00,192.00"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Variation of document length in the collection</figDesc><graphic coords="5,211.51,350.80,192.00,192.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,141.60,150.54,34.81,8.07;7,381.24,150.54,90.98,8.07;7,249.72,161.68,115.93,8.66;7,145.20,173.08,100.24,8.66;7,381.12,173.08,90.64,8.66;7,145.20,184.48,117.46,8.66;7,381.12,184.48,90.64,8.66;7,145.20,195.76,107.56,8.66;7,381.12,195.76,90.64,8.66;7,145.20,207.16,179.44,8.66;7,381.12,207.16,90.64,8.66;7,145.20,218.44,155.20,8.66;7,379.08,218.58,94.82,8.07;7,145.20,229.84,172.12,8.66;7,381.12,229.84,90.64,8.66;7,228.48,241.24,158.46,8.66;7,145.20,252.52,182.44,8.66;7,382.56,252.52,90.76,8.66;7,145.20,263.92,326.56,8.66;7,145.20,275.32,213.77,8.66;7,381.12,275.32,90.64,8.66;7,142.92,286.60,168.52,8.66;7,381.12,286.60,90.64,8.66"><head></head><label></label><figDesc>expB2c1.0 KLbfree d 20 t 20 0 0.0772 0.1000 0.1000 Ignores terms with low IDF from index 7 IRIT CombSUMc1.0 KLbfree d 20 t 20 2 0.0874 0.1111 0.1000 8 IRIT In expB2c1.0 KLbfree d 20 t 20 0 ignore low idf 0.0793 0.1444 0.0889 9 IRIT LGDc1.0 KLbfree d 20 t 20 1 ignore low idf 0.0937 0.1111 0.0889 10 IRIT CombSUMc1.0 2 ignore low idf* 0.0721 0.1333 0.0778</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,134.76,144.36,345.85,158.95"><head>Table 1 .</head><label>1</label><figDesc>Test collection statistics</figDesc><table coords="5,134.76,144.36,345.85,158.95"><row><cell>3.1 Collection statistics</cell><cell></cell></row><row><cell cols="2">Some statistical characteristics of the Case-based 2011 collection is depicted in</cell></row><row><cell cols="2">table 1. The histogram in figure 1 shows the variation of document length in the</cell></row><row><cell>collection.</cell><cell></cell></row><row><cell>Number of documents</cell><cell>55,634</cell></row><row><cell>Average document length</cell><cell>3,078</cell></row><row><cell>Total number of tokens</cell><cell>171,251,809</cell></row><row><cell>Size of the vocabulary</cell><cell>815,708</cell></row><row><cell>Number of queries</cell><cell>10</cell></row><row><cell>Average query length</cell><cell>30</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.72,658.58,84.27,7.52"><p>http://www.irit.fr</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="6,144.72,658.58,145.23,7.52"><p>http://trec.nist.gov/trec_eval/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.88,322.00,337.64,8.66;8,151.56,333.04,328.96,8.66;8,151.56,343.96,329.16,8.66;8,151.56,354.88,21.82,8.66" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,210.96,333.04,265.75,8.66">The CLEF 2011 medical image retrieval and classification tasks</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Eggel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,165.12,343.96,102.31,8.66">CLEF 2011 working notes</title>
		<meeting><address><addrLine>Amsterdam, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011-09">September 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.88,362.68,337.88,10.82;8,151.56,375.88,60.64,8.66" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,267.00,364.84,161.62,8.66">Information-based models for ad hoc IR</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clinchant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">É</forename><surname>Gaussier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,452.28,364.84,28.48,8.66">SIGIR</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="234" to="241" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.88,385.84,337.74,8.66;8,151.56,396.76,245.50,8.66" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="8,202.56,385.84,278.06,8.66;8,151.56,396.76,69.86,8.66">Probabilistic models for Information Retrieval based on Divergence from Randomness</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
		<respStmt>
			<orgName>University of Glasgow</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="8,142.88,406.84,337.58,8.66;8,151.56,417.76,31.96,8.66" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,245.16,406.84,134.80,8.66">Combination of Multiple Searches</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">A</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Shaw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,401.76,406.84,26.33,8.66">TREC</title>
		<imprint>
			<biblScope unit="page" from="243" to="252" />
			<date type="published" when="1994">1994. 1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.88,427.72,337.75,8.66;8,151.56,438.76,329.11,8.66;8,151.56,449.68,52.18,8.66" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,261.60,427.72,120.06,8.66">Research directions in terrier</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">C V</forename><surname>Lioma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,393.48,427.72,87.15,8.66;8,151.56,438.76,159.94,8.66">Novatica/UPGRADE Special Issue on Web Information Access</title>
		<editor>
			<persName><forename type="first">Ricardo</forename><surname>Baeza-Yates</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>Invited Paper</note>
</biblStruct>

<biblStruct coords="8,142.88,459.64,337.63,8.66;8,151.56,470.68,183.64,8.66" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="8,221.28,459.64,130.83,8.66">An algorithm for suffix stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<biblScope unit="page" from="313" to="316" />
			<pubPlace>San Francisco, CA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.88,478.36,337.75,10.94;8,151.56,491.56,270.52,8.66" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,263.04,480.64,217.59,8.66;8,151.56,491.56,101.06,8.66">Retrieval constraints and word frequency distributions a log-logistic model for ir</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clinchant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">É</forename><surname>Gaussier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,259.68,491.56,86.91,8.66">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="25" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.88,501.64,337.64,8.66;8,151.56,512.56,328.99,8.66;8,151.56,523.48,329.07,8.66;8,151.56,534.52,97.48,8.66" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,241.56,501.64,238.96,8.66;8,151.56,512.56,147.34,8.66">Voting techniques for a multi-terminology based biomedical information retrieval (regular paper)</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Dinh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Tamine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,323.28,512.56,157.27,8.66;8,151.56,523.48,68.28,8.66">Conference on Artificial Intelligence in Medicine (AIME)</title>
		<meeting><address><addrLine>Bled, Slovenia</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011-06-07">02/07/2011-06/07/2011. 2011</date>
			<biblScope unit="volume">6747</biblScope>
			<biblScope unit="page" from="184" to="193" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.88,544.48,337.74,8.66;8,151.56,555.40,329.14,8.66;8,151.56,566.44,320.68,8.66" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,200.04,544.48,175.23,8.66">Analyses of multiple evidence combination</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,403.44,544.48,77.18,8.66;8,151.56,555.40,329.14,8.66;8,151.56,566.44,138.81,8.66">Proceedings of the 20th annual international ACM SIGIR conference on Research and development in information retrieval. SIGIR &apos;97</title>
		<meeting>the 20th annual international ACM SIGIR conference on Research and development in information retrieval. SIGIR &apos;97<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1997">1997</date>
			<biblScope unit="page" from="267" to="276" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.54,576.40,337.77,8.66;8,151.56,587.32,328.96,8.66;8,151.56,598.24,257.68,8.66" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,203.04,576.40,277.27,8.66;8,151.56,587.32,32.00,8.66">Generative model-based metasearch for data fusion in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Efron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,208.08,587.32,272.44,8.66;8,151.56,598.24,75.81,8.66">Proceedings of the 9th ACM/IEEE-CS joint conference on Digital libraries. JCDL &apos;09</title>
		<meeting>the 9th ACM/IEEE-CS joint conference on Digital libraries. JCDL &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="153" to="162" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.54,608.32,318.90,8.66" xml:id="b10">
	<monogr>
		<title level="m" type="main" coord="8,200.40,608.32,193.44,8.66">In: Relevance Feedback in Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Rocchio</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971">1971</date>
			<biblScope unit="page" from="313" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.54,618.28,338.01,8.66;8,151.56,629.20,77.14,8.66" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="8,290.04,618.28,118.08,8.66">Modern Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Ribeiro-Neto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999-05">May 1999</date>
			<publisher>Addison Wesley</publisher>
		</imprint>
	</monogr>
	<note>1st edn</note>
</biblStruct>

<biblStruct coords="8,142.54,639.28,338.09,8.66;8,151.56,650.20,154.66,8.66" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="8,321.48,639.28,159.16,8.66;8,151.56,650.20,42.07,8.66">Search Engines -Information Retrieval in Practice</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strohman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Pearson Education</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
