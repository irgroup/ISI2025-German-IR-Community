<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,98.53,148.91,405.94,15.12">Combining document representations for prior-art retrieval</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,236.44,182.75,53.57,8.74"><forename type="first">Eva</forename><surname>D'hondt</surname></persName>
							<email>e.dhondt@let.ru.nl</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Foraging Lab</orgName>
								<orgName type="institution">Radboud University Nijmegen</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,298.15,182.75,68.41,8.74"><forename type="first">Suzan</forename><surname>Verberne</surname></persName>
							<email>s.verberne@cs.ru.nl</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Foraging Lab</orgName>
								<orgName type="institution">Radboud University Nijmegen</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,225.29,230.45,57.59,8.74"><forename type="first">Wouter</forename><surname>Alink</surname></persName>
							<email>wouter@spinque.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Foraging Lab</orgName>
								<orgName type="institution">Radboud University Nijmegen</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,290.62,230.45,87.09,8.74;1,284.20,244.40,34.59,8.74"><forename type="first">Roberto</forename><forename type="middle">Cornacchia</forename><surname>Spinque</surname></persName>
							<email>roberto@spinque.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Foraging Lab</orgName>
								<orgName type="institution">Radboud University Nijmegen</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,98.53,148.91,405.94,15.12">Combining document representations for prior-art retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6AD952C26C4DE02173AC0AF3F2F97171</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing; H.3.3 Information Search and Retrieval Retrieval</term>
					<term>Text representation Prior Art Search</term>
					<term>Patent retrieval</term>
					<term>CLEF-IP track</term>
					<term>dependency triples</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we report on our participation in the CLEF-IP 2011 prior art retrieval task. We investigated whether adding syntactic information in the form of dependency triples to a bag-of-words representation could lead to improvements in patent retrieval.</p><p>In our experiments, we investigated this effect on the title, abstract and first 400 words of the description section. The experiments were conducted in the Spinque framework with which we tried to optimize for the combinations of text representation and document sections. We found that adding triples did not improve overall MAP scores, compared to the baseline bag-of-words approach but does result in slightly higher set recall scores. In future work we will extend our experiments to use all the text sections of the patent documents and fine-tune the mixture weights.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper, we describe our contribution to the prior-art retrieval track which was organised in the context of the Intellectual Property (IP) benchmark at the CLEF 2011 Labs. For the third year in a row, we focused on improving patent retrieval with the aid of syntactic-semantic information in addition to the baseline bag-of-words approach. In a follow-up study to last year's participation in the CLEF-IP classification track <ref type="bibr" coords="1,267.78,672.25,14.61,8.74" target="#b10">[11]</ref>, Koster et al. <ref type="bibr" coords="1,344.28,672.25,10.52,8.74" target="#b5">[6]</ref> found that patent classification can be improved by adding syntactic phrases in the form of dependency triples, to a bag-of-words representation. This year we were interested to see if a similar improvement could be found for prior art retrieval, by adding dependency triples to the words. In the CLEF-IP 2010 prior art track the Hildesheim team found that using (statistical) phrases as index units leads to a better improvement for titles than for the other document sections <ref type="bibr" coords="1,350.91,732.02,9.96,8.74" target="#b2">[3]</ref>. Keeping this in mind, our aim for this year's track was two-fold: (a) Examining the added value of using dependency triples on top of words in prior-art retrieval; (b) Optimizing the combination of the different documents sections and text representations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Data Description</head><p>The CLEF-IP 2011 corpus, a part of the MAREC collection, was provided by the IRF <ref type="bibr" coords="2,482.35,178.74,10.52,8.74" target="#b0">[1]</ref> and contains approximately 3 million documents, pertaining to more than 1 million patents<ref type="foot" coords="2,477.54,189.12,3.97,6.12" target="#foot_0">1</ref> . Most documents (2.6 million) came from the European Patent Office (EPO) and a smaller subset (around 400,000) consisted of patent documents from the World Intellectual Property Organization (WIPO). The patent documents were stored in the IRF XML format <ref type="bibr" coords="2,411.39,226.56,9.96,8.74" target="#b4">[5]</ref>. A patent document contains metadata such as name of inventor, IPC-R code, date of application, ... as well as (a mixture of) English, German or French text sections for the title, abstract, claims and/or description sections of the patent. In our experiments we only used the English text sections and IPC-R codes. The organizers distributed a training set of 300 patents and -unlike the previous yearsonly one topic set containing 3973 documents.</p><p>3 Experimental Set-up</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Patent Section Extraction</head><p>Using a perl script we extracted the English title, abstract, claims and description sections from the original XML files. We also saved the first 400 words of the description sections and the IPC-R codes<ref type="foot" coords="2,113.58,383.82,3.97,6.12" target="#foot_1">2</ref> separately. All the sections were saved as plain text in temporary text files. If a document did not contain a section or if -according to the XML tags-the section was not in English, no corresponding text file was created. The XML documents contain many text-internal XML tags that indicate figures, references, formulae, etc. in the original patent document. All such tags and the texts that they enclose were filtered from the text using a perl script.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Patent Parsing</head><p>In a preprocessing step the image references and claims headers in the text were removed using the regular expressions described by <ref type="bibr" coords="2,252.54,491.45,10.52,8.74" target="#b8">[9]</ref> in order to facilitate syntactic parsing of the claims and description sentences. We then sentenced the remaining text using a Perl script and knowledge of most common abbreviations in patent texts. The sentences in the resulting text files were parsed using the AEGIR dependency parser <ref type="bibr" coords="2,290.69,527.32,10.52,8.74" target="#b7">[8,</ref><ref type="bibr" coords="2,305.40,527.32,11.62,8.74" target="#b9">10]</ref>, version 1.8.2. One of the AEGIRs output formats is a dependency representation which is comparable to the Stanford typed dependencies <ref type="bibr" coords="2,90.00,551.23,9.96,8.74" target="#b3">[4]</ref>, in the sense that it generates a set of binary relations between words for an input sentence, thereby converting some function words (such as prepositions) to relations. In addition to that, AEGIR performs a number of normalizing syntactic transformations, such as passive-to-active transformation.</p><p>Because of the large amount of data we used a time constraint of maximum 1 second per sentence. This resulted in a loss of parsing output that differed somewhat between the separate sections.</p><p>Due to the sheer size of the corpus we were not able to completely parse the description and claims sections of the entire corpus within the given time. We therefore had to limit our experiments on the impact of triples to the title, abstract and first 400 words of the description. The keywords used for the bag-of-words component in the experiments were extracted from the title, abstract and the full description. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Spinque Framework</head><p>We modeled and executed our runs as search strategies within the Spinque framework <ref type="bibr" coords="3,466.12,231.12,9.96,8.74" target="#b1">[2]</ref>. This is a prototype interactive retrieval environment where search processes are divided into two phases: the search strategy definition and the actual search.</p><p>The framework has a GUI-based drag-and-drop strategy editor which allows the user to construct the search strategies as graph structures, where edges represent data-flows consisting of terms, documents (e.g. patent-documents), document-sections (e.g. invention-title, abstract, description) and named entities (e.g. patents, IPC-R codes, companies). The nodes connected by such edges are pre-defined, general-purpose operational blocks, that either provide source data (the patent corpus and the topics corpus) or modify their input data-flow by applying operations such as selection based on IPC-R classes, extraction of specific sections from documents, or ranking of sections and documents, to name a few.</p><p>Search strategies defined in this framework are automatically translated into a probabilistic relational query language and executed on top of an SQL database engine. The ranking scores that are used as the basis for the probabilities were calculated with the Okapi BM25 ranking algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Experiments</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1">Query term selection</head><p>This year, we performed query term selection on the triples, based on their relevance for a specific IPC-R class. The LCS software <ref type="bibr" coords="3,234.58,475.12,10.52,8.74" target="#b6">[7]</ref> that we used for the classification track builds class profiles which contain the term distribution (word and dependency triples) per IPC-R class. We extracted the subset of dependency triples that were most informative for correct classification, namely the top 25% of the triples ranked on their Winnow scores, from last year's class profiles and used them to filter the topic triples. Some class profiles for smaller IPC-R classes did not contain many triples (&lt; 1000). In these cases all triples that contributed to classification were extracted. The aim of this filtering step is to remove the noisy, less informative topic triples from the query thus improving precision. Since a patent document is usually labeled with not just one single IPC-R code but rather belongs to multiple categories (on average a patent document contains 3 different IPC-R codes (on subclass level), the filtering is not so severe that it weeds out the individual differences between topic patent documents. In other words, the individual filtered topic documents are still very different from one another due to the relatively large subsets of terms from the class profiles that were used as filters and the different combinations of IPC-R classes per document. The filtering step reduced the average number of triples per topic document (over all sections) from 180 to 60.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2">Strategy building</head><p>The search strategies were constructed and evaluated in Spinque's strategy builder interface. Our strategies consisted of two steps: <ref type="bibr" coords="3,241.84,698.73,12.73,8.74" target="#b0">(1)</ref> As in last year's approach we first filtered the corpus on the IPC-R codes of the topic document to create a subcorpus per topic document that contains documents with at least one IPC-R class in common with the topic document; (2) Terms (words and/or triples) from the sections in the topic documents were then used to query the respective sections of documents in the subcorpus. We did not perform any term selection for the bag-ofwords approach. The resulting document lists were then merged into a larger results list. The ranking in that list depended on the documents scores (BM25 scores from their separate runs) multiplied by the weights given to each results list in the configuration. An example of a search strategy used in this track is shown in figure <ref type="figure" coords="4,287.40,159.84,3.87,8.74">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3">Determining the weighting configuration</head><p>The mixture weights in the Spinque framework allow for a reranking step while merging the result lists of the runs with individual sections. Finding the optimal mixture weights is a very timeconsuming process, because of the large parameter space. Due to time constraints we were not able to train on many coefficient combinations for the mixtures. We used two different approaches to determine the weight configurations used in the submitted runs: (a) Normalisation over retrieval scores of individual sections; and (b) trial-and-error weighing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3.1">Determining the relative importance of different sections</head><p>The mixture coefficients for the combinations of different text sections were found by running a subset of the training set topics on the respective text sections, that is, evaluating the title, abstract and descriptions sections independently from one another. We then took the Mean Average Precision (MAP) scores of these runs, normalised them to sum up to 1 and used the resulting ratios as coefficients for the mixtures. The coefficients for mixing the words only and triples only runs were found using the 'trial and error' method on the training set. Starting from a 50/50 combination we used binary search to arrive at the optimal configuration: a words only (0.8) and triples only (0.2) combination.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.4">Submitted runs</head><p>We chose to submit four separate runs:</p><p>1. triples only: A baseline run to gauge the impact such precise index terms as Dependency triples can have on retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Words only:</head><p>A standard bag-of-words baseline run. Keywords were stemmed using the Porter stemmer (version 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Combination 1:</head><p>Combining the results list of the words only (stemmed) and triples only (unstemmed) runs in a 80/20 configuration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Combination 2:</head><p>Even though triples are lemmatized by the parser, the patent domain consists of many highly specialized subdomains which deploy their own jargon. Consequently the patent documents usually contain a lot of words which may not feature in the parser lexicon <ref type="bibr" coords="4,149.39,745.64,14.61,8.74" target="#b9">[10]</ref>. The AEGIR parser recognises these words using robust rules which lead to good estimates of POS tags (important for correct syntactic analysis later on) but applies no lemmatisation beyond the basic singular-plural differences. We therefore submitted an extra run to examine the impact of stemming of the triples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>In this section we present the results of our submitted runs in terms of MAP, Precision and Recall for the general (Table <ref type="table" coords="5,188.02,202.65,4.43,8.74">3</ref>) and English language-specific test data (Table <ref type="table" coords="5,404.74,202.65,3.87,8.74">4</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Impact of dependency triples on retrieval</head><p>As expected, triples by themselves are too specific to be used for retrieval: the triples only run achieved a very high set precision but fairly low set recall. On average, only 250 documents were retrieved per topic document in this run. The MAP scores for the different sections on a subset of the training data in table 2 show decided differences between the sections. However, in the combination runs, merging the triple only and the bag-of-words result lists presented some interesting results: While dependency triples are usually seen as a way of improving ranking, we achieved the highest set recall scores (measured with the language-specific English relevance assessments) compared to the other participants. An analysis of the result list of the combination 1 run shows that around 5% of relevant documents retrieved in this run (2.5% of all the relevant patents) were found using triples, but were not found in the words only approach. This may show that using dependency triples, i.e. information which abstracts away from the surface form of the sentence, can contribute to retrieval where a bag-of-words approach falls short. However, at this point, the contribution is very small. An alternative explanation is that the dependency triples have improved the ranking of documents in the results list that fell underneath the cut-off point of retrieving 1000 patents per query in the words only run. In which case, there is a complete overlap between the results from the triples only run and the documents found by the words only approach and the improvement in set recall score for the combined is an artefact of our choice of threshold.</p><p>Furthermore, another 36% of the relevant documents in combined 1 run were found by both the words and triples approaches. We would expect these documents to feature high in the combined results list thus improving the MAP score (compared to the words only run). However, we did not find much difference in the rankings and a slight decrease in MAP score. We expect that finetuning the 80/20 words-triples mixture coefficients on a held-out set of the test corpus may improve the rankings.</p><p>In the combination 2 run we experimented to try and raise recall by using stemming in the triples as well in the keywords, but we found that precision suffers much in that trade-off: While we did find more relevant documents, they were all pooled at the bottom of the results list. Moreover, the MAP score was significantly lower than for the combination 1 run. It is clear that the mixture weights should be tuned separately for combinations with stemmed triples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Impact of the different sections</head><p>We did not have the opportunity to examine the impact of the different sections in much detail. Rather we focussed on optimising the impact of those sections were dependency triples were the most successful in their own right (see section 3.4.3). However, this independency assumption is problematic: While it was a good starting point, namely in the mixtures the most weight was given to those sections that were most likely to have relevant documents high in the list, this strategy cannot properly account for interaction between sections and suffers from the uneven distribution of (English) text data in the corpus. In future work we will use further tuning via trial and error method to try and find a local if not global optimum.</p><p>In our participation to the CLEF-IP11 prior art retrieval track we examined the impact of adding dependency triples obtained with the AEGIR parser to a bag-of-words approach. Triples by themselves are very specific terms, as reflected by the high precision score achieved in the triple only run. Interestingly, we found that adding triples lead to a slight improvement in recall, rather than in precision as we had expected. It is not quite clear if this is due to the normalisation features of triples or an indirect effect of their higher precision. We also experimented with stemming of the triples, but this led to a severe loss of precision. In future work we will extend our experiments by adding data of all the description sections and the claims section, both for the words en triples approach. We will also keep working on tuning the mixture coefficients by a 'trial-and-error' method, rather than basing the coefficients on individual retrieval performance of the sections. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="8,482.02,500.98,8.74,28.12;8,482.02,489.92,8.74,7.75;8,482.02,456.95,8.74,28.53;8,482.02,418.41,8.74,35.23;8,482.02,403.15,8.74,11.93;8,482.02,372.63,8.74,27.20;8,482.02,350.50,8.74,18.54;8,482.02,332.21,8.74,14.97;8,107.27,184.42,359.64,492.48"><head>Figure 1 :Table 4 :</head><label>14</label><figDesc>Figure 1: Search strategy for triples only run</figDesc><graphic coords="8,107.27,184.42,359.64,492.48" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,90.00,118.94,434.56,68.66"><head>Table 1 :</head><label>1</label><figDesc>Estimate of missing parsing output -measured on representative set of 1000 documents title abstract description-400 claims 3 description 3</figDesc><table coords="3,95.98,142.99,415.05,44.60"><row><cell cols="2">nr. of doc that contain section in EN 997</cell><cell>378</cell><cell>388</cell><cell>541</cell><cell>388</cell></row><row><cell>nr. of sentences</cell><cell>997</cell><cell>1323</cell><cell>5699</cell><cell>6508</cell><cell>68969</cell></row><row><cell>av.sentence length</cell><cell>8.32</cell><cell>33.58</cell><cell>27.63</cell><cell>52.25</cell><cell>30.20</cell></row><row><cell>% of unparsed sentences</cell><cell>0.00</cell><cell>0.01</cell><cell>0.02</cell><cell>1.2</cell><cell>0.03</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,90.00,386.49,423.00,130.71"><head>Table 2 :</head><label>2</label><figDesc></figDesc><table coords="4,90.00,386.49,423.00,130.71"><row><cell cols="5">MAP scores -mixture coefficients for sections mixtures</cell></row><row><cell></cell><cell cols="2">words only</cell><cell cols="2">triples only</cell></row><row><cell></cell><cell cols="4">MAP coeff MAP coeff</cell></row><row><cell>title</cell><cell>0.0607</cell><cell>0.4</cell><cell>0.0109</cell><cell>0.2</cell></row><row><cell>abstract</cell><cell cols="4">0.0586 0.38 0.0334 0.62</cell></row><row><cell>description</cell><cell cols="2">0.0342 0.22</cell><cell>N/A</cell><cell>N/A</cell></row><row><cell>description-400</cell><cell>N/A</cell><cell cols="3">N/A 0.0097 0.18</cell></row><row><cell cols="5">3.4.3.2 Determining the relative importance of triples and words in the combined</cell></row><row><cell>runs</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,105.24,701.66,407.76,6.99;2,90.00,711.13,310.72,6.99"><p>Please note the difference between a patent and a patent document: a patent is not a physical document itself but a name for a group of patent documents that have the same patent ID number.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,105.24,720.63,290.51,6.99"><p>We used the full IPC-R code up to the level of the subgroups, e.g. A01J 5/01.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,105.24,730.14,407.76,6.99;2,90.00,739.60,46.86,6.99"><p>Parsing output from these sections was incomplete for the whole corpus and not used for the subsequent experiments.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,110.48,295.98,178.54,8.74" xml:id="b0">
	<monogr>
		<ptr target="http://www.ir-facility.org/" />
		<title level="m" coord="6,110.48,295.98,50.30,8.74">Home -IRF</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,315.39,402.52,8.74;6,110.48,327.35,402.53,8.74;6,110.48,339.30,402.52,8.74;6,110.48,351.26,402.52,8.74;6,110.48,363.21,249.79,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,343.57,315.39,122.91,8.74">Searching clef-ip by strategy</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Alink</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Roberto</forename><surname>Cornacchia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Arjen</forename><surname>De</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vries</forename></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-15754-756</idno>
	</analytic>
	<monogr>
		<title level="m" coord="6,243.36,339.30,269.64,8.74;6,110.48,351.26,51.59,8.74">Multilingual Information Access Evaluation I. Text Retrieval Experiments</title>
		<title level="s" coord="6,242.61,351.26,155.23,8.74">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Giorgio</forename><surname>Di Nunzio</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mikko</forename><surname>Kurimo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thomas</forename><surname>Mandl</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Djamel</forename><surname>Mostefa</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Anselmo</forename><surname>Peas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Giovanna</forename><surname>Roda</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin / Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6241</biblScope>
			<biblScope unit="page" from="468" to="475" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,382.62,402.52,8.74;6,110.48,394.58,402.52,8.74;6,110.48,406.53,354.66,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,362.29,382.62,150.70,8.74;6,110.48,394.58,98.13,8.74">Phrases or Terms? The Impact of Different Query Types</title>
		<author>
			<persName coords=""><forename type="first">Daniela</forename><surname>Becks</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Womser-Hacker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,234.86,394.58,278.14,8.74;6,110.48,406.53,284.61,8.74">Proceedings of the Conference on Multilingual and Multimodal Information Access Evaluation (CLEF 2010)</title>
		<meeting>the Conference on Multilingual and Multimodal Information Access Evaluation (CLEF 2010)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page">99</biblScope>
		</imprint>
	</monogr>
	<note>CLEF-IP workshop</note>
</biblStruct>

<biblStruct coords="6,110.48,425.94,402.52,8.74;6,110.48,437.90,402.52,8.74;6,110.48,449.85,402.52,8.74;6,110.48,461.81,212.65,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,368.86,425.94,144.14,8.74;6,110.48,437.90,60.28,8.74">The Stanford typed dependencies representation</title>
		<author>
			<persName coords=""><forename type="first">Marie-Catherine</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christopher</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,191.04,437.90,321.96,8.74;6,110.48,449.85,248.06,8.74">Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation -CrossParser &apos;08, number ii</title>
		<meeting><address><addrLine>Morristown, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,481.22,285.22,8.74" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><surname>Irf</surname></persName>
		</author>
		<title level="m" coord="6,135.09,481.22,128.33,8.74">Clef Ip 2011 Track Guidelines</title>
		<imprint>
			<publisher>IRF</publisher>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="6,110.48,500.63,402.53,8.74;6,110.48,512.59,402.53,8.74;6,110.48,524.54,402.52,8.74;6,110.48,536.50,402.52,8.74;6,110.48,548.45,75.30,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,454.19,500.63,58.82,8.74;6,110.48,512.59,110.95,8.74">Phrase-Based Document Categorization</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">A</forename><surname>Cornelis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean</forename><forename type="middle">G</forename><surname>Koster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Suzan</forename><surname>Beney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Merijn</forename><surname>Verberne</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Vogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,234.42,524.54,226.15,8.74;6,121.53,536.50,250.64,8.74">The Kluwer International Series on Information Retrieval</title>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mihai</forename><surname>Lupu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Katja</forename><surname>Mayer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">John</forename><surname>Tait</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Anthony</forename><forename type="middle">J</forename><surname>Trippe</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="263" to="286" />
		</imprint>
	</monogr>
	<note>Current Challenges in Patent Information Retrieval</note>
</biblStruct>

<biblStruct coords="6,110.48,567.86,402.53,8.74;6,110.48,579.82,402.52,8.74;6,110.48,591.77,223.48,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,368.91,567.86,144.09,8.74;6,110.48,579.82,102.49,8.74">Multi-classification of patent applications with Winnow</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">A</forename><surname>Cornelis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marc</forename><surname>Koster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean</forename><forename type="middle">G</forename><surname>Seutter</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Beney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,238.78,579.82,274.22,8.74;6,110.48,591.77,124.72,8.74">Perspectives of Systems Informatics, 5th International Andrei Ershov Memorial Conference</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="546" to="555" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,611.18,402.52,8.74;6,110.48,623.14,402.52,8.74;6,110.48,635.09,402.52,8.74;6,110.48,647.05,118.09,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,359.78,611.18,153.22,8.74;6,110.48,623.14,182.86,8.74">Constructing a broad-coverage lexicon for text mining in the patent domain</title>
		<author>
			<persName coords=""><forename type="first">Nelleke</forename><surname>Oostdijk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Suzan</forename><surname>Verberne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cornelis</forename><surname>Koster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,316.72,623.14,196.28,8.74;6,110.48,635.09,402.52,8.74;6,110.48,647.05,86.57,8.74">Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC 2010). European Language Resources Association (ELRA)</title>
		<meeting>the Seventh conference on International Language Resources and Evaluation (LREC 2010). European Language Resources Association (ELRA)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,666.46,402.52,8.74;6,110.48,678.41,402.52,8.74;6,110.48,690.37,402.53,8.74;6,110.48,702.32,289.44,8.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,295.25,666.46,217.76,8.74;6,110.48,678.41,63.55,8.74">Patent claim decomposition for improved information extraction</title>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Parapatics</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Dittenbach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,183.34,690.37,329.66,8.74;6,110.48,702.32,162.96,8.74">Current Challenges in Patent Information Retrieval, The Kluwer International Series on Information Retrieval</title>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mihai</forename><surname>Lupu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Katja</forename><surname>Mayer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">John</forename><surname>Tait</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Anthony</forename><forename type="middle">J</forename><surname>Trippe</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,721.73,402.52,8.74;6,110.48,733.69,402.52,8.74;6,110.48,745.64,294.81,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,419.84,721.73,93.17,8.74;6,110.48,733.69,133.48,8.74">Quantifying the challenges in parsing patent claims</title>
		<author>
			<persName coords=""><forename type="first">Suzan</forename><surname>Verberne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Eva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nelleke</forename><surname>Oostdijk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cornelis</forename><surname>Koster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,253.07,733.69,259.92,8.74;6,110.48,745.64,206.10,8.74">Proceedings of the 1st International Workshop on Advances in Patent Information Retrieval (AsPIRe 2010)</title>
		<meeting>the 1st International Workshop on Advances in Patent Information Retrieval (AsPIRe 2010)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="14" to="21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,112.02,402.53,8.74;7,110.48,123.98,402.52,8.74;7,110.48,135.93,402.52,8.74;7,110.48,147.89,138.98,8.74" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,343.06,112.02,169.94,8.74;7,110.48,123.98,177.04,8.74">Patent classification experiments with the Linguistic Classification System LCS</title>
		<author>
			<persName coords=""><forename type="first">Suzan</forename><surname>Verberne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Merijn</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eva D'</forename><surname>Hondt</surname></persName>
		</author>
		<idno>Sl: sn</idno>
	</analytic>
	<monogr>
		<title level="m" coord="7,311.65,123.98,201.35,8.74;7,110.48,135.93,360.75,8.74">Proceedings of the Conference on Multilingual and Multimodal Information Access Evaluation (CLEF 2010)</title>
		<meeting>the Conference on Multilingual and Multimodal Information Access Evaluation (CLEF 2010)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page">49</biblScope>
		</imprint>
	</monogr>
	<note>CLEF-IP workshop</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
