<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,116.04,100.02,370.91,12.62;1,145.81,117.95,311.38,12.62">Patent classification experiments with the Linguistic Classification System LCS in CLEF-IP 2011</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,228.14,155.62,68.41,8.74"><forename type="first">Suzan</forename><surname>Verberne</surname></persName>
							<email>s.verberne@cs.ru.nl</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Foraging Lab</orgName>
								<orgName type="institution">Radboud University Nijmegen</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,319.24,155.62,55.63,8.74"><forename type="first">Eva</forename><surname>D'hondt</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Foraging Lab</orgName>
								<orgName type="institution">Radboud University Nijmegen</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,116.04,100.02,370.91,12.62;1,145.81,117.95,311.38,12.62">Patent classification experiments with the Linguistic Classification System LCS in CLEF-IP 2011</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">844BE513A50E047902984CB072CA75F6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We report the results of a series of classification experiments with the Linguistic Classification System LCS in the context of CLEF-IP 2011. We participated in the main classification task: classifying documents on the subclass level. We investigated (1) the use of different sections (abstract, description, metadata) from the patent documents; (2) adding dependency triples to the bag-of-words representation;</p><p>(3) adding the WIPO corpus to the EPO training data; (4) the use of patent citations in the test data for reranking the classes; and (5) the threshold on the class scores for class selection. We found that adding full descriptions to abstracts gives a clear improvement; the first 400 words of the description also improves classification but to a lesser degree. Adding metadata (applicants, inventors en address) did not improve classification. Adding dependency triples to words gives a much higher recall at the cost of a lower precision but this effect is largely due to the class selection threshold. We did not find an effect from adding the WIPO corpus, nor from reranking with patent citations. In future work, we plan to investigate whether there are other methods for reranking with patent citations that does give an improvement, because we feel that the citations may still give valuable information. Our most important finding however is the importance of the threshold on the class selection. For the current work, we only compared two values for the threshold and the results are much better for 1.0 than for 0.5. The 0.5 threshold gives higher recall in all runs, which was the original motivation for submitting runs with a lower threshold. However, because the much lower precision, the F-scores are lower. We think that there is still some improvement to be gained from proper tuning of the class selection threshold, and the use of a flexible threshold (also taking into account the different text representations). This is part of our future work.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper, we describe the classification experiments that we conducted in the context of the Intellectual Property (IP) track at CLEF 2011 (CLEF-IP<ref type="foot" coords="1,341.10,576.24,3.97,6.12" target="#foot_0">1</ref> ). In 2009, the track was organized for the first time with a prior art retrieval task. In 2010, a classification task was added to the track. In 2011, this task was continued and extented with a new optional sub-task, which is to classify a given patent document up to the subgroup level, when the subclass is given. We only participated in the main classification task: classifying documents on the subclass level.</p><p>The goal of the classification task at CLEF-IP is to classify a given patent document, according to the International Patent Classification system (IPC). For the purpose of the track, the organization released a collection of 2.6 million patent documents from the European Patent Office (EPO), extended with 400,000 documents from the World Intellectual Property Organization (WIPO). These 3 Million documents with content in English, German and French pertain to over 1 Million patents. <ref type="foot" coords="1,166.24,695.79,3.97,6.12" target="#foot_1">2</ref> From the collection, 1,000 documents (the 'topics') per language were held out as test set. The remainder of the corpus constitutes the target data, on which participants could develop their methods.</p><p>In this notebook paper, we describe our classification experiments with the Linguistic Classification System LCS. We only performed mono-lingual classification, training and evaluating our models on English texts only. We evaluate a number of classification variables: (1) the use of different patent sections, <ref type="bibr" coords="2,211.54,162.83,12.73,8.74" target="#b1">(2)</ref> adding dependency triples to the bag-of-words representation, (3) expanding the EPO training corpus with WIPO documents, (4) using patent citations to rerank the selected classes, and (5) tuning the threshold on class selection.</p><p>In Section 2, we describe the data selection, data preparation and the classification settings used. The results from the classification experiments are presented in Section 3, followed by our conclusions in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Classification experiments with LCS</head><p>For our classification experiments, we used the Linguistic Classification System (LCS)<ref type="foot" coords="2,462.59,271.59,3.97,6.12" target="#foot_2">3</ref>  <ref type="bibr" coords="2,470.11,273.17,10.52,8.74" target="#b1">[2,</ref><ref type="bibr" coords="2,482.29,273.17,7.01,8.74" target="#b2">3]</ref>. The LCS can perform both mono-classification (each document is assigned exactly one class label) and multi-classification. In the training phase, the LCS takes as input a file which list the paths to the classification files followed by their classes. After this training phase the LCS can be used for testing the trained classifier on a test collection of documents with known classes (usually held-out training data), or for producing a classification of new documents without known classes.</p><p>Three classifiers have been implemented in the LCS: Naive Bayes, Winnow and SV M light . Last year <ref type="bibr" coords="2,111.24,356.85,9.96,8.74" target="#b5">[6]</ref>, we experimented with both Winnow and SV M light and we found that their classification accuracy scores are comparable but that SV M light is much slower. Therefore, we decided to use Winnow for this year's CLEF-IP experiments. Winnow has a number of parameters that can be tuned: α, β and maxiters (the number of training iterations). Based on the tuning we did last year, we decided to use α = 1.02, β = 0.98 and maxiters = 10.</p><p>In our classification experiments, we compared the following experimental settings:</p><p>1. The use of different sections (abstract, description, metadata) from the patent documents; 2. The use of different document representations for classification, adding dependency triples to the bag-of-words representation. 3. The training corpus selection: EPO only, or EPO and WIPO together; 4. The use of patent citations in the test patents for reranking the assigned classes; 5. The threshold on the class scores for class selection.</p><p>We will explain how we prepared the experiments for each of these comparisons in the following subsections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Corpus preparation: extracting IPC classes and sections</head><p>From all patents in the target data, we extracted the information needed for classification: the IPC-R classes, the textual content from the English abstract and description; and applicants, inventors en address as additional metadata. For each patent, we selected the most recent version which contains all the information needed. <ref type="foot" coords="2,244.49,601.27,3.97,6.12" target="#foot_3">4</ref> Table <ref type="table" coords="2,278.57,602.85,4.98,8.74" target="#tab_0">1</ref> shows the size of the training corpus when particular patent sections are included. We allowed the abstract to be empty if either the description or the metadata sections contains content. As a result, the subcorpus 'abstract and metadata' is the largest: 1,3M documents, some of which only contain metadata. We separately extracted the first 400 words of the description because the experiences from other participants in last year's workshop <ref type="bibr" coords="2,256.08,662.62,10.52,8.74" target="#b4">[5]</ref> taught us that the head of the description is a good alternative to the complete description, which may be too heavy to classify due to its length. We conducted experiments to validate this assumption. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Different document representations: adding triples to words</head><p>In CLEF-IP 2010, we experimented with the addition of dependency triples to the bag-of-words representation, which is generally used in text classification. The results on the 2010 test set were mixed <ref type="bibr" coords="3,120.64,250.73,10.52,8.74" target="#b5">[6]</ref> but in follow-up experiments <ref type="bibr" coords="3,268.41,250.73,9.96,8.74" target="#b2">[3]</ref>, we consistently found a significant improvement in F-score when we added dependency triples to the word-based representation of patent abstracts. This year, we again investigated the improvement that can be gained from adding dependency triples to the bag of words, but we did not limit ourselves to classification of abstracts. We parsed the abstracts and the first 400 words of the descriptions with the AEGIR dependency parser <ref type="bibr" coords="3,493.08,299.45,10.52,8.74" target="#b3">[4,</ref><ref type="bibr" coords="3,505.25,299.45,7.75,8.74" target="#b6">7]</ref> version 1.8.2. AEGIR's output representation is comparable to the Stanford typed dependencies representation <ref type="bibr" coords="3,155.88,323.36,9.96,8.74" target="#b0">[1]</ref>, in the sense that it generates a set of binary relations between words for an input sentence, thereby converting some function words (such as prepositions) to relations. In addition to that, AEGIR performs a number of normalizing transformations, such as passive-toactive transformation. For example, the clause "an inflammatory reaction, caused by the bowel tissue" leads to the same analysis as "the bowel tissue causes an inflammatory reaction". An example of the triple representation can be found in Figure <ref type="figure" coords="3,352.10,383.13,4.98,8.74" target="#fig_0">1</ref> below <ref type="bibr" coords="3,388.63,383.13,9.96,8.74" target="#b5">[6]</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Training corpus selection: adding WIPO data to EPO data</head><p>In text classification, system performance usually goes up when the size of the training set increases. While the CLEF-IP test set only consisted of documents from the EPO corpus, we investigated if adding documents from another corpus, namely the WIPO, to the EPO training set led to improvements in classification accuracy. We added the WIPO corpus to two of our section subcorpora: abstracts and description, and abstracts, description and metadata. Table <ref type="table" coords="3,462.99,700.81,4.98,8.74" target="#tab_2">2</ref> shows the resulting document counts for the training corpora. From the table it is clear that in the WIPO corpus, there are fewer documents with the metadata fields applicants, inventors en address than in the EPO corpus. 2.4 The use of patent citations for reranking the classes Some of the patent files (topics) in the test set contain citations to other EPO patents. We used these citations to rerank the LCS output using the following procedure:</p><p>1. For each topic, we extracted the patents that are cited by the topic (labelled as patcit in the XML file); 2. We looked up each of the citations in the training corpus and extracted their IPC-R classes.</p><p>We found that 562 of the 1,000 topics contains at least one cited patent with one or more IPC-R classes. 3. These 'citation classes' get a vote each time they occur in a cited patent. A vote is worth 1.0 in addition to the LCS score.</p><p>For example, in one of the experiments, LCS selected five classes for the topic EP-1223323-A2, and assigned them the following scores: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">The threshold on the class scores for class selection</head><p>In the case of multi-classification, LCS is flexible with respect to the number of classes that are returned per document. Internally, it produces a full ranking of classes for each document in the test set. The user can regulate the selection of classes with three parameters: (1) a threshold that puts a lower bound on the classification score for a class to be selected, (2) the maximum number of classes selected per document ('maxranks') and (3) the minimum number of classes selected per document ('minranks'). In the experiments on the target data, we kept the selection threshold to 1.0 (which is the default). Based on the average number of classes per document in the target data (2.7 according to <ref type="bibr" coords="4,190.01,664.87,10.30,8.74" target="#b5">[6]</ref>), we decided to set maxranks = 4. Setting minranks = 1 assures that each document is assigned at least one class, even if all classes have a score below the threshold.</p><p>In the submitted runs on the test data, we decided to lower the class selection threshold to 0.5 because the value of 1.0 gives an average of 1.8 classes per test document; setting it at 0.5 gives an average of 3.2 classes. The latter seemed wiser for a recall-oriented task. Also, we increased maxranks to 5. In additional experiments, we evaluated the results for a threshold of 1.0 against the results for the threshold of 0.5. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>For training the classification models, we used the target data with the exception of the 2000 most recent documents in the training corpus, which we used as test set in the development stage.</p><p>A complete overview of the results on the real test data (the 1,000 topics provided by the track organization) is shown in Table <ref type="table" coords="5,227.63,590.11,3.87,8.74" target="#tab_4">3</ref>. As opposed to last year, when we measured standard deviations over multiple runs of the same experiment, we only performed each experiment once this year.</p><p>Our results on the 2010 data showed that standard deviations are small and even small differences in the results tend to be significant because of the large data set <ref type="bibr" coords="5,374.27,625.97,9.96,8.74" target="#b2">[3]</ref>. Figures <ref type="figure" coords="5,140.43,639.48,4.98,8.74">2</ref><ref type="figure" coords="5,145.41,639.48,4.98,8.74">3</ref><ref type="figure" coords="5,145.41,639.48,4.98,8.74">4</ref><ref type="figure" coords="5,145.41,639.48,4.98,8.74">5</ref><ref type="figure" coords="5,150.39,639.48,4.98,8.74">6</ref>at the end of the paper show the effects of different sections, text representation, corpus selection, patent citations and class selection threshold respectively (the five experimental variables that we compare).</p><p>Figure <ref type="figure" coords="5,142.76,676.87,5.73,8.77">2</ref> shows that adding the description to the abstract gives a clear improvement in classification accuracy: from 0.54 to 0.62 in F-score. The effect of adding the first 400 words of the description instead of the complete description, is smaller, giving an F-score of 0.60. Surprisingly, adding metadata (applicants, inventors en address) to the abstracts and descriptions does not give any improvement. This is in contrast with last year's results, when some participants reported significant improvement from adding applicants, inventors en address as metadata <ref type="bibr" coords="5,451.59,736.68,9.96,8.74" target="#b4">[5]</ref>.</p><p>Figure <ref type="figure" coords="6,142.51,103.02,5.73,8.77">3</ref> shows that adding dependency triples to the bag-of-words representation has an effect but whether this is a positive effect highly depends on the evaluation measure used. Recall is higher for the words+triples representation but this comes at the cost of a much lower precision. The experimental setting with the lowest F-score of all, ad400WT, has the highest recall of all runs (0.87). We had a look at the full ranking of the classes and found that for the runs with triples, the class scores are generally higher. This means that more classes get a score above the fixed threshold of 0.5 (in fact, the average number of classes selected per patent for ad400WT is 5.0, which is the maximum number of selected classes). As a result, recall is higher and precision is lower.</p><p>Figure <ref type="figure" coords="6,141.63,211.27,5.73,8.77">4</ref> shows that there is no effect of adding the WIPO documents to the EPO training corpus. More data generally gives better classification results, but in this task and using this data, increasing the number of documents from 650K to 905K did not generate any effect.</p><p>Figure <ref type="figure" coords="6,141.28,247.79,5.73,8.77">5</ref> shows that the use of patent citations in the test data for reranking the classes has no visible effect either. We plan to investigate whether there are other methods for reranking with patent citations that does give an improvement, because we feel that the citations may still give valuable information.</p><p>Figure <ref type="figure" coords="6,141.62,296.26,5.73,8.77">6</ref> shows that the threshold on the class scores for class selection is highly important for the evaluation scores. For the current work, we only compared two values for the threshold, 0.5 and 1.0, and it is clearly visible that the results are much better for 1.0 than for 0.5. The 0.5 threshold gives higher recall in all runs, which was the original motivation for submitting runs with a lower threshold. However, because the much lower precision, the F-scores are lower. The default LCS threshold of 1.0 clearly is the better choice here. We think that there is still some improvement to be gained from proper tuning of the class selection threshold, and the use of a flexible threshold (also taking into account the different text representations). This is part of our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We reported the results of a series of classification experiments in the context of CLEF-IP 2011. We investigated (1) the use of different sections (abstract, description, metadata) from the patent documents; (2) adding dependency triples to the bag-of-words representation; (3) adding the WIPO corpus to the EPO training data; (4) the use of patent citations in the test data for reranking the classes; and (5) the threshold on the class scores for class selection.</p><p>We found that adding full descriptions to abstracts gives a clear improvement; the first 400 words of the description also improves classification but to a lesser degree. Adding metadata (applicants, inventors en address) did not improve classification. Adding dependency triples to words gives a much higher recall at the cost of a lower precision but this effect is largely due to the class selection threshold. We did not find an effect from adding the WIPO corpus, nor from reranking with patent citations. Our most important finding is the importance of the threshold on the class selection. Our future work will be directed at tuning this threshold. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,90.00,550.17,423.00,7.89;3,90.00,561.15,423.00,7.86;3,90.00,572.11,266.88,7.86"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Part of the original text from the abstract of document EP-0011358-A1.txt (left) and the two document representations that we created: words and triples. The classification experiments are performed on either the words representation, or words together with triples.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,97.54,264.37,407.92,7.89"><head>Fig. 2 .Fig. 3 .Fig. 4 .F1Fig. 5 . 5 0F1Fig. 6 .</head><label>234556</label><figDesc>Fig. 2. The effect of different patent sections. Words only, EPO corpus, no reranking, threshold=0.5.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,91.40,99.97,415.98,72.90"><head>Table 1 .</head><label>1</label><figDesc>Number of EPO documents in training corpus when particular patent sections are included.</figDesc><table coords="3,91.40,120.77,211.70,52.10"><row><cell>Sections</cell><cell>Number of docs</cell></row><row><cell>abstracts</cell><cell>855,261</cell></row><row><cell>abstracts and metadata</cell><cell>1,325,364</cell></row><row><cell>abstracts and description</cell><cell>648,441</cell></row><row><cell>abstracts, description and metadata</cell><cell>649,557</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,90.00,99.97,423.00,60.19"><head>Table 2 .</head><label>2</label><figDesc>Number of EPO and WIPO documents in training corpus when particular patent sections are included.</figDesc><table coords="4,91.40,129.99,326.47,30.18"><row><cell>Sections</cell><cell cols="2">No. of EPO docs No. of WIPO docs Total</cell></row><row><cell>abstracts and description</cell><cell>648,441</cell><cell>257,017 905,458</cell></row><row><cell>abstracts, description and metadata</cell><cell>649,557</cell><cell>16,270 665,827</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,90.00,100.47,448.37,391.20"><head>Table 3 .</head><label>3</label><figDesc>Classification results (Precision, Recall and F1) according to trec eval 9.0 for all runs on test set (1,000 topics), sorted by F1. For each measure, the best-scoring setting is printed in boldface.</figDesc><table coords="5,91.40,132.72,446.97,358.95"><row><cell>Run</cell><cell>Sections</cell><cell cols="2">Text representation Corpus</cell><cell>Rerank</cell><cell>Class</cell><cell>P</cell><cell>R</cell><cell>F1</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>with</cell><cell>selection</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>citations?</cell><cell>threshold</cell><cell></cell><cell></cell></row><row><cell>ad400WT</cell><cell>abs, desc400</cell><cell>words+triples</cell><cell>EPO</cell><cell>no</cell><cell>0.5</cell><cell cols="3">0.2995 0.8657 0.4206</cell></row><row><cell cols="2">ad400WTcit abs, desc400</cell><cell>words+triples</cell><cell>EPO</cell><cell>yes</cell><cell>0.5</cell><cell cols="3">0.2995 0.8657 0.4206</cell></row><row><cell>ad400WT1</cell><cell>abs, desc400</cell><cell>words+triples</cell><cell>EPO</cell><cell>no</cell><cell>1.0</cell><cell cols="3">0.3957 0.8457 0.4932</cell></row><row><cell>aWT</cell><cell>abs</cell><cell>words+triples</cell><cell>EPO</cell><cell>no</cell><cell>0.5</cell><cell cols="3">0.4522 0.7778 0.5275</cell></row><row><cell>amWTcit</cell><cell>abs, meta</cell><cell>words+triples</cell><cell>EPO</cell><cell>yes</cell><cell>0.5</cell><cell cols="3">0.4441 0.8039 0.5311</cell></row><row><cell>amWT</cell><cell>abs, meta</cell><cell>words+triples</cell><cell>EPO</cell><cell>no</cell><cell>0.5</cell><cell cols="3">0.4485 0.7984 0.5313</cell></row><row><cell>aW</cell><cell>abs</cell><cell>words</cell><cell>EPO</cell><cell>no</cell><cell>0.5</cell><cell cols="3">0.4764 0.7644 0.5412</cell></row><row><cell>aWcit</cell><cell>abs</cell><cell>words</cell><cell>EPO</cell><cell>yes</cell><cell>0.5</cell><cell cols="3">0.474 0.7728 0.543</cell></row><row><cell>amW</cell><cell>abs, meta</cell><cell>words</cell><cell>EPO</cell><cell>no</cell><cell>0.5</cell><cell cols="3">0.4744 0.7828 0.5441</cell></row><row><cell>ad400W</cell><cell>abs, desc400</cell><cell>words</cell><cell>EPO</cell><cell>no</cell><cell>0.5</cell><cell cols="3">0.5197 0.8431 0.5981</cell></row><row><cell>admWOW</cell><cell cols="2">abs, desc, meta words</cell><cell cols="2">EPO+WIPO no</cell><cell>0.5</cell><cell cols="3">0.5359 0.8531 0.6118</cell></row><row><cell cols="3">admWOWcit abs, desc, meta words</cell><cell cols="2">EPO+WIPO yes</cell><cell>0.5</cell><cell cols="3">0.5321 0.8625 0.6131</cell></row><row><cell>admWcit</cell><cell cols="2">abs, desc, meta words</cell><cell>EPO</cell><cell>yes</cell><cell>0.5</cell><cell cols="3">0.5379 0.8563 0.6168</cell></row><row><cell>admW</cell><cell cols="2">abs, desc, meta words</cell><cell>EPO</cell><cell>no</cell><cell>0.5</cell><cell cols="3">0.5436 0.8506 0.6186</cell></row><row><cell>adW</cell><cell>abs, desc</cell><cell>words</cell><cell>EPO</cell><cell>no</cell><cell>0.5</cell><cell cols="3">0.5518 0.8459 0.6231</cell></row><row><cell>aW1</cell><cell>abs</cell><cell>words</cell><cell>EPO</cell><cell>no</cell><cell>1.0</cell><cell cols="3">0.6893 0.6435 0.6235</cell></row><row><cell>adWcit</cell><cell>abs, desc</cell><cell>words</cell><cell>EPO</cell><cell>yes</cell><cell>0.5</cell><cell cols="3">0.5485 0.8555 0.6249</cell></row><row><cell>adWOW</cell><cell>abs, desc</cell><cell>words</cell><cell cols="2">EPO+WIPO no</cell><cell>0.5</cell><cell cols="3">0.553 0.8505 0.6252</cell></row><row><cell>adWOWcit</cell><cell>abs, desc</cell><cell>words</cell><cell cols="2">EPO+WIPO yes</cell><cell>0.5</cell><cell cols="3">0.5489 0.8583 0.6254</cell></row><row><cell>amW1</cell><cell>abs, meta</cell><cell>words</cell><cell>EPO</cell><cell>no</cell><cell>1.0</cell><cell cols="3">0.6993 0.6472 0.6302</cell></row><row><cell>aWT1</cell><cell>abs</cell><cell>words+triples</cell><cell>EPO</cell><cell>no</cell><cell>1.0</cell><cell cols="3">0.7068 0.6627 0.6425</cell></row><row><cell>amWT1</cell><cell>abs, meta</cell><cell>words+triples</cell><cell>EPO</cell><cell>no</cell><cell>1.0</cell><cell cols="3">0.7173 0.6726 0.6513</cell></row><row><cell cols="3">admWOW1 abs, desc, meta words</cell><cell cols="2">EPO+WIPO no</cell><cell>1.0</cell><cell cols="3">0.7198 0.7492 0.6890</cell></row><row><cell cols="3">admWOWcit1 abs, desc, meta words</cell><cell cols="2">EPO+WIPO yes</cell><cell>1.0</cell><cell cols="3">0.7056 0.7744 0.6925</cell></row><row><cell>ad400W1</cell><cell>abs, desc400</cell><cell>words</cell><cell>EPO</cell><cell>no</cell><cell>1.0</cell><cell cols="3">0.7416 0.7328 0.6926</cell></row><row><cell>admW1</cell><cell cols="2">abs, desc, meta words</cell><cell>EPO</cell><cell>no</cell><cell>1.0</cell><cell cols="3">0.7352 0.7419 0.6932</cell></row><row><cell>adW1</cell><cell>abs, desc</cell><cell>words</cell><cell>EPO</cell><cell>no</cell><cell>1.0</cell><cell cols="3">0.7374 0.737 0.6939</cell></row><row><cell>adWcit1</cell><cell>abs, desc</cell><cell>words</cell><cell>EPO</cell><cell>yes</cell><cell>1.0</cell><cell cols="3">0.7229 0.7649 0.6991</cell></row><row><cell>adWOW1</cell><cell>abs, desc</cell><cell>words</cell><cell cols="2">EPO+WIPO no</cell><cell>1.0</cell><cell cols="3">0.7443 0.7501 0.7025</cell></row><row><cell cols="2">adWOWcit1 abs, desc</cell><cell>words</cell><cell cols="2">EPO+WIPO yes</cell><cell>1.0</cell><cell cols="3">0.7265 0.7754 0.7059</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,99.96,715.44,131.62,7.86"><p>http://www.ir-facility.org/clef-ip</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,99.96,726.40,413.04,7.86;1,99.96,737.36,98.50,7.86"><p>A patent is the name for a group of patent documents that relate to the same invention; they have the same patent ID number.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,99.96,704.48,413.04,7.86;2,99.96,715.44,160.72,7.86"><p>A demo of the application can be found at http://ir-facility.net/news/linguistic-classification-systemprototype/ for registered IRF members.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="2,92.74,724.63,3.65,5.24;2,99.96,726.40,413.04,7.86;2,99.96,737.36,217.51,7.86"><p><ref type="bibr" coords="2,92.74,724.63,3.65,5.24" target="#b3">4</ref> E.g. in the corpus directory EP/000000/00/59/01/, EP-0005901-A3.xml is newer than EP-0005901-A2.xml and both are newer than EP-0005901-B1.xml.</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,93.58,648.38,419.42,7.86;6,102.15,659.34,410.85,7.86;6,102.15,670.30,216.15,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,266.90,648.38,197.24,7.86">The Stanford typed dependencies representation</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">C</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,487.12,648.38,25.88,7.86;6,102.15,659.34,381.06,7.86">Coling 2008: Proceedings of the workshop on Cross-Framework and Cross-Domain Parser Evaluation</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,93.58,681.91,419.41,7.86;6,102.15,692.87,231.64,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,281.72,681.91,226.16,7.86">Multi-classification of patent applications with Winnow</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H A</forename><surname>Koster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Seutter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Beney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s" coord="6,102.15,692.87,140.53,7.86">Lecture Notes in Computer Science</title>
		<imprint>
			<biblScope unit="page" from="545" to="554" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,93.58,704.48,419.42,7.86;6,102.15,715.44,410.86,7.86;6,102.15,726.40,410.85,7.86;6,102.15,737.36,330.53,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,413.56,704.48,99.45,7.86;6,102.15,715.44,57.36,7.86">Phrase-Based Document Categorization</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">A</forename><surname>Cornelis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean</forename><forename type="middle">G</forename><surname>Koster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Suzan</forename><surname>Beney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Merijn</forename><surname>Verberne</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Vogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,135.48,726.40,209.91,7.86;6,408.79,726.40,104.21,7.86;6,102.15,737.36,126.49,7.86">The Kluwer International Series on Information Retrieval</title>
		<editor>
			<persName><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mihai</forename><surname>Lupu</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Katja</forename><surname>Mayer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">John</forename><surname>Tait</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Anthony</forename><forename type="middle">J</forename><surname>Trippe</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="263" to="286" />
		</imprint>
	</monogr>
	<note>Current Challenges in Patent Information Retrieval</note>
</biblStruct>

<biblStruct coords="7,93.58,103.73,419.41,7.86;7,102.15,114.69,410.85,7.86;7,102.15,125.65,402.04,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,347.45,103.73,165.55,7.86;7,102.15,114.69,131.95,7.86">Constructing a broad coverage lexicon for text mining in the patent domain</title>
		<author>
			<persName coords=""><forename type="first">Nelleke</forename><surname>Oostdijk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Suzan</forename><surname>Verberne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">A</forename><surname>Cornelis</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Koster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,253.70,114.69,259.30,7.86;7,102.15,125.65,372.91,7.86">Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC 2010). European Language Resources Association (ELRA)</title>
		<meeting>the Seventh conference on International Language Resources and Evaluation (LREC 2010). European Language Resources Association (ELRA)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,93.58,136.61,419.42,7.86;7,102.15,147.57,245.26,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,215.41,136.61,292.71,7.86">CLEF-IP 2010: Retrieval Experiments in the Intellectual Property Domain</title>
		<author>
			<persName coords=""><forename type="first">Florina</forename><surname>Piroi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Tait</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,113.67,147.57,205.45,7.86">CLEF 2010 LABs and Workshops Notebook Papers</title>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,93.58,158.53,419.41,7.86;7,102.15,169.49,410.85,7.86;7,102.15,180.45,239.98,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,268.30,158.53,244.70,7.86;7,102.15,169.49,81.20,7.86">Patent classification experiments with the Linguistic Classification System LCS</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Verberne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Vogel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Dhondt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,206.57,169.49,306.44,7.86;7,102.15,180.45,211.54,7.86">Proceedings of the Conference on Multilingual and Multimodal Information Access Evaluation (CLEF 2010)</title>
		<meeting>the Conference on Multilingual and Multimodal Information Access Evaluation (CLEF 2010)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note>CLEF-IP workshop</note>
</biblStruct>

<biblStruct coords="7,93.58,191.40,419.41,7.86;7,102.15,202.36,410.85,7.86;7,102.15,213.32,231.43,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,404.10,191.40,108.90,7.86;7,102.15,202.36,101.87,7.86">Quantifying the Challenges in Parsing Patent Claims</title>
		<author>
			<persName coords=""><forename type="first">Suzan</forename><surname>Verberne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Eva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nelleke</forename><surname>Oostdijk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">A</forename><surname>Cornelis</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Koster</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,226.77,202.36,286.23,7.86;7,102.15,213.32,149.36,7.86">Proceedings of the 1st International Workshop on Advances in Patent Information Retrieval (AsPIRe 2010)</title>
		<meeting>the 1st International Workshop on Advances in Patent Information Retrieval (AsPIRe 2010)</meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="14" to="21" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
