<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,143.80,115.96,327.76,12.62;1,179.33,133.89,256.69,12.62">Three Statistical Summarizers at CLEF-INEX 2014 Tweet Contextualization Track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,240.42,171.56,123.71,8.74"><forename type="first">Juan-Manuel</forename><surname>Torres-Moreno</surname></persName>
							<email>juan-manuel.torres@univ-avignon.fr</email>
							<affiliation key="aff0">
								<orgName type="department">École Polytechnique de Montréal -Département de Génie Informatique CP</orgName>
								<address>
									<addrLine>6079 Succ. Centre Ville</addrLine>
									<postCode>H3C 3A7</postCode>
									<settlement>Montréal (</settlement>
									<region>Québec)</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Université d&apos;Avignon et des Pays de</orgName>
								<address>
									<addrLine>Vaucluse ; BP</addrLine>
									<postBox>911228</postBox>
									<postCode>84911, Cedex 9</postCode>
									<settlement>Avignon</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,143.80,115.96,327.76,12.62;1,179.33,133.89,256.69,12.62">Three Statistical Summarizers at CLEF-INEX 2014 Tweet Contextualization Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5660C88D426C7D53F17FCBFEF0D611A6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>INEX</term>
					<term>Automatic Text Summarization</term>
					<term>Tweet contextualization</term>
					<term>Cortex</term>
					<term>Artex</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>According to the organizers, the objective of the 2014 CLEF-INEX Tweet Contextualization Task is: "...The Tweet Contextualization aims at providing automatically information -a summary that explains the tweet. This requires combining multiple types of processing from information retrieval to multi-document summarization including entity linking." We present three statistical summarizer systems applied to the CLEF-INEX 2014 task. Cortex summarizer uses several sentence selection metrics and an optimal decision module to score sentences from a document source. Artex summarizer uses a simple inner product among the topic-vector and the pseudo-word vector. Reg summarizer is a performant graph-based summarizer. The results show that our systems performed well on CLEF-INEX task. Our three systems have obtained the first rank in the INEX manual evaluation.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Automatic text summarization is indispensable to cope with ever increasing volumes of valuable information. An abstract is by far the most concrete and most recognized kind of text condensation <ref type="bibr" coords="1,298.21,541.99,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="1,310.39,541.99,7.01,8.74" target="#b1">2]</ref>. We adopted a simpler method, usually called extraction, that allows to generate summaries by extraction of relevant sentences <ref type="bibr" coords="1,177.68,565.90,7.75,8.74" target="#b1">[2]</ref><ref type="bibr" coords="1,185.43,565.90,3.87,8.74" target="#b2">[3]</ref><ref type="bibr" coords="1,185.43,565.90,3.87,8.74" target="#b3">[4]</ref><ref type="bibr" coords="1,189.30,565.90,7.75,8.74" target="#b4">[5]</ref>. Essentially, extracting aims at producing a shorter version of the text by selecting the most relevant sentences of the original text, which we juxtapose without any modification. The vector space model <ref type="bibr" coords="1,394.47,589.81,10.52,8.74" target="#b5">[6,</ref><ref type="bibr" coords="1,406.65,589.81,7.75,8.74" target="#b6">7]</ref> has been used in information extraction, information retrieval, question-answering, and it may also be used in text summarization <ref type="bibr" coords="1,287.18,613.72,9.96,8.74" target="#b7">[8]</ref>. Cortex<ref type="foot" coords="1,340.19,612.15,3.97,6.12" target="#foot_0">3</ref> is an automatic summarization system <ref type="bibr" coords="1,167.97,625.68,10.52,8.74" target="#b8">[9]</ref> which combines several statistical methods with an optimal decision algorithm, to choose the most relevant sentences.</p><p>An open domain Question-Answering system (QA) has to exactly answer a question expressed in natural language. QA systems are confronted with a fine and difficult task because they are expected to supply specific information and not whole documents. Currently there exists a strong demand for this kind of text processing systems on the Internet. A QA system comprises, a priori, the following stages <ref type="bibr" coords="2,206.28,178.77,14.61,8.74" target="#b9">[10]</ref>:</p><p>-Transform the questions into queries, then associate them to a set of documents; -Filter and sort these documents to compute various degrees of similarity; -Identify the sentences which might contain the answers, then extract text fragments from those that constitute the answers. In this phase an analysis using Named Entities (NE) is essential to find the expected answers.</p><p>Most research efforts in summarization emphasize generic summarization <ref type="bibr" coords="2,134.77,292.03,12.45,8.74" target="#b10">[11]</ref><ref type="bibr" coords="2,147.22,292.03,4.15,8.74" target="#b11">[12]</ref><ref type="bibr" coords="2,151.37,292.03,12.45,8.74" target="#b12">[13]</ref>. User query terms are commonly used in information retrieval tasks. However, there are few papers in literature that propose to employ this approach in summarization systems <ref type="bibr" coords="2,252.62,315.94,12.45,8.74" target="#b13">[14]</ref><ref type="bibr" coords="2,265.07,315.94,4.15,8.74" target="#b14">[15]</ref><ref type="bibr" coords="2,269.22,315.94,12.45,8.74" target="#b15">[16]</ref>. In the systems described in <ref type="bibr" coords="2,414.72,315.94,14.61,8.74" target="#b13">[14]</ref>, a learning approach is used (performed). A document set is used to train a classifier that estimates the probability that a given sentence is included in the extract. In <ref type="bibr" coords="2,462.34,339.85,14.61,8.74" target="#b14">[15]</ref>, several features (document title, location of a sentence in the document, cluster of significant words and occurrence of terms present in the query) are applied to score the sentences. In <ref type="bibr" coords="2,254.08,375.72,15.50,8.74" target="#b15">[16]</ref> learning and feature approaches are combined in a two-step system: a training system and a generator system. Score features include short length sentence, sentence position in the document, sentence position in the paragraph, and tf.idf metrics. Our generic summarization system includes a set of eleven independent metrics combined by a Decision Algorithm. Query-based summaries can be generated by our systems using a modification of the scoring method. In both cases, no training phase is necessary in our system. This paper is organized as follows. In Section 2 we explain the CLEF-INEX 2014 Tweet Contextualization Track. In Section 3.1 we explain the methodology of our work. Experimental settings and results obtained with Cortex summarizer are presented in Section 5. Section 7 exposes the conclusions of the paper and the future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">INEX 2014 Tweet Contextualization Track</head><p>The Initiative for the Evaluation of XML Retrieval (INEX) is an established evaluation forum for XML information retrieval (IR) <ref type="bibr" coords="2,372.99,577.02,14.60,8.74" target="#b16">[17]</ref>. In 2014, tweet contextualization INEX task at CLEF, aims "given a new tweet, the system must provide some context about the subject of the tweet, in order to help the reader to understand it. This context should take the form of a readable summary, not exceeding 500 words, composed of passages from a provided Wikipedia corpus." <ref type="foot" coords="2,175.72,635.22,3.97,6.12" target="#foot_1">4</ref>Like in iNEX Question Answering track 2011, 2012 and 2013, the present task is about contextualizing tweets, i.e. answering questions of the form "What is this tweet about?" using a recent cleaned dump of the Wikipedia<ref type="foot" coords="3,412.84,141.33,3.97,6.12" target="#foot_2">5</ref> . As organizers claim, the general process involves three steps:</p><p>-Tweet analysis.</p><p>-Passage and/or XML elements retrieval.</p><p>-Construction of the answer.</p><p>Then, a relevant passage segment contains:</p><p>-Relevant information but -As few non-relevant information as possible (the result is specific to the question).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Document Collection</head><p>The corpus has been rebuilt in 2013 from a dump of the English Wikipedia from November 2012. All notes and bibliographic references were removed to facilitate the extraction of plain text answers. (Notes and bibliographic references are difficult to handle). Organizers kept only non empty Wikipedia pages (pages having at least one section).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Tweets set</head><p>For the Track 2014, a set of 240 tweets in English have been selected by the organizers from CLEF RepLab 2013 together with their related entity. The tweets have &gt;= 80 characters and do not contain urls in order to focus on content analysis.</p><p>In the CLEF-INEXorganizers words: "RepLab provides several annotations for tweets, we selected three types of them: the category (4 distinct), an entity name from the wikipedia (61 distinct) and a manual topic label (235 distinct). The entity name should be used as an entry point into wikipedia or DbPedia and gives the contextual perspective. The usefulness of topic labels for this automatic task is an open question at this moment because of their variety".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Summarization System</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Cortex Summarizer</head><p>Cortex <ref type="bibr" coords="3,168.50,590.82,15.50,8.74" target="#b17">[18,</ref><ref type="bibr" coords="3,185.66,590.82,12.73,8.74" target="#b18">19]</ref> is a single-document extract summarization system. It uses an optimal decision algorithm that combines several metrics. These metrics result from processing statistical and informational algorithms on the document vector space representation.</p><p>The INEX 2014 Tweet Contextualization Track evaluation is a real-world complex question (called long query) answering, in which the answer is a summary constructed from a set of relevant documents. The documents are parsed to create a corpus composed of the query and the the multi-document retrieved by a Perl program supplied by INEX organizers <ref type="foot" coords="4,348.40,165.24,3.97,6.12" target="#foot_3">6</ref> . This program is coupled to Indri system<ref type="foot" coords="4,189.14,177.20,3.97,6.12" target="#foot_4">7</ref> to obtain for each query, 50 documents from the whole corpus.</p><p>The idea is to represent the text in an appropriate vectorial space and apply numeric treatments to it. In order to reduce complexity, a preprocessing is performed to the question and the document: words are filtered, lemmatized and stemmed. The Cortex system uses 11 metrics (see <ref type="bibr" coords="4,385.87,226.59,15.50,8.74" target="#b19">[20,</ref><ref type="bibr" coords="4,403.02,226.59,12.73,8.74" target="#b18">19]</ref> for a detailed description of these metrics) to evaluate the sentence's relevance.</p><p>By example, the topic-sentence overlap measure assigns a higher ranking for the sentences containing question words and makes selected sentences more relevant. The overlap is defined as the normalized cardinality of the intersection between the query word set T and the sentence word set S.</p><formula xml:id="formula_0" coords="4,241.00,304.85,239.59,22.31">Overlap(T, S) = card(S ∩ T ) card(T )<label>(1)</label></formula><p>The system scores each sentence with a decision algorithm that relies on the normalized metrics. Before combining the votes of the metrics, these have been split into two sets: one set contains every metric λ i &gt; 0.5, while the other set contains every metric λ i &lt; 0.5 (values equal to 0.5 are ignored). We then compute two values α and β, which give the sum of distances (positive for α and negative for β) to the threshold 0.5 (the number of metrics is Γ , which is 11 in our experiment):</p><formula xml:id="formula_1" coords="4,243.85,437.47,236.75,30.32">α = Γ i=1 (λ i -0.5); λ i &gt; 0.5<label>(2)</label></formula><formula xml:id="formula_2" coords="4,244.10,472.42,236.50,30.32">β = Γ i=1 (0.5 -λ i ); λ i &lt; 0.5<label>(3)</label></formula><p>The value given to each sentence s given a query q is calculated with:</p><formula xml:id="formula_3" coords="4,235.68,549.06,244.91,36.42">if(α &gt; β) then Score(s, q) = 0.5 + α Γ else Score(s, q) = 0.5 -β Γ<label>(4)</label></formula><p>The Cortex system is applied to each document of a topic and the summary is generated by concatenating higher score sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Artex</head><p>Artex<ref type="foot" coords="5,165.77,141.43,3.97,6.12" target="#foot_5">8</ref> computes the score of each sentence by calculating the inner product between a sentence vector, an average pseudo-sentence vector (the "global topic") and an average pseudo-word vector (the "lexical weight"). The summary is generated concatenating the sentences with the highest scores.</p><p>An average document vector represents the "global topic" of all sentences vectors is constructed. The "lexical weight" for each sentence, i.e. the number of words in the sentence, is obtained. A score for each sentence is calculated using their proximity with the "global topic" and their "lexical weight". Let s µ = (s µ,1 , s µ,2 , . . . , s µ,N ) be a vector of the sentence µ = 1, 2, . . . , ρ. The average pseudo-word vector a = [a µ ], was defined as the average number of occurrences of N words used in the sentence s µ :</p><formula xml:id="formula_4" coords="5,273.10,282.85,207.50,26.65">a µ = 1 N j s µ,j<label>(5)</label></formula><p>and the average pseudo-sentence vector b = [b j ] as the average number of occurrences of each word j used through the ρ sentences:</p><formula xml:id="formula_5" coords="5,275.98,353.48,204.61,26.35">b j = 1 ρ µ s µ,j<label>(6)</label></formula><p>The weight of each sentence is calculated as follows:</p><formula xml:id="formula_6" coords="5,265.13,413.88,215.46,8.77">ω(s) = (s × b) × a (7)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Reg Summarizer</head><p>We create a graph G = (V, A) where S vertices represent sentences and A the set of edges. An edge between two vertices is created if the corresponding sentences have at least one word in common. An adjacency matrix is constructed from the matrix S [P=sentences×N=words] as follows: If the element S i,k = 1 of S matrix (in the phrase i the word k is present), we check the k column. If the element S j,k = 1 we put 1 in a i,j of the adjacency matrix A, which means that i and j sentences share the word k. To extract the heaviest sentence, a variant of tree problem maximum weight has been proposed. The weights are on the vertices; not on the edges. We have built an algorithm inspired on the Kruskal's algorithm <ref type="bibr" coords="5,134.77,571.53,14.61,8.74" target="#b20">[21]</ref>. The proposed algorithm works as follows:</p><p>generate the adjacency matrix A [P ×P ] ; calculating the weight of the vertices, i.e. the sum of the incoming edges of the vertex; calculate the degree of each vertex: i.e. the number of shared words with the other sentences.</p><p>The adjacency matrix A [P ×P ] is generated from the VSM model:</p><formula xml:id="formula_7" coords="6,145.17,148.29,22.80,9.65">a ij =</formula><p>1 if a word used by the sentence i is also used by the sentence j 0 elsewhere</p><p>The solution is based on a calculation greedy search paths. The algorithm Reg performs the following steps:</p><p>1. Select the vertex heavy v 0 , and put it in T . It will be called root. The root is chosen whose degree is &gt;= 2. 2. Add to T the heavy neighbor of v 0 . It will choose among those who are not part of T . 3. Repeat 2 until k have the required vertices. 4. Return the path T .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experiments Settings and Results</head><p>In this study, we used the document sets made available during the Initiative for the Evaluation of XML retrieval (INEX) <ref type="foot" coords="6,329.95,339.11,3.97,6.12" target="#foot_6">9</ref> , in particular on the INEX 2012 Tweet Contextualization Track.</p><p>The strategy of our three summarizer systems to deal multi-document summary problem is quite simple: first, a long single document D is formed by concatenation of all i = 1, ..., n relevant documents provided by Indri engine: d 1 , d 2 , ...d n . The first line of this multi-document D is the tweet T . Each summarizer extracts of D the most relevant sentences following T . Then, this subset of sentences is sorted by the date of documents d i . The summarizer adds sentences into the summary until the word limit is reached. To evaluate the performance of eaxh system on INEX tweet contextualization track, we used the online package available from CLEF-INEX website<ref type="foot" coords="6,289.82,458.84,7.94,6.12" target="#foot_7">10</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>Table <ref type="table" coords="6,163.36,517.94,4.98,8.74" target="#tab_0">1</ref> shows the official results of Informativeness based on sentences. The performances (rank) of our summarizers are: Cortex (Run 356)=9/14, Artex (Run 357)=10/14 and Reg (Run 358)=12/14.</p><p>Table <ref type="table" coords="6,177.24,553.98,4.98,8.74" target="#tab_1">2</ref> shows the official results of Informativeness based on Noun Phrases (NP). The performances (rank) of our summarizers are: Cortex (Run 356)=9/14, Artex (Run 357)=10/14 and Reg (Run 358)=12/14.</p><p>Table <ref type="table" coords="6,177.28,590.02,4.98,8.74" target="#tab_2">3</ref> shows the official results of manual evaluation of CLEF-INEX 2014 contextualization task. The performances (rank) of our summarizers are: Cortex (Run 356)=2/14, Artex (Run 357)=3/14 and Reg (Run 358)=1/22. The results must be interpreted as follow: ). The second one, Artex is based on the inner product of main topic and pseudo-words vectors. The third system is Reg, a graph-based summarizer. Our three summarizers have obtained very good results in manual evaluations. Reg is the better system in terms of readability, syntax, diversity and structure manual evaluations. We show that a simple statistical summarizers without knowledge obtains good performances in this complex summarization and tweet contextualization task. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,206.40,115.91,199.49,114.99"><head>Table 1 .</head><label>1</label><figDesc>Informativeness based on sentences</figDesc><table coords="7,206.40,134.94,199.49,95.96"><row><cell cols="5">Rank Participant Unigrams Bigrams skipgrams</cell></row><row><cell>1</cell><cell>ref2013</cell><cell>0.705</cell><cell>0.794</cell><cell>0.796</cell></row><row><cell>2</cell><cell>ref2014</cell><cell cols="2">0.7528 0.8499</cell><cell>0.8516</cell></row><row><cell>• • •</cell><cell></cell><cell>• • •</cell><cell></cell><cell>• • •</cell></row><row><cell>9</cell><cell cols="3">356 (Cortex) 0.8415 0.9696</cell><cell>0.9702</cell></row><row><cell>10</cell><cell cols="2">357 (Artex) 0.8539</cell><cell>0.97</cell><cell>0.9712</cell></row><row><cell>• • •</cell><cell></cell><cell>• • •</cell><cell></cell><cell>• • •</cell></row><row><cell>12</cell><cell>358 (Reg)</cell><cell cols="2">0.8731 0.9832</cell><cell>0.9841</cell></row><row><cell>• • •</cell><cell></cell><cell>• • •</cell><cell></cell><cell>• • •</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,134.77,256.67,345.84,324.50"><head>Table 2 .</head><label>2</label><figDesc>Informativeness based on NPs In this paper we have presented three statistical summarizer systems applied on CLEF-INEX 2014 Tweet Contextualization Track. The first one, Cortex is based on the fusion process of several different sentence selection metrics. The decision algorithm obtains good scores on the INEX 2014 Tweet Contextualization Track (the decision process is a good strategy without training corpus</figDesc><table coords="7,134.77,275.70,278.19,229.54"><row><cell cols="5">Rank Participant Unigrams Bigrams skipgrams</cell></row><row><cell>1</cell><cell>ref2013</cell><cell cols="2">0.7468 0.8936</cell><cell>0.9237</cell></row><row><cell>2</cell><cell>ref2014</cell><cell>0.7784</cell><cell>0.917</cell><cell>0.9393</cell></row><row><cell>• • •</cell><cell></cell><cell>• • •</cell><cell></cell><cell>• • •</cell></row><row><cell>9</cell><cell cols="2">356 (Cortex) 0.8477</cell><cell>0.971</cell><cell>0.9751</cell></row><row><cell>10</cell><cell cols="3">357 (Artex) 0.8593 0.9709</cell><cell>0.9752</cell></row><row><cell>• • •</cell><cell></cell><cell>• • •</cell><cell></cell><cell>• • •</cell></row><row><cell>12</cell><cell>358 (Reg)</cell><cell>0.8816</cell><cell>0.984</cell><cell>0.9864</cell></row><row><cell>• • •</cell><cell></cell><cell>• • •</cell><cell></cell><cell>• • •</cell></row><row><cell cols="5">-Readable: % of passages considered as readable (Non trash)</cell></row><row><cell cols="5">-Syntax % of passages without syntax or grammatical errors</cell></row><row><cell cols="3">-Diversity % of non redundant passages</cell><cell></cell><cell></cell></row><row><cell cols="4">-Structure % of non breaking anaphora passages</cell><cell></cell></row><row><cell>7 Conclusions</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,147.67,116.41,316.94,117.23"><head>Table 3 .</head><label>3</label><figDesc>Readability results for our systems (runs 356-358)</figDesc><table coords="8,147.67,137.68,316.94,95.96"><row><cell cols="6">Rank System (Run) Readability Syntax Diversity Structure Average</cell></row><row><cell>1</cell><cell>Reg (358)</cell><cell cols="4">94.82% 87.31% 72.17% 93.10% 86.85%</cell></row><row><cell>2</cell><cell>Cortex (356)</cell><cell>95.24%</cell><cell>85.19% 70.31%</cell><cell>92.40%</cell><cell>85.78%</cell></row><row><cell>3</cell><cell>Artex (357)</cell><cell>94.88%</cell><cell>82.53% 71.34%</cell><cell>91.58%</cell><cell>85.08%</cell></row><row><cell>• • •</cell><cell></cell><cell></cell><cell>• • •</cell><cell></cell><cell>• • •</cell></row><row><cell>6</cell><cell>Ref'13</cell><cell>91.74%</cell><cell>69.82% 60.52%</cell><cell>85.80%</cell><cell>76.97%</cell></row><row><cell>7</cell><cell>Ref'12</cell><cell>91.39%</cell><cell>69.58% 60.67%</cell><cell>85.56%</cell><cell>76.80%</cell></row><row><cell>• • •</cell><cell></cell><cell></cell><cell>• • •</cell><cell></cell><cell>• • •</cell></row><row><cell>14</cell><cell>(370)</cell><cell>90.10%</cell><cell>68.30% 53.83%</cell><cell>80.70%</cell><cell>73.23%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="1,144.73,656.80,335.86,7.86"><p>CORTEX es Otro Resumidor de TEXtos (CORTEX is anotheR TEXt summarizer).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="2,144.73,657.44,207.61,7.47"><p>https://inex.mmci.uni-saarland.de/tracks/qa/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="3,144.73,645.84,335.86,8.11;3,144.73,657.44,181.94,7.47"><p>See the official CLEF-INEX 2014 Tweet Contextualization Track Website: https: //inex.mmci.uni-saarland.de/tracks/qa/.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3" coords="4,144.73,623.92,259.01,8.11"><p>See: http://qa.termwatch.es/data/getINEX2011corpus.pl.gz</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4" coords="4,144.73,634.88,335.85,7.86;4,144.73,645.84,335.85,7.86;4,144.73,656.80,332.19,8.11"><p>Indri is a search engine from the Lemur project, a cooperative work between the University of Massachusetts and Carnegie Mellon University in order to build language modelling information retrieval tools. See: http://www.lemurproject.org/indri/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_5" coords="5,144.73,656.80,200.01,8.37"><p>In French, Artex is Autre Résumeur de TEXtes.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_6" coords="6,144.73,646.48,160.54,7.47"><p>https://inex.mmci.uni-saarland.de/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_7" coords="6,144.73,657.44,131.80,7.47"><p>http://qa.termwatch.es/data/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,142.96,299.08,74.67,7.86;8,256.50,299.08,82.96,7.86;8,385.56,299.08,95.01,7.86;8,151.52,310.04,329.05,7.86" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="8,178.95,299.08,38.68,7.86;8,256.50,299.08,82.96,7.86;8,385.56,299.08,63.57,7.86">American Standard for Writing Technical report</title>
		<author>
			<persName coords=""><surname>Ansi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
			<publisher>American National Standards Institute, Inc</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
	<note>ANSI Z39.14.1979</note>
</biblStruct>

<biblStruct coords="8,142.96,321.59,337.63,7.86;8,151.52,332.54,95.50,7.86" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="8,236.56,321.59,240.44,7.86">Resume automatique de documents : une approche statistique</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Torres-Moreno</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Hermes-Lavoisier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,344.09,337.63,7.86;8,151.52,355.05,172.65,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,207.12,344.09,198.23,7.86">The Automatic Creation of Literature Abstracts</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">P</forename><surname>Luhn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,416.07,344.09,64.52,7.86;8,151.52,355.05,105.70,7.86">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">159</biblScope>
			<date type="published" when="1958">1958</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,366.59,337.63,7.86;8,151.52,377.55,121.86,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,231.06,366.59,157.92,7.86">New Methods in Automatic Extracting</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">P</forename><surname>Edmundson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,398.22,366.59,82.37,7.86;8,151.52,377.55,31.17,7.86">Journal of the ACM (JACM)</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="264" to="285" />
			<date type="published" when="1969">1969</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,389.10,337.63,7.86;8,151.52,400.06,80.11,7.86" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="8,260.67,389.10,171.94,7.86">Advances in automatic text summarization</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Mani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mayburi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>The MIT Press</publisher>
			<pubPlace>U.S.A.</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,411.60,337.62,7.86;8,151.52,422.56,170.90,7.86" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="8,219.25,411.60,261.33,7.86;8,151.52,422.56,68.41,7.86">The SMART Retrieval System -Experiments un Automatic Document Processing</title>
		<author>
			<persName coords=""><forename type="first">Gregory</forename><surname>Salton</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971">1971</date>
			<pubPlace>Englewood Cliffs</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,434.10,337.63,7.86;8,151.52,445.06,78.67,7.86" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="8,289.63,434.10,187.13,7.86">Introduction to Modern Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Gregory</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mcgill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>McGraw-Hill</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,456.61,337.62,7.86;8,151.52,467.57,329.05,7.86;8,151.52,478.53,329.07,7.86;8,151.52,489.49,173.52,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,216.51,467.57,264.06,7.86;8,151.52,478.53,88.85,7.86">A new hybrid summarizer based on vector space model, statistical physics and linguistics</title>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">Da</forename><surname>Cunha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Velázquez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Morales</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Vivaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Sanjuan</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Torres-Moreno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,259.62,478.53,192.10,7.86">MICAI 2007: Advances in Artificial Intelligence</title>
		<meeting><address><addrLine>Berlin/Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="872" to="882" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.96,501.03,337.62,7.86;8,151.52,511.99,329.06,7.86;8,151.52,522.95,287.19,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,402.33,501.03,78.24,7.86;8,151.52,511.99,61.15,7.86">Condensés automatiques de textes</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Torres-Moreno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Velazquez-Morales</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Meunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,219.95,511.99,260.64,7.86;8,151.52,522.95,66.11,7.86">Lexicometrica. L&apos;analyse de données textuelles : De l&apos;enquête aux corpus littéraires</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
	<note>www.cavi.univ-paris3.fr/lexicometrica</note>
</biblStruct>

<biblStruct coords="8,142.61,534.49,337.96,7.86;8,151.52,545.45,329.06,7.86;8,151.52,556.41,119.64,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,307.70,534.49,172.88,7.86;8,151.52,545.45,138.87,7.86">Traitement automatique des langues pour l&apos;accès au contenu des documents</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Jacquemin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zweigenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,303.56,545.45,177.02,7.86;8,151.52,556.41,51.20,7.86">Le document en sciences du traitement de l&apos;information</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="71" to="109" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,567.96,337.96,7.86;8,151.52,578.91,329.06,7.86;8,151.52,589.87,272.53,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,319.79,567.96,160.78,7.86;8,151.52,578.91,186.23,7.86">Statistical Methods for Retrieving Most Significant Paragraphs in Newspaper Articles</title>
		<author>
			<persName coords=""><forename type="first">Jose</forename><surname>Abracos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gabriel</forename><forename type="middle">Pereira</forename><surname>Lopes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,225.60,589.87,72.90,7.86">ACL/EACL97-WS</title>
		<editor>
			<persName><forename type="first">Inderjeet</forename><surname>Mani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mark</forename><forename type="middle">T</forename><surname>Maybury</surname></persName>
		</editor>
		<meeting><address><addrLine>Madrid, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997-07-11">July 11 1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,601.42,337.96,7.86;8,151.52,612.38,329.06,7.86;8,151.52,623.34,20.99,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,286.43,601.42,177.11,7.86">Sentence Extraction as a Classification Task</title>
		<author>
			<persName coords=""><forename type="first">Simone</forename><surname>Teufel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marc</forename><surname>Moens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,339.79,612.38,72.90,7.86">ACL/EACL97-WS</title>
		<editor>
			<persName><forename type="first">Inderjeet</forename><surname>Mani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mark</forename><forename type="middle">T</forename><surname>Maybury</surname></persName>
		</editor>
		<meeting><address><addrLine>Madrid, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,634.88,337.96,7.86;8,151.52,645.84,329.06,7.86;8,151.52,656.80,229.27,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,304.57,634.88,176.00,7.86;8,151.52,645.84,34.11,7.86">Automated Text Summarization in SUM-MARIST</title>
		<author>
			<persName coords=""><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chin</forename><surname>Yew</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lin</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,389.19,645.84,91.40,7.86;8,151.52,656.80,79.56,7.86">Advances in Automatic Text Summarization</title>
		<editor>
			<persName><forename type="first">Inderjeet</forename><surname>Mani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mark</forename><forename type="middle">T</forename><surname>Maybury</surname></persName>
		</editor>
		<imprint>
			<publisher>The MIT Press</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="81" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,119.67,337.96,7.86;9,151.52,130.63,329.05,7.86;9,151.52,141.59,303.01,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,364.98,119.67,115.60,7.86;9,151.52,130.63,28.71,7.86">A Trainable Document Summarizer</title>
		<author>
			<persName coords=""><forename type="first">Julian</forename><surname>Kupiec</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jan</forename><forename type="middle">O</forename><surname>Pedersen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Francine</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,199.49,130.63,281.09,7.86;9,151.52,141.59,221.30,7.86">Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="68" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,152.55,337.96,7.86;9,151.52,163.51,329.05,7.86;9,151.52,174.47,329.06,7.86;9,151.52,185.43,69.88,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,368.00,152.55,112.58,7.86;9,151.52,163.51,145.88,7.86">Advantages of Query Biased Summaries in Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Anastasios</forename><surname>Tombros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Phil</forename><surname>Gray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,185.36,174.47,39.56,7.86">AAAI98-S</title>
		<editor>
			<persName><forename type="first">Eduard</forename><surname>Hovy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dragomir</forename><forename type="middle">R</forename><surname>Radev</surname></persName>
		</editor>
		<meeting><address><addrLine>Stanford, California, USA</addrLine></address></meeting>
		<imprint>
			<publisher>The AAAI Press</publisher>
			<date type="published" when="1998">March 23-25 1998</date>
			<biblScope unit="page" from="34" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,196.39,337.96,7.86;9,151.52,207.35,189.01,7.86;9,400.98,207.35,79.59,7.86;9,151.52,218.30,134.69,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,414.14,196.39,66.43,7.86;9,151.52,207.35,189.01,7.86;9,400.98,207.35,58.97,7.86">Using Document Features and Statistical Modeling to Improve Summarization</title>
		<author>
			<persName coords=""><forename type="first">Judith</forename><forename type="middle">D</forename><surname>Schlesinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Deborah</forename><forename type="middle">J</forename><surname>Backer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><forename type="middle">L</forename><surname>Donway</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,151.52,218.30,30.14,7.86">DUC&apos;01</title>
		<meeting><address><addrLine>New Orleans, LA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,229.26,337.98,7.86;9,151.52,240.22,329.06,7.86;9,151.52,251.18,329.05,7.86;9,151.52,262.14,329.06,7.86;9,151.52,273.10,138.65,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,458.48,229.26,22.11,7.86;9,151.52,240.22,329.06,7.86;9,151.52,251.18,175.89,7.86">Comparative Evaluation of Focused Retrieval -9th International Workshop of the Inititative for the Evaluation of XML Retrieval</title>
	</analytic>
	<monogr>
		<title level="m" coord="9,334.34,251.18,43.86,7.86">INEX 2010</title>
		<title level="s" coord="9,413.71,262.14,66.88,7.86;9,151.52,273.10,71.10,7.86">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Shlomo</forename><surname>Geva</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Jaap</forename><surname>Kamps</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ralf</forename><surname>Schenkel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Andrew</forename><surname>Trotman</surname></persName>
		</editor>
		<meeting><address><addrLine>Vugh, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">December 13-15, 2010. 2011</date>
			<biblScope unit="volume">6932</biblScope>
		</imprint>
	</monogr>
	<note>Revised Selected Papers</note>
</biblStruct>

<biblStruct coords="9,142.61,284.06,337.97,7.86;9,151.52,295.02,329.06,7.86;9,151.52,305.98,20.99,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="9,401.46,284.06,79.13,7.86;9,151.52,295.02,201.10,7.86">CORTEX, un algorithme pour la condensation automatique de textes</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Torres-Moreno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Velázquez-Morales</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Meunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,371.29,295.02,21.74,7.86">ARCo</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">365</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,316.94,337.96,7.86;9,151.52,327.89,329.07,7.86;9,151.52,338.85,114.36,7.86" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="9,457.28,316.94,23.29,7.86;9,151.52,327.89,313.34,7.86">Automatic summarization system coupled with a question-answering system (qaas)</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Torres-Moreno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">L</forename><surname>St-Onge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gagnon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>El-Bèze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bellot</surname></persName>
		</author>
		<idno>CoRR, abs/0905.2990</idno>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,349.81,337.98,7.86;9,151.52,360.77,221.14,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="9,401.34,349.81,79.25,7.86;9,151.52,360.77,115.78,7.86">Condensés de textes par des méthodes numériques</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Torres-Moreno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Velazquez-Morales</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Meunier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,275.78,360.77,22.22,7.86">JADT</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="723" to="734" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.61,371.73,337.96,7.86;9,151.52,382.69,20.99,7.86" xml:id="b20">
	<monogr>
		<title level="m" type="main" coord="9,200.13,371.73,55.36,7.86">Graph Theory</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Gould</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988">1988</date>
			<publisher>The Benjamin/Cummings Publishing Company,Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
