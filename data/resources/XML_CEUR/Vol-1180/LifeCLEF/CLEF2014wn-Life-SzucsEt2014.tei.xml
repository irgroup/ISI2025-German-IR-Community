<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,139.10,152.67,317.20,12.64;1,207.65,170.67,180.12,12.64">Viewpoints combined classification method in imagebased plant identification task</title>
				<funder ref="#_4tvaqkZ">
					<orgName type="full">European Union</orgName>
				</funder>
				<funder>
					<orgName type="full">European Social Fund</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,212.09,209.60,50.74,9.05"><forename type="first">Gábor</forename><surname>Szűcs</surname></persName>
							<email>szucs@tmit.bme.hu</email>
							<affiliation key="aff0">
								<orgName type="institution">Inter-University Centre for Telecommunications and Informatics</orgName>
								<address>
									<addrLine>Kassai str. 26</addrLine>
									<postCode>H-4028</postCode>
									<settlement>Debrecen</settlement>
									<country key="HU">Hungary</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,271.11,209.70,46.94,8.96"><forename type="first">Dávid</forename><surname>Papp</surname></persName>
							<email>pappdavid27@gmail.com</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Telecommunications and Media Informatics</orgName>
								<orgName type="institution">Budapest University of Technology and Economics</orgName>
								<address>
									<addrLine>Magyar Tudósok krt. 2</addrLine>
									<postCode>H-1117</postCode>
									<settlement>Budapest</settlement>
									<country key="HU">Hungary</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,326.43,209.70,53.28,8.96"><forename type="first">Dániel</forename><surname>Lovas</surname></persName>
							<email>lovas.daniel@simonyi.bme.hu</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Telecommunications and Media Informatics</orgName>
								<orgName type="institution">Budapest University of Technology and Economics</orgName>
								<address>
									<addrLine>Magyar Tudósok krt. 2</addrLine>
									<postCode>H-1117</postCode>
									<settlement>Budapest</settlement>
									<country key="HU">Hungary</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,139.10,152.67,317.20,12.64;1,207.65,170.67,180.12,12.64">Viewpoints combined classification method in imagebased plant identification task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A1B34994A16E5782C4A82426B02CCEC8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>GMM based Fisher vector</term>
					<term>C-support vector classification</term>
					<term>viewpoint combination</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The image-based plant identification challenge was focused on tree, herbs and ferns species identification based on different types of images. The aim of the task was to produce relevant species for each observation of a plant of the test dataset. We have elaborated a viewpoints combined classification method for this challenge. We have applied dense SIFT for feature detection and description; and Gaussian Mixture Model based Fisher vector was calculated to represent an image with high-level descriptor. The chosen classifier was the C-support vector classification algorithm with RBF (Radial Basis Function) kernel, and we have optimized two hyperparameters (C from C-SVC and γ from RBF kernel) by a grid search with two-dimensional grid. We have constructed a combined classifier using the weighted average of reliability values of classifier at each viewpoint. The results show that our combined method exceeds our best classifier among the list of classifiers constructed for different viewpoints.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.32" lry="841.92"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Accurate knowledge of the identity, statistics and uses of plants is essential in the agricultural development. Identifying plant species is usually a very difficult task, even for professionals (such as farmers or wood exploiters) or for the botanists themselves. Using image retrieval technologies is nowadays considered by botanists as a promising direction in this problem, and in order to solve it a challenge is announced in the LifeCLEF campaign <ref type="bibr" coords="1,209.57,616.19,10.69,8.96" target="#b2">[3]</ref>.</p><p>The image-based plant identification task <ref type="bibr" coords="1,292.37,639.35,11.72,8.96" target="#b6">[7]</ref> was focused on tree, herbs and ferns species identification based on different types of images. There are 7 viewpoints at the images: branch, leaf, scan (scan or scan-like pictures of leaf, briefly "LeafScan"), flower, fruit, stem, and entire views. The number of species was about 500, which is an important step towards covering the entire flora of a given region.</p><p>The aim of the task was to produce a list of relevant species for each observation of a plant of the test dataset, i.e. one or a set of several pictures related to a same event: one same person photographing several detailed views on various organs the same day with the same device with the same lightening conditions observing one same plant. So the task was observation-centered (not image-centered).</p><p>The task was based on the Pl@ntView dataset focusing plants on France (some plants observations came from neighbouring countries). It contains more than 60000 pictures belonging each to one of the 7 types of view reported into the meta-data, in an xml file (one per image) with explicit tags, like ObservationId, species names, date, etc.</p><p>The task was evaluated as a plant species retrieval task based on multi-image plant observations queries. The goal was to retrieve the correct plant species among the top results of a ranked list of species returned by the evaluated system. An observation may contain 1 to 5 images depicting the same individual plant observed by the same person the same day. Each image of a query observation is associated with a single view type (entire plant, branch, leaf, fruit, flower, stem or leaf scan) and with contextual metadata (data, location, and author). Each participating group was allowed to submit up to 4 runs built from different methods.</p><p>User rating information (pictures with the average of the user ratings on image quality) was also available, but we have not used this additional information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Image-based plant classification 2.1 Elaboration of image descriptors</head><p>The first part of the classification is the accomplishment of representation of each image based on the visual content. This consists of three steps: (i) feature detection, (ii) feature description, (iii) image description as usual phases in computer vision.</p><p>Feature detection: Lots of different feature types can be detected in an image, e.g. corners, edges, ridges, as "interesting" part of an image. Furthermore many possible feature extraction methods are available for images, but we have chosen SIFT (Scale-Invariant Feature Transform) algorithm <ref type="bibr" coords="2,275.93,624.35,32.08,8.96">[11][12]</ref>, because this is a widely used method in practice and in theoretical works (as well) with some possible further development of this method.</p><p>Feature description: In our solution we have used dense sampling method with SIFT (briefly dense SIFT). This sampling method can be considered as a two-dimensional grid upon the image, where SIFT descriptors were calculated at each grid point. After that we have used PCA (Principal Component Analysis) <ref type="bibr" coords="3,347.59,189.42,23.36,8.96">[1][9]</ref> to reduce the dimensions of the descriptor vectors from 128 to 80. This descriptor vector belongs to only one "interesting" point of an image, but an image possesses many feature descriptor vectors, which should be aggregated into an image descriptor.</p><p>Image description: The final step of the representation creating is the completion of high level representation of each image. We have applied BoW (bag-of-words) model <ref type="bibr" coords="3,124.70,278.73,12.17,8.96" target="#b5">[6]</ref>[10] for this purpose, where images are treated as documents. According to this, "visual words" (so called "codewords") in images need to be defined from feature descriptors. The whole set of codewords gives the codebook (similarly to dictionary in text tasks). To determine the codebook we used GMM (Gaussian Mixture Model) <ref type="bibr" coords="3,124.70,331.65,31.97,8.96">[15][17]</ref>. This is a parametric probability density function represented as a weighted sum of (in our case 256) Gaussian component densities. GMM parameters were estimated based on the training set by using the iterative EM (Expectation Maximization) algorithm <ref type="bibr" coords="3,165.86,371.37,10.69,8.96" target="#b4">[5]</ref>, but an initial model was needed for EM. In our training procedure the kmeans clustering <ref type="bibr" coords="3,195.26,384.57,16.79,8.96" target="#b12">[13]</ref> was performed over all the vectors with 256 clusters, which resulted the initial model for EM. As a result of the algorithms described above, a codebook with 256 codewords was available for further calculations, which can be considered as a concise representation of the image set. According to the codebook the next step is to create a descriptor that specifies the distribution of the visual codewords in any image, called high-level descriptor. To represent an image with high-level descriptor, the GMM based Fisher vector <ref type="bibr" coords="3,281.21,463.89,16.66,8.96" target="#b13">[14]</ref>[15] was calculated. These vectors were the final representation (image descriptor) of the images. The code used to train GMM vocabularies and compute the Fisher vectors is a standalone C++ library, developed by Jorge Sánchez, to support the research of Visual Geometry Group of Oxford University <ref type="bibr" coords="3,124.70,516.83,10.69,8.96" target="#b7">[8]</ref>. The two hyperparameters (C from C-SVC and γ from RBF kernel) were optimized by a grid search with two-dimensional grid. The algorithm was trained with the training image set, and then validated on the validation set, while the hyperparameters were different in each iteration. The parameter pair that gave the best result is selected to train the final classification model (for each category) based on the whole image set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Training the classifier</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Preliminary testing</head><p>After the training, the codebook was already available and only Fisher vector of each image should be computed. At the preliminary testing we have selected only 50 species (classes) for training and testing as well. RBF based kernel matrix was built from the Fisher vectors of the test and training images. Each C-SVC classifier was parametered with this matrix and the hyperparameters were the same as in the final classification models. Since the classifiers are assigned to species, the generated model for a classifier is responsible to separate the designated class from the other ones. Thus a classifier is able to provide a confidence value showing a certainty of the class in a given image.</p><p>We have trained 7 classifiers for each viewpoint and we have evaluated as preliminary testing based on precision and computer run time. The results of the preliminary testing can be seen in Table <ref type="table" coords="4,208.92,398.73,3.79,8.96" target="#tab_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Viewpoints combination for observation classification</head><p>The decision about the observation could be based on majority voting of image decisions, but we have used continuous information instead of discrete one. C-SVC classifier calculates continuous reliability value for each class at each image, and we have constructed a combined classifier using the weighted average of reliability values. Our combined classifier has applied a formula (as can be seen in Equation <ref type="formula" coords="5,403.25,149.70,3.62,8.96" target="#formula_1">1</ref>.) for the aggregated reliability value that an image belongs to class c (species c).</p><formula xml:id="formula_0" coords="5,139.50,187.42,331.16,57.71">             p i N n n i p i i i i NVP i i i NVP i i c r N w w c R w w c R , 1<label>7 1 , 7 1 1 1 ) ( 1 1 ) ( 1 ) ( (1)</label></formula><p> NVP is the number of viewpoints, which equals to seven in this challenge  wi is the weight parameter of viewpoint i  rn(c) is reliability value for class c coming from C-SVC classifier  Ni,p is the number of images in viewpoint i taken from the p-th plant observed Based on R(c) values the final decision is always the species that possesses the largest R(c) value. In the challenge the order of predicted species should have been submitted, and we have constructed the order based on R(c) values as well.</p><p>At the estimation of weight parameters we have taken the goodness of different viewpoint classifiers into the consideration. As can be seen in the results of the preliminary testing (at Table <ref type="table" coords="5,193.74,398.49,3.62,8.96" target="#tab_0">1</ref>), the LeafScan has the best precision. So the LeafScan has got the largest weight parameter, and on an empirical way we have chosen the following weight parameters: LeafScan: 7.5, Leaf: 2.5, Flower: 1.5, Fruit: 1.5, Stem: 1.5, Branch: 1.5, Entire: 1.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Evaluation metrics</head><p>In the official evaluation instead of precision (as used in our preliminary testing) a new evaluation metric was defined for measurement of goodness of the observation classification. This metric (S score) is defined as follows.</p><formula xml:id="formula_1" coords="5,233.12,569.97,237.55,38.72">     u P p p u U u u S P U S 1 , 1<label>1 1 (2)</label></formula><p> U : number of users (who have at least one image in the test data)  Pu : number of individual plants observed by the u-th user  Nu,p : number of pictures taken from the p-th plant observed by the u-th user  Su,p : score between 1 and 0 equals to the inverse of the rank of the correct species (for the p-th plant observed by the u-th user)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Final official results</head><p>Simage score can be calculated for each viewpoint, and these scores can be compared. Our final official results for each viewpoint and the observation can be seen in Table <ref type="table" coords="6,124.70,379.29,3.34,8.96" target="#tab_1">2</ref>., and it can be shown that S score of observation exceeds the best S score of all viewpoints. Our final official observation results (BME TMIT) compared with other participants can be seen in Fig. <ref type="figure" coords="6,201.76,630.47,3.76,8.96" target="#fig_1">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We have elaborated a viewpoints combined classification method for image-based plant identification task. We have applied dense SIFT for feature detection and description; and Gaussian Mixture Model based Fisher vector was calculated to represent an image with high-level descriptor. The chosen classifier was the C-support vector classification algorithm with RBF (Radial Basis Function) kernel, and we have optimized two hyperparameters (C from C-SVC and γ from RBF kernel) by a grid search with two-dimensional grid. We have constructed a combined classifier using the weighted average of reliability values of classifier at each viewpoint. The weight parameters of the combined classifier were based on our preliminary testing results. Our observation result of the combined method exceeds our best score of all viewpoints. At the official evaluation our solution has reached 0.255 score value.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,124.70,570.59,345.77,8.96;3,124.70,583.79,345.93,8.96;3,124.70,597.11,345.47,8.96;3,124.70,610.31,345.60,8.96;3,124.70,623.51,345.93,8.96;3,124.70,636.71,345.80,8.96;3,124.70,649.91,345.42,8.96;3,124.70,663.26,345.76,8.96;3,124.70,676.46,252.22,8.96"><head>For the classification task</head><label></label><figDesc>we have divided the labelled image set into three subsets: training, validation and test set (the last one is used for preliminary testing). The validation image set was used for calibration of the trained model during the validation phase of the training procedure. To train the classifier (classification model) based on training image set, a variation of SVM (Support Vector Machine) was used, the C-SVC (C-support vector classification)[2][4]  with RBF (Radial Basis Function) kernel. The SVM is basically a binary linear classifier, thus in order to extend it to a number of classified categories, the one-against-all technique was used. During this method a binary classifier was created for each category in the training set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,199.22,373.46,196.81,8.10;7,124.68,147.36,345.72,210.84"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Final official observation results of participants</figDesc><graphic coords="7,124.68,147.36,345.72,210.84" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,135.74,424.22,328.49,158.09"><head>Table 1 .</head><label>1</label><figDesc>Results of the preliminary testing</figDesc><table coords="4,135.74,441.69,328.49,140.62"><row><cell>viewpoint</cell><cell>precision</cell><cell>testing time (per image)</cell></row><row><cell></cell><cell></cell><cell>[sec]</cell></row><row><cell>Branch</cell><cell>0.341</cell><cell>1.82</cell></row><row><cell>Leaf</cell><cell>0.583</cell><cell>1.59</cell></row><row><cell>LeafScan</cell><cell>0.965</cell><cell>0.95</cell></row><row><cell>Stem</cell><cell>0.492</cell><cell>1.39</cell></row><row><cell>Flower</cell><cell>0.512</cell><cell>1.61</cell></row><row><cell>Entire</cell><cell>0.314</cell><cell>1.44</cell></row><row><cell>Fruit</cell><cell>0.482</cell><cell>1.56</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,192.50,418.10,222.25,166.37"><head>Table 2 .</head><label>2</label><figDesc>Our final official results</figDesc><table coords="6,192.50,435.45,222.25,149.02"><row><cell>viewpoints and observation</cell><cell>S score</cell></row><row><cell>Branch</cell><cell>0.052</cell></row><row><cell>Leaf</cell><cell>0.019</cell></row><row><cell>LeafScan</cell><cell>0.119</cell></row><row><cell>Stem</cell><cell>0.072</cell></row><row><cell>Flower</cell><cell>0.115</cell></row><row><cell>Entire</cell><cell>0.06</cell></row><row><cell>Fruit</cell><cell>0.07</cell></row><row><cell>Observation</cell><cell>0.255</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>The publication was supported by the <rs type="grantNumber">TÁMOP-4.2.2.C-11/1/KONV-2012-0001</rs> project. The project has been supported by the <rs type="funder">European Union</rs>, co-financed by the <rs type="funder">European Social Fund</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_4tvaqkZ">
					<idno type="grant-number">TÁMOP-4.2.2.C-11/1/KONV-2012-0001</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Although the goal was to classify the observations containing more images, an additional metric was defined for the image classification as can be seen in Equation <ref type="formula" coords="6,447.91,163.02,3.77,8.96">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>  </head><p> U : number of users (who have at least one image in the test data)  Pu : number of individual plants observed by the u-th user  Nu,p : number of pictures taken from the p-th plant observed by the u-th user  Su,p,n : score between 1 and 0 equals to the inverse of the rank of the correct species (for the n-th picture taken from the p-th plant observed by the u-th user)</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="8,132.67,176.99,337.98,8.10;8,141.74,188.03,212.33,8.10" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,234.18,176.99,110.31,8.10">Principal Component Analysis</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Abdi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">J</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,351.43,176.99,119.21,8.10;8,141.74,188.03,87.91,8.10">Wiley Interdisciplinary Reviews: Computational Statistics</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="433" to="459" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.67,199.07,338.00,8.10;8,141.74,209.99,327.29,8.10" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,260.57,199.07,185.24,8.10">A Training Algorithm for Optimal Margin Classifier</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Boser</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Guyon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,451.02,199.07,19.65,8.10;8,141.74,209.99,251.17,8.10">Proc. of the 5th Annual ACM Workshop on Computational Learning Theory</title>
		<meeting>of the 5th Annual ACM Workshop on Computational Learning Theory</meeting>
		<imprint>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="144" to="152" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.67,221.03,337.64,8.10;8,141.74,232.07,329.08,8.10;8,141.74,242.99,111.62,8.10" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,205.85,232.07,228.81,8.10">Lifeclef 2014: multimedia life species identification challenges</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,454.27,232.07,16.55,8.10;8,141.74,242.99,85.28,8.10">Proceedings of CLEF 2014</title>
		<meeting>CLEF 2014</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.67,254.03,337.89,8.10;8,141.74,265.07,56.40,8.10" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,231.05,254.03,88.03,8.10">Support-vector networks</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,326.21,254.03,66.26,8.10">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.67,275.99,337.71,8.10;8,141.74,287.06,299.21,8.10" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,267.52,275.99,202.85,8.10;8,141.74,287.06,35.69,8.10">Maximum likelihood from Incomplete Data via the EM Algorithm</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Dempster</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Laird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,183.74,287.06,139.02,8.10">Journal of the Royal Statistical Society</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="38" />
			<date type="published" when="1977">1977</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.67,298.10,338.04,8.10;8,141.74,309.02,328.97,8.10;8,141.74,320.06,24.12,8.10" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,301.97,298.10,164.95,8.10">Recognizing and Learning Object Categories</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Fergus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Torralba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,141.74,309.02,324.59,8.10">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.67,331.10,337.84,8.10;8,141.74,342.02,271.84,8.10" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,141.74,342.02,131.61,8.10">Lifeclef plant identifcation task 2014</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goeau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Selmi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Barthélémy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,292.13,342.02,75.00,8.10">CLEF working notes</title>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page">2014</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.67,353.06,337.58,8.10;8,141.74,364.10,328.91,8.10;8,141.74,375.02,67.59,8.10" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,362.64,353.06,107.61,8.10;8,141.74,364.10,172.27,8.10">The devil is in the details: an evaluation of recent feature encoding methods</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Chatfield</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lempitsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,321.89,364.10,129.93,8.10">British Machine Vision Conference</title>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="76" to="77" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.67,386.06,337.76,8.10;8,141.74,397.10,328.70,8.10;8,141.74,408.02,257.31,8.10" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,242.67,386.06,227.75,8.10;8,141.74,397.10,38.36,8.10">PCA-SIFT: A more distinctive representation for local image descriptors</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sukthankar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,196.34,397.10,274.10,8.10;8,141.74,408.02,159.88,8.10">CVPR 2004. Proceedings of the 2004 IEEE Computer Society Conference on</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">506</biblScope>
		</imprint>
	</monogr>
	<note>Computer Vision and Pattern Recognition</note>
</biblStruct>

<biblStruct coords="8,132.40,419.06,338.05,8.10;8,141.74,430.10,328.96,8.10;8,141.74,441.02,287.69,8.10" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,283.07,419.06,187.38,8.10;8,141.74,430.10,152.55,8.10">Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ponce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,301.01,430.10,169.69,8.10;8,141.74,441.02,133.47,8.10">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</title>
		<meeting>the IEEE Conference on Computer Vision and Pattern Recognition<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2169" to="2178" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.40,452.06,338.26,8.10;8,141.74,463.10,226.61,8.10" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,195.86,452.06,219.86,8.10">Distinctive Image Features from Scale-Invariant Keypoints</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,423.31,452.06,47.35,8.10;8,141.74,463.10,99.47,8.10">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.40,474.04,338.25,8.10;8,141.74,485.08,240.17,8.10" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,191.61,474.04,195.38,8.10">Object Recognition from local scale-invariant features</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,402.79,474.04,67.86,8.10;8,141.74,485.08,99.95,8.10">International Conference on Computer Vision</title>
		<meeting><address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1150" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.40,496.12,338.01,8.10;8,141.74,507.04,328.97,8.10;8,141.74,518.08,96.87,8.10" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,197.60,496.12,269.14,8.10">Some methods for classification and analysis of multivariate observations</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Macqueen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,141.74,507.04,325.37,8.10">Proceedings of the Fifth Berkeley Symposium on Mathematical Statistics and Probability</title>
		<meeting>the Fifth Berkeley Symposium on Mathematical Statistics and Probability</meeting>
		<imprint>
			<date type="published" when="1967">1967</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="281" to="297" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.40,529.12,337.92,8.10;8,141.74,540.04,328.97,8.10;8,141.74,551.08,24.12,8.10" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,239.17,529.12,227.59,8.10">Fisher kernel on visual vocabularies for image categorization</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Dance</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,141.74,540.04,324.59,8.10">IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR)</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.40,562.12,338.31,8.10;8,141.74,573.04,144.63,8.10" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="8,211.16,562.12,255.73,8.10">Gaussian Mixture Models, Encyclopedia of Biometric Recognition</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Reynolds</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009-02">February. 2009</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="659" to="663" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.40,584.08,338.17,8.10;8,141.74,595.12,328.97,8.10;8,141.74,606.04,136.09,8.10" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="8,282.17,584.08,188.40,8.10;8,141.74,595.12,32.59,8.10">Improved Fisher Vector for Large Scale Image Classification</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sánchez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mensink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,189.37,595.12,277.81,8.10">Proc. of the 11th European Conference on Computer Vision (ECCV): Part IV</title>
		<meeting>of the 11th European Conference on Computer Vision (ECCV): Part IV</meeting>
		<imprint>
			<date type="published" when="2010">September 05-11. 2010</date>
			<biblScope unit="page" from="143" to="156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,132.40,617.08,338.28,8.10;8,141.74,628.12,243.65,8.10" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="8,185.62,617.08,214.34,8.10">Estimating gaussian mixture densities with EM: A tutorial</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Tomasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,187.43,628.12,130.95,8.10">Chinese Journal of Electron Devices</title>
		<imprint>
			<biblScope unit="page" from="15" to="18" />
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>Tech. rep., Duke University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
