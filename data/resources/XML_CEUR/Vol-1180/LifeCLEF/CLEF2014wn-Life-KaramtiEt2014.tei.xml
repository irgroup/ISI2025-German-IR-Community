<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,161.76,66.80,291.80,12.93;1,183.72,84.68,247.84,12.93">MIRACL at LifeCLEF 2014: Multi-organ observation for Plant Identification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,157.68,122.29,65.69,9.96"><forename type="first">Hanen</forename><surname>Karamti</surname></persName>
							<email>karamti.hanen@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">City ons Sfax</orgName>
								<orgName type="laboratory">MIRACL Laboratory</orgName>
								<orgName type="institution">University of Sfax</orgName>
								<address>
									<postBox>.P</postBox>
									<postCode>B3023</postCode>
									<settlement>Sfax</settlement>
									<country key="TN">TUNISIA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,231.39,122.29,62.71,9.96"><forename type="first">Sana</forename><surname>Fakhfakh</surname></persName>
							<email>sanafakhfakh@yahoo.fr</email>
							<affiliation key="aff0">
								<orgName type="department">City ons Sfax</orgName>
								<orgName type="laboratory">MIRACL Laboratory</orgName>
								<orgName type="institution">University of Sfax</orgName>
								<address>
									<postBox>.P</postBox>
									<postCode>B3023</postCode>
									<settlement>Sfax</settlement>
									<country key="TN">TUNISIA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,302.11,122.29,68.02,9.96"><forename type="first">Mohamed</forename><surname>Tmar</surname></persName>
							<email>mohamed.tmar@isimsf.rnu.tn</email>
							<affiliation key="aff0">
								<orgName type="department">City ons Sfax</orgName>
								<orgName type="laboratory">MIRACL Laboratory</orgName>
								<orgName type="institution">University of Sfax</orgName>
								<address>
									<postBox>.P</postBox>
									<postCode>B3023</postCode>
									<settlement>Sfax</settlement>
									<country key="TN">TUNISIA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,378.81,122.29,54.44,9.96"><forename type="first">Walid</forename><surname>Mahdi</surname></persName>
							<email>walid.mahdi@isimsf.rnu.tn</email>
							<affiliation key="aff0">
								<orgName type="department">City ons Sfax</orgName>
								<orgName type="laboratory">MIRACL Laboratory</orgName>
								<orgName type="institution">University of Sfax</orgName>
								<address>
									<postBox>.P</postBox>
									<postCode>B3023</postCode>
									<settlement>Sfax</settlement>
									<country key="TN">TUNISIA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,275.40,134.29,64.82,9.96"><forename type="first">Faiez</forename><surname>Gargouri</surname></persName>
							<email>faiez.gargouri@fsegs.rnu.tn</email>
							<affiliation key="aff0">
								<orgName type="department">City ons Sfax</orgName>
								<orgName type="laboratory">MIRACL Laboratory</orgName>
								<orgName type="institution">University of Sfax</orgName>
								<address>
									<postBox>.P</postBox>
									<postCode>B3023</postCode>
									<settlement>Sfax</settlement>
									<country key="TN">TUNISIA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,161.76,66.80,291.80,12.93;1,183.72,84.68,247.84,12.93">MIRACL at LifeCLEF 2014: Multi-organ observation for Plant Identification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C001C3026FE291DF67442EBEE3E9E825</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>plant observation</term>
					<term>feature extraction</term>
					<term>ImageClef</term>
					<term>XML</term>
					<term>image retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ImageCLEF 2014 has a challenge based on analysis for identifying plants. This article describes our first participation to the multiimage plant observation queries task of PlantCLEF 2014. The task will be evaluated as a plant species retrieval task based on multi-image plant observations queries. The goal is to retrieve the correct plant species among the top results of a ranked list of species returned by the evaluated system. In this paper, we present two method. Our first method is purely visual and entirely automatic, using only the image information. One should mention that the total time spent with preparing this submission was only about three week. The results were accordingly fairly poor. The challenge of our second method is to identify plant species based on combination of textual and structural context of image. Indeed, we have used the meta-data in our system for exploring the image characteristics. Our approach is based on a modern technique for exploitation of structure of XML document. Also, the results were accordingly fairly poor. Although our results are not quite promising as compared to other participant groups, they can still guide our work in this field for some conclusions reached.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The plant identification has become an important and challenging research area since it is estimated that approximately one half of world plant species is still not cataloged. Among such unidentified species one may find, for instance, the healing of a disease or a plant that can cooperate in the equilibrium of the ecosystem around it.</p><p>Despite the importance of studies related to the description and categorization of plants, this task remains still a difficult for a botanist which is limited to a specific amount of information about the vegetal. Furthermore, among the information which may be collected, the most relevant for the botanist analysis are flowers and fruits. However, it turns out that in most cases these elements are observed only in specific periods of the year. This is a complicated issue given that the observation may not be possible when these characteristics are noticeable.</p><p>A solution for this impasse is the identification of plant by observing its different organs, such as it has been demonstrated in <ref type="bibr" coords="2,355.75,183.97,10.00,9.96" target="#b0">[1]</ref>. Indeed, botanists usually observe simultaneously several organs like the leaves and the fruits or the flowers in order to disambiguate species which could be confused if only one organ were observed. Moreover, if only one organ is observed, such as the bark of a deciduous plant during winter where nothing else is observable, then the observation of this organ with several photos related to different point of views could be more informative than only one point of view.</p><p>Thus, image analysis based on computational tools is a worthwhile approach in order to help the botanist or even provide by itself a reliable outcome for the classification task. In this context, ImageCLEF the Combined Lab Evaluation Forum (CLEF) hosts an annual competition on identification plant species.</p><p>In this year, ImageCLEF organizes a new challenge dedicated to botanical data (called PlantCLEF 2014), the species identification task won't be imagecentered but observation-centered. The aim of the task will be to produce a list of relevant species for each observation of a plant of the test dataset, i.e. one or a set of several pictures related to a same event: one same person photographing several detailed views on various organs the same day with the same device with the same lightening conditions observing one same plant. The main novelties compared to the last years are the following: An explicit multi-image query scenario, User ratings on image quality, a new type of view called 'Branch' additionally to the 6 others views (Scan, photos of Flower, Fruit, Stem, Leaf and Entire views), and basically more species (the number of species will be this year about 500, which is an important step towards covering the entire flora of a given region).</p><p>In this context, the following paper describes our (team MIRACL) approach for the LifeCLEF, task on multi-image plant observation queries. Our focus for this endeavor was on three main points: (i) image retrieval based on content that requires a thorough knowledge of low-level features of image. (ii) Image retrieval based on context based on information extracted in proximity of image for example: title or caption of image, textual description, etc. (iii) the combination of textual and visual features.</p><p>The following Section 2 describes the materials and methods used. In Section 3, we describe the results of our experiments. Finally, some conclusions reached are presented in Section 4. The task will be based on Pl@ntView dataset which focuses on 500 herb, tree and fern species centered on France (some plants observations are from neighboring countries). This database (shows figure <ref type="figure" coords="3,372.57,454.09,4.46,9.96" target="#fig_0">1</ref>) is maintained by the French project PlantNet (INRIA, CIRAD, Telabotanica) and the French CNRS program MASTODONS. It contains more than 60000 pictures belonging each to one of the 7 types of view reported into the meta-data, in a xml file (one per image) with explicit tags <ref type="bibr" coords="3,155.40,513.85,10.00,9.96" target="#b7">[8]</ref>. For (1), ( <ref type="formula" coords="3,211.37,513.85,3.88,9.96" target="#formula_1">2</ref>), ( <ref type="formula" coords="3,229.87,513.85,3.88,9.96">3</ref>), ( <ref type="formula" coords="3,248.24,513.85,3.88,9.96">5</ref>), ( <ref type="formula" coords="3,267.11,513.85,4.25,9.96">6</ref>) and ( <ref type="formula" coords="3,301.32,513.85,3.88,9.96">7</ref>), the images are taken directly from the trees. For (4), the images are oriented vertically along the main natural axis and with the petiole visible collected using flatbed scanners. These images haven't an uniform background. Each image has an xml file associated that contain the following meta-data:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Material and Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Database</head><p>-ObservationId: the plant observation ID from which several pictures can be associated -FileName</p><p>The full database is split into training and testing dataset. The train dataset has 47815 images (1987 of 'Branch', 6356 photographs of 'Entire', 13164 of 'Flower ', 3753 'Fruit ', 7754 of 'Leaf ', 3466 'Stem' and 11335 'scans' and 'scan-like' pictures of 'leaf '). The test dataset results in 8163 plant-observation-queries. These queries are based on 13146 images (731 of 'Branch', 2983 photographs of 'Entire', 4559 of 'Flower ', 1184 'Fruit ', 2058 of 'Leaf ', 935 'Stem' and 696 'scans' and 'scan-like' pictures of 'leaf ') .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Methods</head><p>In this section, we will present our methods.</p><p>Feature Extraction Two main functionalities are supported of feature extraction (run 1): data extraction processing and query processing. The data extraction processing is responsible for extracting appropriate features from images and storing them into their feature vectors. This process is usually performed offline. A feature vector V I of an image I can be thought of as a list of low-levels features (C 1 , C 2 , ..., C m ), where m is the number of features. We have used three descriptor to features extraction:</p><p>-A color layout descriptor (CLD) <ref type="bibr" coords="5,294.52,69.37,10.57,9.96" target="#b2">[3]</ref> is designed to capture the spatial distribution of color in an image. The feature extraction process consists of two parts: grid based representative color selection and discrete cosine transform with quantization. The image is divided into an 8 × 8 grid. An 8 × 8 pixel image is created, with each pixel given the representative color from the corresponding grid area in the image. The 8 × 8 matrix is transformed with the discrete cosine transform. Finally, a zigzag scan is performed on the matrix. The resulting matrices (one for each color component) make up the descriptor. -A Edge Histogram Descriptor (EHD) <ref type="bibr" coords="5,315.53,176.65,10.57,9.96" target="#b1">[2]</ref> is a texture descriptor proposed for MPEG-7 expresses only the local edge distribution in the image -A Scalable Color Descriptor (SCD) <ref type="bibr" coords="5,307.35,200.29,10.00,9.96" target="#b3">[4]</ref>, the historgram is generated by color quantizing the image into 256 bins in the HSV color space, with 16 bins for hue, and 4 bins each for saturation and value. The image on the right is an example of color images with corresponding histograms. The left image and center image are more similar to each other based on the color histograms, compared to the image on the right. This descriptor is useful when searching for similarities between images.</p><p>The C i represents the combination of C CLD , C SCD and C EHD of feature i. The query processing, in turn, extracts a feature vector from a query and applies a metric (Euclidean distance equation 1) to evaluate the similarity between the query image and the database images <ref type="bibr" coords="5,302.07,326.89,10.00,9.96" target="#b6">[7]</ref>.</p><formula xml:id="formula_0" coords="5,195.48,368.46,285.16,30.50">S visuelI = dist Euclidean (V I , V Ii ) = m i=1 (C I -C Ii ) 2<label>(1)</label></formula><p>The similarites scores of the queries results builds a score vector. A score vector S visuelI of an image I can be thought of as a set of scores (S visuel1 , S visuel2 , ..., S visueln ), where n is the dimension of database images.</p><p>System using Structure of XML document In this section, we are interested in Context-based Image retrieval techniques, and more precisely in Image retrieval based on textual and structural context in XML documents. Image context is composed all textual information surrounding the image. For retrieve image presentated in Figure <ref type="figure" coords="5,260.42,510.85,3.91,9.96" target="#fig_1">2</ref>, we can use text surrounding image such as document title, image name, image caption, etc There are other sources of evidence that were used as visual descriptors, information from link around the image, structure of XML document. Indeed, We focus on XML documents don't have a homogeneous structure. What makes the structure as new source of evidence. The textual context remains insufficient in most of time. In this context, <ref type="bibr" coords="5,261.99,582.49,10.57,9.96" target="#b4">[5]</ref> say: "Ignore the document structure is to ignore its semantics". The idea is to calculate the relevancy score of image element based on information from the textual and structural context to answer a specific information needs of user, expressed as query composed of set of keywords. And seeking the most appropriate manner to combine two sources of evidence: text and structure. Our main inspiration is to use the structure to involve each textual information depending on its position in XML document, that is textual information that gives the best possible description of image element.</p><p>In run 2, we propose a automatic method in the field of image retrieval that takes into account the structure as a source of evidence and its impact on search performance. We present a new source of evidence dedicated to image retrieval based on the intuition that each textual node contains information that describes semantically a image element. And the participation of each text node in the score of a image element varies with its position in there XML document. To compute the geometric distance, we initially place the nodes of each XML document in an Euclidean space to calculate the coordinates of each node. Then, we compute the score of a image element depending on the distance between each textual node <ref type="bibr" coords="6,218.07,413.89,10.00,9.96" target="#b5">[6]</ref>. Figure <ref type="figure" coords="6,268.02,413.89,4.98,9.96">3</ref> present our indexing system based on textual and structural context for image.</p><p>The result will be represented by a vector S scoreI . This vector of an image I can be thought of as a set of scores (S score1 , S score2 , ..., S scoren ), where n is the dimension of database images.</p><p>Combination of Textual and Visual features From our two vectors S score and S visuel , we calculate a score that is a linear combination of scores for each modality:</p><formula xml:id="formula_1" coords="6,154.92,530.54,325.72,83.69">S scorei =      S score1 S score2 . . . S scoren      S visueli =      S visuel1 S visuel2 . . . S visueln      S i =      S 1 S 2 . . . S n      S i = score(S visueli , S scorei ) = αS visueli + (1 -α)S scorei<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Results</head><p>Miracl team has submitted three automatic runs to the multi-image plant observation queries. And the details are as follows <ref type="bibr" coords="8,335.81,105.37,10.00,9.96" target="#b8">[9]</ref>. In the first run, we extracted visual descriptors from the images, used texture, color and edge model for generating the feature vectors. In the second run, we changed the evidence source of image in hope of taking general context of image into account the textual and structural information in XML document.</p><p>In the third run, also the last run, we fused the classifiers of the two runs above to form a new kind of degree of attribution. The results are showed in Table <ref type="table" coords="8,297.62,302.41,3.91,9.96" target="#tab_0">1</ref>. From it we can find that the first run achieves the best results in all kinds of pictures. That's to say, the visual scheme usually can reach a better result for combination of different visual descriptors advantages. The run for the contextual descriptors is in the middle place of the three runs and the one for flip combination descriptors gets the worst results which is in contradiction with our expectation. So we can speculate that the reasons for this phenomenon may have a relation to the number of training images in certain species which have very few images and the meta data of image are similar and relatively short which does not identify a species.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This work is our first try in the plant identifcation task. Although the results are not quite promising, we still reach some conclusions and gain some experience.</p><p>(1) At first, as there are some species which have only a few images, the bias for these species may be emphasized and combing some retrieval methods is a good choice.</p><p>(2) Many speacies have the same observation and the same id class. In fact, we have a problem to product the run. Each run contains betwen 10 to 200 species for each queries.</p><p>While our solution was not performing up to the best ones in this competition (the idea score is 0.47), it is fast, accurate enough for non-critical applications and has potential for improvement. We intend to proceed developing this solution further and plan a mobile phone implementation of it.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,187.44,394.12,240.33,8.97"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Sample images for the database of PlantCLEF 2014</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,217.56,215.44,180.40,8.97;6,319.99,72.69,87.42,116.52"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Example of a image element context.</figDesc><graphic coords="6,319.99,72.69,87.42,116.52" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="8,193.92,210.28,224.33,63.81"><head>Table 1 .</head><label>1</label><figDesc>Results for all runs in plant collection</figDesc><table coords="8,193.92,231.48,224.33,42.60"><row><cell>Run name</cell><cell>Retrieval type</cell><cell>Score</cell></row><row><cell>Miracl Run 1</cell><cell>Visual</cell><cell>0, 063</cell></row><row><cell cols="3">Miracl Run 2 Context(Textual and Structural) 0, 051</cell></row><row><cell>Miracl Run 3</cell><cell>Visual + Context</cell><cell>0, 047</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This score (equation <ref type="formula" coords="7,244.46,349.33,4.46,9.96">2</ref>) is a dot product between two vectors representing the visual features and the textual features. The parameter α is used to weight the amount of information conveyed by each modality.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Evaluation Metric</head><p>The metric evaluation S was related to the rank of the correct species in the list of retrieved species as follows <ref type="bibr" coords="7,265.66,480.13,10.00,9.96" target="#b7">[8]</ref>:</p><p>Where U :is the number of users. P u : number of individual plants observed by the u th user. N u,p : number of pictures taken from the p th plant observed by the u th user. S u,p,n : score between 1 and 0 equals to the inverse of the rank of the correct species (for the n th picture taken from the p th plant observed by the u th user).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="9,138.32,93.04,342.31,8.97;9,146.88,103.96,333.69,8.97;9,146.88,114.88,333.68,8.97;9,146.88,125.92,300.50,8.97" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,423.60,103.96,56.98,8.97;9,146.88,114.88,102.21,8.97">Nozha: Multiorgan Plant Identification</title>
		<author>
			<persName coords=""><forename type="first">Hervé</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julien</forename><surname>Barbe</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Bakic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Joly</forename><surname>Vera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexis</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean-François And</forename><surname>Barthelemy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Boujemaa</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,271.02,114.88,209.54,8.97;9,146.88,125.92,229.45,8.97">Proceedings of the 1st ACM International Workshop on Multimedia Analysis for Ecological Data (MAED &apos;12)</title>
		<meeting>the 1st ACM International Workshop on Multimedia Analysis for Ecological Data (MAED &apos;12)</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="41" to="44" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.32,136.84,342.23,8.97;9,146.88,147.76,333.68,8.97;9,146.88,158.80,116.41,8.97" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,401.30,136.84,79.25,8.97;9,146.88,147.76,125.25,8.97">Efficient Use of Local Edge Histogram Descriptor</title>
		<author>
			<persName coords=""><forename type="first">Dong</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeon</forename><surname>Kwon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yoon</forename><surname>Seok</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chee</forename><surname>Won</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,296.78,147.76,183.78,8.97;9,146.88,158.80,44.32,8.97">Proceedings of the 2000 ACM Workshops on Multimedia</title>
		<meeting>the 2000 ACM Workshops on Multimedia</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="51" to="54" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.32,169.72,342.14,8.97;9,146.88,180.64,333.56,8.97;9,146.88,191.56,333.69,8.97;9,146.88,202.60,25.45,8.97" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,278.05,169.72,202.41,8.97;9,146.88,180.64,293.00,8.97">The MPEG-7 color layout descriptor: a compact image feature description for high-speed image/video segment retrieval</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kasutani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Yamada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,464.44,180.64,16.00,8.97;9,146.88,191.56,248.93,8.97">Proceedings. 2001 International Conference on Image Processing</title>
		<meeting>2001 International Conference on Image Processing</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="674" to="677" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.32,213.52,342.13,8.97;9,146.88,224.44,333.69,8.97;9,146.88,235.48,152.56,8.97" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,227.25,213.52,211.64,8.97">MPEG-7 Color Descriptors and Their Applications</title>
		<author>
			<persName coords=""><forename type="first">Leszek</forename><surname>Cieplinski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,464.46,213.52,16.00,8.97;9,146.88,224.44,333.69,8.97;9,146.88,235.48,81.46,8.97">Proceedings of the 9th International Conference on Computer Analysis of Images and Patterns (CAIP &apos;01)</title>
		<meeting>the 9th International Conference on Computer Analysis of Images and Patterns (CAIP &apos;01)</meeting>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="11" to="20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.32,246.40,342.22,8.97;9,146.88,257.32,333.68,8.97;9,146.88,268.36,25.45,8.97" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,253.56,246.40,163.28,8.97">Querying and Ranking XML Documents</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Schlieder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Holger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,440.89,246.40,39.64,8.97;9,146.88,257.32,250.03,8.97">Journal of the American Society for Information Science and Technolog</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="489" to="503" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.32,279.28,342.24,8.97;9,146.88,290.20,333.57,8.97;9,146.88,301.24,163.71,8.97" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,314.30,279.28,166.25,8.97;9,146.88,290.20,88.54,8.97">A New Metric for Multimedia Retrieval in Structured Documents</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Fakhfakh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tmar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Mahdi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,255.27,290.20,225.18,8.97;9,146.88,301.24,82.64,8.97">15th International Conference on Enterprise Information Systems, ICEIS 2013</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="240" to="247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.32,312.16,342.07,8.97;9,146.88,323.08,207.18,8.97" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,214.34,312.16,266.05,8.97;9,146.88,323.08,55.82,8.97">Vectorisation du modèle d&apos;appariement pour la recherche d&apos;images par le contenu</title>
		<author>
			<persName coords=""><forename type="first">Hanen</forename><surname>Karamti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,224.06,323.08,50.49,8.97">CORIA 2013</title>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="335" to="340" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.32,334.12,342.39,8.97;9,146.88,345.04,333.47,8.97;9,146.88,355.96,333.54,8.97;9,146.88,367.00,150.51,8.97" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,218.63,355.96,257.91,8.97">LifeCLEF 2014: multimedia life species identification challenges</title>
		<author>
			<persName coords=""><forename type="first">Alexis</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Henning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hervé</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hervé</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Concetto</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andreas</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Willem-Pier And</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bob</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,161.05,367.00,107.71,8.97">Proceedings of CLEF 2014</title>
		<meeting>CLEF 2014</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.32,377.92,342.26,8.97;9,146.88,388.84,333.54,8.97;9,146.88,399.88,147.74,8.97" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,317.17,388.84,140.22,8.97">LifeCLEF Plant Identification Task</title>
		<author>
			<persName coords=""><forename type="first">Hervé</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexis</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean-François And</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Barthélémy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nozha</forename><surname>Boujemaa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,161.05,399.88,104.94,8.97">CLEF working notes 2014</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
