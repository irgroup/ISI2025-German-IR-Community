<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,144.60,115.90,326.16,12.90;1,266.63,133.83,82.10,12.90">SVM Candidates and Sparse Representation for Bird Identification</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,158.34,172.53,71.12,8.64"><forename type="first">Rodrigo</forename><surname>Martinez</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Facultad de Ciencias (FC) http</orgName>
								<orgName type="institution">ciencias</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,238.91,172.53,45.96,8.64"><forename type="first">Laura</forename><surname>Silva</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Facultad de Estudios Superiores -Zaragoza (FES-Zaragoza)</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,296.80,172.53,59.44,8.64"><forename type="first">Esau</forename><surname>Villarreal</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Facultad de Estudios Superiores -Zaragoza (FES-Zaragoza)</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Instituto de Investigaciones en Matematicas Aplicadas y en Sistemas (IIMAS) http://www.iimas.unam</orgName>
								<orgName type="institution">Universidad Nacional Autonoma de Mexico (UNAM) http</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">No Institute</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,372.03,172.53,61.15,8.64"><forename type="first">Gibran</forename><surname>Fuentes</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Instituto de Investigaciones en Matematicas Aplicadas y en Sistemas (IIMAS) http://www.iimas.unam</orgName>
								<orgName type="institution">Universidad Nacional Autonoma de Mexico (UNAM) http</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">No Institute</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,284.41,184.49,42.07,8.64"><forename type="first">Ivan</forename><surname>Meza</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Instituto de Investigaciones en Matematicas Aplicadas y en Sistemas (IIMAS) http://www.iimas.unam</orgName>
								<orgName type="institution">Universidad Nacional Autonoma de Mexico (UNAM) http</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">No Institute</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,144.60,115.90,326.16,12.90;1,266.63,133.83,82.10,12.90">SVM Candidates and Sparse Representation for Bird Identification</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E980052FC028A107C9C998FFB1542C85</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a description of our approach for the "Bird task Identification LifeCLEF 2014". Our approach consists of four stages: (1) a filtering stage for the filtering of audio bird recordings; (2) segmentation stage for the extraction of syllables; (3) a candidate generation based on HOG features from the syllables using SVM; and (4) a species identification using a Sparse Representation-based Classification of HOG and LBP features. Our approach ranked seventh team-wise in the challenge and showed a poor performance in the fourth stage.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this work we present the description of our system submitted to the LifeCLEF 2014 Bird task <ref type="bibr" coords="1,174.97,487.77,11.62,8.64" target="#b1">[2]</ref> part of the LifeCLEF 2014 Laboratory <ref type="bibr" coords="1,350.82,487.77,10.58,8.64" target="#b2">[3]</ref>. This task is concerned with the identification of bird species based on their signing. This setting has potential applications on ecological surveillance or biodiversity conservation. This year the task was formally defined as:</p><p>The task will be focused on bird identification based on different types of audio records over 501 species from South America centered on Brazil. Additional information includes contextual meta-data (author, date, locality name, comment, quality rates). The main originality of this data is that it was specifically built through a citizen sciences initiative conducted by Xeno-canto, an international social network of amateur and expert ornithologists. This makes the task closer to the conditions of a real-world application: (i) audio records of the same species are coming from distinct birds living in distinct areas (ii) audio records by different users that might not used the same combination of microphones and portable recorders (iii) audio records are taken at different periods in the year and different hours of a day involving different background noise (other bird species, insect chirping, etc). <ref type="foot" coords="2,335.14,129.60,3.49,6.05" target="#foot_0">1</ref>At the core of our approach is the Sparse Representation-based Classification (SRC) <ref type="bibr" coords="2,480.67,150.31,10.58,8.64" target="#b4">[5]</ref>, a methodology that has been quite successful in face recognition. We adapted SRC to work at the syllable-level. In addition, our approach is composed of filtering, syllable extraction and candidate generation. In the filtering stage, the audio recordings are uniformly processed to be on the same bandwidth and to eliminate stationary noise. In the syllable extraction, the system identifies a set of syllables based on short time energy filter. Finally, we generate a set of candidate species based on the syllable information. For a recording, a set of candidates per syllable is ranked to generate a unique set.</p><p>The outline of this paper is as follows. Section 2 presents the architecture of our approach. Section 3 explains the preprocessing stage, section 4 the extraction of syllables stage, section 5 the candidates generation stage, section 5 the candidates generation stage, section 6 the identification stage. Section 7 presents our results. Finally, section 8 presents some conclusions and discusses about future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Architecture of the approach</head><p>Our approach is composed of four stages represented in Figure <ref type="figure" coords="2,388.62,344.95,3.74,8.64" target="#fig_0">1</ref>. The first stage filters the recording in the frequency domain. The second stage extracts bird syllables from the filtered signal. We have two settings for this, a coarse and fined grained setting. The third stage has the goal of creating a set of n candidates given a syllable. A final set of candidates for the recording is produced combining the candidate sets of each syllable. The model for the candidates is generated using the fine grained syllables. Finally, the four stage has the goal of doing the identification using the Sparse Representation-based Classification of the syllables. It tries to select from the candidate set the species with more resemblance to the examples from a dictionary based on hand picked syllables. The syllables are based on the coarse segmentation, and it relies on the representation of the syllable as a visual feature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Filtering</head><p>There are two aspects we follow for the filtering of the signal. First we re-sample the original recordings from 44100hz to 16000hz. After this we apply a bandpass FIR filter between 500hz and 4500hz frequencies. Empirically we identified that most of the singing frequencies were located in this bandwidth. However, the low performance of our approach points to review this assumption. Figure <ref type="figure" coords="2,349.03,563.51,4.98,8.64" target="#fig_1">2</ref> shows the effect of this filtering in one of the recordings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Segmentation of syllables</head><p>The segmentation of syllables is done using a short time energy filter.  being filtered from the previous stage. Figure <ref type="figure" coords="4,324.53,119.31,4.98,8.64" target="#fig_2">3</ref> shows the syllable identified by this stage.  Syllables are normalized by resizing them into a specific size in the frequency domain (100x100 pixels). Figure <ref type="figure" coords="4,260.36,335.51,4.98,8.64" target="#fig_4">4</ref> shows a syllable after the normalization process. We have defined two thresholds for fined and coarse segmentation. Table <ref type="table" coords="4,411.06,347.47,4.98,8.64" target="#tab_3">3</ref> summarizes the number of syllables extracted for each type of segmentation in both databases. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Candidates generation</head><p>A set of candidates of the possible species is generated using a Support Vector Machine. For this we extract visual features from the segmented syllables. In particular we experimented with Histograms of Oriented Gradients (HOG) <ref type="bibr" coords="4,361.13,536.38,11.62,8.64" target="#b0">[1]</ref> and Local Binary Patterns (LBP) <ref type="bibr" coords="4,162.46,548.34,10.58,8.64" target="#b3">[4]</ref>. For each syllable in a recording we extract the candidates. These candidate sets are agglomerated into a final set. Figure <ref type="figure" coords="4,318.67,560.29,4.98,8.64" target="#fig_5">5</ref> shows the effect on the size of the set containing the target species. For our experiments we define the size of the set to be 200 candidate species.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Sparse Representation-based Classification</head><p>For the identification stage we follow the method of Wright et. al. <ref type="bibr" coords="4,405.13,632.53,10.58,8.64" target="#b4">[5]</ref>, originally proposed for the face recognition problem in which has been successful. We adapted the methodology to work at the syllable level on this bird task.   The method relies on a dictionary representation of the syllables of the i species. Each specie is represented by j instances of species' syllables, which is given by a vector of arity m. Together candidates and instances define the dictionary matrix A of M XN dimension (where M = ixj). Given an unknown instance of a syllable y the goal of the method is to identify the vector x which represents the contributions of elements of the dictionary A to generate the syllable y. In other words, the contribution of each syllable to generate the unknown syllable. Once the contribution of each element of the dictionary is identified, it is a matter of quantifying the contribution by each candidate and decide if the contribution is enough to conclude that they represent the same person.</p><p>In order to identify the contribution of each candidate, SRC uses the 1 minimization:</p><formula xml:id="formula_0" coords="6,247.54,259.97,233.06,23.90">minimize x = argmin||x|| 1 subject to Ax = y (1)</formula><p>This minimizes the sum of the individual contributions of a candidate such that the multiplication of the metric dictionary A and the contributions x generate the unknown instance. To perform this minimization we use the homotopy method since it is fast to create a good approximation of the vector x <ref type="bibr" coords="6,311.85,327.70,10.58,8.64" target="#b5">[6]</ref>.</p><p>Once the vector x is identified the method proposes to calculate the square residuals per instance in the dictionary:</p><formula xml:id="formula_1" coords="6,277.41,363.25,203.18,9.65">r i = |y -Ax i |<label>(2)</label></formula><p>In which x i is the contribution vector with the values for the candidates different to i zeroed. In this way, the r i represents a score of the contribution of the instances of the candidate i. After calculating the residual per candidate, we look to identify the candidate which has the lower residual, this represent the one which is less different from the candidate and it is our identified person. We adapted this setting for the identification of bird species. First, the candidate species were extracted from the third stage of our system. Given the list of candidates from this stage we generated the matrix A. For our experiments i was variable but j was set to 5. In particular the instances of A were hand picked for experts in the field as good syllables examples for a species. The size m for the vector depended on the representation HOG or LBP features. At this stage we used the coarse syllables extracted in the second stage.</p><p>We performed the methodology explained above for each syllable. We collected the identified species and ranked them by the probability obtained in the stage of candidate generation. This sorted list was used to produce the output required by the challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Experimental Results</head><p>We submitted three configurations of our system: 100 HOG + HOG The sparse system used the 100 top candidates generated with HOG features, and the HOG features to identify the species. 50 HOG + HOG The sparse system used the 50 top candidates with HOG features, and the HOG features to identify the species.</p><p>50 HOG + LBP The sparse system used the 50 top candidates generated with HOG features, and the LBP features to identify the species. As you can notice the performance of our system was poor. To reduce the amount of candidates did not have a significant improvement. On the other hand, the use of LBP affected the performance.</p><p>In order to analyse the labellings produced by our system, we analyse the results over a subset of the training corpus, those marked with more than one bird singing. We found that only 209 bird species were correctly recover. Table ?? shows the 10 most successful species. However, our performance is so poor that it is hard to account for the errors on the rest of the species at the moment. These working notes present our system proposal for the identification of bird species through singing. This proposal was built in the context of the LifeCLEF 2014 Bird task <ref type="bibr" coords="7,153.58,560.80,10.58,8.64" target="#b1">[2]</ref>, a part of the LifeCLEF 2014 Laboratory <ref type="bibr" coords="7,328.40,560.62,12.72,8.59" target="#b2">[3]</ref>. Our approach first generates candidates using SVM and the identification of the species at the syllable level using a sparse representation. As result of the challenge we identify several problems with our setting which had a poor performance in the challenge 25% of the best. We have several hypothesis of what could had been wrong. First, our filtering of the recording was to aggressive. Second, the segmentation of the syllables was not at the level and in many cases segmented more than syllable. Third, the identification stage fail to identify the species at a good rate 17% with 100 candidates. Fourth, we did not use information of the metadata or at the song level of the species.</p><p>In the future we aim to generate a better setting for the filtering and syllable segmentation, maybe by incorporating elements of other approaches. We also would like to continue experimenting with the setting of identification through SRC to fully discarded or to find the correct way to set it up in the task of bird identification.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,169.05,294.65,277.25,8.12"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. System architecture for the identification of species of bird signing.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,134.77,605.32,345.82,8.12;3,134.77,616.63,262.66,7.77;3,190.96,495.03,241.29,84.97"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Example of the filtering of a recording. The spectrogram above represents the original recording. The spectrogram above represents the recording after filtering.</figDesc><graphic coords="3,190.96,495.03,241.29,84.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,168.57,281.34,278.20,8.12;4,190.96,171.05,241.29,84.97"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Segmented syllables for a recording using a short time energy filter.</figDesc><graphic coords="4,190.96,171.05,241.29,84.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="5,252.47,370.51,110.41,8.12;5,229.87,164.55,160.98,170.02"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Normalized syllable.</figDesc><graphic coords="5,229.87,164.55,160.98,170.02" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="5,134.77,606.03,345.81,8.12;5,134.77,617.34,202.53,7.77"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Percentage of times the target species belongs to the candidates (blue curve). Percentage of times the target species is the first candidate (red line)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,200.08,388.86,215.18,51.41"><head>Table 1 .</head><label>1</label><figDesc>Number of syllables extracted from the recordings.</figDesc><table coords="4,250.74,410.18,113.88,30.09"><row><cell>Train Test</cell></row><row><cell>Fined grained 52, 666 23, 953</cell></row><row><cell>Coarse grained 47, 899</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,173.15,169.59,269.05,62.37"><head>Table 2 .</head><label>2</label><figDesc>Mean average precision of identification of bird species in testing.</figDesc><table coords="7,186.82,190.91,241.72,41.05"><row><cell cols="2">Background species without backbround species</cell></row><row><cell>100 HOG + HOG 10.5%</cell><cell>12.9%</cell></row><row><cell>50 HOG + HOG 10.4%</cell><cell>12.8%</cell></row><row><cell>50 HOG + LBP 7.4%</cell><cell>8.9%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,134.77,384.02,334.05,138.58"><head>Table 3 .</head><label>3</label><figDesc>List of best identified species in recording with more than one species registered.</figDesc><table coords="7,134.77,405.34,261.44,117.26"><row><cell>Laterallus viridis</cell><cell>Emberizoides herbicola</cell></row><row><cell cols="2">Cercomacra melanaria Cyanocorax cristatellus</cell></row><row><cell>Nyctibius griseus</cell><cell>Setopagis parvulus</cell></row><row><cell cols="2">Hypocnemis hypoxantha Procnias nudicollis</cell></row><row><cell cols="2">Synallaxis cinerascens Crypturellus tataupa</cell></row><row><cell>8 Conclusions and Future work</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,657.09,172.75,7.77"><p>From http://www.imageclef.org/node/180 (May,</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1" coords="2,319.72,657.09,20.92,7.77"><p>2014)</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,138.13,210.62,335.23,7.77;8,146.47,221.58,262.43,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,224.10,210.62,190.97,7.77">Histograms of oriented gradients for human detection</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Dalal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,420.83,210.62,52.53,7.77;8,146.47,221.58,148.65,7.77">Conference on Computer Vision and Pattern Recognition</title>
		<meeting><address><addrLine>San Diego, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">Junio 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.13,232.54,334.33,7.77;8,146.47,243.50,121.44,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,326.53,232.54,129.69,7.77">Lifeclef bird identification task 2014</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rauber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,146.47,243.50,95.30,7.77">CLEF working notes 2014</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.13,254.46,340.21,7.77;8,146.47,265.42,300.65,7.77;8,146.47,276.38,124.02,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,206.56,265.42,224.71,7.77">Lifeclef 2014: multimedia life species identification challenges</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,146.47,276.38,97.87,7.77">Proceedings of CLEF 2014</title>
		<meeting>CLEF 2014</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.13,287.33,340.53,7.77;8,146.47,298.29,46.32,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,212.23,287.33,158.31,7.77">Texture classification using texture spectrum</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>He</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,376.69,287.33,71.34,7.77">Pattern Recognition</title>
		<imprint>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="905" to="910" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.13,309.25,333.98,7.77;8,146.47,320.21,314.29,7.77;8,146.47,331.17,57.53,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,348.87,309.25,123.24,7.77;8,146.47,320.21,49.50,7.77">Robust face recognition via sparse representation</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ganesh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,201.75,320.21,235.11,7.77">Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="210" to="227" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>IEEE Transactions on</note>
</biblStruct>

<biblStruct coords="8,138.13,342.13,304.92,7.99;8,146.47,353.09,310.43,7.77;8,146.47,364.05,84.17,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,364.97,342.13,78.08,7.99;8,146.47,353.09,134.34,7.77">Fast 1 -minimization algorithms for robust face recognition</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sastry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,286.65,353.09,146.35,7.77">Image Processing, IEEE Transactions on</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3234" to="3246" />
			<date type="published" when="2013-08">Aug 2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
