<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,154.24,115.96,306.88,12.62;1,220.22,133.89,174.92,12.62">Pl@ntNet&apos;s participation at LifeCLEF 2014 Plant Identification Task</title>
				<funder>
					<orgName type="full">Agropolis</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,162.91,171.56,56.55,8.74"><forename type="first">Hervé</forename><surname>Goëau</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Inria</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,230.01,171.56,48.08,8.74"><forename type="first">Alexis</forename><surname>Joly</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Inria</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">LIRMM</orgName>
								<address>
									<settlement>Montpellier</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,294.98,171.56,65.62,8.74"><forename type="first">Itheri</forename><surname>Yahiaoui</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Inria</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,371.15,171.56,47.77,8.74"><forename type="first">Vera</forename><surname>Bakić</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Inria</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,429.48,171.56,22.97,8.74;1,142.56,183.51,74.70,8.74"><forename type="first">Anne</forename><surname>Verroust-Blondet</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Inria</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,227.81,183.51,60.95,8.74"><forename type="first">Pierre</forename><surname>Bonnet</surname></persName>
							<email>pierre.bonnet@cirad.fr</email>
							<affiliation key="aff2">
								<orgName type="laboratory">CIRAD</orgName>
								<orgName type="institution">UMR AMAP</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,299.30,183.51,81.67,8.74"><forename type="first">Daniel</forename><surname>Barthelemy</surname></persName>
							<email>daniel.barthelemy@cirad.fr</email>
							<affiliation key="aff3">
								<orgName type="department">BIOS Direction and INRA</orgName>
								<orgName type="laboratory">CIRAD</orgName>
								<orgName type="institution">UMR AMAP</orgName>
								<address>
									<postCode>F-34398</postCode>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,391.53,183.51,74.04,8.74"><forename type="first">Nozha</forename><surname>Boujemaa</surname></persName>
							<email>boujemaa@inria.fr</email>
							<affiliation key="aff4">
								<orgName type="department">Direction of Saclay Center</orgName>
								<orgName type="institution" key="instit1">INRIA</orgName>
								<orgName type="institution" key="instit2">nozha</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,268.59,195.47,93.08,8.74"><forename type="first">Jean-François</forename><surname>Molino</surname></persName>
							<email>jean-francois.molino@ird.fr</email>
							<affiliation key="aff5">
								<orgName type="laboratory">IRD</orgName>
								<orgName type="institution">UMR AMAP</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,154.24,115.96,306.88,12.62;1,220.22,133.89,174.92,12.62">Pl@ntNet&apos;s participation at LifeCLEF 2014 Plant Identification Task</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">CA2BE67EF5CA04C214304D19422AF436</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Pl@ntNet</term>
					<term>Inria</term>
					<term>LifeCLEF</term>
					<term>plant</term>
					<term>leaves</term>
					<term>flowers</term>
					<term>fruits</term>
					<term>stem</term>
					<term>bark</term>
					<term>scan</term>
					<term>branch</term>
					<term>multi-organ</term>
					<term>image</term>
					<term>collection</term>
					<term>identification</term>
					<term>classification</term>
					<term>evaluation</term>
					<term>benchmark</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the participation of Inria within the Pl@ntNet project 7 at the LifeCLEF2014 plant identification task. The aim of the task was to produce a list of relevant species for each plant observation in a test dataset according to a training dataset. Each plant observation contains several annotated pictures with organ/view tags: Flower, Leaf, Fruit, Stem, Branch, Entire, Scan (exclusively of leaf). Our system treated independently each category of organ/view and then a late hierarchical fusion is used in order to combine the results on visual content analysis from the most local level analysis in pictures to the highest level related to a plant observation. For the photographs of flowers, leaves, fruits, stems, branches and entire views of plants, a large scale matching approach of local features extracted using different spatial constraints is used. For scans, the method combines the large scale matching approach with shape descriptors and geometric parameters on shape boundary. Then, several fusion methods are experimented through the four submitted runs in order to combine hierarchically the local responses to the final response at the plant observation level. The four submitted runs obtained good results and got the 4th to the 7th place over 27 submitted runs by 10 participating teams.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The plant identification task of LifeCLEF2014 [?] [?] was organized as a plant species retrieval task over 500 species with visual content being the main available information. The aim of the task was to produce a list of relevant species for each observation in a test dataset containing 8163 plant observations based on 13146 images, where each observation can contain several pictures of detailed views on various organs: Flower, Fruit, Leaf, Stem, Entire, Branch and Scan (scans or scan-like pictures of leaf exclusively). The training dataset contains numerous plant observations related to 47815 images tagged with these organ/view information.</p><p>We present in this paper the methods used in order to produce the four submitted runs by Inria within the PlantNet project. It is based more or less on the same system used during our previous participations to the ImageCLEF2011-2013 plant tasks [?] but with some improvements mainly related to new types of combination of image list results provided by the different image queries from a same plant observation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Description of the system</head><p>Each tested observation can potentially contain several pictures on several organs/views. Our system treated independently each organ/view and then a late hierarchical fusion framework is used in order to combine the visual content analysis from the most local level in pictures to the highest level related to one same plant observation.</p><p>-local level <ref type="bibr" coords="2,204.34,376.66,4.87,8.77">(</ref> We explored the fact that in most cases, one organ or one group of organs, is generally centred in the pictures of the dataset. Harris corners were used at four distinct resolutions with multiple orientations ([?]). In addition, as in [?], to minimize the effect of the cluttered background, a rhomboid-shaped mask was applied to the input image and we used a Gaussian-like distribution in a 7x7 grid in order to take more points at the center of the pictures (the figure ??(a)  , we consider that a given local feature x is dominating another local feature y if it is closer to a query feature q (according to the distance used as matching function). Two images I 1 and I 2 can then be compared with reference to a query image I q by counting the number of query local features q i for which a local feature of I 1 is dominating all features of I 2 (or conversely). More precisely, images are ranked using a quick sort algorithm based on the following comparison function:</p><formula xml:id="formula_0" coords="4,237.58,346.17,243.02,30.32">f (I 1 , I 2 ) = sgn( n i=1 sgn(r 1 i -r 2 i ))<label>(1)</label></formula><p>where r 1 i is the rank of the best match of I 1 in the k-nns of q i and r 2 i is the rank of the best match of I 1 in the k-nns of q i . One advantage of this ranking function is that it is much less sensitive to the value of k. When k grows, the ranking of the top-K images becomes more and more stable. Ideally, the image ranking could even be computed from the complete rankings of all local features in the dataset. But for efficiency reasons, this is clearly not manageable, and we choose a value of k = 600.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Shape boundary description on scans</head><formula xml:id="formula_1" coords="4,134.77,502.99,79.00,8.74">(Run 1, 2, 3 &amp; 4 )</formula><p>In the case of leaf scans and scan-like pictures, additional boundary descriptors are used since it has been showed to provide a consistent improvement of the global performances in the previous ImageCLEF2011 dataset [?]. Involving a first step of automatic leaf boundary detection, these descriptors are the Directional Fragment Histogram (DFH) describing the leaf margin, and several geometric parameters embedded in one single vector (Shapes6) of 6 dim. measuring 6 standard geometric parameters on the shape: rectangularity, convexity, solidity, circularity, Sphericity and Ellipse variance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Image level: late fusion of features</head><p>At this step, we have now for each image query I q several image training response lists, one for each type of (local or global) features. The next step is now to combine these responses in order to obtain a single response. Thus, we use a late fusion approach with different methods experimented through the four submitted runs.</p><p>CIN and WP (Run 1 ) For a query image I q , according to its organ/view, the basic algorithm applied is: (i) starting from the retrieved lists of similar training images for each type of feature, (ii) transform each list of images into a probability distribution by species with an adaptive rule CIN (see below), (iii) merge probabilities for all types of features with a Weighted Probability approach (WP).</p><p>CIN It an adaptive KNN rule established in this particular context of plant observations [?]. For converting an image response list to a species probability distribution, we use this adaptive rule focusing on plant observations (rather than images). Indeed, the more a species will be represented in a response through various plants observed by distinct users at different dates and locations, the more the associated images will be informative for predicting a species. In contrast, numerous redundant near duplicate images from the same plant observation will be less informative for predicting a species. Instead of using a basic KNN rule focusing on images, we search for top-K classes (species) represented with at least K different plant observations. The values of K and K are determined empirically based on the given training database, and are constant for a database: K is a percentage of the average size of the training class, while K is a percentage of the number of training classes. The response R is scanned from the most to the least similar image, the counter of the number of classes with at least K images is incremented accordingly, and when we find K such classes, we stop the scanning of the response. The adaptive criterion is important in order to avoid the noise in the final response: (a) had we searched for a fixed (and not dependent on the training data) number of classes with at least K plant observations, we would often output classes that are not relevant to fill-in the pre-defined requirement, or (b) had we output a fixed number of most similar classes, we would give more weight to the classes with small number of plant observations and would not reward the fact that some classes are well represented in terms of plant observations. Finally, our K per class resulted in the K per image of 85, ranging from 15 to 205, for the most to the least different-plantobservation-containing response; organ-wise, the values of K ranged from 66 for Stem to 101 for Fruit.</p><p>Moreover, to eliminate the redundant images, we consider only two most similar images per one plant observation: the score per plant observation S m is the average of the image scores S i . The score for a class is the sum of the scores of its plant observations S m : this step actually favours the well-represented classes, and penalizes the classes with small number of plant observations. Finally, the classes with only one image coming from one plant observation are removed from the list as outliers.</p><p>Weighted Probability combination (WP) At this step we have several species probability distributions, one for each type of features and we use a weighted fusion in order to obtain a final probability distribution. Let us define F as a set of local features and P (C k f ) as probability of class C k for feature f ∈ F . In order to reflect the discriminating power of each local feature, we define the final probability:</p><formula xml:id="formula_2" coords="6,248.61,190.09,231.98,22.21">P (C k ) = f ∈F w(f ) * P (C k f )<label>(2)</label></formula><p>where</p><formula xml:id="formula_3" coords="6,230.62,229.19,249.98,22.21">w(f ) = max ∀k P (C k f )/ f ∈F max ∀k P (C k f )<label>(3)</label></formula><p>BordaMNZ &amp; IrpMNZ (BordaMNZ: Run 2, 3 &amp; 4, IrpMNZ; Run 4 ) In [?] the authors proposed similarity ranking lists fusion algorithms in order to merge some multi-feature similarity lists into a final overall similarity ranking list. They showed good performances on their experimental results with basic algorithms working directly with the ranks, i.e. without complicated and empirical transformation of similarity lists into probability distributions. We experimented here with two algorithms in order to merge the image training response lists given by each type of features into one single list: the Borda Count Algorithm taken from social theory in voting, and the Inverse Rank Position Algorithm (Irp). Basically a score is computed for each training image contained in the response lists to combine, and then used for sorting a final merged list of training images. Considering an image query Q, a training image I i , and several image training response lists R, one for each feature f from a set of available features F , the score used in the Borda Count algorithm is the sum of the rank positions of the training image in the lists to merge:</p><formula xml:id="formula_4" coords="6,223.34,456.80,257.26,30.55">Borda(Q, I i ) = F f =1 rankposition(I i , f )<label>(4)</label></formula><p>The score used in the Irp algorithm is the inverse of the sum of inverses of the rank positions of the training image in the different lists to merge:</p><formula xml:id="formula_5" coords="6,230.18,527.07,250.41,27.01">Irp(Q, I i ) = 1 F f =1 1 rankposition(Ii,f ) (5)</formula><p>Like in the previous work mentioned in <ref type="bibr" coords="6,307.38,564.28,10.28,8.74">[?]</ref>, we used the MNZ extension of these two algorithms (BordaMNZ and IrpMNZ ) in order to heavily weights common training images in the lists to combine. Indeed, the hypothesis is that different lists contain similar sets of relevant training images while they contain different sets of non-relevant training images. Basically, the weights are based on the number of Non-Zero entries of each training images in the lists to combine, i.e. the number of times a training image appears in the ranked lists.</p><formula xml:id="formula_6" coords="6,222.21,656.12,258.38,9.65">BordaM N Z(Q, I i ) = Borda(Q, I i ) × α (6) IrpM N Z(Q, I i ) = Irp(Q, I i ) × α (7)</formula><p>where α is the number of feature response lists in which a training image was found.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Intermediate levels: multiple-images and organs/views</head><p>At this step, we have now a knowledge at the image query level combining the different type of features for each image query from a same observation plant query O q . This knowledge can be a probability distribution if the Weighted Probability approach was used, or a ranked training image list if the BordaMNZ or IrpMNZ methods were used. The image queries from a same plant O q can be related to the same or distinct organs and views showing different angles of the plant and we try here to take advantage from the complementarity of these views in order to compute a final knowledge at the observation level. Next combinations of knowledge are performed in this order:</p><p>image level to organ/view level (if the query plant O q has several images from one same organ/view V q ), then, organ/view level to observation level (if the query plant O q as several organs V ).</p><p>Only the Weighted Probability approach (Run 1 ) and the BordaMNZ approach (Run 2, 3 &amp; 4 ) are used in these upper levels of combination following the same formulas in previous subsections ??.</p><p>For instance, at organ level with the Weighted Probability approach, given several probability distributions from a set of different organs/views V , we apply the same the weighted fusion used as in subsection ?? where local features F are replaced by V .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Observation level and decision: the final knowledge to a species list</head><formula xml:id="formula_7" coords="7,134.77,547.16,79.00,8.74">(Run 1, 2, 3 &amp; 4 )</formula><p>At this final step, we have for one query observation plant O q , a distribution of probabilities if the Weighted Probability approach was used in the lower levels of fusion (Run 1 ), or a final list of training image response if the BordaMNZ was used instead.</p><p>In the case of the WP approach, the final list of species is directly given by the probability distribution following a decreasing order of probabilities. In the case of the BordaMNZ approach, we use a last step for converting the image list response into a probability distribution with the CIN rule (see previous section ??).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Summary of the different submitted runs</head><p>Preliminary evaluation and feature selection Considering the available number of visual feature for each images and the distinct methods of combinations, we supposed here that each type of organ/views has a its own relevant subset of visual features exploited no necessarily with the same combination method. We made some intensive preliminary evaluations on the training dataset in order to find these subsets and methods for each type of organ/views. We used a Leave One (Observation) Out procedure: focusing on one organ/view, for image from the training dataset, we use it as an internal query and excluded from the returned ranked image response list all the images belonging to the same plant observation as the query image, in order to remove a bias related to near duplicate images form a same plant. We concluded that in most of the cases, it was more or less the same subsets of features which was pointed out by the 3 fusion methods BordaMNZ, IrpMNZ and WP. Since the BordaMNZ demonstrated the best performances for mostly every organ/view, we choose to select its subset of visual features. As might be expected, color is dominant for the flower but may lead to confusion for leaves, while texture plays an important role for stems and fruits. The features finally selected are presented in table ??: Recap chart of the different submitted runs The Table <ref type="table" coords="8,404.38,510.39,4.98,8.74" target="#tab_3">2</ref> summary of the different methods used at each level of fusion for each submitted run.</p><p>PlantNet Run 1 is actually more or less the same method used for the submitted run Inria PlantNet Run 1 during the previous ImageCLEF 2013 Plant Task [?]. We used this configuration as a baseline in order to see the score this year despite 250 more new species, and to see if we can obtain better scores with the 3 new approaches experimented in the 3 other submitted runs.</p><p>PlantNet Run2 is the BordaMNZ version of the PlantNet Run 1, where for each step of fusion we changed the Weighted Probability WP combination method by the BordaMNZ method. In this way, only list responses are merged at each step, and finally we use the CIN approach in order to obtain a list of probability of species, and thus, a list of ranked of species according to these probability values.</p><p>PlantNet Run 3 is like the PlantNet Run2 except that we changed the local responses combination with the Ranking Dominate vote (see previous subsection ??).</p><p>PlantNet Run 4 is supposed to be the best configuration, where for each level of combination we choose the best method according to the preliminary evaluations on the training dataset. The BordaMNZ is most of the time the retained method, except for scans and stem pictures at the feature combination level for which we had noticed better performances with the IprMNZ combination. At the time of writing the paper, we noticed a mistake with the Fruit organ where we selected a Weighted Probability approach and which probably gave bad combinations in upper level since image response lists were expected instead of probability distributions. Submitted "image" runs For each submitted run, it was recommended but not mandatory to submit a second set of run files detailing species prediction at image level like in the previous ImageCLEF 2013 Plant Task [?]. The aim was to see if the participants can take benefit from the combination of multiple images from a same plant. In order to produce these complementary "image" runs, we simplify the hierarchical fusion of treatment, stopping at the feature combination level for one same image query (see Table <ref type="table" coords="9,385.81,493.41,3.87,8.74" target="#tab_4">3</ref>). Unfortunately, we encountered a problem during the generation of the file (Image) PlantNet Run 3 and we were not able to submit it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>Table ?? resumes the official scores for the first 7 submitted runs out of 27 total. Figure ?? gives an overview of all results obtained by the participants. Our four runs give generally good results and are placed in the 7 top runs, and we can say that our team take the lead of the pack of other participating teams, but far behind the impressive results obtained by the IBM AU team. As expected, we slightly improved performances with the new methods introduced this year, the previous method experimented in the PlantNet Run 1 being the less effective one. Best results are obtained by the full BordaMNZ approach in PlantNet Run for the first 6 submitted runs out of 14 total. Figure ?? gives an overview of all results obtained by the participants who submitted these optional runs. Our 3 submitted "image" runs by our team are in the top 6. For each method, like for most of other methods used by the other participants, it highlights the fact that we obtained some slightly improvement by combining the pictures and the organs/views from a same plant observation query.</p><p>Table ?? resumes the detailed scores by organs/views obtained for the first 10 submitted runs out of 14 total and Figure ?? gives an overview of all results obtained by the participants who submitted these optional runs. In most cases, our 3 submitted "image" runs by our team are in the top 6, expect for the Entire and Flower where the 4th run of IBM AU obtained best results, and for the Stem where the FINKI team used some better approaches.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>Inria within the PlantNet project submitted four runs, and 3 complementary "image" runs, that used the same hierarchical fusion framework, and where each run was related to distinct configurations of methods. All the submitted runs obtained good results and are ranked from the 4th to the 7th place compared to the other submitted run, but clearly behind the best results obtained by the IBM AU team. The first run was more or less the same approach used in the previous ImageCLEF 2013 plant identification task, and was considered as a baseline in our work. We try to improve this approach with simple but effective fusion approaches of ranked lists of results based on the Borda Count and the Inverse </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,134.77,205.83,345.81,7.89;3,134.77,216.81,83.01,7.86;3,142.43,121.90,79.53,59.65"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Examples of interest points detection with rhomboid-based mask and with grid-based weighting</figDesc><graphic coords="3,142.43,121.90,79.53,59.65" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="11,134.77,351.77,345.81,7.89;11,134.77,362.76,181.92,7.86;11,134.77,115.83,345.84,211.20"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Overview of the official scores of the LifeCLEF 2014 Plant Task. The four submitted runs by our team are in the top 7.</figDesc><graphic coords="11,134.77,115.83,345.84,211.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="13,184.21,351.77,246.94,7.89;13,134.77,115.83,345.84,211.20"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Overview of the detailed image scores by organ/view.</figDesc><graphic coords="13,134.77,115.83,345.84,211.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" coords="12,134.77,115.83,345.84,211.20"><head></head><label></label><figDesc></figDesc><graphic coords="12,134.77,115.83,345.84,211.20" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,134.77,370.14,345.81,119.09"><head>Table 1 .</head><label>1</label><figDesc>Selected features for each type of organ/view according to the preliminary evaluation on the training dataset with a Leave One (Observation) Out procedure.</figDesc><table coords="8,154.76,402.40,305.83,86.83"><row><cell>SURF Fourier EOH riLbp wRGB wLUV HSV SEFH DFH Shapes6</cell></row><row><cell>Branch</cell></row><row><cell>Entire</cell></row><row><cell>Flower</cell></row><row><cell>Fruit</cell></row><row><cell>Leaf</cell></row><row><cell>Scan</cell></row><row><cell>Stem</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,134.77,281.83,345.82,127.14"><head>Table 2 .</head><label>2</label><figDesc>Summary of the different methods used at each level of fusion for each submitted run.</figDesc><table coords="9,140.31,311.84,333.35,97.13"><row><cell>Run name</cell><cell>Local</cell><cell>Features</cell><cell cols="2">Images Organs/views</cell><cell>Observation (decision)</cell></row><row><cell cols="2">PlantNet Run 1 VOB</cell><cell>CIN+WP</cell><cell>WP</cell><cell>WP</cell></row><row><cell cols="2">PlantNet Run 2 VOB</cell><cell>BordaMNZ</cell><cell cols="2">BordaMNZ BordaMNZ</cell><cell>CIN</cell></row><row><cell cols="2">PlantNet Run 3 RD</cell><cell>BordaMNZ</cell><cell cols="2">BordaMNZ BordaMNZ</cell><cell>CIN</cell></row><row><cell></cell><cell></cell><cell>Fruit: WP</cell><cell></cell><cell></cell></row><row><cell cols="2">PlantNet Run 4 VOB</cell><cell>Scan: IprMNZ Stem: IprMNZ</cell><cell cols="2">BordaMNZ BordaMNZ</cell><cell>CIN</cell></row><row><cell></cell><cell></cell><cell>Others: BordaMNZ</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="10,134.77,115.91,345.84,331.68"><head>Table 3 .</head><label>3</label><figDesc>Summary of the different methods used at each level of fusion for each submitted "image" run. It is disappointing that the new Ranking Vote experimented in PlantNet Run 3 didn't show some improvement and is strangely very close to the second run PlantNet Run 2. Finally, our supposed best run PlantNet Run 4, with the best combination at each level of fusion, didn't show the best performances, but it is still better of our baseline Run PlantNet 1. Table?? resumes the scores obtained</figDesc><table coords="10,134.77,147.67,295.30,299.92"><row><cell>Run name</cell><cell>Local</cell><cell>Features</cell><cell>Decision</cell></row><row><cell cols="2">(Image) PlantNet Run 1 VOB</cell><cell>CIN+WP</cell><cell></cell></row><row><cell cols="2">(Image) PlantNet Run 2 VOB</cell><cell>BordaMNZ</cell><cell>CIN</cell></row><row><cell cols="2">(Image) PlantNet Run 3 RD</cell><cell>BordaMNZ</cell><cell>CIN</cell></row><row><cell></cell><cell></cell><cell>Fruit: WP</cell><cell></cell></row><row><cell cols="2">(Image) PlantNet Run 4 VOB</cell><cell>Scan: IprMNZ Stem: IprMNZ</cell><cell>CIN</cell></row><row><cell></cell><cell cols="2">Others: BordaMNZ</cell><cell></cell></row><row><cell cols="2">2. Run name</cell><cell>Score</cell><cell></cell></row><row><cell></cell><cell cols="2">IBM AU Run 4 0,471</cell><cell></cell></row><row><cell></cell><cell cols="2">IBM AU Run 3 0,459</cell><cell></cell></row><row><cell></cell><cell cols="2">IBM AU Run 2 0,454</cell><cell></cell></row><row><cell></cell><cell cols="2">PlantNet Run 2 0,289</cell><cell></cell></row><row><cell></cell><cell cols="2">PlantNet Run 3 0,289</cell><cell></cell></row><row><cell></cell><cell cols="2">PlantNet Run 4 0,282</cell><cell></cell></row><row><cell></cell><cell cols="2">PlantNet Run 1 0,278</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="10,134.77,460.57,345.81,18.85"><head>Table 4 .</head><label>4</label><figDesc>Official scores of the LifeCLEF 2014 Plant Task obtained by the the first 7 submitted runs out of 27 total.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="11,134.77,473.52,345.81,18.85"><head>Table 5 .</head><label>5</label><figDesc>"Image" scores of the LifeCLEF 2014 Plant Task obtained by the the first 6 submitted "image" runs out of 14 total.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_0" coords="1,144.73,656.80,136.48,7.86"><p>http://www.plantnet-project.org/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. Part of this work was funded by the <rs type="funder">Agropolis</rs> foundation through the project Pl@ntNet (http://www.plantnet-project.org/)</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run</head><p>Branch Entire Flower Fruit Leaf Leaf Scan Stem IBM AU Run 4 0,292 0,333 0,585 0,339 0,318 0,64 0,269 IBM AU Run 3 0,298 0,34 0,57 0,326 0,304 0,614 0,267 IBM AU Run 2 0,294 0,335 0,555 0,317 0,3 0,612 0,267 PlantNet Run 4 0,112 0,167 0,366 0,197 0,165 0,541 0,152 PlantNet Run 2 0,112 0,181 0,376 0,22 0,164 0,453 0,156 PlantNet Run 1 0,112 0,168 0,366 0,197 0,165 0,449 0,133 IBM AU Run 1 0,103 0,193 0,389 0,161 0,103 0,278 0,138 FINKI Run 1 0,088 0,117 0,255 0,177 0,16 0,4 0,157 FINKI Run 2 0,108 0,099 0,187 0,16 0,14 0,399 0,18 FINKI Run 3 0,088 0,117 0,255 0,177 0,162 0,36 0,159 Table <ref type="table" coords="12,163.35,523.83,4.13,7.89">6</ref>. Detailed image scores by organ/views obtained by the the first 10 submitted runs out of 14 total.</p><p>Rank Position Algorithms. These two approaches performed slightly better, and we obtained the best results for the full BordaMNZ approach.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="13,142.96,407.03,337.62,7.86;13,151.52,417.99,329.06,7.86;13,151.52,428.94,329.06,7.86;13,151.52,439.90,172.80,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,269.87,407.03,90.39,7.86">Models for metasearch</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">A</forename><surname>Aslam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montague</surname></persName>
		</author>
		<idno type="DOI">10.1145/383952.384007</idno>
		<ptr target="http://doi.acm.org/10.1145/383952.384007" />
	</analytic>
	<monogr>
		<title level="m" coord="13,383.09,407.03,97.48,7.86;13,151.52,417.99,329.06,7.86;13,151.52,428.94,85.07,7.86;13,295.62,428.94,39.06,7.86">Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting>the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="276" to="284" />
		</imprint>
	</monogr>
	<note>SIGIR &apos;01</note>
</biblStruct>

<biblStruct coords="13,142.96,450.58,337.62,7.86;13,151.52,461.54,329.06,7.86;13,151.52,472.49,329.05,7.86;13,151.52,483.45,25.60,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,240.01,461.54,240.57,7.86;13,151.52,472.49,15.40,7.86">Inria&apos;s participation at imageclef 2013 plant identification task</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bakic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mouine</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ouertani-Litayem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Verroust-Blondet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,187.78,472.49,188.24,7.86">CLEF (Online Working Notes/Labs/Workshop</title>
		<meeting><address><addrLine>Valencia, Espagne</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,494.13,337.62,7.86;13,151.52,505.09,329.06,7.86;13,151.52,516.04,317.27,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,283.84,505.09,196.74,7.86;13,151.52,516.04,94.76,7.86">Inria imedia2&apos;s participation at ImageCLEF 2012 plant identification task</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bakić</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mouine</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ouertani-Litayem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Ouertani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Verroust-Blondet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,267.27,516.04,168.11,7.86">CLEF (Notebook Papers/Labs/Workshop</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,526.72,26.09,7.86;13,187.80,526.72,292.78,7.86;13,151.52,537.68,253.30,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,344.88,526.72,131.91,7.86">Surf: Speeded up robust features</title>
		<author>
			<persName coords=""><forename type="first">Ess</forename><surname>Bay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,165.60,537.68,210.55,7.86">Computer Vision and Image Understanding (CVIU)</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,548.35,333.03,7.86" xml:id="b4">
	<monogr>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Evans</surname></persName>
		</author>
		<title level="m" coord="13,195.99,548.35,117.15,7.86">Notes on the opensurf library</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>University of Bristol</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Tech. rep.</note>
</biblStruct>

<biblStruct coords="13,142.96,559.02,337.62,7.86;13,151.52,569.98,304.81,7.86" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ferecatu</surname></persName>
		</author>
		<title level="m" coord="13,207.64,559.02,272.93,7.86;13,151.52,569.98,104.39,7.86">Image retrieval with active relevance feedback using both visual and keyword-based descriptors</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
		<respStmt>
			<orgName>Univ. Versailles St-Quentin</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. thesis</note>
</biblStruct>

<biblStruct coords="13,142.96,580.66,337.62,7.86;13,151.52,591.62,329.06,7.86;13,151.52,602.57,243.49,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,228.75,591.62,126.94,7.86">Multi-organ plant identification</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Barbe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bakić</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Barthélémy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,377.31,591.62,103.27,7.86;13,151.52,602.57,214.83,7.86">Workshop on Multimedia Analysis for Ecological Data Proceedings. MAED &apos;12</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,613.25,337.62,7.86;13,151.52,624.21,318.05,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,166.63,624.21,127.91,7.86">Lifeclef plant identification task</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Selmi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F</forename><surname>Molino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Barthélémy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,335.75,624.21,83.64,7.86">CLEF working notes</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="page">2014</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.96,634.88,337.62,7.86;13,151.52,645.84,329.06,7.86;13,151.52,656.80,173.74,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="13,399.83,634.88,80.75,7.86;13,151.52,645.84,282.20,7.86">Participation of IN-RIA&amp; Pl@ntNet to ImageCLEF 2011 plant images classification task</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Mouysset</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,455.88,645.84,24.70,7.86;13,151.52,656.80,140.34,7.86">CLEF (Notebook Papers/Labs/Workshop</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,119.67,336.33,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="14,240.44,119.67,140.40,7.86">Random maximum margin hashing</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Buisson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,402.16,119.67,48.12,7.86">CVPR 2011</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,130.63,337.96,7.86;14,151.52,141.59,329.06,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="14,240.85,130.63,200.65,7.86">A posteriori multi-probe locality sensitive hashing</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Buisson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,463.02,130.63,17.55,7.86;14,151.52,141.59,300.76,7.86">Proceedings of the 16th ACM international conference on Multimedia. MM &apos;08</title>
		<meeting>the 16th ACM international conference on Multimedia. MM &apos;08</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,152.55,337.96,7.86;14,151.52,163.51,329.06,7.86;14,151.52,174.47,196.46,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="14,276.15,163.51,204.43,7.86;14,151.52,174.47,38.91,7.86">Lifeclef 2014: multimedia life species identification challenges</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Goëau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Glotin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Spampinato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rauber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bonnet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">P</forename><surname>Vellinga</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,211.47,174.47,107.85,7.86">Proceedings of CLEF 2014</title>
		<meeting>CLEF 2014</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,185.43,337.96,7.86;14,151.52,196.39,329.06,7.86;14,151.52,207.35,329.06,7.86;14,151.52,218.30,320.48,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="14,357.10,185.43,123.48,7.86;14,151.52,196.39,215.99,7.86">Image retrieval based on similarity score fusion from feature similarity ranking lists</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jovic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Hatakeyama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hirota</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,252.36,207.35,164.39,7.86">Fuzzy Systems and Knowledge Discovery</title>
		<title level="s" coord="14,424.10,207.35,56.48,7.86;14,151.52,218.30,82.07,7.86">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Wang</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Jiao</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Shi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Liu</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">4223</biblScope>
			<biblScope unit="page" from="461" to="470" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,229.26,337.96,7.86;14,151.52,240.22,329.05,7.86;14,151.52,251.18,326.06,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="14,323.62,229.26,156.96,7.86;14,151.52,240.22,177.98,7.86">Gray scale and rotation invariant texture classification with local binary patterns</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pietikäinen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mäenpää</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,351.05,240.22,125.32,7.86">Computer Vision -ECCV 2000</title>
		<title level="s" coord="14,151.52,251.18,141.41,7.86">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">1842</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,262.14,337.96,7.86;14,151.52,273.10,125.55,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="14,326.24,262.14,154.34,7.86;14,151.52,273.10,51.37,7.86">Leaf shape descriptor for tree species identification</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Yahiaoui</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Mzoughi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Boujemaa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="14,223.70,273.10,24.70,7.86">ICME</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="14,142.61,284.06,337.97,7.86;14,151.52,295.02,329.06,7.86;14,151.52,305.98,207.19,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="14,253.62,284.06,226.97,7.86;14,151.52,295.02,66.09,7.86">Efficient processing of top-k dominating queries on multidimensional data</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Yiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Mamoulis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="14,236.81,295.02,243.76,7.86;14,151.52,305.98,40.70,7.86">Proceedings of the 33rd international conference on Very large data bases</title>
		<meeting>the 33rd international conference on Very large data bases</meeting>
		<imprint>
			<publisher>VLDB Endowment</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="483" to="494" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
