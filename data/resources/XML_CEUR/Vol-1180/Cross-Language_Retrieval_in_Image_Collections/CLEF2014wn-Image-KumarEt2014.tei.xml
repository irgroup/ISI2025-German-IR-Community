<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,139.98,116.95,335.40,12.62;1,182.77,134.89,249.82,12.62;1,231.54,152.82,152.27,12.62">Automatic Annotation of Liver CT Images: the Submission of the BMET Group to ImageCLEFmed 2014</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,139.74,190.57,61.80,8.74"><forename type="first">Ashnil</forename><surname>Kumar</surname></persName>
							<email>ashnil.kumar@sydney.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Technologies</orgName>
								<orgName type="institution">University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Institute of Biomedical Engineering and Technology</orgName>
								<orgName type="institution">University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,218.43,190.57,50.26,8.74"><forename type="first">Shane</forename><surname>Dyer</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">School of Electrical and Information Engineering</orgName>
								<orgName type="institution">University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,279.24,190.57,61.03,8.74"><forename type="first">Changyang</forename><surname>Li</surname></persName>
							<email>changyang.li@sydney.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Technologies</orgName>
								<orgName type="institution">University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Institute of Biomedical Engineering and Technology</orgName>
								<orgName type="institution">University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,357.16,190.57,85.52,8.74"><forename type="first">Philip</forename><forename type="middle">H W</forename><surname>Leong</surname></persName>
							<email>philip.leong@sydney.edu.au</email>
							<affiliation key="aff1">
								<orgName type="department">School of Electrical and Information Engineering</orgName>
								<orgName type="institution">University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Institute of Biomedical Engineering and Technology</orgName>
								<orgName type="institution">University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,275.09,202.52,54.38,8.74"><forename type="first">Jinman</forename><surname>Kim</surname></persName>
							<email>jinman.kim@sydney.edu.au</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information Technologies</orgName>
								<orgName type="institution">University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Institute of Biomedical Engineering and Technology</orgName>
								<orgName type="institution">University of Sydney</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,139.98,116.95,335.40,12.62;1,182.77,134.89,249.82,12.62;1,231.54,152.82,152.27,12.62">Automatic Annotation of Liver CT Images: the Submission of the BMET Group to ImageCLEFmed 2014</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">59DA69948AD25563605F87000AFFEE27</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>SVM</term>
					<term>Image Retrieval</term>
					<term>Multi-class Classification</term>
					<term>Image Annotation</term>
					<term>Liver</term>
					<term>Computed Tomography</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we present the strategies that were designed and applied by the Institute of Biomedical Engineering and Technology (BMET) team to the liver image annotation task of ImageCLEF 2014. This was the first year this challenge was held and as such our strategies form the basis for future exploration in this area. The major challenge of the liver annotation task was limited training data, with some annotation labels having very few positive samples and other labels having no samples at all. We propose two strategies for annotating the liver images given the unbalanced nature of the training dataset. Our first method uses multi-class classification scheme where each label has a classifier that is trained to separate it from the other labels. Our second method uses the similarity scores from an image retrieval algorithm as weights for a majority voting scheme, thereby reducing the inherent bias towards labels that have a high number of samples. We also investigate the performance of our methods using different feature sets. In total, BMET submitted 8 runs to the ImageCLEF liver annotation task. All of our runs achieved high scores (&gt; 90%) during evaluation. We also achieved the highest score out of all submissions to the ImageCLEF 2014 liver annotation task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>ImageCLEF <ref type="bibr" coords="1,191.77,597.34,10.52,8.74" target="#b0">[1]</ref> is the image retrieval track of the Cross Language Evaluation Forum (CLEF). In the past, one of the major focuses of ImageCLEF <ref type="bibr" coords="1,442.06,609.29,8.19,8.74" target="#b1">[2]</ref><ref type="bibr" coords="1,450.25,609.29,4.09,8.74" target="#b2">[3]</ref><ref type="bibr" coords="1,450.25,609.29,4.09,8.74" target="#b3">[4]</ref><ref type="bibr" coords="1,450.25,609.29,4.09,8.74" target="#b4">[5]</ref><ref type="bibr" coords="1,450.25,609.29,4.09,8.74" target="#b5">[6]</ref><ref type="bibr" coords="1,450.25,609.29,4.09,8.74" target="#b6">[7]</ref><ref type="bibr" coords="1,454.34,609.29,8.19,8.74" target="#b7">[8]</ref> has been medical imaging, with tasks ranging from modality-classification to casebased retrieval. In 2014, for the first time, the objective of the ImageCLEF medical imaging task was the automatic annotation of medical images <ref type="bibr" coords="1,446.64,645.16,9.96,8.74" target="#b8">[9]</ref>. The aim of the challenge was to generate a structured report based on an analysis of the image features in computed tomography (CT) images of the liver, with the goal of detecting subtle differences in image features and to annotate them using a standard terminology.</p><p>One of the major challenges was the limited amount of training data compared to the number of annotations that needed to be recognised. In particular, there were some annotations that did not occur at all in the dataset. Similarly, there were also instances where all of the training samples had the same annotation. Our methods were thus designed to account for the unbalanced dataset by reducing the bias towards annotations with more samples.</p><p>In this paper, we outline our submission to ImageCLEF 2014 liver annotation challenge. We present two methods for the annotation of liver CT images, one based on multi-class classification and another using image retrieval. Our aim was to perform the annotation using visual features only. As such, we do not utilise any of the information in the ONtology of the LIver for RAdiology (ONLIRA) <ref type="bibr" coords="2,205.16,296.35,14.61,8.74" target="#b9">[10]</ref>, such as the semantic distance between related terms <ref type="bibr" coords="2,462.34,296.35,14.61,8.74" target="#b10">[11]</ref>. Our method treats the challenge as multiple multi-class classification problems. We adapted well-established classification and retrieval techniques to investigate their perform on the annotation of liver CT images. We envision that this will establish a baseline for improvements in future iterations of the challenge.</p><p>The following terminology is employed in the remainder of this paper. A question refers to a specific annotation task, i.e., an element of the structured report that needs to be automatically filled. A label is a possible annotation that can be assigned to a question. An answer is the label that is assigned to the question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Materials</head><p>The training dataset contained 50 CT volumes cropped to the region around the liver; the volumes had varied resolutions (x: 190-308 pixels, y: 213-387 pixels, slices: 41-588) and spacings (x, y: 0.674-1.007mm, slice: 0.399-2.5mm). A mask of the liver pixels and the bounding box for a selected lesion was provided for each image in the training dataset. The training data also included a set of 60 well-established image features (with a total dimensionality of 458) that had been extracted from the images in the dataset. The answers to 73 questions was provided for each training image.</p><p>The test dataset contained 10 CT volumes, with varied resolutions and pixel spacings, cropped to the region around the liver. The test data also included a mask of the liver pixels, a bounding box for a lesion and a set of 60 wellestablished image features (with a total dimensionality of 458) for each image in the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview</head><p>Our aim was to investigate annotation using variations of two methods: support vector machine (SVM) classification <ref type="bibr" coords="3,294.25,174.76,15.50,8.74" target="#b11">[12]</ref> and content-based image retrieval <ref type="bibr" coords="3,462.34,174.76,14.61,8.74" target="#b12">[13]</ref>. The specific variations that we used were:</p><p>• Method 1: Two stage classification using SVMs with linear kernels.</p><p>• Method 2: Two stage classification using SVMs with radial basis function (RBF) kernels. • Method 3: Content-based image retrieval.</p><p>• Method 4: Content-based image retrieval with feature selection.</p><p>The two-stage classification method is described in Section 3.3 and the image retrieval method is described in Section 3.4.</p><p>We also investigated the effect of expanding feature set on all these methods. The feature set expansion is described in Section 3.2.</p><p>Our method was applied to a subset of the annotations; seven questions where the label sets were unbounded (e.g., measurements in millimetres or counts of particular objects) were excluded. We also excluded one question that accepted multiple labels as the answer. In total, we answered 64 of the 73 questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Feature Sets</head><p>We used two feature sets for the annotation challenge. These were:</p><p>• Feature Set 1: The well-established features included with dataset after cleaning as described below (total dimensionality = 446). • Feature Set 2: Feature Set 1 + a bag-of-visual-words (BoVW) features, constructed as described below (total dimensionality = 1446).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset Features</head><p>The image features in the dataset included features extracted from the liver, the hepatic vasculature of the liver, and the selected lesion. Features extracted globally across all lesions were also included. The features described object shape properties (e.g., volume, surface area, sphericity, solidity, convexity, Hu shape invariants <ref type="bibr" coords="3,311.41,537.56,14.76,8.74" target="#b13">[14]</ref>), texture information (e.g., Haralick <ref type="bibr" coords="3,150.27,549.52,14.61,8.74" target="#b14">[15]</ref>, Gabor <ref type="bibr" coords="3,202.67,549.52,14.61,8.74" target="#b15">[16]</ref>, Tamura <ref type="bibr" coords="3,261.36,549.52,14.61,8.74" target="#b16">[17]</ref>, Haar <ref type="bibr" coords="3,307.61,549.52,14.76,8.74" target="#b17">[18]</ref>), and pixel intensity information.</p><p>We cleaned the feature data by removing feature dimensions that had a nota-number (NaN) value or that were used to scale other features. We removed the Anatomical Location feature (5 dimensions) of the lesion since one training image had NaN values for this feature. The Hu Moments feature (3 dimensions) of the lesion was also removed for the same reason. We also removed the first two dimensions (upper and lower bounds) of the Histogram feature of the lesion and the HistogramOfAllLesions (a feature extracted across all lesions). The cleaned feature set had a dimensionality of 446. Readers are directed to the task documentation for more information about the image features.   Bag-of-Visual-Words We extracted Scale Invariant Feature Transform (SIFT) descriptors <ref type="bibr" coords="4,186.57,404.19,15.50,8.74" target="#b18">[19]</ref> from key points detected in the 2D slices of the CT images. There were a total of 4,524,946 descriptors extracted from the training dataset and 433,846 descriptors extracted from the test dataset.</p><p>We created a visual codebook from the SIFT descriptors extracted from the training dataset. We randomly sampled 5% of the descriptors and grouped the subsampled data using k-means clustering with k = 1000. The cluster centres were treated as the visual words in the codebook. A single visual word was assigned to every descriptor in both datasets; this assignment was determined by finding the visual word whose cluster centre with the minimum Euclidean distance from the descriptor. A BoVW descriptor was then created for every image using a 1000-bin histogram of the visual words in that image <ref type="bibr" coords="4,432.55,523.74,14.61,8.74" target="#b19">[20]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Annotation using Two Stage Classification</head><p>Our two stage classification approach for image annotation is shown in Figure <ref type="figure" coords="4,472.86,573.43,3.87,8.74" target="#fig_2">1</ref>. Each stage consisted of a bank of several SVM classifiers. This two stage approach was repeated separately for each question. Due to the unbalanced training dataset, we expected that the classifiers for labels with low samples would have relatively low accuracy. For this reason, we used the two stage approach to introduce further discriminative power, especially in the case of ties.</p><p>Let Ω be a question. Also let L Ω be the set of labels for Ω with |L Ω | = l. For every label A ∈ L, we trained a A-vs-rest (1-vs-all) SVM classifier, hence forming l 1-vs-all classifiers. We also trained A-vs-B (1-vs-1) SVMs for every pair of labels A, B ∈ L where A = B, forming a total of l 2 -l /2 1-vs-1 classifiers. For every question, our first stage was composed of the 1-vs-all classifiers and the second stage was composed of the 1-vs-1 classifiers.</p><p>After the classifiers have been trained, our annotation process proceeded as follows. An un-annotated image (from the test dataset) was classified using the first stage. If only one of the 1-vs-all SVMs returned a positive classification (i.e., there was no tie) then the label corresponding to that classifier was adopted as the answer. If the classifiers in the first stage assigned multiple labels (i.e., multiple 1-vs-all classifiers returned positive results) then the second stage was activated.</p><p>Let L + ⊆ L be the set of labels given positive responses by the first stage of classifiers. During the second stage, we classified the un-annotated image using the 1-vs-1 classifiers for all the labels in L + (i.e., the 1-vs-1 classifiers for the tied labels). A majority voting scheme was used to select the answer.</p><p>Two tiebreaker situations remained after both classification stages were completed. The ties included the case where the first stage did not return a positive label and when there was a tie in the vote during the second stage (multiple labels had the highest majority vote). In both of these situations, we set the answer to "other", noted in the task description as the label selected when the radiologist was unsure of the correct annotation. For such ties in questions Ω where "other" / ∈ L Ω , we selected the label "N/A" if it was available or "false" for questions that expected a boolean answer.</p><p>During training, we tested our algorithm on various SVM kernels (linear, quadratic, radial basis function (RBF), multilayer perceptron, polynomial) and parameters using 10-fold cross validation. We discovered that the best overall accuracy was achieved by the RBF kernel with scaling factor equal to 1. There were only five questions in which the RBF kernel was beaten by other kernels and in each of these cases the difference was not significant. We therefore selected the commonly-used linear kernel and the RBF kernels for our classification approach (Methods 1 and 2, respectively).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Annotation using Image Retrieval</head><p>Our image retrieval based approach for annotation used the most similar training images to select the answers for an un-annotated image. While the classification approach (Section 3.3) trained separate classifiers for each question, the retrieval approach attempted to answer all of the questions together. An overview of the method is shown in Figure <ref type="figure" coords="5,254.33,586.32,3.87,8.74" target="#fig_3">2</ref>.</p><p>We defined the similarity of the the unannotated image (U ) and a training image (T ) as the Euclidean distance between their respective feature vectors:  where u i was the i-th feature in the feature vector of U , t i was the i-th feature in the feature vector of T , and d was the dimensionality of the feature set (see Section 3.2). Under this formulation, lower values of s indicated greater similarity with s (U, T ) = 0 implying that U and T were exactly similar. We selected the n most similar images from the training data. Let S = {s 1 , ..., s n } be the similarity values of these images (sorted from most similar to least similar). A weighted voting scheme was used to select the answer for each question. The weights for the voting scheme were determined from the set of similarity values. The weight w i for the i-th most similar image was calculated as:</p><formula xml:id="formula_0" coords="5,251.34,637.46,229.25,30.32">s (U, T ) = d i=0 (u i -t i ) 2 (1)</formula><formula xml:id="formula_1" coords="6,282.38,540.18,198.21,23.23">w i = c × s i s 1<label>(2)</label></formula><p>where c was a constant scaling factor and s i ∈ S was the similarity value of the i-th most similar image. In our experiments, we empirically set n = 10 and c = 10. Our weighting scheme adjusted the value of the vote based on the calculated similarity. Images with a higher similarity would thus have a stronger vote compared to images with a lower similarity. The weighting was necessary due to the unbalanced nature of the dataset. If a majority voting scheme was used then the labels that had a higher frequency in the dataset would have a higher chance to be selected as the answer (depending on the value of n). In the case of a tie (multiple labels having the same weighted vote), we set the answer to "other". When "other" was not part of the label set, we selected the label "N/A" if it was available or "false" for questions that expected a boolean answer.</p><p>We also designed an alternate question-based version of our retrieval scheme for annotation; this is noted as Method 4 in Section 3.1. In the alternate scheme, we applied sequential feature selection <ref type="bibr" coords="7,307.02,367.03,15.50,8.74" target="#b20">[21]</ref> to use the most discriminating features for each question during the similarity calculation (Equation <ref type="formula" coords="7,429.22,378.98,3.87,8.74">1</ref>). This ensured that optimised features were used to retrieve the most similar images, i.e., image retrieval was performed using the features most suited for answering a particular question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussion</head><p>We submitted eight runs to the ImageCLEF 2014 liver annotation challenge. The runs were created using a combination of the four methods listed in Section 3.1 and the two feature sets listed in Section 3.2. The runs were evaluated on completeness, the percentage of questions that were answered, and accuracy, the percentage of completed questions with a correct answer. Only 65 questions formed part of the evaluation; questions with unbounded labels (e.g., measurements) were not evaluated as part of the 2014 challenge. Table <ref type="table" coords="7,405.08,542.70,4.98,8.74" target="#tab_1">1</ref> shows the mean completeness and accuracy of our eight runs.</p><p>There were 20 registered participants for the ImageCLEF 2014 liver annotation challenge. However, only three groups (including ours) submitted runs for evaluation. A comparison of the groups is shown in Table <ref type="table" coords="7,413.95,590.55,3.87,8.74" target="#tab_2">2</ref>. In 2014, our submission achieved the highest score of all the participants.</p><p>The results show that all of our runs achieved high scores (&gt; 0.92). We achieved a completeness score of 0.98 for every run because we always answered 64 of the 65 questions. The question that we excluded from our submission was one that accepted multiple labels as the answer. We could answer this question and achieve a perfect completeness score by removing the tiebreaker from both of our annotation methods. This would be an exception for only this particular question, i.e., all other questions would still go through a tiebreaker process if necessary.</p><p>In general, there were no large differences between the two variants of the classification method. That is, the accuracy of two classification methods (Method 1 and Method 2) were approximately the same. This suggests that the choice of kernel was not a major factor in the overall accuracy of the annotation. This outcome was contrary to the training stage (as stated in Section 3.3) where our selection of the RBF kernel (Method 2) was due to its higher accuracy compared to the other kernels. We attribute this difference to the unbalanced training dataset, which may not have reflected the labels of the test dataset. However, our high scores (&gt; 0.93) demonstrate that our classification approach for annotation performs well despite the unbalanced training dataset.</p><p>The score of the retrieval method with feature selection (Method 4) was equal to or less than that of the retrieval method with no feature selection (Method 3). This result is counter-intuitive as the expectation is that feature selection would improve the accuracy of the annotation. One explanation for this could be that the feature selection reduces the similarity scores calculated during retrieval (since fewer features are used), which in turn negatively impacts the weighted vote by returning voting power to labels with a larger number of training samples.</p><p>It is interesting to note that the classification methods performed best when using the expanded feature set (Feature Set 2) while the retrieval methods performed best when using the normal feature set (Feature Set 1). This suggests that one of the major considerations in the annotation of the liver is the combination of features and methods. That is, the findings indicate that one cannot choose a method for annotation without considering which features will be used, and vice versa.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>This paper described the methods and results of the BMET group's submission to the liver annotation task of ImageCLEF 2014. Our eight runs investigated different combinations of methods and feature sets. While all of our runs achieved high scores they also revealed the areas in which our method could be optimised.</p><p>Our future work will investigate building associations between image features and ONLIRA terms to create classifiers for labels with no samples in the training dataset <ref type="bibr" coords="9,169.69,143.90,14.61,8.74" target="#b21">[22]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,181.44,357.05,252.47,7.86"><head>Fig. 1 :</head><label>1</label><figDesc>Fig. 1: An overview of the classification scheme for annotation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="6,190.30,381.95,234.76,7.86"><head>Fig. 2 :</head><label>2</label><figDesc>Fig.2: An overview of the retrieval scheme for annotation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,177.68,116.61,260.00,149.82"><head>Table 1 :</head><label>1</label><figDesc>Summary of Results 1</figDesc><table coords="7,177.68,142.97,260.00,123.46"><row><cell cols="6">Run Method Feature Set Completeness Accuracy Score</cell></row><row><cell>1</cell><cell>1</cell><cell>1</cell><cell>0.98</cell><cell>0.89</cell><cell>0.935</cell></row><row><cell>2</cell><cell>1</cell><cell>2</cell><cell>0.98</cell><cell>0.90</cell><cell>0.939</cell></row><row><cell>3</cell><cell>2</cell><cell>1</cell><cell>0.98</cell><cell>0.89</cell><cell>0.933</cell></row><row><cell>4</cell><cell>2</cell><cell>2</cell><cell>0.98</cell><cell>0.90</cell><cell>0.939</cell></row><row><cell>5</cell><cell>3</cell><cell>1</cell><cell>0.98</cell><cell>0.91</cell><cell>0.947</cell></row><row><cell>6</cell><cell>3</cell><cell>2</cell><cell>0.98</cell><cell>0.87</cell><cell>0.927</cell></row><row><cell>7</cell><cell>4</cell><cell>1</cell><cell>0.98</cell><cell>0.91</cell><cell>0.947</cell></row><row><cell>8</cell><cell>4</cell><cell>2</cell><cell>0.98</cell><cell>0.87</cell><cell>0.926</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,196.91,116.61,221.55,77.39"><head>Table 2 :</head><label>2</label><figDesc>Comparison of Results 1</figDesc><table coords="8,196.91,142.97,221.55,51.03"><row><cell>Group</cell><cell cols="3">Completeness Accuracy Score</cell></row><row><cell>BMET (our group)</cell><cell>0.98</cell><cell>0.91</cell><cell>0.94</cell></row><row><cell>CASMIP</cell><cell>0.95</cell><cell>0.91</cell><cell>0.93</cell></row><row><cell>piLabVAVlab</cell><cell>0.51</cell><cell>0.39</cell><cell>0.45</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="7,144.73,657.80,298.12,8.11"><p>These results are from http://www.imageclef.org/2014/liver#Results.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. The authors would like to thank the organisers of the ImageCLEF 2014 liver annotation task for their assistance in procuring the detailed results.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="9,142.96,245.86,337.62,7.86;9,151.52,254.55,329.06,10.13;9,151.52,267.78,329.06,7.86;9,151.52,278.74,293.29,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,151.52,267.78,226.29,7.86">ImageCLEF 2014: Overview and analysis of the results</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Martinez-Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Patricia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Marvasti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Üsküdarlı</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Paredes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Cazorla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Garcia-Varea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Morell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,402.58,267.78,73.88,7.86">CLEF proceedings</title>
		<title level="s" coord="9,151.52,278.74,141.41,7.86">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin / Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,289.13,337.62,7.86;9,151.52,300.09,329.06,7.86;9,151.52,311.05,329.06,7.86;9,151.52,322.01,329.06,7.86;9,151.52,332.97,329.06,7.86;9,151.52,343.93,107.02,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,151.52,300.09,329.06,7.86;9,151.52,311.05,19.07,7.86">Overview of the ImageCLEFmed 2007 medical retrieval and medical annotation tasks</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deserno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,263.37,322.01,217.21,7.86;9,151.52,332.97,34.93,7.86">Advances in Multilingual and Multimodal Information Retrieval</title>
		<title level="s" coord="9,259.72,332.97,142.45,7.86">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Jijkoun</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Mandl</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Oard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Peñas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Petras</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Santos</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin / Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">5152</biblScope>
			<biblScope unit="page" from="472" to="491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,354.32,337.62,7.86;9,151.52,365.28,329.05,7.86;9,151.52,376.24,329.05,7.86;9,151.52,387.20,329.06,7.86;9,151.52,398.16,329.06,7.86;9,151.52,409.12,107.02,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,151.52,365.28,267.90,7.86">Overview of the ImageCLEFmed 2008 medical image retrieval task</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Kahn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Hatt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,217.94,387.20,262.64,7.86;9,151.52,398.16,24.88,7.86">Evaluating Systems for Multilingual and Multimodal Information Access</title>
		<title level="s" coord="9,252.95,398.16,145.46,7.86">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Kurimo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Mandl</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Peñas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">V</forename><surname>Petras</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin / Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5706</biblScope>
			<biblScope unit="page" from="512" to="522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,419.51,337.62,7.86;9,151.52,430.47,329.06,7.86;9,151.52,441.43,329.06,7.86;9,151.52,452.39,329.06,7.86;9,151.52,463.35,329.05,7.86;9,151.52,474.31,105.49,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,242.93,430.47,233.81,7.86">Overview of the CLEF 2009 medical image retrieval track</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Eggel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Radhouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Bakke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Kahn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,241.67,452.39,238.91,7.86;9,151.52,463.35,48.76,7.86">Multilingual Information Access Evaluation II. Multimedia Experiments</title>
		<title level="s" coord="9,271.81,463.35,140.16,7.86">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Caputo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Kalpathy-Cramer</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin / Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">6242</biblScope>
			<biblScope unit="page" from="72" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,484.70,337.62,7.86;9,151.52,495.66,329.05,7.86;9,151.52,506.62,273.56,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,210.57,495.66,270.00,7.86;9,151.52,506.62,47.50,7.86">Overview of the CLEF 2011 medical image classification and retrieval tasks</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Eggel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,221.01,506.62,166.13,7.86">CLEF (Notebook Papers/Labs/Workshop</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,517.02,337.62,7.86;9,151.52,527.98,329.06,7.86;9,151.52,538.94,319.33,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,227.43,527.98,253.15,7.86;9,151.52,538.94,72.92,7.86">Overview of the ImageCLEF 2012 medical image retrieval and classification tasks</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Eggel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,246.43,538.94,186.46,7.86">CLEF (Online Working Notes/Labs/Workshop</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,549.33,337.62,7.86;9,151.52,560.29,329.05,7.86;9,151.52,571.25,25.60,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,170.63,560.29,199.59,7.86">Overview of the ImageCLEF 2013 medical tasks</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,381.12,560.29,99.46,7.86">Working notes of CLEF</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,581.65,337.62,7.86;9,151.52,592.60,329.06,7.86;9,151.52,603.56,329.06,7.86;9,151.52,614.52,329.05,7.86;9,151.52,625.48,149.75,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,269.99,592.60,210.59,7.86;9,151.52,603.56,329.06,7.86;9,151.52,614.52,69.71,7.86">Evaluating performance of biomedical image retrieval systems-an overview of the medical image retrieval task at Image-CLEF 2004-2013</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G S</forename><surname>De Herrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Antani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.compmedimag.2014.03.004</idno>
	</analytic>
	<monogr>
		<title level="j" coord="9,236.63,614.52,192.72,7.86">Computerized Medical Imaging and Graphics</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,142.96,633.61,337.63,10.13;9,151.52,646.84,329.05,7.86;9,151.52,657.80,206.90,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,166.05,646.84,183.78,7.86">ImageCLEF Liver CT Image Annotation Task</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Marvasti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kökciyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Türkay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Yazıcı</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yolum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Üsküdarlı</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Acar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,389.39,646.84,91.19,7.86;9,151.52,657.80,78.17,7.86">CLEF 2014 Evaluation Labs and Workshop</title>
		<title level="s" coord="9,237.52,657.80,87.99,7.86">Online Working Notes</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,120.67,337.96,7.86;10,151.52,131.63,329.05,7.86;10,151.52,142.59,256.80,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,443.97,120.67,36.61,7.86;10,151.52,131.63,220.14,7.86">Semantic description of liver CT images: An ontological approach</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kokciyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Turkay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Uskudarli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yolum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Bakir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Acar</surname></persName>
		</author>
		<idno type="DOI">10.1109/JBHI.2014.2298880</idno>
	</analytic>
	<monogr>
		<title level="j" coord="10,379.29,131.63,101.29,7.86;10,151.52,142.59,110.40,7.86">IEEE Journal of Biomedical and Health Informatics</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,153.55,337.96,7.86;10,151.52,164.48,237.76,7.89" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,257.60,153.55,222.98,7.86;10,151.52,164.51,42.83,7.86">Evaluating WordNet-based measures of lexical semantic relatedness</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Budanitsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hirst</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,202.32,164.51,106.72,7.86">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="13" to="47" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,175.47,337.96,7.86;10,151.52,186.42,329.05,7.86;10,151.52,197.38,25.60,7.86" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="10,272.84,175.47,207.74,7.86;10,151.52,186.42,173.02,7.86">Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Scholkopf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">J</forename><surname>Smola</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,208.34,337.96,7.86;10,151.52,219.30,329.05,7.86;10,151.52,230.23,161.89,7.89" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="10,321.45,208.34,159.12,7.86;10,151.52,219.30,278.65,7.86">Content-based medical image retrieval: a survey of applications to multidimensional and multimodality data</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Cai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,439.38,219.30,41.19,7.86;10,151.52,230.26,63.09,7.86">Journal of Digital Imaging</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1025" to="1039" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,241.22,337.96,7.86;10,151.52,252.15,170.53,7.89" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,196.41,241.22,194.98,7.86">Visual pattern recognition by moment invariants</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">K</forename><surname>Hu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,399.19,241.22,81.38,7.86;10,151.52,252.18,83.31,7.86">Information Theory, IRE Transactions on</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="187" />
			<date type="published" when="1962">1962</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,263.14,337.96,7.86;10,151.52,274.07,329.07,7.89;10,151.52,285.05,18.43,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,342.08,263.14,138.49,7.86;10,151.52,274.10,28.67,7.86">Textural features for image classification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Haralick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Shanmugam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Dinstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,190.28,274.10,222.14,7.86">IEEE Transactions on Systems, Man and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="610" to="621" />
			<date type="published" when="1973">1973</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,296.01,337.96,7.86;10,151.52,306.97,323.14,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,250.33,296.01,213.32,7.86">Unsupervised texture segmentation using gabor filters</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Farrokhnia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,151.52,306.97,264.17,7.86">IEEE International Conference on Systems, Man and Cybernetics</title>
		<imprint>
			<biblScope unit="page" from="14" to="19" />
			<date type="published" when="1990">1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,317.93,337.96,7.86;10,151.52,328.86,329.07,7.89;10,151.52,339.85,32.25,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,311.26,317.93,169.32,7.86;10,151.52,328.89,40.74,7.86">Textural features corresponding to visual perception</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Tamura</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Yamawaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,204.26,328.89,224.93,7.86">IEEE Transactions on Systems, Man and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="460" to="473" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,350.81,337.96,7.86;10,151.52,361.77,329.06,7.86;10,151.52,372.73,114.30,7.86" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="10,242.82,350.81,237.75,7.86;10,151.52,361.77,30.33,7.86">Rapid object detection using a boosted cascade of simple features</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Viola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,202.65,361.77,277.93,7.86;10,151.52,372.73,46.11,7.86">IEEE Computer Society Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<biblScope unit="page" from="511" to="518" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,383.68,337.96,7.86;10,151.52,394.62,212.03,7.89" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="10,206.91,383.68,230.90,7.86">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,448.30,383.68,32.27,7.86;10,151.52,394.64,138.96,7.86">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,405.60,337.96,7.86;10,151.52,416.53,288.53,7.89" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="10,281.04,405.60,140.12,7.86">Case-based fracture image retrieval</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,428.34,405.60,52.24,7.86;10,151.52,416.56,216.03,7.86">International Journal of Computer Assisted Radiology and Surgery</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="401" to="411" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,427.52,337.96,7.86;10,151.52,438.45,222.28,7.89" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="10,301.44,427.52,175.44,7.86">Floating search methods in feature selection</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pudil</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Novovičová</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,151.52,438.48,112.86,7.86">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1119" to="1125" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,142.61,449.44,337.96,7.86;10,151.52,460.40,329.05,7.86;10,151.52,471.33,171.89,7.89" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="10,325.41,449.44,155.17,7.86;10,151.52,460.40,133.16,7.86">Attribute-based classification for zeroshot visual object categorization</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lampert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Nickisch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Harmeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,296.52,460.40,184.05,7.86;10,151.52,471.36,82.43,7.86">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="453" to="465" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
