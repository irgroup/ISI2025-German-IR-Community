<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,146.80,115.90,321.76,12.68;1,236.80,133.83,141.75,12.68">Liver CT Annotation via Generalized Coupled Tensor Factorization</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,230.31,171.50,55.14,8.80"><forename type="first">Beyza</forename><surname>Ermis</surname></persName>
							<email>beyza.ermis@boun.edu.tr</email>
							<affiliation key="aff0">
								<orgName type="institution">Boğaziçi University</orgName>
								<address>
									<postCode>34342</postCode>
									<settlement>Bebek, İstanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,308.14,171.50,76.91,8.80"><forename type="first">A</forename><forename type="middle">Taylan</forename><surname>Cemgil</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Boğaziçi University</orgName>
								<address>
									<postCode>34342</postCode>
									<settlement>Bebek, İstanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,146.80,115.90,321.76,12.68;1,236.80,133.83,141.75,12.68">Liver CT Annotation via Generalized Coupled Tensor Factorization</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3C8037F098E2CACFFA2411359C61A057</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>matrix factorization</term>
					<term>coupled analysis</term>
					<term>missing value prediction</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This study deals with the missing answers prediction problem. We address this problem using coupled analysis of ImageCLEF2014 dataset by representing it as a heterogeneous data, i.e., dataset in the form of matrices. We propose to use an approach based on probabilistic interpretation of tensor factorization models, i.e., Generalized Coupled Tensor Factorization, which can simultaneously fit a large class of matrix/tensor models to higher-order matrices/tensors with common latent factors using different loss functions. Numerical experiments demonstrate that joint analysis of data from multiple sources via coupled factorization gives high prediction performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this study, the task is to predict user expressed (UsE) features by using the computer generated (CoG) features. UsE features are some predefined questions related to liver, vessels, lesions and CoG features are the features which are derived from image itself. Our aim is to fill in a pre-prepared form and provide computer aided automatic annotation of liver CT volumes by using image features <ref type="bibr" coords="1,172.20,492.81,10.51,8.80" target="#b0">[1,</ref><ref type="bibr" coords="1,184.37,492.81,7.01,8.80" target="#b1">2]</ref>.</p><p>We consider, for answer prediction, both KL-divergence and Euclidean distancebased cost functions as well as coupled matrix factorization models <ref type="bibr" coords="1,433.78,516.72,8.19,8.80" target="#b2">[3]</ref><ref type="bibr" coords="1,441.97,516.72,4.10,8.80" target="#b3">[4]</ref><ref type="bibr" coords="1,446.07,516.72,8.19,8.80" target="#b4">[5]</ref> using GCTF <ref type="bibr" coords="1,166.79,528.67,10.51,8.80" target="#b5">[6]</ref> framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>In this study, we use Generalized Coupled Tensor factorization framework <ref type="bibr" coords="1,451.57,584.33,14.06,8.80" target="#b5">[6]</ref> for coupled factorization of several tensors and matrices to fill in the missing entries in observed data. A generalized tensor factorization problem is specified by an observed tensor X with possibly missing entries and a collection of latent tensors to be estimated, Z 1:|α| = {Z α } for α = 1...|α|.</p><p>GCTF framework is a generalization of the Probabilistic Latent Tensor factorization (PLTF) <ref type="bibr" coords="1,217.20,656.06,10.51,8.80" target="#b6">[7]</ref> to coupled factorization. The Probabilistic Latent Tensor Factorization framework (PLTF) <ref type="bibr" coords="2,282.56,118.93,10.51,8.80" target="#b6">[7]</ref> is appeared as an extension of the matrix factorization model <ref type="bibr" coords="2,224.89,130.89,10.51,8.80" target="#b2">[3]</ref> and enables one to incorporate domain specific information to any arbitrary factorization model and provides the update rules for multiplicative expectation-maximization (EM) algorithms. In this framework, the goal is to compute an approximate factorization of a given higher-order tensor, i.e., a multiway array, X in terms of a product of individual factors Z α as:</p><formula xml:id="formula_0" coords="2,236.34,210.71,244.25,22.52">X(v 0 ) ≈ X(v 0 ) = v0 α Z α (v α ),<label>(1)</label></formula><p>where some of the factors are possibly fixed. Here, we define v as the set of all indices in a model, v 0 as the set of visible indices, v α as the set of indices in Z α , and vα = vv α as the set of all indices not in Z α and α = 1, ...K as the factor index. Since the product α Z α (v α ) is collapsed over a set of indices, the factorization is latent. The approximation problem is cast as an optimization problem where we minimize the divergence d(X, X), where d is a divergence between the observed data X and model prediction X. In applications, d is typically taken as Euclidean (EUC), Kullback-Leibler (KL) or Itakura-Saito (IS) <ref type="bibr" coords="2,134.77,340.67,9.96,8.80" target="#b6">[7]</ref>.</p><p>Here, we have two-dimensional datasets so we use nonnegative variant of the matrix factorization model. The matrix factorization model can be defined in the PLTF notation as follows. Given a matrix X, its factorization model is defined as:</p><formula xml:id="formula_1" coords="2,225.06,408.83,255.53,22.13">X(i, j) ≈ X(i, j) = r Z 1 (i, r)Z 2 (j, r)<label>(2)</label></formula><p>where the index sets V = {i, j, k, r}, V 0 = {i, j}, V 1 = {i, r} and V 2 = {j, r}.</p><p>The update equation for non-negative generalized matrix/tensor factorization is expressed as:</p><formula xml:id="formula_2" coords="2,190.24,487.43,286.11,27.25">Z α ← Z α • ∆ α (M • X-p • X) ∆ α (M • X1-p ) s.t. Z α (v α ) &gt; 0. (<label>3</label></formula><formula xml:id="formula_3" coords="2,476.35,496.63,4.24,8.80">)</formula><p>where • is the Hadamard product (element-wise product), M is a 0 -1 mask array with</p><formula xml:id="formula_4" coords="2,186.68,537.82,258.87,10.71">M (v 0 ) = 1 (M (v 0 ) = 0) if X(v 0 ) is observed (missing).</formula><p>Here p determines the cost function, i.e., p = {0, 1, 2} correspond to the β-divergence <ref type="bibr" coords="2,134.77,562.34,10.51,8.80" target="#b4">[5]</ref> that unifies EUC, KL, and IS cost functions, respectively. In this iteration, we define the tensor valued function ∆ α (A) as:</p><formula xml:id="formula_5" coords="2,236.84,598.19,243.75,21.20">∆ α (A) = vα A(v 0 ) α =α Z α (v α )<label>(4)</label></formula><p>∆ α (A) is an object, the same size of Z α , obtained simply by multiplying all factors other than the one being updated with an object of the order of the data. Hence the key observation is that the ∆ α function is just computing a </p><formula xml:id="formula_6" coords="3,194.66,155.05,221.77,38.33">0 Euclidean Zα ← Zα • ν R ν,α ∆α,ν (Mν •Xν ) ν R ν,α ∆α,ν (Mν • Xν ) 1 Kullback-Leibler Zα ← Zα • ν R ν,α ∆α,ν (Mν • X-1 ν •Xν ) ν R ν,α ∆α,ν (Mν )</formula><p>tensor product and collapses this product over indices not appearing in Z α , which is algebraically equivalent to computing a marginal sum.</p><p>This update rule can be used iteratively for all non-negative Z α and converges to a local minimum provided we start from some non-negative initial values. For updating Z α , we need to compute the ∆ function twice for arguments A</p><formula xml:id="formula_7" coords="3,134.77,270.36,345.83,22.58">= M ν • X-p ν • X ν and A = M ν • X1-p ν .</formula><p>It is easy to verify that update equations for the KL-NMF (non-negative matrix factorization) problem (for p = 1) are obtained as a special case of (3).</p><p>The Generalized Coupled Tensor Factorization (GCTF) <ref type="bibr" coords="3,397.38,318.72,10.51,8.80" target="#b5">[6]</ref> model takes the PLTF model one step further where, in this case, we have multiple observed tensors X ν that are supposed to be factorized simultaneously:</p><formula xml:id="formula_8" coords="3,218.01,363.51,262.58,23.72">X ν (v 0,ν ) ≈ Xν (v 0,ν ) = v0,ν α Z α (v α ) R ν,α<label>(5)</label></formula><formula xml:id="formula_9" coords="3,222.38,412.65,253.97,21.36">R ν,α = 1 if X ν and Z α connected 0 otherwise . (<label>6</label></formula><formula xml:id="formula_10" coords="3,476.35,419.33,4.24,8.80">)</formula><p>where ν = 1, ...|ν| and R is a coupling matrix that is defined as in <ref type="bibr" coords="3,440.02,448.42,11.62,8.80" target="#b5">(6)</ref>. Note that, distinct from PLTF model, there are multiple visible index sets (v 0,ν ) in the GCTF model, each specifying the attributes of the observed tensor X ν . The inference, i.e., estimation of the shared latent factors Z α , can be achieved via iterative optimization (see <ref type="bibr" coords="3,270.17,496.83,10.29,8.80" target="#b5">[6]</ref>). For non-negative data and factors, one can obtain the following compact fixed point equation where each Z α is updated in an alternating fashion fixing the other factors</p><formula xml:id="formula_11" coords="3,214.21,520.14,266.38,50.55">Z α for α = α Z α ← Z α • ν R ν,α ∆ α,ν (M ν • X-p ν • X ν ) ν R ν,α ∆ α,ν (M ν • X1-p ν ) .<label>(7)</label></formula><p>Here p, as in (3), determines the cost function, (see Table <ref type="table" coords="3,392.94,582.09,3.87,8.80" target="#tab_0">1</ref>). In this iteration, the key quantity is the ∆ α,ν function that is defined as follows:</p><formula xml:id="formula_12" coords="3,194.32,615.91,286.27,34.15">∆ α,ν (A) =   v0,ν ∩vα A(v 0,ν ) v0∩vα α =α Z α (v α ) R ν,α   (8)</formula><p>3 Experiments and Results</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Experimental Setting</head><p>In this section, we address the missing answers (UsE features) prediction task on user expressed (UsE) features. UsE features are provided by a radiologist and represented by a 73×6 cell array. In our experiments, we used one column of that data which stands for annotation's values. For the experiments, we choose and separate the questions into two groups. In the first group, we used the question set: S1 = {3, 5, 7, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28} and in the second group we used the question set: S2 = {29, 30, 31, 38, 39, 40, 41, 44, 48, 60, 66, 68, 71}. The questions in the first group have answers between {0 -3} and the questions in the second group have binary values {0 -1}. ImageCLEF2014 (liver CT annotation task) <ref type="bibr" coords="4,434.46,291.73,10.51,8.80" target="#b1">[2]</ref> has the content of 50 Matlab data files for training and 10 Matlab data files for test that contains CoG and UsE for each sample. We generate observation samplequestions matrices X 1 and X 2 by using these samples and the questions. In the end, we have the matrix X 1 of size 60 × 21 and X 2 of size 60 × 13. In matrix X 1 , an entry X 1 (i, k) indicates the value of the answer k for sample i. Likewise, an entry X 2 (i, p) indicates the value of the answer p for sample i in matrix X 2 . To predict the UsE features, we use Computer generated (CoG) features. These features image-based features and they are generated by an interactive segmentation software. These features are stored in a 60 × 4 cell array.</p><p>Likewise UsE features, we used feature's value in our experiments. Here, we generate sample-features matrix Z 1 of size 60 × 447. In matrix Z 1 , an entry Z 1 (i, j) indicates the value of the feature j for sample i.</p><p>Finally, we generate question-feature matrices Z 2 of size 447 × 21 and Z 3 of size 447×13 in order to complete the missing answers in X 1 and X 2 respectively.</p><p>The first 50 rows of X 1 and X 2 are observed and used for training while the rows from 51 to 60 are not observed and used for test. In order to fill in the missing entries in X 1 and X 2 , we applied the coupled approach to a CPstyle tensor factorization model by analysing the tensor X 1 with X 2 . They have samples mode in common and this gives us the following model: <ref type="figure" coords="5,187.78,305.20,4.98,8.80">1</ref> for the visualization of the general structure of the model.)</p><formula xml:id="formula_13" coords="5,134.77,247.91,228.78,66.09">X1 (i, k) = Z 1 (i, j)Z 2 (j, k) X2 (i, p) = Z 1 (i, j)Z 3 (j, p) (See Figure</formula><p>After solving this model and obtain the values for latent factors, we construct the estimated matrices for X 1 and X 2 . Here, our goal is to predict ordinal values for answers on a scale of {1, . . . R}. We can reduce this prediction task to a set of binary threshold problems, namely, predicting r ≥ 1, r ≥ 2, . . . , r ≥ R. We try 1000 threshold values between 0 -1, compute the accuracy of prediction for each value and choose the threshold value that gives the best accuracy performance. Threshold selection is not an easy task when we have different types of questions. For example, in the datasets there are several questions that their answers could have different values from all other questions. So, we have to find a unique value for that specific question. In this study, we ignore the questions with varied answers. That is why we have chosen these two sets of questions: to group the questions that have same type of answers is easier for this stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>Evaluation: Completeness and accuracy of the prediction are the two main evaluation criteria of this study. The predicted annotations are compared to the manual annotations of the test dataset. To measure the completeness, the number of predicted features are divided by total number of features and to measure the accuracy, the number of correct predicted features divided by total number of predicted features. Finally, the total score is given in terms of the ratio of correct answers in separate groups. In the previous run we have used KL-divergence to estimate the factors and non-optimal threshold values to relate the real-valued predictions to the discrete predictions. We just choose a one threshold value manually, then predict all answers by using that value. At the end, we obtained the results given in Table <ref type="table" coords="6,472.85,154.80,3.87,8.80" target="#tab_1">2</ref>.</p><p>Then, we used the thresholding method that we described in the Experimental Setting section. It determines the optimum value and we rerun the experiments by using this method. Here, we used both Euclidean distance and KL-divergence. Afterwards, we obtained the results with higher accuracy given in Table <ref type="table" coords="6,176.12,214.58,3.87,8.80" target="#tab_2">3</ref>. We can clearly see that, our new method outperforms the previous one and the selection of the threshold significantly affects the prediction accuracy. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>In this study, we have studied answer prediction problem using coupled analysis of imageCLEF2014 data <ref type="bibr" coords="6,259.81,416.86,10.51,8.80" target="#b1">[2]</ref> represented as datasets in the form of matrices. The problem is formulated as simultaneous factorization of higher-order tensors/matrices extracting common latent factors from the shared modes. We have used Generalized Coupled Tensor Factorization framework, which enables us to develop coupled models for joint analysis of multiple data sets in a compact way using various models and cost functions. In our coupled analysis, we have studied both KL-divergence and Euclidean distance-based cost functions. In this study, we have used some questions and try to predict the values of their answers by using Euclidean distance and KL-divergence. We plan to extend our study to use different losses such as logistic loss or hinge loss and predict the answers of all questions in the dataset that have answers in a wide variety.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,134.77,567.24,345.81,7.92;4,134.77,578.20,227.33,7.92;4,205.80,487.79,52.77,58.77"><head>2 Z 1 Z 3 Fig. 1 :</head><label>2131</label><figDesc>Fig. 1: General sketch of the proposed model. The blocks visualize the matrices that are defined in the model and the relation between them.</figDesc><graphic coords="4,205.80,487.79,52.77,58.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,194.66,127.29,205.14,22.46"><head>Table 1 :</head><label>1</label><figDesc>Update rules for different p values</figDesc><table coords="3,194.66,141.84,205.14,7.92"><row><cell>p Cost Function</cell><cell>Multiplicative Update Rule</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,134.77,619.38,345.81,41.59"><head>Table 2 :</head><label>2</label><figDesc>Completion and accuracy results of previous method with EUC distance and KL divergence.</figDesc><table coords="5,188.11,641.70,236.06,19.27"><row><cell>Cost Function</cell><cell cols="3">Completeness Accuracy Total Score</cell></row><row><cell>Kullback-Leibler (KL)</cell><cell>0.51</cell><cell>0.39</cell><cell>0.45</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,134.77,281.24,345.81,52.95"><head>Table 3 :</head><label>3</label><figDesc>Completion and accuracy results of our method with EUC distance and KL divergence.</figDesc><table coords="6,188.11,303.56,236.06,30.63"><row><cell>Cost Function</cell><cell cols="3">Completeness Accuracy Total Score</cell></row><row><cell>Euclidean (EUC)</cell><cell>0.5151</cell><cell>0.8911</cell><cell>0.6775</cell></row><row><cell>Kullback-Leibler (KL)</cell><cell>0.5151</cell><cell>0.8882</cell><cell>0.6764</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,138.35,591.08,342.23,7.92;6,146.91,602.04,333.66,7.92;6,146.91,613.00,184.66,7.92" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,162.59,602.04,161.15,7.92">imageclef liver ct image annotation task</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Marvasti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kökciyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Türkay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Yazıcı</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yolum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Üsküdarlı</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Acar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,365.84,602.04,114.73,7.92;6,146.91,613.00,55.96,7.92">CLEF 2014 Evaluation Labs and Workshop</title>
		<title level="s" coord="6,210.70,613.00,87.98,7.92">Online Working Notes</title>
		<imprint>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,623.87,342.23,7.92;6,146.91,634.83,333.66,7.92;6,146.91,645.79,333.67,7.92;6,146.91,656.74,285.53,7.92" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,146.91,645.79,228.98,7.92">ImageCLEF 2014: Overview and analysis of the results</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Martinez-Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Patricia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Marvasti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Üsküdarlı</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Paredes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Cazorla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Garcia-Varea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Morell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,402.20,645.79,74.26,7.92">CLEF proceedings</title>
		<title level="s" coord="6,146.91,656.74,141.37,7.92">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,119.62,342.22,7.92;7,146.91,130.57,156.44,7.93" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,246.56,119.62,234.01,7.92;7,146.91,130.58,37.71,7.92">Learning the parts of objects by non-negative matrix factorization</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">S</forename><surname>Seung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,192.47,130.58,27.92,7.92">Nature</title>
		<imprint>
			<biblScope unit="volume">401</biblScope>
			<biblScope unit="page" from="788" to="791" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,141.54,342.22,7.92;7,146.91,152.50,273.55,7.92" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,204.15,141.54,247.13,7.92">Bayesian inference in non-negative matrix factorisation models</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">T</forename><surname>Cemgil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,458.57,141.54,22.00,7.92;7,146.91,152.50,163.10,7.92">Computational Intelligence and Neuroscience</title>
		<imprint>
			<biblScope unit="page">785152</biblScope>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,163.46,342.23,7.92;7,146.91,174.42,111.71,7.92" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="7,348.20,163.46,132.37,7.92;7,146.91,174.42,51.46,7.92">Nonnegative Matrix and Tensor Factorization</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cichoki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zdunek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Phan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Amari</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,185.37,342.23,7.92;7,146.91,196.33,66.92,7.92" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,317.35,185.37,159.48,7.92">Generalised coupled tensor factorisation</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">K</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">T</forename><surname>Cemgil</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Simsekli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,160.99,196.33,24.18,7.92">NIPS</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.35,207.29,342.23,7.92;7,146.91,218.25,60.91,7.92" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,262.60,207.29,155.75,7.92">Probabilistic latent tensor factorization</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">K</forename><surname>Yilmaz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">T</forename><surname>Cemgil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,439.00,207.29,41.58,7.92">LVA/ICA</title>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="346" to="353" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
