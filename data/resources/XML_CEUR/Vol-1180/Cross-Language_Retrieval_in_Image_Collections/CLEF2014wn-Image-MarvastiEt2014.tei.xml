<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,147.90,114.96,319.55,15.78;1,291.90,132.90,31.55,15.78">ImageCLEF Liver CT Image Annotation Task 2014</title>
				<funder ref="#_cQA4rmv #_qgWZZp6 #_nMCJPy9">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,146.75,172.15,73.82,9.96"><forename type="first">Neda</forename><forename type="middle">B</forename><surname>Marvasti</surname></persName>
							<email>neda.barzegarmarvasti@boun.edu.tr</email>
							<affiliation key="aff0">
								<orgName type="department">Electrical and Electronics Department</orgName>
								<orgName type="institution">Bo §aziçi University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,231.12,172.15,70.00,9.96"><forename type="first">Nadin</forename><surname>Kökciyan</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Engineering Department</orgName>
								<orgName type="institution">Bo §aziçi University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,311.67,172.15,60.81,9.96"><forename type="first">Rü³tü</forename><surname>Türkay</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Faculty of Medicine</orgName>
								<orgName type="institution">Istanbul University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,383.04,172.15,78.33,9.96"><forename type="first">Abdülkadir</forename><surname>Yazc</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Engineering Department</orgName>
								<orgName type="institution">Bo §aziçi University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,196.45,184.11,55.50,9.96"><forename type="first">Pnar</forename><surname>Yolum</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Engineering Department</orgName>
								<orgName type="institution">Bo §aziçi University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,262.50,184.11,71.46,9.96"><forename type="first">Suzan</forename><surname>Üsküdarl</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Computer Engineering Department</orgName>
								<orgName type="institution">Bo §aziçi University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,363.89,184.11,50.55,9.96"><forename type="first">Burak</forename><surname>Acar</surname></persName>
							<email>acarbu@boun.edu.tr</email>
							<affiliation key="aff0">
								<orgName type="department">Electrical and Electronics Department</orgName>
								<orgName type="institution">Bo §aziçi University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,147.90,114.96,319.55,15.78;1,291.90,132.90,31.55,15.78">ImageCLEF Liver CT Image Annotation Task 2014</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DD2419C104A42854F61D54AC990B99D7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>ImageCLEF</term>
					<term>Liver CT annotation task</term>
					<term>Automatic annotation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The rst Liver CT annotation challenge was organized during the 2014 Image-CLEF workshop held in Sheeld, UK. This challenge entailed the annotation of Liver CT scans to generate structured reports. This paper describes the motivations for this task, the training and test datasets, the evaluation methods, and discusses the approaches of the participating groups. abstract environment.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>ImageCLEF <ref type="bibr" coords="1,190.58,428.78,10.52,9.96" target="#b0">[1]</ref> was part of the Cross Language Evaluation Forum (CLEF) 2014 consisting of four main tasks: Robot Vision, Image Annotation, Liver CT Annotation, and Domain Adaptation. It was the rst time that the automatic annotation of Liver CT images was provided as a challenge.</p><p>The purpose of the Liver CT annotation task was to automatically generate structured reports with the use of computer generated features of liver CT volumes. Structured reports are highly valuable in medical contexts due to the processing opportunities they provide, such as reporting, image retrieval, and computer-aided diagnosis systems. However, structured reports are cumbersome and time consuming to create. Furthermore, their creation requires domain expertise who is time constrained. Consequently, such structured medical reports are often not found or are incomplete in practice. This challenge was designed to aid the generation of structured reports.</p><p>The datasets provided for this challenge consisted of 50 training and 10 test datasets. Participants were asked to answer a xed set of multiple-choice questions about livers. The questions were automatically generated from an opensource ontology of liver for radiology (onlira) <ref type="bibr" coords="1,335.73,620.58,9.96,9.96" target="#b1">[2]</ref>. The answers to the questions describe the properties of the liver, the hepatic vasculature of the liver, and a specic lesion within the liver. During this task, the user is presented with the following training data: (1) data from a CT scan, (2) a liver mask, (3) a volume-of-interest that highlights the selected lesion, and (4) a rich set of imaging observations. The imaging observations are ONLIRA based annotations that were manually entered by radiologists. Participants were permitted to extract their own image features from the CT data and use them. The results were evaluated in terms of the completeness and accuracy of the generated report.</p><p>The rest of the paper is organized as follows, Section 2 gives a detailed description of the task and introduces the participants. Section 3 presents the main results of the task and the results of the participants, and Section 4 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Liver CT Annotation Challenge</head><p>This section describes the task and introduces the participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Task Denition and Datasets</head><p>The Liver CT annotation task is proposed towards the generation of structured reports describing the semantic features of the liver, its vascularity, and the types of lesions in the liver. The goal of proposing this task is to develop automated mechanisms to assist in the dicult and practically infeasible task of annotating medical records.</p><p>The training dataset includes 50 cases, each consisting of: a cropped CT image of the liver a 3D matrix with the same size as cropped CT image, a liver mask that species the part corresponding to the liver a 3D matrix indicating the liver areas with a 1 and nonliver areas with a 0, a bounding box (ROI) corresponding to the region of the selected lesion within the liver as a vector of 6 numbers corresponding to the coordinates of two opposite corners, a set of 60 computer generated (CoG) features obtained from an interactive segmentation software a 60 × 4 array, and A set of 73 user expressed features (UsE) manually entered by a radiologist and stored in a 73 × 6 array.</p><p>In training dataset 50 .mat les, each consisting of all the above data were given to the participants. The format of the test dataset is the same except that the UsE features are missing, which the participants were expected to predict. The participants were allowed to extract and use their own image features. It is important to note that the resolution of CT images may vary (x : 190 -308 pixels, y : 213 -238 pixels, and z : 41 -588 slices). The spacing may also vary in the range of (x, y : 0.674 -1.007 mm, slice : 0.399 -2.5 mm).</p><p>Computer Generated Features For each case, there is a set of 60 CoG image descriptors. Table <ref type="table" coords="3,214.35,131.28,4.98,9.96">4</ref> provides the list of all CoG features for a case. Some of them have only one value and the rest are vectors with dierent dimension. For example, the size of "HistogramOfAllLesions" is67, while the size of "LiverVolume" is 1. The total dimension of all features is 454. A web based data collection application, called CaReRa-Web <ref type="foot" coords="3,400.46,356.00,3.97,7.94" target="#foot_0">4</ref> .</p><p>For each case, there are 73 user expressed (UsE) features represented in a 73× 6 cell array. These features clinically characterize the liver, hepatic vascularity, and liver's lesions. In the training dataset, the UsE features are manually entered by an expert radiologist. Every UsE feature corresponds to a question answered by a radiologist. Some UsE features may take on more than one value. Such features are represented with a multi-selection answers.</p><p>In the test phase, the participants were expected to predict the UsE features. "Free text" related to value Text</p><p>The "Group" and "Concept" are the ONLIRA-based concepts. Each concept may have several properties. Each property may have multiple values whose indices and meaning are given in "Indices" and "Values" columns, respectively. Properties deemed irrelevant are marked as NA by the radiologist. UsE features are grouped as: Liver, Vessel, General and Lesion. Table <ref type="table" coords="3,381.80,599.47,4.98,9.96" target="#tab_5">5</ref> lists every group and its corresponding concepts, properties, possible values and their assigned indices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Evaluation methodology</head><p>The evaluation is performed on the basis of the completeness and accuracy of the predicted annotations with reference to the manual annotations of the test dataset. Completeness is dened as the number of predicted features divided by total number of features, while accuracy is the number of correct predicted features divided by total number of predicted features.</p><p>For answers that allow multiple values to a question, the correct prediction of a single feature is considered as a correct annotation.</p><formula xml:id="formula_0" coords="4,189.84,232.10,290.75,22.31">Completeness = number of predicted U sE f eatures T otal number of U sE f eatures<label>(1)</label></formula><formula xml:id="formula_1" coords="4,179.43,261.85,301.16,22.31">Accuracy = number of correctly predicted U sE f eatures N umber of predicted U sE f eatures<label>(2)</label></formula><p>T otalScore = Completeness × Accuracy (3)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Participation</head><p>Among 20 groups, which registered for the task and signed the license agreement to access the datasets, only 3 of them submitted at least one run. The number of runs per group was limited to ten. Tables 1 describes these runs. 3 Results</p><p>The groups that submitted their results based their prediction on classiers, image retrieval, and generalized coupled tensor factorization (GCTF).</p><p>The BMET group, achieved the best results using the image retrieval techniques with total score of %94.7. Classier-based methods were used by both BMET and CASMIP groups. Only piLabVAVlab used a GCTF method. Table <ref type="table" coords="4,475.62,596.61,4.98,9.96" target="#tab_3">2</ref> shows the completeness, accuracy and total score achieved by each run on the test dataset.</p><p>The BMET group <ref type="bibr" coords="4,231.60,632.54,10.52,9.96" target="#b3">[4]</ref> submitted 8 runs, of which 4 of them used a classierbased approach and the remaining used an image retrieval algorithm. They used two dierent feature sets: the prepared CoG features from the database and a bag of visual words (BoVW). In the classier-based approach, they used twostage classication, where each stage consists of a bank of several support vector machines (SVM), which is used for each UsE feature. A two-stage classication is proposed to solve the unbalanced training dataset. For each UsE feature, the rst stage is composed of the 1-vs-all classiers and the second stage is consisted of the 1-vs-1 classiers. Second classier is activated only if the result of the rst step is more than one label. In the second stage they run 1-vs-1 classier for the set of labels resulting from the rst step and a majority voting scheme is used to select the nal answer. In their rst and second runs, they used linear kernels while in their third and fourth runs, they employed radial basis function (RBF) kernel. They examined these two kernels with both sets of features.</p><p>In the image retrieval based approach, they used the most similar training images to select the UsE features for the test image. Similarity is calculated by computing the Euclidean distance between image feature vectors. Finally, they applied a weighted voting scheme to select the label assigned to each UsE features using the "n" most similar images to the test image, where n = 10 in this scenario. Basically, this algorithm votes images more similarity to the test image with higher values. Results of this approach with two dierent sets of features are seen in 5th and 6th runs. In 7th and 8h runs, they applied a sequential feature selection method to use the most discriminating features for each question during the similarity calculation, in order to use the most suitable one. As mentioned above, BMET group used two kernels for SVM classication, however, there is no signicant performance dierence in the results, which the participants attribute to the unbalanced training dataset. Their classication methods performed best when they employed their expanded feature set. Their retrieval method performed best when the given CoG features were employed. This observation suggests that the nature of feature sets are important for utilizing dierent methods.</p><p>CASMIP group <ref type="bibr" coords="5,219.99,465.17,10.52,9.96" target="#b4">[5]</ref> submitted one run to the task, which achieved the second best performance. They tried four dierent classiers in the learning phase: linear discriminant analysis (LDA), logistic regression (LR), K-nearest neighbors (KNN), and nally SVM to predict UsE features. An exhaustive search of every combination of image features is done using leave-one-out cross validation method on training data for every UsE feature and classier. As the result, for each UsE feature the best classier and its related features are learned. They used only a certain part of provided CoG features, which was achieved by ignoring 21 high-dimension features, i.e. they ignored features with dimensionally more than one. Instead, 9 additional features have been added to individual lesion features extracted in the lesion ROI describing the gray level features of liver, lesion, and boundary of lesion properties. The learning step was performed using all UsE features of the training dataset except cluster size, lobe and segments, which were obtained directly from image features. Python scikit-Learn Machine learning toolbox was used for implementing each classier with the default parameters. As the result, for most of the UsE features they got same performance using any classier and any combination of image features. Hence they assigned any classier and all image features for them. For 6 of the UsE features that describe the density, contrast and location of lesions, one of the LDA or KNN classiers was chosen along with their selected features.</p><p>piLabVAVlab group <ref type="bibr" coords="6,242.22,155.39,10.52,9.96" target="#b5">[6]</ref> considered the dataset as heterogeneous data and GCTF approach was applied to predict UsE features. They considered both KLdivergence and Euclidean-distance-based cost functions as well as the coupled matrix factorization models using GCTF framework. They tried to predict approximately half of the UsE features. In order to achieve this, UsE features with only 4 indices whose values vary from 0 to 3 were considered as the rst group and UsE features with binary indices were considered as the second groups. The reason for this was that the threshold selection needed to be specied for each type of question. Thus, they considered questions with similar answer ranges in a study and ignore question with varied answer ranges. Basically, they provide three matrices for 50 training and 10 test cases: X 1 : A 60 × 21 matrix (UsE features of rst group). X 2 : A 60 × 13 matrix (UsE features of second group). Z 1 : A 60 × 447 matrix (all CoG features).</p><p>They estimated the latent matrices: Z 2 and Z 3 by using coupled matrix factorization models according to the following formula:</p><formula xml:id="formula_2" coords="6,275.91,391.26,204.68,10.32">X 1 = Z 1 * Z 2<label>(4)</label></formula><formula xml:id="formula_3" coords="6,275.91,406.20,204.68,10.32">X 2 = Z 1 * Z 3<label>(5)</label></formula><p>The UsE features of the 10 test cases are predicted with Z 2 and Z 3 . Since the predicted values are not discrete, a binary thresholding method has been proposed to extract the labels of UsE features.</p><p>This group submitted one run during the submission period, which had the accuracy of %45. However, after the submission deadline, they claimed that they had improved their thresholding method and requested that we evaluate their new results (see Table <ref type="table" coords="6,234.29,500.64,28.25,9.96" target="#tab_3">2 run2</ref> and<ref type="table" coords="6,285.22,500.64,17.73,9.96" target="#tab_4">run3</ref>).</p><p>Among 73 UsE features, 7 of them were excluded from the evaluation because of their unbounded labels (numeric continuous values). The BMET group achieved the highest scores with completeness of %98 (See Table <ref type="table" coords="6,420.95,536.70,3.87,9.96" target="#tab_3">2</ref>. In terms of accuracy, BMET group has also attained the best performance by using an image retrieval method. In terms of classier-based methods, BMET and CASMIP groups both obtained the total score of %93.</p><p>Table <ref type="table" coords="6,177.36,584.72,4.98,9.96" target="#tab_4">3</ref> compares the results of dierent runs in predicting dierent groups of UsE features. We divide UsE features into 5 groups: liver, vessels and three lesion groups with area, lesion and component concepts. Results show that all the groups have completed the vessel UsE features with high accuracy. The BMET and CASMIP groups completed liver features in full with accuracy more than %80. None of the groups can completely annotate the area related concepts of lesions. Components related concepts of lesion are completed fully and annotated  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This was the rst time the liver CT annotation task was proposed. We provided liver patient data collected via a hybrid patient information entry system whose liver characteristics are based on the ONLIRA ontology. The challenge presented to the participants was to predict UsE features of patient records, given CoG features. As this was the rst time for this challenge, it was not surprising that few groups were able to submit their runs for this complex task. out of 20 teams 3 teams submitted at least 1 run. The approaches and results were reviewed and documented in this paper.</p><p>The main challenge of the task was due to the unbalanced dataset and participants tried to overcome this issue with dierent methods. Among all methods image retrieval obtained the best performance. It was observed that feature selection is important for the best performance of the prediction method.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Lesion Lesion</head><p>Cluster Size 1(1), 2(2), 3(3), 4(4), 5(5), multiple <ref type="bibr" coords="11,466.91,296.83,12.22,6.14" target="#b5">(6)</ref> For simple cases this value shows number of lesions inside the ROI, but in case of having more than one lesions of a certain type, the biggest lesion is annotated as a sample of that cluster and number of lesions with same properties is written here Contrast Uptake NA(-1), dense(0), heterogeneous(1), homogeneous( </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="10,540.55,174.49,3.87,6.14;10,317.66,185.45,32.78,6.14;10,229.43,196.41,72.84,6.14;10,317.66,196.41,188.55,6.14;10,229.43,207.37,85.03,6.14;10,229.43,218.33,64.93,6.14;10,317.66,207.37,161.57,6.14;10,229.43,229.29,54.44,6.14;10,317.66,229.29,177.26,6.14;10,229.43,240.25,63.91,6.14;10,317.66,240.25,188.55,6.14;10,169.55,256.68,45.30,6.14;10,229.43,251.20,85.04,6.14;10,229.43,262.16,33.53,6.14;10,284.91,262.16,29.56,6.14;10,229.43,273.12,38.44,6.14;10,317.66,251.20,183.06,6.14;10,229.43,284.08,85.04,6.14;10,229.43,295.04,30.20,6.14;10,317.66,284.08,188.55,6.14;10,169.55,311.48,39.16,6.14;10,229.43,306.00,85.03,6.14;10,229.43,316.96,80.28,6.14;10,317.66,306.00,176.90,6.14;10,229.43,327.92,16.25,6.14;10,262.22,327.92,19.83,6.14;10,298.60,327.92,15.87,6.14;10,229.43,338.88,30.20,6.14;10,317.66,327.92,107.13,6.14;10,169.55,355.31,56.69,6.14;10,229.43,349.83,33.78,6.14;10,294.63,349.83,19.84,6.14;10,229.43,360.79,53.51,6.14;10,301.79,360.79,12.67,6.14;10,229.43,371.75,55.33,6.14;10,317.66,349.83,195.08,6.14;10,229.43,382.71,85.04,6.14;10,229.43,393.67,30.20,6.14;10,317.66,382.71,188.55,6.14;10,136.56,407.33,28.17,17.68;10,169.55,410.51,60.69,6.14;10,229.43,405.03,85.04,6.14;10,229.43,415.99,57.22,6.14;10,317.66,405.03,188.55,6.14;10,229.43,426.95,85.04,6.14;10,229.43,437.90,40.70,6.14;10,317.66,426.95,226.76,6.14;10,169.55,448.86,30.97,6.14;10,169.55,459.82,45.95,6.14;10,229.43,448.86,85.04,6.14;10,229.43,459.82,55.27,6.14;10,317.66,448.86,188.55,6.14;10,229.43,470.78,85.04,6.14;10,229.43,481.74,51.57,6.14;10,317.66,470.78,226.76,6.14;10,229.43,492.70,85.03,6.14;10,229.43,503.66,39.18,6.14;10,299.11,503.66,15.35,6.14;10,229.43,514.62,64.06,6.14;10,229.43,525.58,49.54,6.14;10,317.66,492.70,127.39,6.14;10,169.55,536.53,44.30,6.14;10,169.55,547.49,17.91,6.14;10,229.43,536.53,85.04,6.14;10,229.43,547.49,24.44,6.14;10,317.66,536.53,188.55,6.14;10,229.43,558.45,85.04,6.14;10,229.43,569.41,20.73,6.14;10,317.66,558.45,226.76,6.14;10,229.43,580.37,85.03,6.14;10,229.43,591.33,39.18,6.14;10,299.11,591.33,15.35,6.14;10,229.43,602.29,85.04,6.14;10,229.43,613.25,21.49,6.14;10,317.66,580.37,127.39,6.14;10,169.55,624.21,50.44,6.14;10,169.55,635.16,17.91,6.14;10,229.43,624.21,85.03,6.14;10,229.43,635.16,44.40,6.14;10,317.66,624.21,188.55,6.14;10,229.43,646.12,85.03,6.14;10,229.43,657.08,40.70,6.14;10,317.66,646.12,226.76,6.14;10,229.43,668.04,85.03,6.14;10,229.43,679.00,39.18,6.14;10,299.11,679.00,15.35,6.14;10,229.43,689.96,85.04,6.14;10,229.43,700.92,21.49,6.14;10,317.66,668.04,127.39,6.14;10,169.55,717.36,51.95,6.14;10,229.43,711.88,85.03,6.14;10,229.43,722.84,24.44,6.14;10,317.66,711.88,188.55,6.14;10,229.43,733.79,85.03,6.14;10,229.43,744.75,20.73,6.14;10,317.66,733.79,226.76,6.14;11,136.56,111.64,78.09,17.68;11,236.07,111.64,48.48,17.68;11,324.30,111.64,150.52,17.68;11,136.56,133.96,28.17,17.68;11,176.19,131.65,50.29,6.14;11,176.19,142.61,17.91,6.14;11,236.07,131.65,85.03,6.14;11,236.07,142.61,44.40,6.14;11,324.30,131.65,188.55,6.14;11,236.07,153.57,85.03,6.14;11,236.07,164.53,40.70,6.14;11,324.30,153.57,226.76,6.14;11,176.19,175.49,27.89,6.14;11,176.19,186.45,51.95,6.14;11,236.07,175.49,85.03,6.14;11,236.07,186.45,55.28,6.14;11,324.30,175.49,188.55,6.14;11,236.07,197.41,85.03,6.14;11,236.07,208.37,51.57,6.14;11,324.30,197.41,226.76,6.14;11,176.19,219.32,56.43,6.14;11,176.19,230.28,17.91,6.14;11,236.07,219.32,85.03,6.14;11,236.07,230.28,44.40,6.14;11,324.30,219.32,188.55,6.14;11,236.07,241.24,85.03,6.14;11,236.07,252.20,40.70,6.14;11,324.30,241.24,226.76,6.14;11,136.56,254.91,36.44,17.68;11,176.19,263.56,29.30,6.14;11,236.07,263.56,38.36,6.14;11,324.30,263.56,202.50,6.14;11,324.30,274.52,226.76,6.14;11,324.30,285.48,64.59,6.14"><head></head><label></label><figDesc>, increased(1), normal(2), other(3) Left Lobe Left Lobe Craniocaudal Dimension(mm) The amount change in size of left lobe(mm) amount change in size of caudate lobe(mm) , increased(1), normal(2), other(3) Hepatic V. Lumen Type obliterated(0), open(1), partially obliterated(2), other(3) image using ICD10 codes (bar rated) and in the free text MD's comments are written (bar separated).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="11,367.10,373.55,95.18,6.14;11,236.07,384.50,68.81,6.14;11,324.30,384.50,226.76,6.14;11,324.30,395.46,226.76,6.14;11,324.30,406.42,226.77,6.14;11,324.30,417.38,130.55,6.14;11,236.07,428.34,167.87,6.14;11,420.15,428.34,34.29,6.14;11,470.65,428.34,80.41,6.14;11,324.30,439.30,226.76,6.14;11,324.30,450.26,226.76,6.14;11,324.30,461.22,168.75,6.14;11,236.07,472.18,6.19,6.14;11,257.31,472.18,33.40,6.14;11,305.75,472.18,15.35,6.14;11,236.07,483.13,29.51,6.14;11,324.30,472.18,64.95,6.14;11,236.07,494.09,57.20,6.14;11,324.30,494.09,226.76,6.14;11,324.30,505.05,68.66,6.14;11,236.07,516.01,184.40,6.14;11,236.07,526.97,64.31,6.14;11,324.30,526.97,226.77,6.14;11,324.30,537.93,62.97,6.14;11,236.07,548.89,63.06,6.14;11,324.30,548.89,226.76,6.14;11,324.30,559.85,57.22,6.14;11,397.94,559.85,73.47,6.14;11,487.85,559.85,63.21,6.14;11,324.30,570.81,226.76,6.14;11,324.30,581.76,226.76,6.14;11,324.30,592.72,226.76,6.14;11,324.30,603.68,37.39,6.14;11,236.07,614.64,85.03,6.14;11,236.07,625.60,10.75,6.14;11,324.30,614.64,226.77,6.14;11,324.30,625.60,153.93,6.14;11,176.19,642.04,19.22,6.14;11,236.07,636.56,19.84,6.14;11,324.30,636.56,178.51,6.14;11,236.07,647.52,34.05,6.14;11,324.30,647.52,226.76,6.14;11,324.30,658.48,226.76,6.14;11,324.30,669.44,63.21,6.14;11,236.07,680.39,23.03,6.14;11,324.30,680.39,215.20,6.14;11,236.07,691.35,24.83,6.14;11,324.30,691.35,217.25,6.14;11,236.07,702.31,85.04,6.14;11,236.07,713.27,20.99,6.14;11,324.30,702.31,64.95,6.14;11,236.07,724.23,85.04,6.14;11,236.07,735.19,20.22,6.14;11,324.30,724.23,64.95,6.14;11,236.07,746.15,85.04,6.14;11,236.07,757.11,20.22,6.14;11,324.30,746.15,64.95,6.14;11,236.07,768.07,153.18,6.14"><head></head><label></label><figDesc>, moderate(4), other(5) Contrast Pattern NA(-1), central(0), early uptake then wash out(1), xing contrast in late phase(2), heterogeneous(3), homogeneous(4), peripheric(5), peripheric nodular(6), spokes wheel(7), undecided(8), other(1), uid uid(0), uid gas(1), uid solid(2), gas solid(3), other(4) is Debris observed? True(1),False(0),NA(-1) Debris Location NA(-1), oating inside(0), located on dependent position(1),other(2) is Close to Vein NA(-1), HepaticArtery(0), HepaticPortalVein(1), Rightmm which represents width of the lesion height a number in mm which represents heigth of the lesion is Gallbladder Adjacent? True(1),False(0) is Peripherical Localized? True(1),False(0) is Subcapsular Localized? True(1),False(0) is Central Localized True(1),False(0)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,134.77,456.01,305.85,93.02"><head></head><label></label><figDesc>The format of the 73 × 6 UsE data is:</figDesc><table coords="3,151.10,466.22,289.52,82.81"><row><cell cols="2">Column Annotation Features</cell><cell>Type</cell></row><row><cell>1</cell><cell>Group</cell><cell>string</cell></row><row><cell>2</cell><cell>Concept</cell><cell>string</cell></row><row><cell>3</cell><cell>Properties</cell><cell>string</cell></row><row><cell>4</cell><cell>Indices</cell><cell>bar separated list of integers</cell></row><row><cell>5</cell><cell>Values</cell><cell>bar separated list of strings</cell></row><row><cell>6</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,134.77,404.70,398.03,71.18"><head>Table 1 :</head><label>1</label><figDesc>ImageCLEF Liver CT Image Annotation Task 2014 participants who performed at least one run.</figDesc><table coords="4,136.56,427.02,107.44,17.68"><row><cell>Group name Aliation</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,134.77,121.21,345.84,235.29"><head>Table 2 :</head><label>2</label><figDesc>Results of the runs of Liver CT annotation task. CoG: just given CoG features are used. CoG+: user generated features are added to given CoGfeatures.</figDesc><table coords="7,134.77,152.18,345.84,204.32"><row><cell cols="6">Group name Run Completeness Accuracy Total Score method used feature used</cell></row><row><cell>BMET</cell><cell>run1 0.98</cell><cell>0.89</cell><cell>0.935</cell><cell cols="2">SVM-linear CoG</cell></row><row><cell>BMET</cell><cell>run2 0.98</cell><cell>0.90</cell><cell>0.939</cell><cell cols="2">SVM-linear CoG+</cell></row><row><cell>BMET</cell><cell>run3 0.98</cell><cell>0.89</cell><cell>0.933</cell><cell cols="2">SVM-RBF CoG</cell></row><row><cell>BMET</cell><cell>run4 0.98</cell><cell>0.90</cell><cell>0.939</cell><cell cols="2">SVM-RBF CoG+</cell></row><row><cell>BMET</cell><cell>run5 0.98</cell><cell>0.91</cell><cell>0.947</cell><cell>IR-noFS</cell><cell>CoG</cell></row><row><cell>BMET</cell><cell>run6 0.98</cell><cell>0.87</cell><cell>0.927</cell><cell>IR-noFS</cell><cell>CoG+</cell></row><row><cell>BMET</cell><cell>run7 0.98</cell><cell>0.91</cell><cell>0.947</cell><cell>IR-FS</cell><cell>CoG</cell></row><row><cell>BMET</cell><cell>run8 0.98</cell><cell>0.87</cell><cell>0.926</cell><cell>IR-FS</cell><cell>CoG+</cell></row><row><cell>CASMIP</cell><cell>run1 0.95</cell><cell>0.91</cell><cell>0.93</cell><cell cols="2">LDA+KNN CoG+</cell></row><row><cell cols="2">piLabVAVlab run1 0.51</cell><cell>0.39</cell><cell>0.45</cell><cell>MF-KL</cell><cell>CoG</cell></row><row><cell cols="2">piLabVAVlab run2 0.51</cell><cell>0.89</cell><cell>0.677</cell><cell>MF-EUC</cell><cell>CoG</cell></row><row><cell cols="2">piLabVAVlab run3 0.51</cell><cell>0.88</cell><cell>0.676</cell><cell>MF-KL</cell><cell>CoG</cell></row><row><cell cols="6">with accuracy higher than %72 by both BIMET and CASMIP groups. Lesion</cell></row><row><cell cols="6">related concepts of lesions are annotated completely by only BIMET group with</cell></row><row><cell cols="2">accuracy more than %72.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,134.77,383.69,397.97,184.76"><head>Table 3 :</head><label>3</label><figDesc>Completeness(complete.) and Accuracy(acc.) for ve dierent groups of UsE</figDesc><table coords="7,134.77,403.30,397.97,165.15"><row><cell>features</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>GroupName</cell><cell>Liver</cell><cell></cell><cell>Vessel</cell><cell></cell><cell cols="2">LesionArea</cell><cell cols="4">LesionLesion LesionComponent</cell></row><row><cell>name</cell><cell cols="9">complete. acc. complete. acc. complete. acc. complete. acc. complete.</cell><cell>acc.</cell></row><row><cell>BMET-run1</cell><cell>1.00</cell><cell>0.91</cell><cell>1.00</cell><cell>1.00</cell><cell>0.92</cell><cell>0.78</cell><cell>1.00</cell><cell>0.72</cell><cell>1.00</cell><cell>0.93</cell></row><row><cell>BMET-run2</cell><cell>1.00</cell><cell>0.93</cell><cell>1.00</cell><cell>1.00</cell><cell>0.92</cell><cell>0.77</cell><cell>1.00</cell><cell>0.77</cell><cell>1.00</cell><cell>0.94</cell></row><row><cell>BMET-run3</cell><cell>1.00</cell><cell>0.93</cell><cell>1.00</cell><cell>1.00</cell><cell>0.92</cell><cell>0.76</cell><cell>1.00</cell><cell>0.72</cell><cell>1.00</cell><cell>0.93</cell></row><row><cell>BMET-run4</cell><cell>1.00</cell><cell>0.93</cell><cell>1.00</cell><cell>1.00</cell><cell>0.92</cell><cell>0.77</cell><cell>1.00</cell><cell>0.77</cell><cell>1.00</cell><cell>0.94</cell></row><row><cell>BMET-run5</cell><cell>1.00</cell><cell>0.93</cell><cell>1.00</cell><cell>1.00</cell><cell>0.92</cell><cell>0.79</cell><cell>1.00</cell><cell>0.83</cell><cell>1.00</cell><cell>0.94</cell></row><row><cell>BMET-run6</cell><cell>1.00</cell><cell>0.80</cell><cell>1.00</cell><cell>1.00</cell><cell>0.92</cell><cell>0.72</cell><cell>1.00</cell><cell>0.79</cell><cell>1.00</cell><cell>0.93</cell></row><row><cell>BMET-run7</cell><cell>1.00</cell><cell>0.93</cell><cell>1.00</cell><cell>1.00</cell><cell>0.92</cell><cell>0.79</cell><cell>1.00</cell><cell>0.83</cell><cell>1.00</cell><cell>0.94</cell></row><row><cell>BMET-run8</cell><cell>1.00</cell><cell>0.93</cell><cell>1.00</cell><cell>1.00</cell><cell>0.92</cell><cell>0.68</cell><cell>1.00</cell><cell>0.73</cell><cell>1.00</cell><cell>0.92</cell></row><row><cell>CASMIP</cell><cell>1.00</cell><cell>0.93</cell><cell>1.00</cell><cell>1.00</cell><cell>0.85</cell><cell>0.81</cell><cell>0.90</cell><cell>0.82</cell><cell>1.00</cell><cell>0.94</cell></row><row><cell>piLabVAVlab-run1</cell><cell>0.62</cell><cell>0.77</cell><cell>1.00</cell><cell>0.42</cell><cell>0.46</cell><cell>0.20</cell><cell>0.20</cell><cell>0.00</cell><cell>0.12</cell><cell>0.15</cell></row><row><cell>piLabVAVlab-run2</cell><cell>0.62</cell><cell>0.88</cell><cell>1.00</cell><cell>1.00</cell><cell>0.46</cell><cell>0.77</cell><cell>0.20</cell><cell>1.00</cell><cell>0.12</cell><cell>0.15</cell></row><row><cell>piLabVAVlab-run3</cell><cell>0.62</cell><cell>0.88</cell><cell>1.00</cell><cell>0.99</cell><cell>0.46</cell><cell>0.77</cell><cell>0.20</cell><cell>1.00</cell><cell>0.12</cell><cell>0.15</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="10,136.56,121.21,407.86,78.75"><head>Table 5 :</head><label>5</label><figDesc>List of UsE features</figDesc><table coords="10,136.56,132.56,407.86,67.39"><row><cell cols="3">Group Concept Properties</cell><cell cols="3">Possible values(assigned indices)</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Liver Placement</cell><cell cols="4">downward displacement(0), normal placement(1), left-</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="4">ward displacement(2), upward displacement(3), other(4)</cell></row><row><cell>Liver</cell><cell>Liver</cell><cell>Liver Contour</cell><cell>irregular(0),</cell><cell>lobulated(1),</cell><cell>nodular(2),</cell><cell>regular</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="3,144.73,634.94,335.85,9.41"><p>The CaReRa-Web is a tool that can accessed at https://vavlab.ee.boun.edu.tr:</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1" coords="3,144.73,645.90,335.85,9.41;3,144.73,656.86,333.12,9.41"><p>5904/CareraWeb2. It is available for academic use from the CaReRaproject (Case Retrieval in Radiological Databases) website http://www.vavlab.ee.boun.edu.tr</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_2" coords="9,187.39,777.23,90.84,6.14;9,307.30,777.23,161.94,6.14"><p>TamuraDir2HistogramHist. of lesion's Tamura y directionality.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_3" coords="9,187.39,788.19,90.84,6.14;9,307.30,788.19,161.17,6.14"><p>TamuraDir3HistogramHist. of lesion's Tamura z directionality.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments This work is in part supported by <rs type="projectName">CaReRa</rs> Project (<rs type="projectName">TÜBTAK</rs> Project No: <rs type="grantNumber">110E264</rs>) <rs type="projectName">Bogazici University B</rs>.A.P (Project No: 5324)</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_cQA4rmv">
					<orgName type="project" subtype="full">CaReRa</orgName>
				</org>
				<org type="funded-project" xml:id="_qgWZZp6">
					<idno type="grant-number">110E264</idno>
					<orgName type="project" subtype="full">TÜBTAK</orgName>
				</org>
				<org type="funded-project" xml:id="_nMCJPy9">
					<orgName type="project" subtype="full">Bogazici University B</orgName>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Density NA(-1), hyperdense(0), hypodense</p><p>Density Type NA(-1), heterogeneous(0), homogeneous(1), other </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="8,138.35,324.66,342.23,6.14;8,146.91,335.62,333.66,6.14;8,146.91,346.57,333.67,6.14;8,146.91,356.50,333.67,7.52;8,146.91,368.49,168.88,6.14" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,365.08,346.57,49.01,6.14;8,442.93,346.57,37.65,6.14;8,146.91,357.53,112.66,6.14">Overview and analysis of the results</title>
		<author>
			<persName coords=""><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jesus</forename><surname>Martinez-Gomez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mauricio</forename><surname>Villegas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Burak</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Novi</forename><surname>Patricia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Neda</forename><surname>Marvasti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Suzan</forename><surname>Üsküdarl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Roberto</forename><surname>Paredes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Miguel</forename><surname>Cazorla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ismael</forename><surname>Garcia-Varea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vicente</forename><surname>Morell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,285.00,356.50,72.22,7.52">CLEF proceedings</title>
		<title level="s" coord="8,365.66,357.53,114.93,6.14;8,146.91,368.49,27.77,6.14">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014. 2014</date>
		</imprint>
	</monogr>
	<note>ImageCLEF</note>
</biblStruct>

<biblStruct coords="8,138.35,379.32,342.23,6.14;8,146.91,390.27,250.19,6.14" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="8,440.91,379.32,39.66,6.14;8,146.91,390.27,220.68,6.14">Semantic description of liver ct images: An ontological approach</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kokciyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Turkay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Uskudarli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Yolum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Bakir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Acar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,401.10,342.23,6.14;8,146.91,412.06,333.66,6.14;8,146.91,421.98,333.67,7.52;8,146.91,432.94,333.67,7.52;8,146.91,444.93,25.59,6.14" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,378.94,412.06,101.64,6.14;8,146.91,423.02,111.00,6.14">Clinical experience sharing by similar case retrieval</title>
		<author>
			<persName coords=""><forename type="first">Neda</forename><surname>Barzegar Marvasti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ceyhun</forename><surname>Burak Akgül</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Burak</forename><surname>Acar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nadin</forename><surname>Kökciyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Suzan</forename><surname>Üsküdarl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Pnar</forename><surname>Yolum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rüstü</forename><surname>Türkay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bars</forename><surname>Bakr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,276.24,421.98,204.35,7.52;8,146.91,432.94,260.38,7.52">Proceedings of the 1st ACM international workshop on Multimedia indexing and information retrieval for healthcare</title>
		<meeting>the 1st ACM international workshop on Multimedia indexing and information retrieval for healthcare</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page">6774</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,455.76,342.23,6.14;8,146.91,466.72,333.67,6.14;8,146.91,476.64,333.67,7.52;8,146.91,487.60,230.55,7.52" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,146.91,466.72,333.67,6.14;8,146.91,477.67,76.33,6.14">Automatic annotation of liver ct images: the submission of the bmet group to imageclefmed 2014</title>
		<author>
			<persName coords=""><forename type="first">Ashnil</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shane</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Changyang</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">W</forename><surname>Philip</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jinman</forename><surname>Leong</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,243.70,476.64,130.39,7.52">CLEF 2014 Labs and Workshops</title>
		<title level="s" coord="8,381.96,476.64,98.62,7.52;8,146.91,487.60,131.22,7.52">Notebook Papers. CEUR Workshop Proceedings (CEUR-WS</title>
		<imprint>
			<date type="published" when="2014-09">September 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,499.46,342.22,6.14;8,146.91,509.38,333.68,7.52;8,146.91,520.34,333.67,7.52;8,146.91,531.30,105.49,7.52" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,296.92,499.46,183.65,6.14;8,146.91,510.42,286.81,6.14">Towards content-based image retrieval: From computer generated features to semantic descriptions of liver ct scans</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Assaf</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Leo</forename><surname>Spanier</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Joskowicz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,455.99,509.38,24.60,7.52;8,146.91,520.34,101.25,7.52">CLEF 2014 Labs and Workshops</title>
		<title level="s" coord="8,255.63,520.34,224.95,7.52;8,146.91,531.30,8.96,7.52">Notebook Papers. CEUR Workshop Proceedings (CEUR-WS</title>
		<imprint>
			<date type="published" when="2014-09">September 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.35,543.16,342.22,6.14;8,146.91,553.08,333.67,7.52;8,146.91,564.04,230.55,7.52" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,300.60,543.16,179.98,6.14;8,146.91,554.11,79.53,6.14">Liver ct annotation via generalized coupled tensor factorization</title>
		<author>
			<persName coords=""><forename type="first">Beyza</forename><surname>Ermis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Taylan</forename><surname>Cemgil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,245.38,553.08,129.42,7.52">CLEF 2014 Labs and Workshops</title>
		<title level="s" coord="8,382.44,553.08,98.14,7.52;8,146.91,564.04,131.22,7.52">Notebook Papers. CEUR Workshop Proceedings (CEUR-WS</title>
		<imprint>
			<date type="published" when="2014-09">September 2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
