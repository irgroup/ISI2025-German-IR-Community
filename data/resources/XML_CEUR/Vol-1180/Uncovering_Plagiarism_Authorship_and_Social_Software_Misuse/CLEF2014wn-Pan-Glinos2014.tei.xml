<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,161.30,115.90,292.76,12.90;1,223.43,136.16,168.49,10.75">A Hybrid Architecture for Plagiarism Detection Notebook for PAN at CLEF 2014</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,272.40,172.97,70.57,8.64"><forename type="first">Demetrios</forename><surname>Glinos</surname></persName>
							<email>glinos@eecs.ucf.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Computer Science</orgName>
								<orgName type="institution">University of Central Florida</orgName>
								<address>
									<settlement>Orlando</settlement>
									<region>Florida</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Advanced Text Analytics, LLC</orgName>
								<address>
									<settlement>Orlando</settlement>
									<region>Florida</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,161.30,115.90,292.76,12.90;1,223.43,136.16,168.49,10.75">A Hybrid Architecture for Plagiarism Detection Notebook for PAN at CLEF 2014</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D239ED341E9D9C0DB3B80EAA23D97257</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a hybrid plagiarism detection architecture that operates on the two principal forms of text plagiarism. For order-preserving plagiarism, such as paraphrasing and modified cut-and-paste, it contains a text alignment component that is robust against word choice and phrasing changes that do not alter the basic ordering. And for non-order based plagiarism, such as random phrase reordering and summarization, it contains a two-stage cluster detection component. The first stage identifies a maximal passage in the suspect document that is related to the source document, while the second stage determines whether the suspect passage corresponds to the entire source document or just to a passage within it. Three implementations of this architecture, involving a common text alignment component and three different cluster detection components, participated in the PAN 2014 Text Alignment task and performed very well, achieving very high precision, recall, and overall plagiarism detection scores.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Plagiarism is the attempt to pass off another person's ideas as one's own. This concept involves both intent, which may be inferred from context, and also the ideas themselves. Moreover, since ideas typically involve shared concepts and their relationships to one another, the originality or uniqueness of ideas is also typically inferred from the language used to express those ideas. Not surprisingly, therefore, current research on plagiarism detection centers on what may be objectively identified in a potential plagiarism context, that is, on the detection of similar expressions of ideas. Put simply, the focus is on detecting instances of text reuse.</p><p>Viewed in this context, there are two fundamentally different types of text plagiarism: order-based and non-order based. Order-based plagiarism involves cutting and pasting a passage from the source, as well as order-preserving modifications such as the use of synonyms, insertions and deletions, and minor differences in phrasing. In each such case, the basic order of the concepts presented is essentially the same in the source and plagiarized documents. Non-order based plagiarism also involves presenting source document concepts in the suspect document, but in this case they appear in a substantially different order. An example of this kind of plagiarism is summarization, in which concepts from throughout the source document are assembled in a passage of the plagiarized document. Another example involves the translation of the source document or passage into another natural language which, owing to the different grammatical constructions used by different languages, can have the effect of presenting the concepts of the source document in a generally different order in the plagiarized document. Of course, not all summaries or translations are instances of plagiarism, as that is a matter of intent and context, as discussed above. Moreover, paraphrasing in general may be either order-preserving or not.</p><p>Given these differences, we propose a plagiarism detection architecture that comprises a text alignment component to detect order-based plagiarism and a separate and independent component, which we call a clustering component to detect non-order based plagiarism. We have implemented this architecture in three systems that possess a common text alignment component and differ in their clustering strategies. All three systems participated in the PAN<ref type="foot" coords="2,286.93,251.70,3.49,6.05" target="#foot_0">1</ref> 2014 Text Alignment task and performed well on all test corpora for the task.</p><p>Our hybrid approach differs markedly from current practice, which generally applies a single, common set of algorithms to all plagiarism types using a seed-extendfilter approach. For example, Torrej√≥n and Ramos <ref type="bibr" coords="2,338.75,303.75,11.62,8.64" target="#b7">[8]</ref> and Suchomel et al. <ref type="bibr" coords="2,436.33,303.75,11.62,8.64" target="#b6">[7]</ref> employ sets of n-grams, while Kong et al. <ref type="bibr" coords="2,274.34,315.70,11.62,8.64" target="#b2">[3]</ref> uses sentence-level cosine similarity, to identify the seed or anchor points. And while Palkovskii and Belov <ref type="bibr" coords="2,366.38,327.66,11.62,8.64" target="#b3">[4]</ref> addressed summarization specifically, they did not employ a text alignment component and did not distinguish plagiarism types as we do.</p><p>In our proposed architecture, we use separate components for detecting the two basic types of text reuse: a text alignment component that uses a dynamic programming approach, and a clustering component that uses a seed-extend-filter approach that is similar to those cited above. What makes our approach different is that in our architecture the components are set up to be targeted at detect different types of text reuse so that they essentially do not overlap in detection coverage.</p><p>The sections that follow describe the architecture in detail and present the experimental results obtained. Section 2 covers the system components, including all three versions of clustering module. Section 3 presents the experiments and results. Finally, our conclusions are presented in Section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Description</head><p>The top level architecture of the proposed system is shown in Figure <ref type="figure" coords="2,405.53,557.56,3.74,8.64" target="#fig_0">1</ref>. We consider this a hybrid system since the two principal detection components (alignment and clustering) operate independently and could each run in standalone mode. Nevertheless, they are not co-equals within the system. The clustering component is invoked only when the alignment component does not find any aligned passages within a given document pair. The individual components, including variations tested, are discussed separately in the subsections that follow. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Tokenization</head><p>The system operates on document pairs. Both the source document and the suspected plagiarism (hereafter "suspect") document are preprocessed by the Tokenizer component prior to submission to the detection modules. The Tokenizer first reads each file as a stream of UTF-8 bytes and converts non-printable ASCII characters, newlines, carriage returns, and tabs, to spaces. It then converts the text to lower case and splits the input into tokens using a simple custom tokenization algorithm that separates all words, numbers, special characters, and punctuation, but which preserves punctuation within numerical values, the possessive " 's", and the contraction "n't".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Text Alignment</head><p>The Text Alignment component applies the algorithm described in <ref type="bibr" coords="3,404.43,382.35,11.62,8.64" target="#b0">[1]</ref> to find as many maximal-length token sequences as may be contained in the document pair. The algorithm extends the Smith-Waterman <ref type="bibr" coords="3,279.46,406.26,11.62,8.64" target="#b5">[6]</ref> dynamic programming algorithm, as modified by <ref type="bibr" coords="3,147.56,418.21,10.58,8.64" target="#b1">[2]</ref>, by providing: (a) a recursive mechanism for detecting multiple alignments; (b) a method for handling large documents; (c) a method for joing adjacent subsequences; and (d) a similarity measure for comparing document tokens. For all systems tested, aligned passages that comprised at least 40 tokens in both source and suspect documents were reported as alignment detections. All systems also used these dynamic programming parameters: +2 for token matches, and -1 for insertions, deletions, and misses. The systems were also configured to allow merging up to 2 sets of adjacent subsequences. A simple token similarity measure was also employed in which the articles "a", "an", and "the" were treated as matches, and the following common prepositions were also treated as equivalent: "of", "in", "to", "for", "with", "on", "at", "from", "by", "about", "as", "into", "like", "through", "after", "over", "between", "out", "against", "during", "without", "before", "under", "around", and "among".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Clustering</head><p>A document pair for which no aligned sequences have been found may be an instance of either non-order based plagiarism or of no plagiarism at all. Therefore, to reduce the incidence of false positive detections, the principal idea underlying the proposed clustering approach is that the suspect document must contain a sufficiently dense cluster of terms from the source document that would be greater than the mere coincidental occurrence of common terms in the two documents. The goal is to distinguish, for example, two documents that contain similar expressions of concepts and their relationships, from two documents that merely discuss the same or similar topics. The three variations of the clustering that were tested are discussed separately below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Basic Clustering</head><p>The Basic Clustering algorithm seeks to find clusters in the suspect document that contain important concepts from throughout the source document while not performing any deep tagging or parsing of either document.</p><p>To approximate the set of important concepts, the algorithm finds the top 30 most frequent tokens in the source document that start with a letter and are of length 5 characters or more. The choice of 5 characters was a deliberate attempt to include most proper nouns, but to exclude determiners, personal pronouns, most prepositions, modals, and simple verbs. Once the most frequent terms are identified, the algorithm finds the set of all word trigrams centered on any of these terms, but excluding intermediate tokens that are punctuation or numeric. As a result, the trigrams in this set very often span more than 3 consecutive tokens.</p><p>The trigram set so constructed will be used if the set of trigram occurrences span a sufficient portion of the source document. Since this algorithm searches for summary passages, the concepts from the source are presumed to be drawn from throughout the source document. The algorithm uses 80 percent as the threshold value for this purpose.</p><p>If a trigram set exceeds the threshold, the algorithm then finds occurrences of the trigram set in the suspect document. Each trigram will represent an interval in the suspect document. The intervals may possibly overlap. Intervals that are within 20 tokens of each other are merged into clusters. If any clusters exceed 40 tokens in length, the largest such cluster is retained and reported as a summary detection.</p><p>It should be noted that this clustering algorithm does not search for a source passage corresponding to the suspect cluster, and so it will report either a summary detection or no detection at all.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Word Clustering</head><p>The Word Clustering algorithm seeks to improve suspect document cluster detection and also to improve overall detection recall by determining whether the maximal suspect cluster is a summary of the entire source document or whether it corresponds merely to a passage within it.</p><p>In this algorithm, suspect cluster detection is improved in several ways. First, the set of source concepts is taken as the set union of the top 20 most frequent words of length 5 or more and also the top 20 most frequent tokens of such length that start with an uppercase letter in the original source document. Second, this algorithm uses bigrams instead of trigrams and dispenses with the concept spread threshold. Instances of the bigrams are then located within the suspect document and clusters are formed from bigram intervals that are within 15 tokens of each other. Finally, the best suspect cluster is selected from among the remaining clusters that are at least 40 tokens in length and which contain at least 8 of the source document terms, if any.</p><p>The algorithm selects the remaining suspect cluster that has highest Jaccard coefficient of value at least 0.65 for the source concept words and the content words in the suspect cluster. For this purpose, the content words for a cluster are the tokens in the cluster that begin with an alphabetic character, are at least 5 characters in length, and are not contained in the following list of stop words:"the", "of", "and", "a", "in", "to", "is", "was", "it", "for", "with", "he", "be", "on", "i", "that", "by", "at", "you", "'s", "are", "not", "his", "this", "from", "but", "had", "which", "she", "they", "or", "an", "were", "we", "their", "been", "has", "have", "will", "would", "her", "n't", "there", "can", "all", "as", "if", "who", "what", and "said".</p><p>If a maximal suspect cluster is found, the algorithm attempts to find a similar passage in the source document based on the content words, determined as above, for the suspect cluster. Occurrences in the source document are found and merged into clusters if within 15 tokens of each other, and clusters of at least 40 tokens are retained. Similarly to suspect cluster selection, the maximal source cluster is selected as the cluster that contains at least 8 suspect content words and has the greatest Jaccard coefficient computed using its content words and the suspect cluster content words, provided such value is at least 0.50.</p><p>Using this algorithm, if a suspect cluster is found and a source cluster is also found, then a source passage detection is reported. Otherwise, if a suspect cluster is found but no source cluster is found, then a summary detection is reported. And if no suspect cluster is found, no detection is reported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Bigram Clustering</head><p>The Bigram Clustering algorithm seeks to improve passage detection by extending the Word Clustering algorithm in cases where no source cluster is detected. First, the Word Clustering algorithm is applied as described above to detect suspect and source passages, with the exception that clusters need only contain 4 of the base concept words instead of 8 words.</p><p>In the event that a maximal suspect passage is found but no corresponding source passage is found, this algorithm computes all bigrams for the suspect passage. Bigrams and then Jaccard coefficients are then computed for the source clusters that were discovered by the Word Clustering algorithm. The maximal source cluster is selected to be the cluster with the highest Jaccard coefficient, provided such value is at least 0.25.</p><p>The outputs of this algorithm are the same as for the Word Clustering algorithm, that is, no detection if no suspect cluster is detected, and either a passage detection or a summary detection depending on whether or not a source passage is found.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head><p>The PAN Workshop series provides a valuable forum and test corpora for the evaluation of plagiarism detection systems. Three test corpora were used for the 2014 Text Alignment task. These corpora contain the numbers and mixes of plagiarism types for document pairs shown in the table below.</p><p>Full details of the construction of the corpus are contained in <ref type="bibr" coords="5,409.13,584.71,10.58,8.64" target="#b4">[5]</ref>. Briefly, however, the plagiarism types are described as follows: The no plagiarism category is selfexplanatory. The no-obfuscation category represents cut-and-paste copying, although some differences in white space and line breaks are introduced. The random obfuscation category includes some amount of random text operations, such as word shuffling, adding or deleting words or phrases, and word replacement using synonyms. Cyclic translation involves translations of a document using automated translation services plagiarism. Indeed, summary obfuscations are primarily non-order-based. Against this corpus, all three systems performed very well, with recall over 83%, precision over 96%, and PlagDet scores over 88%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>From the experimental results above, and from our experience in developing the systems that participated in the PAN 2014 Text Alignment evaluation, several conclusions are in order.</p><p>First, detecting non-order based plagiarism is a more difficult problem than orderbased plagiarism. The marked improvement for the Basic Clustering system against Test Corpus 3 shows the impact of greater detections by the text alignment component.</p><p>Second, clustering does seem to be a beneficial approach for detecting non-orderbased plagiarism. When comparing the results obtained here against those presented in <ref type="bibr" coords="7,134.77,288.81,10.58,8.64" target="#b0">[1]</ref>, which used a text alignment component alone, the results are decidedly better.</p><p>And finally, there remains room for improvement. The recall values for the clustering systems tested are much less than their corresponding precision values, indicating to us that improved recall should be focus of future development efforts. Although we feel that this effort should be directed at non-order based plagiarism, we believe it is also worthwhile also to examine what improvements can also be made for order-based plagiarism.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,206.95,200.38,201.46,8.12"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Top-level architecture of the proposed system.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,657.09,68.24,7.77"><p>http://pan.webis.de</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The performance of all three systems against the test corpora is shown in Table <ref type="table" coords="6,134.77,302.59,3.74,8.64">2</ref>. Overall, against all corpora, the Word Clustering system performed better than the Basic Clustering system, and the Bigram Clustering system performed best of all.</p><p>As shown in the table, precision was uniformly high at approximately 96% for all systems and all corpora. Recall varied, ranging from a low of approximately 76% for the Basic Clustering System running against Test Corpus 2, to values over 84% for the Word and Bigram Clustering systems against Test Corpus 3. Plagiarism Detection ("PlagDet") scores ranged from a low of 84.30% for the Basic Clustering system against Test Corpus 2, to a high of 88.77% for the Bigram Clustering system against Test Corpus 3. From the results, it is apparent that Test Corpus 3 presented an easier mix of test cases. This is not surprising, since this corpus did not include any instances of cyclic translation or summary obfuscation, which present many instances of non-order based</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="7,138.13,409.41,327.67,7.77;7,146.47,420.37,191.74,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,188.31,409.41,214.89,7.77">Discovering Similar Passages Within Large Text Documents</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Glinos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,421.46,409.41,40.30,7.77">CLEF 2014</title>
		<title level="s" coord="7,146.47,420.37,126.47,7.77">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.13,430.60,317.86,7.77;7,146.47,441.56,177.14,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,186.81,430.60,214.62,7.77">An Improved Algorithm for Matching Biological Sequences</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Gotoh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,419.88,430.60,36.11,7.77;7,146.47,441.56,66.34,7.77">Journal of Molecular Biology</title>
		<imprint>
			<biblScope unit="volume">162</biblScope>
			<biblScope unit="page" from="705" to="708" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.13,451.79,323.58,7.77;7,146.47,462.75,334.11,7.77;7,146.47,473.71,320.77,7.77;7,146.47,485.51,296.87,6.31" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,311.29,451.79,150.42,7.77;7,146.47,462.75,248.34,7.77">Approaches for Source Retrieval and Text Alignment of Plagiarism Detection-Notebook for PAN at CLEF 2013</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Qu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Han</surname></persName>
		</author>
		<ptr target="http://www.clef-initiative.eu/publication/working-notes" />
	</analytic>
	<monogr>
		<title level="m" coord="7,215.05,473.71,208.11,7.77">Working Notes Papers of the CLEF 2013 Evaluation Labs</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Tufis</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2013-09">Sep 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.13,494.89,275.09,7.77;7,146.47,505.85,312.63,7.77;7,146.47,516.81,252.19,7.77;7,146.47,528.61,296.87,6.31" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,239.13,494.89,174.09,7.77;7,146.47,505.85,158.01,7.77">Using Hybrid Similarity Methods for Plagiarism Detection-Notebook for PAN at CLEF 2013</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Palkovskii</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Belov</surname></persName>
		</author>
		<ptr target="http://www.clef-initiative.eu/publication/working-notes" />
	</analytic>
	<monogr>
		<title level="m" coord="7,146.47,516.81,208.11,7.77">Working Notes Papers of the CLEF 2013 Evaluation Labs</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Tufis</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2013-09">Sep 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.13,538.00,324.16,7.77;7,146.47,548.96,333.86,7.77;7,146.47,559.92,318.61,7.77;7,146.47,570.88,41.84,7.77;7,146.47,582.68,296.87,6.31" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,182.34,548.96,254.18,7.77">Overview of the 5th International Competition on Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tippmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="http://www.clef-initiative.eu/publication/working-notes" />
	</analytic>
	<monogr>
		<title level="m" coord="7,256.97,559.92,208.11,7.77">Working Notes Papers of the CLEF 2013 Evaluation Labs</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Tufis</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2013-09">Sep 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.13,592.06,322.72,7.77;7,146.47,603.02,330.29,7.77;7,146.47,614.82,247.46,6.31" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,239.97,592.06,178.60,7.77">Identification of common molecular subsequences</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Waterman</surname></persName>
		</author>
		<ptr target="http://www.bibsonomy.org/bibtex/2b9b41ee6be5e380bb59f67a3249ac8dd/hkayabilisim" />
	</analytic>
	<monogr>
		<title level="j" coord="7,424.74,592.06,36.11,7.77;7,146.47,603.02,65.50,7.77">Journal of molecular biology</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="195" to="197" />
			<date type="published" when="1981">1981</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.13,622.16,330.48,9.82;7,146.47,635.17,332.55,7.77;7,146.47,646.13,274.59,7.77;7,146.47,657.93,296.87,6.31" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,298.38,624.21,170.23,7.77;7,146.47,635.17,200.33,7.77">Diverse Queries and Feature Type Selection for Plagiarism Discovery-Notebook for PAN at CLEF 2013</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Suchomel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kasprzak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Brandejs</surname></persName>
		</author>
		<ptr target="http://www.clef-initiative.eu/publication/working-notes" />
	</analytic>
	<monogr>
		<title level="m" coord="7,168.88,646.13,208.11,7.77">Working Notes Papers of the CLEF 2013 Evaluation Labs</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Tufis</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2013-09">Sep 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.13,119.96,281.32,7.77;8,146.47,130.92,308.47,7.77;8,146.47,141.88,252.19,7.77;8,146.47,153.68,296.87,6.31" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,234.66,119.96,184.79,7.77;8,146.47,130.92,153.84,7.77">Text Alignment Module in CoReMo 2.1 Plagiarism Detector-Notebook for PAN at CLEF 2013</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Torrej√≥n</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ramos</surname></persName>
		</author>
		<ptr target="http://www.clef-initiative.eu/publication/working-notes" />
	</analytic>
	<monogr>
		<title level="m" coord="8,146.47,141.88,208.11,7.77">Working Notes Papers of the CLEF 2013 Evaluation Labs</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Tufis</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2013-09">Sep 2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
