<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,143.30,148.76,321.75,15.96;1,175.34,166.16,244.64,15.96;1,211.37,186.64,172.60,12.00">Developing High-Resolution Universal Multi-Type N-Gram Plagiarism Detector Notebook for PAN at CLEF 2014</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,241.49,224.72,64.15,9.05"><forename type="first">Yurii</forename><surname>Palkovskii</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute of Foreign Philology SkyLine LLC</orgName>
								<orgName type="department" key="dep2">Plagiarism Detector</orgName>
								<orgName type="institution">State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,312.35,224.72,52.96,9.05;1,176.54,246.38,35.86,8.18"><forename type="first">Alexei</forename><surname>Belov Zhytomyr</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute of Foreign Philology SkyLine LLC</orgName>
								<orgName type="department" key="dep2">Plagiarism Detector</orgName>
								<orgName type="institution">State University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,214.67,246.38,43.81,8.18"><forename type="first">Ivan</forename><surname>Franko</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Institute of Foreign Philology SkyLine LLC</orgName>
								<orgName type="department" key="dep2">Plagiarism Detector</orgName>
								<orgName type="institution">State University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,143.30,148.76,321.75,15.96;1,175.34,166.16,244.64,15.96;1,211.37,186.64,172.60,12.00">Developing High-Resolution Universal Multi-Type N-Gram Plagiarism Detector Notebook for PAN at CLEF 2014</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C54A4578A3000A0EB44927D42EBB516D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes approaches used for the Plagiarism Detection task during PAN 2014 International Competition on Uncovering Plagiarism, Authorship, and Social Software Misuse, that scored 1-st place with plagdet score (0.907) for test corpus no.3 and 3-rd place score (0.868) for test corpus no. 2. In this work we aggregated all the previously researched experience from PAN12 and PAN 13 research works [2] and thus further improved previously developed methods of detecting plagiarism [8], with the help of: contextual ngrams, surrounding context n-grams, named entity based n-grams, odd-even skip n-grams, functional words frame based n-grams, TF-IDF sentence level similarity index and noise sensitive clusterization algorithm, focused summary type detection heuristics, combined into a single model to mark similarity sections and thus effectively detect different types of obfuscation techniques.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Each year PAN competition pushes forward the baseline of plagiarism detection effectiveness thus making it harder and harder to compete with the top plagdet score becoming close to the absolute values irrespective of even more demanding plagiarism types included into the new corpora. This year we tried to incorporate all the knowledge we could aggregate via already published PAN works <ref type="bibr" coords="1,405.55,537.61,11.47,9.05" target="#b2">[3,</ref><ref type="bibr" coords="1,417.02,537.61,7.64,9.05" target="#b1">2,</ref><ref type="bibr" coords="1,424.66,537.61,7.64,9.05" target="#b3">4,</ref><ref type="bibr" coords="1,432.30,537.61,7.64,9.05" target="#b4">5]</ref> and try to figure out how to make most of the algorithms that already proved to achieve best performance during the last years. The introduction of the lately developed TIRA platform <ref type="bibr" coords="1,161.78,572.17,11.69,9.05" target="#b0">[1]</ref> has greatly boosted the software deployment and thus made it easier both to participate in the competition, synchronize the local result and the result in the test environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>The main goal of this year research was to aggregate all the most efficient methods <ref type="bibr" coords="1,124.82,671.92,11.54,9.05" target="#b5">[6,</ref><ref type="bibr" coords="1,136.36,671.92,7.69,9.05" target="#b6">7]</ref> that have already been applied to the task of plagiarism detection. The dominating approach that showed best results and greatly improved recall was the one demonstrated by Efstathios Stamatatos <ref type="bibr" coords="2,307.85,149.48,11.69,9.05" target="#b6">[7]</ref> -namely the introductions of stopwords n-gram generation. We combined the above idea with another idea introduced by Jan Kasprzak <ref type="bibr" coords="2,200.59,172.52,11.63,9.05" target="#b2">[3,</ref><ref type="bibr" coords="2,212.21,172.52,7.75,9.05" target="#b3">4]</ref> of generating context based n-grams from both the exact sentence context, surrounding sentences n-gram extraction and n-gram generation based on cyclical word deletion. We also introduced "Named Entity injection as ngram" method: basically it is not an n-gram in any manner, but we considered an option to somehow "inject" the Named Entity uniqueness into the general model and to achieve this we harvest all the Named Entities from the text and treat it as a regular n-gram, irrespective of the fact that it is not actually a typical n-gram that usually consists of multiple words.</p><p>We did such analysis and came up with the following methods of n-gram generation:</p><p>1. Regular n-grams 2. Variable length stop-word n-grams 3. Named Entity based n-grams 4. Most Frequently used words n-grams N-grams expansion by: 1. Odd-even generation on a sentence level 2. Resulting n-gram set stemming 3. A single word deletion on a fingerprint level 4. N-grams alphasorting Text preprocessing included special symbols removal and space trimming. The input text parsing was made on 2 levels: sentence level and word level.</p><p>We applied angled ellipse based graphical clustering algorithm <ref type="bibr" coords="2,415.03,465.01,11.69,9.05" target="#b7">[8]</ref> to define clusters of shared fingerprints. The main approach was to detect what kind of plagiarism is dominating within the document pair -by applying special kind of analysis that included global noise level detection, single stage analysis for the existence of verbatim plagiarism clusters, shared fingerprints sequence analysis, diagonal density analysis, summary type presence and then finally selecting which analysis preset will be used for final analysis. Our software selects one of 4 possible parameter presets for the final detection strategy:</p><p>1. Verbatim Plagiarism 2. Random Plagiarism 3. Summary type Plagiarism</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Undefined type with high noise</head><p>The algorithm in detail:</p><p>1. Both d_1 as the 1st document and d_2 as the 2nd document are preloaded with the same preloading sequence.</p><p>2. The text is being preprocessed via all special characters and text control symbols with the initial offsets kept intact. Diacritics is being neutralized by dot net provided ".Normalize" method. At word delimitation stage, we also apply StringComparison.InvariantCultureIgnoreCase option to get better split quality. We used our own developed sentence split heuristics, based on a set of predefined rules for sentence delimitation. If global parameter for punctuation signs removal is on, the application removes punctuation marks, again with the offsets left intact.</p><p>3. Each sentence is being split into words. We use text representation with object structure, having access to each sentence and word by both value and offset, using hash tables and inverted indices with performance as a consideration.</p><p>4. We do quality preprocessing for each word if global flag is on again with the resulting word-length and offset being corrected to pertain globally correct offsets.</p><p>5. At this stage we generate all required n-grams. N-grams are formed using different strategies: structural n-grams, regular n-grams, stop-word based n-grams, Named Entity based n-grams, near-context based n-grams. We use different input for n-grams input values: words sequences of different lengths and Named Entities. The former being divided into several stages with a separate stage for a specific n-gram generation strategy <ref type="bibr" coords="3,204.07,344.99,11.02,9.05" target="#b3">[4,</ref><ref type="bibr" coords="3,215.09,344.99,7.34,9.05" target="#b5">6,</ref><ref type="bibr" coords="3,222.43,344.99,7.34,9.05" target="#b6">7,</ref><ref type="bibr" coords="3,229.78,344.99,7.34,9.05" target="#b7">8]</ref>. All resulting n-grams are then translated to hashes using dot net built in .GetHash method and stored within hash table, with key being a hash and value being the n-gram offset.</p><p>6. We do a complete search within hash table of d_1 against hash table of d_2 aggregating the results into a list of "shared" n-grams.</p><p>7. At this stage we do a sentence-against-sentence vector space model statistical analysis. We pre-calculate word vector for each sentence and then we ran exhaustive comparison via sentence-against-sentence analysis with cosine similarity being a final comparison value stored as a result. If this similarity value exceeds a predefined global threshold, we add a final result cluster that points to the analyzed sentence pair. The interesting point is, that this stage results do affect the final results only at late stage 9.</p><p>8. For each "shared" n-gram detected we run a clustering algorithm to define the exact clusters of n-grams that are the final product of the developed application. Our clusterization algorithm has been already described in our previous publications <ref type="bibr" coords="3,446.95,506.05,10.66,9.05" target="#b7">[8]</ref>. 9. Clustering algorithm is the most complicated part of the software and most computationally intensive procedure. The exact logic of this stage depends on a global strategy that is automatically selected in an attempt to better tackle a specific type of obfuscation.</p><p>10. We form initial clusters from detected "shared" n-grams via skewed eclipse based (last year we used circle-based type) offset based two dimensional plain graphical analysis. 11. We do vector space model analysis routines at this point. 12. We merge n-gram based detected clusters with VSM detected clusters at this point.</p><p>13. We compute n-gram ordering in all detected clusters. 14. We do 1st stage preprocessing for all detected clusters that includes: building n-gram distribution histogram <ref type="bibr" coords="3,247.21,655.60,10.66,9.05" target="#b7">[8]</ref>, cluster removal from the current result list if cluster absolute length is less than a globally predefined value, cluster removal from the current result list if cluster "is inside" another large cluster.</p><p>15. We do final cluster remerge procedure: clusters are close enough (using a predefined global value) then they are merged into a single cluster, thus adjusting granularity score.</p><p>16. We do final cluster list post-processing: removing all clusters that are too small in length (character-based), contain very few n-grams, do not have sufficient percent of n-grams located within the main cluster diagonal -so called low "insufficient ngram diagonal distribution", "is vertical" filter that is made in order to mitigate PAN corpus caused malformed clusters and duplicating false positives. 17. Final results are formed from the remaining clusters. We use specially developed visualization tool to graphically assess resulting clusters and follow our methodology of "visualize-analyze-correct" strategy. Below there is a screenshot of the produced final analysis cluster graph, with sample skewed eclipse, that shows the exact "is-in-eclipse" n-gram clustering logic output. Structural n-grams are shown in green and are printed, regular n-grams are shown in red circles, the master cluster definition of gold standard xml-descriptor is marked by a red rectangle whereas vector space model detected cluster (marked in grey) fully coincides with finally detected cluster (marked in black), which, in its turn, coincides with the master cluster (marked in red). Shared Named Entities are marked in blue and act as a regular ngrams. The graph is formed using "Zero Obfuscation Strategy" (see 18 for more details): 18. The above mentioned steps from 1 to 17 are strategy dependent. That is, they use a special preset of parameters that best fits specific obfuscation type. At the initial analysis stage, the software analyses several critical input data characteristics: global noise level, cluster ordering, number of verbatim plagiarism clusters via the percent of clusters with absolute diagonal distribution. Then it selects one of the three possible parameter sets -"Zero Obfuscation Strategy", "Low Obfuscation Strategy, Low Noise", "High Noise Strategy", "High Obfuscation Strategy, High Noise Strategy" and recursively runs another analysis. Each of the abovementioned strategies use its own globally predefined sets of values and switches that define the exact changes in routines in steps 1-17 mentioned above.</p><p>19. At this stage software compares the results of preliminary analysis that was used for strategy definition with the results received with strategy applied. Final result is chosen at this stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head><p>The developed software scored 1-st place with plagdet score (0.907) for test corpus no.3 and 3-rd place score (0.868) for test corpus no. 2. At the moment we are not able to and explain the difference in results as long as both corpora are not yet publically downloadable and we do not know the difference between the test corpora versions, we are waiting for the test data release to further research the difference in the achieved Recall and Granularity. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corpus</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions and Future Work</head><p>The result achieved at this year PAN competition shows really tight competition for every percent. Comparing our previous results to this year results we may conclude that we made really good progress landing between the best competing teams at PAN. Unfortunately, due to many different factors that go beyond the scope of the abovementioned research, we were not able to fully optimize the developed system. The majority of the parameters used were heuristically set to most optimal values we come with initially. This fact shows large space for future improvements. Applying genetic algorithm for global parameter tuning will definitely give much better results and will allow much better tuning for each specific corpus.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" coords="4,136.20,388.90,334.10,180.85"><head></head><label></label><figDesc></figDesc><graphic coords="4,136.20,388.90,334.10,180.85" type="bitmap" /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgments. To the <rs type="institution">PAN RnD team</rs>, for their fantastic job making deploying and running software on TIRA platform possible, for their prompt responses and discrete guidance both on the competition website and Google groups. We would like to thank our competing teams as well, as our research was heavily based on and dramatically boosted by the knowledge and experience they shared in their previously published works and live workshop discussions at previous PANs. We also would like to thank the organizers for providing support and the official letter of invitation to be able to append PAN workshop aiding us with visa acquisition for the conference.</p></div>
			</div>			<div type="references">

				<listBibl>

<biblStruct coords="6,146.58,177.32,324.06,9.05;6,160.82,188.84,309.85,9.05;6,160.82,200.36,309.70,9.05;6,160.82,211.76,172.62,9.05" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,458.47,177.32,12.17,9.05;6,160.82,188.84,204.36,9.05">An Evaluation Framework for Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alberto</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,389.34,188.84,81.33,9.05;6,160.82,200.36,242.58,9.05">23rd International Conference on Computational Linguistics (COLING 10)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010-08">August 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,146.58,223.28,323.90,9.05;6,160.82,234.80,309.84,9.05;6,160.82,246.32,309.51,9.05;6,160.82,257.84,310.06,9.05;6,160.82,269.39,309.97,9.05;6,160.82,280.79,7.53,9.05" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,419.01,234.80,51.65,9.05;6,160.82,246.32,250.50,9.05">Overview of the 5th International Competition on Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthias</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tim</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Tippmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Johannes</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Efstathios</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,363.09,257.84,107.79,9.05;6,160.82,269.39,130.69,9.05">Working Notes Papers of the CLEF 2013 Evaluation Labs</title>
		<editor>
			<persName><forename type="first">Pamela</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dan</forename><surname>Tufis</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2013-09">September 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,146.58,292.31,324.00,9.05;6,160.82,303.83,309.85,9.05;6,160.82,315.35,309.74,9.05;6,160.82,326.87,309.59,9.05;6,160.82,338.39,294.18,9.05" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,370.96,292.31,99.63,9.05;6,160.82,303.83,309.85,9.05;6,160.82,315.35,309.74,9.05;6,160.82,326.87,309.59,9.05;6,160.82,338.39,82.55,9.05">Detección de plagio en documentos: sistema externo monolingüe de altas prestaciones basado en ngramas contextuales&quot; (Plagiarism Detection in Documents: High Performance Monolingual External Plagiarism Detector System Based on Contextual N-grams)</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Rodríguez-Torrejón</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Martín-Ramos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,250.44,338.39,160.37,9.05">Procesamiento del Lenguaje Natural. N</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,146.58,349.79,323.82,9.05;6,160.82,361.31,309.71,9.05;6,160.82,372.83,93.56,9.05;6,291.13,372.83,179.01,9.05;6,160.82,384.35,309.42,9.05;6,160.82,395.87,199.36,9.05" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,351.95,349.79,118.45,9.05;6,160.82,361.31,309.71,9.05;6,160.82,372.83,93.56,9.05;6,291.13,372.83,77.32,9.05">CoReMo System (Contextual Reference Monotony) A Fast, Low Cost and High Performance Plagiarism Analyzer System: Lab for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Rodríguez-Torrejón</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Martín-Ramos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,290.14,384.35,180.10,9.05;6,160.82,395.87,43.13,9.05">Notebook Papers of CLEF 2010 LABs and Workshops</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Harman</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">E</forename><surname>Pianta</surname></persName>
		</editor>
		<meeting><address><addrLine>Padua, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010-09-23">2010. 22-23 September. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,146.58,407.27,323.77,9.05;6,160.82,418.79,309.90,9.05;6,160.82,430.31,309.81,9.05;6,160.82,441.85,309.91,9.05;6,160.82,453.37,309.62,9.05;6,160.82,464.89,309.50,9.05;6,160.82,476.29,170.64,9.05" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,412.51,418.79,58.21,9.05;6,160.82,430.31,185.40,9.05">Recent Trends in Digital Text Forensics and its Evaluation</title>
		<author>
			<persName coords=""><forename type="first">Tim</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anna</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthias</forename><surname>Busse</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Francisco</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Efstathios</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,423.02,441.85,47.71,9.05;6,160.82,453.37,309.62,9.05;6,160.82,464.89,259.40,9.05">Information Access Evaluation meets Multilinguality, Multimodality, and Visualization. 4th International Conference of the CLEF Initiative (CLEF 13)</title>
		<editor>
			<persName><forename type="first">Pamela</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Roberto</forename><surname>Paredes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013-09">September 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,146.58,487.81,324.01,9.05;6,160.82,499.33,309.62,9.05;6,160.82,510.85,309.48,9.05;6,160.82,522.37,309.97,9.05;6,160.82,533.89,21.02,9.05" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="6,392.45,487.81,78.15,9.05;6,160.82,499.33,309.62,9.05;6,160.82,510.85,168.51,9.05">Three Way Search Engine Queries with Multi-feature Document Comparison for Plagiarism Detection-Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">Šimon</forename><surname>Suchomel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jan</forename><surname>Kasprzak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michal</forename><surname>Brandejs</surname></persName>
		</author>
		<ptr target="http://www.clef-initiative.eu/publication/working-notes" />
		<editor>Forner et al.</editor>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,146.58,545.29,296.84,9.05;6,160.82,556.81,303.18,9.05" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,251.45,545.29,187.29,9.05">Plagiarism Detection Using Stopword n-Grams</title>
		<author>
			<persName coords=""><forename type="first">Efstathios</forename><surname>Stamatatos</surname></persName>
		</author>
		<idno type="DOI">10.1002/asi.21630</idno>
		<ptr target="http://dx.doi.org/10.1002/asi.21630" />
	</analytic>
	<monogr>
		<title level="j" coord="6,160.82,556.81,29.28,9.05">JASIST</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2512" to="2527" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,146.58,568.33,305.33,9.05;6,160.82,579.85,301.53,9.05;6,160.82,591.37,307.99,9.05;6,160.82,602.89,236.17,9.05;6,160.82,614.29,158.18,9.05" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="6,303.37,568.33,148.55,9.05;6,160.82,579.85,301.53,9.05;6,160.82,591.37,243.03,9.05">Applying Specific Clusterization and Fingerprint Density Distribution with Genetic Algorithm Overall Tuning in External Plagiarism Detection-Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">Yurii</forename><surname>Palkovskii</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alexei</forename><surname>Belov</surname></persName>
		</author>
		<ptr target="http://www.clef-initiative.eu/publication/working-notes" />
		<editor>Forner et al.</editor>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
