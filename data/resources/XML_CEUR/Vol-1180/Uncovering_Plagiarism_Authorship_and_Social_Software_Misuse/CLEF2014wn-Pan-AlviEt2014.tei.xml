<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,161.94,116.10,291.47,12.64;1,278.60,134.03,58.16,12.64;1,222.93,153.85,169.49,10.53">Hashing and Merging Heuristics for Text Reuse Detection Notebook for PAN at CLEF-2014</title>
				<funder ref="#_hUybySZ">
					<orgName type="full">Deanship of Scientific Research at King Fahd University of Petroleum &amp; Minerals</orgName>
					<orgName type="abbreviated">KFUPM</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,217.05,189.96,43.86,8.76"><forename type="first">Faisal</forename><surname>Alvi</surname></persName>
							<email>alvif@kfupm.edu.sa</email>
							<affiliation key="aff0">
								<orgName type="institution">King Fahd University of Petroleum &amp; Minerals</orgName>
								<address>
									<country key="SA">Saudi Arabia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,270.35,189.96,64.64,8.76"><forename type="first">Mark</forename><surname>Stevenson</surname></persName>
							<email>mark.stevenson@sheffield.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,344.43,189.96,49.40,8.76"><forename type="first">Paul</forename><surname>Clough</surname></persName>
							<email>p.d.clough@sheffield.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,161.94,116.10,291.47,12.64;1,278.60,134.03,58.16,12.64;1,222.93,153.85,169.49,10.53">Hashing and Merging Heuristics for Text Reuse Detection Notebook for PAN at CLEF-2014</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F3DCBAA6CC033E47DD0F31F82248D576</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes a joint software entry by King Fahd University of Petroleum &amp; Minerals and the University of Sheffield for the text-alignment task at PAN-2014. We employ the three steps of seeding, extension and filtering for text alignment. For seeding we use character n-grams with a variant of the Rabin-Karp Algorithm for multiple pattern search. We then use an elaborate merging mechanism with several cases to combine the individually found seeds. A short filtering step is then used to remove extraneous passages. This approach scored plagdet scores of 0.65954 and 0.73416 on test corpora 2 and 3 during the final test run.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.28" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Text Reuse Detection has been a part of plagiarism detection at the PAN Competition since inception as text alignment <ref type="bibr" coords="1,267.71,441.13,11.45,8.76" target="#b4">[5,</ref><ref type="bibr" coords="1,279.16,441.13,7.64,8.76" target="#b5">6]</ref> in 2012-14 and as extrinsic plagiarism detection earlier. For the year 2013, the text alignment task consisted of finding passages of reused text in five different types of obfuscated document pairs: no plagiarism, no obfuscation, random obfuscation, translation obfuscation and summary obfuscation. Since the training corpus for PAN-2014 text alignment is the same as in 2013, it could be inferred that similar obfuscation types could be in use in 2014.</p><p>Several approaches have been employed by participants for text alignment including character n-grams, word n-grams and their variants, along with various similarity metrics. Three distinct stages in participants' approaches have been identified in PAN Overview paper for 2013 <ref type="bibr" coords="1,237.28,548.73,10.79,8.76" target="#b5">[6]</ref>: <ref type="bibr" coords="1,254.16,548.73,11.62,8.76" target="#b0">(1)</ref> seeding, (2) extension, and (3) filtering.</p><p>For our current year's (2014) entry, our submitted software also consists of these three stages of seeding, extension/merging and filtering. In the seeding stage we use character n-grams after post-processing and apply a variant of the Rabin-Karp Algorithm <ref type="bibr" coords="1,160.24,596.55,11.62,8.76" target="#b1">[2]</ref> for multiple pattern search <ref type="bibr" coords="1,289.26,596.55,11.45,8.76" target="#b2">[3,</ref><ref type="bibr" coords="1,300.71,596.55,7.64,8.76" target="#b3">4]</ref> to find matching seeds. We then classify pairs of matching seeds within source and suspicious documents into four classes: containment, overlap, near-disjoint and far-disjoint. We then use case-by-case merging to combine pairs of various classes. Finally, we apply filtering to remove short passages in order to exclude false positives. Our approach has shown mid-range results for the 2013 and 2014 training and test corpora.</p><p>As outlined in the first section our approach consists of 3 phases: seeding, extension and filtering along with some preprocessing. An overview of the resulting software appears in the block diagram as shown in Figure <ref type="figure" coords="2,297.23,166.53,3.74,8.76">1</ref>. The language of the software was java. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Preprocessing</head><p>Initially the 'pairs' file is sorted according to the source file by file number. Since one source document may be linked to several suspicious documents, a single hashing of source document is repeatedly used for finding matches in corresponding suspicious documents. Furthermore, during hashing, all punctuation, whitespace and non-printable characters are removed. This is done as two perfectly reused strings (one in the source document and other in the suspicious one) could go undetected because of an unequal amount of spaces, punctuation and/or other characters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Seeding</head><p>Seeding is defined as "Given a suspicious document and a source document, matches (so-called "seeds") between the two documents are identified using some seed heuristic.... By coming up with as many reasonable seeds as possible, the subsequent step of extending them into aligned passages becomes a lot easier". <ref type="bibr" coords="2,377.54,608.50,11.62,8.76" target="#b5">[6]</ref> For seeding, or identifying exact matches of character n-grams between two documents, we use Rabin-Karp Algorithm <ref type="bibr" coords="2,286.52,632.41,11.62,8.76" target="#b1">[2]</ref> for multiple pattern search <ref type="bibr" coords="2,408.08,632.41,10.79,8.76" target="#b2">[3,</ref><ref type="bibr" coords="2,418.87,632.41,7.19,8.76" target="#b3">4]</ref>. This is done by first placing all character n-grams (for a particular value of n) into a multiple valued hashtable, and then finding matches for character n-grams of the suspicious document from the hashtable. Due to hashing, the search time of this is reduced from O(source size × susp size) to O(source size + susp size) -a substantial saving over naïve string search. However, we employ several optimizations and simplifications to the Rabin-Karp Algorithm in java as follows:</p><p>1. We use java's built-in java.util.hashmap collection, which in-turn utilises java's built-in hashCode() method as a hash function, that ensures a unique hash value for each unique character n-gram.</p><p>2. Since several strings are repeated in a document at different locations, use of a single-valued hashtable will inevitably lead to collisions -hence we use a multiple valued hashtable called a multihashmap to store these, as shown in Figure <ref type="figure" coords="3,463.40,234.84,3.74,8.76">2</ref>. A multihashmap can be created by some modifications to the original hashmap provided in java. For example, the character 20-gram "symptomsofarrhythmia" appears several times in a source document and it is recorded each time with new locations as a value.</p><p>3. For each n-gram its location is stored as a 3-tuple (start location, end location, size) in the multihashmap. Some book-keeping is done to keep track of whitespace and other ignored characters in the location(s), while the size parameter keeps track of actual size.</p><p>Once the multihashmap for a particular source document is created, we make a run of each suspicious file to find the matching character n-grams. The output is a list of pairs of 3-tuples: one from the source file and the other from the suspicious file. For example after the algorithm is run on a source file with the corresponding suspicious file, the output would be a list of the form:</p><formula xml:id="formula_0" coords="3,149.71,604.73,330.88,26.55">List of 3-tuple pairs = {(x 1 , y 1 , s 1 ) → (a 1 , b 1 , s ′ 1 ), (x 2 , y 2 , s 2 ) → (a 2 , b 2 , s ′ 2 ), . . .} In the list above, the entry (x 1 , y 1 , s 1 ) → (a 1 , b 1 , s ′ 1 )</formula><p>means that the text in the source file from position x 1 to y 1 of size s 1 is aligned with the text in the suspicious file from location a 1 to b 1 of size s ′ 1 . It may be noted that y 1 &gt; x 1 and b 1 &gt; a 1 , furthermore</p><formula xml:id="formula_1" coords="3,134.76,654.55,114.67,12.60">s 1 ≤ y 1 -x 1 , s ′ 1 ≤ b 1 -a 1 .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Extension</head><p>Once the list of matching pairs is generated between a pair of source and suspicious documents, the next step is the extension or merging of these matches into contiguous, aligned passages. This is done by combining seeds or matches that satisfy certain criteria both in the source and suspicious documents into larger matches. We identify four distinct categories of matches as follows based on their vicinity towards each other. Consider two matching pairs</p><formula xml:id="formula_2" coords="4,265.90,194.68,214.69,12.60">(x 1 , y 1 , s 1 ) → (a 1 , b 1 , s ′ 1 ), (x 2 , y 2 , s 2 ) → (a 2 , b 2 , s ′ 2 )</formula><p>where (x 1 , y 1 , s 1 ) indicates text from position x 1 to position y 1 of size s 1 in the source document, and (a 1 , b 1 , s ′ 1 ) indicates the corresponding text from position a 1 to b 1 of size s ′ 1 in the suspicious document. In order to merge these pairs in each of the source and suspicious documents, we identify four categories of matches as follows:</p><p>1. Containment: Containment is the relationship between two matches within the same document when the text-positions of one match are fully contained within the text-positions of the other. More formally, the match (x  Strategy for Merging The overall strategy for merging is based on the idea that two matching pairs that have either one of the containment, overlap or near-disjoint relationship can be merged towards forming a larger 3-tuple. 3-tuples that are far-disjoint cannot be merged. Furthermore, if two mapping pairs of 3-tuples have a different relationship in the source and suspicious documents then these tuples may be combined according to their respective categories. However, in a particular case of 3-tuples, i.e., when the 3-tuples have a near-disjoint relationship in one document and overlap or containment relationship in the other document, then no merging may be carried out. This is because it is a likely case of term-repetition, a situation in which a term is repeated within one of the documents, but it may mistakenly map to a large of text in the other document.</p><p>Figure <ref type="figure" coords="5,178.10,250.71,4.98,8.76" target="#fig_0">3</ref> shows the four categories, while Table <ref type="table" coords="5,339.97,250.71,4.98,8.76" target="#tab_3">1</ref> gives a case-by-case listing of the merging strategies that we used for merging.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Filtering</head><p>After seeding and merging, the next step is filtering. For PAN-2014 training corpus, it was observed that short passages, typically less than 200 characters resulted in a lot of false positives. Hence all passages which were less than 200 characters in the source document aligned with passages less than 100 characters in the suspicious document were removed. The final output was then written to the XML files. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Setup</head><p>The first step before testing was to select the values of the parameters n and gap for character-n-grams and the gap size. Since this was a first time participation for us, one of the goals of our approach was to ensure at least a 90% precision while getting a high value of recall. After testing through a range of values, n = 20, gap = 200 was found to be the most suitable since, this set of values ensured at least 90% precision on all training corpora, while giving the highest values for the overall plagdet score and recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Training Corpora</head><p>We tested our approach on three corpora <ref type="bibr" coords="6,304.57,284.96,11.62,8.76" target="#b6">[7]</ref>  These results imply that our approach based on hashing and merging heuristics gives very good plagdet scores for no plagiarism and no obfuscation cases, mid-range scores for random and translation obfuscations, and marginal scores for summary obfuscation.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Test Corpora</head><p>For the final testing, the final software was uploaded on 30/April/2014 and test runs on all three test corpora were done on 16/May/2014. No errors were found during the runs, and hence exactly a single run was done on each of the test corpora. Results of runs on test corpora 2 and 3 have been published and are listed in Table <ref type="table" coords="7,407.94,171.97,3.74,8.76" target="#tab_5">2</ref>, while results of test corpus 1 runs were made available to the participants only (as it was the early bird corpus). It can be observed from Table <ref type="table" coords="7,292.56,195.88,4.98,8.76" target="#tab_5">2</ref> that the overall plagdet scores are inline with those obtained for the training corpora earlier.</p><p>Currently, performance results of the software according to various obfuscation types are not available on the test corpora. However, it is expected that these results will be in agreement with the training corpora results too. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and Future Work</head><p>In this work, we used hashing and merging heuristics on character n-grams for text reuse detection. Our approach scored a mid-range performance on PAN-2014 test corpora. From the training corpora, it was obvious that while the approach scored very well in no plagiarism and no obfuscation types, there was room for improvement for translation and random obfuscations. Furthermore, a completely new approach may need to be devised for the marginal summary obfuscation scores. Several directions of future work arise from here. For the current approach, a better detection with improved recall can be achieved if a more fine-grained merging mechanism is adopted with further sub-cases. Likewise, an improved granularity would also help in improvising detection score, by confining matches to only the necessary number.</p><p>On a different level, we can devise new approaches by using a variety of mechanisms such as character skip grams <ref type="bibr" coords="7,283.34,581.63,11.62,8.76" target="#b0">[1]</ref> or other natural language processing mechanisms for a more indepth processing. This could provide new insights into text reuse detection, especially on random, translation and summary obfuscations.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,243.38,654.92,128.59,8.01"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Classes of Matching pairs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,319.53,284.96,161.07,8.76;6,134.76,296.92,345.84,8.76;6,134.76,308.87,345.86,8.76;6,149.71,322.84,209.00,8.76;6,149.71,334.61,293.28,9.30;6,149.71,346.79,195.13,8.76;6,149.71,358.76,230.75,8.76;6,149.71,370.74,241.46,8.76;6,149.71,382.71,219.76,8.76"><head></head><label></label><figDesc>for training: PAN-2014 training corpus, PAN-2013 test corpus 1 and PAN-2013 test corpus 2. Figure 4 gives a graphical representation of the results on the three corpora. The scores ranges obtained were as follows: (a) Overall plagdet scores: 0.6 -0.7 for each corpus, (b) No-plagiarism scores: approximately full score ≈ 1.0 for each corpus, (c) No-obfuscation scores: &gt; 0.9 for each corpus, (d) Random obfuscation scores: 0.4 -0.5 for each corpus, (e) Translation obfuscation scores: 0.5 -0.6 for each corpus, (f) Summary obfuscation scores: &lt; 0.1 for each corpus.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,238.80,654.92,137.74,8.01;6,165.84,449.82,298.32,167.21"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Results on Training Corpora</figDesc><graphic coords="6,165.84,449.82,298.32,167.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,138.25,383.79,340.50,255.67"><head>Table 1 .</head><label>1</label><figDesc>Strategies for Merging Various Cases</figDesc><table coords="5,138.25,406.42,340.50,233.03"><row><cell cols="3">Relationship in Source Relationship in Suspicious Replacement Action</cell></row><row><cell cols="2">(x1, y1, s1), (x2, y2, s2) (a1, b1, s ′ 1 ), (a2, b2, s ′ 2 )</cell><cell>Replacement 3-tuple</cell></row><row><cell></cell><cell>Containment</cell><cell>(x1, y1, s1) → (a1, b1, s ′ 1 )</cell></row><row><cell cols="2">Containment: (x1, y1, s1) Overlap</cell><cell>(x1, y1, s1) → (a1, b2, b2 -a1)</cell></row><row><cell>contains (x2, y2, s2)</cell><cell>Near-disjoint</cell><cell>No change (Term Repetition likely)</cell></row><row><cell></cell><cell>Far-disjoint</cell><cell>Merging not possible</cell></row><row><cell></cell><cell>Containment</cell><cell>(x1, y2, y2 -x1) → (a1, b1, s ′ 1 )</cell></row><row><cell>Overlap: (x1, y1, s1)</cell><cell>Overlap</cell><cell>(x1, y2, y2 -x1) → (a1, b2, b2 -a1)</cell></row><row><cell>overlaps (x2, y2, s2)</cell><cell>Near-disjoint</cell><cell>No change (Term Repetition likely)</cell></row><row><cell></cell><cell>Far-disjoint</cell><cell>Merging not possible</cell></row><row><cell></cell><cell>Containment</cell><cell>No change (Term Repetition likely)</cell></row><row><cell>Near-disjoint:</cell><cell>Overlap</cell><cell>No change (Term Repetition likely)</cell></row><row><cell>x2 -y1 ≤ gap</cell><cell>Near-disjoint</cell><cell>(x1, y2, y2 -x1) → (a1, b2, b2 -a1)</cell></row><row><cell></cell><cell>Far-disjoint</cell><cell>Merging not possible</cell></row><row><cell></cell><cell>Containment</cell><cell></cell></row><row><cell>Far-disjoint</cell><cell>Overlap</cell><cell>Merging not possible</cell></row><row><cell>x2 -y1 &gt; gap</cell><cell>Near-disjoint</cell><cell></cell></row><row><cell></cell><cell>Far-disjoint</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,230.36,273.75,154.63,111.81"><head>Table 2 .</head><label>2</label><figDesc>Results on Test Corpora</figDesc><table coords="7,230.36,296.37,154.63,89.18"><row><cell></cell><cell cols="2">Test Corpus 2 Test Corpus 3</cell></row><row><cell>Plagdet</cell><cell>0.65954</cell><cell>0.73416</cell></row><row><cell>Precision</cell><cell>0.93375</cell><cell>0.90081</cell></row><row><cell>Recall</cell><cell>0.55068</cell><cell>0.67283</cell></row><row><cell>Granularity</cell><cell>1.07111</cell><cell>1.06943</cell></row><row><cell>Runtime</cell><cell>4m 57s</cell><cell>4m 17s</cell></row><row><cell>Documents</cell><cell>5185</cell><cell>4800</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. <rs type="person">Faisal Alvi</rs> would like to acknowledge the support provided for this work by the <rs type="funder">Deanship of Scientific Research at King Fahd University of Petroleum &amp; Minerals (KFUPM)</rs> under Research Grant <rs type="grantNumber">RG-1113-1 &amp; 2</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_hUybySZ">
					<idno type="grant-number">RG-1113-1 &amp; 2</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="8,138.12,142.77,300.77,7.88;8,146.47,153.73,320.29,7.88" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,284.52,142.77,154.38,7.88;8,146.47,153.73,76.28,7.88">s-grams: Defining Generalized n-grams for Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Järvelin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Järvelin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Järvelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,228.45,153.73,132.97,7.88">Information Processing Management</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1005" to="1019" />
			<date type="published" when="2007-07">Jul 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.12,164.69,340.46,7.88;8,146.47,175.65,207.55,7.88" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,232.64,164.69,184.49,7.88">Efficient Randomized Pattern-Matching Algorithms</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">M</forename><surname>Karp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Rabin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,423.30,164.69,55.28,7.88;8,146.47,175.65,98.25,7.88">IBM Journal of Research and Development</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="249" to="260" />
			<date type="published" when="1987-03">March 1987</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.12,186.61,318.15,7.88;8,146.47,197.57,252.53,7.88" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,248.56,186.61,204.57,7.88">Exact Pattern Matching with Feed-forward Bloom Filters</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Moraru</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">G</forename><surname>Andersen</surname></persName>
		</author>
		<idno>4:3.18</idno>
	</analytic>
	<monogr>
		<title level="j" coord="8,146.47,197.57,136.22,7.88">Journal of Experimental Algorithmics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="3" />
			<date type="published" when="2012-09">Sep 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.12,208.53,329.27,7.88;8,146.47,219.48,324.10,7.88;8,146.47,230.44,23.90,7.88" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,228.54,208.53,133.17,7.88">Approximate Multiple Strings Search</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Muth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">U</forename><surname>Manber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,379.96,208.53,87.43,7.88;8,146.47,219.48,114.09,7.88">7th Annual Symposium, Combinatorial Pattern Matching</title>
		<title level="s" coord="8,307.22,219.48,126.47,7.88">Lecture Notes in Computer Science</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="75" to="86" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.12,241.40,329.56,7.88;8,146.47,252.36,310.38,7.88;8,146.47,263.32,281.42,7.88;8,146.47,274.28,322.04,7.88;8,146.47,285.24,20.92,7.88" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,385.25,252.36,71.60,7.88;8,146.47,263.32,180.33,7.88">Overview of the 4th International Competition on Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Graßegger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Oberländer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tippmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,241.72,274.28,208.11,7.88">Working Notes Papers of the CLEF 2012 Evaluation Labs</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Karlgren</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Womser-Hacker</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2012-09">Sep 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.12,296.20,324.17,7.88;8,146.47,307.16,333.87,7.88;8,146.47,318.11,318.61,7.88;8,146.47,329.07,39.59,7.88" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,182.34,307.16,254.18,7.88">Overview of the 5th International Competition on Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tippmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,256.97,318.11,208.11,7.88">Working Notes Papers of the CLEF 2013 Evaluation Labs</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Tufis</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2013-09">Sep 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,138.12,340.03,310.15,7.88;8,146.47,350.99,309.05,7.88;8,146.47,361.95,151.65,7.88" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,340.49,340.03,107.78,7.88;8,146.47,350.99,73.99,7.88">An Evaluation Framework for Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Barrón-Cedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,238.61,350.99,216.91,7.88;8,146.47,361.95,52.83,7.88">23rd International Conference on Computational Linguistics (COLING &apos;10)</title>
		<imprint>
			<date type="published" when="2010-08">Aug 2010</date>
			<biblScope unit="page" from="997" to="1005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
