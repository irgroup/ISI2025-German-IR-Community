<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D53819460F93A49F65C5D300BD57D2D6</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CoReMo 2.3 Plagiarism Detector Text Alignment Module</head><p>Notebook for PAN at CLEF 2014 Diego Antonio Rodríguez Torrejón, José Manuel Martín Ramos Departamento de Tecnologías de la Información Universidad de Huelva (Spain) dartsystems@gmail.com, jmmartin@dti.uhu.com</p><p>Abstract. In this paper, the basics of the three tuning approaches of the evolving CoReMo Plagiarism Detector are shown, focused for the Text Alignment task. In the last PAN edition, it was observed that the different corpora could condition the necessary tuning, and the results using an overfitted tuning from a different corpus could be far from the expected ones. This year's goal has been to find the way to get the system could be selftuned, looking for improving the performance of any fixed parameter tuning, and to be very closed to the overfitted performance for any corpus. All of these tuning approaches have a high Plagdet performance for any corpus, but it's intended to show the different advances effect on each corpus and for all the years corpora. They include new features for parameters selftuning, based on the size and the ratio of the compared documents. For the competition, our choice was based on the most constant detection quality tuning approach when any condition (called WideTuning).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>CoReMo (Contextual Reference Monotony) is an external Plagiarism Detector approach which has taken part in the PAN <ref type="bibr" coords="1,307.99,523.66,11.63,12.05" target="#b0">[1]</ref> competition since the 2010 edition, highlighting its efficacy (best ranked in the Text Alignment task in PAN 2013) and its efficiency, especially for large documents, as in PAN 2012, which proved to be at least 10 times faster than any rival approach. These amazing benefits were achieved through an innovative different type ngrams combining model, called Extended Contextual Ngrams model (XCTnG) <ref type="bibr" coords="1,282.75,583.96,11.01,12.05" target="#b1">[2]</ref>[3], and a selftuning feature based on the analysis of the optimal tuning achieved when training by different corpora and subcorpora, having rules only based on the ngrams matching ratio. In a nutshell, the Extended Contextual NGrams model used by CoReMo is the result of removing the stopwords and shortlength words before a stems extraction. The stems are then combined to get 3grams, by direct neighborhood or by skipping once or twice at most one stem. This gets four different ngrams beginning from each word stem. Finally, the inner stems combinations are alphabetically ordered. This process improves the matching probability when the plagiarism obfuscation happens.</p><p>To filter the chance matching, then the Reference Monotony is used, which rejects the matching ngram when it happens far from any minimum length matching group. The minimum group length and maximum distance are rule based since 2.1 version.</p><p>The detection seeds are finally bound when their distance is below a fixed threshold, but currently, in 2.3 version this threshold is rule based too.</p><p>In the Overview of the 5th International Competition of Plagiarism Detection [4] PAN 2013, it led to the overall conclusion that almost all new 2013 algorithms versions had worse outcome than their 2012 version, or at least their behavior was not the expected for both years corpora. It was also felt, that the difficulty of detecting plagiarism in the 2012 corpus was higher than in the 2013 one, because in all the cases it was achieved an improved Plagdet than for 2012 corpus, as well as much lower required analysis time.</p><p>For CoReMo 2.1 (PAN2013) compared to CoReMo 1.9 (PAN2012), although the result was better in the corpus 2013, it was not the same case for the 2012 corpus. Although the Overview's authors believed an overfitting of the new system for the corpus of 2013 as the possible cause, the CoReMo authors considered to be the 1.9 version the really overfitted for the 2012 corpus, having an illogical but optimal granularity reduction binding distance of up to 80.000 characters, twenty times higher than the one used in version 2.1, being this last one large enough to achieve very similar but more accurate results thanks to the highest quality and number of its detection seeds.</p><p>However, the facts that the detection in the corpus PAN2012 could and have to be improved, and that its best fitting was far from the necessary one for the PAN2013 corpora, are leaving the door open to study the different features between the corpora, which may be the key to new selftuning methods to achieve acceptable results for all the corpora together, or even to improve them for each case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Analysis of the Different Corpora</head><p>To establish the way to set the automatic tuning of the granularity filter's binding distance (the greatest tuning parameter deviation), distinctive features were seek between 2012 and 2013 corpora that allowed how to decide it. The data used in the analysis can be found in Table <ref type="table" coords="2,249.32,552.56,3.75,12.05" target="#tab_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Training Stage</head><p>By the analysis of the differences between the corpora used to train the system, possibly useful for tuning, it was essentially seen that the average size of the documents in PAN2013 was much lower than in PAN2012 and that the ratio between the sizes of suspicious documents and source also changed significantly for each corpus, so it was suspected its possible influence for the different optimal setting of CoReMo for each one.</p><p>For that purpose, the PAN12 and PAN13 competition and training corpora were analyzed by CoReMo 2.1, using different parameters for the chunk length and granularity filter binding distance to find the optimal settings for each one.</p><p>The CoReMo efficiency, ready for multicore systems, allowed to arrange hundreds of runs with different configurations on these corpora, as it only takes 4.5 seconds to analyze any of the PAN13 corpora, and about 45 seconds for the PAN12 ones.</p><p>The first and obvious possible improvement lies in tuning the chunk length proportionally to the size of the documents analyzed instead of a fixed length. This adjustment improved the result with the corpus of PAN2012, though curiously it had slightly worse outcome in PAN2013.</p><p>The second improvement was to propose different granularity filter binding distances for the suspicious and source documents. This step actually achieved improvements for all the corpora, although the optimum settings for the 2012 and 2013 corpora were quite different. By this way the best optimal setting was achieved for the PAN2013 competition corpus, achieving a 0.8349 Plagdet score when the distance filter is 8% of the suspicious document size, without affecting the distance between the source detections (we used the 100%). In the 2012 corpus, the optimum is achieved by binding distances of 30% of the the suspicious document size and 50% of the source document size.</p><p>The third improvement was to apply rules based on the ratio between suspicious and source document sizes, to decide when applying the above optimal settings, which improved the performance achieved for PAN2012 significantly (0.6905) at the expense of a slight decrease in the performance for PAN2013 to 0.8319.</p><p>Finally, noting that despite having very similar characteristics in terms of documents and corpus size, the optimal chunk size settings were slightly different for each PAN corpus, similar relationship rules between document sizes were arranged to tune the chunk size, improving the results obtained for all the corpus (i.e. 0.6930 in PAN2012) but for the PAN2013 competition one, which had shown again another slight decrease, until 0.8995.</p><p>The Table <ref type="table" coords="3,183.44,648.96,5.00,12.05" target="#tab_1">2</ref> describes the rules to define these selftuning. The authors think that these rules can still be more optimized by any kind of interpolation. In Fig. <ref type="figure" coords="4,167.74,274.96,3.75,12.05" target="#fig_0">1</ref>, it can be seen the effect of each analyzed possible optimization on its own corpus and the other ones. The left hand side is for PAN2013 test corpus optimizations, the center is for the rule based tuning (focused to any corpora) and the right hand side is for PAN 2012 test corpus optimizations.</p><p>Concluding the analysis of the tests, it can be stated that the auto setting will not get optimal performance for any corpus, but a very closed one to it and good enough to meet the expectations for all of them, despite their considerable differences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">New Features in CoReMo 2.3</head><p>In its continuous evolution, CoReMo 2.3 includes the following new features since the 2.1 (PAN2013) version: • Support for Hindi language, since CoReMo 2.2</p><p>• Granularity Filter dumping distance tunable as fixed one or as proportional to document size. • Independent Granularity Filter settings for source and suspicious documents.</p><p>• Rules for autotuning Granularity Filter by the ratio suspicious/source sizes.</p><p>• New autotuning chunk size rule based on the suspicious/source sizes ratio.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Tuning Approaches Presented</head><p>Due to the new TIRA environment <ref type="bibr" coords="5,267.02,276.86,11.63,12.05" target="#b4">[5]</ref> features, for this issue, there different CoReMo tuning approaches have been provided: 1. CoReMo 2.1 Settings: the same as proposed last year, without the explained improvements, but without the existing bug when the 2013 competition, which left the last detection unregistered when it was near the end of the document. Though curiously it was the best performing of all the three at the EarlyBird evaluation, this fact doesn't match with the training experiments by 2013 and 2012 corpora or by the final competition corpus. 2. Optimum Settings for PAN2013: it only includes the granularity filer distance proportional to the documents size, different for the source document (100% of its size) and the suspicious document (8% of its size). It achieved the best performance when training, but for PAN2012 corpora, which was almost a 5% below the WideTuning version. It also got the best PAN2014 performance of the three tuning approaches, as expected. 3. Wide Tuning Version: It exploits the four new features above explained, with self tuning for both granularity filter distances and chunk length, by rules based on the ratio between documents size. It Achieves the best Plagdet average for all the corpora, being significantly better than the others for the PAN2012 corpora, although slightly lower for 2013 ones. Table <ref type="table" coords="5,152.07,506.06,5.00,12.05" target="#tab_2">3</ref> shows the Plagdet score achieved by the three tuning approaches for the different corpora used in training and the PAN2014 competition corpus, including the EarlyBird evaluation, where curiously, the previous year's tuning approach (CoReMo 2.1) achieved the best results. The tuning approach choosing to be submitted to compete for the ranking, based on which we would use for a production system, was the WideTuning version, although the EarlyBird evaluation forecasts and the features of the competition corpus get to feel that the best fit to win would be respectively the previous year tuning or the 2013 corpora optimized one. During the last PAN edition, it was compared the combination of the different current and previous year's corpora and approaches, and it was noted that the 2012 corpus was significantly the hardest to detect for any approach, having lower Plagdet scores and needing much larger runtimes. The WideTuning approach, allowed us to obtain for 2012 up to 5% more Plagdet score than the others, while on the 2013 corpora it falls less than 0.5% below the optimum one. It's not the first time we prefer showing our research than our ranking progress, as we did in previous years using local translation systems instead of the best external Google Service.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Performance Analysis</head><p>The CoReMo 2.3 performance is still amazing with a 0.85 Plagdet score, precision 0.90, recall 0.80, and an optimal 1.00 granularity. Everything is very closed to the winning approaches, but with the fastest runtime of only 31 seconds: at least 4 times faster than the next one, and 100 times faster than the winning approach. Nevertheless, currently the TIRA system does not offer the ability to operate in the multicore mode, and CoReMo is optimized to use it, allowing to run the same job in just 4 seconds using an AMD FX8120 based machine.</p><p>The Table <ref type="table" coords="6,181.15,444.06,5.00,12.05" target="#tab_3">4</ref> shows that, as expected, the best tuning approach was the PAN2013 optimized (but it gets about 0.04 less Plagdet for PAN2012 test corpus than our choice), and the selected WideTuning version gets almost same best performance, having only 0,001 below score. Both CoReMo 23 tuning versions get to overpass the last year's tuning performance, however, a possible overfitting effect may be present on the best PAN13 optimized due to its lowest PAN2012 test corpus performance (see Table <ref type="table" coords="6,459.50,640.46,3.60,12.05" target="#tab_2">3</ref>). We recommend to check the PAN2012 test corpus performance for all the PAN14 participants approaches which could arrange it in a reasonable time, to look for any possible overfittings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Works</head><p>Although these autosettings are in very good direction and achieving very good results at best runtime for any corpus, the authors think that the selftuning rules for granularity reduction could be significantly improved by another function different to simple thresholds to change fixed parameters values.</p><p>As we mentioned in the previous editions, these methods could be combined with others such as the use of thesaurus to minimize the effect of replacing words by other synonyms.</p><p>It would be wise to check the performance of all participant approaches, looking for any possible overfittings, on the PAN2012 competition corpus (or at least which could arrange it in a reasonable time), which has proved to be the most difficult ever to analyze, and, at least in our case, has demonstrated to require very different settings that for 2013 or 2014 corpora.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,123.30,526.96,265.52,11.71;4,155.30,514.57,25.83,6.70;4,185.60,507.07,18.83,6.70;4,209.80,514.57,24.04,6.70;4,235.60,507.07,28.02,6.70;4,260.70,514.57,30.32,6.70;4,290.50,507.07,24.04,6.70;4,317.80,514.57,23.53,6.70;4,341.40,507.07,30.33,6.70"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. Optimal settings for each optimization applied to different corpora fixed 4000 fix 28% 8%/100% Ruled Bind WideTuning 30%/50% fixed%40 fixed 80.000</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,87.80,576.66,419.90,112.17"><head>Table 1 .</head><label>1</label><figDesc>Data Analysis of file sizes in different corpora</figDesc><table coords="2,87.80,598.66,419.90,90.17"><row><cell>PAN Corpus</cell><cell>Size</cell><cell cols="3">Suspicious Sources Pairs</cell><cell>Susp. Average</cell><cell>Src. Average</cell><cell>Susp/Src (avg)</cell><cell>Susp. Median</cell><cell>Src. Median</cell><cell>Susp/Src (median)</cell></row><row><cell cols="2">2012 test 656MB</cell><cell>3000</cell><cell>3500</cell><cell cols="2">3000 84499</cell><cell>115029</cell><cell>0,73</cell><cell>22867</cell><cell>12183</cell><cell>1,88</cell></row><row><cell cols="2">2012 train 1,35 GB</cell><cell>1804</cell><cell>4210</cell><cell cols="3">6000 165379 250102</cell><cell>0,66</cell><cell cols="2">55175 112334</cell><cell>0,49</cell></row><row><cell cols="2">2013 test 29,8 MB</cell><cell>1826</cell><cell>3169</cell><cell>5185</cell><cell>8762</cell><cell>4366</cell><cell>2,01</cell><cell>6269</cell><cell>2454</cell><cell>2,55</cell></row><row><cell cols="2">2013 train 30,4 MB</cell><cell>1827</cell><cell>3230</cell><cell>5185</cell><cell>8710</cell><cell>4487</cell><cell>1,94</cell><cell>6262</cell><cell>2382</cell><cell>2,63</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,120.20,147.46,364.67,98.37"><head>Table 2 .</head><label>2</label><figDesc>Selfadjusting Rules</figDesc><table coords="4,120.20,171.16,364.67,74.67"><row><cell>parameter</cell><cell>susp/sour &lt; 1.6</cell><cell>1.6 &gt; = susp/sour &lt; 3.0</cell><cell>3.0 &lt; = susp /sour</cell></row><row><cell>Susp. filter distance</cell><cell>susp file length 8%</cell><cell cols="2">30%suspfile length</cell></row><row><cell>Sour. filter distance</cell><cell>100% source file length</cell><cell cols="2">50%source file length</cell></row><row><cell>chunk_length</cell><cell>chunk_length</cell><cell>nominal chunk_length</cell><cell>chunk_length + +</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,104.50,566.26,383.29,121.77"><head>Table 3 .</head><label>3</label><figDesc>Plagdet Score achieved on different corpora</figDesc><table coords="5,104.50,586.36,383.29,101.67"><row><cell>Tuning approach</cell><cell>PAN14 test</cell><cell>PAN14 EarlyBird</cell><cell>PAN13 test</cell><cell>PAN13 training</cell><cell>PAN12 test</cell><cell>Average 12~13</cell><cell>Average 12~14</cell></row><row><cell>CoReMo 2.3 2013 optimum (Soft. 2)</cell><cell>0.85006</cell><cell>0.84490</cell><cell>0.83417</cell><cell>0.82766</cell><cell>0.65747</cell><cell>0.77310</cell><cell>0.79234</cell></row><row><cell>CoReMo 2.3 WideTuning (Soft. 3)</cell><cell cols="2">0.84823 0.84870</cell><cell cols="2">0.82952 0.82478</cell><cell>0.69304</cell><cell>0.78245</cell><cell>0.79901</cell></row><row><cell>CoReMo 2.1 (Soft. 4)</cell><cell cols="2">0.84667 0.85120</cell><cell cols="3">0.82827 0.82709 0.66816</cell><cell>0.77451</cell><cell>0.79255</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,124.90,504.26,322.50,85.31"><head>Table 4 .</head><label>4</label><figDesc>PAN2014 Corpus 3 (new) performance</figDesc><table coords="6,152.60,525.76,294.80,63.81"><row><cell></cell><cell cols="2">Plagdet Precision Recall Granularity</cell></row><row><cell>CoReMo 21</cell><cell>0.84667 0.89179 0.80590</cell><cell>1.00000</cell></row><row><cell cols="2">CoReMo 23 PAN13 optimized 0.85006 0.90770 0.79931</cell><cell>1.00000</cell></row><row><cell>CoReMo 23 WideTuning</cell><cell>0.84870 0.90032 0.80267</cell><cell>1.00000</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="7,128.28,377.28,341.96,10.85;7,136.20,388.18,333.87,10.85;7,136.20,398.98,304.10,10.85" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,416.15,377.28,54.08,10.85;7,136.20,388.18,134.65,10.85">An Evaluation Framework for Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alberto</forename><surname>Barróncedeño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,289.27,388.18,180.80,10.85;7,136.20,398.98,92.10,10.85">23rd International Conference on Computational Linguistics (COLING 10)</title>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2010-08">August 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,128.28,409.88,342.43,10.85;7,136.20,420.68,321.89,10.85" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="7,371.17,409.88,99.54,10.85;7,136.20,420.68,230.95,10.85">Text Alignment Module in CoReMo 2.1 Plagiarism Detector-Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">Diego</forename><forename type="middle">A</forename><surname>Rodríguez Torrejón</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">José</forename><surname>Manuel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martín</forename><surname>Ramos</surname></persName>
		</author>
		<editor>Forner et al.</editor>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">6</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,128.28,431.58,341.97,10.85;7,136.20,442.38,333.92,10.85;7,136.20,453.28,20.19,10.85" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="7,311.37,431.58,158.88,10.85;7,136.20,442.38,330.12,10.85">Ngramas de contexto cercano para mejorar la detección de plagio (Surrounding Context Ngrams to Improve the Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Rodrígueztorrejón</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Martínramos</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="7,128.28,464.08,342.17,10.85;7,136.20,474.98,334.04,10.85;7,136.20,485.78,334.03,10.85;7,136.20,496.68,334.18,10.85;7,136.20,507.48,72.64,10.84" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,333.41,474.98,136.83,10.85;7,136.20,485.78,135.97,10.85">Overview of the 5th International Competition on Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthias</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tim</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Tippmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Johannes</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Efstathios</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,165.78,496.68,212.86,10.85">Working Notes Papers of the CLEF 2013 Evaluation Labs</title>
		<editor>
			<persName><forename type="first">Pamela</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dan</forename><surname>Tufis</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2013-09">September 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,128.28,518.38,341.96,10.85;7,136.20,529.18,334.24,10.85;7,136.20,540.08,334.28,10.85;7,136.20,550.88,334.29,10.85;7,136.20,561.78,334.26,10.85;7,136.20,572.58,153.41,10.85" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,289.79,529.18,180.65,10.85;7,136.20,540.08,37.41,10.85">Recent Trends in Digital Text Forensics and its Evaluation</title>
		<author>
			<persName coords=""><forename type="first">Tim</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Anna</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Matthias</forename><surname>Busse</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Francisco</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Efstathios</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,192.28,550.88,278.21,10.85;7,136.20,561.78,288.70,10.85">Information Access Evaluation meets Multilinguality, Multimodality, and Visualization. 4th International Conference of the CLEF Initiative (CLEF 13)</title>
		<editor>
			<persName><forename type="first">Pamela</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Roberto</forename><surname>Paredes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Paolo</forename><surname>Rosso</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013-09">September 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,128.28,583.48,341.87,10.85;7,136.20,594.28,333.94,10.85;7,136.20,605.18,202.13,10.85" xml:id="b5">
	<monogr>
		<ptr target="http://www.clefinitiative.eu/publication/workingnotes" />
		<title level="m" coord="7,347.72,583.48,122.42,10.85;7,136.20,594.28,139.72,10.85">CLEF 2013 Evaluation Labs and Workshop -Working Notes Papers</title>
		<editor>
			<persName><forename type="first">Pamela</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dan</forename><surname>Tufis</surname></persName>
		</editor>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013">2326 September. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,128.28,615.98,341.92,10.85;7,136.20,626.88,208.47,10.85" xml:id="b6">
	<monogr>
		<ptr target="http://users.dsic.upv.es/grupos/nle/ceri/index.html" />
		<title level="m" coord="7,134.98,615.98,249.68,10.85">II Congreso Español de Recuperación de Información (CERI 2012)</title>
		<meeting><address><addrLine>Valencia</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1718-06">1718 June. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
