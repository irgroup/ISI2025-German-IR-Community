<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,148.44,115.90,318.48,12.90;1,283.23,133.83,48.91,12.90;1,223.43,154.02,168.49,10.75">Author Verification using PPM with Parts of Speech Tagging Notebook for PAN at CLEF 2014</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,280.58,190.76,54.20,8.64"><forename type="first">Sarah</forename><surname>Harvey</surname></persName>
							<email>sharvey@cs.uwaterloo.ca</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Waterloo</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,148.44,115.90,318.48,12.90;1,283.23,133.83,48.91,12.90;1,223.43,154.02,168.49,10.75">Author Verification using PPM with Parts of Speech Tagging Notebook for PAN at CLEF 2014</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8220E9AD2D6431F464A5D7001A33F1D8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we describe a compression-based authorship verification model used in conjunction with a parts of speech tagger. We use standard language-specific parts of speech taggers on the texts in question to generate a stream of symbols representing each word, run the PPM (Prediction by Partial Matching) algorithm on the resulting stream, and use Bobicev's method of calculating and comparing cross-entropies to determine text authorship.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Authorship attribution is generally described as determining the author of a particular disputed work. This is framed as a problem of authorship identification, where, given a sample of documents of known authorship, identify which author wrote the unknown text. This may also be framed as a problem of authorship verification, where we simply want to get a binary answer of whether the author in question wrote a particular text. This is one of the tasks set for PAN2014, an evaluation lab for methods relating to various aspects of stylometry <ref type="bibr" coords="1,248.37,453.45,11.99,8.64" target="#b1">[2]</ref>[3] <ref type="bibr" coords="1,272.36,453.45,11.99,8.64" target="#b3">[4]</ref>.</p><p>PPM is a popular off-the-shelf compression method that has been explored for attribution purposes <ref type="bibr" coords="1,204.33,477.70,12.13,8.64" target="#b7">[8]</ref>[1] <ref type="bibr" coords="1,228.59,477.70,12.13,8.64" target="#b4">[5]</ref>, but it has primarily only been explored for raw texts, and primarily only for the English language. We extract the statistical model powering PPM and use its predictive capabilities on a per-word basis as opposed to a per-character basis in previous experiments. We pre-process the texts in question to convert into POS-symbol streams, use PPM to calculate entropies, then calculate the probability of authorship based on these entropies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head><p>The basis of our method is extremely simple: run the texts in question through a parts of speech tagger and label each corresponding part with a symbol, then run the PPM algorithm on the resulting symbols, and calculate the cross-entropy between the known and unknown texts. This method is an extension of <ref type="bibr" coords="1,339.21,632.53,10.58,8.64" target="#b0">[1]</ref>, in that we use the same method of calculating cross-entropies and running a pairwise t-test on the results. We change things slightly by simply preprocessing the text by running the parts of speech tagger.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Parts of speech tagging</head><p>The effectiveness of PPM on texts is purely dependent on whether or not the context size of the model can accurately capture word usage patterns. While PPM usage has been studied on English texts <ref type="bibr" coords="2,254.97,166.74,11.39,8.64" target="#b8">[9]</ref>[10], it appears that its effectiveness is relatively unknown on other forms of texts. We posit that this is due to the fact that the effectiveness of PPM per-language requires context-sizing tweaks to accurately capture patterns in symbols for other languages. We decide to reduce the texts in question to symbols representing the parts of speech of the original words, and assess the effectiveness of the PPM statistical model on per-word instead of per character instances.</p><p>We used TreeTagger <ref type="bibr" coords="2,229.40,239.19,25.71,8.64">[7][6]</ref> for converting texts to their parts of speech equivalents, due to the fact that it had support for English, Dutch, and Spanish language tagging. Unfortunately due to time constraints we were not able to test other English speech of taggers (of which there are numerous), nor were we able to test this method for the Greek corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Prediction by Partial Matching (PPM)</head><p>PPM is a compression technique that makes use of a combination of a previously seen context along with Markov chains to generate a statistical model that represents the originally seen text. Symbols on an input stream simultaneously update the model, in addition to being arithmetically coded in the resulting output stream. For the purposes of authorship attribution it is simpler to discard the arithmetic coder and any 'state' optimizations in place for compression; we are mostly only concerned with the statistical model for which we use to calculate the next character probabilties, and thus the resulting entropies, of the text in question.</p><p>The basic methdology for PPM is as follows:</p><p>1. Assume: a context structure already containing previously seen symbols in the stream 2. Read a symbol s from the stream 3. Query the context structure as to whether an n-order chain exists containing n -1 previously seen symbols along with s 4. If an n-order chain does not exist... (a) Query the n -1-order chain with n -2 previously seen symbols along with s (b) Repeat for progressively smaller chains until an order -1 chain is reached 5. Increment the symbol counter in the context structure for n, n -1, ... -1 order chains. If the symbol does not exist, initialize it in all context-matching chains that</p><p>do not yet contain the symbol s.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Repeat for each successive symbol s</head><p>We wrote our own version of PPM in C using a hard-coded symbol context-size of 5. Code for this is available on Github<ref type="foot" coords="2,286.51,634.96,3.49,6.05" target="#foot_0">1</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Cross-entropy calculation</head><p>We used Bobicev's cross-entropy calculation method for comparing entropies generated by the PPM model <ref type="bibr" coords="3,205.99,158.11,13.01,8.64" target="#b0">[1]</ref>. A rundown of the algorithm is as follows:</p><p>-Concatenate all known-author texts into a text K. Let the unknown-author text be known as text U . -Split K into k fixed n-size text chunks, and split U into u fixed n-size text chunks.</p><p>-Generate same-entropies -Compare the same-entropies with the cross-entropies using a pairwise t-test with a null hypothesis that the values are equivalent. If the null hypothesis is accepted, then we can consider that K and U are written by the same author.</p><p>Determining the appropriate values for n and the p-value for pairwise t-test required some initial experimentation. We settled on a n value of 300 (i.e. a word chunk size of 300), for most languages, with the exception of Spanish, which had a n value of 100. We also used a standard p-value of 0.05 for most languages, with the exception of Spanish, which used a p-value of 0.01.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Initial testing</head><p>We briefly experimented with varying the cross-entropy chunk sizes, in order to determine how the value of 350 words was determined in <ref type="bibr" coords="3,344.00,632.53,10.58,8.64" target="#b0">[1]</ref>, while simultaneously comparing t-test thresholds across languages. A graph showing the results on the training texts is denoted by Figure <ref type="figure" coords="3,218.89,656.44,3.74,8.64" target="#fig_0">1</ref>.  We present a variant on a compression-based attribution scheme (PPM) by making the model train on parts of speech of the text, versus individual characters of the text. In this manner we can capture the style using a statistical model based on the ordering of the type of words, in contrast to the actual words being used. We found that this approach performed particularly poor for Dutch Reviews, but surprisingly well for Spanish Articles and Dutch Essays. For English Essays, performance was almost baseline, and for English Novels performance was inconsistent. We did not evaluate any Greek-language approaches in this evaluation lab.</p><p>We have a number of take-aways from this evaluation lab with regards to attributed performance and possible improvements for future work:</p><p>-It appears that an adequate choice of word chunk size is critical to the performance of this method. By reducing the chunk size for Spanish Articles to 100, we saw an improvement of 20%, that was consistent over the training and test results. Initial analysis of varying chunk size for the other languages did not show noticeable improvements, hence we simply used the size of 350 as mentioned in <ref type="bibr" coords="5,429.32,272.52,10.58,8.64" target="#b0">[1]</ref>. It is possible that more granular tuning might produce different results, as we only looked at intervals of 50 words. -We simply used a fixed context-size of 5 for the PPM model, and did not vary this value. Not much prior work exists in experimenting with this value in authorship verification in general, so it would be interesting to see further analysis in this area. -We only tried using a single parts of speech tagger (TreeTagger) due to the fact it had support for 3 of the languages in question in this evaluation lab. Future work would include evaluating the results of other parts of speech taggers such as the Stanford Log-linear Part-of-Speech Tagger, or the Brill Tagger. As correct tagging is imperative for our approach to work correctly, it is possible that we could see improvements in both English Essay and English Novel authorship verification if alternate English taggers are used. -There is a clear contrast in performance between the Dutch Reviews and the Dutch Essays corpora. It is very interesting that there is a clear stylistic difference between these two corpora that this method managed to capture in such a way that the essays were more easily reidentifiable over the reviews. We posit that this is due to the fact that the essays are likely to be more clearly structured with a strong style, such that this is more readily capturable by our technique.</p><p>In general, it appears that this technique on its own does not perform exemplary in answering the binary-answer question posed by this evaluation lab: did a particular author A write a work W ? It is possible that this technique may serve to augment an existing verification method by perhaps providing information regarding the ordering of type of words, versus the word usage itself. We hope to improve upon this method by coupling it with existing verification techniques that capture actual word usage.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,195.10,381.54,225.14,8.12"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Initial results with varying cross-entropy chunk sizes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,141.74,237.99,264.63,181.47"><head>•</head><label></label><figDesc>For each k: * Generate a PPM statistical model on (K -k) * Run the model on k and calculate the resulting entropy. • For each u:</figDesc><table /><note coords="3,177.27,294.10,189.58,8.96;3,175.61,306.06,230.75,8.96;3,141.74,323.48,108.73,9.03;3,158.68,339.65,164.53,8.96;3,158.68,352.99,55.15,8.96;3,175.61,367.71,230.55,8.96;3,158.68,382.43,166.19,8.96;3,158.68,395.77,55.36,8.96;3,175.61,410.49,230.75,8.96"><p>* Generate a PPM statistical model on (U -u) * Run the model on u and calculate the resulting entropy. -Generate cross-entropies • Generate a PPM statistical model on U • For each k: * Run the model on k and calculate the resulting entropy. • Generate a PPM statistical model on K • For each u: * Run the model on u and calculate the resulting entropy.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,226.16,400.06,163.04,84.29"><head>Table 1 .</head><label>1</label><figDesc>Training results</figDesc><table coords="4,226.16,421.38,163.04,62.97"><row><cell>Corpus</cell><cell>AUC</cell><cell cols="2">C@1 Combined</cell></row><row><cell cols="4">Dutch Essays 0.64497 0.61046 0.39373</cell></row><row><cell cols="3">Dutch Reviews 0.4391 0.5</cell><cell>0.2197</cell></row><row><cell cols="3">English Essays 0.585 0.53</cell><cell>0.31005</cell></row><row><cell cols="3">English Novels 0.6728 0.71</cell><cell>0.47769</cell></row><row><cell cols="3">Spanish Articles 0.7858 0.65</cell><cell>0.51077</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,134.77,506.46,254.43,126.20"><head>Table 2 .</head><label>2</label><figDesc>Test results</figDesc><table coords="4,134.77,525.94,254.43,106.72"><row><cell>Corpus</cell><cell>AUC</cell><cell cols="2">C@1 Combined</cell></row><row><cell cols="4">Dutch Essays 0.6441 0.61458 0.39585</cell></row><row><cell cols="3">Dutch Reviews 0.354 0.48</cell><cell>0.16992</cell></row><row><cell cols="3">English Essays 0.57855 0.54</cell><cell>0.31242</cell></row><row><cell cols="4">English Novels 0.5398 0.525 0.2834</cell></row><row><cell cols="2">Spanish Articles 0.79</cell><cell>0.65</cell><cell>0.5135</cell></row><row><cell cols="2">4 Discussion and Future Work</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,657.93,204.42,6.31"><p>https://github.com/worldwise001/ppm-c/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,142.61,624.25,192.16,7.77" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="5,196.81,624.25,111.82,7.77">Authorship detection with ppm</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Bobicev</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,142.61,635.17,326.32,7.77;5,150.95,646.13,311.15,7.77;5,150.95,657.09,225.50,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,358.20,635.17,106.63,7.77">Clef 2014 labs and workshops</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Halvey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,226.65,646.13,235.45,7.77;5,150.95,657.09,162.69,7.77">CEUR Workshop Proceedings (CEUR-WS.org). 5th International Conference of the CLEF Initiative (CLEF 14)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
	<note>notebook papers</note>
</biblStruct>

<biblStruct coords="6,142.61,119.96,331.25,7.77;6,150.95,130.92,320.66,7.77;6,150.95,141.88,329.02,7.77;6,150.95,152.84,181.94,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,163.91,130.92,304.27,7.77">Information access evaluation meets multilinguality, multimodality, and visualization</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Busse</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,163.16,141.88,316.81,7.77;6,150.95,152.84,119.12,7.77">Recent Trends in Digital Text Forensics and its Evaluation. 4th International Conference of the CLEF Initiative (CLEF 13)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.61,163.80,330.74,7.77;6,150.95,174.76,243.49,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,241.36,163.80,191.59,7.77">Overview of the author identification task at pan 2013</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,451.43,163.80,21.92,7.77;6,150.95,174.76,217.34,7.77">CLEF 2013 Evaluation Labs and Workshop-Working Notes Papers</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.61,185.72,336.08,7.77;6,150.95,196.67,320.36,7.77;6,150.95,207.63,316.68,7.77;6,150.95,218.59,285.41,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,258.84,185.72,219.86,7.77;6,150.95,196.67,92.81,7.77">A repetition based measure for verification of text collections and for text categorization</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">V</forename><surname>Khmelev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Teahan</surname></persName>
		</author>
		<idno type="DOI">10.1145/860435.860456</idno>
		<ptr target="http://doi.acm.org/10.1145/860435.860456" />
	</analytic>
	<monogr>
		<title level="m" coord="6,261.74,196.67,209.57,7.77;6,150.95,207.63,238.25,7.77;6,444.22,207.63,23.41,7.77;6,150.95,218.59,10.64,7.77">Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Informaion Retrieval</title>
		<meeting>the 26th Annual International ACM SIGIR Conference on Research and Development in Informaion Retrieval<address><addrLine>Toronto, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="104" to="110" />
		</imprint>
	</monogr>
	<note>SIGIR &apos;03</note>
</biblStruct>

<biblStruct coords="6,142.61,229.55,325.35,7.77;6,150.95,240.51,267.20,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,196.28,229.55,200.50,7.77">Probabilistic part-of-speech tagging using decision trees</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,414.42,229.55,53.54,7.77;6,150.95,240.51,241.06,7.77">Proceedings of International Conference on New Methods in Language Processing</title>
		<meeting>International Conference on New Methods in Language Processing</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.61,251.47,321.34,7.77;6,150.95,262.43,185.25,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,196.28,251.47,251.31,7.77">Improvements in part-of-speech tagging with an application to german</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,150.95,262.43,159.10,7.77">Proceedings of the ACL SIGDAT-Workshop</title>
		<meeting>the ACL SIGDAT-Workshop</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.61,273.39,302.25,7.77;6,150.95,284.35,295.20,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,207.24,273.39,182.00,7.77">A survey of modern authorship attribution methods</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,395.56,273.39,49.30,7.77;6,150.95,284.35,211.53,7.77">Journal of the American Society for information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="538" to="556" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.61,295.30,290.26,7.77;6,150.95,306.26,316.91,7.77;6,150.95,317.22,23.90,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,249.48,295.30,183.39,7.77;6,150.95,306.26,49.37,7.77">Using compression-based language models for text categorization</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Teahan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">J</forename><surname>Harper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,218.30,306.26,163.67,7.77">Language Modeling for Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="141" to="165" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.24,328.18,338.34,7.77;6,150.95,339.14,70.97,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="6,201.47,328.18,237.46,7.77">Text classification and segmentation using minimum cross-entropy</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">J</forename><surname>Teahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,456.91,328.18,23.66,7.77">RIAO</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="943" to="961" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
