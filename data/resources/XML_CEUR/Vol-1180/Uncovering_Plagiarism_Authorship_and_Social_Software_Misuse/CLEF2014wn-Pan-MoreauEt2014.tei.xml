<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,170.16,115.90,275.04,12.90;1,189.81,133.83,235.73,12.90;1,223.43,153.79,168.49,10.75">Author Verification: Exploring a Large set of Parameters using a Genetic Algorithm Notebook for PAN at CLEF 2014</title>
				<funder>
					<orgName type="full">Centre for Global Intelligent Content</orgName>
				</funder>
				<funder ref="#_28RmRze">
					<orgName type="full">Science Foundation Ireland</orgName>
				</funder>
				<funder>
					<orgName type="full">Trinity College, University of Dublin</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,210.09,190.30,59.38,8.64"><forename type="first">Erwan</forename><surname>Moreau</surname></persName>
							<email>moreaue@cs.tcd.ie</email>
							<affiliation key="aff0">
								<orgName type="laboratory">CNGL and Computational Linguistics Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,278.92,190.30,52.84,8.64"><forename type="first">Arun</forename><surname>Jayapal</surname></persName>
							<email>jayapala@cs.tcd.ie</email>
							<affiliation key="aff0">
								<orgName type="laboratory">CNGL and Computational Linguistics Group</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,358.09,190.30,42.71,8.64"><forename type="first">Carl</forename><surname>Vogel</surname></persName>
							<email>vogel@cs.tcd.ie</email>
							<affiliation key="aff1">
								<orgName type="laboratory">Computational Linguistics Group</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Centre for Computing and Language Studies School of Computer Science</orgName>
								<orgName type="institution">Statistics Trinity College Dublin</orgName>
								<address>
									<settlement>Dublin</settlement>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,170.16,115.90,275.04,12.90;1,189.81,133.83,235.73,12.90;1,223.43,153.79,168.49,10.75">Author Verification: Exploring a Large set of Parameters using a Genetic Algorithm Notebook for PAN at CLEF 2014</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A729BBE6239AB895EEC2AA6665A8DCE1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we present the system we submitted to the PAN'14 competition for the author verification task. We consider the task as a supervised classification problem, where each case in a dataset is an instance. Our system works by applying the same combination of parameters to every case in a dataset. Thus, the training stage consists in finding an optimal combination of parameters which maximizes the performance on the training data using cross-validation. This is achieved using a simple genetic algorithm, since the space of all possible combinations is impractical.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this author verification task, a training set containing 6 datasets was provided; each dataset consists of a set of problems (between 96 and 200) which belong to the same language and genre; each problem consists of a small set (between 1 and 5) of "known" documents written by a single person and a "questioned" document: the task is to determine whether the questioned document was written by the same person. More precisely, the system must provide its prediction as a value in the interval [0, 1], which represents the probability that the answer is positive (same author). The intended interpretation is for 0 to mean "different author" with maximum certainty, and for 1 to mean "same author" with maximum certainty, and any intermediate value describes the likeliness of a positive answer, and with 0.5 equivalent to the system saying "I don't know". The predictions are evaluated using the product of the area under the ROC curve (AUC) and the modified accuracy measure c@1 [6], which treats 0.5 answers as a particular case.</p><p>We consider the task as a supervised learning problem, where, for each dataset, the goal is to find a function which, when applied to a set of unseen problems in this dataset, maximizes the performance (product of AUC and C@1). This function must be generic enough to capture the stylistic characteristics of every author. It is meant to represent how to capture any author's style within a particular dataset, that is, in the context of a particular language and genre. For example, the type of observations (e.g., word bigrams) to take into account depends on the language, but whether a particular observation (e.g., the bigram "it is") is relevant or not is specific to a given author.</p><p>We define the space of all possible functions in the following way: each function is defined by a set of parameters, each parameter being assigned a particular value among a predefined set of possible values. The process of selecting features from the texts, combining them in any predefined way, and learning how to interpret the differences between the known documents and the questioned document is entirely driven by the values taken by these parameters. For example, a parameter indicates which distance metric should be used to compare the unknown document to the set of known documents. We call a particular combination of parameters a configuration. We define the two following strategies which share only a subset of common parameters:</p><p>-The fine-grained strategy, described in ยง3, in which there are many possible parameters, is intended to try as many configurations (or functions) as possible, in order to maximize the performance. -The robust strategy, described in ยง4, is a more simple method which uses only a small subset of parameters. It is intended to be safer (in particular less prone to overfitting), but probably not to perform as well as the fined-grained strategy.</p><p>For the fine-grained strategy, the space of all possible configurations is too big to be explored exhaustively. This is why we implement a simple genetic algorithm, which is supposed to converge to a (possibly local) optimal configuration. This algorithm is described in ยง3.4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">General architecture</head><p>For every problem to solve, we extract observations<ref type="foot" coords="2,343.64,442.52,3.49,6.05" target="#foot_0">3</ref> from the set of known texts, and try to measure the four following abstract characteristics:</p><p>their consistency, i.e. how consistently these observations apply among the known documents written by the author; their divergence (from a reference corpus), i.e. how much the frequency of these observations differs from the reference corpus (see ยง3.2); the confidence of the system in the reliability of these observations; the distance between the known documents and the questioned document with respect to these observations.</p><p>We consider multiple ways to compute and use these four characteristic values. In particular, the configuration file defines:</p><p>the types of observations to take into account; the method to compute every characteristic at the observation level; the method to extract the most relevant subset of observations;</p><p>the method to obtain a global value for each of the four characteristics; which subset of these values will be used as features in the machine learning stage.</p><p>The final step consists in training (or applying) a ML model based on these features. There can actually be two models: the first and most important one predicts the scores for each case in the dataset; the second optional one is meant to detect the ambiguous cases, so that they can be assigned 0.5 instead of their predicted score, in order to maximize the c@1 score.</p><p>In the robust strategy the parameters are restricted to a small set of possible configurations, whereas with the fine-grained strategy, on the contrary, we explore a vast space of parameters (about 10 19 possible combinations in the predefined space that we use). This is why the learning stage for the latter consists in learning an optimal configuration using a genetic algorithm.</p><p>3 The fine-grained strategy</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Observations and frequency statistics</head><p>We consider a large set of observations types, among which the configuration can use any subset. These are typically various kinds of n-grams, but not only:</p><p>words (actually tokens) unigrams to trigrams; -Characters trigrams to pentagrams.</p><p>-Part-Of-Speech (POS) tags unigrams to tetragrams; -Combinations of POS tags and tokens, including skip-grams, e.g.:</p><p>"&lt;POS tag&gt; &lt;token&gt; &lt;POS tag&gt;" or "&lt;token&gt; _ &lt;POS tag&gt;"; -"stop words" n-grams, i.e. tokens n-grams considering only a predefined list of the the most frequent tokens in the language,<ref type="foot" coords="3,315.69,440.36,3.49,6.05" target="#foot_1">4</ref> from trigrams to pentagrams; -Token length classes, where the tokens are classified depending on their length into 6 categories: lower than 2, 3 to 4, 5 to 6, 6 to 8, 8 to 10, more than 10. -Token-Type Ratio (number of distinct tokens divided by total number of words).</p><p>The POS tags are computed using TreeTagger<ref type="foot" coords="3,330.78,498.13,3.49,6.05" target="#foot_2">5</ref>  [8]. The lists of most frequent words in the language are computed from the complete set of documents in the training data: we consider the 200 most frequent words, except for Dutch (100 most frequent words).</p><p>A few thresholds are applied when extracting these observations, in order to remove some noise in the data and/or improve efficiency:</p><p>-Minimum absolute frequency in a document (possible values: 2, 3, 5); -Minimum proportion of documents among the reference corpus which contain the observation (possible values: 10%, 25%, 50%); -Minmimum proportion of known documents containing the observation (only for known documents) (possible values: 30%, 51%);</p><p>The frequency of all the observations which fulfill these conditions relativized to the total possible number of such observations lpq is stored for very observation type specified in the configuration. For every observation, various statistics are computed based on the set of frequencies extracted from the known documents: mean, standard deviation, median, etc. Practically, in the training stage, the observations and the statistics are computed only once and then stored, so that the data can be used as many times as necessary with different combinations of parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Features</head><p>The consistency, divergence, confidence and distance values are based on the frequency statistics extracted during the first step. At first they are computed for every distinct observation. Then they can be "synthetized" in different ways according to the configuration; the final features can be either specific to each observation type or global.</p><p>Consistency The consistency value is meant to represent how constant the use of a particular observation is, so that it can be assessed whether the observation is used in a similar way in the unknown document. For example, the standard deviation of the (relative) frequency of the observation among the known documents is a valid indicator (the lower it is, the higher the consistency is). Other statistics are available, e.g. range between minimum and maximum, ratio between first and third quartile, etc. However these statistics are more reliable with a high number of known documents, and require at the very least two distinct documents.</p><p>The goal of the consistency measure is to distinguish as far as possible between the observations which are specific to the author and those which are only specific to the document (for example the subject of an essay). This is why the more known documents there are the most accurate the consistency is. Consequently, cases which contain only one known document are irrelevant for consistency. <ref type="bibr" coords="4,339.89,452.90,3.49,6.05" target="#b5">6</ref> Divergence The divergence measure is meant to represent to what extent a particular observation is specific to an author. This value is calculated against a reference corpus, which should ideally be an independent set of documents in the same language and genre as the dataset. But since we do not have access to such a corpus for every dataset, we simply consider the whole set of documents (known and unknown) in the training set as the reference corpus. Because it is meant only to measure divergence, the only important assumption that we make is that it contains documents written by a sufficient number of different authors, and that it is not massively imbalanced (for instance if most of the documents were by the same author). <ref type="bibr" coords="4,309.07,579.83,3.49,6.05" target="#b6">7</ref> The system can use different methods to measure the divergence of an observation: several simple statistics like the absolute difference between the frequency means (or medians), but also more complex measures which try to estimate the difference between the two distribution (known documents and documents in the reference corpus). Some of these measures assume a normal distribution of the observation frequency accross the documents: <ref type="bibr" coords="5,180.70,177.42,3.49,6.05" target="#b7">8</ref> we use several measures based on the Bhattacharrya distance [1]. These measures are also more reliable when the number of distinct documents is high.</p><p>Confidence The confidence measure is intended to find the most discriminative observations, based on their consistency and divergence values. Thus, it simply combines these two values in order to rank the observations by their discriminative power for the given author: for instance, an observation which is very consistent but not distinctive (or the opposite) might be less interesting than another one which is less consistent but has a better divergence value.</p><p>We consider various ways to combine the two numerical values: product, mean, geometric mean, weighted product, etc. There is also an option to ignore the consistency score (i.e. use the divergence as confidence), and another one for ranking the two values, so that the rank is used instead of the actual score.</p><p>Distance Finally the distance measure is meant to capture how different the unknown document is from the set of known documents. The distance value is usually not meaningful at the level of the observation, but becomes meaningful only once computed on a selected set of observations.</p><p>Various standard similarity or distance measures can be used, like the cosine or Jaccard similarity, but also some more specific measures, like the probability that the observed frequency in the unknown document belongs to the distribution observed in the known documents (assuming this is a normal distribution). The distance can be weighted in different ways with a coefficient based on the confidence score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Scoring stage</head><p>The configuration defines what kind and how many features will be used, as well as how to obtain them. Multiple possibilities have been implemented, including:</p><p>-There can be a set of features for each observations type, or all observations types can be combined in a generic set of features; -The maximum number of observations to consider for the distance feature(s); -Whether consistency, divergence and confidence scores should be included in the features.</p><p>with several authors: the relative ordering of the observations according to their specificity to an author should not be impacted. <ref type="bibr" coords="5,139.00,655.22,2.99,5.18" target="#b7">8</ref> We had observed in [5] that this assumption holds in most cases for frequent n-grams.</p><p>A regression model is trained/applied to the features which have been computed for all the input cases (instances for the model). <ref type="bibr" coords="6,325.16,129.60,3.49,6.05">9</ref> We use the Weka [3] (version 3.6.10) implementation of SVM regression [4] (with polynomial or RBF kernel), and decision trees regression [7], with variants depending on their parameters.</p><p>Optionally, a second model can be generated/applied in order to evaluate the confidence in each answer, and possibly replace it with 0.5 (unanswered case). This classification "confidence model" can use any of the available features, as well as the score computed with the first regression model. <ref type="bibr" coords="6,300.09,201.33,6.97,6.05">10</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Genetic learning</head><p>The complete "author verification model" which is returned at the end of the training stage consists of the scoring model (that is, the regression model and optionally the confidence model), but also the configuration which was found to be optimal on the training set by cross-validation. This is achieved using the generic genetic algorithm described next.</p><p>The individuals in a population are the configurations, in which every parameter is assigned a particular value among a predefined set (the "genotype"). Starting from a random population, the algorithm iterates through each generation by selecting a proportion of the population to "breed" the next generation.</p><p>The method for making a configuration which performs better more likely to get selected is as follows: all the configurations in the population are ranked from 1 to N by their performance in ascending order. The probability of an individual being selected is defined as r/N รpร2, where r is its rank and p is the proportion to retain as breeders. For example, if the population N = 200 and p = 10% (that is, 20 breeders are selected at each stage), the probability for the best performing configuration (with relative rank N/N = 1) to be selected is 1 ร 10% ร 2 = 20%, and the probability for the worst performing configuration (with relative rank 1/200 = 0.05) is 0.01. Since the average relative rank r/N is 0.5 by definition, the method selects, on average, N ร0.5รpร2 = N ร p breeders, as expected (consequently p must not be higher than 0.5).</p><p>Every new individual is generated based on two "parents" picked randomly among the breeders; every of its parameter is defined as one of its parents value (each having a 0.5 probability to be picked), but can be "mutated" with a (small) predefined probability. We also use two variants: one consists in reusing a few of the previous best individuals in each new generation (elitism), and the other in including a small proportion of totally random individuals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The robust strategy</head><p>In the robust strategy, consistency and divergence features were used to verify whether the document X has been authored by the author of the given documents Y = {y 1 , y 2 , ...y n }, but in a slightly different way as above: the consistency defines how well the words or n-grams or character-grams were used consistently used across all the documents Y and X. Whereas, divergence defines how well document X is distinct from documents Y and viceversa. The intuition behind using this feature is that these features could provide an insight into how the document X and documents Y co-vary linguistically.</p><p>Divergence Motivated from the Jaccard similarity, we use a slight variant to compute the divergence of documents Y to document X (J 1 ) and of document X to documents Y (J 2 ):</p><p>(1)</p><formula xml:id="formula_0" coords="7,204.63,238.86,229.28,22.31">J 1 = (p + q) (p + q + r) J 2 = (p + r) (p + q + r)</formula><p>where p is the number of words found in both X and Y documents, q is the number of words found in Y but not in X and r is the number of words found in X but not in Y documents. J 1 will provide a measure on how distinct Y is from X, whereas J 2 will provide a measure on how distinct X is from Y .</p><p>The above provided are the document level metrics, which are used to compute the word-level divergence for X and Y . One assumption considered here for word-level metric; to compute divergence of word x i in X to Y , when the word w i is identified in Y , we assign a boolean value 0 assuming no divergence and when w i is not identified in Y , we assign 1 to a temporary variable F assuming complete divergence of word w i . With, F , J 1 , J 2 and relative frequency values (rf 1 i and rf 2 i ) for each word, we compute the divergence for words in X to Y (d i,J1 ) and Y to X (d i,J2 ) as:</p><p>(2)</p><formula xml:id="formula_1" coords="7,198.68,412.86,241.86,12.69">d i,J1 = F * J 1 * rf 1 i d i,J2 = F * J 2 * rf 2 i</formula><p>Consistency Consistency is defined as the difference between the relative frequencies:</p><p>(3)</p><formula xml:id="formula_2" coords="7,203.74,464.67,231.75,12.69">c i,J1 = rf 1 i -rf 2 i c i,J2 = rf 2 i -rf 1 i</formula><p>These measures are based only on the characters tetragrams' frequencies (the other observations types are not taken into account). In order to train or apply the model, the scoring stage defined in the fine-grained strategy is used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Observations and results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Genetic learning process</head><p>Since the system was being implemented specifically for the task and we had to deal with the time constraints for the competition, the process of tuning the genetic learning parameters was not carried out in optimal conditions. In particular, we could not afford to run many different cases, especially cases which require a long time; moreover, bugs were fixed and features were added along the process. This is why we are not able to provide here a very detailed analysis of the impact of the parameters on the evolution of the performance. Yet we did several preliminary tests in order to determine a couple q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q 0.2 Average performance for various combinations of genetic parameters (preliminary test stage). GeneticParams contains the following parameters: population, breeders proportion; mutation probability; elitism proportion; random proportion. Example: on the longest curve (in green with square symbols), it can be observed that the average performance at the 20th generation was close to 0.6. 12 of optimal combinations of genetic learning parameters. Figure <ref type="figure" coords="8,392.70,405.78,4.98,8.64" target="#fig_0">1</ref> shows the results of one of these.</p><p>In general, the system was able to converge relatively quickly (a few tens of generations at most) to a high level of performance with most tested combinations of parameters. In particular, the size of the population did not have a major impact on the convergence (even though a larger population makes the evolution smoother). This is why we opted for using a small population size, in order to minimize the time required for the system to find optimal configurations. Figure <ref type="figure" coords="8,345.19,490.14,4.98,8.64">2</ref> shows how the two selected sets of parameters performed during the main learning stage. <ref type="bibr" coords="8,358.12,500.42,6.97,6.05">13</ref> In total, between 13,400 and 26,700 configurations (in a space of 10 19 possibilities) by dataset were evaluated in <ref type="bibr" coords="8,136.01,534.48,5.98,5.18">12</ref> Moreover, the legend shows that this value is the average over a population of 30 configurations obtained after 19 iterations, where, at each stage: 20% of the previous configurations are selected as breeders (i.e., 6 configurations); the probability of a mutation (of an individual parameter) is 0.02; 10% (i.e., 3 configurations) of the new generation is made of the 10% best previous configurations ("cloned" directly without any alteration); 5% (i.e., 1 or 2 configurations) are totally random configurations. <ref type="bibr" coords="8,136.01,600.43,5.98,5.18">13</ref> A recent server (24 Intel Xeon 3GHz cores) was used for the computation, but with only one core for each pair dataset/genetic configuration. It is difficult to evaluate exactly the total time spent due to various technical interruptions. Computing a single generation took in average between 20 and 48 minutes (depending mostly on the size of the dataset) for the "fast" configuration (30 individuals) and between 50 and 117 minutes for the "slow" configuration (75 individuals).</p><p>the genetic learning process. Each configuration was evaluated using only 3 fold crossvalidation during the main genetic process; after this stage, a subset of the best configurations found was evaluated again using 10 fold and then 20 fold cross-validation.</p><p>q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q q 0.2 </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Observations</head><p>Below we present some characteristics observed in the configurations which were selected by the genetic learning process (in the case of the fine-grained strategy):</p><p>Observation types In most cases only a few observations types are selected (from 3 to 11). Several POS n-grams (as well as POS/tokens combinations) are selected in the five cases where they are available; words n-grams are also selected in most cases, but characters n-grams never are. The word length and the type/token ratio are used in half of the cases. At least one knid of stop words n-grams is selected in 4 datasets.</p><p>Consistency, divergence, confidence and distance methods The Bhattacharrya coefficient is used the main criterion for divergence in most cases, and in particular in all datasets where the median number of known documents is higher than 1. The consistency value is actually not used at all in most cases (4): the system choses to use only divergence as confidence to select the relevant observations. The most simple distance metrics are selected in general (mean of the difference, euclidean or cosine distance), but half of the time the frequency is weighted with the confidence score. The number of observations taken into account seems to depend mostly on the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Learning stage</head><p>The decision tree regression (M5P) is selected most of the time for the scoring model. The confidence model stage is selected in only one case; this must be because, in general, the errors made by this classification model are more costly in performance than the benefit of assigning 0.5 scores.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Earlybird test set and final model selection</head><p>Thanks to the Tira system [2], we were able to evaluate both strategies on the "earlybird corpus". Figure <ref type="figure" coords="10,219.12,245.11,4.98,8.64" target="#fig_1">3</ref> shows the performance of the two strategies on the training set (by cross-validation) and the earlybird test set; the results obtained on the training set by cross-validation were always better with the fine-grained strategy, but in two cases they were better with the robust strategy on the earlybird test set. This is of course an expected consequence of how the two strategies were defined: the robust strategy is usually not as good as the fine-grained one, but is less data-independent; conversely the fine-grained strategy is more prone to overfitting. But, more interestingly, we noticed that, with the fine-grained strategy, the performance drops much more (between the training set and the earlybird test set) when the dataset has only a small number of known documents by case in average, especially on the datasets in which most cases contain only one known document. In table 1 we report the performance and compute the drop in performance in all cases, and for each dataset the difference between this value and the average value; based on this difference, we can observe that the drop in performance correlates quite strongly with the (low) number of known documents by case for the fine-grained strategy, whereas it does not at all for the robust strategy.</p><p>As a consequence, we decided to use both strategies in our official submission: for the three datasets where there is only one known document (Dutch essays and reviews and English novels), the model corresponding to the robust strategy is used instead of the fine-grained model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Results</head><p>Table <ref type="table" coords="10,159.00,528.66,4.98,8.64">2</ref> shows the performance obtained on each dataset by both strategies on the training set, the earlybird test set and the final test set, as well as our official ranking. <ref type="bibr" coords="10,461.81,538.94,6.97,6.05">14</ref> In particular, it shows that our decision to use the robust approach in three cases was good: it performed better than any of the two original strategies taken independently. However our hypothesis that this was linked with the low number of known documents might not hold, since our results on the English novels are quite low compared to the other participants' results, and this would not have happened with the fine-grained strategy. Overall, our system was among the best in this task, ranking third among 13 in average performance. Table <ref type="table" coords="11,158.05,401.52,3.36,8.06">1</ref>. Comparison of the performance on the training set and the earlybird corpus, and impact of the number of known documents by case depending on the strategy. The penultimate column is the difference in performance between the two datasets, and the last column is the difference between the aforementioned value and the average value for the same strategy. Finally the Spearman correlation is calculated between the value in the last column and the mean number of known documents.</p><p>Table <ref type="table" coords="12,158.78,115.83,3.36,8.06">2</ref>. Results on all datasets with both strategies. The "mixed" column for the final test set corresponds to our official submission. Remark: there were 13 participants in this task. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="8,134.77,328.18,345.81,8.12;8,134.77,339.33,345.82,7.94;8,134.77,350.45,345.81,7.77;8,134.77,361.41,345.81,7.77;8,134.77,372.37,43.33,7.77;8,178.10,370.51,5.98,5.18"><head>Figure 1 .</head><label>1</label><figDesc>Figure1. Average performance for various combinations of genetic parameters (preliminary test stage). GeneticParams contains the following parameters: population, breeders proportion; mutation probability; elitism proportion; random proportion. Example: on the longest curve (in green with square symbols), it can be observed that the average performance at the 20th generation was close to 0.6.12    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="11,134.77,325.02,345.81,8.12;11,134.77,336.32,345.81,7.77;11,134.77,347.28,26.92,7.77"><head>Figure 3 .</head><label>3</label><figDesc>Figure3. Performance of the fine-grained and robust strategies on the training set and the earlybird test set (the datasets are identified by their initials, their full name can be found in table 1 below).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="12,145.51,148.11,324.34,96.24"><head></head><label></label><figDesc>Training set CV Earlybird test set Final test set robust fine-grained robust fine-grained mixed robust fine-grained mixed rank Dutch essays 0.802 0.817 0.777 0.501 0.777 0.755 0.563 0.777 4 Dutch reviews 0.389 0.608 0.338 0.253 0.338 0.375 0.350 0.375 3 English essays 0.292 0.493 0.265 0.446 0.446 0.325 0.372 0.372 3 English novels 0.722 0.860 0.324 0.370 0.324 0.313 0.352 0.313 8 Greek articles 0.359 0.595 0.246 0.541 0.541 0.436 0.565 0.565 Spanish articles 0.622 0.863 0.468 0.657 0.657 0.335 0.634 0.634 2 Average 0.531 0.706 0.403 0.461 0.514 0.423 0.473 0.502 3</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="2,144.73,646.13,335.85,7.77;2,144.73,657.09,73.95,7.77"><p>We use the term "observation" here to avoid any confusion with the features used in the machine learning stage.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="3,144.73,634.98,266.41,7.77"><p>Other tokens are replaced with a special symbol, e.g. "the _ _ is _".</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_2" coords="3,144.73,646.13,335.85,7.77;3,144.73,657.09,51.29,7.77"><p>http://www.cis.uni-muenchen.de/ schmid/tools/TreeTagger. POS tags are not used for the Greek dataset.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_3" coords="4,144.73,602.26,335.85,7.77;4,144.73,613.22,328.48,7.77"><p>It is possible then to use different parts of the document, but this is not reliable in general since the distinction between document specific and author specific observations cannot be made.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_4" coords="4,144.73,624.21,335.85,7.77;4,144.73,635.17,335.85,7.77;4,144.73,646.13,335.85,7.77;4,144.73,657.09,335.85,7.77"><p>Although it is quite unlikely given the size of the training sets, we do not have any guarantee that the second condition is satisfied in all the datasets provided. Assuming these conditions are fulfilled, the fact that the reference corpus contains documents by the author of the problem studied is not an issue, because it is frequent that a particular stylistic feature can be observed</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_5" coords="6,144.73,613.06,335.85,7.77;6,144.73,623.73,228.25,8.06"><p>When training the model, the Y/N answers are converted to 1/0, so that the predictions of the system are values in [0, 1], which is the expected output format.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_6" coords="6,144.73,635.17,335.85,7.77;6,144.73,646.13,335.85,7.77;6,144.73,657.09,263.76,7.77"><p>In the learning stage, the model which was trained is applied to the instances. Depending on the configuration, the instances can be split up so that the second model is based on unseen instances (but then less instances are used to train each model, of course).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14" xml:id="foot_7" coords="10,144.73,646.13,335.85,7.77;10,144.73,657.09,110.57,7.77"><p>The results provided at the time of writing have not been made official yet, therefore changes can still happen in the ranking.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We are grateful to the reviewers for their valuable feedback, and to the organizers of the task for their hard work and their availability.</p><p>This research is supported by the <rs type="funder">Science Foundation Ireland</rs> (Grant <rs type="grantNumber">12/CE/I2267</rs>) as part of the <rs type="funder">Centre for Global Intelligent Content</rs> (www.cngl.ie) funding at <rs type="funder">Trinity College, University of Dublin</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_28RmRze">
					<idno type="grant-number">12/CE/I2267</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="12,138.13,399.43,334.67,7.77;12,146.47,410.38,296.69,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,216.19,399.43,256.62,7.77;12,146.47,410.38,115.03,7.77">On a measure of divergence between two statistical populations defined by their probability distributions</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bhattacharyya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,267.09,410.38,96.89,7.77">Bulletin of Cal. Math. Soc</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="99" to="109" />
			<date type="published" when="1943">1943</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.13,421.34,331.25,7.77;12,146.47,432.30,306.38,7.77;12,146.47,443.26,330.54,7.77;12,146.47,454.22,334.11,7.77;12,146.47,465.18,114.05,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,159.43,432.30,197.32,7.77">Recent trends in digital text forensics and its evaluation</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Busse</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,284.31,443.26,192.70,7.77;12,146.47,454.22,334.11,7.77;12,146.47,465.18,10.64,7.77">Information Access Evaluation meets Multilinguality, Multimodality, and Visualization. 4th International Conference of the CLEF Initiative (CLEF 13)</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Mรผller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Paredes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Rosso</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Stein</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013-09">September 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.13,476.14,327.53,7.77;12,146.47,487.10,322.06,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,413.37,476.14,52.28,7.77;12,146.47,487.10,96.28,7.77">The weka data mining software: an update</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Reutemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,248.73,487.10,145.10,7.77">ACM SIGKDD Explorations Newsletter</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="18" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.13,498.06,328.28,7.77;12,146.47,509.01,313.78,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,381.50,498.06,84.91,7.77;12,146.47,509.01,149.25,7.77">Improvements to platt&apos;s SMO algorithm for SVM classifier design</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">S</forename><surname>Keerthi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">K</forename><surname>Shevade</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bhattacharyya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">R K</forename><surname>Murthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,301.63,509.01,57.78,7.77">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="637" to="649" />
			<date type="published" when="2001-03">Mar 2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.13,519.97,339.11,7.77;12,146.47,530.93,333.58,7.77;12,146.47,541.89,181.03,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,229.23,519.97,248.01,7.77;12,146.47,530.93,49.98,7.77">Style-based Distance Features for Author Verification -Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Moreau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Vogel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,233.32,530.93,243.02,7.77">CLEF 2013 Evaluation Labs and Workshop -Working Notes Papers</title>
		<meeting><address><addrLine>Valencia, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013-09">2013. Sep 2013</date>
		</imprint>
	</monogr>
	<note>Online proceedings</note>
</biblStruct>

<biblStruct coords="12,138.13,552.85,325.84,7.77;12,146.47,563.81,323.25,7.77;12,146.47,574.77,331.46,7.77;12,146.47,585.73,224.44,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="12,232.39,552.85,146.56,7.77">A simple measure to assess non-response</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peรฑas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rodrigo</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P11-1142" />
	</analytic>
	<monogr>
		<title level="m" coord="12,397.24,552.85,66.73,7.77;12,146.47,563.81,323.25,7.77;12,146.47,574.77,46.08,7.77">Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</title>
		<meeting>the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies<address><addrLine>Portland, Oregon, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2011-06">June 2011</date>
			<biblScope unit="page" from="1415" to="1424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.13,596.69,339.34,7.77;12,146.47,607.64,100.36,7.77" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Quinlan</surname></persName>
		</author>
		<title level="m" coord="12,198.52,596.69,131.45,7.77">C4.5: programs for machine learning</title>
		<meeting><address><addrLine>San Francisco, CA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.13,618.60,321.34,7.77;12,146.47,629.56,225.59,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,191.80,618.60,251.31,7.77">Improvements in part-of-speech tagging with an application to german</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,146.47,629.56,156.81,7.77">Proceedings of the ACL SIGDAT-Workshop</title>
		<meeting>the ACL SIGDAT-Workshop</meeting>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="47" to="50" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
