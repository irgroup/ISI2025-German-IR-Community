<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,136.78,115.90,341.79,12.90;1,281.70,133.83,51.96,12.90;1,223.43,153.68,168.49,10.75">Using sentence similarity measure for plagiarism source retrieval Notebook for PAN at CLEF 2014</title>
				<funder>
					<orgName type="full">PAN Lab</orgName>
				</funder>
				<funder ref="#_DfxFGJw">
					<orgName type="full">Russian Foundation for Basic Research</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,233.18,190.08,58.68,8.64"><forename type="first">Denis</forename><surname>Zubarev</surname></persName>
							<email>zubarev@isa.ru</email>
							<affiliation key="aff0">
								<orgName type="department">Institute for Systems Analysis of Russian Academy of Sciences</orgName>
								<address>
									<settlement>Moscow</settlement>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,315.70,190.08,62.01,8.64"><forename type="first">Ilya</forename><surname>Sochenkov</surname></persName>
							<email>isochenkov@sci.pfu.edu.ru</email>
							<affiliation key="aff1">
								<orgName type="institution">Peoples&apos; Friendship University of Russia</orgName>
								<address>
									<settlement>Moscow</settlement>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,136.78,115.90,341.79,12.90;1,281.70,133.83,51.96,12.90;1,223.43,153.68,168.49,10.75">Using sentence similarity measure for plagiarism source retrieval Notebook for PAN at CLEF 2014</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">33C6CED2898F246ED99555E6802C1006</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes a method that was implemented in the software submitted to PAN 2014 competition for the source retrieval task. For generating queries we use the most important noun phrases and words of sentences selected from a given suspicious document. To download documents that are likely to be sources of plagiarism we employ a sentence similarity measure.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The plagiarism detection track on PAN <ref type="bibr" coords="1,294.87,374.00,11.62,8.64" target="#b2">[3]</ref> is divided in two subtasks: source retrieval and text alignment. Detailed information about these tasks is provided in <ref type="bibr" coords="1,436.95,385.96,10.58,8.64" target="#b6">[7]</ref>. In this paper we present a method that is supposed to solve the former task. The search engines (Indri, ChatNoir) are used to retrieve a candidate source for a suspicious document. We formulate a set of queries for search engines based on sentences of a suspicious document. The process of formulating queries is very important because it determines the maximum possible recall that can be achieved by a source retrieval method. One of goals of this paper is to explore an influence of using a phrasal search on recall. We need also to pay attention to filtering of incorrect source candidates to keep precision high enough. It allows to save computational resources during second task solution. We employ a sentence similarity measure for filtering source candidates. If a candidate contains a sentence that is quite similar to some suspicious sentence we consider such a candidate as a source, otherwise the candidate is filtered. An another goal is to minimize amount of queries to maximum possible extent. To achieve this goal we use a small amount of suspicious document sentences for generating a set of queries and we actively filter the queries based on downloaded sources.</p><p>The rest of this paper is organized as follows: Section 2 provides the details of the source retrieval method. Section 3 describes used sentence similarity measure. Section 4 provides information about conducted experiments. Section 5 presents the performance of the software in PAN 2014 competition. Section 6 concludes the paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Source retrieval method</head><p>The source retrieval method consists of several steps:</p><p>1. suspicious document chunking 2. query formulation 3. download filtering 4. search control These steps are almost identical to those ones described in <ref type="bibr" coords="2,371.73,186.93,10.58,8.64" target="#b6">[7]</ref>. The algorithm 1 shows a pseudocode of our source retrieval algorithm, which we describe in details in the sections below.</p><p>In our method we use linguistic information such as forms of a word and syntactic dependencies of words. We use the dependency tree of a sentence to construct two-word noun phrases. If a noun is linked to another word and there are no words between them, then we consider such a structure as a phrase. Forms of words are used for measuring sentence similarity. To obtain linguistic information we use Freeling <ref type="bibr" coords="2,417.55,272.59,10.58,8.64" target="#b0">[1]</ref>. It performs document splitting, part-of-speech tagging, and dependency parsing.</p><p>We use TF-IDF weighting in our method, hence we formed a collection for calculating IDF weights of words. This collection consisted of English Wikipedia's articles (about 400,000 documents) that were chosen randomly. We suppose that this collection is sufficient for our tasks, since it allows us to distinguish words that are regularly used in any writing from some important ones.</p><p>Algorithm 1 General overview of source retrieval method </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Suspicious document chunking</head><p>Firstly, the suspicious document is split into sentences. To calculate a weight of a sentence we sum weights of all words and phrases in the sentence. The score of a word is obtained using TF-IDF weighting. The TF weight is calculated using the equation ( <ref type="formula" coords="3,472.86,161.03,3.87,8.64" target="#formula_4">4</ref>) from section 3. The IDF weight is obtained by using the equation ( <ref type="formula" coords="3,408.50,172.99,3.87,8.64" target="#formula_1">2</ref>) from section 3. Words that comprise a two-word noun phrases do not contribute in an overall sentence weight. A phrase weight is calculated as follows: W phr = 2(W h + W d ), where W h is the weight of a head word and W d is the weight of a dependent one.</p><p>After calculating the weight of all sentences we select some sentences using different filters. Firstly, a sentence weight must exceed 0.45 value, since the low weight points to insignificance of information. Other parameters are taken into consideration, such as the maximum and minimum amount of words (excluding prepositions, conjunctions, articles) per sentence. Rationale for this is to exclude short sentences that may have rather high similarity with some sentence only because of sharing the most weighted words. Very large sentences are typically either errors of splitting or large lists. It is not likely to fetch a snippet that contains the whole large sentence, so we omit them. N sentences with the highest scores, which satisfied these criteria, are selected for further analysis. We call them suspicious sentences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Query formulation</head><p>Before formulating queries we delete articles, pronouns, prepositions as well as duplicate words or phrases from each selected sentence. We use two available search engines Indri <ref type="bibr" coords="3,156.28,397.90,16.60,8.64" target="#b9">[10]</ref> and ChatNoir <ref type="bibr" coords="3,230.77,397.90,11.62,8.64" target="#b7">[8]</ref> for submitting queries. Sentences which contain phrases are submitted to Indri. For that we take 6 the most important (the most weighted) entities (phrases or words) from the sentence. The phrases are wrapped up by the special operator to leverage the phrasal search supported by Indri. If the sentence does not contain any phrases, 6 of the most weighted words are submitted to ChatNoir as a query. The formed queries are sequentially submitted to the search engines. This scheme is similar to approach that was used by Elizalde <ref type="bibr" coords="3,287.68,469.63,11.62,8.64" target="#b1">[2]</ref> in PAN 2013.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Download filtering</head><p>Seven first snippets returned by a search engine are downloaded and preprocessed by means of Freeling. Then we calculate the similarity between suspicious sentences and sentences extracted from the snippets. A method described in section 3 is used for measuring the similarity. If the similarity between any suspicious sentence and a snippet sentence exceeds M inSim, then a document to which a snippet belongs is scheduled for downloading. Such document is considered to be a source document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Search control</head><p>To filter the rest of the queries we use downloaded documents. After downloading sources are subjected to preprocessing by Freeling. Then again we calculate the similarity between suspicious sentences and sentences extracted from the downloaded documents. If there is a sentence similar to a suspicious one, the latter is marked as a misuse.</p><p>The misuses are not used in the query formulation process, since their sources have already been found. This approach is similar to one used by Haggag <ref type="bibr" coords="4,408.37,131.27,10.58,8.64" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Sentence similarity measure</head><p>Let us introduce the method for measuring sentence similarity. Given two arbitrary sentences s e and s t from documents d e and d t respectively, denote as N (s e , s t ) a set of word pairs with the same lemma, where the first element is taken from s e and the second one from s t . We compare two sentences by considering word pairs from the set N (s e , s t ). For calculating an overall similarity measure of two sentences we compute multiple similarities measures and then combine its values. The employed similarities are described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">IDF overlap measure</head><p>Similar to <ref type="bibr" coords="4,176.84,331.38,11.62,8.64" target="#b5">[6]</ref> we define IDF overlap as follows:</p><formula xml:id="formula_0" coords="4,229.31,356.92,251.29,20.53">I 1 (s e , s t ) = (we,wt)∈N (se,st) IDF (w e )<label>(1)</label></formula><formula xml:id="formula_1" coords="4,236.30,398.52,240.42,23.23">IDF (w e ) = log |D| |D| m(w e , D) , (<label>2</label></formula><formula xml:id="formula_2" coords="4,476.72,405.58,3.87,8.64">)</formula><p>where D is a set of documents and m(w e , D) is an amount of documents that contain the word w e . For correctness sake we assume that if m(w e , D) = 0, then IDF (w e ) = 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">TF-IDF-based similarity measure</head><p>Let us define TF-IDF-based measure in the following way:</p><formula xml:id="formula_3" coords="4,185.97,531.60,294.63,20.53">I 2 (s e , s t ) = (we,wt)∈N (se,st) f (w e , w t )IDF (w e )T F (w t , d t )<label>(3)</label></formula><formula xml:id="formula_4" coords="4,241.80,576.46,238.79,10.59">T F (w t , d t ) = log |dt| (k(w t , d t ))<label>(4)</label></formula><p>where |d t | is an amount of words in a document d t and k(w t , d t ) is an amount of the word w t in a document d t . f (w e , w t ) is a kind of a penalty for mismatch of w e , w t forms :</p><p>f (w e , w t ) = 1.0, if forms of the words are the same 0.8, otherwise</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Sentence syntactic similarity measure</head><p>To be able to measure syntactic similarity we need to generate syntactic dependency tree from each sentence. We define Syn(s e ) as a set that contains triplets (w h , σ, w d ), where w h , w d are normalized head and dependent word respectively, σ is type of syntactic relation. We define syntactic similarity in the following way:</p><formula xml:id="formula_6" coords="5,204.77,191.70,275.83,41.05">I 3 (s e , s t ) = (w h ,σ,w d )∈(Syn(se)∩Syn(st)) IDF (w h ) (w h ,σ,w d )∈Syn(se) IDF (w h )<label>(6)</label></formula><p>Rationale for using syntactic information is to treat sentences not as a bag-of-words but as syntactically linked text. The syntactic similarity will be low for sentences in which the same words are used but they are linked in a different way. This measure is quite similar to one, described in <ref type="bibr" coords="5,267.87,278.51,10.58,8.64" target="#b4">[5]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Overall sentence similarity</head><p>The overall sentence similarity we define as a linear combination of described measures.</p><p>Sim(s e , s t ) = W Idf * I 1 (s e , s t ) + W T f Idf * I 2 (s e , s t ) + W Synt * I 3 (s e , s t ), <ref type="bibr" coords="5,468.98,356.89,11.62,8.64" target="#b6">(7)</ref> where W Idf , W T f Idf , W Synt determine relative contributions of each similarity. If Sim(s e , s t ) &gt; M inSim, then the suspicious sentence is considered as the plagiarised sentence. The process of tuning these four parameters is described in section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experiments</head><p>Experiments were run on the training corpus provided by the PAN organizers (about 100 documents of Webis-TRC-12 <ref type="bibr" coords="5,255.90,465.15,10.46,8.64" target="#b8">[9]</ref>). The source retrieval method described in section 2 is highly tunable and has multiple parameters. Some parameters were tuned separately, namely parameters that are involved in the process of the query generation (the amount of words and phrases in query, document chunking parameters). One of these parameters was varied while the others were fixed. The values that performed well in terms of the F-measure were chosen for further experiments. The ChatNoir oracle was used for the source retrieval evaluation. The found parameters are shown in table 1. The experiments showed that using only words for the candidates retrieval decreased recall by over 30%.</p><p>There are many tunable parameters in the method for measuring sentence similarity. For tuning these parameters we fixed parameters that are involved in the query generation process. All possible snippets and full document texts were fetched for queries that were formulated by using the fixed parameters. The downloaded data were preprocessed by Freeling and prepared for loading by our software. Using such preprocessed data, multiple combinations of M inSim, W Idf , W T f Idf , W Synt parameters were tried. In the end we chose a combination that gave the best F-measure. The obtained parameters are shown in table <ref type="table" coords="5,255.97,656.44,3.74,8.64" target="#tab_2">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>Table <ref type="table" coords="6,159.32,322.04,4.98,8.64" target="#tab_3">3</ref> shows results of our software on the test data (about 100 documents of Webis-TRC-12 corpus <ref type="bibr" coords="6,197.77,334.00,10.46,8.64" target="#b8">[9]</ref>). Results were obtained by means of the evaluation platform TIRA <ref type="bibr" coords="6,473.49,334.00,10.58,8.64" target="#b2">[3]</ref>. As can be seen from Table <ref type="table" coords="6,263.32,512.64,3.74,8.64" target="#tab_3">3</ref>, our software achieved F1 score of 0.45. It was the second highest achieved the F1 score by all participants.</p><p>An average of 37.03 queries were submitted per suspicious document and 18.62 results downloaded. The amount of both queries and downloaded results were relatively low in comparison with the other softwares particapated in PAN. Only 37 sentences were transformed into queries from 83 selected sentences on average. Such heavy filtering was crucial for achieving relatively high precision. It was experimentally found that the query filtering decreased recall but on the other hand significantly increased precision. According to results our software downloaded 18.62 * 0.54 = 10.05 true positives for one suspicious document on average. This means that at least 3.7 queries were required for retrieving true positives results. This result proved that using phrases for candidate retrieval is quite reasonable and effective. However, the amount of queries to first detection was 5.4. It seems that ranking of sentences according to its weight was not the best strategy. Nevertheless, indicators that are measuring time to first detection were also low in comparison with the other participants results. On average, 2.25 full texts were downloaded until the first correct source document. It suggests that the snippets filtering based on employing sentence similarity measure worked relatively well.</p><p>No plagiarism sources were detected for 3 suspicious documents, which was about 3% of the suspicious documents in the test corpus. This result shows that the software is able to retrieve sources of plagiarism for the majority of documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>This paper describes the source retrieval method that can achieve relatively high retrieval performance while minimizing the workload. It is possible to employing two approaches, namely the phrasal search for the retrieving of candidates and using sentence similarity measure for the filtering of the candidates.</p><p>Many search engines support phrasal search to some extent. Some of them (e.g. Yandex, Yahoo) provide a proximity search which makes it possible to search phrases, and the other search engines (e.g. Google) provide the exact phrase search.</p><p>The filtering that is based on the sentence similarity measure works well when a snippet is an original sentence (or some part of it). If snippets contain heavily overlapped fragments of one sentence divided by a delimiter, then it is hardly useful to employ sentence comparison. We occasionally experienced this issue during experiments with ChatNoir snippets. But we believe that snippets that are provided by the popular search engines (e.g. Google, Yandex) contain the original sentences. Therefore results of our method are supposed to be reproducible in real-world environment.</p><p>However, there is some room for further improvements. It is probably worth reducing the set of phrases only to collocations. The rationale for this is based on an assumption that it is very easy to change a phrase using synonym of a head or a dependent word. But one cannot simply change any word in collocation because the phrase will lose its meaning. So one needs to synonymize the whole phrase or to leave it as it is.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,176.70,115.83,261.95,85.88"><head>Table 1 .</head><label>1</label><figDesc>The chosen parameters that are involved in the query generation</figDesc><table coords="6,218.03,136.80,179.29,64.91"><row><cell>Parameters</cell><cell>Values</cell></row><row><cell>minimum weight of a sentence</cell><cell>0.45</cell></row><row><cell cols="2">minimum amount of words in a sentence 11</cell></row><row><cell>maximum amount words in a sentence</cell><cell>33</cell></row><row><cell cols="2">maximum amount of suspicious sentences 83</cell></row><row><cell>words and phrases per query</cell><cell>6</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,136.16,216.07,294.12,51.81"><head>Table 2 .</head><label>2</label><figDesc>The tuned parameters for the measuring sentence similarity</figDesc><table coords="6,136.16,237.04,284.45,30.84"><row><cell cols="5">sentences for measuring similarity MinSim WIdf WTfIdf WSynt</cell></row><row><cell>snippet sentences</cell><cell>0.5</cell><cell>0.4</cell><cell>0.4</cell><cell>0.2</cell></row><row><cell>sentences from a downloaded document</cell><cell>0.4</cell><cell>0.5</cell><cell>0.0</cell><cell>0.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="6,136.16,375.77,347.09,106.36"><head>Table 3 .</head><label>3</label><figDesc>PAN 2014 Source retrieval final results</figDesc><table coords="6,136.16,394.91,347.09,87.23"><row><cell cols="8">Submission Retrieval Performance F1 Precision Recall Queries Downloads Queries Downloads Workload Time to 1st Detection No Detection</cell></row><row><cell cols="2">zubarev14 0.45 0.54</cell><cell>0.45</cell><cell>37.03</cell><cell>18.62</cell><cell>5.4</cell><cell>2.25</cell><cell>3</cell></row><row><cell cols="2">suchomel14 0.11 0.08</cell><cell>0.40</cell><cell>19.05</cell><cell>237.3</cell><cell>3.1</cell><cell>38.6</cell><cell>2</cell></row><row><cell cols="2">williams14 0.47 0.57</cell><cell cols="2">0.48 117.13</cell><cell>14.41</cell><cell>18.82</cell><cell>2.34</cell><cell>4</cell></row><row><cell>kong14</cell><cell>0.12 0.08</cell><cell>0.48</cell><cell>83.5</cell><cell>207.01</cell><cell>85.7</cell><cell>24.9</cell><cell>6</cell></row><row><cell cols="2">prakash14 0.39 0.38</cell><cell>0.51</cell><cell>59.96</cell><cell>38.77</cell><cell>8.09</cell><cell>3.76</cell><cell>7</cell></row><row><cell cols="2">elizalde14 0.34 0.40</cell><cell>0.39</cell><cell>54.5</cell><cell>33.2</cell><cell>16.4</cell><cell>3.9</cell><cell>7</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We gratefully acknowledge support by <rs type="funder">Russian Foundation for Basic Research</rs> under grant No. <rs type="grantNumber">14-07-31149</rs> and the <rs type="funder">PAN Lab</rs> organizers for their effort in organizing PAN 2014.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_DfxFGJw">
					<idno type="grant-number">14-07-31149</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,142.61,613.13,320.61,7.77;7,150.95,624.09,322.14,7.77;7,150.95,635.05,86.74,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,414.41,613.13,48.81,7.77;7,150.95,624.09,223.56,7.77">FreeLing 1.3: Syntactic and semantic services in an open-source NLP library</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Atserias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Casas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Comelles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>González</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Padró</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Padró</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,392.16,624.09,75.90,7.77">Proceedings of LREC</title>
		<meeting>LREC</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="48" to="55" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,646.13,327.20,7.77;7,150.95,657.09,142.50,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,197.11,646.13,203.06,7.77">Using statistic and semantic analysis to detect plagiarism</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Elizalde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,418.25,646.13,51.55,7.77;7,150.95,657.09,112.20,7.77">CLEF (Online Working Notes/Labs/Workshop</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,119.96,331.25,7.77;8,150.95,130.92,298.75,7.77;8,150.95,141.88,329.63,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,163.91,130.92,197.32,7.77">Recent trends in digital text forensics and its evaluation</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Busse</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,379.24,130.92,70.46,7.77;8,150.95,141.88,217.85,7.77">Information Access Evaluation. Multilinguality, Multimodality, and Visualization</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="282" to="302" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,152.84,337.35,7.77;8,150.95,163.80,329.63,7.77" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,251.18,152.84,228.79,7.77;8,150.95,163.80,115.83,7.77">Plagiarism candidate retrieval using selective query formulation and discriminative query scoring</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Haggag</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>El-Beltagy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,284.64,163.80,165.73,7.77">CLEF (Online Working Notes/Labs/Workshop</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,174.76,333.94,7.77;8,150.95,185.72,291.37,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,248.08,174.76,228.47,7.77;8,150.95,185.72,28.10,7.77">A dependency grammar and WordNet based sentence similarity measure</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Dong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,185.31,185.72,168.86,7.77">Journal of Computational Information Systems</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1027" to="1035" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,196.67,312.73,7.77;8,150.95,207.63,315.59,7.77;8,150.95,218.59,247.44,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,371.17,196.67,84.17,7.77;8,150.95,207.63,90.10,7.77">Similarity measures for tracking information flow</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Moffat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zobel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,258.98,207.63,207.56,7.77;8,150.95,218.59,145.31,7.77">Proceedings of the 14th ACM international conference on Information and knowledge management</title>
		<meeting>the 14th ACM international conference on Information and knowledge management</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="517" to="524" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,229.55,324.16,7.77;8,150.95,240.51,305.96,7.77;8,150.95,251.47,326.83,7.77;8,150.95,262.43,261.95,7.77" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,186.83,240.51,254.18,7.77">Overview of the 5th International Competition on Plagiarism Detection</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tippmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kiesel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="http://www.clef-initiative.eu/publication/working-notes" />
	</analytic>
	<monogr>
		<title level="m" coord="8,289.34,251.47,188.44,7.77;8,150.95,262.43,17.43,7.77">Working Notes Papers of the CLEF 2013 Evaluation Labs</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Tufis</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2013-09">Sep 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,273.39,328.33,7.77;8,150.95,284.35,291.37,7.77;8,150.95,295.30,298.34,7.77;8,150.95,306.26,138.40,7.77" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,150.95,284.35,188.27,7.77">ChatNoir: a search engine for the ClueWeb09 corpus</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Graßegger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tippmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Welsch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,357.41,284.35,84.92,7.77;8,150.95,295.30,298.34,7.77;8,150.95,306.26,28.50,7.77">Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 35th international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1004" to="1004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.61,317.22,301.41,7.77;8,150.95,328.18,323.24,7.77;8,150.95,339.14,289.03,7.77;8,150.95,350.10,267.91,7.77" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,321.97,317.22,122.05,7.77;8,150.95,328.18,123.78,7.77">Crowdsourcing interaction logs to understand text reuse from the web</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hagen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Völske</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<ptr target="http://www.aclweb.org/anthology/P13-1119" />
	</analytic>
	<monogr>
		<title level="m" coord="8,390.27,328.18,83.92,7.77;8,150.95,339.14,272.03,7.77">Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL 13)</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Fung</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Poesio</surname></persName>
		</editor>
		<meeting>the 51st Annual Meeting of the Association for Computational Linguistics (ACL 13)</meeting>
		<imprint>
			<publisher>ACL</publisher>
			<date type="published" when="2013-08">Aug 2013</date>
			<biblScope unit="page" from="1212" to="1221" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,142.24,361.06,326.69,7.77;8,150.95,372.02,323.07,7.77;8,150.95,382.98,147.50,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,332.48,361.06,136.44,7.77;8,150.95,372.02,96.44,7.77">Indri: A language model-based search engine for complex queries</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,265.36,372.02,208.67,7.77;8,150.95,382.98,29.89,7.77">Proceedings of the International Conference on Intelligent Analysis</title>
		<meeting>the International Conference on Intelligent Analysis</meeting>
		<imprint>
			<publisher>Citeseer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="2" to="6" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
