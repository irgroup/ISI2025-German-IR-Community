<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,165.89,115.90,283.58,12.90;1,218.35,133.83,178.65,12.90;1,223.43,153.68,168.49,10.75">UJM at CLEF in Author Verification based on optimized classification trees. Notebook for PAN at CLEF 2014</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,170.77,190.08,50.63,8.64"><forename type="first">Jordan</forename><surname>Fréry</surname></persName>
							<email>jordan.frery@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratoire Hubert Curien</orgName>
								<orgName type="institution">Université de Lyon</orgName>
								<address>
									<postCode>F-42023</postCode>
									<settlement>Saint-Etienne</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,230.85,190.08,75.36,8.64"><forename type="first">Christine</forename><surname>Largeron</surname></persName>
							<email>christine.largeron@univ-st-etienne.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratoire Hubert Curien</orgName>
								<orgName type="institution">Université de Lyon</orgName>
								<address>
									<postCode>F-42023</postCode>
									<settlement>Saint-Etienne</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,332.54,190.08,107.58,8.64"><forename type="first">Mihaela</forename><surname>Juganaru-Mathieu</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Institut H. Fayol</orgName>
								<orgName type="institution">École Nationale Supérieure des Mines</orgName>
								<address>
									<postCode>F-42023</postCode>
									<settlement>Saint-Etienne</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,165.89,115.90,283.58,12.90;1,218.35,133.83,178.65,12.90;1,223.43,153.68,168.49,10.75">UJM at CLEF in Author Verification based on optimized classification trees. Notebook for PAN at CLEF 2014</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">34B31292CB0EC35C40300D25B155718E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This article describes our proposal for the Author Identification task in the PAN CLEF Challenge 2014. We have adopted a machine learning approach based on several representations of the texts and on optimized decision trees which have as entry various attributes and which are learned for every training corpus separately for this classification task. Our method ranked us at the 2nd place with an overall AUC of 70.7%, and C@1 of 68.4% and, between the 1st and the 6th place on the six corpora.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The task Author Identification (AI) in the CLEF-PAN Challenge is to solve a large set of problems like : given a set A of sample texts, all texts in A are written by a single author and an unidentified document u, determine if u was written by the author of A. The difficulties of this task are various : the limited data : sometimes, A has only one text, some languages that we do not know or we are not able to understand. We adopt a machine learning approach based on several representations of the texts and on optimized decision trees which are based on various attributes and which are learned for every training corpus separately. We decided to represent the documents in different vector spaces and by various types of features :</p><p>length of the sentences, variety of vocabulary, n-characters grams, n-words gram, punctuation marks.</p><p>For each feature, we considered two numerical values : a mean and a counter. Another global counter was also used. Because we are not able to indicate or to justify the features which are the most important for a given type of document, we used decision trees based on an adapted version of CART, to learn a decision model suited for a kind of document. Thus, each corpus defined by a language and a genre, has its own learned tree.</p><p>So, our proposal is based on:</p><p>the proposition of vector space models and attributes that represent the documents in a way as optimal as possible.</p><p>the formulation of the Author Verification problem as a supervised classification problem.</p><p>the evaluation of this approach on different groups of problems in the challenge context.</p><p>Section 2 describes the vector spaces that we choose to represent the documents. The Section 3 is dedicated to the methodological approach. Finally, Section 4 presents the experiments and the results obtained on the training set and for the challenge. We will finish with some conclusions and future perspectives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Textual representation</head><p>A problem inside a corpus consists in a given set A of documents written by the same author and another document u whose author is unknown. The aim is to decide whether u has the same author as all documents d i in A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Vector space models</head><p>In order to represent the textual documents as vectors we use different vector space models <ref type="bibr" coords="2,165.74,332.56,10.58,8.64" target="#b0">[1]</ref>. The first one is the well known term frequency-inverse document frequency weighting scheme (tf-idf) introduced by Salton <ref type="bibr" coords="2,325.77,344.52,10.58,8.64" target="#b1">[2]</ref>. This model is very efficient to isolate terms that are frequent in one document and not in the others. A document d in a corpus A is represented as a vector of weights d = (w 1 , . . . , w j , . . . , w |T | ) where the weight w j of the term t j in d corresponds to the product of the term frequency tf j of the term t j in d by the inverse document frequency idf (j) defined by:</p><formula xml:id="formula_0" coords="2,243.73,412.44,236.86,23.23">idf (j) = log |A| |{d ∈ A : t j ∈ d}|<label>(1)</label></formula><p>This representation can be defined for terms corresponding either to words or characters. In order to take into account the variety of the style and vocabulary, we consider representations based on the punctuation, length of phrases and diversity of the vocabulary as detailed in Table <ref type="table" coords="2,239.67,475.94,3.74,8.64" target="#tab_0">1</ref>. word per sentence mean and standard deviation correlation coefficient R7 Vocabulary diversity total number of different terms divided by the euclidean distance total number of occurrences of words R8 Punctuation average of punctuation marks per sentence cosine similarity characters: "," ";" ":" "(" ")" "!" "?"</p><p>We note that this table contains usual representation spaces and some original ones as well as different comparison methods that, based on an empirical search, appeared to be relevant for this task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Documents comparison</head><p>Our approach requires to compare all documents inside a corpus using the cosine similarity, euclidean distance or the correlation coefficient. These measures are normalized, between 0 and 1 for the euclidean distance and cosine similarity and, between -1 and 1 for the correlation coefficient. For two documents represented as vectors d i and d j , the cosine similarity cos(d i , d j ) is defined as follows:</p><formula xml:id="formula_1" coords="3,258.07,273.22,222.52,23.26">cos(d i , d j ) = d i • d j ||d i ||d j ||<label>(2)</label></formula><p>The cosine similarity equals to 1 when the documents have the same representation. Conversely, if two documents are highly different, cosine similarity will tend to be 0.</p><p>The correlation coefficient corrcoef (d i , d j ) <ref type="bibr" coords="3,324.64,327.63,11.62,8.74" target="#b4">[5]</ref> between two documents is given by:</p><formula xml:id="formula_2" coords="3,241.78,348.37,238.81,24.10">corrcoef (d i , d j ) = C ij C ii * C jj<label>(3)</label></formula><p>where C ij denotes the covariance between the documents d i and d j .</p><p>Table <ref type="table" coords="3,175.05,408.73,4.98,8.64" target="#tab_0">1</ref> presents the different representation spaces and the measures we used to compare the documents belonging to a corpus. In our methodological approach, we extracted two attributes for each representation space of Table <ref type="table" coords="3,389.94,432.64,4.98,8.64" target="#tab_0">1</ref> in order to represent the unknown documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Methodological approach</head><p>Given a corpus P containing all the documents having the same language and the same type, we have p ∈ P problems to solve and, for each problem there are one or several documents written by the same author and one document (u) whose author is unknown. Thus, the dataset of the supervised learning problem contains all the unknown documents of one corpus, described by 17 attributes but also by the class which has two modalities (SameAuthor or DifferentAuthor). Note that the known documents are not directly taken into account in this dataset however they are used to compute the representation of unknown documents. In supervised learning, models are learned by splitting the dataset into two subsets. The first one, called learning set, is used to learn the model, in our case, a decision tree. The second subset, called test set, is used to evaluate the model. The decision tree learned during the learning step is use to define the class of each unknown document corresponding to a problem. The evaluation of the quality of the decision rules is done by computing the well classification rate or the area under the ROC curve (AUC) obtained by comparing the predicted class and the true class for the unknown documents belonging to the test set. The accuracy of the models depends largely on the attributes predictive power. That leads us to define two attributes per representation space and a global attribute.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Attributes definition</head><p>We use a dissimilarity counter method that we designed while experimenting on the PAN2013 corpora in Author identification and which yielded very good results <ref type="bibr" coords="4,451.03,218.75,10.58,8.64" target="#b2">[3]</ref>. We chose to use it back for PAN 2014 in a modified version. This method only works for problems with at least two known texts (|A| &gt;= 2). Given P, the set of problems provided for one corpus defined by A p the set of documents written by one author and u p the unknown document for a problem p, p = 1, ..., |P|, such as:</p><formula xml:id="formula_3" coords="4,246.38,307.62,234.21,9.65">P = {(A p , u p ), p ∈ 1, ..., |P|}<label>(4)</label></formula><p>For each document u p , corresponding to a given problem, and for each representation space R v , v ∈ {1, .., 8}, we calculate two attributes count v (u p ) and mean v (u p ) as follows:</p><formula xml:id="formula_4" coords="4,167.79,379.64,312.80,9.65">count v (u p ) = |{di ∈ A p /min{s(d i , d j ), d j ∈ A -d i } &gt; s(d i , u p )}|<label>(5)</label></formula><formula xml:id="formula_5" coords="4,223.71,417.23,256.88,23.23">mean v (u p ) = 1 |A p | × di∈Ap s(d i , u p )<label>(6)</label></formula><p>count v (u p ) gives the number of documents d i ∈ A p for which the similarity between d i and u p is lower than the minimum of the similarities of d i with the other documents d j ∈ A p -d i . It comes intuitively and indicates how many times u p is the most dissimilar to every document in A p . mean v (u p ) represents the average of the similarities between the documents in A p and u p .</p><p>These two attributes are computed for each representation space. Consequently, since v ∈ {1, .., 8} we have 16 attributes. A last attribute, T OT count (u p ) is built to have a more global representation:</p><formula xml:id="formula_6" coords="4,239.61,589.93,240.98,30.20">T OT count (u p ) = 8 v=1 count v (u p )<label>(7)</label></formula><p>Finally we have 17 attributes describing each unknown document belonging to a problem provided for one corpus comprised by the documents with the same language and genre.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Decision tree classifier</head><p>For the task of Author Verification, we used the Classification and Regression Trees (CART) algorithm which constructs binary trees using the features and thresholds that yield the largest information gain at each node <ref type="bibr" coords="5,328.84,165.35,10.58,8.64" target="#b3">[4]</ref>. The trees are built by using each training corpus from PAN2014 separately in such a way to obtain one tree per corpus. We train the classifier with the attributes given previously plus the true label for the given unknown document. At each step, the attribute that best splits the set of unknown documents into the two classes is chosen using the gini impurity. In order to avoid overfitting, we apply post-pruning technique which consists in building the tree which classify the training set perfectly and then prune the tree <ref type="bibr" coords="5,361.09,237.08,10.58,8.64" target="#b5">[6]</ref>.</p><p>For each problem of the corpus, the decision tree has the following informations for the unknown document:</p><p>count v (u p ), ∀v ∈ {1, .., 8} mean v (u p ), ∀v ∈ {1, .., 8} -T OT count (u p ) class(u p ), the true label of a problem</p><p>The previous data allow us to build rules where we classify 100% of problems correctly. In order to handle overfitting we remove all leaves with less than 5% of the total number of problems so we can keep more general rules. Moreover, we choose not to answer problems that have a low probability to belong to one class. The rule we set is that when the probability for a text to be written by the same author is between 0.4 and 0.6, we change the probability to 0.5 so that we choose to not answer this problem. So finally there are 3 modalities for the class: sameAuthor, differentAuthor or undefined.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Experimentation and results</head><p>For the learning step, the implementation has been done in Python. We used scikit-learn library <ref type="foot" coords="5,163.82,483.74,3.49,6.05" target="#foot_0">3</ref> for the n-grams representation and for CART.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Learning</head><p>The experimentation has been made on the training corpus which contains 696 problems labelled as DE, DR, GR, EN, EE or SP where D stands for Dutch (DE, DR), GR for Greek, SP for Spanish and E for English (EE, EN). We have essays and review for Dutch (DE, DR) and essays and novels for English (EE, EN). For experimentation, we have made a 10-fold cross validation for each group of problems in order to evaluate the quality of the decision trees on the training set.</p><p>The table 2 shows for each corpus: the number of problems and the result calculated with the area under the ROC curve (AUC) on the training dataset. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Corpus</head><p>EN EE DR DE SP GR AUC 61 % 72% 60% 90% 77% 68% C@1 59 % 71% 58% 90% 75% 64% Time(min) 3:10 0:54 0:08 0:29 1:00 0:57 Final rank(ROC * c@1) 7/13 1/13 6/13 2/13 4/13 7/12 Rank(Exe. time)</p><p>3/13 3/13 3/13 4/13 3/13 3/12</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>With an overall score of 0.707 for AUC and 0.684 for C@1 we obtained a final score of 0.484 (AU C * C@1) which is the second best submission. As shown in Table <ref type="table" coords="7,458.98,271.45,3.74,8.64" target="#tab_1">3</ref>, we obtained the 1st rank for the English Essays corpus, 2nd for the Dutch Essays corpus and 4th for the Spanish corpus. For the evaluation corpora of PAN2014, the results we obtained were consistent with the ones we had while training our decision tree. However we lost significant accuracy for the English novels corpus (near 30% of loss). We would need to study the evaluation corpus to understand why we had such a loss of accuracy. Moreover our approach is not time-consuming as shown in Table <ref type="table" coords="7,396.29,343.18,3.74,8.64" target="#tab_1">3</ref>.</p><p>During this challenge we saw that the most difficult task was to gather features that complement each other. CART enable us to identify good predictive features. However, we did not try all possibilities for text representations. Lastly we found that building efficient attributes, like with the counter method, greatly improved the accuracy of CART for some corpora.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" coords="6,134.77,359.19,345.83,186.97"><head></head><label></label><figDesc></figDesc><graphic coords="6,134.77,359.19,345.83,186.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,136.44,506.35,342.47,110.19"><head>Table 1 .</head><label>1</label><figDesc>List of representation spaces and comparison measures</figDesc><table coords="2,136.44,527.67,342.47,88.87"><row><cell></cell><cell>Representation space</cell><cell>Comparison method</cell></row><row><cell>Term</cell><cell>Model</cell><cell></cell></row><row><cell cols="2">R1 Character 8-grams tf-idf</cell><cell>cosine similarity</cell></row><row><cell cols="2">R2 Character 3-grams tf-idf</cell><cell>correlation coefficient</cell></row><row><cell>R3 Word 2-grams</cell><cell>tf-idf</cell><cell>correlation coefficient</cell></row><row><cell>R4 Word 1-gram</cell><cell>tf-idf without the 30% most frequent words</cell><cell>correlation coefficient</cell></row><row><cell>R5 Word 1-gram</cell><cell>tf-idf without stop words</cell><cell>correlation coefficient</cell></row><row><cell>R6 Phrases</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,240.95,115.83,133.46,8.12"><head>Table 3 .</head><label>3</label><figDesc>Challenge evaluation results</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="5,144.73,657.09,75.80,7.77"><p>http://scikit-learn.org</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The following tree is the one used over the English Essays (EE) corpus where "samples" is the number of problems remaining at a node. There are, in total, 200 problems to be classified. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Evaluation</head><p>The evaluation of the decision trees built during the learning step was done during the competition. The table 3 contains the official results of PAN14 in Author Identification for our team computed by the organizers of the challenge.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="7,138.13,458.40,315.04,7.77;7,146.47,469.36,276.91,7.77" xml:id="b0">
	<monogr>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sanger</surname></persName>
		</author>
		<title level="m" coord="7,234.52,458.40,218.65,7.77;7,146.47,469.36,64.39,7.77">Text Mining Handbook: Advanced Approaches in Analyzing Unstructured Data</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.13,480.32,332.02,7.77;7,146.47,491.28,60.35,7.77" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="7,209.98,480.32,162.68,7.77">Introduction to Modern Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>McGraw-Hill</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.13,502.24,332.29,7.77;7,146.47,513.20,308.22,7.77;7,146.47,524.16,58.30,7.77" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,236.88,502.24,182.62,7.77">Overview of the Author Identification Task at PAN</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,307.12,513.20,147.57,7.77;7,146.47,524.16,58.30,7.77">Working Notes Papers of the CLEF 2013 Evaluation Labs</title>
		<editor>
			<persName><forename type="first">Pamela</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Roberto</forename><surname>Navigli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Dan</forename><surname>Tufis Edn</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.13,535.12,313.71,7.77" xml:id="b3">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">O</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename></persName>
		</author>
		<title level="m" coord="7,297.89,535.12,127.80,7.77">Classification and Regression Trees</title>
		<imprint>
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.13,546.08,337.08,7.77;7,146.47,557.03,331.45,7.77;7,146.47,567.99,176.38,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,190.51,546.08,284.70,7.77;7,146.47,557.03,141.24,7.77">Correlation coefficient of linguistic variables and its applications to quantifying relations in imprecise management data</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">C</forename><surname>Ngan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.engappai.2012.09.009</idno>
		<ptr target="http://dx.doi.org/10.1016/j.engappai.2012.09.009" />
	</analytic>
	<monogr>
		<title level="j" coord="7,293.39,557.03,84.42,7.77">Eng. Appl. Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="347" to="356" />
			<date type="published" when="2013-01">Jan 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,138.13,578.95,342.45,7.77" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,198.30,578.95,92.97,7.77">Simplifying decision trees</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Quinlan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,296.58,578.95,85.09,7.77">Int. J. Man-Mach. Stud</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="221" to="234" />
			<date type="published" when="1987-09">Sep 1987</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
