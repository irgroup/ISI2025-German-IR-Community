<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,147.56,148.84,311.48,16.02;1,253.16,166.30,88.98,16.02">Overview of the Author Identification Task at PAN 2014</title>
				<funder ref="#_YcRmafB">
					<orgName type="full">United States National Science Foundation</orgName>
				</funder>
				<funder ref="#_KXprYMa">
					<orgName type="full">Spanish Ministry of Education and Science</orgName>
				</funder>
				<funder ref="#_HaCvFTG">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,146.06,207.46,86.29,9.11"><forename type="first">Efstathios</forename><surname>Stamatatos</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of the Aegean</orgName>
								<address>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,240.41,207.46,74.11,9.11"><forename type="first">Walter</forename><surname>Daelemans</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Antwerp</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,322.55,207.46,62.54,9.11"><forename type="first">Ben</forename><surname>Verhoeven</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Antwerp</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,393.13,207.46,61.97,9.11"><forename type="first">Martin</forename><surname>Potthast</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Bauhaus-Universität Weimar</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,185.12,218.98,49.18,9.11"><forename type="first">Benno</forename><surname>Stein</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Bauhaus-Universität Weimar</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,242.33,218.98,51.94,9.11"><forename type="first">Patrick</forename><surname>Juola</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Duquesne University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,302.27,218.98,102.52,9.11"><forename type="first">Miguel</forename><forename type="middle">A</forename><surname>Sanchez-Perez</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">Instituto Politécnico Nacional</orgName>
								<address>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,257.35,230.44,94.69,9.11"><forename type="first">Alberto</forename><surname>Barrón-Cedeño</surname></persName>
							<affiliation key="aff5">
								<orgName type="institution">Universitat Politècnica de Catalunya</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,147.56,148.84,311.48,16.02;1,253.16,166.30,88.98,16.02">Overview of the Author Identification Task at PAN 2014</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6D4996EDC95CB3FA3412CB85F9DC453E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The author identification task at PAN-2014 focuses on author verification. Similar to PAN-2013 we are given a set of documents by the same author along with exactly one document of questioned authorship, and the task is to determine whether the known and the questioned documents are by the same author or not. In comparison to PAN-2013, a significantly larger corpus was built comprising hundreds of documents in four natural languages (Dutch, English, Greek, and Spanish) and four genres (essays, reviews, novels, opinion articles). In addition, more suitable performance measures are used focusing on the accuracy and the confidence of the predictions as well as the ability of the submitted methods to leave some problems unanswered in case there is great uncertainty. To this end, we adopt the c@1 measure, originally proposed for the question answering task. We received 13 software submissions that were evaluated in the TIRA framework. Analytical evaluation results are presented where one language-independent approach serves as a challenging baseline. Moreover, we continue the successful practice of the PAN labs to examine meta-models based on the combination of all submitted systems. Last but not least, we provide statistical significance tests to demonstrate the important differences between the submitted approaches.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="595.38" lry="841.98"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Authorship analysis has attracted much attention in recent years due to both the rapid increase of texts in electronic form and the need for intelligent systems able to handle this information. Authorship analysis deals with the personal style of authors and includes three major areas:</p><p>-Author identification: Given a set of candidate authors for whom some texts of undisputed authorship exist, attribute texts of unknown authorship to one of the candidates. This can be applied mainly to forensic applications and literary analysis <ref type="bibr" coords="1,180.80,671.18,15.83,9.11" target="#b12">[13,</ref><ref type="bibr" coords="1,199.10,671.18,11.87,9.11" target="#b30">31]</ref>.</p><p>-Author profiling: The extraction of demographic information such as gender, age, etc. about the authors. This has significant applications mainly in market analysis <ref type="bibr" coords="2,180.80,172.84,15.35,9.11" target="#b27">[28]</ref>.</p><p>-Author clustering: The segmentation of texts into stylistically homogeneous parts. This can be applied to distinguish different authors in collaborative writing, to detect plagiarism without a reference corpus (i.e., intrinsic plagiarism detection <ref type="bibr" coords="2,185.54,225.04,14.95,9.11" target="#b34">[35]</ref>), and to detect changes in the personal style of a certain author by examining their works chronologically <ref type="bibr" coords="2,303.80,236.50,15.35,9.11" target="#b13">[14]</ref>.</p><p>Author identification is by far the most prevalent field of authorship analysis in terms of published studies. The authorship attribution problem can be viewed as a closed-set classification task where all possible candidate authors are known. This is suitable in many forensic applications where the investigators of a case can provide a specific set of suspects based on certain restrictions (e.g., access to specific material, knowledge of specific facts, etc.). A more general definition of the authorship attribution problem corresponds to an open-set classification task where the true author of the disputed texts is not necessarily included in the set of candidate authors. This setting is much more difficult in comparison to the closed-set attribution scenario, especially when the size of the candidate author set is small <ref type="bibr" coords="2,416.75,357.52,15.58,9.11" target="#b17">[18]</ref>. Finally, when the set of candidate authors is singleton, we get the author verification problem. This is an even more difficult attribution task.</p><p>The PAN-2014 evaluation lab continues the practice of PAN-2013 and focuses on the author verification problem <ref type="bibr" coords="2,268.04,403.56,15.40,9.11" target="#b14">[15]</ref>. First, this is a fundamental problem in authorship attribution <ref type="bibr" coords="2,214.60,415.02,16.76,9.11" target="#b19">[20]</ref> and by studying it we can extract more useful conclusions about the performance of certain attribution methods. Any author identification task can be decomposed into a series of author verification problems. Therefore, the ability of an approach to effectively deal with this task means that it can cope with every authorship attribution problem. Moreover, in comparison to PAN-2013, we provide a larger collection of verification problems including more natural languages and genres. Thus, we can study more reliably the performance of the submitted approaches under different conditions and test their ability to be adapted to certain properties of documents. In addition, we define more appropriate performance measures that are suitable for this cost-sensitive task focusing on the ability of the submitted approaches to assign confidence scores in their answers as well as their ability to leave the most uncertain cases unanswered.</p><p>Based on the successful practice of PAN-2013, we build a meta-classifier to combine all submitted approaches and examine the performance of this ensemble model in comparison to the individual participants <ref type="bibr" coords="2,348.80,576.00,15.32,9.11" target="#b14">[15]</ref>. Moreover, we use one effective model submitted to PAN-2013 as a baseline method. This enables us to have a more challenging baseline (in comparison to random guess) that reflects and can be adapted to the difficulty of a certain corpus. Finally, we provide tests of statistical significance to examine whether there are important differences in the performance of the submitted methods, the baseline, and the meta-classifier.</p><p>In the remainder of this paper, Section 2 reviews previous work in author verification, Section 3 analytically describes the evaluation setup used at PAN-2014 and Section 4 presents the evaluation results in detail. A review of the submitted approaches is included in Section 5 and Section 6 summarizes the main conclusions that can be drawn and discusses future work directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Relevant Work</head><p>The author verification problem was first discussed in <ref type="bibr" coords="3,356.60,226.48,15.36,9.11" target="#b31">[32]</ref>. Based on a corpus of newspaper articles in Greek, they used multiple regression to produce a response function for a given author and a threshold value to determine whether or not a questioned document was by that author. False acceptance and false rejection rates were used to evaluate this model. The same metrics were used by <ref type="bibr" coords="3,394.44,272.44,16.82,9.11" target="#b36">[37]</ref> to evaluate an authorship verification method based on a rich set of linguistic features.</p><p>Perhaps the best-known approach for author verification, the unmasking method, was introduced in <ref type="bibr" coords="3,200.36,306.94,15.30,9.11" target="#b18">[19]</ref>. The main idea is to build a SVM classifier to distinguish the questioned document from the set of known documents, then to remove the most important features and repeat this process. In case the questioned and known documents are by the same author, the accuracy of the classifier significantly drops after a small number of repetitions while it remains relatively high when they are not by the same author. Accuracy and F 1 were used to evaluate this method that was very effective in long documents but fails when documents are relatively short <ref type="bibr" coords="3,451.40,375.94,15.41,9.11" target="#b32">[33]</ref>. Modifications and additional evaluation tests for the unmasking method can be found in <ref type="bibr" coords="3,135.06,398.94,16.68,9.11" target="#b33">[34]</ref> and <ref type="bibr" coords="3,171.14,398.94,15.30,9.11" target="#b15">[16]</ref>.</p><p>Luyckx and Daelemans approximated the author verification problem as a binary classification task by considering all available texts by other authors as negative examples <ref type="bibr" coords="3,166.70,433.44,15.40,9.11" target="#b21">[22]</ref>. They used recall, precision, and F 1 to evaluate their approach in a corpus of student essays in Dutch. Escalante et al. applied particle swarm model selection to select a suitable classifier for a given author <ref type="bibr" coords="3,374.98,456.48,10.65,9.11" target="#b4">[5]</ref>. They used F 1 and balanced error rate (the average of error rates for positive and negative class) to evaluate their approach on two corpora of English newswire stories and Spanish poems. More recently, Koppel and Winter proposed an effective method that attempts to transform authorship verification from a one-class classification task to a multiclass classification problem by introducing additional authors, the so-called impostors, using documents found in external sources (e.g., the Web) <ref type="bibr" coords="3,410.14,525.48,15.35,9.11" target="#b19">[20]</ref>. Accuracy and recall-precision graphs were used to evaluate this method.</p><p>Author verification was included in previous editions of the PAN evaluation lab. The author identification task at PAN-2011 <ref type="bibr" coords="3,323.12,559.92,11.68,9.11" target="#b0">[1]</ref> included 3 author verification problems, each comprising a number of texts (i.e., email messages) of known authorship, all by the same author, and a number of questioned texts (either by the author of the known texts or not). Performance was measured by macro-average precision, recall and F 1 . PAN-2013 was exclusively focused on the author verification problem <ref type="bibr" coords="3,160.56,617.46,15.41,9.11" target="#b14">[15]</ref>. New training and evaluation corpora were built on three languages (i.e., English, Greek, and Spanish) where each verification problem included at most 10 documents by the same author and exactly one questioned document. Beyond a binary answer for each verification problem, the participants could also produce (optionally) a probability-like score to indicate the confidence of a positive answer. Recall, precision, F 1 and ROC graphs were used to evaluate the performance of the 18 participants. Moreover, a simple meta-model combining all the submitted methods achieved the best overall performance. For the first time, software submissions were requested at PAN-2013 enabling reproducibility of the results and future evaluation on different corpora.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation Setup</head><p>PAN-2014 focuses on author verification, similar to PAN-2013. Given a set of known documents all written by the same author and exactly one questioned document, the task is to determine whether the questioned document was written by that particular author or not. Similar to the corresponding task at PAN-2013, best efforts were applied to ensure that all known and questioned documents within a problem are matched for genre, register, theme, and date of writing. In contrast to PAN-2013, the number of known documents is limited to at most 5, while a greater variety of languages and genres is covered. The text length of documents varies from a few hundred to a few thousand words, depending on the genre.</p><p>The participants were asked to submit their software and consider as input parameters the language and genre of the documents. For each verification problem, they should provide a score, a real number in [0,1], corresponding to the probability of a positive answer (i.e., the known and the questioned documents are by the same author). In case the participants wanted to leave some verification problems unanswered, they could assign a probability score of exactly 0.5 to those problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Corpus</head><p>The PAN-2014 corpus comprises author verification problems in four languages: Dutch, English, Greek, and Spanish. For Dutch and English there are two genres in separate parts of the corpus. An overview of the training and evaluation corpus of the author identification task is shown in Table <ref type="table" coords="4,305.70,500.94,3.76,9.11" target="#tab_0">1</ref>. As can be seen, beyond language and genre there is variety of known texts per problem and text-length. The size of both training and evaluation corpora is significantly larger than the corresponding corpora of PAN-2013. All corpora in both training and evaluation sets are balanced with respect to the number of positive and negative examples.</p><p>The Dutch corpus is a transformed version of the CLiPS Stylometry Investigation (CSI) corpus <ref type="bibr" coords="4,178.80,569.94,15.36,9.11" target="#b37">[38]</ref>. This recently released corpus contains documents from two genres: essays and reviews, which are the two Dutch genres present in the corpus for this task. All documents were written by language students at the University of Antwerp between 2012 and 2014. All authors are native speakers of Dutch. The CSI corpus was developed for use in computational stylometry research (i.e. detection of age, gender, personality, region of origin, etc.), but has many other purposes as well (e.g., deception detection, sentiment analysis). We adapted the CSI corpus to match the needs of the authorship verification task and ended up with 200 problem sets for the review genre and 192 problem sets in the essay genre. All verification problems include 1-5 known texts. The training and evaluation set each contain half of the problem sets in each genre.</p><p>The English essays corpus was derived from a previously existing corpus of English-as-second-language students. The Uppsala Student English (USE) corpus <ref type="bibr" coords="5,458.89,454.14,11.82,9.11" target="#b1">[2]</ref> was originally intended to become a tool for research on foreign languages learning. It consists of university-level full-time students' essays handed by electronic means. In this kind of texts stylistic awareness represents an important writing factor. The USE corpus includes clear borders between writings produced in the framework of three different terms: a, b, and c. Every essay is intended to be produced on personal, formal, or academic style. A total of 440 authors contributed with at least one essay to the corpus, resulting in 1,489 documents. The average size of an essay is 820 words. Typically, one student contributed with more than one essay, often surpassing the different terms. Taking advantage of the USE corpus meta-information, we defined two main constraints: every document in the collection, known or questioned, should contain at least 500 words and the number of known documents in a case must range between one and five. As a result of the first constraint, only 435 authors were considered. We also took advantage of the students' background information to set case-generation rules. Firstly, all the documents in a case must come from students from the same term (i.e., both were written within term a, b, or c). Secondly, we divided the students in age-based clusters. To form negative verification problems, based on the fact that the students' age ranged between 18 and 59 years, an author A was considered as candidate match for author A q according to the following rules:</p><p>-If A q is younger than 20 years old, A must be younger than 20 as well; -If A q is between 20 and 25 years old, A must be exactly the same age;</p><p>-If A q is between 26 and 30 years old, A must be in the same age range; and</p><p>-If A q is older than 30 years old, A must be older than 30 as well.</p><p>This combination of age-and term-related constraints allowed us to create cases where the authors come from similar backgrounds. During our generation process, the texts as in the USE corpus were slightly modified. Anonymization labels were substituted by a randomly chosen proper name in English. In order not to provide any hint about a case, the same name was used both in the questioned and known documents. One source USE document could be considered at most twice in the authorship verification corpus: once in a positive case and once in a negative case.</p><p>The English novels used in the PAN-2014 corpus represent an attempt to provide a narrower focus in terms of both content and writing style than many similar collections. Instead of simply focusing on a single genre or time period, they focus on a very small subgenre of speculative and horror fiction known generally as the "Cthulhu Mythos". This is specifically a shared-universe genre, based originally on the writings of the American H.P. Lovecraft (for this reason, the genre is also called "Lovecraftian horror"), a shared universe with a theme of human ineffectiveness in the face of a set of powerful named "cosmic horrors". It is also typically characterized by extremely florid prose and an unusual vocabulary. Perhaps most significantly, many of the elements of this genre are themselves unusual terms (e.g., unpronounceable proper names of these cosmic horrors such as "Cthulhu", "Nyarlathotep", "Lloigor", "Tsathoggua", or "Shub-Niggurath"), thus creating a strong shared element that is unusual in regular English prose. Similarly, the overall theme and tone of these stories is strongly negative (many of them, for example, take the form of classical tragedies and end with the death of the protagonist). For this reason, we feel that this testbed provides a number of unusual elements that may be appropriately explored as an example of a tightly controlled genre. The corpus covers an extended length of time, from Lovecraft's original work to modern fan-fiction. Documents were gathered from a variety of on-line sources including Project Gutenberg<ref type="foot" coords="6,166.94,501.50,3.00,5.45" target="#foot_0">1</ref> and FanFiction<ref type="foot" coords="6,237.98,501.50,3.00,5.45" target="#foot_1">2</ref> , and edited for uniformity of format; in some cases lengthy works were broken down into subsections based on internal divisions such as chapters or sections.</p><p>The Greek corpus comprises newspaper opinion articles published in the Greek weekly newspaper TO BHMA<ref type="foot" coords="6,250.34,547.46,3.00,5.45" target="#foot_2">3</ref> from 1996 to 2012. Note that the training corpus in Greek was formed based on the respective training and evaluation corpora of PAN-2013. The length of each article is at least 1,000 words while the number of known texts per problem varies between 1 to 5. In each verification problem, we included texts that had strong thematic similarities indicated by the occurrence of certain keywords. In contrast to PAN-2013, there was no stylistic analysis of the texts to indicate authors with very similar styles or texts of the same author with notable differences.</p><p>The Spanish corpus refers to the same genre as the Greek corpus. Newspaper opinion articles of the Spanish newspaper El Pais <ref type="foot" coords="7,342.98,160.92,3.00,5.45" target="#foot_3">4</ref> were considered and author verification problems were formed taking into account thematic similarities between articles as indicated by certain keywords used to index the articles in the website of this newspaper. All verification problems for this corpus include exactly five known texts, while the average text length is relatively large, exceeding 1,000 words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Performance measures</head><p>The probability scores provided by the participants are used to build ROC curves and the area under the curve (AUC) is used as a scalar evaluation measure. This is a wellknown evaluation technique for binary classifiers <ref type="bibr" coords="7,333.91,286.18,10.66,9.11" target="#b5">[6]</ref>. In addition, the performance measures used in this task should be able to take unanswered problems into account. Similarly to other tasks, like question answering, it is preferred to leave the problem unanswered rather than responding incorrectly when there is great uncertainty. The measures of recall and precision used at PAN-2013 were not able to reward submissions that left problems unanswered while maintaining high accuracy in given answers.</p><p>In the current evaluation setup we adopted the c@1 measure, originally proposed for question answering tasks, which explicitly extends accuracy based on the number of problems left unanswered <ref type="bibr" coords="7,249.06,389.64,15.36,9.11" target="#b26">[27]</ref>. More specifically, to use this measure we first transform probability scores to binary answers. Every score greater than 0.5 is considered as a positive answer (i.e., the known and questioned documents are by the same author), every score lower than 0.5 is considered as a negative answer (i.e., the known and questioned documents are by different authors) while all scores equal to 0.5 correspond to unanswered problems. Then, c@1 is defined as follows:</p><formula xml:id="formula_0" coords="7,337.76,467.16,3.34,9.11">)</formula><p>where n is the number of problems, n c is the number of correct answers, and n u is the number of problems left unanswered. If a participant would provide an answer different from 0.5 for all problems, then c@1 will be equal to accuracy. If all problems are left unanswered, then c@1 will be zero. If only some problems are left unanswered, this measure will be increased as if these problems were answered with the same accuracy as the rest of the problems. Therefore, this measure rewards participants that maintain a high number of correct answers, for which there is great confidence, and decrease the number of incorrect answers, for uncertain cases, by leaving them unanswered.</p><p>To provide a final rank of participants, AUC and c@1 are combined in the final score which is merely the product of these two measures. In addition, the efficiency of the submitted methods is measured in terms of elapsed runtime.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Baseline</head><p>The author verification task has a random guess baseline of 0.5 for both AUC and c@1. However, this baseline is not challenging. What we need is a baseline that corresponds to a standard method so that we know what submissions are really better than the state of the art. Moreover, since the evaluation corpus comprises several languages and genres, we need a baseline that can reflect and adapt to the difficulty of a specific corpus.</p><p>Based on the submissions of the author identification task at PAN-2013, it is possible to use state-of-the-art methods (in particular, the PAN-2013 winners) and apply them to PAN-2014 corpus. However, since the PAN-2014 task comprises more languages, we need a language-independent approach. In addition, we need a method that can provide both binary answers and probability scores (the latter was optional at PAN-2013). Based on these requirements, we selected the approach of <ref type="bibr" coords="8,418.27,298.66,16.87,9.11" target="#b10">[11]</ref> to serve as baseline. More specifically, this approach has the following characteristics:</p><p>-It is language-independent.</p><p>-It can provide both binary answers and real scores.</p><p>-The real scores are already calibrated to probability-like scores for a positive answer (i.e., all scores greater than 0.5 correspond to a positive answer).</p><p>-It was the winner of PAN-2013 in terms of overall AUC scores.</p><p>It should be noted that this baseline method has not been specifically trained on the corpora of PAN-2014, so its performance is not optimized. It can only be viewed as a general method that can be applied to any corpus. Moreover, this approach does not leave problems unanswered, so it cannot take advantage of the new performance measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Meta-classifier</head><p>Following the practice of PAN-2013, we examine the performance of a meta-model that combines all answers given by the participants for each problem. We define a straight-forward meta-classifier that calculates the average of the probability scores provided by the participants for each problem. It can be seen as a heterogeneous ensemble model that combines base classifiers corresponding to different approaches. Note that the average of all the provided answers is not likely to be exactly 0.5; hence, this meta-model very rarely leaves problems unanswered. This meta-model can be naturally extended by allowing all answers with a score between 0.5-a and 0.5+a to become equal to 0.5. However, since the parameter a should be tuned to an arbitrary predefined value or be optimized for each language/genre, we decided not to perform such an extension.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Evaluation Results</head><p>We received 13 submissions from research teams in Australia, Canada (2), France, Germany (2), India, Iran, Ireland, Mexico (2), United Arab Emirates, and United Kingdom. The participants submitted and evaluated their author verification software within the TIRA framework <ref type="bibr" coords="9,240.08,469.92,10.61,9.11" target="#b7">[8]</ref>. A separate run for each corpus corresponding to each language and genre was performed.</p><p>The overall results of the task concerning the performance of the submitted approaches in the whole evaluation corpus are shown in Table <ref type="table" coords="9,389.77,504.42,3.76,9.11" target="#tab_1">2</ref>. These evaluation scores are the result of micro-averaging over the set of 796 verification problems. Put in other words, each verification problem has the same weight in this analysis, so the language and genre information are not taken into account. As can be seen, the overall winner method of Khonji and Iraqi <ref type="bibr" coords="9,267.20,550.44,16.72,9.11" target="#b16">[17]</ref> achieved the best results in terms of AUC and was also very effective in terms of c@1. On the other hand, it was one of the less efficient methods requiring about 21 hours for processing the whole evaluation corpus. The second best submission by Frery et al. <ref type="bibr" coords="9,336.50,584.94,11.68,9.11" target="#b6">[7]</ref> was much more efficient and achieved the best c@1 score. In general, most of the submitted methods outperformed the baseline. It has to be emphasized that the best five participants were able to leave some problems unanswered. In total 4 out of the 13 participants answered all problems. Moreover, one participant provided binary answers instead of probability scores <ref type="bibr" coords="9,152.53,642.42,16.67,9.11" target="#b35">[36]</ref> and one participant did not process the Greek corpus <ref type="bibr" coords="9,387.02,642.42,15.46,9.11" target="#b9">[10]</ref>. With respect to the meta-classifier, which is averaging the answers of all 13 participants, its performance is significantly better than each individual system, achieving a final score greater than 0.5. Tables 3-8 present the evaluation results on each of the six corpora separately. In all tables, the best performing submission (excluding the meta-classifier and the baseline method) is in boldface. In terms of average performance of all submitted approaches, the corpus of Dutch essays seems to be the easiest while the corpus of Dutch reviews to be the hardest one. The latter can be partially explained by the fact that the corpus provides only one known document per problem and that it contains only short texts. Moreover, the availability of multiple relatively long known documents seems to assist the submitted systems to achieve a better average performance on the Greek and Spanish corpora compared to the English corpora of essays and novels. There is a different winner for each corpus with the exception of <ref type="bibr" coords="13,124.76,276.16,16.72,9.11" target="#b16">[17]</ref> who won on both Greek and Spanish corpora. This might indicate a better tuning of their approach for newspaper opinion articles rather than essays, reviews or novels. However, the performance of this submission on all corpora is notable since it is usually included in the first 3-best performing methods with the exception of the English essays where it is ranked 6th (excluding the meta-classifier).</p><p>The performance of the baseline method varies. In the English and Spanish corpora it is relatively low. In the Dutch and Greek corpora it is very challenging, outperforming almost half of the participants. In addition, the meta-classifier is very effective on all corpora. However, it is outperformed by some individual participants on three corpora. Another interesting remark is that the problems left unanswered by most participants are not evenly distributed across the corpora. The majority of the problems left unanswered by Castillo et al. <ref type="bibr" coords="13,315.50,402.66,11.74,9.11" target="#b3">[4]</ref> refer to Dutch reviews (possibly reflecting the difficulty of this corpus). Similarly, Moreau et al. <ref type="bibr" coords="13,390.58,414.18,16.72,9.11" target="#b24">[25]</ref> did not answer many problems of Dutch essays while most of the unanswered problems of Frery et al. <ref type="bibr" coords="13,137.96,437.16,11.74,9.11" target="#b6">[7]</ref> belong to English essays and Greek articles. On the other hand, Mayor et al. <ref type="bibr" coords="13,124.76,448.68,16.72,9.11" target="#b22">[23]</ref> left at least one problem unanswered in each corpus.</p><p>The ROC curves of the best performing participants on the whole evaluation corpus are shown in Figure <ref type="figure" coords="13,244.63,471.66,3.76,9.11" target="#fig_0">1</ref>. More specifically, the convex hull of all submitted approaches together with the participants' curves who are part of the convex hull are shown. The overall winning approach of Khonji and Iraqi <ref type="bibr" coords="13,368.98,494.64,16.72,9.11" target="#b16">[17]</ref> and the second-best method of Frery et al. <ref type="bibr" coords="13,214.88,506.16,11.74,9.11" target="#b6">[7]</ref> dominate the convex hull in case the false positive and false negative errors have the same cost <ref type="bibr" coords="13,265.52,517.62,10.61,9.11" target="#b5">[6]</ref>. In low values of FPR in the ROC space, where the cost of false positives is considered higher than the cost of false negatives, the approach of Modaresi and Gross <ref type="bibr" coords="13,267.68,540.66,16.72,9.11" target="#b22">[23]</ref> is the best. On the other hand, if the false negatives have larger cost than the false positives, in large values of FPR in the ROC space, the approach of Moreau et al. <ref type="bibr" coords="13,282.98,563.64,16.78,9.11" target="#b24">[25]</ref> is the most effective. Note also that the submission by Castillo et al. <ref type="bibr" coords="13,244.10,575.16,10.65,9.11" target="#b3">[4]</ref>, ranked in the 3 rd position in the overall results (see Table <ref type="table" coords="13,153.07,586.62,3.62,9.11" target="#tab_1">2</ref>), is not part of the convex hull meaning that this approach is always outperformed by another approach no matter the cost of the false positives and false negatives.</p><p>In addition, Figure <ref type="figure" coords="13,214.35,621.12,5.01,9.11" target="#fig_0">1</ref> depicts the ROC curves of the baseline method and the metaclassifier. The baseline is clearly less effective than the best participants. It outperforms only Frery et al. <ref type="bibr" coords="13,247.22,644.16,11.74,9.11" target="#b6">[7]</ref> in very low values of FPR. On the other hand, the meta-classifier clearly outperforms the convex hull of all the submitted methods in the whole range of the curve. This means that the meta-classifier is more effective than any individual submission for any given cost of false positives and false negatives.</p><p>We computed statistical significance of performance differences between systems using approximate randomization testing <ref type="bibr" coords="14,296.08,516.30,16.76,9.11" target="#b25">[26]</ref>  <ref type="foot" coords="14,312.74,516.08,3.00,5.45" target="#foot_4">5</ref> . As noted by <ref type="bibr" coords="14,376.78,516.30,16.72,9.11" target="#b38">[39]</ref> among others, for comparing outputs from classifiers, frequently used statistical significance tests such as paired t-tests make assumptions that do not hold for precision scores and F-scores. Approximate randomisation testing does not make these assumptions and can handle complicated distributions. We did a pairwise comparison of accuracy of all systems based on this method and the results are shown in Table <ref type="table" coords="14,353.69,573.78,3.76,9.11">9</ref>. The null hypothesis is that there is no difference in the output of two systems. When the probability of accepting the null hypothesis is p &lt; 0.05 we consider the systems to be significantly different from each other. When p &lt; 0.001 the difference is highly significant, when 0.001 &lt; p &lt; 0.01 the difference is very significant, and when 0.01 &lt; p &lt; 0.05 the difference is significant. Based on this analysis, it is easy to see that there are no significant differences in systems of neighboring rank. The winner submission of <ref type="bibr" coords="15,385.79,650.48,16.82,9.11" target="#b16">[17]</ref> is either very significantly or highly significantly better than the rest of the approaches (with the exception of the second winner <ref type="bibr" coords="15,269.88,673.52,10.54,9.11" target="#b6">[7]</ref>). In addition, the meta-classifier is highly significantly better than all the participants except for the first two winners.</p><p>Table <ref type="table" coords="15,148.28,151.25,3.38,8.10">9</ref>. Pairwise significance tests for the entire evaluation corpus. Significant differences are marked with asterisks, *** corresponds to highly significant difference (p &lt; 0.001), ** corresponds to very significant difference (0.001 &lt; p &lt; 0.01), * corresponds to significant difference (0.01 &lt; p &lt; 0.05), while = means the difference is not significant (p &gt; 0.05). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Survey of Submissions</head><p>Among 13 participant approaches, 7 were submitted by teams that had participated also in the PAN-2013 competition. Some of them attempted to improve the method proposed in 2013 <ref type="bibr" coords="16,196.76,200.44,10.84,9.11" target="#b8">[9,</ref><ref type="bibr" coords="16,210.08,200.44,12.53,9.11" target="#b11">12,</ref><ref type="bibr" coords="16,225.08,200.44,12.53,9.11" target="#b20">21,</ref><ref type="bibr" coords="16,240.07,200.44,13.37,9.11" target="#b35">36]</ref> and others presented new models <ref type="bibr" coords="16,391.05,200.44,10.97,9.11" target="#b3">[4,</ref><ref type="bibr" coords="16,404.50,200.44,12.53,9.11" target="#b22">23,</ref><ref type="bibr" coords="16,419.44,200.44,11.91,9.11" target="#b24">25]</ref>.</p><p>All the submitted approaches can be described according to some basic properties. First, an author verification method is either intrinsic or extrinsic. For each verification problem, intrinsic methods use only the known texts and the unknown text of that problem to make some analysis and decide whether they are by the same author or not. They don't make use of any other texts by other authors. The majority of submitted approaches falls into this category <ref type="bibr" coords="16,316.70,269.44,10.88,9.11" target="#b3">[4,</ref><ref type="bibr" coords="16,330.02,269.44,7.54,9.11" target="#b6">7,</ref><ref type="bibr" coords="16,340.04,269.44,7.51,9.11" target="#b8">9,</ref><ref type="bibr" coords="16,350.05,269.44,12.46,9.11" target="#b9">10,</ref><ref type="bibr" coords="16,365.02,269.44,12.53,9.11" target="#b11">12,</ref><ref type="bibr" coords="16,380.05,269.44,12.53,9.11" target="#b20">21,</ref><ref type="bibr" coords="16,395.08,269.44,12.46,9.11" target="#b23">24,</ref><ref type="bibr" coords="16,410.08,269.44,12.46,9.11" target="#b24">25,</ref><ref type="bibr" coords="16,425.08,269.44,12.53,9.11" target="#b28">29,</ref><ref type="bibr" coords="16,440.08,269.44,11.87,9.11" target="#b35">36]</ref>. On the other hand, extrinsic methods attempt to transform author verification from a oneclass classification task (where the known texts are the positive examples and there are no negative examples) to a binary classification task (where documents by other authors play the role of the negative examples). To this end, for each verification problem, extrinsic methods need additional documents by other authors found in external resources. The approaches of <ref type="bibr" coords="16,278.88,338.44,15.84,9.11" target="#b16">[17,</ref><ref type="bibr" coords="16,297.26,338.44,12.53,9.11" target="#b22">23,</ref><ref type="bibr" coords="16,312.32,338.44,13.36,9.11" target="#b39">40]</ref> belong to this category. The winner submission of PAN-2014 by <ref type="bibr" coords="16,248.22,349.96,16.80,9.11" target="#b16">[17]</ref> is a modification of the Impostors method <ref type="bibr" coords="16,451.46,349.96,15.31,9.11" target="#b19">[20]</ref>, similarly to PAN-2013 <ref type="bibr" coords="16,230.71,361.42,15.30,9.11" target="#b29">[30]</ref>, where a corpus of external documents for each language/genre was used.</p><p>Another important characteristic of a verification method is its type of learning. There are lazy approaches where the training phase is nearly omitted and all necessary processing is performed at the time they have to decide about a new verification problem. Most of the submitted approaches follow this idea <ref type="bibr" coords="16,371.03,418.98,10.99,9.11" target="#b3">[4,</ref><ref type="bibr" coords="16,385.09,418.98,7.51,9.11" target="#b8">9,</ref><ref type="bibr" coords="16,395.74,418.98,12.53,9.11" target="#b9">10,</ref><ref type="bibr" coords="16,411.34,418.98,12.53,9.11" target="#b11">12,</ref><ref type="bibr" coords="16,426.94,418.98,12.53,9.11" target="#b16">17,</ref><ref type="bibr" coords="16,442.54,418.98,12.53,9.11" target="#b20">21,</ref><ref type="bibr" coords="16,458.14,418.98,12.53,9.11" target="#b22">23,</ref><ref type="bibr" coords="16,124.76,430.44,12.53,9.11" target="#b28">29,</ref><ref type="bibr" coords="16,140.06,430.44,12.53,9.11" target="#b35">36,</ref><ref type="bibr" coords="16,155.30,430.44,11.91,9.11" target="#b39">40]</ref>. On the other hand, eager methods attempt to build a general model based on the training corpus. For example, <ref type="bibr" coords="16,278.21,441.96,11.83,9.11" target="#b6">[7]</ref> builds a decision tree for each corpus, <ref type="bibr" coords="16,453.90,441.96,16.81,9.11" target="#b24">[25]</ref> apply a genetic algorithm to find the characteristics of the verification model for each corpus, and <ref type="bibr" coords="16,173.73,464.94,16.77,9.11" target="#b23">[24]</ref> use fuzzy C-means clustering to extract a general description of each corpus. Since eager methods perform most of the necessary calculations in the training phase, they are generally more efficient in terms of runtime.</p><p>With respect to the features used for text representation, the majority of the participant methods focused on low-level measures. More specifically most of the proposed features are either character measures (i.e., punctuation mark counts, prefix/suffix counts, character n-grams, etc.) or lexical measures (i.e., vocabulary richness measures, sentence/word length counts, stopword frequency, n-grams of words/stopwords, word skip-grams, etc.). There were a few attempts to incorporate syntactic features, namely POS tag counts <ref type="bibr" coords="16,309.01,568.44,15.96,9.11" target="#b16">[17,</ref><ref type="bibr" coords="16,329.72,568.44,12.53,9.11" target="#b24">25,</ref><ref type="bibr" coords="16,346.94,568.44,11.87,9.11" target="#b39">40]</ref>, while one approach was exclusively based on that type of information <ref type="bibr" coords="16,308.33,579.96,15.37,9.11" target="#b9">[10]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>The author identification task at PAN-2014 focused on the author verification problem. The task definition was practically the same as in PAN-2013. However, this year we substantially enlarged both training and evaluation corpora and enriched them to include several languages and genres. In that way, we enabled participants to study how they can adapt and fine-tune their approaches according to a given language and genre. Another important novelty was the use of different performance measures that put emphasis on both the appropriate ranking of the provided answers in terms of confidence (AUC) as well as the ability of the submitted systems to leave some problems unanswered when there is great uncertainty (c@1). We believe that this combination of performance measures is more appropriate for author verification, a cost-sensitive task.</p><p>Similar to PAN-2013, the overall winner was a modification of the Impostors method <ref type="bibr" coords="17,157.74,241.66,15.32,9.11" target="#b16">[17]</ref>. The performance of this approach was notably stable in all six different corpora despite the fact that it did not leave many problems unanswered. This demonstrates the great potential of extrinsic verification methods. In addition, the significantly larger training corpus allowed participants to explore, for the first time, the use of eager learning methods in the author verification task. Such an approach may be both effective and efficient as it is demonstrated by the overall performance and runtime of the second overall winner <ref type="bibr" coords="17,291.66,310.66,10.62,9.11" target="#b6">[7]</ref>.</p><p>We received 13 software submissions, a reduced figure in comparison to 18 submissions at PAN-2013, possibly due to the greater difficulty of the task. Moreover, this year the evaluation of the submitted systems was performed by participants themselves using the TIRA framework <ref type="bibr" coords="17,299.32,356.62,10.63,9.11" target="#b7">[8]</ref>. Seven participants from PAN-2013 submitted their approaches again this year. It is remarkable that those teams that slightly modified their existing approach did not achieve a high performance <ref type="bibr" coords="17,443.90,379.66,10.84,9.11" target="#b8">[9,</ref><ref type="bibr" coords="17,458.14,379.66,12.53,9.11" target="#b11">12,</ref><ref type="bibr" coords="17,124.76,391.14,12.53,9.11" target="#b20">21,</ref><ref type="bibr" coords="17,140.06,391.14,11.91,9.11" target="#b35">36]</ref>. On the other hand, the teams that radically changed their approach, including the ability to leave some problems unanswered, achieved very good results <ref type="bibr" coords="17,443.30,402.66,10.87,9.11" target="#b3">[4,</ref><ref type="bibr" coords="17,458.14,402.66,12.53,9.11" target="#b22">23,</ref><ref type="bibr" coords="17,124.76,414.18,11.91,9.11" target="#b24">25]</ref>.</p><p>Based on the software submissions at PAN-2013, we were able to define a challenging baseline method that is better than random guessing and can reflect the difficulty of the examined corpus. In many cases, the baseline method was ranked in the middle of the participants list, clearly showing the approaches with notable performance. Given the enhanced set of methods for author verification, collected at PAN-2013 and PAN-2014, we think that it will be possible to further improve the quality of the baseline methods in future competitions. Moreover, following the successful practice of PAN-2013, we examined the performance of a meta-model that combines all submitted systems in a heterogeneous ensemble. This meta-classifier was better than each individual submitted method while its ROC curve clearly outperformed the convex hull of all submitted approaches. This demonstrates the great potential of heterogeneous models in author verification, a practically unexplored area.</p><p>For the first time, we applied statistical significance tests on the results of the submitted methods to highlight the real differences between them. According to these tests, there is no significant difference between systems ranked in neighboring positions. However, there are highly significant differences between the winner approach and the rest of the submissions (with the exception of the second winner). We believe that such significance tests are absolutely necessary to extract reliable conclusions and we are going to adopt them in future evaluation labs.</p><p>One of our ambitions in this task was to involve experts from forensic linguistics so that they can manually (or semi-automatically) analyze the same corpora and submit their answers. This could serve as another very interesting baseline approach that would enable the comparison of fully-automated systems with traditional human expert methods. Unfortunately, this attempt was not successful. So far, we were not able to find experts in forensic linguistics willing to participate or to devote the necessary time to solve a large amount of author verification problems under certain time constraints. We are still working on this direction.</p><p>We believe that the focus of PAN-2013 and PAN-2014 on the author verification task has produced a significant progress in this field concerning the development of new corpora and new methods as well as in defining an appropriate evaluation framework. Clearly, author verification is far from being a solved task and there are many variations that can be explored in future evaluation labs including cross-topic and cross-genre verification (i.e., where the known and the questioned documents do not match in terms of topic/genre) and very short text verification (i.e., where the documents are tweets or SMS messages).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="14,125.78,471.85,336.80,8.10;14,125.78,482.89,115.22,8.10"><head>Fig. 1 .</head><label>1</label><figDesc>Fig.1. ROC graphs of the best performing submissions and their convex hull, the baseline method, and the meta-classifier.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="15,191.21,204.74,8.10,25.00;15,191.21,232.03,8.10,7.00;15,191.21,241.25,8.10,16.95;15,211.13,204.74,8.10,19.49;15,211.13,226.51,8.10,6.50;15,211.13,235.26,8.10,8.75;15,231.11,204.74,8.10,28.06;15,231.11,235.01,8.10,6.46;15,231.11,243.76,8.10,8.71;15,251.03,204.74,8.10,28.01;15,251.03,235.02,8.10,6.46;15,251.03,243.73,8.10,8.72;15,271.01,204.74,8.10,23.99;15,271.01,231.01,8.10,6.50;15,271.01,239.76,8.10,8.75;15,290.93,204.74,8.10,27.49;15,290.93,234.49,8.10,6.50;15,290.93,243.23,8.10,8.73;15,310.91,204.74,8.10,27.04;15,310.91,234.00,8.10,6.50;15,310.91,242.75,8.10,8.75;15,330.95,204.74,8.10,34.01;15,330.95,241.00,8.10,7.00;15,330.95,250.25,8.10,20.93;15,350.87,204.74,8.10,39.46;15,350.87,246.49,8.10,6.50;15,350.87,255.24,8.10,8.73;15,370.87,204.74,8.10,28.53;15,370.87,235.49,8.10,7.00;15,370.87,244.76,8.10,39.49;15,390.79,204.74,8.10,43.49;15,410.77,204.74,8.10,49.97;15,410.77,256.96,8.10,7.00;15,410.77,266.21,8.10,25.00;15,430.69,204.74,28.08,26.51;15,129.80,305.15,28.50,8.10;15,129.80,315.47,50.46,8.10;15,196.52,309.83,4.48,9.00;15,216.50,309.83,244.08,9.00;15,129.80,327.83,34.29,8.10;15,129.80,338.15,17.01,8.10;15,216.50,332.51,244.08,9.00;15,129.80,355.73,39.26,8.10;15,236.42,355.19,4.48,9.00;15,256.40,355.19,4.48,9.00;15,276.32,355.19,4.48,9.00;15,296.30,355.19,4.48,9.00;15,316.28,355.19,4.48,9.00;15,336.26,355.19,4.48,9.00;15,356.18,355.19,104.40,9.00;15,129.80,378.41,47.73,8.10;15,256.40,377.93,4.48,9.00;15,276.32,377.93,4.48,9.00;15,296.30,377.93,4.48,9.00;15,316.28,377.93,4.48,9.00;15,336.26,377.93,4.48,9.00;15,356.18,377.93,4.48,9.00;15,376.18,377.93,44.44,9.00;15,436.00,377.93,24.58,9.00;15,129.80,401.11,47.71,8.10;15,276.32,400.63,4.48,9.00;15,296.30,400.63,4.48,9.00;15,316.28,400.63,4.48,9.00;15,336.26,400.63,4.48,9.00;15,356.18,400.63,4.48,9.00;15,376.18,400.63,4.48,9.00;15,396.10,400.63,4.48,9.00;15,416.08,400.63,4.48,9.00;15,436.00,400.63,24.58,9.00;15,129.80,423.85,43.76,8.10;15,296.30,423.31,4.48,9.00;15,316.28,423.31,4.48,9.00;15,336.26,423.31,4.48,9.00;15,356.18,423.31,104.40,9.00;15,129.80,446.53,47.22,8.10;15,316.28,446.05,4.48,9.00;15,336.26,446.05,4.48,9.00;15,356.18,446.05,104.40,9.00;15,129.80,469.21,46.72,8.10;15,336.26,468.73,4.48,9.00;15,356.18,468.73,104.40,9.00;15,129.80,486.73,43.26,8.10;15,129.80,497.11,20.96,8.10;15,356.18,491.41,4.48,9.00;15,376.18,491.41,24.46,9.00;15,416.08,491.41,4.48,9.00;15,436.00,491.41,24.58,9.00;15,129.80,509.47,48.25,8.10;15,129.80,519.79,8.80,8.10;15,376.18,514.15,24.46,9.00;15,416.08,514.15,4.48,9.00;15,436.00,514.15,24.58,9.00;15,129.80,532.15,37.75,8.10;15,129.80,542.47,39.52,8.10;15,396.10,536.83,4.48,9.00;15,416.08,536.83,4.48,9.00;15,436.00,536.83,24.58,9.00;15,129.80,560.05,43.49,8.10;15,416.08,559.51,4.48,9.00;15,436.00,559.51,4.48,9.00;15,456.04,559.51,4.48,9.00;15,129.80,577.57,49.97,8.10;15,129.80,587.89,34.29,8.10;15,436.00,582.25,24.58,9.00;15,129.80,605.41,25.53,8.10;15,451.60,604.93,8.98,9.00"><head>Frery</head><label></label><figDesc>* *** *** *** *** *** *** *** *** *** *** *** Khonji &amp; Iraqi = ** *** ** ** ** ** ** *** *** *** *** ***</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,127.82,161.87,337.02,261.68"><head>Table 1 .</head><label>1</label><figDesc>Statistics of the training and evaluation corpora used in the author identification task at PAN-2014.</figDesc><table coords="5,142.76,192.59,307.36,230.96"><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Avg. of</cell><cell>Avg.</cell></row><row><cell></cell><cell>Language</cell><cell>Genre</cell><cell cols="2">#Problems #Docs</cell><cell>known docs per</cell><cell>words per</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>problem</cell><cell>document</cell></row><row><cell></cell><cell>Dutch</cell><cell>Essays</cell><cell>96</cell><cell>268</cell><cell>1.8</cell><cell>412.4</cell></row><row><cell></cell><cell>Dutch</cell><cell>Reviews</cell><cell>100</cell><cell>202</cell><cell>1.0</cell><cell>112.3</cell></row><row><cell></cell><cell>English</cell><cell>Essays</cell><cell>200</cell><cell>729</cell><cell>2.6</cell><cell>848.0</cell></row><row><cell>Training</cell><cell>English</cell><cell>Novels</cell><cell>100</cell><cell>200</cell><cell>1.0</cell><cell>3,137.8</cell></row><row><cell></cell><cell>Greek</cell><cell>Articles</cell><cell>100</cell><cell>385</cell><cell>2.9</cell><cell>1,404.0</cell></row><row><cell></cell><cell>Spanish</cell><cell>Articles</cell><cell>100</cell><cell>600</cell><cell>5.0</cell><cell>1,135.6</cell></row><row><cell></cell><cell cols="2">Total</cell><cell>696</cell><cell>2,384</cell><cell>2.4</cell><cell>1,091.0</cell></row><row><cell></cell><cell>Dutch</cell><cell>Essays</cell><cell>96</cell><cell>287</cell><cell>2.0</cell><cell>398.1</cell></row><row><cell></cell><cell>Dutch</cell><cell>Reviews</cell><cell>100</cell><cell>202</cell><cell>1.0</cell><cell>116.3</cell></row><row><cell></cell><cell>English</cell><cell>Essays</cell><cell>200</cell><cell>718</cell><cell>2.6</cell><cell>833.2</cell></row><row><cell>Evaluation</cell><cell>English</cell><cell>Novels</cell><cell>200</cell><cell>400</cell><cell>1.0</cell><cell>6,104.0</cell></row><row><cell></cell><cell>Greek</cell><cell>Articles</cell><cell>100</cell><cell>368</cell><cell>2.7</cell><cell>1,536.6</cell></row><row><cell></cell><cell>Spanish</cell><cell>Articles</cell><cell>100</cell><cell>600</cell><cell>5.0</cell><cell>1,121.4</cell></row><row><cell></cell><cell cols="2">Total</cell><cell>796</cell><cell>2,575</cell><cell>2.2</cell><cell>1,714.9</cell></row><row><cell>TOTAL</cell><cell></cell><cell></cell><cell>1,492</cell><cell>4,959</cell><cell>2.3</cell><cell>1,415.0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="9,132.56,151.91,331.74,220.08"><head>Table 2 .</head><label>2</label><figDesc>Overall evaluation results of the author identification task at PAN-2014.</figDesc><table coords="9,132.56,171.41,331.74,200.58"><row><cell>Rank</cell><cell></cell><cell cols="2">FinalScore AUC</cell><cell>c@1</cell><cell>Runtime</cell><cell>Unansw. Problems</cell></row><row><cell></cell><cell>META-CLASSIFIER</cell><cell>0.566</cell><cell>0.798</cell><cell>0.710</cell><cell></cell><cell>0</cell></row><row><cell>1</cell><cell>Khonji &amp; Iraqi</cell><cell>0.490</cell><cell>0.718</cell><cell>0.683</cell><cell>20:59:40</cell><cell>2</cell></row><row><cell>2</cell><cell>Frery et al.</cell><cell>0.484</cell><cell>0.707</cell><cell>0.684</cell><cell>00:06:42</cell><cell>28</cell></row><row><cell>3</cell><cell>Castillo et al.</cell><cell>0.461</cell><cell>0.682</cell><cell>0.676</cell><cell>03:59:04</cell><cell>78</cell></row><row><cell>4</cell><cell>Moreau et al.</cell><cell>0.451</cell><cell>0.703</cell><cell>0.641</cell><cell>01:07:34</cell><cell>50</cell></row><row><cell>5</cell><cell>Mayor et al.</cell><cell>0.450</cell><cell>0.690</cell><cell>0.651</cell><cell>05:26:17</cell><cell>29</cell></row><row><cell>6</cell><cell>Zamani et al.</cell><cell>0.426</cell><cell>0.682</cell><cell>0.624</cell><cell>02:37:25</cell><cell>0</cell></row><row><cell>7</cell><cell>Satyam et al.</cell><cell>0.400</cell><cell>0.631</cell><cell>0.634</cell><cell>02:52:37</cell><cell>7</cell></row><row><cell>8</cell><cell>Modaresi &amp; Gross</cell><cell>0.375</cell><cell>0.610</cell><cell>0.614</cell><cell>00:00:38</cell><cell>0</cell></row><row><cell>9</cell><cell>Jankowska et al.</cell><cell>0.367</cell><cell>0.609</cell><cell>0.602</cell><cell>07:38:18</cell><cell>7</cell></row><row><cell>10</cell><cell>Halvani &amp; Steinebach</cell><cell>0.335</cell><cell>0.595</cell><cell>0.564</cell><cell>00:00:54</cell><cell>3</cell></row><row><cell></cell><cell>BASELINE</cell><cell>0.325</cell><cell>0.587</cell><cell>0.554</cell><cell>00:21:10</cell><cell>0</cell></row><row><cell>11</cell><cell>Vartapetiance &amp; Gillam</cell><cell>0.308</cell><cell>0.555</cell><cell>0.555</cell><cell>01:07:39</cell><cell>0</cell></row><row><cell>12</cell><cell>Layton</cell><cell>0.306</cell><cell>0.548</cell><cell>0.559</cell><cell>27:00:01</cell><cell>0</cell></row><row><cell>13</cell><cell>Harvey</cell><cell>0.304</cell><cell>0.558</cell><cell>0.544</cell><cell>01:06:19</cell><cell>100</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="10,141.14,173.15,308.10,220.10"><head>Table 3 .</head><label>3</label><figDesc>Evaluation results on the evaluation corpus of Dutch essays.</figDesc><table coords="10,141.14,192.65,308.10,200.60"><row><cell></cell><cell>FinalScore</cell><cell>AUC</cell><cell>c@1</cell><cell>Runtime</cell><cell>Unansw. Problems</cell></row><row><cell>META-CLASSIFIER</cell><cell>0.867</cell><cell>0.957</cell><cell>0.906</cell><cell></cell><cell>0</cell></row><row><cell>Mayor et al.</cell><cell>0.823</cell><cell>0.932</cell><cell>0.883</cell><cell>00:15:05</cell><cell>2</cell></row><row><cell>Frery et al.</cell><cell>0.821</cell><cell>0.906</cell><cell>0.906</cell><cell>00:00:30</cell><cell>0</cell></row><row><cell>Khonji &amp; Iraqi</cell><cell>0.770</cell><cell>0.913</cell><cell>0.844</cell><cell>00:58:21</cell><cell>0</cell></row><row><cell>Moreau et al.</cell><cell>0.755</cell><cell>0.907</cell><cell>0.832</cell><cell>00:02:09</cell><cell>34</cell></row><row><cell>Castillo et al.</cell><cell>0.741</cell><cell>0.861</cell><cell>0.861</cell><cell>00:01:57</cell><cell>2</cell></row><row><cell>Jankowska et al.</cell><cell>0.732</cell><cell>0.869</cell><cell>0.842</cell><cell>00:23:26</cell><cell>1</cell></row><row><cell>BASELINE</cell><cell>0.685</cell><cell>0.865</cell><cell>0.792</cell><cell>00:00:52</cell><cell>0</cell></row><row><cell>Zamani et al.</cell><cell>0.525</cell><cell>0.741</cell><cell>0.708</cell><cell>00:00:27</cell><cell>0</cell></row><row><cell>Vartapetiance &amp; Gillam</cell><cell>0.517</cell><cell>0.719</cell><cell>0.719</cell><cell>00:06:37</cell><cell>0</cell></row><row><cell>Satyam et al.</cell><cell>0.489</cell><cell>0.651</cell><cell>0.750</cell><cell>00:01:21</cell><cell>0</cell></row><row><cell>Halvani &amp; Steinebach</cell><cell>0.399</cell><cell>0.647</cell><cell>0.617</cell><cell>00:00:06</cell><cell>2</cell></row><row><cell>Harvey</cell><cell>0.396</cell><cell>0.644</cell><cell>0.615</cell><cell>00:02:19</cell><cell>0</cell></row><row><cell>Modaresi &amp; Gross</cell><cell>0.378</cell><cell>0.595</cell><cell>0.635</cell><cell>00:00:05</cell><cell>0</cell></row><row><cell>Layton</cell><cell>0.307</cell><cell>0.546</cell><cell>0.563</cell><cell>00:55:07</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="10,141.14,412.99,308.04,209.82"><head>Table 4 .</head><label>4</label><figDesc>Evaluation results on the evaluation corpus of Dutch reviews.</figDesc><table coords="10,141.14,432.49,308.04,190.32"><row><cell></cell><cell>FinalScore</cell><cell>AUC</cell><cell>c@1</cell><cell>Runtime</cell><cell>Unansw. Problems</cell></row><row><cell>Satyam et al.</cell><cell>0.525</cell><cell>0.757</cell><cell>0.694</cell><cell>00:00:16</cell><cell>2</cell></row><row><cell>Khonji &amp; Iraqi</cell><cell>0.479</cell><cell>0.736</cell><cell>0.650</cell><cell>00:12:24</cell><cell>0</cell></row><row><cell>META-CLASSIFIER</cell><cell>0.428</cell><cell>0.737</cell><cell>0.580</cell><cell></cell><cell>0</cell></row><row><cell>Moreau et al.</cell><cell>0.375</cell><cell>0.635</cell><cell>0.590</cell><cell>00:01:25</cell><cell>0</cell></row><row><cell>Zamani et al.</cell><cell>0.362</cell><cell>0.613</cell><cell>0.590</cell><cell>00:00:11</cell><cell>0</cell></row><row><cell>Jankowska et al.</cell><cell>0.357</cell><cell>0.638</cell><cell>0.560</cell><cell>00:06:24</cell><cell>0</cell></row><row><cell>Frery et al.</cell><cell>0.347</cell><cell>0.601</cell><cell>0.578</cell><cell>00:00:09</cell><cell>5</cell></row><row><cell>BASELINE</cell><cell>0.322</cell><cell>0.607</cell><cell>0.530</cell><cell>00:00:12</cell><cell>0</cell></row><row><cell>Halvani &amp; Steinebach</cell><cell>0.316</cell><cell>0.575</cell><cell>0.550</cell><cell>00:00:03</cell><cell>0</cell></row><row><cell>Mayor et al.</cell><cell>0.299</cell><cell>0.569</cell><cell>0.525</cell><cell>00:07:01</cell><cell>1</cell></row><row><cell>Layton</cell><cell>0.261</cell><cell>0.503</cell><cell>0.520</cell><cell>00:56:17</cell><cell>0</cell></row><row><cell>Vartapetiance &amp; Gillam</cell><cell>0.260</cell><cell>0.510</cell><cell>0.510</cell><cell>00:05:43</cell><cell>0</cell></row><row><cell>Castillo et al.</cell><cell>0.247</cell><cell>0.669</cell><cell>0.370</cell><cell>00:01:01</cell><cell>76</cell></row><row><cell>Modaresi &amp; Gross</cell><cell>0.247</cell><cell>0.494</cell><cell>0.500</cell><cell>00:00:07</cell><cell>0</cell></row><row><cell>Harvey</cell><cell>0.170</cell><cell>0.354</cell><cell>0.480</cell><cell>00:01:45</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="11,144.32,168.53,308.04,220.14"><head>Table 5 .</head><label>5</label><figDesc>Evaluation results on the evaluation corpus of English essays.</figDesc><table coords="11,144.32,188.09,308.04,200.58"><row><cell></cell><cell>FinalScore</cell><cell>AUC</cell><cell>c@1</cell><cell>Runtime</cell><cell>Unansw. Problems</cell></row><row><cell>META-CLASSIFIER</cell><cell>0.531</cell><cell>0.781</cell><cell>0.680</cell><cell></cell><cell>0</cell></row><row><cell>Frery et al.</cell><cell>0.513</cell><cell>0.723</cell><cell>0.710</cell><cell>00:00:54</cell><cell>15</cell></row><row><cell>Satyam et al.</cell><cell>0.459</cell><cell>0.699</cell><cell>0.657</cell><cell>00:16:23</cell><cell>2</cell></row><row><cell>Moreau et al.</cell><cell>0.372</cell><cell>0.620</cell><cell>0.600</cell><cell>00:28:15</cell><cell>0</cell></row><row><cell>Layton</cell><cell>0.363</cell><cell>0.595</cell><cell>0.610</cell><cell>07:42:45</cell><cell>0</cell></row><row><cell>Modaresi &amp; Gross</cell><cell>0.350</cell><cell>0.603</cell><cell>0.580</cell><cell>00:00:07</cell><cell>0</cell></row><row><cell>Khonji &amp; Iraqi</cell><cell>0.349</cell><cell>0.599</cell><cell>0.583</cell><cell>09:10:01</cell><cell>1</cell></row><row><cell>Halvani &amp; Steinebach</cell><cell>0.338</cell><cell>0.629</cell><cell>0.538</cell><cell>00:00:07</cell><cell>1</cell></row><row><cell>Zamani et al.</cell><cell>0.322</cell><cell>0.585</cell><cell>0.550</cell><cell>00:02:03</cell><cell>0</cell></row><row><cell>Mayor et al.</cell><cell>0.318</cell><cell>0.572</cell><cell>0.557</cell><cell>01:01:07</cell><cell>10</cell></row><row><cell>Castillo et al.</cell><cell>0.318</cell><cell>0.549</cell><cell>0.580</cell><cell>01:31:53</cell><cell>0</cell></row><row><cell>Harvey</cell><cell>0.312</cell><cell>0.579</cell><cell>0.540</cell><cell>00:10:22</cell><cell>0</cell></row><row><cell>BASELINE</cell><cell>0.288</cell><cell>0.543</cell><cell>0.530</cell><cell>00:03:29</cell><cell>0</cell></row><row><cell>Jankowska et al.</cell><cell>0.284</cell><cell>0.518</cell><cell>0.548</cell><cell>01:16:35</cell><cell>5</cell></row><row><cell>Vartapetiance &amp; Gillam</cell><cell>0.270</cell><cell>0.520</cell><cell>0.520</cell><cell>00:16:44</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="11,144.32,412.75,308.04,220.14"><head>Table 6 .</head><label>6</label><figDesc>Evaluation results on the evaluation corpus of English novels.</figDesc><table coords="11,144.32,432.31,308.04,200.58"><row><cell></cell><cell>FinalScore</cell><cell>AUC</cell><cell>c@1</cell><cell>Runtime</cell><cell>Unansw. Problems</cell></row><row><cell>Modaresi &amp; Gross</cell><cell>0.508</cell><cell>0.711</cell><cell>0.715</cell><cell>00:00:07</cell><cell>0</cell></row><row><cell>Zamani et al.</cell><cell>0.476</cell><cell>0.733</cell><cell>0.650</cell><cell>02:02:02</cell><cell>0</cell></row><row><cell>META-CLASSIFIER</cell><cell>0.472</cell><cell>0.732</cell><cell>0.645</cell><cell></cell><cell>0</cell></row><row><cell>Khonji &amp; Iraqi</cell><cell>0.458</cell><cell>0.750</cell><cell>0.610</cell><cell>02:06:16</cell><cell>0</cell></row><row><cell>Mayor et al.</cell><cell>0.407</cell><cell>0.664</cell><cell>0.614</cell><cell>01:59:47</cell><cell>8</cell></row><row><cell>Castillo et al.</cell><cell>0.386</cell><cell>0.628</cell><cell>0.615</cell><cell>02:14:11</cell><cell>0</cell></row><row><cell>Satyam et al.</cell><cell>0.380</cell><cell>0.657</cell><cell>0.579</cell><cell>02:14:28</cell><cell>3</cell></row><row><cell>Frery et al.</cell><cell>0.360</cell><cell>0.612</cell><cell>0.588</cell><cell>00:03:11</cell><cell>1</cell></row><row><cell>Moreau et al.</cell><cell>0.313</cell><cell>0.597</cell><cell>0.525</cell><cell>00:11:04</cell><cell>12</cell></row><row><cell>Halvani &amp; Steinebach</cell><cell>0.293</cell><cell>0.569</cell><cell>0.515</cell><cell>00:00:07</cell><cell>0</cell></row><row><cell>Harvey</cell><cell>0.283</cell><cell>0.540</cell><cell>0.525</cell><cell>00:46:30</cell><cell>0</cell></row><row><cell>Layton</cell><cell>0.260</cell><cell>0.510</cell><cell>0.510</cell><cell>07:27:58</cell><cell>0</cell></row><row><cell>Vartapetiance &amp; Gillam</cell><cell>0.245</cell><cell>0.495</cell><cell>0.495</cell><cell>00:13:03</cell><cell>0</cell></row><row><cell>Jankowska et al.</cell><cell>0.225</cell><cell>0.491</cell><cell>0.457</cell><cell>02:36:12</cell><cell>1</cell></row><row><cell>BASELINE</cell><cell>0.202</cell><cell>0.453</cell><cell>0.445</cell><cell>00:08:31</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="12,144.32,168.35,308.04,220.08"><head>Table 7 .</head><label>7</label><figDesc>Evaluation results on the evaluation corpus of Greek articles.</figDesc><table coords="12,144.32,187.85,308.04,200.58"><row><cell></cell><cell>FinalScore</cell><cell>AUC</cell><cell>c@1</cell><cell>Runtime</cell><cell>Unansw. Problems</cell></row><row><cell>Khonji &amp; Iraqi</cell><cell>0.720</cell><cell>0.889</cell><cell>0.810</cell><cell>03:41:48</cell><cell>0</cell></row><row><cell>META-CLASSIFIER</cell><cell>0.635</cell><cell>0.836</cell><cell>0.760</cell><cell></cell><cell>0</cell></row><row><cell>Mayor et al.</cell><cell>0.621</cell><cell>0.826</cell><cell>0.752</cell><cell>00:51:03</cell><cell>3</cell></row><row><cell>Moreau et al.</cell><cell>0.565</cell><cell>0.800</cell><cell>0.707</cell><cell>00:05:54</cell><cell>4</cell></row><row><cell>Castillo et al.</cell><cell>0.501</cell><cell>0.686</cell><cell>0.730</cell><cell>00:03:14</cell><cell>0</cell></row><row><cell>Jankowska et al.</cell><cell>0.497</cell><cell>0.731</cell><cell>0.680</cell><cell>01:36:00</cell><cell>0</cell></row><row><cell>Zamani et al.</cell><cell>0.470</cell><cell>0.712</cell><cell>0.660</cell><cell>00:15:12</cell><cell>0</cell></row><row><cell>BASELINE</cell><cell>0.452</cell><cell>0.706</cell><cell>0.640</cell><cell>00:03:38</cell><cell>0</cell></row><row><cell>Frery et al.</cell><cell>0.436</cell><cell>0.679</cell><cell>0.642</cell><cell>00:00:58</cell><cell>7</cell></row><row><cell>Layton</cell><cell>0.403</cell><cell>0.661</cell><cell>0.610</cell><cell>04:40:29</cell><cell>0</cell></row><row><cell>Halvani &amp; Steinebach</cell><cell>0.367</cell><cell>0.611</cell><cell>0.600</cell><cell>00:00:04</cell><cell>0</cell></row><row><cell>Satyam et al.</cell><cell>0.356</cell><cell>0.593</cell><cell>0.600</cell><cell>00:12:01</cell><cell>0</cell></row><row><cell>Modaresi &amp; Gross</cell><cell>0.294</cell><cell>0.544</cell><cell>0.540</cell><cell>00:00:05</cell><cell>0</cell></row><row><cell>Vartapetiance &amp; Gillam</cell><cell>0.281</cell><cell>0.530</cell><cell>0.530</cell><cell>00:10:17</cell><cell>0</cell></row><row><cell>Harvey</cell><cell>0.000</cell><cell>0.500</cell><cell>0.000</cell><cell></cell><cell>100</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="12,144.32,412.51,308.04,220.14"><head>Table 8 .</head><label>8</label><figDesc>Evaluation results on the evaluation corpus of Spanish articles.</figDesc><table coords="12,144.32,432.01,308.04,200.64"><row><cell></cell><cell>FinalScore</cell><cell>AUC</cell><cell>c@1</cell><cell>Runtime</cell><cell>Unansw. Problems</cell></row><row><cell>META-CLASSIFIER</cell><cell>0.709</cell><cell>0.898</cell><cell>0.790</cell><cell></cell><cell>0</cell></row><row><cell>Khonji &amp; Iraqi</cell><cell>0.698</cell><cell>0.898</cell><cell>0.778</cell><cell>04:50:49</cell><cell>1</cell></row><row><cell>Moreau et al.</cell><cell>0.634</cell><cell>0.845</cell><cell>0.750</cell><cell>00:18:47</cell><cell>0</cell></row><row><cell>Jankowska et al.</cell><cell>0.586</cell><cell>0.803</cell><cell>0.730</cell><cell>01:39:41</cell><cell>0</cell></row><row><cell>Frery et al.</cell><cell>0.581</cell><cell>0.774</cell><cell>0.750</cell><cell>00:01:01</cell><cell>0</cell></row><row><cell>Castillo et al.</cell><cell>0.558</cell><cell>0.734</cell><cell>0.760</cell><cell>00:06:48</cell><cell>0</cell></row><row><cell>Mayor et al.</cell><cell>0.539</cell><cell>0.755</cell><cell>0.714</cell><cell>01:12:14</cell><cell>5</cell></row><row><cell>Harvey</cell><cell>0.514</cell><cell>0.790</cell><cell>0.650</cell><cell>00:05:23</cell><cell>0</cell></row><row><cell>Zamani et al.</cell><cell>0.468</cell><cell>0.731</cell><cell>0.640</cell><cell>00:17:30</cell><cell>0</cell></row><row><cell>Vartapetiance &amp; Gillam</cell><cell>0.436</cell><cell>0.660</cell><cell>0.660</cell><cell>00:15:15</cell><cell>0</cell></row><row><cell>Halvani &amp; Steinebach</cell><cell>0.423</cell><cell>0.661</cell><cell>0.640</cell><cell>00:00:27</cell><cell>0</cell></row><row><cell>Modaresi &amp; Gross</cell><cell>0.416</cell><cell>0.640</cell><cell>0.650</cell><cell>00:00:08</cell><cell>0</cell></row><row><cell>BASELINE</cell><cell>0.378</cell><cell>0.713</cell><cell>0.530</cell><cell>00:04:27</cell><cell>0</cell></row><row><cell>Layton</cell><cell>0.299</cell><cell>0.553</cell><cell>0.540</cell><cell>05:17:25</cell><cell>0</cell></row><row><cell>Satyam et al.</cell><cell>0.248</cell><cell>0.443</cell><cell>0.560</cell><cell>00:08:09</cell><cell>0</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="6,130.04,665.10,95.99,8.18"><p>http://www.gutenberg.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="6,130.04,675.66,97.41,8.18"><p>https://www.fanfiction.net/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="6,130.04,686.22,77.95,8.18"><p>http://www.tovima.gr</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="7,130.04,686.22,60.20,8.18"><p>http://elpais.com</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="14,132.62,675.84,337.77,8.18;14,133.28,686.22,153.12,8.18"><p>We used the implementation by Vincent Van Asch available from the CLiPS website http://www.clips.uantwerpen.be/scripts/art</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgement</head><p>This work was partially supported by the <rs type="programName">WIQ-EI IRSES</rs> project (Grant No. <rs type="grantNumber">269180</rs>) within the <rs type="programName">FP7 Marie Curie</rs> action and by grant <rs type="grantNumber">OCI-1032683</rs> from the <rs type="funder">United States National Science Foundation</rs>. The work of the last author is funded by the <rs type="funder">Spanish Ministry of Education and Science</rs> (<rs type="projectName">TACARDI</rs> project, <rs type="grantNumber">TIN2012-38523-C02-00</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_HaCvFTG">
					<idno type="grant-number">269180</idno>
					<orgName type="program" subtype="full">WIQ-EI IRSES</orgName>
				</org>
				<org type="funding" xml:id="_YcRmafB">
					<idno type="grant-number">OCI-1032683</idno>
					<orgName type="program" subtype="full">FP7 Marie Curie</orgName>
				</org>
				<org type="funded-project" xml:id="_KXprYMa">
					<idno type="grant-number">TIN2012-38523-C02-00</idno>
					<orgName type="project" subtype="full">TACARDI</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="18,128.53,452.76,288.00,9.11;18,146.06,464.28,311.41,9.11;18,146.06,475.73,214.21,9.12" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="18,250.46,452.76,166.07,9.11;18,146.06,464.28,159.34,9.11">Overview of the International Authorship Identification Competition at PAN-2011</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Argamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,171.08,475.73,159.61,9.12">CLEF Notebook Papers/Labs/Workshop</title>
		<editor>
			<persName><forename type="first">V</forename><surname>Petras</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Clough</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,128.53,487.26,338.90,9.11;18,146.06,498.77,205.30,9.12" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="18,216.64,487.26,250.79,9.11;18,146.06,498.78,56.15,9.11">USE--The Uppsala Student English Corpus: An instrument for needs analysis</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">W</forename><surname>Axelsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="18,208.58,498.77,62.45,9.12">ICAME Journal</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="155" to="157" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,128.53,510.23,336.36,9.12;18,146.06,521.75,318.35,9.12;18,146.06,533.28,95.02,9.11" xml:id="b2">
	<analytic>
	</analytic>
	<monogr>
		<title level="m" coord="18,378.46,510.23,86.43,9.12;18,146.06,521.75,42.29,9.12">CLEF 2014 Labs and Workshops</title>
		<title level="s" coord="18,195.56,521.75,238.85,9.12">Notebook Papers. CEUR Workshop Proceedings (CEUR-WS</title>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Halvey</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">W</forename><surname>Kraaij</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,128.53,544.74,316.42,9.11;18,146.06,556.26,308.58,9.11;18,146.06,567.78,120.28,9.11" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="18,389.98,544.74,54.97,9.11;18,146.06,556.26,308.58,9.11">Unsupervised Method for the Authorship Identification Task -Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Cervantes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Vilariño</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>León</surname></persName>
		</author>
		<editor>Cappellato, et al.</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,128.53,579.24,333.01,9.11;18,146.06,590.75,289.32,9.12;18,146.06,602.21,294.96,9.12" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="18,400.12,579.24,61.42,9.11;18,146.06,590.76,176.86,9.11">Particle Swarm Model Selection for Authorship Verification</title>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">J</forename><surname>Escalante</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y-Gómez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Villaseñor-Pineda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,340.22,590.75,95.16,9.12;18,146.06,602.21,202.14,9.12">Proceedings of the 14th Iberoamerican Conference on Pattern Recognition</title>
		<meeting>the 14th Iberoamerican Conference on Pattern Recognition</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="563" to="570" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,128.53,613.73,318.85,9.12;18,146.06,625.26,85.31,9.11" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="18,193.82,613.74,133.29,9.11">An Introduction to ROC Analysis</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Fawcett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="18,333.80,613.73,109.80,9.12">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="861" to="874" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,128.53,636.72,312.79,9.11;18,146.06,648.24,299.47,9.11" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="18,343.52,636.72,97.80,9.11;18,146.06,648.24,176.68,9.11">UJM at CLEF in Author Identification -Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Fréry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Largeron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Juganaru-Mathieu</surname></persName>
		</author>
		<editor>Cappellato, et al.</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="18,128.53,659.78,337.74,9.11;18,146.06,671.24,313.04,9.11;18,146.06,682.75,318.05,9.12;19,146.06,149.67,286.34,9.12;19,146.06,161.13,219.44,9.12" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="18,200.27,671.24,233.25,9.11">Recent Trends in Digital Text Forensics and its Evaluation</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Gollub</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Beyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Busse</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="18,386.62,682.75,77.49,9.12;19,146.06,149.67,286.34,9.12;19,146.06,161.13,190.87,9.12">Information Access Evaluation meets Multilinguality, Multimodality, and Visualization. 4th International Conference of the CLEF Initiative</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Paredes</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Rosso</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Stein</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,128.53,172.66,299.48,9.11;19,146.06,184.18,288.53,9.11;19,146.06,195.64,84.41,9.11" xml:id="b8">
	<monogr>
		<title level="m" type="main" coord="19,272.18,172.66,155.84,9.11;19,146.06,184.18,252.70,9.11">VEBAV -A Simple, Scalable and Fast Authorship Verification Scheme -Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Halvani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Steinebach</surname></persName>
		</author>
		<editor>Cappellato, et al.</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,133.11,207.16,314.38,9.11;19,146.06,218.68,235.57,9.11" xml:id="b9">
	<monogr>
		<title level="m" type="main" coord="19,191.06,207.16,256.43,9.11;19,146.06,218.68,133.30,9.11">Author Verification Using PPM with Parts of Speech Tagging -Notebook for PAN at CLEF 2014</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Harvey</surname></persName>
		</author>
		<editor>Cappellato, et al.</editor>
		<imprint>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,133.11,230.14,284.96,9.11;19,146.06,241.66,318.05,9.11;19,146.06,253.18,317.27,9.11;19,146.06,264.63,301.33,9.12;19,146.06,276.16,22.55,9.11" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="19,310.82,230.14,107.25,9.11;19,146.06,241.66,318.05,9.11;19,146.06,253.18,162.30,9.11">Proximity based One-class Classification with Common N-Gram Dissimilarity for Authorship Verification Task -Notebook for PAN at CLEF 2013</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jankowska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kešelj</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Milios</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="19,171.08,264.63,271.90,9.12">CLEF 2013 Evaluation Labs and Workshop -Working Notes Papers</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Tufis</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,133.11,287.62,324.65,9.11;19,146.06,299.14,320.81,9.11;19,146.06,310.66,84.41,9.11" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="19,310.82,287.62,146.94,9.11;19,146.06,299.14,284.99,9.11">Ensembles of Proximity-Based One-Class Classifiers for Author Verification -Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Jankowska</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Kešelj</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Milios</surname></persName>
		</author>
		<editor>Cappellato, et al.</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,133.11,322.11,317.43,9.12;19,146.06,333.64,22.55,9.11" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="19,182.73,322.12,90.53,9.11">Authorship Attribution</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="19,279.68,322.11,119.07,9.12">Foundations and Trends in IR</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="234" to="334" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,133.11,345.16,318.20,9.11;19,146.06,356.61,100.00,9.12" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="19,182.73,345.16,253.47,9.11">An Overview of the Traditional Authorship Attribution Subtask</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="19,146.06,356.61,70.01,9.12">Proc. of CLEF&apos;12</title>
		<meeting>of CLEF&apos;12</meeting>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,133.11,368.14,333.71,9.11;19,146.06,379.65,317.80,9.12;19,146.06,391.13,183.58,9.12" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="19,257.15,368.14,209.67,9.11;19,146.06,379.66,18.04,9.11">Overview of the Author Identification Task at PAN-2013</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Juola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="19,348.62,379.65,115.24,9.12;19,146.06,391.13,154.22,9.12">CLEF 2013 Evaluation Labs and Workshop -Working Notes Papers</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Tufis</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,133.11,402.66,307.09,9.11;19,146.06,414.17,303.04,9.12;19,146.06,425.64,22.55,9.11" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="19,389.56,402.66,50.64,9.11;19,146.06,414.18,168.41,9.11">Cross-Genre Authorship Verification Using Unmasking</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Kestemont</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Luyckx</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Crombez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="19,321.86,414.17,60.52,9.12">English Studies</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="340" to="356" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,133.11,437.16,334.33,9.11;19,146.06,448.68,321.69,9.11;19,146.06,460.14,14.19,9.11" xml:id="b16">
	<monogr>
		<title level="m" type="main" coord="19,243.26,437.16,224.18,9.11;19,146.06,448.68,236.04,9.11">A Slightly-modified GI-based Author-verifier with Lots of Features (ASGALF) -Notebook for PAN at CLEF 2014</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Khonji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Iraqi</surname></persName>
		</author>
		<editor>Cappellato, et al.</editor>
		<imprint>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,133.11,471.66,312.85,9.11;19,146.06,483.17,217.79,9.12" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="19,304.11,471.66,137.36,9.11">Authorship Attribution in the Wild</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Argamon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="19,146.06,483.17,145.77,9.12">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="83" to="94" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,133.11,494.64,315.13,9.11;19,146.06,506.15,309.18,9.12;19,146.06,517.62,80.29,9.11" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="19,335.28,494.64,112.97,9.11;19,146.06,506.16,142.07,9.11">Measuring Differentiability: Unmasking Pseudonymous Authors</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Schler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Bonchek-Dokow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="19,295.04,506.15,155.78,9.12">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="1261" to="1276" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,133.11,529.14,315.27,9.11;19,146.06,540.65,277.16,9.12;19,146.06,552.11,136.95,9.12" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="19,253.82,529.14,194.57,9.11;19,146.06,540.66,26.44,9.11">Determining if Two Documents are by the Same Author</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Winter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="19,179.42,540.65,243.80,9.12;19,146.06,552.11,44.71,9.12">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="178" to="187" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,133.11,563.64,314.56,9.11;19,146.06,575.16,235.57,9.11" xml:id="b20">
	<monogr>
		<title level="m" type="main" coord="19,191.06,563.64,256.61,9.11;19,146.06,575.16,133.30,9.11">A Simple Local n-gram Ensemble for Authorship Verification -Notebook for PAN at CLEF 2014</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Layton</surname></persName>
		</author>
		<editor>Cappellato, et al.</editor>
		<imprint>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,133.11,586.62,318.93,9.11;19,146.06,598.13,284.93,9.12;19,146.06,609.65,317.22,9.12;19,146.06,621.12,42.52,9.11" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="19,272.15,586.62,179.89,9.11;19,146.06,598.14,128.72,9.11">Authorship Attribution and Verification with Many Authors and Limited Data</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Luyckx</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="19,292.46,598.13,138.53,9.12;19,146.06,609.65,265.99,9.12">Proceedings of the Twenty-Second International Conference on Computational Linguistics (COLING)</title>
		<meeting>the Twenty-Second International Conference on Computational Linguistics (COLING)</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="513" to="520" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="19,133.11,632.64,329.02,9.11;19,146.06,644.16,318.83,9.11;19,146.06,655.64,235.57,9.11" xml:id="b22">
	<monogr>
		<title level="m" type="main" coord="19,173.30,644.16,291.59,9.11;19,146.06,655.64,112.79,9.11">A Single Author Style Representation for the Author Verification Task -Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Mayor</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gutierrez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Toledo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ledesma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Fuentes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Meza</surname></persName>
		</author>
		<editor>Cappellato, et al.</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,133.11,149.68,312.04,9.11;20,146.06,161.14,324.47,9.11;20,146.06,172.66,26.39,9.11" xml:id="b23">
	<monogr>
		<title level="m" type="main" coord="20,252.74,149.68,192.41,9.11;20,146.06,161.14,230.57,9.11">A Language Independent Author Verifier Using Fuzzy C-Means Clustering -Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Modaresi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gross</surname></persName>
		</author>
		<editor>Cappellato, et al.</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,133.11,184.18,336.13,9.11;20,146.06,195.64,322.79,9.11;20,146.06,207.16,84.41,9.11" xml:id="b24">
	<monogr>
		<title level="m" type="main" coord="20,298.52,184.18,170.72,9.11;20,146.06,195.64,286.99,9.11">Author Verification: Exploring a Large set of Parameters using a Genetic Algorithm -Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Moreau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jayapal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Vogel</surname></persName>
		</author>
		<editor>Cappellato, et al.</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,133.11,218.67,300.08,9.12;20,146.06,230.13,106.98,9.12" xml:id="b25">
	<monogr>
		<title level="m" type="main" coord="20,206.06,218.67,227.13,9.12;20,146.06,230.13,48.50,9.12">Computer Intensive Methods for Testing Hypotheses: An Introduction</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">W</forename><surname>Noreen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,133.11,241.65,335.71,9.12;20,146.06,253.17,318.91,9.12;20,146.06,264.64,106.19,9.11" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="20,251.06,241.66,167.58,9.11">A Simple Measure to Assess Nonresponse</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Rodrigo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,436.54,241.65,32.28,9.12;20,146.06,253.17,295.00,9.12">Proc. of the 49th Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>of the 49th Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="1415" to="1424" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,133.11,276.16,330.45,9.11;20,146.06,287.62,297.48,9.11;20,146.06,299.13,288.37,9.12" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="20,398.58,276.16,64.98,9.11;20,146.06,287.62,140.51,9.11">Overview of the Author Profiling Task at PAN 2013</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rosso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Koppel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Inches</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,173.60,299.13,231.45,9.12">Working Notes Papers of the CLEF 2013 Evaluation Labs</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Tufis</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,133.11,310.66,335.99,9.11;20,146.06,322.12,312.23,9.11;20,146.06,333.64,147.23,9.11" xml:id="b28">
	<monogr>
		<title level="m" type="main" coord="20,330.26,310.66,138.84,9.11;20,146.06,322.12,312.23,9.11;20,146.06,333.64,24.50,9.11">A Statistical Analysis Approach to Author Identification Using Latent Semantic Analysis -Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">Anand</forename><surname>Satyam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">K</forename><surname>Dawn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">K</forename><surname>Saha</surname></persName>
		</author>
		<editor>Cappellato, et al.</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,133.11,345.16,325.99,9.11;20,146.06,356.61,322.76,9.12;20,146.06,368.13,252.01,9.12" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="20,196.64,345.16,262.46,9.11;20,146.06,356.62,91.34,9.11">Authorship Verification Using the Impostors Method -Notebook for PAN at CLEF 2013</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Seidman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,421.96,356.61,46.86,9.12;20,146.06,368.13,222.58,9.12">CLEF 2013 Evaluation Labs and Workshop -Working Notes Papers</title>
		<editor>
			<persName><forename type="first">P</forename><surname>Forner</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><surname>Navigli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Tufis</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,133.11,379.65,334.37,9.12;20,146.06,391.13,304.41,9.12;20,146.06,402.66,22.55,9.11" xml:id="b30">
	<analytic>
		<title level="a" type="main" coord="20,206.02,379.66,212.83,9.11">A Survey of Modern Authorship Attribution Methods</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="20,426.10,379.65,41.38,9.12;20,146.06,391.13,247.17,9.12">Journal of the American Society for Information Science and Technology</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="538" to="556" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,133.11,414.18,333.67,9.11;20,146.06,425.63,323.09,9.12" xml:id="b31">
	<analytic>
		<title level="a" type="main" coord="20,342.43,414.18,124.35,9.11;20,146.06,425.64,119.43,9.11">Automatic Text Categorization in Terms of Genre and Author</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Stamatatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Fakotakis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Kokkinakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="20,272.48,425.63,105.04,9.12">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="471" to="495" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,133.11,437.16,323.46,9.11;20,146.06,448.68,280.01,9.11;20,146.06,460.13,314.59,9.12;20,146.06,471.65,179.68,9.12" xml:id="b32">
	<analytic>
		<title level="a" type="main" coord="20,264.07,437.16,192.49,9.11;20,146.06,448.68,265.27,9.11">Short Text Authorship Attribution via Sequence Kernels, Markov Chains and Author Unmasking: An Investigation</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Guenter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,146.06,460.13,314.59,9.12;20,146.06,471.65,85.18,9.12">Proceedings of the International Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the International Conference on Empirical Methods in Natural Language Processing</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="482" to="491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,133.11,483.18,321.04,9.11;20,146.06,494.63,316.64,9.12;20,146.06,506.15,212.51,9.12" xml:id="b33">
	<analytic>
		<title level="a" type="main" coord="20,320.48,483.18,133.67,9.11;20,146.06,494.64,46.95,9.11">Meta Analysis within Authorship Verification</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Lipka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Meyer Zu Eissen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,210.26,494.63,252.44,9.12;20,146.06,506.15,129.83,9.12">Proceedings of the 19th International Conference on Database and Expert Systems Applications</title>
		<meeting>the 19th International Conference on Database and Expert Systems Applications</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="34" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,133.11,517.61,333.80,9.12;20,146.06,529.13,201.07,9.12" xml:id="b34">
	<analytic>
		<title level="a" type="main" coord="20,305.74,517.62,114.46,9.11">Intrinsic Plagiarism Analysis</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Lipka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Prettenhofer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="20,426.88,517.61,40.03,9.12;20,146.06,529.13,103.28,9.12">Language Resources and Evaluation</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="63" to="82" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,133.11,540.66,323.65,9.11;20,146.06,552.12,308.06,9.11;20,146.06,563.64,14.19,9.11" xml:id="b35">
	<monogr>
		<title level="m" type="main" coord="20,272.12,540.66,184.64,9.11;20,146.06,552.12,201.98,9.11">A Trinity of Trials: Surrey&apos;s 2014 Attempts at Author Verification -Notebook for PAN at CLEF</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vartapetiance</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Gillam</surname></persName>
		</author>
		<editor>Cappellato, et al.</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,133.11,575.16,326.75,9.11;20,146.06,586.61,313.32,9.12;20,146.06,598.13,71.45,9.12" xml:id="b36">
	<analytic>
		<title level="a" type="main" coord="20,214.67,575.16,241.28,9.11">Linguistic Profiling for Author Recognition and Verification</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Van Halteren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,156.92,586.61,302.46,9.12;20,146.06,598.13,42.56,9.12">Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics</title>
		<meeting>the 42nd Annual Meeting on Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,133.11,609.66,304.87,9.11;20,146.06,621.12,286.77,9.11;20,146.06,632.63,305.84,9.12;20,146.06,644.15,167.20,9.12" xml:id="b37">
	<analytic>
		<title level="a" type="main" coord="20,284.93,609.66,153.06,9.11;20,146.06,621.12,286.77,9.11;20,146.06,632.64,130.56,9.11">CLiPS Stylometry Investigation (CSI) Corpus: A Dutch Corpus for the Detection of Age, Gender, Personality, Sentiment and Deception in Text</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Verhoeven</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Daelemans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,294.14,632.63,157.76,9.12;20,146.06,644.15,137.20,9.12">Proc. of the 9th Int. Conf. on Language Resources and Evaluation (LREC)</title>
		<meeting>of the 9th Int. Conf. on Language Resources and Evaluation (LREC)</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="20,133.11,655.64,292.85,9.11;20,146.06,667.15,281.34,9.12;20,146.06,678.67,179.79,9.12" xml:id="b38">
	<analytic>
		<title level="a" type="main" coord="20,179.99,655.64,245.97,9.11;20,146.06,667.16,45.06,9.11">More Accurate Tests for the Statistical Significance of Result Differences</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Yeh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="20,208.52,667.15,218.88,9.12;20,146.06,678.67,42.56,9.12">Proceedings of the 18th Conference on Computational Linguistics</title>
		<meeting>the 18th Conference on Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="947" to="953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="21,133.11,149.68,302.99,9.11;21,146.06,161.14,275.82,9.11;21,146.06,172.65,305.27,9.12;21,146.06,184.17,90.58,9.12" xml:id="b39">
	<analytic>
		<title level="a" type="main" coord="21,146.06,161.14,275.82,9.11;21,146.06,172.66,97.03,9.11">Authorship Identification Using Dynamic Selection of Features from Probabilistic Feature Set</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zamani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Nasr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Babaie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Abnar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dehghani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Shakery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="21,260.24,172.65,191.09,9.12;21,146.06,184.17,62.06,9.12">Proc. of the 5th International Conference of the CLEF Initiative</title>
		<meeting>of the 5th International Conference of the CLEF Initiative</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
