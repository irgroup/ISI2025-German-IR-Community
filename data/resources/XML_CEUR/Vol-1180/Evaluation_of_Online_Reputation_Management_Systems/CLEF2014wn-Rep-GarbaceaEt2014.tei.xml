<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,154.75,115.90,305.86,12.90;1,206.16,133.83,203.04,12.90;1,344.74,153.76,81.03,10.75">Feature Selection and Data Sampling Methods for Learning Reputation Dimensions</title>
				<funder ref="#_Eq5XH7k">
					<orgName type="full">Royal Dutch Academy of Sciences (KNAW)</orgName>
				</funder>
				<funder ref="#_PDQ6jNg">
					<orgName type="full">European Community</orgName>
				</funder>
				<funder ref="#_5hzWh4f #_UP4Tk8y">
					<orgName type="full">Netherlands Organisation for Scientific Research (NWO)</orgName>
				</funder>
				<funder ref="#_cCa5Rzu">
					<orgName type="full">Center for Creation, Content and Technology</orgName>
					<orgName type="abbreviated">CCCT</orgName>
				</funder>
				<funder ref="#_hMBU6Fy">
					<orgName type="full">Netherlands eScience Center</orgName>
				</funder>
				<funder ref="#_FD2VWm3">
					<orgName type="full">VOX-Pol</orgName>
				</funder>
				<funder ref="#_UnM9sbR">
					<orgName type="full">HPC Fund</orgName>
				</funder>
				<funder ref="#_AYKDyyF #_JPJPe9j #_XeJUYrt #_XHdRsZp #_g6WD8wa">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,191.39,190.23,69.69,8.64"><forename type="first">Cristina</forename><surname>GÃ¢rbacea</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,268.02,190.23,63.31,8.64"><forename type="first">Manos</forename><surname>Tsagkias</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">The University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,354.91,190.23,69.07,8.64"><forename type="first">Maarten</forename><surname>De Rijke</surname></persName>
							<email>derijke@uva.nl</email>
							<affiliation key="aff0">
								<orgName type="institution">The University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,200.86,201.87,59.07,8.74"><forename type="first">C</forename><surname>Garbacea</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,271.82,203.12,59.78,7.01"><forename type="first">E</forename><surname>Tsagkias</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Amsterdam</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,154.75,115.90,305.86,12.90;1,206.16,133.83,203.04,12.90;1,344.74,153.76,81.03,10.75">Feature Selection and Data Sampling Methods for Learning Reputation Dimensions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F32CEB027286F081D233CBD80B111759</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We report on our participation in the reputation dimension task of the CLEF RepLab 2014 evaluation initiative, i.e., to classify social media updates into eight predefined categories. We address the task by using corpus-based methods to extract textual features from the labeled training data to train two classifiers in a supervised way. We explore three sampling strategies for selecting training examples, and probe their effect on classification performance. We find that all our submitted runs outperform the baseline, and that elaborate feature selection methods coupled with balanced datasets help improve classification accuracy.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Today's growing popularity of social media requires the development of methods that can automatically monitor the reputation of real world entities in a social context. Even though reputation management is currently witnessing a shift from the traditional offline environment to an online setting, the algorithmic support for processing large amounts of user generated data created on a daily basis is still narrow and limited. For this reason, computational tools that can instantly extract and analyze the relevant content expressed online are in high demand.</p><p>In this paper we present our contribution to RepLab 2014 <ref type="bibr" coords="1,375.26,483.40,10.58,8.64" target="#b2">[3]</ref>, an evaluation initiative promoted by the EU project LiMoSINe, <ref type="foot" coords="1,297.09,493.69,3.49,6.05" target="#foot_0">1</ref> which focuses on monitoring the reputation of entities (companies, organizations, celebrities, universities) on Twitter. In previous years RepLab mainly addressed tasks like named entity disambiguation, reputation polarity, topic detection and topic ranking. This year, RepLab has introduced two new tasks: (i) reputation dimensions and (ii) author profiling. We describe each of them.</p><p>The reputation dimensions task aims at classifying tweets into eight reputation dimensions. These dimensions are defined according to the RepTrak framework, <ref type="foot" coords="1,449.55,565.50,3.49,6.05" target="#foot_1">2</ref> which aims at facilitating reputation analysis. According to RepTrak, inside each dimension lie specific attributes that can be customized for clients in order to allow for program and message-ready analysis. An overview of these categories is presented in Table <ref type="table" coords="1,456.21,603.03,3.74,8.64">1</ref>. For example, the tweet "We are sadly going to be loosing Sarah Smith from HSBC Bank, Table <ref type="table" coords="2,168.93,127.68,3.88,8.64">1</ref>: The eight reputation dimensions according to the Replab 2014 challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dimension Gloss</head><p>Products &amp; Services Related to the products and services offered by the company and reflecting customers' satisfaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Innovation</head><p>The innovativeness displayed by the company, nurturing novel ideas and incorporating these ideas into products. Workplace Related to the employees' satisfaction and the company's ability to attract, form and keep talented and highly qualified people.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Governance</head><p>Capturing the relationship between the company and the public authorities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Citizenship</head><p>The company's acknowledgement of community and environmental responsibility, including ethic aspects of the business: integrity, transparency and accountability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Leadership</head><p>Related to the leading position of the company.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Performance</head><p>Focusing on long term business success and financial soundness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Undefined</head><p>In case a tweet cannot be classified into none of the above dimensions, it is labelled as "Undefined."</p><p>as she has been successful in moving forward into a. . . http://fb.me/18FKDLQIr" belongs to the "Workplace" reputation dimension, while "HSBC to upgrade 10,000 POS terminals for contactless payments. . . http://bit.ly/K9h6 QW" is related to "Innovation."</p><p>The author profiling task aims at profiling Twitter users with respect to their domain of expertise and influence for identifying the most influential opinion makers in a particular domain of expertise. The task is further divided into two subtasks: (i) author categorization, and (ii) author ranking. The first subtask aims at the classification of Twitter profiles according to the type of author, i.e., journalist, professional, authority, activist, investor, company or celebrity. The second subtask aims at identifying user profiles with the biggest influence on a company's reputation.</p><p>We focus on the reputation dimensions task. Our main research question is how we can use machine learning to extract and select discriminative features that can help us learn to classify the reputation dimension of a tweet. In our approach we exploit corpus-based methods to extract textual features that we use for training a Support Vector Machine (SVM) and a Naive Bayes (NB) classifier in a supervised way. The rest of paper is organized as follows. In Section 2 we present related work, in Section 3 we introduce our feature extraction approach, in Section 5 we describe our experimental setup, in Section 6 we report on our results. We follow up with an error analysis and reflections in Section 7 and conclude in Section 8.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Related Work</head><p>The field of Online Reputation Management (ORM) is concerned with the development of automatic ways for tracking online content that can impact the reputation of a company. This involves non-trivial aspects from natural language processing, opinion mining, sentiment analysis and topic detection. Generally, opinions expressed about individuals or organizations cannot be structured around a predefined set of features/aspects. Entities require complex modeling, which is a less understood process, and this turns ORM into a challenging field of research and study.</p><p>The RepLab campaigns address the task of detecting the reputation of entities on social media (Twitter). Each year there are new tasks defined by the organizers. Replab 2012 <ref type="bibr" coords="3,178.42,249.96,11.62,8.64" target="#b3">[4]</ref> focused on profiling, that is filtering the stream of tweets for detecting those microblog posts which are related to a company and their implications on the brand's image, and monitoring, i.e., topical clustering of tweets for identifying topics that harm a company's reputation and therefore, require the immediate attention of reputation management experts. Replab 2013 <ref type="bibr" coords="3,308.58,297.78,11.62,8.64" target="#b1">[2]</ref> built upon the previously defined tasks and proposed a full reputation monitoring system consisting of four individual tasks. First, the filtering task asked systems to detect which tweets are related to an organization by taking entity name disambiguation into account. Second, the polarity detection for reputation classification task, required systems to decide on whether the content of a social media update has positive, neutral or negative implications for the company's reputation. Third, the topic detection task aimed at grouping together tweets that are about the same topic. Four, the priority assignment task aimed at ranking the previous topics based on their potential for triggering a reputation alert.</p><p>Replab proposes an evaluation test bed made up of multilingual tweets in English and Spanish with human annotated data for a significant number of entities. The best systems from previous years addressed the majority of the above presented tasks as classification tasks by the use of conventional machine learning techniques, and focused on the extraction of features that encapsulate the main characteristics of a specific reputation related class. For the filtering and polarity detection tasks, Hangya and Farkas <ref type="bibr" coords="3,468.98,465.15,11.62,8.64" target="#b8">[9]</ref> reduce the size of the vocabulary following an elaborate sequence of data preprocessing steps and create an n-gram based supervised model, which was found previously successful on short messages like tweets <ref type="bibr" coords="3,299.13,501.02,10.58,8.64" target="#b0">[1]</ref>. Graph-based semantic approaches for assembling domain specific affective lexicon seem not to yield very accurate results given the inherent short and noisy content of social media updates <ref type="bibr" coords="3,381.75,524.93,15.27,8.64" target="#b18">[20]</ref>. The utility of topic modeling algorithms and unsupervised techniques based on clustering are explored in <ref type="bibr" coords="3,134.77,548.84,10.79,8.64" target="#b6">[7,</ref><ref type="bibr" coords="3,145.55,548.84,7.19,8.64" target="#b4">5]</ref>, both addressing the topic detection task. Peetz et al. <ref type="bibr" coords="3,362.28,548.84,16.60,8.64" target="#b13">[15]</ref> show how active learning can maximize performance for entity name disambiguation by systematically interacting with the user and updating the classification model.</p><p>The reputation dimensions task stems from the hypothesis that customer satisfaction is easier to measure and manage when we understand the key drivers of reputation that actively influence a company's success. The Reptrak system was designed to identify these drivers by evaluating how corporate reputation emerges from the emotional connection that an organization develops with its stakeholders. In this scenario, reputation is measured on a scale from 0-100 and considers the degree of admiration, trust, good feeling and overall esteem investors display about the organization. Reptrak defines seven key aspects that define reputation and the reputation dimensions task uses them to define the reputation dimensions that we listed in Table <ref type="table" coords="4,376.94,131.27,4.98,8.64">1</ref> except the "Undefined" category, which is an extra class local to the reputation dimensions task.</p><p>In our study we follow <ref type="bibr" coords="4,246.11,155.18,10.58,8.64" target="#b8">[9]</ref>, and in particular GÃ¢rbacea et al. <ref type="bibr" coords="4,397.22,155.18,10.58,8.64" target="#b7">[8]</ref>, who presented a highly accurate system on the task of predicting reputation polarity. We build on their approaches but we focus on the task of reputation dimensions and we also explore the effect of balanced and unbalanced training sets on classification accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Feature Engineering</head><p>Classifying tweets by machine learning techniques imposes the need to represent each document as a set of features based on the presence, absence or frequency of terms occurring inside the text. Frequency distribution, tf.idf or Ï 2 calculations are common approaches in this respect. In addition, identifying the semantic relations between features can capture the linguistic differences across corpora <ref type="bibr" coords="4,365.81,292.23,15.27,8.64" target="#b19">[21]</ref>.</p><p>In our approach we consider textual features that we extract using corpus-based methods for frequency profiling. We build on the assumption that more elaborate feature extraction methods can help us identify discriminative features relevant for characterizing a reputation dimension class. We hypothesize that frequency profiling using the log-likelihood ratio method (LLR) <ref type="bibr" coords="4,273.64,352.01,15.27,8.64" target="#b14">[16]</ref>, which is readily used to identify discriminative features between corpora, can also yield discriminative features specific to each of our reputation dimension classes. We extract unigrams and bigrams (the latter because they can better capture the context of a term) from our training data after having it split into eight annotated reputation dimensions, each corresponding to one of the given labels. Our procedure for extracting textual features is described in what follows.</p><p>Given two corpora we want to compare, a word frequency list is first produced for each corpus. Although here a comparison at word level is intended, part of speech (POS) or semantic tag frequency lists are also common. The log-likelihood statistic is performed by constructing a contingency table that captures the frequency of a term as compared to the frequency of other terms inside two distinct corpora. We build our first corpus out of all the annotated tweets for our target class and our second corpus out of all the tweets found in the rest of the reputation dimension classes. For example, for finding discriminative terms for the class "Products &amp; Services," we compare pairs of corpora of the form: "Products &amp; Services" vs. "Innovation" and "Workplace" and "Governance" and "Citizenship" and "Leadership" and "Performance" and "Undefined." We repeat this process for each of the eight classes and rank terms by their LLR score in descending order. We only keep terms that have higher frequency in the target class than for all the rest of the classes. This results in using as features only terms expected to be highly discriminative for our target class.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Strategies for Sampling Training Data</head><p>Machine learning methods are sensitive to the class distribution in the training set; this is a well described issue <ref type="bibr" coords="4,239.16,644.48,15.27,8.64" target="#b20">[22]</ref>. Some of RepLab's datasets, such as the one used for detecting reputation polarity, have different distributions among classes and between training and test set. These differences can potentially impact the classification effectiveness of a system. To this extent, we are interested in finding out what the effect is of balancing the training set of a classifier on its classification accuracy. Below, we describe three strategies for sampling training data. Similarly as before, we evaluate the system using ten fold cross validation on the training data, we repeat the process ten times, and we select the model with the highest accuracy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Setup</head><p>We conduct classification experiments to assess the discriminative power of our features for detecting the reputation dimension of a tweet. We are particularly interested in knowing the effectiveness of our extracted textual LLR features for each of the eight reputation dimension classes, and the effect of the three sampling strategies for selecting training data.</p><p>We submitted a total of 5 supervised systems where we probe the usefulness of machine learning algorithms for the current task. We list our runs in Table <ref type="table" coords="5,420.85,427.90,3.74,8.64" target="#tab_0">2</ref>. We train our classifiers regardless of any association with a given entity, since there are cases in the training data when not all classes are present for an entity (see Table <ref type="table" coords="5,410.92,451.81,3.60,8.64" target="#tab_1">3</ref>). In UvA RD 1 we choose to train an SVM classifier using all the available training tweets for each reputation dimension class, which implies that our classes are very unbalanced at this stage. In our next runs, UvA RD 2 and UvA RD 3, we randomly sample 214 tweets from each reputation dimension class and train a NB classifier, and respectively an SVM classifier. We also consider that using more training data can help our classifiers become more robust and better learn the distinguishing features of our classes. We explore a bootstrapping approach in runs UvA RD 4 and UvA RD 5, which train an NB classifier and an SVM classifier, respectively, using 7,738 tweets for each reputation dimension class. For under-represented classes we randomly sample from the labeled training data until we reach the defined threshold.</p><p>Dataset The Replab 2014 dataset is based on the Replab 2013 dataset and consists of automotive and banking related Twitter messages in English and Spanish, targeting a total number of 31 entities. Crawling the messages was performed in the period June -December 2012 using the entity's canonical name as query. For each entity, there are around 2,200 tweets collected: around 700 tweets at the beginning of the timeline used as training set, and approximately 1,500 tweets collected at a later stage reserved as and Spannish tweets. Our preprocessing steps are basic and aim to normalize text content: we lowercase the tweets, remove language specific stopwords and replace Twitter specific mentions @user, URLs and numbers with the [USER], [URL] and [NUMBER] placeholder tags. We consider of interest since users generally supply them to categorize and increase the visibility of a tweet. For this reason we delete hashmarks and preserve the remaining token, i.e., #BMW is converted to BMW, so that Twitter specific words cannot be distinguished from other words. We reduce character repetition inside words to at most 3 characters to differentiate between the regular and the emphasized usage of a word. All unnecessary characters ["#$%&amp;()?! * +,./:;&lt;=&gt;\Ë{}Ë] are discarded. We apply Porter stemming algorithm to reduce inflectional forms of related words to a basic common form.</p><p>Feature selection We select our textual features by applying the LLR approach; see Table <ref type="table" coords="7,159.88,377.81,4.98,8.64" target="#tab_2">4</ref> for the distribution of features over reputation dimensions in the training set. We represent each feature as a boolean value based on whether or not it occurs inside the tweet content. There is a bias towards extracting more features from the "Products &amp; Services" reputation dimension class, since the majority of tweets in the training data have this label. At the opposite end, the "Innovation" and "Leadership" classes are among the least represented in the training set, which explains their reduced presence inside our list of LLR extracted features.</p><p>Training We use supervised methods for text classification and choose to train an entity independent classifier. For our classifiers we consider Naive Bayes (NB) and a Support Vector Machines (SVM). We motivate our choice of classifiers based on their performance on text classification tasks that involve many word features <ref type="bibr" coords="7,424.15,511.15,16.13,8.64" target="#b9">[10,</ref><ref type="bibr" coords="7,440.28,511.15,12.10,8.64" target="#b10">11,</ref><ref type="bibr" coords="7,452.38,511.15,12.10,8.64" target="#b11">12,</ref><ref type="bibr" coords="7,464.47,511.15,12.10,8.64" target="#b17">19]</ref>. We train them using the different scenarios described in Section 4: making use of all training data, balancing classes to account for the least represented class ("Innovation", 214 tweets) and bootstrapping to consider for the most represented class ("Products &amp; Services", 7,738 tweets). We conduct our experiments using the natural language toolkit <ref type="bibr" coords="7,134.77,570.92,11.62,8.64" target="#b5">[6]</ref> and the scikit-learn framework <ref type="bibr" coords="7,275.00,570.92,15.27,8.64" target="#b12">[14]</ref>. We use NB with default nltk.classify settings; for SVM we choose a linear kernel.</p><p>Evaluation Replab 2014 allowed participants to send up to 5 runs per task. For the Reputation dimension task systems were asked to classify tweets into 7 reputation dimension classes (see Table <ref type="table" coords="7,225.16,632.53,3.69,8.64">1</ref>); samples tagged as "Undefined" according to human assessors are not considered in the evaluation. Performance is measured in terms of accuracy (% of correctly annotated cases), and precision, recall and F-measure over each class are reported for comparison purposes. In the evaluation of our system we also take into account the predictions made for the "Unknown" class. The predictions for this class were ignored in the official evaluation, and therefore the absolute numbers between the two evaluations do not match.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>We list the performance of our official runs in Tables <ref type="table" coords="8,355.53,342.97,4.98,8.64" target="#tab_3">5</ref> and<ref type="table" coords="8,381.46,342.97,3.74,8.64" target="#tab_4">6</ref>. All our runs perform better than the baseline (0.6221). We highlight the fact that we make predictions for all 8 classes, including the "Undefined" category which is not considered in the official evaluation. We also decide to ignore empty tweets, even though these are taken into consideration by the official evaluation script! Our most effective run is UvA RD 4, where we train a NB classifier using a bootstrapping approach to balance our classes. It is followed closely by UvA RD 5, which suggests that oversampling to balance classes towards the most representative class is a more sensible decision than using all training data or downsampling classes towards the least represented one. When we use all training data (UvA RD 1) we provide the SVM classifier with more informative features than when dropping tweets (in runs UvA RD 2, UvA RD 3), which confirms the usefulness of our LLR extracted features. Balancing classes with only 214 tweets per class can still yield competitive results, which are rather close to our previous approaches, and a lot more accurate in the case of the SVM classifier. We notice that NB constantly outperforms SVM. NB's better accuracy might be due to independence assumptions it makes among features, which is in line with other research carried on text classification tasks where NB classifiers output other methods with very competitive accuracy scores <ref type="bibr" coords="8,348.50,547.08,15.61,8.64" target="#b15">[17,</ref><ref type="bibr" coords="8,364.11,547.08,11.70,8.64" target="#b16">18,</ref><ref type="bibr" coords="8,375.81,547.08,7.80,8.64" target="#b7">8]</ref>.</p><p>Looking at the performance of our system per class, we find the following. The "Citizenship" and "Leadership" reputation dimension classes present high precision, followed by "Governance" and "Products &amp; Services." Recall is very high for the latter class, which comes as no surprise given the large number of features we extract with this label that tend to bias the predictions of our classifier towards "Products &amp; Services." The F1-measure is remarkably low for the "Innovation" class, since there are only few "Innovation" annotated tweets in the training set.</p><p>Detailed statistics of the number of tweets classified per reputation dimension class by our best system are presented in Table <ref type="table" coords="8,301.65,656.44,3.74,8.64" target="#tab_5">7</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Analysis</head><p>In our analysis section, we perform a further experiment to assess how much including empty tweets in the evaluation and making predictions for the "Unknown" class influences results in terms of accuracy. We regenerated our top two best runs excluding the "Undefined" features and removing the 427 empty annotated tweets from the gold standard test file. We report on an almost 3% improvement in accuracy for run UvA RD 4 (from 0.6704 to 0.6897) and a 2% increase in accuracy for run UvA RD 5 (from 0.6604 to 0.6739).</p><p>On the one hand, we believe it is difficult to assess the performance of submitted systems and compare methods for the task of detecting Reputation Dimensions on Twitter data among RepLab participants since making predictions for only 7 reputation dimension classes outperforms systems that consider the "Undefined" category. We are not convinced that including empty tweets in the evaluation is a good idea and we were expecting the test corpus to be re-crawled beforehand so as to ignore non-relevant entries from the gold standard file.</p><p>Finally, our suggestion is that results could be more reliable and useful if the ratio of classified tweets would actually be considered when establishing a hierarchy of sub- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8">Conclusion</head><p>We have presented a corpus-based approach for inferring textual features from labeled training data in addressing the task of detecting reputation dimensions in tweets at CLEF RepLab 2014. Our results show that machine learning techniques can perform reasonably accurate on text classification if the text is well modeled using appropriate feature selection methods. Our unigram and bigram LLR features combined with an NB classifier trained on balanced data confirm steady increases in performance when the classification model is inferred from more example documents with known class labels. In future work we plan to use Wikipedia pages and incorporate entity linking methods for to improve the detection of concepts underlying the reputation dimensions inside tweets. We would also like to probe the utility of some other classifiers, like Random Forests, at an entity level, and consider tweets separately by language.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,466.91,533.05,13.69,8.64;2,134.77,545.01,345.84,8.64;2,134.77,556.96,345.83,8.64;2,134.77,568.92,345.83,8.64;2,134.77,580.87,345.84,8.64;2,134.77,592.83,345.84,8.64;2,134.77,604.78,293.68,8.64"><head></head><label></label><figDesc>For training the classifiers we use the provided annotated tweets in the training set and explore three strategies for sampling training examples: (i) we use all training examples for all classes, (ii) we downsample classes to match the size of the smallest class, (iii) we oversample classes to match the size of the largest class. Our results show that our runs consistently outperform the baseline, and demonstrate that elaborate feature extraction and oversampling the training data peak classification accuracy at 0.6704.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,134.77,170.29,345.84,9.03;5,134.77,182.63,156.62,8.64;5,134.77,197.74,345.84,9.03;5,134.77,210.09,345.84,8.64;5,134.77,222.04,345.84,8.64;5,134.77,234.00,274.27,8.64;5,134.77,249.11,345.83,9.03;5,134.77,261.45,345.84,8.64;5,134.77,273.41,77.86,8.64"><head></head><label></label><figDesc>Unbalanced strategy. This strategy uses the original class distribution in the training data, and it uses all of the training data. Downsampling. This strategy downsamples the training examples of each class to match the size of the smallest class. Training examples are removed at random. We evaluate the system using ten fold cross validation on the training data, and we repeat the process ten times. We select the model with the highest accuracy. Oversampling. This strategy oversamples the training examples of each class to match the size of the largest class. For each class, training examples are selected at random and are duplicated.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,134.77,127.68,345.84,206.95"><head>Table 2 :</head><label>2</label><figDesc>Description of UvA's five runs for the reputation dimensions task at RepLab 2014 using either a Support Vector Machine (SVM) classifier or a Naive Bayes classifier (NB) and three strategies for sampling training data: all training data (All), downsampling (Down), and oversampling (Up). The corpus also comprises additional unlabeled background tweets for each entity (up to 50,000, with a large variability across entities). We make use of labeled tweets only and do not process messages for which the text content is not available or users profiles went private. The training set consists of 15,562 tweets. Out of these, we can access 15,294 (11,657 English, 3,637 Spanish) tweets. The test set consists of</figDesc><table coords="6,134.77,178.69,232.23,108.12"><row><cell>Run</cell><cell cols="2">Classifier Sampling</cell></row><row><cell cols="2">UvA RD 1 SVM</cell><cell>All</cell></row><row><cell cols="2">UvA RD 2 NB</cell><cell>Down</cell></row><row><cell cols="2">UvA RD 3 SVM</cell><cell>Down</cell></row><row><cell cols="2">UvA RD 4 NB</cell><cell>Up</cell></row><row><cell cols="2">UvA RD 5 SVM</cell><cell>Up</cell></row><row><cell>test set.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,134.77,370.71,345.84,294.36"><head>Table 3 :</head><label>3</label><figDesc></figDesc><table coords="6,134.77,413.96,345.84,251.11"><row><cell>Training set</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Total</cell><cell cols="5">7,738 214 459 1,298 2,165</cell><cell>292</cell><cell cols="2">931 2,197</cell></row><row><cell>Average/entity</cell><cell>249</cell><cell>6</cell><cell>14</cell><cell>41</cell><cell>69</cell><cell>9</cell><cell>30</cell><cell>70</cell></row><row><cell>Maximum/entity</cell><cell>563</cell><cell>42</cell><cell cols="2">80 358</cell><cell>461</cell><cell>99</cell><cell>81</cell><cell>387</cell></row><row><cell>Minimum/entity</cell><cell>12</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>2</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Test set</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Total</cell><cell cols="5">15,670 305 1,111 3,362 4,970</cell><cell>733</cell><cell cols="2">1,584 4,284</cell></row><row><cell>Average/entity</cell><cell>505</cell><cell>9</cell><cell cols="2">35 108</cell><cell>160</cell><cell>23</cell><cell>51</cell><cell>138</cell></row><row><cell>Maximum/entity</cell><cell cols="5">1,183 113 223 932 1,230</cell><cell>158</cell><cell>184</cell><cell>480</cell></row><row><cell>Minimum/entity</cell><cell>10</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>3</cell><cell>0</cell><cell>1</cell><cell>1</cell></row><row><cell cols="9">32,446 tweets, out of we which we make predictions for 32,019 (24,254 English, 7,765</cell></row><row><cell cols="8">Spanish) non-empty tweets. Table 3 summarizes our training and test datasets.</cell><cell></cell></row><row><cell cols="9">Preprocessing Normalization techniques help to reduce the large vocabulary size of the</cell></row><row><cell cols="9">standard unigram model. Social media posts are known for the lack of language regu-</cell></row><row><cell cols="9">larity, typically containing words in multiple forms, in upper and lower case, with char-</cell></row><row><cell cols="9">acter repetitions and misspellings. The presence of blogging annotations, abundance of</cell></row><row><cell cols="9">hashtags, emoticons, URLs, and heavy punctuation can be interpreted as possible in-</cell></row><row><cell cols="9">dicators of the rich meaning conveyed. We apply uniform lexical analysis to English</cell></row></table><note coords="6,170.28,370.71,310.32,8.64;6,134.77,382.66,125.47,8.64;6,227.13,398.16,233.13,7.77"><p><p>Distribution of training (top) and test (bottom) data per reputation dimension class (excluding empty tweets).</p>Prod./Serv. Innov. Work Gov. Citizen. Leader. Perform. Undef.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,134.77,127.68,345.83,62.14"><head>Table 4 :</head><label>4</label><figDesc>Distribution of extracted textual features per reputation dimension class using log-likelihood ratio (LLR) on the training dataset.</figDesc><table coords="7,164.29,155.13,286.78,34.69"><row><cell></cell><cell cols="7">Prod./Serv. Innov. Work Gov. Citizen. Leader. Perform. Undef.</cell></row><row><cell>LLR Unigrams</cell><cell>2,032</cell><cell>9</cell><cell>45 218</cell><cell>360</cell><cell>34</cell><cell>105</cell><cell>223</cell></row><row><cell>LLR Bigrams</cell><cell>1,012</cell><cell>24</cell><cell>50 151</cell><cell>109</cell><cell>22</cell><cell>133</cell><cell>143</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,134.85,127.68,345.68,83.06"><head>Table 5 :</head><label>5</label><figDesc>Official results for our runs for the reputation dimension task at RepLab 2014.</figDesc><table coords="8,226.21,142.82,162.93,67.92"><row><cell cols="2">System Accuracy Classified tweets (%)</cell></row><row><cell>UvA RD 1 0.6520</cell><cell>0.9112</cell></row><row><cell>UvA RD 2 0.6468</cell><cell>0.9494</cell></row><row><cell>UvA RD 3 0.6254</cell><cell>0.9445</cell></row><row><cell>UvA RD 4 0.6704</cell><cell>0.9526</cell></row><row><cell>UvA RD 5 0.6604</cell><cell>0.9566</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,134.77,127.68,345.84,291.36"><head>Table 6 :</head><label>6</label><figDesc>System performance for the reputation dimension task using log-likelihood ratio features. We report on precision, recall and F1-score for each reputation dimension class, averaged over all entities.</figDesc><table coords="9,136.16,167.08,343.78,251.96"><row><cell cols="8">Metric Prod.&amp;Serv. Innovation Workplace Governance Citizenship Leadership Performance</cell></row><row><cell>UvA RD 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Precision 0.6134</cell><cell>0.1666</cell><cell>0.5901</cell><cell>0.5469</cell><cell>0.8176</cell><cell>0.7226</cell><cell>0.4043</cell></row><row><cell>Recall</cell><cell>0.9067</cell><cell>0.0130</cell><cell>0.1281</cell><cell>0.3192</cell><cell>0.4762</cell><cell>0.1155</cell><cell>0.1176</cell></row><row><cell>F1-score</cell><cell>0.7317</cell><cell>0.0241</cell><cell>0.2105</cell><cell>0.4031</cell><cell>0.6018</cell><cell>0.1991</cell><cell>0.1822</cell></row><row><cell>UvA RD 2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Precision 0.6317</cell><cell>0.2758</cell><cell>0.1110</cell><cell>0.4617</cell><cell>0.8228</cell><cell>0.7130</cell><cell>0.4120</cell></row><row><cell>Recall</cell><cell>0.8919</cell><cell>0.0261</cell><cell>0.2455</cell><cell>0.2612</cell><cell>0.5120</cell><cell>0.1102</cell><cell>0.1026</cell></row><row><cell>F1-score</cell><cell>0.7395</cell><cell>0.0476</cell><cell>0.1528</cell><cell>0.3336</cell><cell>0.6312</cell><cell>0.1908</cell><cell>0.1642</cell></row><row><cell>UvA RD 3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Precision 0.6678</cell><cell>0.0159</cell><cell>0.5232</cell><cell>0.4941</cell><cell>0.7965</cell><cell>0.5170</cell><cell>0.3460</cell></row><row><cell>Recall</cell><cell>0.8220</cell><cell>0.2026</cell><cell>0.2402</cell><cell>0.2871</cell><cell>0.5740</cell><cell>0.1223</cell><cell>0.1357</cell></row><row><cell>F1-score</cell><cell>0.7369</cell><cell>0.0294</cell><cell>0.3292</cell><cell>0.3631</cell><cell>0.6671</cell><cell>0.1978</cell><cell>0.1949</cell></row><row><cell>UvA RD 4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Precision 0.6041</cell><cell>0.2307</cell><cell>0.1300</cell><cell>0.6214</cell><cell>0.8553</cell><cell>0.7727</cell><cell>0.4660</cell></row><row><cell>Recall</cell><cell>0.9322</cell><cell>0.0098</cell><cell>0.1147</cell><cell>0.2698</cell><cell>0.5446</cell><cell>0.0913</cell><cell>0.0988</cell></row><row><cell>F1-score</cell><cell>0.7331</cell><cell>0.0188</cell><cell>0.1218</cell><cell>0.3762</cell><cell>0.6654</cell><cell>0.1633</cell><cell>0.1630</cell></row><row><cell>UvA RD 5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Precision 0.6144</cell><cell>0.0194</cell><cell>0.5253</cell><cell>0.6011</cell><cell>0.8015</cell><cell>0.7128</cell><cell>0.4018</cell></row><row><cell>Recall</cell><cell>0.9055</cell><cell>0.0947</cell><cell>0.0738</cell><cell>0.3360</cell><cell>0.5279</cell><cell>0.0967</cell><cell>0.1101</cell></row><row><cell>F1-score</cell><cell>0.7320</cell><cell>0.0322</cell><cell>0.1294</cell><cell>0.4310</cell><cell>0.6365</cell><cell>0.1702</cell><cell>0.1728</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="10,134.77,127.68,345.84,199.27"><head>Table 7 :</head><label>7</label><figDesc>Number of classified tweets for our best run, UvA RD 4, per reputation dimension compared to the number of tweets in the gold standard. We were surprised to see systems with high accuracy scores ranking high up in the charts despite classifying fewer tweets than other runs with lower accuracy scores and more test set samples considered. It is well-known that accuracy is highly dependent upon the percentage of instances classified.</figDesc><table coords="10,134.77,154.78,261.49,136.31"><row><cell>Dimension</cell><cell cols="2">UvA RD 4 Gold Standard</cell></row><row><cell>Products &amp; Services</cell><cell>24,075</cell><cell>15,903</cell></row><row><cell>Innovation</cell><cell>13</cell><cell>306</cell></row><row><cell>Workplace</cell><cell>982</cell><cell>1,124</cell></row><row><cell>Governance</cell><cell>1,458</cell><cell>3,395</cell></row><row><cell>Citizenship</cell><cell>3,192</cell><cell>5,027</cell></row><row><cell>Leadership</cell><cell>87</cell><cell>744</cell></row><row><cell>Performance</cell><cell>332</cell><cell>1,598</cell></row><row><cell>Undefined</cell><cell>1,333</cell><cell>4,349</cell></row><row><cell>mitted runs.</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,635.80,161.89,6.31"><p>http://www.limosine-project.eu</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,144.73,646.97,334.53,6.31;1,144.73,657.93,113.97,6.31"><p>http://www.reputationinstitute.com/about-reputation-institute/ the-reptrak-framework</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This research was partially supported by the <rs type="funder">European Community</rs>'s <rs type="programName">Seventh Framework Programme</rs> (<rs type="grantNumber">FP7/2007-2013</rs>) under grant agreements nr <rs type="grantNumber">288024</rs> (LiMoSINe) and nr <rs type="grantNumber">312827</rs> (<rs type="funder">VOX-Pol</rs>), the <rs type="funder">Netherlands Organisation for Scientific Research (NWO)</rs> under project nrs <rs type="grantNumber">727.011.005</rs>, <rs type="grantNumber">612.001.116</rs>, <rs type="grantNumber">HOR-11-10</rs>, <rs type="grantNumber">640.006.013</rs>, the <rs type="funder">Center for Creation, Content and Technology (CCCT)</rs>, the <rs type="projectName">QuaMerdes</rs> project funded by the <rs type="programName">CLA-RIN-nl program</rs>, the <rs type="projectName">TROVe</rs> project funded by the <rs type="programName">CLARIAH program</rs>, the <rs type="programName">Dutch national program</rs> <rs type="projectName">COMMIT</rs>, the <rs type="programName">ESF Research Network Program</rs> <rs type="projectName">ELIAS</rs>, the <rs type="projectName">Elite Network Shifts</rs> project funded by the <rs type="funder">Royal Dutch Academy of Sciences (KNAW)</rs>, the <rs type="funder">Netherlands eScience Center</rs> under project number <rs type="grantNumber">027.012.105</rs>, the <rs type="programName">Yahoo! Faculty Research and Engagement Program</rs>, the <rs type="programName">Microsoft Research PhD program</rs>, and the <rs type="funder">HPC Fund</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_PDQ6jNg">
					<idno type="grant-number">FP7/2007-2013</idno>
					<orgName type="program" subtype="full">Seventh Framework Programme</orgName>
				</org>
				<org type="funding" xml:id="_AYKDyyF">
					<idno type="grant-number">288024</idno>
				</org>
				<org type="funding" xml:id="_FD2VWm3">
					<idno type="grant-number">312827</idno>
				</org>
				<org type="funding" xml:id="_5hzWh4f">
					<idno type="grant-number">727.011.005</idno>
				</org>
				<org type="funding" xml:id="_UP4Tk8y">
					<idno type="grant-number">612.001.116</idno>
				</org>
				<org type="funding" xml:id="_JPJPe9j">
					<idno type="grant-number">HOR-11-10</idno>
				</org>
				<org type="funded-project" xml:id="_cCa5Rzu">
					<idno type="grant-number">640.006.013</idno>
					<orgName type="project" subtype="full">QuaMerdes</orgName>
					<orgName type="program" subtype="full">CLA-RIN-nl program</orgName>
				</org>
				<org type="funded-project" xml:id="_XeJUYrt">
					<orgName type="project" subtype="full">TROVe</orgName>
					<orgName type="program" subtype="full">CLARIAH program</orgName>
				</org>
				<org type="funded-project" xml:id="_XHdRsZp">
					<orgName type="project" subtype="full">COMMIT</orgName>
					<orgName type="program" subtype="full">Dutch national program</orgName>
				</org>
				<org type="funded-project" xml:id="_g6WD8wa">
					<orgName type="project" subtype="full">ELIAS</orgName>
					<orgName type="program" subtype="full">ESF Research Network Program</orgName>
				</org>
				<org type="funded-project" xml:id="_Eq5XH7k">
					<orgName type="project" subtype="full">Elite Network Shifts</orgName>
				</org>
				<org type="funding" xml:id="_hMBU6Fy">
					<idno type="grant-number">027.012.105</idno>
					<orgName type="program" subtype="full">Yahoo! Faculty Research and Engagement Program</orgName>
				</org>
				<org type="funding" xml:id="_UnM9sbR">
					<orgName type="program" subtype="full">Microsoft Research PhD program</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="11,138.13,142.68,342.45,7.77;11,150.95,153.49,293.46,7.93" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,376.48,142.68,104.10,7.77;11,150.95,153.64,13.74,7.77">Sentiment analysis of Twitter data</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Vovsha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Rambow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Passonneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,180.09,153.49,210.82,7.72">Proceedings of the Workshop on Language in Social Media</title>
		<meeting>the Workshop on Language in Social Media</meeting>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="30" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.13,164.56,342.45,7.77;11,150.95,175.52,329.63,7.77;11,150.95,186.32,329.64,7.93;11,150.95,197.44,199.94,7.77" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,236.40,175.52,244.18,7.77;11,150.95,186.48,26.81,7.77">Overview of Replab 2013: Evaluating online reputation monitoring systems</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>AmigÃ³</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carrillo-De-Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Chugur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Corujo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Meij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,192.55,186.32,284.54,7.72">Information Access Evaluation. Multilinguality, Multimodality and Visualization</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="volume">8138</biblScope>
			<biblScope unit="page" from="333" to="352" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.13,208.36,342.45,7.77;11,150.95,219.32,329.63,7.77;11,150.95,230.12,329.63,7.93;11,150.95,241.08,155.69,7.93" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,205.19,219.32,275.39,7.77;11,150.95,230.27,112.66,7.77">Overview of RepLab 2014: author profiling and reputation dimensions for Online Reputation Management</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>AmigÃ³</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carrillo-De-Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Chugur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Corujo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Meij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,279.86,230.12,200.72,7.72;11,150.95,241.08,55.63,7.72">Proceedings of the Fifth International Conference of the CLEF Initiative</title>
		<meeting>the Fifth International Conference of the CLEF Initiative<address><addrLine>Sheffield, UK</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014-09">Sept. 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.13,252.15,342.45,7.77;11,150.95,262.96,329.63,7.93;11,150.95,273.92,106.03,7.93" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,402.03,252.15,78.55,7.77;11,150.95,263.11,217.40,7.77">Overview of Replab 2012: Evaluating online reputation management systems</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>AmigÃ³</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Corujo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Meij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,390.44,262.96,90.14,7.72;11,150.95,273.92,79.63,7.72">CLEF (Online Working Notes/Labs/Workshop)</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.13,284.99,342.45,7.77;11,150.95,295.80,329.64,7.93;11,150.95,306.91,20.17,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,346.83,284.99,133.75,7.77;11,150.95,295.95,96.81,7.77">Reina at RepLab 2013 topic detection task: Community detection</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L A</forename><surname>Berrocal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">G</forename><surname>Figuerola</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Z</forename><surname>Rodriguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,264.17,295.80,212.14,7.72">CLEF 2013 Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.13,317.68,342.46,7.93;11,150.95,328.79,123.02,7.77" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="11,265.32,317.68,152.03,7.72">Natural Language Processing with Python</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Loper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>O&apos;Reilly Media Inc</publisher>
			<pubPlace>Sebastopol, California</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.13,339.71,342.45,7.77;11,150.95,350.51,329.63,7.93;11,150.95,361.47,102.91,7.93" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,340.50,339.71,140.08,7.77;11,150.95,350.67,185.02,7.77">Modelling techniques for Twitter contents: A step beyond classification based approaches</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Castellanos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Cigarran</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Garcia-Serrano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,351.47,350.51,129.11,7.72;11,150.95,361.47,76.21,7.72">CLEF 2013 Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.13,372.54,342.45,7.77;11,150.95,383.35,287.82,7.93" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,312.48,372.54,168.09,7.77;11,150.95,383.50,17.23,7.77">Detecting the reputation polarity of microblog posts</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>GÃ¢rbacea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Tsagkias</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,183.58,383.35,229.35,7.72">ECAI 2014: 21st European Conference on Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,138.13,394.42,342.45,7.77;11,150.95,405.23,272.19,7.93" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,250.58,394.42,230.00,7.77;11,150.95,405.38,21.56,7.77">Filtering and polarity detection for reputation management on tweets</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Hangya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Farkas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,188.06,405.23,208.39,7.72">CLEF 2013 Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,416.30,338.34,7.77;11,150.95,427.11,329.63,7.93;11,150.95,438.22,48.06,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,199.26,416.30,281.32,7.77;11,150.95,427.26,44.63,7.77">Text categorization with Support Vector Machines: Learning with many relevant features</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,210.85,427.11,174.32,7.72">10th European Conference on Machine Learning</title>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="137" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,449.14,338.34,7.77;11,150.95,459.95,329.62,7.93;11,150.95,470.90,178.08,7.93" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,198.26,449.14,278.19,7.77">A statistical learning model of text classification for Support Vector Machines</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Joachims</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,161.01,459.95,319.57,7.72;11,150.95,470.90,69.09,7.72">24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="128" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,481.98,338.34,7.77;11,150.95,492.78,329.63,7.93;11,150.95,503.90,20.17,7.77" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,260.19,481.98,220.38,7.77;11,150.95,492.94,20.70,7.77">A comparison of event models for Naive Bayes text classification</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Nigam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,186.94,492.78,192.69,7.72">AAAI-98 Workshop on learning for text categorization</title>
		<imprint>
			<publisher>AAAI Press</publisher>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="41" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,514.66,338.35,7.93;11,150.95,525.62,115.83,7.93" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,221.77,514.82,145.92,7.77">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,374.20,514.66,106.38,7.72;11,150.95,525.62,31.23,7.72">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,536.69,338.34,7.77;11,150.95,547.50,329.63,7.93;11,150.95,558.46,112.13,7.93" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,339.23,536.69,141.35,7.77;11,150.95,547.65,190.62,7.77">Towards and active learning system for company name disambiguation in microblog streams</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">H</forename><surname>Peetz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,358.12,547.50,122.47,7.72;11,150.95,558.46,85.43,7.72">CLEF 2013 Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,569.38,338.35,7.93;11,150.95,580.34,170.78,7.93" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,250.89,569.53,165.10,7.77">Comparing corpora using frequency profiling</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Rayson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Garside</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,432.99,569.38,47.60,7.72;11,150.95,580.34,68.21,7.72">Workshop on comparing corpora</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,591.26,338.35,7.93;11,150.95,602.22,329.64,7.93;11,150.95,613.33,33.62,7.77" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,180.01,591.41,174.22,7.77">An empirical study of the Naive Bayes classifier</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Rish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,359.86,591.26,120.73,7.72;11,150.95,602.22,285.11,7.72">International Joint Conference in Artificial Intelligence. Workshop on Empirical Methods in Artificial Intelligence</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,624.25,338.34,7.77;11,150.95,635.05,268.98,7.93" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="11,289.55,624.25,191.03,7.77;11,150.95,635.21,67.74,7.77">An analysis of data characteristics that affect Naive Bayes performance</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Rish</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hellerstein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Thathachar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,224.90,635.05,168.72,7.72">International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,646.13,338.34,7.77;11,150.95,656.93,154.16,7.93" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="11,214.71,646.13,265.86,7.77;11,150.95,657.09,25.90,7.77">Techniques for improving the performance of Naive Bayes for text classification</title>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">M</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,192.05,656.93,29.43,7.72">CICLing</title>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="682" to="693" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,119.96,338.34,7.77;12,150.95,130.77,329.63,7.93;12,150.95,141.73,89.72,7.93" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="12,430.38,119.96,50.19,7.77;12,150.95,130.92,141.98,7.77">UNED online reputation monitoring team at RepLab</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>De Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Giner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,330.69,130.77,149.89,7.72;12,150.95,141.73,63.02,7.72">CLEF 2013 Conference and Labs of the Evaluation Forum</title>
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,152.69,338.35,7.93;12,150.95,163.64,141.15,7.93" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="12,249.06,152.84,171.67,7.77">Selecting systemic features for text classification</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Whitelaw</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Patrick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,435.07,152.69,45.52,7.72;12,150.95,163.64,114.53,7.72">Australasian Language Technology Workshop</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.24,174.60,338.35,7.93;12,150.95,185.72,148.46,7.77" xml:id="b20">
	<monogr>
		<title level="m" type="main" coord="12,244.84,174.60,231.92,7.72">Data Mining: Practical Machine Learning Tools and Techniques</title>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
			<publisher>Morgan Kaufmann Publishers Inc</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
