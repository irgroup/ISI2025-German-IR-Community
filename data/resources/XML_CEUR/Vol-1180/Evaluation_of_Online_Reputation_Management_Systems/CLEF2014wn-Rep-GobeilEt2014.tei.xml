<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,158.06,151.67,290.81,12.54;1,156.14,169.07,283.14,12.54">INSTANCE-BASED LEARNING FOR TWEET CATEGORIZATION IN CLEF REPLAB 2014</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,199.94,207.32,56.25,9.05"><forename type="first">Julien</forename><surname>Gobeill</surname></persName>
							<email>julien.gobeill@hesge.ch</email>
							<affiliation key="aff0">
								<orgName type="department">HEG / HES-SO</orgName>
								<orgName type="laboratory">BiTeM group</orgName>
								<orgName type="institution">University of Applied Sciences</orgName>
								<address>
									<addrLine>7 rte de Drize</addrLine>
									<postCode>1227</postCode>
									<settlement>Carouge</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">SIBtex group</orgName>
								<orgName type="institution">SIB Swiss Institute of Bioinformatics</orgName>
								<address>
									<addrLine>1 rue Michel-Servet</addrLine>
									<postCode>1206</postCode>
									<settlement>Genève</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,269.45,207.32,69.05,9.05"><forename type="first">Arnaud</forename><surname>Gaudinat</surname></persName>
							<email>arnaud.gaudinat@hesge.ch</email>
							<affiliation key="aff0">
								<orgName type="department">HEG / HES-SO</orgName>
								<orgName type="laboratory">BiTeM group</orgName>
								<orgName type="institution">University of Applied Sciences</orgName>
								<address>
									<addrLine>7 rte de Drize</addrLine>
									<postCode>1227</postCode>
									<settlement>Carouge</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,346.87,207.32,51.84,9.05"><forename type="first">Patrick</forename><surname>Ruch</surname></persName>
							<email>patrick.ruch@hesge.ch</email>
							<affiliation key="aff0">
								<orgName type="department">HEG / HES-SO</orgName>
								<orgName type="laboratory">BiTeM group</orgName>
								<orgName type="institution">University of Applied Sciences</orgName>
								<address>
									<addrLine>7 rte de Drize</addrLine>
									<postCode>1227</postCode>
									<settlement>Carouge</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">SIBtex group</orgName>
								<orgName type="institution">SIB Swiss Institute of Bioinformatics</orgName>
								<address>
									<addrLine>1 rue Michel-Servet</addrLine>
									<postCode>1206</postCode>
									<settlement>Genève</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,158.06,151.67,290.81,12.54;1,156.14,169.07,283.14,12.54">INSTANCE-BASED LEARNING FOR TWEET CATEGORIZATION IN CLEF REPLAB 2014</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D6CAFBAA0F7A149373D80300205AFE46</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>BiTeM/SIBtex is a university research group with a strong background in Text Mining and Bibliomics, and a long tradition of participating in large evaluation campaigns. The CLEF RepLab 2014 Track was the occasion to integrate several local tools into a complete system for tweet monitoring and categorization based on instance-based learning. The algorithm we implemented was a k Nearest Neighbors. Dealing with the domain (automotive or banking) and the language (English or Spanish), the experiments showed that the categorizer was not affected by the choice of representation: even with all data merged into one single Knowledge Base (KB), the observed performances were close to those with dedicated KBs. Furthermore, English training data in addition to the sparse Spanish data were useful for Spanish categorization (+14% for accuracy for automotive, +26% for banking). Finally, our best official run was in top five. Yet, performances suffered from an overprediction of the most prevalent category, while we were not able to address this issue of unbalanced labels within the competition time. The algorithm showed the defects of its virtues: it was very robust, but not easy to improve. BiTeM/SIBtex tools for tweet monitoring are available within the DrugsListener Project page of the BiTeM website (http://bitem.hesge.ch/).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.32" lry="842.04"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>BiTeM/SIBtex is a university research group with a strong background in Text Mining and Bibliomics, and a particular focus on clinical and biological data. Occasionally, the group is involved in studies with data from the intellectual property (granted patents) or the social media (tweets and reviews) domains. Finally, the group has a long tradition of participating in large evaluation campaigns, such as TREC, NTCIR or CLEF <ref type="bibr" coords="1,196.82,608.53,7.52,9.05" target="#b0">[1]</ref><ref type="bibr" coords="1,204.34,608.53,3.76,9.05" target="#b1">[2]</ref><ref type="bibr" coords="1,204.34,608.53,3.76,9.05" target="#b2">[3]</ref><ref type="bibr" coords="1,208.10,608.53,7.52,9.05" target="#b3">[4]</ref>. The CLEF RepLab 2014 Track was the occasion to integrate several local tools into a complete system, and to evaluate a simple and robust statistical approach for tweet classification in competition.</p><p>BiTeM/SIBtex only took part in the first task: Reputation Dimensions. The goal of the task was to perform text categorization on Twitter, i.e. to design a system able to assign a predefined category to a tweet. This category was one out of eight related to companies' reputations. All tweets dealt with entities from the automotive (20 entities) or the banking (11 entities) domain, and were in English (93%) or in Spanish (7%). For training and/or learning purposes, participants were provided with approximately 15,000 tweets labeled by human experts (the training set). Additionally, participants were allowed to use provided sets of tweets related to the mentioned companies for incorporating domain knowledge. Then, the systems had to predict the good categories for 32,000 unlabeled tweets (the test set).</p><p>In this task, the main difficulty was to efficiently preprocess the text, as standard Natural Language Processing strategies can fail to deal with the short, noisy, and strongly contextualised nature of the tweets. Another difficulty was to efficiently learn from unbalanced classes: indeed, the "Products &amp; Services" category was assigned to 44% of the training tweets, versus only 1% for the "Innovation" category. Finally, this was a multilingual task, but the language distribution also was unbalanced, with less than 10% Spanish learning instances. We applied a simple and robust statistical approach in order to design our system, based on instance-based learning for categorization purposes. Instance-based learning is a kind of machine learning that compares unseen instances with labelled instances contained in a Knowledge Base (KB). The instance-based learning algorithm we chose to implement is k Nearest Neighbors (k-NN).</p><p>Three particular questions were investigated during this study:</p><p>-Q1 : is it better to build one KB for each domain, or to merge automotive and banking into the same KB ? -Q2 : is it better to build one KB for each language, or to merge English and Spanish into the same KB ? -Q3 : as the labels are unbalanced, is it efficient to use weighting strategies for categorization ?</p><p>2 Methods</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Overall architecture of the system</head><p>Figure <ref type="figure" coords="2,165.10,555.85,4.98,9.05" target="#fig_0">1</ref> illustrates the overall architecture of our system. The workflow is divided into two steps: the training phase (offline), and the test phase (online). Three independent components act cooperatively to preprocess data (component 1), building the knowledge base (component 2) and classifying tweets (component 3). During the training phase, all tweets belonging to the training set were preprocessed by component 1. Component 1 is composed of several standard Natural Language Processing treatments, along with a language detector. Then, they were indexed in one or several indexes by component 2, in order to make the KB. Component 2 is an Information Retrieval platform, which builds indexes for related documents retrieval.</p><p>During the test phase, all tweets belonging to the test set also were preprocessed by component 1. Then, for a given test tweet, the component 3 (k-NN) exploited the KB in order to retrieve the most similar tweets seen in the training data, and to infer a predicted category. Official runs were computed with the whole test set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Data</head><p>A training set of approximately 15,000 labelled tweets was provided by the organizers. There as an average of 511 tweets for an automotive entity, versus 485 for a banking entity. Table <ref type="table" coords="3,221.54,652.72,4.98,9.05" target="#tab_0">1</ref> shows the average distribution of each category for a given entity. Here is a representative example of a tweet: 208844584137134080: Me and a sexy BMW M3 at last nights shoot &lt;a href="http://t.co/ibW6sdXW" class="twitter-timeline-link" data-pre-embedded="true" dir="ltr" &gt;pic.twitter.com/ibW6sdXW&lt;/a&gt; Tweets often contain metadata within tags, the most frequent being hyperlinks (&lt;a&gt;) and emphasis (&lt;b&gt;). Moreover, they often don't have proper punctuation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Preprocessing</head><p>The goal of the component 1 was to preprocess the tweets in order to have proper and efficient instances to index (for the training phase) or search (for the test phase). For this purpose, a set of basic rules was applied. Tags were first discarded. Contents within an emphasis tag (&lt;b&gt;) were repeated in order to be overweighted. Contents within a hyperlink tag (&lt;a&gt;) also were repeated, and were preceded by the "HREF" mention.</p><p>For language detection purposes, we performed simple N-Gram-Based Text Categorization, based on the Cavnar and Trenkle works <ref type="bibr" coords="4,360.45,568.81,10.85,9.05" target="#b4">[5]</ref>. This approach aims at comparing n-grams frequency profiles in a given text, with profiles observed in large English and Spanish corpus. This simple approach is reported to have an accuracy in the range of 92% to 99%. N-grams profiles were taken from [6].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Indexing</head><p>The goal of the component 2 was to build one or several indexes from the training data, in order to obtain a related documents search engine. For this purpose, we used the Terrier platform <ref type="bibr" coords="5,215.21,149.48,10.69,9.05" target="#b5">[7]</ref>. We used default stemming, stop words and a Poisson weighting scheme (PL2).</p><p>Dealing with Q1 and Q2, we investigated several strategies and built several indexes:</p><p>all: a unique index with all the training tweets; -cars: an index with all tweets from the automotive domain; -banks: an index with all tweets from the banking domain; -cars_en: an index with all English tweets from the automotive domain; -banks_en: an index with all English tweets from the banking domain; -cars_es: an index with all Spanish tweets from the automotive domain; -banks_es: an index with all Spanish tweets from the banking domain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">k-NN</head><p>The goal of the component 3 was to categorize tweets from the test set. For this purpose, we used a k-NN, a remarkably simple algorithm which assigns to a new text the categories that are the most prevalent among the k most similar tweets contained in the KB <ref type="bibr" coords="5,170.06,355.07,10.69,9.05" target="#b6">[8]</ref>. Similar tweets were retrieved thanks to component 2. Then, a score computer inferred the category from the k most similar instances, following this formula:</p><formula xml:id="formula_0" coords="5,199.71,402.21,209.12,21.81">) ( ) , ( max arg } ... , { 2 1 i K x i c c c c x RSV c x E predcat i m     </formula><p>where predcat is the predicted category for a test tweet, c1,c2…cm are the possible categories, K is the set of the k nearest neighbors of the test tweet, RSV(xi) is the retrieval status value given by the component 2 (i.e. the similarity score) of the neighbor xi, and E(xi,c) is 1 when xi is of category c, 0 otherwise. Dealing with Q3, an additional score computing was tested for handling the issue of unbalanced labels when using a k-NN. Several studies were conducted for such an issue <ref type="bibr" coords="5,148.10,520.09,7.88,9.05" target="#b7">[9]</ref><ref type="bibr" coords="5,155.98,520.09,3.94,9.05" target="#b8">[10]</ref><ref type="bibr" coords="5,155.98,520.09,3.94,9.05" target="#b9">[11]</ref><ref type="bibr" coords="5,159.92,520.09,11.82,9.05" target="#b10">[12]</ref>. Solutions varies from rebalancing the training data to injecting weights in the score computing. The conclusions about how the k-NN really suffers from unbalanced data are not always concrete. Due to a lack of time, we investigated only one solution and chose to compute a weight associated to the local distribution of training tweets. The formula thus evolved into:</p><formula xml:id="formula_1" coords="5,156.96,590.21,282.51,21.74">) , , ( ) ( ) , ( max arg } ... , { 2 1 c d k x W x RSV c x E predcat i i K x i c c c c i m       </formula><p>where d is a parameter and W(xi,k+d,c) is the frequency of training tweets from category c in the set of the k nearest neighbors of xi.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results and Discussions</head><p>The Q1, Q2 and Q3 issues were addressed with the training data, thanks to a ten-fold cross validation strategy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Q1: is it better to build one KB for each domain, or to merge automotive and banking into the same KB ?</head><p>First, we investigated Q1, by exploiting the all, cars, and banks indexes. Both languages were merged into the same indexes. Figures <ref type="figure" coords="6,377.47,267.83,9.45,9.05" target="#fig_1">2a</ref> and<ref type="figure" coords="6,414.27,267.83,10.01,9.05" target="#fig_2">2b</ref> show the performances of the system for different values of k.  Experiments showed that the optimal k for these data was around 10. They also showed that throughout the curves, it was better to use specific indexes (orange curves) versus a unique merged index (blue curves). Yet, the difference between best performances is not significant, with an accuracy of 0.69 for the all and the banks indexes for banks tweets (at k=10), and accuracies of 0.77 versus 0.76 for the cars index and the all index. We can say that, for categorizing tweets from a given domain, data from the other domain do not provide useful information, but do not degrade the optimal performances, thanks to the k-NN robustness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Q2: is it better to build one KB for each language, or to merge English and Spanish into the same KB ?</head><p>Second, we investigated Q2, especially for the Spanish language that represented less than 7% of the training data. We exploited the cars, banks, cars_es and banks_es indexes. Figures <ref type="figure" coords="7,193.98,286.07,9.45,9.05" target="#fig_3">3a</ref> and<ref type="figure" coords="7,224.17,286.07,10.01,9.05" target="#fig_4">3b</ref> show the performances of the system for different values of k.  Experiments showed that the optimal k for Spanish data was around 30, significantly higher than the general case. This could be explained by the smaller set of Spanish instances. They also showed that it was better to use both languages indexes (orange curves) versus a Spanish-specific index (blue curves). We can say that, for categorizing tweets from Spanish, an additional amount of English data provides useful information and increases the top accuracy (from 0.69 to 0.79 for cars, from 0.57 to 0.72 for banks).</p><p>The same experiments with the English language (not reported) showed no significant differences between the merged and the English-specific indexes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Q3: as the labels are unbalanced, is it efficient to use weighting strategies for categorization ?</head><p>The last experiments aimed at tuning the k-NN for dealing with unbalanced labels. Results with different values of d (not reported) showed no improvements from the unweighted k-NN. Other strategies need to be investigated fur this issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Official submissions and results</head><p>We finally submitted two runs. For both runs, the automotive and banking training tweets were in separate Knowledge Bases. For run 1 (SIBtex_RD_1), we used a merged index for both languages. For run 2 (SIBtex_RD_2), we used specific languages. The best accuracy in the competition was 0.731. SIBtex_RD_1 had an official accuracy of 0.707 and was ranked #4. SIBtex_RD_2 had an official accuracy of 0.704 and was ranked #6. Interestingly, performances were better with the test set.</p><p>Official statistics also showed that, in our run, the "Products &amp; Services" category was overrepresented (68% instead of 49% in the gold standard). Although we failed to design an efficient strategy for dealing with unbalanced data, this distribution shows that our k-NN probably suffered from this issue.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>We designed a complete system for tweet categorization according to predefined reputational categories. Dealing with the domain (automotive or banking) and the language (English or Spanish), we explored a range of representations and wanted to know if it was better to use separate or merged Knowledge Bases. The experiments showed that the k-NN was not very affected by the kind of representations: even with all data merged into one single KB, the observed performances are close to those observed with dedicated KB. Moreover, English training data were useful for Spanish categorization (+14% for accuracy for automotive, +26% for banking). Yet, the unbalanced labels make the k-NN to predict the most prevalent category ("Products &amp; Services") more often than necessary (68% instead of 49%); this issue needs to be investigated in future works. The k-NN showed the defects of its virtues: it was robust, but not easy to improve. BiTeM/SIBtex tools for tweet monitoring are available within the DrugsListener Project page of the BiTeM website <ref type="bibr" coords="9,407.95,161.00,15.39,9.05">[13]</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,221.93,448.94,141.53,7.31;3,138.25,147.35,318.85,299.90"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overall architecture of the system</figDesc><graphic coords="3,138.25,147.35,318.85,299.90" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,148.22,449.90,310.39,7.31;6,187.82,459.01,219.86,7.32;6,161.65,300.40,283.45,148.05"><head>Figure 2a :</head><label>2a</label><figDesc>Figure 2a: Performances for the cars test set, using the all index (all training data merged) or the specific cars index (only cars training data), for different values of k.</figDesc><graphic coords="6,161.65,300.40,283.45,148.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,144.98,625.48,316.94,7.32;6,182.06,634.72,231.38,7.32;6,161.65,475.80,283.45,148.05"><head>Figure 2b :</head><label>2b</label><figDesc>Figure 2b: Performances for the banks test set, using the all index (all training data merged) or the specific banks index (only banks training data), for different values of k.</figDesc><graphic coords="6,161.65,475.80,283.45,148.05" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="7,146.78,470.18,313.00,7.31;7,154.58,479.41,286.46,7.32;7,155.85,321.15,283.45,147.50"><head>Figure 3a :</head><label>3a</label><figDesc>Figure 3a: Performances for the cars -Spanish test set, using the cars index (English and Spanish merged) or the specific cars -Spanish index (only Spanish data), for different values of k.</figDesc><graphic coords="7,155.85,321.15,283.45,147.50" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="7,140.90,650.21,325.05,7.31;7,151.58,659.44,292.34,7.32;7,156.00,500.70,283.45,147.85"><head>Figure 3b :</head><label>3b</label><figDesc>Figure 3b: Performances for the banks -Spanish test set, using the banks index (English and Spanish merged) or the specific banks -Spanish index (only Spanish data), for different values of k.</figDesc><graphic coords="7,156.00,500.70,283.45,147.85" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,124.82,149.01,345.85,223.27"><head>Table 1 :</head><label>1</label><figDesc>Average distribution of reputation labels in training entities. The first observation from Table 1 is that classes are unbalanced. For the automotive domain, 66% of training tweets deal with Products &amp; Services, while only 0.8% deal with Leadership. The second observation is that distributions are different for the banking domain (e.g. only 21.4% for Products &amp; Services). The distribution observed in test set (not reported) were consistent with those observed in the training set.</figDesc><table coords="4,206.69,170.05,182.15,112.74"><row><cell>Category</cell><cell>Automotive (20 entities)</cell><cell>Banking (11 entities)</cell></row><row><cell>Citizenship</cell><cell>53</cell><cell>104</cell></row><row><cell>Governance</cell><cell>2</cell><cell>114</cell></row><row><cell>Innovation</cell><cell>8</cell><cell>4</cell></row><row><cell>Leadership</cell><cell>4</cell><cell>19</cell></row><row><cell>Performance</cell><cell>20</cell><cell>49</cell></row><row><cell>Products &amp; Services</cell><cell>338</cell><cell>104</cell></row><row><cell>Undefined</cell><cell>75</cell><cell>66</cell></row><row><cell>Workplace</cell><cell>10</cell><cell>25</cell></row><row><cell>TOTAL</cell><cell>511</cell><cell>485</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,146.58,226.28,324.07,9.05;9,160.82,237.80,309.69,9.05;9,160.82,249.32,73.09,9.05" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,368.35,226.28,102.31,9.05;9,160.82,237.80,129.55,9.05">Report on the trec 2009 experiments: Chemical IR track</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gobeill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Teodoro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Pasche</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ruch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,297.73,237.80,172.79,9.05;9,160.82,249.32,43.25,9.05">the Eighteenth Text REtrieval Conference (TREC-18)</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,146.58,260.87,324.01,9.05;9,160.82,272.39,309.99,9.05;9,160.82,283.79,50.88,9.05" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="9,379.99,260.87,90.61,9.05;9,160.82,272.39,309.99,9.05;9,160.82,283.79,21.56,9.05">Simple Pre and Post Processing Strategies for Patent Searching in CLEF Intellectual Property Track</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gobeill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Pasche</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Teodoro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ruch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,146.58,295.31,324.12,9.05;9,160.82,306.83,309.68,9.05;9,160.82,318.35,309.58,9.05;9,160.82,329.87,191.10,9.05" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,160.82,306.83,291.74,9.05">Automatic IPC encoding and novelty tracking for effective patent mining</title>
		<author>
			<persName coords=""><forename type="first">Teodoro</forename><forename type="middle">D</forename><surname>Gobeill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pasche</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Ruch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Vishnyakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lovis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,160.82,318.35,309.58,9.05;9,160.82,329.87,51.95,9.05">The 8th NTCIR Workshop Meeting on Evaluation of Information Access Technologies</title>
		<meeting><address><addrLine>Tokyo, Japan</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="309" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,146.58,341.39,323.82,9.05;9,160.82,352.79,309.68,9.05;9,160.82,364.31,150.36,9.05" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,329.69,341.39,140.71,9.05;9,160.82,352.79,248.60,9.05">Selection of relevant articles for curation for the Comparative Toxicogenomic Database</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Vishnyakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Pasche</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Ruch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,422.32,352.79,48.19,9.05;9,160.82,364.31,41.54,9.05">BioCreative Workshop</title>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="31" to="38" />
		</imprint>
	</monogr>
	<note>Internet</note>
</biblStruct>

<biblStruct coords="9,146.58,375.83,323.94,9.05;9,160.82,387.35,309.91,9.05;9,160.82,398.87,131.34,9.05" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,299.33,375.83,150.01,9.05">N-gram-based Text Categorization</title>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Cavnar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Trenkle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,160.82,387.35,309.91,9.05;9,160.82,398.87,102.29,9.05">Proceedings of SDAIR-94, 3rd Annual Symposium on Document Analysis and Information Retrieval</title>
		<meeting>SDAIR-94, 3rd Annual Symposium on Document Analysis and Information Retrieval</meeting>
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,146.58,421.79,323.97,9.05;9,160.82,433.31,309.38,9.05;9,160.82,444.85,309.57,9.05;9,160.82,456.37,64.10,9.05" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,160.82,433.31,305.22,9.05">Terrier: A High Performance and Scalable Information Retrieval Platform</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,172.92,444.85,297.47,9.05;9,160.82,456.37,35.06,9.05">Proceedings of ACM SIGIR&apos;06 Workshop on Open Source Information Retrieval</title>
		<meeting>ACM SIGIR&apos;06 Workshop on Open Source Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,146.58,467.89,323.80,9.05;9,160.82,479.29,167.64,9.05" xml:id="b6">
	<monogr>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schütze</surname></persName>
		</author>
		<title level="m" coord="9,286.13,467.89,184.26,9.05;9,160.82,479.29,41.51,9.05">Foundations of Statistical Natural Language Processing</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,146.58,490.81,323.76,9.05;9,160.82,502.33,128.13,9.05" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,194.06,490.81,272.12,9.05">Neighbor-weighted K-nearest neighbor for unbalanced text corpus</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Tan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,160.82,502.33,73.72,9.05">Expert Syst. Appl</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">4</biblScope>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,151.20,513.85,319.44,9.05;9,160.82,525.37,112.28,9.05" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,202.61,513.85,263.95,9.05">An Evaluation of Statistical Approaches to Text Categorization</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,160.82,525.37,36.27,9.05">Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="69" to="90" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,151.20,536.89,319.24,9.05;9,160.82,548.29,309.44,9.05;9,160.82,559.81,309.85,9.05;9,160.82,571.33,133.38,9.05" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,253.13,536.89,200.12,9.05">A re-examination of text categorization methods</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,160.82,548.29,309.44,9.05;9,160.82,559.81,256.09,9.05">Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval (SIGIR &apos;99)</title>
		<meeting>the 22nd annual international ACM SIGIR conference on Research and development in information retrieval (SIGIR &apos;99)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="42" to="49" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,151.20,582.85,319.14,9.05;9,160.82,594.37,279.33,9.05" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,273.05,582.85,197.29,9.05;9,160.82,594.37,109.37,9.05">Adaptive weighted learning for unbalanced multicategory classification</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Qiao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,276.53,594.37,42.19,9.05">Biometrics</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="159" to="168" />
			<date type="published" when="2008-03">Mar. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
