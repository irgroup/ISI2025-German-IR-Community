<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,141.00,116.02,333.23,12.62;1,152.04,134.02,311.16,12.62;1,178.08,151.90,258.96,12.62">LyS at CLEF RepLab 2014: Creating the State of the Art in Author Influence Ranking and Reputation Classification on Twitter</title>
				<funder ref="#_5PqCKtm">
					<orgName type="full">Xunta de Galicia</orgName>
				</funder>
				<funder ref="#_7dPkd4m">
					<orgName type="full">Ministerio de Economía y Competitividad and FEDER</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,135.84,190.10,58.14,8.74"><forename type="first">David</forename><surname>Vilares</surname></persName>
							<email>david.vilares@udc.es</email>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Computación</orgName>
								<orgName type="laboratory">Grupo LyS</orgName>
								<orgName type="institution">Universidade da Coruña Campus de A Coruña</orgName>
								<address>
									<addrLine>s/n</addrLine>
									<postCode>15071, A</postCode>
									<settlement>Coruña</settlement>
									<country key="ES">España</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,201.36,190.10,59.48,8.74"><forename type="first">Miguel</forename><surname>Hermo</surname></persName>
							<email>miguel.hermo@udc.es</email>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Computación</orgName>
								<orgName type="laboratory">Grupo LyS</orgName>
								<orgName type="institution">Universidade da Coruña Campus de A Coruña</orgName>
								<address>
									<addrLine>s/n</addrLine>
									<postCode>15071, A</postCode>
									<settlement>Coruña</settlement>
									<country key="ES">España</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,269.39,190.10,74.43,8.74"><forename type="first">Miguel</forename><forename type="middle">A</forename><surname>Alonso</surname></persName>
							<email>miguel.alonso@udc.es</email>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Computación</orgName>
								<orgName type="laboratory">Grupo LyS</orgName>
								<orgName type="institution">Universidade da Coruña Campus de A Coruña</orgName>
								<address>
									<addrLine>s/n</addrLine>
									<postCode>15071, A</postCode>
									<settlement>Coruña</settlement>
									<country key="ES">España</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,351.71,190.10,108.84,8.74"><forename type="first">Carlos</forename><surname>Gómez-Rodríguez</surname></persName>
							<email>carlos.gomez@udc.es</email>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Computación</orgName>
								<orgName type="laboratory">Grupo LyS</orgName>
								<orgName type="institution">Universidade da Coruña Campus de A Coruña</orgName>
								<address>
									<addrLine>s/n</addrLine>
									<postCode>15071, A</postCode>
									<settlement>Coruña</settlement>
									<country key="ES">España</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,279.48,201.98,56.50,8.74"><forename type="first">Jesús</forename><surname>Vilares</surname></persName>
							<email>jvilares@udc.es</email>
							<affiliation key="aff0">
								<orgName type="department">Departamento de Computación</orgName>
								<orgName type="laboratory">Grupo LyS</orgName>
								<orgName type="institution">Universidade da Coruña Campus de A Coruña</orgName>
								<address>
									<addrLine>s/n</addrLine>
									<postCode>15071, A</postCode>
									<settlement>Coruña</settlement>
									<country key="ES">España</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,141.00,116.02,333.23,12.62;1,152.04,134.02,311.16,12.62;1,178.08,151.90,258.96,12.62">LyS at CLEF RepLab 2014: Creating the State of the Art in Author Influence Ranking and Reputation Classification on Twitter</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5B7BE78279C28A57CED8F00EBB016583</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Reputation Monitoring</term>
					<term>Author Ranking</term>
					<term>Twitter</term>
					<term>Natural Language Processing</term>
					<term>Machine Learning</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our participation at RepLab 2014, a competitive evaluation for reputation monitoring on Twitter. The following tasks were addressed: (1) categorisation of tweets with respect to standard reputation dimensions and (2) characterisation of Twitter profiles, which includes: (2.1) identifying the type of those profiles, such as journalist or investor, and (2.2) ranking the authors according to their level of influence on this social network. We consider an approach based on the application of natural language processing techniques in order to take into account part-of-speech, syntactic and semantic information. However, each task is addressed independently, since they respond to different requirements. The official results confirm the competitiveness of our approaches, which achieve the 2nd place, tied in practice with the 1st place, at the author ranking task; and 3rd place at the reputation dimensions classification tasks.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In recent years, Twitter has become a wide information network, where millions of users share their views about products and services. This microblogging social network is an important source of information for companies and organisations, which aim to know what people think about their articles. In this way, identifying how people relate aspects and traits such as performance, services or leadership with their business, is a good starting point for monitoring the perception of the public via sentiment analysis applications. In a similar line, companies are interested in user profiling: identifying the profession, cultural level, age or the level of influence of authors in an specific domain may have potential benefits when making decisions with respect to advertisement policies, for example.</p><p>The RepLab 2014 on Twitter <ref type="bibr" coords="2,277.93,119.06,10.56,8.74" target="#b0">[1]</ref> focusses on these challenges, providing standard metrics and test collections where both academic and commercial systems can be evaluated. The collections contain tweets written in English and Spanish. Two main tasks were proposed: (1) categorisation of tweets with respect to standard reputation dimensions and (2) characterisation of Twitter profiles. The first task consisted of classifying tweets into the standard reputation dimensions: products&amp;services, innovation, workplace, citizenship, governance, leadership, performance and undefined. The characterization of Twitter profiles is composed of two subtasks: (2.1) author categorisation and (2.2) author ranking. The author categorisation task covers up to 7 user types: journalist, professional, authority, activist, investor, company or celebrity. With respect to the author ranking task, the goal is to detect influential and non-influential users, ranking them according to this aspect (from the most to the least influential). Our approaches achieve state-of-the-art results for the classification on reputation dimensions and author ranking.</p><p>The remainder of the paper is structured as follows. Section 2 describes the main features of our methods. Sections 3, 4 and 5 show how we tackle the proposed tasks, illustrating and discussing the official results. Finally, we present our conclusions in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System description</head><p>The major part of our models rely on natural language processing (NLP) approaches which include steps such as: preprocessing, part-of-speech (PoS) tagging and parsing. The obtained syntactic trees act as a starting point for extracting the features which feed the supervised classifier employed for tasks 1 (reputation dimensions classification) and 2.1 (author categorisation). We built different models for each task and for each language considered in the evaluation campaign. With respect to task 2.2 (author ranking), a simple but effective method was used. Differences between tasks and languages are explained in the following sections. We describe below the high level architecture of our NLP pipeline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">NLP for online reputation</head><p>Preprocessing We carry out an ad-hoc preprocessing to normalise some of the most common features of the Twitter jargon, which may have an influence on the perfomance of the tasks proposed at RepLab 2014:</p><p>-Replacement of URL's: References to external links and resources are replaced by the string 'URL'. -Hashtags: The use of hashtags may be helpful for classification tasks, since they are often used to label tweets. In this way, we only delete the symbol '#' in order to give to these elements the same treatment as words. -Twitter usernames: In this social network, the usernames are preceded by the symbol '@'. In order not to cause confusion at the tokenisation or tagging steps, we delete that symbol, to then capitalise the first character and give these elements the same treatment as actual proper names.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Part-of-speech tagging</head><p>In order to be able to obtain the syntactic structure of tweets, we first need to label each token of the message with its respective part-of-speech tag. We used the Ancora <ref type="bibr" coords="3,312.58,143.06,10.56,8.74" target="#b1">[2]</ref> and the Penn Treebank <ref type="bibr" coords="3,433.44,143.06,10.56,8.74" target="#b2">[3]</ref> corpora to train the Spanish and the English taggers, respectively. The Spanish tagger relies on the Brill tagger <ref type="bibr" coords="3,241.80,166.94,10.56,8.74" target="#b3">[4]</ref> implementation included with NLTK<ref type="foot" coords="3,415.20,165.51,3.97,6.37" target="#foot_0">1</ref> , following the configuration described at <ref type="bibr" coords="3,250.08,178.82,9.99,8.74" target="#b4">[5]</ref>. With respect to English we used an averaged perceptron discriminative sequence model <ref type="bibr" coords="3,304.08,190.82,10.56,8.74" target="#b5">[6]</ref> which presents state-of-the-art results for the Penn Treebank. Specifically, we took the trained model provided with the TextBlob<ref type="foot" coords="3,192.00,213.27,3.97,6.37" target="#foot_1">2</ref> framework. During the process of PoS tagging we also obtain the lemma of each word.</p><p>Dependency parsing Given a sentence S = w 1 ...w n , where w i represents the word at the position i in the sentence, a dependency parser returns a dependency tree, a set of triplets {(w i , arc ij , w j )} where w i is the head term, w j is the dependent and arc ij represents the dependency type, which denotes the syntactic function that relates the head and the dependent. In this way, the phrase 'best performance' could be represented syntactically as (performance, modifier, best). We rely on MaltParser <ref type="bibr" coords="3,262.91,328.58,9.99,8.74" target="#b6">[7]</ref>, a data-driven dependency parser generator, to build our parsers. We used again the Ancora and the Penn Treebank corpora to train the Spanish and the English parser, respectively. Our aim is to employ dependency parsing to capture the non-local relations between words that lexical-based approaches cannot handle properly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Feature extraction</head><p>Our classifiers are fed with three different types of features:</p><p>-N-grams: This type of features detect the presence of sequences of contiguous words, where n is the number of concatenated terms. In this paper, we consider both 1-grams and 2-grams (which make it possible to capture some contextual information based on word proximity). Simple normalisation techniques such as converting words to their lowercase form are applied.</p><p>In addition to n-grams of words, we also consider n-grams of lemmas<ref type="foot" coords="3,452.88,507.39,3.97,6.37" target="#foot_2">3</ref> . The aim is to reduce sparsity and training more accurate classifiers, specially for Spanish language, where verbs, adjectives and nouns present gender and number declensions. -Psycometric properties: The LIWC <ref type="bibr" coords="3,305.40,556.70,10.56,8.74" target="#b7">[8]</ref> is a software that can be used to identify psychometric word properties present in a text. Among other languages, it provides dictionaries for both Spanish and English. We use those dictionaries in this work to relate words with psychological features such as insight, anger or happiness, but also with topics such as money, sports or religion.</p><p>In this way, we match the words of a text, returning all their psychometric dimensions. -Generalised dependency triplets: In this paper, we apply an enriched approach presented at <ref type="bibr" coords="4,241.80,154.70,10.56,8.74" target="#b8">[9]</ref> of the initial method described at <ref type="bibr" coords="4,407.61,154.70,14.69,8.74" target="#b9">[10]</ref>. Given a dependency triplet of the form (w i , arc ij , w j ) a generalised triplet has the form (g(w i , x), d(arc ij ), g(w j , x)), where g is a generalisation function and x the desired type of generalisation, which can be: the word itself, its lemma, its psychometric properties, its part-of-speech tag or none, if we decide to completely delete the content of the token. On the other hand, the function d can be defined to keep or remove the dependency type of a triplet. For example, the triplet (performance, modifier, best) can be generalised as (optimism, modifier, adjective) by applying the generalisation functions (g(performance, psychometric properties), modifier, g(best, part-of-speech tag)). The goal is to reduce the sparsity of standard dependency triplets, generalising concepts and ideas in a homogeneous way.</p><p>In all cases, we use the number of occurrences as the weighting factor for the supervised classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Classifier</head><p>We use the WEKA <ref type="bibr" coords="4,220.81,365.90,15.60,8.74" target="#b10">[11]</ref> framework for building our classifiers. For each task, we tuned the weights and the kernel of the classifier in order to maximise performance, as detailed in the following sections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Task 1: Reputation Dimensions Categorisation</head><p>The task consisted on relating tweets with the standard reputation dimensions proposed by the Reputation Institute and the RepTrak model<ref type="foot" coords="4,446.16,453.75,3.97,6.37" target="#foot_3">4</ref> : prod-ucts&amp;services, innovation, workplace, citizenship, governance, leadership, performance and undefined (if a tweet is no assigned to any of the other dimensions).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>The RepLab 2014 corpus is composed of English and Spanish tweets extracted from the RepLab 2013 corpus, which contained a collection of tweets referring to up to 61 entities. The RepLab 2014 only takes into account those who refer to banking or automotive entities, where each one is labelled with one of the standard reputation dimensions. To create the collection the canonical name of the entity was used as a query to retrieve the tweets which talk about it. Thus, each tweet contains the name of an entity. In addition, the corpus provides information about the author of each tweet, the content of external links that appear in a message and a flag to know if the tweet is written in English or Spanish.</p><p>Evaluation metrics This task is evaluated as a multi-class categorisation problem. Thus, precision, recall and accuracy are the official metrics: Runs We sent two runs. For each run, we trained two different LibLinear classifiers <ref type="bibr" coords="5,163.79,318.86,14.69,8.74" target="#b11">[12]</ref>: one for English and another one for Spanish language. We tuned the weights for the majority classes (products, citizenship, undefined and governance) using a value of 0.75, giving the less frequent categories a weight of 1. In both cases, our approaches only handle the content of a tweet, discarding the user information and the content of the external links. In the latter case, we think processing the content of the web pages referred to in a tweet may excessively increase the cost of analysing a tweet. In addition, we believe the tweet reputation dimensions are not necessarily to be related with the content of the link, where probably many concepts and ideas appear. The results presented below these lines seem to confirm our hypothesis since we ranked 3rd, very close to the best-performing system. More specifically, our contributions were:</p><p>-Run 1 : The English model took as features: unigrams of lemmas, bigrams of lemmas, and word psychometric properties. With respect to the Spanish classifier, the experimental setup showed that the best-performing model over Spanish messages was composed of: unigrams of lemmas, bigrams of lemmas and generalised triplets of the form ( , dependency type, lemma), i.e., dependency triplets where the head is omitted. In both cases, we tried to obtain the best sets of features via greedy search on the training corpus and a 5-fold cross-validation. -Run 2 : This model uses the same classifier and the same sets of features as run 1, but excluding those which include the name of any of the entities used to create the train corpus. Our main aim was protecting our model from a possible bias on the training corpus. We observed that many tweets belonging to certain entities were labelled mainly only into a single reputation dimension. We were concerned that this fact could create an overfitted model which would not work properly on the test set. In this respect, this run also allowed us to measure the impact on performance of using the name of entities on the test set.</p><p>Results Table <ref type="table" coords="6,203.40,119.06,4.98,8.74" target="#tab_2">3</ref> shows the ranking of the systems for the reputation dimension task, based on their accuracy. The baseline of the RepLab organisation is a naive bag-of-words approach trained on a Support Vector Machine (SVM). Our run 1 ranked 3rd, confirming the effectiveness of our perspective. The second run also worked acceptably, although performance dropped by almost two percentage points. This confirms a slight bias on the test set, since it contains tweets that refer to the same entities as the training set and they were collected in the same interval of time. Table <ref type="table" coords="6,237.48,202.82,4.98,8.74" target="#tab_2">3</ref> show the detailed performance for our best run. Our model obtains both an acceptable recall and precision for the most prevalent classes, but the same is not true for minority classes, due to the small number of samples in the training set. The majority of the participants exhibited this same weakness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Task 2.1: Author categorisation</head><p>The goal of the task was to assign Twitter profiles to one of these categories: journalist, professional, authority, activist, investor, company and celebrity. An additional class undecidable was proposed to place all those users that did not match any of the proposed categories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dataset</head><p>The training and the test set are composed of the authors who wrote the automotive and banking tweets that we mentioned previously. In addition to user information, the organizers included the identifiers of the last 600 tweets of each user at the moment of the creation of the corpus. Due to the lack of time, we decided to download only 100 tweets for each author. In order to obtain these tweets faster, we used the capabilities of the Twitter API to download the timeline of an author instead of downloading the tweets one by one. However, that API method only allows the user to obtain the 3 200 most recent tweets of each author, so we were unable to find the tweets included in the corpus for many of them (the most active ones). More specifically, we could retrieve no tweets for around 1 000 authors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation metrics</head><p>The official results are the average accuracy between the categories corresponding to automotive and banking. Only the authors categorised as influential in the gold standard of task 2.2 are taken into account.</p><p>Runs This task is addressed as follows: given a set of tweets for an author, they are collected into a single file, which is used to finally classify the user according to the proposed categories. Since many of the categories in the training corpus only contained a few authors, we discarded those classes in order to avoid confusing machine learning algorithm. We trained two classifiers, one for each language. After, testing different Support Vector Machine implementations, we obtained the best performance on the training set (5-fold cross-validation) using an SMO <ref type="bibr" coords="6,174.35,656.18,14.69,8.74" target="#b12">[13]</ref>. To identify which authors are Spanish and which ones are English, for each author we counted the number of his last 600 tweets included at the corpus that are written in each language, assigning the author to the most frequent one. This information is provided by the RepLab 2014 organisation, without any need to download the tweets. More specifically, as we did in task 1, we sent two runs:</p><p>-Run 1 : Both the Spanish and the English models use unigrams of lemmas and psychometric properties as features. We selected these features via greedy search on our processed training corpus (where all tweets of a user are merged into a single file). Since we did not have any tweet for many authors, we trained a back-off machine learner: a bag-of-words classifier which categorises these authors according to their profile description. -Run 2 : The only difference with respect to run 1 is the back-off classifier.</p><p>Authors for which we have not downloaded any tweet are always assigned to the majority class in the training corpus: undecidable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Table <ref type="table" coords="8,206.63,305.54,4.98,8.74" target="#tab_3">4</ref> shows the performance of the systems participating in this task. We think that our poor performance is due to the small site of the training corpus that we were able to collect and process. The baseline proposed by the RepLab organisers reinforces our hypothesis, since they used an SVM approach based on a bag-of-words. They also included another baseline which assigns all authors to the majority class in the training corpus. The task focusses on classifying authors a influential and non-influential, as well as ranking them according to that level of influence.</p><p>Dataset It is the same that the employed at task 2.1: Author Categorisation. The proportion in the training set is about 30% of influential users, with the remaining 70% being non-influential.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation metrics</head><p>The organisers address the problem as a traditional ranking information problem using the Mean Average Precision (MAP) as standard metric. The experimental results are ordered according to the average of automotive and banking MAP measures.</p><p>Runs Classification of influential and non-influential users is made via a Lib-Linear classifier, following a machine learning perspective. To rank the authors we take as the starting point the confidence factor reported by the classifier for each sample. The confidence is then used to rank the users according to their level of influence. A higher confidence should indicate a higher influence. With respect to non-influential users, we firstly negate that factor, obtaining in this way lower values for the least influential authors. We again sent two models to evaluate this task, although in this case the runs present significant differences:</p><p>-Run 1 : A bag-of-words model which takes each word of the Twitter profile descriptions to feed the supervised classifier. The weights of the classes were tuned taking 1.8 and 1.3 for influential an non-influential users, respectively. Since the corpus is domain-dependent (automotive and banking tweets) we hypothesise that the brief biography of the user may be an acceptable indicator of influence. We observed that words such as 'car', 'business' or magazine were some of the most relevant tokens in terms of information gain. -Run 2 : This run follows a meta-information perspective, taking the information provided by the Twitter API for any user. More specifically, we used binary features such as: URL in the Twitter profile, verified account, profile user background image, default profile, geo enabled, default profile image, notifications, is translation enabled and contributors enabled. In addition the following numeric features are taken into account: listed count, favourites count, followers count, statuses count, friends count and following.</p><p>Results Table <ref type="table" coords="9,204.00,528.98,4.98,8.74">5</ref> illustrates the official results for this task. The baseline of the RepLab organisers ranks the authors by their number of followers. Our run 1 achieved the 2nd place, tied in practice with the 1st place, reinforcing the validity of the proposal for a specific domain. On the other hand, our second run did not work as expected, although it outperformed the baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>This paper describes the participation of the LyS research group at RepLab 2014. We sent runs for all tasks proposed. The classification for the reputation dimensions task is addressed from a NLP perspective, including preprocessing, part-of-speech tagging and dependency parsing. We use the output obtained by our NLP pipeline for extracting lexical, psychometric and syntactic-based features, which are used to feed a supervised classifier. We ranked 3rd, very close to the best performing system, confirming the effectiveness of the approach. The author categorisation task is addressed from the same perspective. However, we could not properly exploit the approach due to problems to obtain much of the content of the training corpus.</p><p>On the other hand, the author ranking challenge was addressed from a different perspective. We obtained the second best-performing system, tied in practice with the 1st place, by training a bag-of-words classifier which takes the Twitter profile description of the users as features. This model clearly outperformed our second run based on metadata such as the number of favourited tweets or followers.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,262.80,157.66,54.30,9.02;5,330.24,156.06,10.83,4.91;5,321.12,163.38,29.19,6.58;5,467.88,157.94,12.74,8.74;5,270.12,192.94,38.70,9.02;5,322.44,191.22,10.83,4.91;5,312.84,198.54,30.43,6.58;5,467.88,193.22,12.74,8.74;5,244.92,228.10,51.90,9.02;5,319.56,226.38,30.06,6.58;5,300.72,233.82,67.75,6.58;5,467.88,228.38,12.74,8.74;5,134.76,249.38,345.75,8.74;5,134.76,261.38,345.80,8.74;5,134.76,273.26,117.12,8.74"><head></head><label></label><figDesc>N T P +T N +F P +F N (3) where TP and TN refer to the true positives and negatives and FP and FN indicate the false positives and negatives, respectively. The organisers sorted the official results by accuracy.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,169.20,121.15,276.56,374.37"><head>Table 1 .</head><label>1</label><figDesc>Ranking for task 1: Reputation Dimensions Categorisation</figDesc><table coords="7,235.20,145.27,143.83,350.25"><row><cell>Team</cell><cell cols="2">Run Accuracy</cell></row><row><cell>uogTr</cell><cell>4</cell><cell>0,731</cell></row><row><cell>DAE</cell><cell>1</cell><cell>0,723</cell></row><row><cell>LyS</cell><cell>1</cell><cell>0,717</cell></row><row><cell>SIBtex</cell><cell>1</cell><cell>0,707</cell></row><row><cell>CIRGIRDISCO</cell><cell>3</cell><cell>0,707</cell></row><row><cell>SIBtex</cell><cell>2</cell><cell>0,705</cell></row><row><cell>stavicta</cell><cell>4</cell><cell>0,703</cell></row><row><cell>DAE</cell><cell>4</cell><cell>0,703</cell></row><row><cell>LyS</cell><cell>2</cell><cell>0,699</cell></row><row><cell>stavicta</cell><cell>1</cell><cell>0,695</cell></row><row><cell>CIRGIRDISCO</cell><cell>1</cell><cell>0,692</cell></row><row><cell>uogTr</cell><cell>5</cell><cell>0,687</cell></row><row><cell>stavicta</cell><cell>2</cell><cell>0,685</cell></row><row><cell>UvA</cell><cell>4</cell><cell>0,668</cell></row><row><cell>stavicta</cell><cell>3</cell><cell>0,662</cell></row><row><cell>UvA</cell><cell>5</cell><cell>0,659</cell></row><row><cell>UvA</cell><cell>1</cell><cell>0,654</cell></row><row><cell>UvA</cell><cell>2</cell><cell>0,647</cell></row><row><cell>UvA</cell><cell>3</cell><cell>0,622</cell></row><row><cell>baseline-replab</cell><cell></cell><cell>0,622</cell></row><row><cell>uogTr</cell><cell>2</cell><cell>0,621</cell></row><row><cell>lia</cell><cell>2</cell><cell>0,613</cell></row><row><cell>uogTr</cell><cell>3</cell><cell>0,609</cell></row><row><cell>lia</cell><cell>5</cell><cell>0,607</cell></row><row><cell>CIRGIRDISCO</cell><cell>2</cell><cell>0,607</cell></row><row><cell>lia</cell><cell>4</cell><cell>0,596</cell></row><row><cell>DAE</cell><cell>2</cell><cell>0,586</cell></row><row><cell>DAE</cell><cell>5</cell><cell>0,586</cell></row><row><cell>lia</cell><cell>1</cell><cell>0,549</cell></row><row><cell>uogTr</cell><cell>1</cell><cell>0,496</cell></row><row><cell>lia</cell><cell>3</cell><cell>0,357</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,134.76,525.91,345.65,119.97"><head>Table 2 .</head><label>2</label><figDesc>Detailed performance for our best run on the Reputation Dimensions Categorisation task</figDesc><table coords="7,177.60,560.95,260.38,84.93"><row><cell>Category</cell><cell cols="4">Recall Precision #tweets % tweets</cell></row><row><cell>Innovation</cell><cell>0.085</cell><cell>0.271</cell><cell>306</cell><cell>1.09</cell></row><row><cell>Citizenship</cell><cell>0.732</cell><cell>0.848</cell><cell>5027</cell><cell>17.89</cell></row><row><cell>Leadership</cell><cell>0.200</cell><cell>0.484</cell><cell>744</cell><cell>2.65</cell></row><row><cell>Workplace</cell><cell>0.274</cell><cell>0.527</cell><cell>1124</cell><cell>4.00</cell></row><row><cell>Governance</cell><cell>0.461</cell><cell>0.697</cell><cell>3395</cell><cell>12.08</cell></row><row><cell>Performance</cell><cell>0.404</cell><cell>0.499</cell><cell>1598</cell><cell>5.69</cell></row><row><cell cols="2">Products&amp;Services 0.879</cell><cell>0.702</cell><cell>15903</cell><cell>56.60</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,134.76,395.23,346.27,237.43"><head>Table 3 .</head><label>3</label><figDesc>Ranking for task 2.1: Author Categorisation</figDesc><table coords="8,134.76,428.47,346.27,204.19"><row><cell>Team</cell><cell cols="5">Run Automotive Banking Miscelaneous Average</cell></row><row><cell>lia</cell><cell>1</cell><cell>0,445</cell><cell>0,503</cell><cell>0,462</cell><cell>0,474</cell></row><row><cell>baseline-replab</cell><cell></cell><cell>0,426</cell><cell>0,495</cell><cell>-</cell><cell>0,461</cell></row><row><cell>baseline-most frequent</cell><cell></cell><cell>0,45</cell><cell>0,42</cell><cell>0,51</cell><cell>0,435</cell></row><row><cell>UAM-CALYR</cell><cell>2</cell><cell>0,382</cell><cell>0,446</cell><cell>0,392</cell><cell>0,414</cell></row><row><cell>UAM-CALYR</cell><cell>1</cell><cell>0,386</cell><cell>0,421</cell><cell>0,415</cell><cell>0,404</cell></row><row><cell>ORM UNED</cell><cell>1</cell><cell>0,374</cell><cell>0,41</cell><cell>0,392</cell><cell>0,392</cell></row><row><cell>ORM UNED</cell><cell>3</cell><cell>0,389</cell><cell>0,392</cell><cell>0,177</cell><cell>0,391</cell></row><row><cell>lia</cell><cell>2</cell><cell>0,357</cell><cell>0,398</cell><cell>0,377</cell><cell>0,377</cell></row><row><cell>ORM UNED</cell><cell>2</cell><cell>0,352</cell><cell>0,389</cell><cell>0,300</cell><cell>0,371</cell></row><row><cell>lia</cell><cell>3</cell><cell>0,293</cell><cell>0,308</cell><cell>0,369</cell><cell>0,301</cell></row><row><cell>LyS</cell><cell>1</cell><cell>0,142</cell><cell>0,153</cell><cell>0,254</cell><cell>0,147</cell></row><row><cell>LyS</cell><cell>2</cell><cell>0,131</cell><cell>0,137</cell><cell>0,223</cell><cell>0,134</cell></row><row><cell cols="3">5 Task 2.2: Author ranking</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="10,212.28,115.99,190.82,199.05"><head>Table 4 .</head><label>4</label><figDesc>Ranking for task 2.2: Author ranking</figDesc><table coords="10,245.76,140.11,123.03,174.93"><row><cell>Team</cell><cell cols="2">Run MAP</cell></row><row><cell>UTDBRG</cell><cell>4</cell><cell>0.565</cell></row><row><cell>LyS</cell><cell>1</cell><cell>0.563</cell></row><row><cell>UTDBRG</cell><cell>1</cell><cell>0.550</cell></row><row><cell>UTDBRG</cell><cell>5</cell><cell>0.503</cell></row><row><cell>UTDBRG</cell><cell>3</cell><cell>0.499</cell></row><row><cell>Lia</cell><cell>1</cell><cell>0.476</cell></row><row><cell>UAM-CALYR</cell><cell>5</cell><cell>0.465</cell></row><row><cell>UAM-CALYR</cell><cell>1</cell><cell>0.436</cell></row><row><cell>UAM-CALYR</cell><cell>2</cell><cell>0.436</cell></row><row><cell>UTDBRG</cell><cell>2</cell><cell>0.413</cell></row><row><cell>LyS</cell><cell>2</cell><cell>0.403</cell></row><row><cell>UAM-CALYR</cell><cell>3</cell><cell>0.381</cell></row><row><cell>UAM-CALYR</cell><cell>4</cell><cell>0.381</cell></row><row><cell>baseline-replab</cell><cell></cell><cell>0.378</cell></row><row><cell>ORM UNED</cell><cell>3</cell><cell>0.349</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,144.72,623.98,87.27,7.86"><p>http://www.nltk.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,144.72,635.02,165.25,7.86"><p>http://textblob.readthedocs.org/en/dev/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,144.72,645.64,335.79,8.26;3,144.72,656.56,23.10,8.26"><p>Lemmas are the canonical forms of words. For example, the lemma of 'walking' is 'walk'</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,144.72,645.94,308.91,7.86;4,144.72,656.86,42.07,7.86"><p>http://www.reputationinstitute.com/about-reputation-institute/the-reptrakframework</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>Research reported in this paper has been partially funded by <rs type="funder">Ministerio de Economía y Competitividad and FEDER</rs> (Grant <rs type="grantNumber">TIN2010-18552-C03-02</rs>) and by <rs type="funder">Xunta de Galicia</rs> (Grant <rs type="grantNumber">CN2012/008</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_7dPkd4m">
					<idno type="grant-number">TIN2010-18552-C03-02</idno>
				</org>
				<org type="funding" xml:id="_5PqCKtm">
					<idno type="grant-number">CN2012/008</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,142.88,623.98,337.52,7.86;10,151.56,635.02,329.09,7.86;10,151.56,645.94,328.85,7.86;10,151.56,656.86,219.01,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,250.30,635.02,230.35,7.86;10,151.56,645.94,208.69,7.86">Overview of RepLab 2014: author profiling and reputation dimensions for Online Reputation Management</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Amigó</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Carrillo-De-Albornoz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Chugur</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Corujo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Meij</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Spina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,382.17,645.94,98.24,7.86;10,151.56,656.86,191.64,7.86">Proceedings of the Fifth International Conference of the CLEF initiative</title>
		<meeting>the Fifth International Conference of the CLEF initiative</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.88,119.74,337.60,7.86;11,151.56,130.78,328.82,7.86;11,151.56,141.70,329.05,7.86;11,151.56,152.62,328.99,7.86;11,151.56,163.66,47.69,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,306.13,119.74,174.34,7.86;11,151.56,130.78,85.79,7.86">AnCora: Multilevel Annotated Corpora for Catalan and Spanish</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Taulé</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Martí</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Recasens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,322.16,141.70,158.46,7.86;11,151.56,152.62,255.39,7.86">Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC&apos;08)</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Calzolari</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Choukri</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Maegaard</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Mariani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Odjik</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">S</forename><surname>Piperidis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><surname>Tapias</surname></persName>
		</editor>
		<meeting>the Sixth International Conference on Language Resources and Evaluation (LREC&apos;08)<address><addrLine>Marrakech, Morocco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.88,174.58,337.66,7.86;11,151.56,185.50,328.91,7.86;11,151.56,196.54,34.50,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,368.04,174.58,112.50,7.86;11,151.56,185.50,156.75,7.86">Building a large annotated corpus of English: The Penn treebank</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">P</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Marcinkiewicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Santorini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,316.66,185.50,104.57,7.86">Computational linguistics</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="313" to="330" />
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.88,207.46,337.66,7.86;11,151.56,218.38,328.96,7.86;11,151.56,229.42,314.36,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,185.64,207.46,162.16,7.86">A simple rule-based part of speech tagger</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Brill</surname></persName>
		</author>
		<idno type="DOI">10.3115/1075527.1075553</idno>
	</analytic>
	<monogr>
		<title level="m" coord="11,367.05,207.46,113.49,7.86;11,151.56,218.38,164.53,7.86">Proceedings of the workshop on Speech and Natural Language, HLT&apos;91</title>
		<meeting>the workshop on Speech and Natural Language, HLT&apos;91<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="1992">1992</date>
			<biblScope unit="page" from="112" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.88,240.34,337.55,7.86;11,151.56,251.26,328.73,7.86;11,151.56,262.30,130.42,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,347.74,240.34,132.69,7.86;11,151.56,251.26,230.76,7.86">A syntactic approach for opinion mining on Spanish reviews, Natural Language Engineering</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Vilares</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gómez-Rodríguez</surname></persName>
		</author>
		<idno type="DOI">10.1017/S1351324913000181</idno>
	</analytic>
	<monogr>
		<title level="j" coord="11,388.99,251.26,86.39,7.86">Available on CJO</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.88,273.22,337.66,7.86;11,151.56,284.14,328.91,7.86;11,151.56,295.18,328.85,7.86;11,151.56,306.10,328.84,7.86;11,151.56,317.02,118.54,7.86;11,151.56,327.94,197.49,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,197.04,273.22,283.49,7.86;11,151.56,284.14,157.10,7.86">Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<idno type="DOI">10.3115/1118693.1118694</idno>
		<ptr target="http://dx.doi.org/10.3115/1118693.1118694" />
	</analytic>
	<monogr>
		<title level="m" coord="11,327.70,284.14,152.77,7.86;11,151.56,295.18,227.19,7.86;11,429.61,295.18,47.25,7.86">Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the ACL-02 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note>EMNLP &apos;02</note>
</biblStruct>

<biblStruct coords="11,142.88,338.98,337.49,7.86;11,151.56,349.90,328.80,7.86;11,151.56,360.82,212.21,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,151.56,349.90,321.19,7.86">Maltparser: A language-independent system for data-driven dependency parsing</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Nivre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Nilsson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chanev</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Eryigit</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kübler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Marinov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Marsi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,151.56,360.82,123.26,7.86">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="95" to="135" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.88,371.86,337.76,7.86;11,151.56,382.78,227.06,7.86" xml:id="b7">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Pennebaker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Francis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Booth</surname></persName>
		</author>
		<title level="m" coord="11,309.21,371.86,171.44,7.86;11,151.56,382.78,16.65,7.86">Linguistic inquiry and word count: LIWC 2001</title>
		<meeting><address><addrLine>Mahway</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum Associates</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page">71</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.88,393.70,337.66,7.86;11,151.56,404.74,329.05,7.86;11,151.56,415.66,285.99,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,350.29,393.70,130.25,7.86;11,151.56,404.74,262.54,7.86">On the usefulness of lexical and syntactic processing in polarity classification of twitter messages</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Vilares</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gómez-Rodríguez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,422.41,404.74,58.21,7.86;11,151.56,415.66,241.62,7.86">Journal of the Association for Information Science Science and Technology</title>
		<imprint/>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct coords="11,142.55,426.58,337.95,7.86;11,151.56,437.62,328.81,7.86;11,151.56,448.54,327.90,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,265.81,426.58,210.38,7.86">Generalizing dependency features for opinion mining</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Penstein-Rosé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,164.27,437.62,312.55,7.86">Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, ACLShort &apos;09</title>
		<meeting>the ACL-IJCNLP 2009 Conference Short Papers, ACLShort &apos;09<address><addrLine>Suntec, Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="313" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.55,459.46,338.04,7.86;11,151.56,470.50,328.86,7.86;11,151.56,481.42,118.54,7.86;11,151.56,492.34,203.86,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,464.74,459.46,15.85,7.86;11,151.56,470.50,149.27,7.86">The weka data mining software: an update</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Holmes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Pfahringer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Reutemann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
		<idno type="DOI">10.1145/1656274.1656278</idno>
		<ptr target="http://doi.acm.org/10.1145/1656274.1656278" />
	</analytic>
	<monogr>
		<title level="j" coord="11,307.67,470.50,90.50,7.86">SIGKDD Explorations</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="10" to="18" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.55,503.38,337.98,7.86;11,151.56,514.30,329.05,7.86;11,151.56,525.22,72.32,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,415.20,503.38,65.33,7.86;11,151.56,514.30,141.19,7.86">LIBLINEAR: A library for large linear classification</title>
		<author>
			<persName coords=""><forename type="first">R.-E</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C.-J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X.-R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C.-J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,299.62,514.30,173.35,7.86">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.55,536.26,337.85,7.86;11,151.56,547.18,328.88,7.86;11,151.56,558.10,71.81,7.86" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="11,199.68,536.26,110.26,7.86">Advances in kernel methods</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
			<publisher>MIT Press</publisher>
			<biblScope unit="page" from="185" to="208" />
			<pubPlace>Cambridge, MA, USA</pubPlace>
		</imprint>
	</monogr>
	<note>Ch. Fast training of support vector machines using sequential minimal optimization</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
