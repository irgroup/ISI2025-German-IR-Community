<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,174.85,116.95,265.66,12.62;1,167.07,134.89,281.21,12.62;1,215.33,152.82,184.69,12.62">Ensemble Approaches for Large-Scale Multi-Label Classification and Question Answering in Biomedicine</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,139.28,190.71,91.24,8.74"><forename type="first">Yannis</forename><surname>Papanikolaou</surname></persName>
							<email>yannis.papanik@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">Aristotle University of Thessaloniki</orgName>
								<address>
									<postCode>54124</postCode>
									<settlement>Thessaloniki</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,241.08,190.71,93.44,8.74"><forename type="first">Dimitrios</forename><surname>Dimitriadis</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Aristotle University of Thessaloniki</orgName>
								<address>
									<postCode>54124</postCode>
									<settlement>Thessaloniki</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,345.06,190.71,91.90,8.74"><forename type="first">Grigorios</forename><surname>Tsoumakas</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Aristotle University of Thessaloniki</orgName>
								<address>
									<postCode>54124</postCode>
									<settlement>Thessaloniki</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,447.51,190.71,28.56,8.74;1,185.91,202.67,32.30,8.74"><forename type="first">Manos</forename><surname>Laliotis</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Atypon</orgName>
								<address>
									<addrLine>5201 Great America Parkway Suite 510</addrLine>
									<postCode>95054</postCode>
									<settlement>Santa Clara</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,228.76,202.67,92.57,8.74"><forename type="first">Nikos</forename><surname>Markantonatos</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Atypon Hellas</orgName>
								<address>
									<addrLine>Dimitrakopoulou 7, Agia Paraskevi 15341</addrLine>
									<settlement>Athens</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,351.26,202.67,73.72,8.74"><forename type="first">Ioannis</forename><surname>Vlahavas</surname></persName>
							<email>vlahavas@csd.auth.gr</email>
							<affiliation key="aff0">
								<orgName type="institution">Aristotle University of Thessaloniki</orgName>
								<address>
									<postCode>54124</postCode>
									<settlement>Thessaloniki</settlement>
									<country key="GR">Greece</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,174.85,116.95,265.66,12.62;1,167.07,134.89,281.21,12.62;1,215.33,152.82,184.69,12.62">Ensemble Approaches for Large-Scale Multi-Label Classification and Question Answering in Biomedicine</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">EB0F54E5035F0FE3C4829A1AAAB771DD</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>ensemble methods</term>
					<term>multi-label learning</term>
					<term>support vector machines</term>
					<term>latent Dirichlet allocation</term>
					<term>BioASQ</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper documents the systems that we developed for our participation in the BioASQ 2014 large-scale bio-medical semantic indexing and question answering challenge. For the large-scale semantic indexing task, we employed a novel multi-label ensemble method consisting of support vector machines, labeled Latent Dirichlet Allocation models and meta-models predicting the number of relevant labels. This method proved successful in our experiments as well as during the competition. For the question answering task we combined different techniques for scoring of candidate answers based on recent literature.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>At the moment this paper is being written a simple query on the PubMed website for the number of articles included in the database since 1900 gives a total number of 23,921,183 abstracts. 15,027,919 of them were published since 1990 and 8,412,522 only the last decade. These numbers concern only a portion of the total publications from the various scientific societies as this open digital repository contains only articles from biomedicine and life sciences. There is a very large number of scientific publications and this number seems to grow at non-trivial rates each year.</p><p>A key issue for exploiting this fast growing literature is the existence of semantic meta-data describing the topics of each publication. Searching the literature for a particular topic, discovering topic trends and many more tasks all rely on such meta-data. As manual annotation costs time and money, it is of great importance to automate this process. Furthermore, even in cases where this is affordable (e.g. PubMed) there is usually a crucial delay from the moment a new article is published until it gets annotated. However, automatic annotation of new articles is not an easy task in spite of the numerous algorithms and tools available for text classification. We need to deal with millions of documents, millions of features and tens of thousands of concepts, the latter being also highly imbalanced. In addition, each instance can belong to many classes, making our problem one of a multi-label nature. At the same time, such large bodies of knowledge are the perfect sources for developing question-answering systems capable of interacting with the scientific community in natural language.</p><p>In support of researchers working on these problems, the BioASQ <ref type="foot" coords="2,431.41,214.18,3.97,6.12" target="#foot_0">4</ref> European project has developed a competition framework targeted at large-scale online semantic indexing (Task A) and question answering (Task B) in the domain of biomedicine. This paper presents our approaches to deal with both of these tasks for the 2014 challenge of BioASQ. We primarily worked on the semantic indexing task, developing a novel multi-label classifier ensemble, which proved successful both in our experiments as well as during the competition. For the question-answering task we sucesfully replicated a recent approach <ref type="bibr" coords="2,428.51,299.44,9.96,8.74" target="#b0">[1]</ref>.</p><p>The rest of the paper is organized as follows. Section 2 offers background knowledge on the models and algorithms we employed. Section 3 presents our classifier selection approaches for multi-label data. Section 4 describes the actual systems we used for the challenge and the experiments we performed. Section 5 presents our results. Section 6 presents our work on the question answering task. Finally, Section 7 concludes this paper and points to future work directions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Background</head><p>This section provides a brief description of the models/algorithms used in our participation in Task 2A of the BioASQ challenge along with the necessary theory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Support Vector Machines</head><p>Support Vector Machines <ref type="bibr" coords="2,252.28,503.30,10.52,8.74" target="#b1">[2]</ref> have been extensively used in the literature for classification and regression tasks. Being a non-probabilistic binary classification algorithm in its essence, it has managed to achieve state-of-the art performance in numerous tasks and has been applied in multiple domains for solving learning problems. In our experiments we used the Liblinear package <ref type="bibr" coords="2,394.83,551.12,9.96,8.74" target="#b2">[3]</ref>, along with some minor modifications, which fitted perfectly our needs for a very fast and scalable implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">MetaLabeler</head><p>The MetaLabeler <ref type="bibr" coords="2,214.47,626.09,10.52,8.74" target="#b3">[4]</ref> is essentially a meta-model employed in multi-label tasks that serves to automatically determine the cardinality of the label set for a given instance. The idea is to train a linear regression model (e.g. with an SVM) with input from some feature space (an easy option could be simply the word tokens of each instance) and output the number of labels associated to the particular instance.</p><p>The need for the above meta-model arises in multi-label problems where, given an instance, the model's output for each label is a score or a probability. In this case, every instance is associated with a ranking of labels and we need to properly set a threshold so that we get a hard-assignment of labels. It should be noted here, that apart from the MetaLabeler a great deal of work exists in literature to address that particular problem <ref type="bibr" coords="3,328.41,227.59,10.52,8.74" target="#b4">[5]</ref> [6] but alternative solutions usually require a cross-validation procedure which proves to be too time-consuming for large-scale data sets. We also experimented with an approach similar to the MetaLabeler <ref type="bibr" coords="3,193.69,263.45,9.96,8.74" target="#b6">[7]</ref>. In this case, the output of the regression training problem is not the actual number of labels but the one that maximizes some evaluation measure (the F-measure in our case). Thus, given a trained model, we employ it on a validation set to determine the number of labels that would maximize the F-measure for every instance. Even if intuitively this approach would do better as it captures also the misclassification errors of the classifiers, in practice results were inferior compared to the MetaLabeler.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Topic Models</head><p>Latent Dirichlet Allocation (LDA) is a powerful probabilistic model first introduced by <ref type="bibr" coords="3,175.52,390.53,10.52,8.74" target="#b7">[8]</ref>  <ref type="bibr" coords="3,188.43,390.53,10.52,8.74" target="#b8">[9]</ref> in an unsupervised learning context. The key idea is that a corpus of documents hides a number of topics; this model, given the corpus, attempts to learn the distribution of topics to documents (namely the Θ distribution) and the distribution of topics to word tokens (Φ distribution respectively). After learning these distributions, the trained model can be used either in a generative task (e.g. given some topics, produce a new document(s)) or in an inference task (given some new documents, determine the topics they belong to). It is rather obvious to note that this model seems naturally fitted to deal with multilabel problems, apart from the fact that, being totally unsupervised, its resulting topics may be hard to interpret.</p><p>In the works of <ref type="bibr" coords="3,215.93,510.08,15.50,8.74" target="#b9">[10]</ref> and <ref type="bibr" coords="3,252.59,510.08,15.50,8.74" target="#b10">[11]</ref> the LDA theory is incorporated into a supervised learning context where each topic corresponds to a label of the corpus in a one-toone correspondence. We implemented the LLDA and the prior LLDA variant of <ref type="bibr" coords="3,134.77,545.94,14.61,8.74" target="#b10">[11]</ref>. The only difference between the two is that the prior LLDA model takes into account the relative frequencies of labels in the corpus, a crucial fact in case of a problem with power-law statistics<ref type="foot" coords="3,281.58,568.28,3.97,6.12" target="#foot_1">5</ref> like the one we address. In experiments, the prior LLDA model was performing significantly better than the simple LLDA so we used that one for our systems. Even though this model's performance didn't match that of the SVMs, we opted to use it with the motivation that it could do better for some labels and therefore used it in two ensembles (see section 4.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">A Classifier Selection Multi-Label Ensemble</head><p>The main idea behind ensembles is to exploit the fact that different classifiers may do well in different aspects of the learning task so combining them could improve overall performance. Ensembles have been extensively used in literature <ref type="bibr" coords="4,134.77,178.76,15.50,8.74" target="#b12">[13]</ref> with stacking <ref type="bibr" coords="4,215.98,178.76,14.61,8.74" target="#b13">[14]</ref>, bagging <ref type="bibr" coords="4,275.26,178.76,15.50,8.74" target="#b14">[15]</ref> and boosting <ref type="bibr" coords="4,354.81,178.76,15.50,8.74" target="#b15">[16]</ref> being the main methods employed. In the context of multi-label problems, <ref type="bibr" coords="4,351.76,190.71,15.50,8.74" target="#b16">[17]</ref> proposes a fusion method where the probabilistic outputs of heterogeneous classifiers are averaged and the labels above a threshold are chosen. In the same direction, a classifier selection scheme based on the F-measure is proposed in <ref type="bibr" coords="4,340.66,226.58,14.61,8.74" target="#b17">[18]</ref>. For each label and for each of the classifiers the F-measure is computed and the best performing is chosen to predict that particular label. We tried the last approach and even for large validation data sets we found a systematic decline on the micro-F measure.</p><p>In this work, we propose a different method oriented towards a classifier selection (rather than fusion) scheme. Essentially, we treat the problem as having L different classification tasks and requiring to be able to tell which of the models used is more suitable for each of them. In the description below, we suppose that there is a baseline model (i.e. a model that has a better overall performance than the others) but our idea can be applied with minor modifications without this assumption. The main issue addressed by our work is how to select the binary component classifiers for each label, so as to optimize the global micro-averaged f-measure that concerns all labels.</p><p>Formally, suppose we have a baseline model A and q different models B i and we want to combine them in a multi-label task with input feature vectors x and output y, y ∈ L, L being the set of labels. Instead of choosing a voting system for all labels, we could see for which labels each B i performs better than A on some validation set and according to some evaluation metric eval. Let's denote</p><formula xml:id="formula_0" coords="4,134.77,450.47,333.20,42.26">L Bi = {l : eval(B i ) &gt; eval(A), eval(B i ) &gt; eval(B j )}, with l ∈ L and j = i and |L A | = |L| - |L Bi |</formula><p>respectively. Then, when predicting on unseen data, we could predict labels that belong to L A from model A and labels belonging to each L Bi from the respective model B i .</p><p>There are two remaining issues to be solved; a) choose a valid evaluation metric eval and b) assure that results pointed by eval on a validation set can be generalized to new, unseen data. As the contest's main evaluation metric was the micro-F measure we opted for it. As mentioned, we also tried to use the F-measure (per label) but it was not improving overall performance, even on the validation data set.</p><p>Concerning the second issue, initially we tried to address it by just relying on using a large validation data set. However, after obtaining unfavorable results on the competition, we relied on a significance test, namely a McNemar test with a confidence level of 95%. To sum up, we first predict with A (our baseline model) on a validation data set and then for each label and for each model B i we check if choosing B i to predict for that label improves the overall micro-F measure. If yes, that label is candidate to belong to L Bi . Then, for all labels that belong to the candidate sets, we run a McNemar test, or multiple McNemar tests accordingly, to check if the difference in performance is statistically significant. and if there is a B i significantly better than A on that label then we add that label to L Bi . Below we show the pseudo code for this technique. This approach proved to be successful in the competition context, even when using relatively small datasets for validation (around 30k documents). A final note is that when performing multiple statistical comparisons (that is for more than two models) we need to keep control of the family-wise error rate (FWER) in order for the statistical comparisons to be valid. In our case, as the tests we performed were parametrical, we used the Bonferroni-Holmes step method, as proposed in <ref type="bibr" coords="6,240.07,202.63,14.61,8.74" target="#b18">[19]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Description of Systems and experiments</head><p>This section provides the description of our systems, the training procedure and the experiments. We present all results for the systems in the following section, so whenever speaking about e.g. a model being better than another or about performances, we refer the reader to section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Description of the experiments</head><p>In our experiments we used a subset of the corpus, keeping only the documents belonging to the journals from which the new, unseen data would be taken. Thus we ended up with about 4.3 million documents. For all systems, we extracted a dictionary from the corpus keeping words and bi-grams (pairs of words) with more than 6 occurrences and less than half of the size of the corpus, removing stop-words (e.g. "and", "the", etc) and non-arithmetic symbols. In case of the SVMs' training, each feature was represented by its tf-idf value <ref type="foot" coords="6,405.64,417.41,3.97,6.12" target="#foot_3">7</ref> , where tf stands for term frequency and idf, inverse document frequency. In that case we also applied zoning for features belonging in the title and features that were a label (e.g. features such as "humans", "female", etc). In the context of the BioASQ competition we used the last 50 thousand documents for validation and the preceding 1.5 million documents for training.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Systems used in the competition</head><p>We used five systems in the competition, opting to name them as Asclepios, Hippocrates, Sisyphus, Galen and Panacea.</p><p>The first two systems are identical but trained in different size data sets. We trained |L| binary SVMs in a one-vs-all approach (one for each label) and a second-level model, the Metalabeler (for predicting an instance's label cardinality). During prediction we slightly changed the Liblinear code to output a score instead of a binary decision for the SVMs. This way, for each instance we obtain a descending ranking of labels, from the ones with the highest scores to the ones with the lowest. Then, by using the Metalabeler we predict a label cardinality c for that instance and thus choose the top c labels from the ranking. Asclepios was trained on the last 950 thousand documents while Hippocrates was trained on the last 1.5 million documents.</p><p>The rest of the systems are ensembles implemented just as described in section 3. They all have Hippocrates as a component, which was the best performing system, so from now and forth we will refer to it as the baseline model.</p><p>The third system, Sisyphus, consists of an ensemble of two models, the baseline and a model of simple binary SVMs. We initially used vanilla (not tuned) SVMs for the second model but then proceeded in trying also to tune them. Feature scaling with BNS <ref type="bibr" coords="7,232.45,217.25,15.50,8.74" target="#b19">[20]</ref> was our first effort, but the trained models performed worse and training required very long times. The reason for the last observation is that if performing scaling or feature selection in a multi-label problem, the features' scaling factors for training will be different for each label. This means that we need to vectorize the training corpus |L| times, a non-trivial task in our case where |L| is of the order of 10 4 . If using common scaling factors for all labels instead (e.g. by tf-idf as we did) vectorizing needs to be done only once for all labels. Another effort for tuning the SVMs was to experiment with different values for the C parameter (other than the default 1) which did not really yield significant improvements. We then used the idea of <ref type="bibr" coords="7,367.79,324.84,15.50,8.74" target="#b20">[21]</ref> to change the weight parameter for positive instances (w1). When training a classifier with very few positive instances we can choose to penalize a false negative (a positive instance being misclassified) more than a false positive (a negative instance being misclassified). We followed this approach unfortunately just before the end of the third batch. The fourth model, Galen, is an ensemble of the baseline model and a prior LLDA model and the fifth, Panacea, combines in an ensemble the baseline model (SVMs with score ranking and Metalabeler), the tuned binary SVMs, the prior LLDA model (all trained on the last 1.5 × 10 6 documents) and a baseline model trained on the whole corpus (about 4.3m documents, except the last 50k documents). Even if from at first glance it seems redundant to combine two identical models, the reason we did this is the following: the corpus contains articles from 1974 to 2014. During this period a lot of things have changed concerning the semantics of some entities, the semantics of some labels and most importantly the distribution of labels to words. This leads to the effect of the first model, trained in 1.5 million documents (papers from 2007-2012) having a better performance than the second one, trained on the whole corpus (papers between 1974-2012), in terms of the micro-f measure. Nonetheless, the second model learns more labels and is expected to do better in some very rare labels, having more training instances. Driven by this observation we added this model in the ensemble, combining four models in total. Table <ref type="table" coords="8,287.15,191.72,4.98,8.74" target="#tab_1">1</ref> depicts the component models for the five systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Parameter Setup</head><p>All SVM-based models were trained with default parameters (C=1, e=0.01). For the LLDA model, we used 10 Markov chains and averaged them, taking a total of 600 samples (one sample every 5 iterations), after a burn-in period of 300 iterations. Alpha and beta parameters were equal for all labels during training with α = 50/|L| and β = 0.001. As noted in <ref type="bibr" coords="8,326.85,326.44,14.61,8.74" target="#b10">[11]</ref>, the prior LLDA model reduces during prediction to an LDA model with the alpha parameter proportional to the frequency of each label. We set</p><formula xml:id="formula_1" coords="8,238.19,370.40,137.79,22.31">α(l) = 50 × f requency(l) totalLabelT okens + 30 |L|</formula><p>and took 200 samples (one every 5 iterations) after a burn-in of 300 iterations, from a single Markov chain. We note here that there was a lot of room for improving the LLDA variant (e.g. average from many Markov Chains or take more samples) but unfortunately we didn't have the time to do so. Experiments were conducted on a machine with 40 processors and 1Tb of RAM. For the SVM models (apart from those with BNS scaling) the whole training procedure (dictionary extraction, vectorizing and training) for 1.5 × 10 6 documents, a vocabulary of 1.5 × 10 6 features and 26281 labels takes around 32 hours. The SVMs trained with BNS scaling, require a lot longer, about 106 hours while the LLDA model needs around 72 hours. Predicting for the 3.5 × 10 4 documents of Table <ref type="table" coords="8,227.38,524.13,4.98,8.74" target="#tab_2">2</ref> needs around 20 minutes for the SVMs and around 3 hours for the BNS SVMs. The prior LLDA model needs a very long time for predicting, around 33 hours. The reason for this is that the time needed for the Gibbs sampling algorithm is roughly proportional to the number of documents and the number of labels, which in our case, are both of the order of tens of thousands. In case of the size of the BioASQ data sets (∼ 5000 documents) predicting for the LLDA needed around 4 hours.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head><p>In this section we present the results of our experiments. Tables <ref type="table" coords="8,421.92,645.16,4.98,8.74" target="#tab_2">2</ref> and<ref type="table" coords="8,450.49,645.16,4.98,8.74" target="#tab_3">3</ref> show the performance of our component models in terms of the micro-F and macro-F measures. We can see that the Metalabeler on 1.5m documents is performing better in total, with the tuned SVMs following. Also, we can easily observe that the Metalabeler on 4.2 million documents is worse compared to the one on 1.5m documents, learning though 228 more labels. The prior LLDA model is not performing nearly as well as the SVM variants. Table <ref type="table" coords="9,176.71,514.30,4.98,8.74" target="#tab_4">4</ref> shows the performance of the models and the four systems described in section 4.2. Asclepios is omitted as it is identical to Hippocrates. Results are shown for 12.3k documents, having used 35k documents for validation. We can see that the ensemble systems perform better than the baseline (Hippocrates), with Panacea and Sisyphus reaching the best performance even though the validation data set is relatively small.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Question Answering</head><p>Being newcomers in the area of question answering, our modest goal was to replicate work already existing in the literature. We decided to focus on <ref type="bibr" coords="9,467.33,645.16,9.96,8.74" target="#b0">[1]</ref>, an approach presented in the 2013 BioASQ Workshop for extracting answers to factoid questions. Furthermore, we only focused on phase B of the question answering task, taking the gold (correct) relevant concepts, articles, snippets, and RDF triples from the benchmark data sets as input.</p><p>For each factoid question, our system firsts extracts the lexical answer type (LAT). This is achieved by splitting the question into words, extracting the part-of-speech for each word and finally extracting the first consecutive nouns or adjectives in the word list of the question. Then, each of the relevant snippets is split into sentences and each of these sentences are processed with the 2013 Release of MetaMap <ref type="bibr" coords="10,227.12,327.18,15.50,8.74" target="#b21">[22]</ref> in order to extract candidate answers.</p><p>For each candidate answer c, we calculated five scores similarly to <ref type="bibr" coords="10,440.93,339.80,9.96,8.74" target="#b0">[1]</ref>. Let I denote an indicator function, returning 1 if each input is true and 0 otherwise. The first score is prominence, which considers the frequency of each candidate answer c within the set of sentences S of the relevant snippets:</p><formula xml:id="formula_2" coords="10,237.70,398.76,242.90,22.97">Prominence(c) = s∈S I(c ∈ s) |S|<label>(1)</label></formula><p>The second score is a version of prominence that further takes into account the cosine similarity of the question q with each sentence: WeightedProminence(c) = s∈S similarity(q, s)I(c ∈ s) s∈S similarity(q, s)</p><p>The third score, specificity, considers the (in)frequency of each candidate answer in the corpus of PubMed abstracts A released by BioASQ:</p><formula xml:id="formula_4" coords="10,204.46,537.23,276.13,24.72">Specificity(c) = log |A| a∈A I(c ∈ a) / log(|A|)<label>(3)</label></formula><p>The fourth and fifth scores consider the semantic type(s) of the candidate answers as detected by MetaMap. In particular they examine whether these types intersect with the semantic types(s) of the questions LAT (fourth score) and the whole question (fifth score):</p><formula xml:id="formula_5" coords="10,152.90,642.85,327.69,23.08">TypeCoercionLAT(c) = 1 if SemType(c) ∩ SemType(LAT) = ∅ 0 otherwise (4) TypeCoercionQuestion(c) = 0.5 if SemType(c) ∩ SemType(q) = ∅ 0 otherwise<label>(5)</label></formula><p>Table <ref type="table" coords="11,178.22,178.36,4.98,8.74" target="#tab_5">5</ref> presents the results of the above scores as well as their ensemble on the 42 factoid questions out of the 100 questions provided by BioASQ as training set. Results are presented in terms of the three metrics of the BioASQ competition: Strict accuracy (SAcc), which compares the correct answer with the top candidate, lenient accuracy (LAcc), which compares the correct answer with the top 5 candidates and mean reciprocal rank (MRR), which takes into account the position of the correct answer within the ranking of candidates. Interestingly, we notice that in terms of SAcc, the best results are obtained by combining the first three non-semantic scorings. In terms of LAcc, the best results are obtained when combining the first three scorings with TCLAT weighted by 0.5 or with TCQ weighted by 1 and TCLAT weighted by 0.5. The best results in terms of MRR are obtained when combining the first three scorings with TCQ weighted by 0.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusions and Future Work</head><p>In this paper we presented our participation to both of the tasks of the BioASQ challenge, introducing a novel multi-label classifier ensemble method. This approach was successful both in our experiments and during the competition, with the ensemble systems outperforming the baseline models.</p><p>While experimenting with different data sets, we noticed a significant change in the performance of models with time. It would be really interesting to study in a systematic way this concept drift along time, as it could yield interesting observations about trends in the literature, changes of meaning of terms and, from a machine learning view, changes in the hidden distribution. Concerning the LLDA model, we think that there is a lot of room for improvements. For instance, a possible parallelization or some variant of a faster Gibbs sampling implementation scheme during the prediction phase could improve performance by allowing to draw more samples. Either way, a hybrid approach to exploit both the SVM and the LDA theory could bring significant improvements over the multi-label classification problem.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,133.99,226.60,346.61,388.34"><head></head><label></label><figDesc>1. For all documents ∈ V alidationDataset assign the relevant labels ∈ L predicting with model A 2. For each model B i -For all documents ∈ V alidationDataset assign the relevant labels ∈ L predicting with B i 3. For each label l ∈ L calculate the true positives tp Al , false positives f p Al and false negatives f n Al for A 4. For each model B i -For each label ∈ L calculate tp Bil , f p Bil and f n Bil 5. Set tp A = tp Al and f p A , f n A respectively 6. Set the micro-F measure as mf A = McNemar test between models A and B i with significance level 0.95 if B i is significantly better than A add l to L Bi (b) If l belongs to more than one candidateList i perform a McNemar test between models A and each B i with significance level 0.95 applying a FWER correction with the Bonferoni-Holmes step method -If just one B i is significantly better than A add l to L Bi -Else if many B i 's are significantly better than A choose the model B i that has the highest score in the McNemar test with A 6 9. Compute |L A | as |L A | = |L| -|L Bi | 10. For all documents ∈ T estDataset assign the relevant labels ∈ L A predicting with model A 11. For each model B i -For all documents ∈ T estDataset assign the relevant labels ∈ L Bi predicting with model B i</figDesc><table coords="5,309.20,346.78,37.21,14.00"><row><cell>2tp A</cell></row><row><cell>2tp</cell></row></table><note coords="5,320.28,354.66,47.08,6.73;5,138.97,361.34,99.23,8.74;5,157.93,373.88,90.99,9.68;5,175.61,386.27,299.55,9.65;5,175.61,398.22,279.57,9.65;5,175.61,410.18,302.36,9.65;5,138.97,422.94,80.07,8.74;5,150.93,435.50,184.23,9.65;5,174.86,447.83,52.91,8.77"><p><p>A +f p A +f n A 7. For each label l ∈ L -For each model B i • subtract tp A l, f p A l and f n A l from tp A and f p A , f n A respectively • add tp B il, f p B il</p>and f n B il to tp A and f p A , f n A respectively • If the new mf A is better than the previous add l in candidateList i 8. For each label l (a) If l belongs to just one candidateList i perform a</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,149.71,415.79,322.18,110.31"><head>Table 1 .</head><label>1</label><figDesc>Component models for the systems employed in the competition</figDesc><table coords="7,149.71,438.14,322.18,87.96"><row><cell></cell><cell></cell><cell>MetaLabeler</cell><cell>MetaLabeler</cell><cell></cell></row><row><cell></cell><cell>Binary</cell><cell>with SVMs</cell><cell>with SVMs</cell><cell></cell></row><row><cell>Systems</cell><cell>SVM</cell><cell>(1.5m docs)</cell><cell>(4.2m docs)</cell><cell>LLDA</cell></row><row><cell>Asclepios</cell><cell></cell><cell>x</cell><cell></cell><cell></cell></row><row><cell>Hippocrates</cell><cell></cell><cell>x</cell><cell></cell><cell></cell></row><row><cell>Sisyphus</cell><cell>x</cell><cell>x</cell><cell></cell><cell></cell></row><row><cell>Galen</cell><cell></cell><cell>x</cell><cell></cell><cell>x</cell></row><row><cell>Panacea</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,134.77,199.97,345.81,125.70"><head>Table 2 .</head><label>2</label><figDesc>Results for the models with which we experimented trained on the last 1.5 million documents of the corpus and tested on 35k documents already annotated documents from the competition batches</figDesc><table coords="9,148.71,245.68,319.61,79.99"><row><cell>Classifier</cell><cell>no. of labels</cell><cell>Micro-F</cell><cell>Macro-F</cell></row><row><cell>Vanilla SVMs</cell><cell>26281</cell><cell>0.56192</cell><cell>0.33190</cell></row><row><cell>Metalabeler(1.5m documents)</cell><cell>26281</cell><cell>0.59461</cell><cell>0.43622</cell></row><row><cell>SVMs with BNS scaling</cell><cell>26281</cell><cell>0.51024</cell><cell>0.27980</cell></row><row><cell>tuned SVMs( -w1 parameter)</cell><cell>26281</cell><cell>0.58330</cell><cell>0.37729</cell></row><row><cell>Metalabeler(4.2m documents)</cell><cell>26509</cell><cell>0.58508</cell><cell>0.42929</cell></row><row><cell>Prior labeled LDA</cell><cell>26281</cell><cell>0.38321</cell><cell>0.29563</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,134.77,378.03,345.81,103.78"><head>Table 3 .</head><label>3</label><figDesc>Results for the component models of our systems trained on the last 1.5 million documents of the corpus and tested on 12.3k documents already annotated documents from the competition batches</figDesc><table coords="9,148.71,423.74,319.61,58.07"><row><cell>Classifier</cell><cell>no. of labels</cell><cell>Micro-F</cell><cell>Macro-F</cell></row><row><cell>Metalabeler(1.5m documents)</cell><cell>26281</cell><cell>0.60921</cell><cell>0.44745</cell></row><row><cell>tuned SVMs( -w1 parameter)</cell><cell>26281</cell><cell>0.60296</cell><cell>0.40705</cell></row><row><cell>Metalabeler(4.2m documents)</cell><cell>26509</cell><cell>0.55350</cell><cell>0.39926</cell></row><row><cell>Prior labeled LDA</cell><cell>26281</cell><cell>0.37662</cell><cell>0.40125</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="10,153.78,116.91,307.78,81.86"><head>Table 4 .</head><label>4</label><figDesc>Results for the systems that participated in the BioASQ challenge</figDesc><table coords="10,218.60,140.70,175.07,58.07"><row><cell>Systems</cell><cell>Micro-F</cell><cell>Macro-F</cell></row><row><cell>Hippocrates</cell><cell>0.60921</cell><cell>0.44745</cell></row><row><cell>Sisyphus</cell><cell>0.61323</cell><cell>0.44816</cell></row><row><cell>Galen</cell><cell>0.60949</cell><cell>0.44880</cell></row><row><cell>Panacea</cell><cell>0.61368</cell><cell>0.44893</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="11,149.70,281.52,312.88,145.87"><head>Table 5 .</head><label>5</label><figDesc>Results of the different scores and their combinations</figDesc><table coords="11,149.70,303.56,312.88,123.83"><row><cell>Scoring</cell><cell>SAcc</cell><cell>LAcc</cell><cell>MRR</cell></row><row><cell>Prominence (P)</cell><cell>9%</cell><cell>31%</cell><cell>16%</cell></row><row><cell>WeightedProminence (WP)</cell><cell>23%</cell><cell>31%</cell><cell>25%</cell></row><row><cell>Specificity (S)</cell><cell>4%</cell><cell>23%</cell><cell>11%</cell></row><row><cell>P + WP + S</cell><cell>31%</cell><cell>43%</cell><cell>35%</cell></row><row><cell>P + WP + S + TypeCoercionLAT (TCLAT)</cell><cell>26%</cell><cell>40%</cell><cell>31%</cell></row><row><cell>P + WP + S + TCLAT × 0.5</cell><cell>29%</cell><cell>45%</cell><cell>35%</cell></row><row><cell>P + WP + S + TypeCoercionQuestion (TCQ)</cell><cell>24%</cell><cell>45%</cell><cell>33%</cell></row><row><cell>P + WP + S + TCQ × 0.5</cell><cell>29%</cell><cell>48%</cell><cell>36%</cell></row><row><cell>P + WP + S + TCQ × 0.5 + TCLAT</cell><cell>24%</cell><cell>43%</cell><cell>32%</cell></row><row><cell>P + WP + S + TCQ + TCLAT × 0.5</cell><cell>24%</cell><cell>48%</cell><cell>35%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_0" coords="2,144.73,657.80,92.22,7.86"><p>http://www.bioasq.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_1" coords="3,144.73,635.88,335.85,7.86;3,144.73,646.84,335.85,7.86;3,144.73,657.80,160.08,7.86"><p>by referring to a data set with power-law statistics we mean that the vast majority of labels have a very low frequency and only very few have a high frequency, for a more elaborate explanation refer to<ref type="bibr" coords="3,290.48,657.80,14.33,7.86" target="#b11">[12]</ref> </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_2" coords="5,144.73,624.92,335.86,7.86;5,144.73,635.88,335.85,7.86;5,144.73,646.84,335.85,7.86;5,144.73,657.80,55.83,7.86"><p>It is needless at this point to apply again McNemar tests among the Bi models because we are not interested on determining if their differences in performance are significant; we just need to choose one among them as we know they are all doing better than A</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_3" coords="6,144.73,657.80,260.53,7.86"><p>apart from the BNS SVMs in which case we used the BNS value</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="12,142.96,249.33,337.62,7.86;12,151.52,260.29,329.05,7.86;12,151.52,271.25,282.89,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,355.84,249.33,124.73,7.86;12,151.52,260.29,90.45,7.86">Answering factoid questions in the biomedical domain</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Tsatsaronis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Schroeder</surname></persName>
		</author>
		<ptr target="CEUR-WS.org" />
	</analytic>
	<monogr>
		<title level="m" coord="12,413.26,260.29,61.71,7.86">BioASQ@CLEF</title>
		<title level="s" coord="12,216.80,271.25,118.03,7.86">CEUR Workshop Proceedings</title>
		<editor>
			<persName><forename type="first">A</forename><forename type="middle">C N</forename><surname>Ngomo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Paliouras</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1094">1094. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,282.39,337.63,7.89;12,151.52,293.38,32.25,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,248.38,282.42,97.25,7.86">Support-vector networks</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,353.96,282.42,72.35,7.86">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,304.55,337.62,7.86;12,151.52,315.48,307.35,7.89" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,401.83,304.55,78.74,7.86;12,151.52,315.51,112.06,7.86">Liblinear: A library for large linear classification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><forename type="middle">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,271.22,315.51,83.91,7.86">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008-06">June 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,326.68,337.62,7.86;12,151.52,337.64,329.06,7.86;12,151.52,348.60,245.77,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,316.75,326.68,163.83,7.86;12,151.52,337.64,45.31,7.86">Large scale multi-label classification via metalabeler</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Rajan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">K</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,220.77,337.64,259.81,7.86;12,151.52,348.60,62.80,7.86">WWW &apos;09: Proceedings of the 18th international conference on World wide web</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="211" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,359.77,337.62,7.86;12,151.52,370.73,329.06,7.86;12,151.52,381.69,329.06,7.86;12,151.52,392.65,13.82,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,192.46,359.77,224.61,7.86">A study of thresholding strategies for text categorization</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,437.88,359.77,42.70,7.86;12,151.52,370.73,329.06,7.86;12,151.52,381.69,162.98,7.86">SIGIR &apos;01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="137" to="145" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,403.82,337.62,7.86;12,151.52,414.78,211.29,7.86" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="12,239.20,403.82,237.82,7.86">A study on threshold selection for multi-label classification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
		<respStmt>
			<orgName>National Taiwan University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="12,142.96,425.95,337.62,7.86;12,151.52,436.88,272.16,7.89" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="12,342.81,425.95,137.77,7.86;12,151.52,436.91,141.32,7.86">Large-scale multi-label text classification -revisiting neural networks</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Nam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Fürnkranz</surname></persName>
		</author>
		<idno>CoRR abs/1312.5419</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,448.08,337.62,7.86;12,151.52,459.01,122.74,7.89" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,301.82,448.08,104.62,7.86">Latent dirichlet allocation</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,415.82,448.08,64.76,7.86;12,151.52,459.04,17.08,7.86">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003-03">March 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,470.21,337.62,7.86;12,151.52,481.15,239.97,7.89" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,268.89,470.21,93.53,7.86">Finding scientific topics</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,369.64,470.21,110.94,7.86;12,151.52,481.17,83.50,7.86">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="5228" to="5235" />
			<date type="published" when="2004-04">April 2004</date>
		</imprint>
	</monogr>
	<note>Suppl. 1</note>
</biblStruct>

<biblStruct coords="12,142.61,492.35,337.96,7.86;12,151.52,503.30,329.05,7.86;12,151.52,514.26,329.06,7.86;12,151.52,525.22,329.06,7.86;12,151.52,536.18,107.23,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,373.74,492.35,106.83,7.86;12,151.52,503.30,232.70,7.86">Labeled lda: A supervised topic model for credit attribution in multi-labeled corpora</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Ramage</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Nallapati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,406.30,503.30,74.28,7.86;12,151.52,514.26,291.39,7.86;12,207.53,525.22,47.15,7.86">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Stroudsburg, PA, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="248" to="256" />
		</imprint>
	</monogr>
	<note>EMNLP &apos;09</note>
</biblStruct>

<biblStruct coords="12,142.61,547.35,337.96,7.86;12,151.52,558.28,317.39,7.89" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,371.41,547.35,109.16,7.86;12,151.52,558.31,138.88,7.86">Statistical topic models for multi-label document classification</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">N</forename><surname>Rubin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Smyth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,298.03,558.31,53.39,7.86">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="157" to="208" />
			<date type="published" when="2012-07">July 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,569.48,337.96,7.86;12,151.52,580.44,329.06,7.86;12,151.52,591.40,329.06,7.86;12,151.52,602.36,105.71,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="12,281.55,569.48,199.03,7.86;12,151.52,580.44,29.60,7.86">A scalability analysis of classifiers in text categorization</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Kisiel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,201.38,580.44,279.20,7.86;12,151.52,591.40,261.50,7.86">Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Informaion Retrieval. SIGIR &apos;03</title>
		<meeting>the 26th Annual International ACM SIGIR Conference on Research and Development in Informaion Retrieval. SIGIR &apos;03<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="96" to="103" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,613.53,337.96,7.86;12,151.52,624.49,286.30,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,222.92,613.53,160.79,7.86">Ensemble Methods in Machine Learning</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">G</forename><surname>Dietterich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,406.12,613.53,74.45,7.86;12,151.52,624.49,231.73,7.86">Proceedings of the 1st International Workshop in Multiple Classifier Systems</title>
		<meeting>the 1st International Workshop in Multiple Classifier Systems</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,635.64,337.98,7.89;12,151.52,646.62,100.25,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,216.75,635.66,180.47,7.86">Original contribution: Stacked generalization</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">H</forename><surname>Wolpert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,406.22,635.66,53.87,7.86">Neural Netw</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="241" to="259" />
			<date type="published" when="1992-02">February 1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,657.77,320.97,7.89" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="12,206.31,657.80,74.42,7.86">Bagging predictors</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,288.69,657.80,53.39,7.86">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="123" to="140" />
			<date type="published" when="1996-08">August 1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,120.64,337.97,7.89;13,151.52,131.63,32.25,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="13,216.47,120.67,133.07,7.86">The strength of weak learnability</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,357.58,120.67,53.50,7.86">Mach. Learn</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="197" to="227" />
			<date type="published" when="1990-07">July 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,142.59,337.96,7.86;13,151.52,153.52,329.07,7.89;13,151.52,164.51,32.25,7.86" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="13,325.51,142.59,155.07,7.86;13,151.52,153.55,171.75,7.86">Multilabel classification using heterogeneous ensemble of multi-label classifiers</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Tahir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Bouridane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,333.93,153.55,90.37,7.86">Pattern Recogn. Lett</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="513" to="523" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,175.47,337.96,7.86;13,151.52,186.42,329.06,7.86;13,151.52,197.36,145.85,7.89" xml:id="b17">
	<analytic>
		<title level="a" type="main" coord="13,451.91,175.47,28.66,7.86;13,151.52,186.42,329.06,7.86;13,151.52,197.38,30.97,7.86">A onesize-fits-all indexing method does not exist: Automatic selection based on metalearning</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Jimeno-Yepes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">G</forename><surname>Mork</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Aronson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,190.45,197.38,22.77,7.86">JCSE</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="151" to="160" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,208.34,337.96,7.86;13,151.52,219.27,180.24,7.89" xml:id="b18">
	<analytic>
		<title level="a" type="main" coord="13,202.62,208.34,239.37,7.86">Statistical comparisons of classifiers over multiple data sets</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Demsar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,450.22,208.34,30.35,7.86;13,151.52,219.30,121.69,7.86">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,230.26,337.96,7.86;13,151.52,241.22,329.05,7.86;13,151.52,252.18,322.55,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="13,205.79,230.26,274.79,7.86;13,151.52,241.22,68.29,7.86">BNS feature scaling: an improved representation over tf-idf for svm text classification</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Forman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,239.69,241.22,240.89,7.86;13,151.52,252.18,140.54,7.86">Proceedings of the 17th ACM conference on Information and knowledge management. CIKM &apos;08</title>
		<meeting>the 17th ACM conference on Information and knowledge management. CIKM &apos;08<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="263" to="270" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,263.14,337.96,7.86;13,151.52,274.07,274.15,7.89" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="13,325.68,263.14,154.90,7.86;13,151.52,274.10,109.87,7.86">Rcv1: A new benchmark collection for text categorization research</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">G</forename><surname>Rose</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,269.39,274.10,83.91,7.86">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="361" to="397" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,285.05,337.96,7.86;13,151.52,295.99,189.48,7.89" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="13,269.08,285.05,211.50,7.86;13,151.52,296.01,61.37,7.86">An overview of metamap: historical perspective and recent advances</title>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">R</forename><surname>Aronson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,221.21,296.01,30.33,7.86">JAMIA</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="229" to="236" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
