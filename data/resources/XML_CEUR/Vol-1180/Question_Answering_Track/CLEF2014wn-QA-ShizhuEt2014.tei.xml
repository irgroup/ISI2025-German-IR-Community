<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,157.95,116.90,299.46,12.90;1,230.39,134.83,154.58,12.90">CASIA@V2: A MLN-based Question Answering System over Linked Data</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,202.40,172.90,39.57,8.64"><forename type="first">Shizhu</forename><surname>He</surname></persName>
							<email>shizhu.he@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<addrLine>Zhongguancun East Road 95#</addrLine>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,249.16,172.90,60.08,8.64"><forename type="first">Yuanzhe</forename><surname>Zhang</surname></persName>
							<email>yzzhang@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<addrLine>Zhongguancun East Road 95#</addrLine>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,316.39,172.90,36.32,8.64"><forename type="first">Kang</forename><surname>Liu</surname></persName>
							<email>kliu@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<addrLine>Zhongguancun East Road 95#</addrLine>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,376.16,172.90,36.80,8.64"><forename type="first">Jun</forename><surname>Zhao</surname></persName>
							<email>jzhao@nlpr.ia.ac.cn</email>
							<affiliation key="aff0">
								<orgName type="department">Institute of Automation</orgName>
								<orgName type="laboratory">National Laboratory of Pattern Recognition</orgName>
								<orgName type="institution">Chinese Academy of Sciences</orgName>
								<address>
									<addrLine>Zhongguancun East Road 95#</addrLine>
									<postCode>100084</postCode>
									<settlement>Beijing</settlement>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,157.95,116.90,299.46,12.90;1,230.39,134.83,154.58,12.90">CASIA@V2: A MLN-based Question Answering System over Linked Data</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">3FDFB8D47BF3AFF518A1B3DEB3BDEB06</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Question Answering</term>
					<term>Linked Data</term>
					<term>Markov Logic Network</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a question answering system (CASIA@V2) over Linked Data (DBpedia), which translates natural language questions into structured queries automatically. Existing systems usually adopt a pipeline framework, which contains four major steps: 1) Decomposing the question and detecting candidate phrases; 2) mapping the detected phrases into semantic items of Linked Data; 3) grouping the mapped semantic items into semantic triples; and 4) generating the rightful SPARQL query. We present a jointly learning framework using Markov Logic Network(MLN) for phrase detection, phrases mapping to semantic items and semantic items grouping. We formulate the knowledge for resolving the ambiguities in three steps of QALD as first-order logic clauses in a MLN. We evaluate our approach on QALD-4 test dataset and achieve an F-measure score of 0.36, an average precision of 0.32 and an average recall of 0.40 over 50 questions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the rapid development of the Web of Data, there are many RDF datasets published as Linked Data <ref type="bibr" coords="1,223.10,480.12,10.58,8.64" target="#b0">[1]</ref>, such as DBpedia <ref type="bibr" coords="1,308.49,480.12,10.58,8.64" target="#b1">[2]</ref>, Freebase <ref type="bibr" coords="1,362.66,480.12,11.62,8.64" target="#b2">[3]</ref> and YAGO <ref type="bibr" coords="1,422.82,480.12,10.58,8.64" target="#b3">[4]</ref>. The growing Linked Data contain a wealth of knowledge including entities, classes and properties. Moreover, these linked data usually have complex structures and are highly heterogeneous. However, there are the gaps between the users and the Linked Data. On the one hand, the users, even expert programmers, need a lot of practices to handle standard structured query languages like SPARQL. On the other hand, due to the diversity In: Cappellato, L., Ferro, N., Halvey, M., and Kraaij, W., editors <ref type="bibr" coords="1,375.67,581.50,22.41,7.77">(2014)</ref>. CLEF 2014 Labs and Workshops, Notebook Papers. CEUR Workshop Proceedings (CEUR-WS.org), ISSN 1613-0073, http://ceur-ws.org/ Vol-1180/. Thanks to Prof. Hang Li, Dr. Yibo Zhang and Dr. Jie Zhang at Huawei Noah'S Ark Lab and the anonymous reviewers for their insightful advices and and suggestions. This work was sponsored by the National Natural Science Foundation of China (No. 61272332 and No. 61202329) and CCF-Tencent Open Research Fund. This work was supported in part by Noah's Ark Lab of Huawei Tech. Ltm. and high heterogeneity of the Linked Data, it is difficult for humans to select relevant resources and discover useful information. Thus, developing user-friendly interface for accessing those linked data become increasing important.</p><p>Question answering over Linked Data <ref type="bibr" coords="2,302.79,156.17,11.62,8.64" target="#b4">[5]</ref> is aimed at eliminating those gaps, which attempts to allow the users to access those structured data with natural language. For example, with respect to the question: "Which software has been developed by organizations founded in California, USA?", the aim is to automatically convert this utterance into a SPARQL query which contains the following subject-property-object (SPO) triple format: ?url rdf:type dbo:Software, ?url dbo:developer ?x1, ?x1 rdf:type dbo:Company, ?x1 dbo:foundationPlace dbr:California<ref type="foot" coords="2,350.78,226.24,3.49,6.05" target="#foot_0">1</ref> .</p><p>Lopez et al. <ref type="bibr" coords="2,197.37,239.86,11.62,8.64" target="#b5">[6]</ref> have given a comprehensive survey in this research area. The authors develop PowerAqua system <ref type="bibr" coords="2,249.37,251.82,11.62,8.64" target="#b6">[7]</ref> to answer questions on large, heterogeneous datasets. For questions containing quantifiers, comparatives or superlatives, Unger et al. <ref type="bibr" coords="2,444.39,263.77,11.62,8.64" target="#b7">[8]</ref> translate natural language(NL) questions to formal language(FL) structured query using several SPARQL templates and a set of heuristic rules mapping phrase to semantic items. And DEANNA <ref type="bibr" coords="2,194.65,299.64,11.62,8.64" target="#b8">[9]</ref> jointly disambiguates the following tasks based on integer linear programming: segmenting question, mapping phrases to semantic items and constructing SPARQL triple patterns.</p><p>This paper proposes a novel algorithm based on a learning framework, Markov Logic Network (MLN) <ref type="bibr" coords="2,230.35,347.46,15.27,8.64" target="#b9">[10]</ref>, to learn a joint model for constructing structured queries from natural language utterances. MLN is a statistical relational learning framework that combines first-order logic and Markov networks. The appealing property of MLN is that it is readily interpretable by humans and is natural to perform joint learning under the Markov logic framework. We formulate the knowledge for resolving the ambiguities in three steps of QALD (phrase detection, phrase-to-semantic-item mapping and semantic items grouping) as first-order logic clauses in a MLN. In the framework of MLN, all clauses will make interacted effects which combines resolving all problems into a unified process. In this way, the result in each step can be globally optimized. Moreover, different from previous methods, we adopt a learning strategy to automatically learn the patterns for semantic items grouping. We also formulate the learned patterns as first-order clauses in MLN. The model will learn the weights of each clause to determine the most effective patterns for semantic triples construction. In this way, our approach can cover more semantic expressions and answer more questions than previous method based on manually designed patterns.</p><p>We evaluate our approach on QALD-4 test dataset and achieve an F-measure score of 0.36, an average precision of 0.32 and an average recall of 0.40 over 50 questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Description</head><p>The current version of our QA system is not designed to answer the questions which contain numbers, date comparisons and aggregation operations such as group by or order by. We also do not consider the questions which contain filter condition. Figure 1 shows the architecture of our system to translate a question into a formal SPARQL query.</p><p>At first, sequence of tokens(phrase) are detected that probably indicate semantic items, such as software, developed by and California. This step detects full potentially phrases, and leaves the decision for phrases selecting in later steps.</p><p>Next, the phrases are mapping to semantic items. Phrases can denote entities, classes and properties. For example, the phrase software can denote class dbo:Software and property dbo:developer, and the phrase developed by can denote entity dbr:videogamedeveloper, class dbo:BritishRoyalty and property dbo:developer. This step purely constructs a candidate space for every possible mapping, and leaves the decision for select which semantic items in the next step.</p><p>Then, we should make the decisions for choosing phrases, mapping the chosen phrases to suitable semantic items and determine the relations of selected semantic item. We formulate the joint decisions as an generalized inference task. We employ rich features and constraints (including hard and soft constraints) to infer the joint decisions using a MLN.</p><p>Finally, with the inference results, the last step constructs a semantic item query graph, and generates an executable SPARQL query with the question type.</p><p>We will give a detailed description of each component and give a step by step explanation with the following example, Figure <ref type="figure" coords="3,317.65,613.85,4.98,8.64" target="#fig_1">2</ref> shows the intermediate results of every steps:</p><p>Which software has been developed by organizations founded in California, USA?. 2.1 System Pipleline 1) Phrase detection. Sequences of tokens (phrases) that probably indicate semantic items are detected. To this end, we do not use named entity recognizer (NER) because of its low coverage. <ref type="foot" coords="4,204.84,508.34,3.49,6.05" target="#foot_1">2</ref> To avoid missing useful phrases, we retain all n-grams as candidate phrases, and then use some rules to filter them. The rules include: the length of tokens span must be less than 4 (excepting all contiguous tokens are capitalizations); the POS tag of the start token must be jj, nn, rb and vb; all contiguous capitalization tokens must not be split, and so on. For instance, software, developed by, organizations, founded in and California are detected in the example.</p><p>2) Mapping phrase to semantic item. After phrases are detected, each phrase may be mapped to the semantic items in KB (entities, classes and properties). For example, software is mapped to dbo:Software, dbo:developer, etc.; California is mapped to dbr:California, dbr:California (wine), etc. We use different techniques and resources to map phrases to different types of semantic items. For mapping phrases to entities, considering the entities in DBpeida are curated from Wikipeida, we employ anchors, redirections and disambiguations information from Wikipedia. For mapping phrases to classes, considering that classes have lexical variation, especially synonyms, e.g., dbo:Film could be mapped from film, movie and show, we use word2vec tool <ref type="foot" coords="5,435.28,178.41,3.49,6.05" target="#foot_2">3</ref> to convert every word (phrase) into a vector and compute the similarity between the phrase and the class in KB. The similarity scoring methods are introduced in Section 3.2. Then, the top-N most similar classes for each phrase are returned. For mapping phrases to properties, we employ the resources from PATTY <ref type="bibr" coords="5,339.40,227.91,16.60,8.64" target="#b10">[11]</ref> and ReVerb <ref type="bibr" coords="5,409.53,227.91,15.27,8.64" target="#b11">[12]</ref>. Specifically, we first compute the associations between the semantic properties in DBpedia and relation patterns in PATTY and ReVerb through instance alignments as same as <ref type="bibr" coords="5,437.39,251.82,15.27,8.64" target="#b12">[13]</ref>. Next, if a detected phrase is matched to some relation pattern, the corresponding properties in DBpedia will be returned as the candidates. This step purely constructs a candidate space for every possible mapping, and the decision of selecting the best fitting semantic item is made in the next step.</p><p>3) Feature extraction and joint inference. There are ambiguities in phrase detection and mapping-phrase-to-semantic-item. This step consists in the resolution of these ambiguities and determine the relations among the mapped semantic items. It is the core contribution of this paper, which performs disambiguation in a unified manner. First, feature extraction is performed to prepare rich features from the question and the knowledge base. Next, the disambiguation is performed in a joint fashion with a Markov Logic Network (MLN). The detailed information will be presented in the next Section.</p><p>4) SPARQL generation. Based on the inference results, we construct a query graph. The vertex contains the following information: the phrase, token span indexs of the phrase, the mapped semantic item and its type. The edge indicates the relation between two semantic items. For example, we use 1 2 to indicate that the first argument of an item matches the second argument of another item <ref type="foot" coords="5,390.14,442.42,3.49,6.05" target="#foot_3">4</ref> . The right bottom in Figure <ref type="figure" coords="5,163.40,456.04,4.98,8.64" target="#fig_1">2</ref> shows an example of it. The relation in the query graph is paired data merely, but the SPARQL queries need the grouped triples of semantic items. Thus, we convert a query graph into multiple joined semantic triples. Three interconnected semantic items, which must ensure the middle item is a property, are converted into a semantic triple. For example, the query graph dbo:Book <ref type="bibr" coords="5,334.83,504.16,4.25,8.06">[</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Feature extraction &amp; joint inference</head><p>In this section, we will first briefly describe Markov Logic Networks. Then, we present the predicates(features) and the first-order logic formulas for joint inference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Markov Logic Networks</head><p>Markov logic networks combine Markov networks with first-order logic in probabilistic framework <ref type="bibr" coords="6,204.44,301.58,17.62,8.64" target="#b9">[10,</ref><ref type="bibr" coords="6,222.06,301.58,13.22,8.64" target="#b13">14]</ref>. A Markov logic network consists of a set of first-order formulas. Each formula consists of a set of first-order predicates, logical connectors and variables. However, differently to first-order logic where a formula represents a hard constraints, these logic formulas are softened and can be violated with some penalty (the weight of formula) in MLN.</p><p>An MLN M is consists of several weighted formulas {(φ i , w i )} i , where φ i is a first order formula and w i is the penalty(the formula's weight). These weighted formulas define a probability distribution over sets of possible worlds. Let y denote a possible world, then p(y) is defined as follows:</p><formula xml:id="formula_0" coords="6,213.22,414.66,267.38,35.26">p(y) = 1 Z exp   (φi,wi)∈M w i c∈C n φ i f φi c (y)   ,<label>(1)</label></formula><p>where each c is a binding of free variables in φ i to constants; f φi c is a binary feature function that returns 1 if the ground formula we get through replacing the free variables in φ i with the constants in c under the given possible world y is true, and 0 otherwise; C n φ i is the set of all possible bindings for the free variables in φ i . Z is a normalization constant. The Markov Network corresponds to this distribution, where nodes represent ground atoms and factors represent ground formulas.</p><p>Let us illustrate how MLN determine the relation of semantic items mapped by phrases. The following formulas indicates that if two semantic items have some dependency path tags <ref type="foot" coords="6,196.59,556.09,3.49,6.05" target="#foot_5">6</ref> , then they have some type of relations with some weights.</p><p>(φ 1 , w 1 ) : depP athT ag(a, b, "pobj") ∧ (a = b) ⇒ relation(a, b, "2 1").</p><p>(</p><formula xml:id="formula_1" coords="6,210.76,584.31,269.83,51.14">) (φ 2 , w 2 ) : depP athT ag(a, b, "pobj") ∧ (a = b) ⇒ relation(a, b, "1 1").<label>2</label></formula><p>Here, a and b are variables which represent any semantic item, depPathTag and relation are an observed predicate and a hidden predicate, respectively. The values of observed predicates are known from feature extraction, and the values of hidden predicates are infered. The values of two weights w 1 and w 2 affect the decision of choosing relation types between two semantic items.</p><p>There are a lot of methods to inference and learn the weights for MLN <ref type="bibr" coords="7,441.56,180.12,19.52,8.64" target="#b13">[14,</ref><ref type="bibr" coords="7,461.08,180.12,14.64,8.64" target="#b9">10]</ref>. Several packages for MLN learning available online for free, such as Alchemy<ref type="foot" coords="7,443.54,190.40,3.49,6.05" target="#foot_6">7</ref> , Tuffy<ref type="foot" coords="7,474.12,190.40,3.49,6.05" target="#foot_7">8</ref> , thebeast <ref type="foot" coords="7,167.41,202.36,3.49,6.05" target="#foot_8">9</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Predicates</head><p>In MLN, we design several predicates to resolve the ambiguities in phrase detection, mapping phrases to semantic items and semantic items grouping. Specifically, we design a hidden predicate hasPhrase(i) to indicate that the ith candidate phrase has been chosen, predicate hasResouce(i,j) to indicate that the ith phrase is mapped to the jth semantic item, and predicate hasRelation(j,k,rr) to indicate that the jth semantic item and the kth semantic item can be grouped together with the relation type rr. Note that we define four relation types between two semantic items: 1 1, 1 2, 2 1 and 2 2. Here, the relation type t s means the tth argument of the first semantic item corresponds to the sth argument of the second semantic item. The detailed illustration is shown in Table <ref type="table" coords="7,460.62,349.80,3.74,8.64" target="#tab_1">1</ref>. Moreover, we define a set of observed predicates to describe the properties of phrases, semantic items, relations between phrases and relations between semantic items. The observed predicates and descriptions are shown in Table <ref type="table" coords="7,361.00,520.36,3.74,8.64" target="#tab_2">2</ref>.</p><p>Previous methods usually designed some heuristic patterns to group semantic items, which employ the human-designed syntactic path between two phrases to determine the relations between any two phrases. In contrast, we collect all the tokens in the dependency path between two phrases as possible patterns. The predicate phraseDepTag and hasMeanWord are designed to indicate the possible patterns. Note that if these tokens only contain POS tags dt|in|wdt|to|cc|ex|pos|wp or stop words, the predicate hasMean-Word is false, otherwise is true. In this way, our system is expected to cover more language expressions and answer more questions. Moreover, the SPARQL endpoint is used </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Describing the attributes of phrases and relation between two phrases phraseIndex(p, i, j)</head><p>The start and end position of phrase p in question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>phrasePosTag(p, pt)</head><p>The POS tag of head word in phrase p. phraseDepTag(p, q, dt)</p><p>The dependency path tags between phrase p and q. phraseDepOne (p, q)</p><p>If there is only one tag in the dependency path, the predicate is true. hasMeanWord (p, q)</p><p>If there is any one meaning word in the dependency path of two phrases, the predicate is true. Describing the attributes of semantic item and the mapping between phrase and semantic item resourceType(r, rt)</p><p>The type of semantic item r. Types of semantic items include Entity, Class and Property priorMatchScore(p, r, s)</p><p>The prior score of phrase p mapping to semantic item r. Describing the attributes of relation between two semantic items in knowledge base hasRelatedness(p, q, s)</p><p>The semantic coherence of semantic items. isTypeCompatible(p, q, rr)</p><p>If semantic items p is type-compatible with semantic items q, the predicate is true. hasQueryResult(s, p, o, rr1, rr2) If the triple pattern consisting of semantic items s, p, o and relation types rr1, rr2</p><p>have query results, the predicate is true.</p><p>to verify the type compatibility of two semantic items and whether or not one triple pattern can obtain query results. The predicate hasRelatedness needs to computes the coherence score between two semantic items. Following Yahya et al. <ref type="bibr" coords="8,292.21,333.11,10.58,8.64" target="#b8">[9]</ref>, we use the Jaccard coefficient based on the inlinks between two semantic items.</p><p>The predicate priorMatchScore assigns a score prior to mapping a phrase to a semantic item. We use different ways to compute this scores for different semantic item types. For entities, we use a normalized score based on the frequencies of a phrase referring to a entity. For classes and properties, we use different methods. At first, we define three similarity score metrics as follows: a) s 1 : Levenshtein distance score between the labels of semantic item and phrase; b) s 2 : word embedding score, which is the similarity between two phrases, is the maximum value of the cosine of words between two phrases; c) s 3 : instance overlap score, which is computed using the Jaccard coefficient of instance overlap as a similarity score. The prior scores for mapping phrases to classes and properties are αs 1 + (1 -α)s 2 and αs 1 + βs 2 + (1 -α -β)s 3 , respectively. The parameters are set with empirical values<ref type="foot" coords="8,294.70,475.20,6.97,6.05" target="#foot_9">10</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Formulas</head><p>We use two kinds of formulas for jointly decisions: Boolean and Weighted formulas. Boolean formulas are hard constraints which must be satisfied with the entire ground atoms in final inference results. Weighted formulas are soft constraints which could be violated with some penalties. 1) Boolean Formulas (Hard Constraints) Table <ref type="table" coords="8,336.76,577.47,4.98,8.64" target="#tab_3">3</ref> lists the boolean formulas used in this work. The " " notation indicates an arbitrary constant. The "||" notation expresses the number of true grounded atoms in the formula. These formulas express the following constraints: hf1: if a phrase is chosen, then it must have a mapped semantic item; hf2: if a semantic item is chosen, then its mapped phrase must be chosen; resourceT ype(r, "Entity") ⇒!hasRelation(r, , "2 1") ∧ !hasRelation(r, , "2 2") hf10 resourceT ype(r, "Entity") ⇒!hasRelation( , r, "2 1") ∧ !hasRelation(r, , "2 2") hf11 resourceT ype(r, "Class") ⇒!hasRelation(r, , "2 1") ∧ !hasRelation(r, , "2 2") hf12 resourceT ype(r, "Class") ⇒!hasRelation( , r, "2 1") ∧ !hasRelation(r, , "2 2") hf13</p><p>!isT ypeCompatible(r1, r2, rr) ⇒!hasRelation(r1, r2, rr) hf3: a phrase can map to one semantic item at most; hf4: if the phrase is not chosen, then its mapping semantic item should not be chosen; hf5: if a semantic item is chosen, then it should have one relation with other semantic items at least; hf6: two semantic items have one relation at most; hf7: if a relation for two semantic items is chosen, then they must be chosen; hf8: each two chosen phrases must not overlap; hf9, hf10, hf11, hf11: the semantic item with type Entity and Class should not have second argument matching with others; hf12: The chosen relation for two sematic items must be type-compatible.</p><p>2) Weighted Formulas (Soft Constraints) Table <ref type="table" coords="9,340.08,561.79,4.98,8.64" target="#tab_4">4</ref> lists the weighted formulas used in this work. The "+" notation in the formulas indicates that each constant of the logic variable should be weighted separately. Those formulas express the following properties in joint decisions: sf1, sf2: The larger the score of phrase mapping to semantic item, the more likely the corresponding phrase and semantic item should been chosen; sf3: there are some associations between POS tags of phase and types of mapped semantic item; sf4, sf5, sf6: there are some associations between the dependency tags in the depen-dency pattern path of two phases and the types of relation of two mapped semantic items; sh7: the larger the relatedness of two semantic items, the more likely they have a relation; sf8: if the triple pattern has query results, those semantic items should have corresponding relations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and discussion</head><p>Stanford dependency parser <ref type="bibr" coords="10,265.90,241.69,16.60,8.64" target="#b14">[15]</ref> is used for extracting features from dependency parse trees. We use the toolkit thebeast<ref type="foot" coords="10,290.02,251.98,6.97,6.05" target="#foot_10">11</ref> to learn the weights for the formulas and perform MAP inference. The inference algorithm uses a cutting plane approach. And for parameter learning, we set all initial weights to zeros and use online learning algorithm with MIRA update rules to update the weights of formulas. The numbers of iterations for training and testing are set to 10 and 200 epochs, respectively.</p><p>Our system could learn the effectiveness patterns. We show the weights of the learned patterns corresponding with formula sf3 in MLN, as shown in Table <ref type="table" coords="10,435.11,325.96,3.74,8.64" target="#tab_5">5</ref>. From the table, we can see that nn is mapped to Entity more likely than Class and Property, and vb is most likely mapped to Property. It proves that our model can learn the effective and reasonable patterns for QALD.  <ref type="table" coords="10,175.01,505.06,4.98,8.64" target="#tab_1">1</ref> gives the evaluation results with average precision, average recall and Fmeasure. It shows the number of question our system can answer, the number of right and partially right answers among them. Among the factors that affect performance most are: 1) training set consisting of 110 questions is limited, we found some weights of grounded formula are zero; 2) the parameters are used for computing prior score mapping phrase to semantic item are difficult to tune, because we use different method to entities, classes and properties; 3) lack of global constraints, such as, it is hard to count the number of unmapped tokens in question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper, we present a question answering system over Linked Data which translates the natural language questions into the standard RDF data queries (SPARQL). We present a jointly learning framework for phrase detection, phrases mapping to semantic items and semantic items grouping. The novelty of our method lies in that we make joint inference and pattern learning for all subtasks in QALD by using first-order logic. Our benchmark results demonstrate the effectiveness of the proposed method.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,236.88,335.66,141.59,8.12"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. The architecture of CASIA@V2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,248.01,437.29,119.34,8.12;4,134.25,286.46,154.10,139.95"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Framework of our system.</figDesc><graphic coords="4,134.25,286.46,154.10,139.95" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,134.77,504.16,364.08,118.57"><head></head><label></label><figDesc>ClassURI, we generate ?x rdf:type ClassURI . If the query graph contains two connected vertexes, we append a variable to bind the missing match argument of the semantic item. The final SPARQL query is constructed by joining the semantic item triples and combining them with the corresponding SPARQL template. We divide the questions into three types: Yes/No, Number and Normal. Yes/No questions use the ASK WHERE template. With respect to number questions, we use SELECT COUNT(?url) WHERE template, if it cannot obtain a fitting SPARQL query(the query result are not a number), we then use normal question template to generate a query again. Normal questions use the SELECT ?url WHERE template. For instance, we construct the SPARQL query SELECT(?url) WHERE{ ?url rdf:type dbo:Software. ?url dbo:developer ?x1. ?x1 rdf:type dbo:Company. ?x1 dbo:foundationPlace dbr:California.} toward the example.</figDesc><table coords="5,339.08,504.16,141.51,12.48"><row><cell>Class] 1 2 ← →</cell><cell>dbo:author[Property] 1 1 ← →</cell></row></table><note coords="5,134.77,516.89,356.14,8.64;5,134.77,528.85,171.75,8.64;5,294.08,533.76,12.44,7.86;5,308.22,529.14,97.66,8.06;5,393.44,533.76,12.44,7.86;5,407.59,527.17,91.26,10.03;5,134.77,541.87,345.83,8.64;5,134.77,553.83,246.12,8.64"><p>dbr:Danielle Steel[Entity] is converted into ?x rdf:type dbo:Book, dbr:Danielle dbo:author ?x , and dbo:populationTotal[Property] 1 2 ← → dbo:capital[Property] 1 1 ← → dbr:Australia[Entity] 5 is converted into ?x1 dbo:populationTotal ?answer, ?x1 dbo:capital dbr:Australia . If the query graph only contains one vertex which indicates a class</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,201.48,381.17,210.84,87.54"><head>Table 1 .</head><label>1</label><figDesc>Examples of the relation types.</figDesc><table coords="7,201.48,401.98,210.84,66.73"><row><cell cols="2">Type Example</cell><cell>Question</cell></row><row><cell>1 1</cell><cell cols="2">dbo:height 1 1 dbr:Michael Jordan How tall is Michael Jordan?</cell></row><row><cell>1 2</cell><cell>dbo:River 1 2 dbo:crosses</cell><cell>Which river does the Brook-</cell></row><row><cell></cell><cell></cell><cell>lyn Bridge cross?</cell></row><row><cell>2 1</cell><cell>dbo:creator 2 1 dbr:Walt Disney</cell><cell>Which spaceflights were</cell></row><row><cell></cell><cell></cell><cell>launched from Baikonur?</cell></row><row><cell>2 2</cell><cell>dbo:birthPlace 2 2 dbo:capital</cell><cell>Which actors were born in</cell></row><row><cell></cell><cell></cell><cell>the capital of American?</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,226.35,116.82,162.64,8.12"><head>Table 2 .</head><label>2</label><figDesc>Descriptions of observed predicates.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,144.09,116.82,327.17,108.26"><head>Table 3 .</head><label>3</label><figDesc>Descriptions of boolean formulas.</figDesc><table coords="9,144.09,137.68,327.17,87.41"><row><cell>hf1</cell><cell>hasP hrase(p) ⇒ hasResource(p, )</cell></row><row><cell>hf2</cell><cell>hasResource(p, ) ⇒ hasP hrase(p)</cell></row><row><cell>hf3</cell><cell>|hasResource(p, )| ≤ 1</cell></row><row><cell>hf4</cell><cell>!hasP hrase(p) ⇒!hasResource(p, r)</cell></row><row><cell>hf5</cell><cell>hasResource( , r) ⇒ hasRelation(r, , ) ∨ hasRelation( , r, )</cell></row><row><cell>hf6</cell><cell>|hasRelation(r1, r2, )| ≤ 1</cell></row><row><cell>hf7</cell><cell>hasRelation(r1, r2, ) ⇒ hasResource( , r1) ∧ hasResource( , r2)</cell></row><row><cell>hf8</cell><cell>phraseIndex(p1, s1, e1) ∧ phraseIndex(p2, s2, e2) ∧ overlap(s1, e1, s2, e2) ∧</cell></row><row><cell></cell><cell>hasP hrase(p1) ⇒!hasP hrase(p2)</cell></row><row><cell>hf9</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,143.22,278.60,327.17,130.98"><head>Table 4 .</head><label>4</label><figDesc>Descriptions of weighted formulas.</figDesc><table coords="9,143.22,299.46,327.17,110.13"><row><cell>sf1</cell><cell cols="4">priorM atchScore(p, r, s) ⇒ hasP hrase(p)</cell></row><row><cell>sf2</cell><cell cols="4">priorM atchScore(p, r, s) ⇒ hasResource(p)</cell></row><row><cell>sf3</cell><cell cols="5">phraseP osT ag(p, pt+) ∧ resourceT ype(r, rt+) ⇒ hasResource(p, r)</cell></row><row><cell>sf4</cell><cell cols="5">phraseDepT ag(p1, p2, dp+) ∧ hasResource(p1, r1) ∧ hasResource(p2, r2)</cell><cell>⇒</cell></row><row><cell></cell><cell cols="2">hasRelation(r1, r2, rr+)</cell><cell></cell><cell></cell></row><row><cell>sf5</cell><cell cols="2">phraseDepT ag(p1, p2, dp+)</cell><cell>∧</cell><cell cols="2">hasResource(p1, r1)</cell><cell>∧</cell></row><row><cell></cell><cell>hasResource(p2, r2)</cell><cell>∧</cell><cell cols="3">!hasM eanW ord(p1, p2) ⇒ hasRelation(r1, r2, rr+)</cell></row><row><cell>sf6</cell><cell cols="5">phraseDepT ag(p1, p2, dp+) ∧ hasResource(p1, r1) ∧ hasResource(p2, r2) ∧</cell></row><row><cell></cell><cell cols="5">phraseDepOne(p1, p2) ⇒ hasRelation(r1, r2, rr+)</cell></row><row><cell>sf7</cell><cell cols="5">hasRelatedness(r1, r2, s) ∧ hasResource( , r1) ∧ hasResource( , r2)</cell><cell>⇒</cell></row><row><cell></cell><cell>hasRelation(r1, r2, )</cell><cell></cell><cell></cell><cell></cell></row><row><cell>sf8</cell><cell cols="4">hasQueryResult(r1, r2, r3, rr1, rr2)</cell><cell>⇒</cell><cell>hasRelation(r1, r2, rr1)</cell><cell>∧</cell></row><row><cell></cell><cell cols="2">hasRelation(r2, r3, rr2)</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="10,149.71,394.26,284.32,119.44"><head>Table 5 .</head><label>5</label><figDesc>Sample weights of formulas, corresponding with formula sf3.</figDesc><table coords="10,149.71,415.07,234.20,98.63"><row><cell cols="3">POS tag of Phrase type of mapped Item Weight</cell></row><row><cell>nn</cell><cell>Entity</cell><cell>2.11</cell></row><row><cell>nn</cell><cell>Class</cell><cell>0.243</cell></row><row><cell>nn</cell><cell>Property</cell><cell>0.335</cell></row><row><cell>vb</cell><cell>Property</cell><cell>0.517</cell></row><row><cell>wp</cell><cell>Class</cell><cell>0.143</cell></row><row><cell>wr</cell><cell>Class</cell><cell>0.025</cell></row><row><cell>Table</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="10,187.78,561.44,238.05,81.77"><head>Table 6 .</head><label>6</label><figDesc>Evaluate results on QALD-4 test dataset.</figDesc><table coords="10,187.78,582.18,238.05,61.04"><row><cell></cell><cell cols="7">Total Processed Right Partially Recall Precision F-measure</cell></row><row><cell>Xser</cell><cell>50</cell><cell>40</cell><cell>34</cell><cell>6</cell><cell>0.71</cell><cell>0.72</cell><cell>0.72</cell></row><row><cell>gAnswer</cell><cell>50</cell><cell>25</cell><cell>16</cell><cell>4</cell><cell>0.37</cell><cell>0.37</cell><cell>0.37</cell></row><row><cell>CASIA</cell><cell>50</cell><cell>26</cell><cell>15</cell><cell>4</cell><cell>0.40</cell><cell>0.32</cell><cell>0.36</cell></row><row><cell>Intui3</cell><cell>50</cell><cell>33</cell><cell>10</cell><cell>4</cell><cell>0.25</cell><cell>0.23</cell><cell>0.24</cell></row><row><cell>ISOFT</cell><cell>50</cell><cell>50</cell><cell>10</cell><cell>3</cell><cell>0.26</cell><cell>0.21</cell><cell>0.23</cell></row><row><cell>RO FII</cell><cell>50</cell><cell>50</cell><cell>6</cell><cell>0</cell><cell>0.12</cell><cell>0.12</cell><cell>0.12</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,635.81,335.86,8.12;2,144.73,646.77,335.85,8.12;2,144.73,658.08,135.57,7.77"><p>prefixes in semantic items indicate the source of its vocabularies, dbr indicate entity and dbo indicate class and property defined in the DBpedia ontology (http://wiki.dbpedia.org/Ontology39).</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,144.73,625.21,335.85,7.77;4,144.73,636.16,335.85,7.77;4,144.73,647.12,335.85,7.77;4,144.73,658.08,77.49,7.77"><p>We perform testing in two commonly used question corpus (QALD-3 Training data and free917) using Stanford CRF-based NER tool(http://nlp.stanford.edu/software/CRF-NER.shtml). The results demonstrate that merely 51.5% and 23.8% right NEs can be recognized, respectively.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="5,144.73,635.74,133.26,7.77"><p>https://code.google.com/p/word2vec/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="5,144.73,646.91,180.30,7.77"><p>The other marks will be introduced in Section 3.1.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="5,144.73,657.93,285.84,7.93"><p>corresponding the question "How many people live in the capital of Australia?"</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="6,144.73,647.12,335.85,7.77;6,144.73,658.08,196.44,7.77"><p>Actually, the dependency path tags are extracted from the phrases which mapped to semantic items. Here is simplified to illustrate how MLN works.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="7,144.73,635.74,119.61,7.77"><p>http://alchemy.cs.washington.edu</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7" coords="7,144.73,646.91,122.96,7.77"><p>http://hazy.cs.wisc.edu/hazy/tuffy/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8" coords="7,144.73,658.08,121.53,7.77"><p>http://code.google.com/p/thebeast</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_9" coords="8,144.73,657.80,265.48,8.06"><p>Set α to 0.6 for class, set α and β to 0.3 and 0.3 for property, respectively.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_10" coords="10,144.73,658.08,121.53,7.77"><p>http://code.google.com/p/thebeast</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="11,142.61,335.19,242.23,7.77;11,404.56,335.04,76.03,7.72;11,150.95,345.99,43.08,7.72;11,212.96,345.99,58.04,7.72;11,305.12,346.15,103.18,7.77" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,298.04,335.19,86.80,7.77">Linked data-the story so</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Heath</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Berners-Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,404.56,335.04,76.03,7.72;11,150.95,345.99,43.08,7.72;11,212.96,345.99,58.04,7.72">International journal on semantic and information</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,356.17,337.96,7.77;11,150.95,366.98,277.42,7.93" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,409.72,356.17,70.85,7.77;11,150.95,367.13,79.17,7.77">Dbpedia: A nucleus for a web of open data</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Kobilarov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Cyganiak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Ives</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,248.43,366.98,62.32,7.72">The semantic web</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="722" to="735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,377.15,337.96,7.77;11,150.95,387.96,279.52,7.93" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,382.15,377.15,98.42,7.77;11,150.95,388.11,200.91,7.77">Freebase: a collaboratively created graph database for structuring human knowledge</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Bollacker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Paritosh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sturge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,371.46,387.96,31.37,7.72">SIGMOD</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,398.14,337.96,7.77;11,150.95,408.94,47.06,7.93" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,329.40,398.14,132.76,7.77">Yago: a core of semantic knowledge</title>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,150.95,408.94,18.49,7.72">WWW</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,419.12,337.98,7.77;11,150.95,429.92,329.64,7.93;11,150.95,441.04,15.69,7.77" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,318.67,419.12,161.92,7.77;11,150.95,430.08,96.21,7.77">Evaluation of a layered approach to question answering over linked data</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Unger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cimiano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Bär</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,266.11,429.92,110.65,7.72">The Semantic Web-ISWC 2012</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="362" to="374" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,451.06,337.96,7.77;11,150.95,461.86,208.44,7.93" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,310.80,451.06,169.77,7.77;11,150.95,462.02,27.71,7.77">Is question answering fit for the semantic web?: a survey</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Uren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sabou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Motta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,188.07,461.86,48.12,7.72">Semantic Web</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="125" to="155" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,471.89,337.98,7.93;11,150.95,482.85,228.88,7.93" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,277.25,472.04,134.16,7.77">Poweraqua: Fishing the semantic web</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lopez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Motta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Uren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,431.72,471.89,48.87,7.72;11,150.95,482.85,111.84,7.72">The Semantic Web: research and applications</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="393" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,493.02,337.97,7.77;11,150.95,503.83,244.24,7.93" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="11,155.00,503.98,174.83,7.77">Template-based question answering over rdf data</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Unger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Bühmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A.-C</forename><surname>Ngonga Ngomo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Gerber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cimiano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,348.13,503.83,18.49,7.72">WWW</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.61,514.01,337.96,7.77;11,150.95,524.81,209.55,7.93" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,453.56,514.01,27.01,7.77;11,150.95,524.96,137.19,7.77">Natural language questions for the web of data</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Yahya</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Berberich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Elbassuoni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ramanath</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Tresp</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,306.46,524.81,26.36,7.72">EMNLP</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,534.83,338.35,7.93;11,150.95,545.95,85.92,7.77" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,278.52,534.99,81.44,7.77">Markov logic networks</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Domingos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,370.27,534.83,62.87,7.72">Machine learning</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="107" to="136" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,555.97,338.34,7.77;11,150.95,566.78,124.15,7.93" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="11,318.66,555.97,161.91,7.77;11,150.95,566.93,51.63,7.77">Patty: a taxonomy of relational patterns with semantic types</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Nakashole</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Weikum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Suchanek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,221.05,566.78,26.36,7.72">EMNLP</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,576.95,338.34,7.77;11,150.95,587.76,85.05,7.93" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,300.62,576.95,179.95,7.77;11,150.95,587.91,13.03,7.77">Identifying relations for open information extraction</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Soderland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Etzioni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,181.96,587.76,26.36,7.72">EMNLP</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,597.93,338.34,7.77;11,150.95,608.74,116.17,7.93" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,318.57,597.93,162.01,7.77;11,150.95,608.89,44.08,7.77">Semantic parsing on freebase from questionanswer pairs</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Berant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Frostig</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Liang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,213.07,608.74,26.36,7.72">EMNLP</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,618.92,338.34,7.77;11,150.95,629.87,20.17,7.77" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,191.77,618.92,257.68,7.77">Improving the accuracy and efficiency of map inference for markov logic</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Riedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,462.76,618.92,13.36,7.77">UAI</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,142.24,639.74,338.35,7.93;11,150.95,650.70,189.62,7.93" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,372.37,639.90,108.22,7.77;11,150.95,650.86,124.58,7.77">Generating typed dependency parses from phrase structure parses</title>
		<author>
			<persName coords=""><forename type="first">M.-C</forename><surname>De Marneffe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Maccartney</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,293.99,650.70,19.33,7.72">LREC</title>
		<imprint>
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
