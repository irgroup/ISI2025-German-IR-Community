<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,147.57,115.96,320.21,12.62;1,202.32,133.89,210.73,12.62">Results of the BioASQ Track of the Question Answering Lab at CLEF 2014</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,148.20,172.29,63.57,8.74"><forename type="first">George</forename><surname>Balikas</surname></persName>
						</author>
						<author>
							<persName coords="1,219.34,172.29,69.05,8.74"><forename type="first">Ioannis</forename><surname>Partalas</surname></persName>
						</author>
						<author>
							<persName coords="1,296.00,172.29,119.82,8.74"><forename type="first">Axel-Cyrille</forename><surname>Ngonga Ngomo</surname></persName>
						</author>
						<author>
							<persName coords="1,424.72,172.29,42.45,8.74;1,206.71,184.24,35.97,8.74"><forename type="first">Anastasia</forename><surname>Krithara</surname></persName>
						</author>
						<author>
							<persName coords="1,250.49,184.24,56.81,8.74"><forename type="first">Eric</forename><surname>Gaussier</surname></persName>
						</author>
						<author>
							<persName coords="1,334.44,184.24,74.22,8.74"><forename type="first">George</forename><surname>Paliouras</surname></persName>
						</author>
						<title level="a" type="main" coord="1,147.57,115.96,320.21,12.62;1,202.32,133.89,210.73,12.62">Results of the BioASQ Track of the Question Answering Lab at CLEF 2014</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0C5C39D7EB9B00A286231E141709E72F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The goal of this task is to push the research frontier towards hybrid information systems. We aim to promote systems and approaches that are able to deal with the whole diversity of the Web, especially for, but not restricted to, the context of bio-medicine. This goal is pursued by the organization of challenges. The second challenge consisted of two tasks: semantic indexing and question answering. 61 systems participated by 18 different participating teams for the semantic indexing task, of which between 25 and 45 participated in each batch. The semantic indexing task was tackled by 22 systems, which were developed by 8 different organizations. Between 15 and 19 of these systems addressed each batch. The question answering task was tackled by 18 different systems, developed by 7 different organizations. Between 9 and 15 of these systems submitted results in each batch. Overall, the best systems were able to outperform the strong baselines provided by the organizers.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The aim of this paper is twofold. First, we aim to give an overview of the data issued during the BioASQ track of the Question Answering Lab at CLEF 2014. In addition, we aim to present the systems that participated in the challenge and for which we received system descriptions. In particular, we aim to evaluate their performance w.r.t. to dedicated baseline systems. To achieve these goals, we begin by giving a brief overview of the tasks included in the track, including the timing of the different tasks and the challenge data. Thereafter, we give an overview of the systems which participated in the challenge and provided us with an overview of the technologies they relied upon. Detailed descriptions of some of the systems are given in lab proceedings. The evaluation of the systems, which was carried out by using state-of-the-art measures or manual assessment, is the last focal point of this paper. The conclusion sums up the results of the track.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Overview of the Tasks</head><p>The challenge comprised two tasks: (1) a large-scale semantic indexing task (Task 2a) and (2) a question answering task (Task 2b).</p><p>Large-scale semantic indexing. In Task 2a the goal is to classify documents from the PubMed<ref type="foot" coords="2,189.35,129.37,3.97,6.12" target="#foot_0">1</ref> digital library unto concepts of the MeSH<ref type="foot" coords="2,382.44,129.37,3.97,6.12" target="#foot_1">2</ref> hierarchy. Here, new PubMed articles that are not yet annotated are collected on a weekly basis. These articles are used as test sets for the evaluation of the participating systems. As soon as the annotations are available from the PubMed curators, the performance of each system is calculated by using standard information retrieval measures as well as hierarchical ones. The winners of each batch were decided based on their performance in the Micro F-measure (MiF) from the family of flat measures <ref type="bibr" coords="2,177.45,214.64,14.61,8.74" target="#b25">[23]</ref>, and the Lowest Common Ancestor F-measure (LCA-F) from the family of hierarchical measures <ref type="bibr" coords="2,271.92,226.59,9.96,8.74" target="#b11">[9]</ref>. For completeness several other flat and hierarchical measures were reported <ref type="bibr" coords="2,274.05,238.55,9.96,8.74" target="#b5">[3]</ref>. In order to provide an on-line and large-scale scenario, the task was divided into three independent batches. In each batch 5 test sets of biomedical articles were released consecutively. Each of these test sets were released in a weekly basis and the participants had 21 hours to provide their answers. Figure <ref type="figure" coords="2,229.74,286.37,4.98,8.74">1</ref> gives an overview of the time plan of Task 2a. Biomedical semantic QA. The goal of task 2b was to provide a large-scale question answering challenge where the systems should be able to cope with all the stages of a question answering task, including the retrieval of relevant concepts and articles, as well as the provision of natural-language answers. Task 2b comprised two phases: In phase A, BioASQ released questions in English from benchmark datasets created by a group of biomedical experts. There were four types of questions: "yes/no" questions, "factoid" questions,"list" questions and "summary" questions <ref type="bibr" coords="2,248.25,532.56,9.96,8.74" target="#b5">[3]</ref>. Participants had to respond with relevant concepts (from specific terminologies and ontologies), relevant articles (PubMed and Pub-MedCentral<ref type="foot" coords="2,186.27,554.90,3.97,6.12" target="#foot_2">3</ref> articles), relevant snippets extracted from the relevant articles and relevant RDF triples (from specific ontologies). In phase B, the released questions contained the correct answers for the required elements (concepts, articles, snippets and RDF triples) of the first phase. The participants had to answer with exact answers as well as with paragraph-sized summaries in natural language (dubbed ideal answers). The task was split into five independent batches. The two phases for each batch were run with a time gap of 24 hours. For each phase, the participants had 24 hours to submit their answers. We used well-known measures such as mean precision, mean recall, mean F-measure, mean average precision (MAP) and geometric MAP (GMAP) to evaluate the performance of the participants in Phase A. The winners were selected based on MAP. The evaluation in phase B was carried out manually by biomedical experts on the ideal answers provided by the systems. For the sake of completeness, ROUGE <ref type="bibr" coords="3,376.39,354.07,15.50,8.74" target="#b13">[11]</ref> is also reported.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Overview of Participants</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Task 2a</head><p>The participating systems in the semantic indexing task of the BioASQ challenge adopted a variety of approaches including hierarchical and flat algorithms as well as search-based approaches that relied on information retrieval techniques. In the rest of section we describe the proposed systems and stress their key characteristics.</p><p>The new NCBI system <ref type="bibr" coords="3,257.80,488.75,15.50,8.74">[26]</ref> for Task 2a is an extension of the work presented in 2013 and relies on the generic learning-to-rank approach presented in <ref type="bibr" coords="3,134.77,512.66,9.96,8.74" target="#b9">[7]</ref>. This novel approach, dubbed LAMBDA-MART, differs from the previous approach in the following aspects: First, the set of features has been extended to include binary classifier results. In addition, the set of documents used as neighbor documents was reduced to documents indexed after 2009. Moreover, the score function for the selection of the number of features was changed from a linear to a logarithmic approach. Overall, the novel approach achieves an Fmeasure between 0 (RDF triples) and 0.38 (concepts).</p><p>In <ref type="bibr" coords="3,162.47,596.34,15.50,8.74">[18]</ref> flat classification processes were employed for the semantic indexing task. In particular, the authors trained binary SVM classifiers for each label that was present in the data. In order to reduce the complexity they trained the SVMs in fractions of the data. They trained two systems on different corpus: Asclepios on 950 thousand documents and Hippocrates on 1.5 million. Those systems output a ranked lists with labels and a meta-model, namely MetaLabeler <ref type="bibr" coords="3,452.76,656.12,14.61,8.74" target="#b24">[22]</ref>, is used to decide the number of labels that will be submitted for each document. The remaining three systems of the team employ ensemble learning methods. The approach that worked best was a combination of Hippocrates with a model of simple binary SVMs, which were trained by changing the weights parameter for positive instances <ref type="bibr" coords="4,214.43,166.81,14.61,8.74" target="#b12">[10]</ref>. During the training of a classifier with very few positive instances they can chose to penalize a false negative (a positive instance being misclassified) more than a false positive (a negative instance being mis-classified). The proposed approaches, although they are relatively simple, require a lot of processing power and memory. For that reason they used a machine with 40 processors and 1TB RAM.</p><p>Ribadas et al. <ref type="bibr" coords="4,217.12,239.35,15.50,8.74">[20]</ref> employ hierarchical models based on a top-down hierarchical classification scheme <ref type="bibr" coords="4,268.32,251.30,15.50,8.74" target="#b23">[21]</ref> and a Bayesian network which models the hierarchical relations among the labels as well as the training data. The team participated in the first edition of the BioASQ challenge using the same technologies <ref type="bibr" coords="4,172.92,287.17,14.61,8.74" target="#b21">[19]</ref>. In the current competition they focused on the pre-processing of the textual data while keeping the same classification models. More specifically, the authors employ techniques for identifying abbreviations in the text and expanding it afterwards in order to enrich the document. Also, a part of speech tagger is used in order to tokenize the text and identify noun, verbs, adjectives and unknown elements (not identified). Finally, a lemmatization step extracts the canonical forms of those words. Additionally, the authors extract word bigrams and keep only those that are identified as multiword terms. The rational is that multiword terms in a domain with complex terminology, like biomedicine, provide higher discriminant power.</p><p>In <ref type="bibr" coords="4,162.33,407.52,10.52,8.74" target="#b7">[5]</ref> the authors use a standard flat classification scheme, where a SVM is trained for each class label in MeSH. Different training set methodologies are used resulting in different trained classifiers. Due to computational issues only 50,000 documents were used for training. The selection of the best classification scheme is optimized on the precision at top k labels on a validation set.</p><p>In <ref type="bibr" coords="4,162.74,468.10,15.50,8.74" target="#b15">[13]</ref> the authors used the learning to rank (LTR) method for predicting MeSH headings. However, in addition to the information from similar citations, they also used the prediction scores from individual MeSH classifiers to improve the prediction accuracy. In particular, they trained a binary classifier (logistic regression) for each label (MeSH heading). For a target citation, using the trained classifiers, they calculated the annotation probability (score) of every MeSH heading. Then, using NCBI efetch<ref type="foot" coords="4,319.45,538.26,3.97,6.12" target="#foot_3">4</ref> ,they retrieved similar citations for the neighbor scores. Finally, these two scores, together with the default results of NLM official solution MTI, were considered as features in the LTR framework. The LambdaMART <ref type="bibr" coords="4,224.38,575.70,10.52,8.74" target="#b6">[4]</ref> was used as the ranking method in the learning to rank framework.</p><p>In <ref type="bibr" coords="4,161.95,600.41,9.96,8.74" target="#b3">[1]</ref>, they proposed a system which uses Latent Semantic Analysis to identify semantically similar documents in MEDLINE and then constructs a list of MeSH headers from candidates selected from the documents most similar to a new abstract.</p><p>Table <ref type="table" coords="5,176.62,118.99,4.98,8.74" target="#tab_0">1</ref> resumes the principal technologies that were employed by the participating systems and whether a hierarchical or a flat approach has been followed. flat Ensemble Learning, SVMs <ref type="bibr" coords="5,134.77,214.76,12.45,6.12" target="#b21">[19]</ref> hierarchical SVMs, Bayes networks <ref type="bibr" coords="5,134.77,222.73,12.45,6.12" target="#b29">[27]</ref> flat MetaMap <ref type="bibr" coords="5,335.22,222.73,8.05,6.12" target="#b4">[2]</ref>, information retrieval, search engines <ref type="bibr" coords="5,134.77,230.70,12.45,6.12" target="#b16">[14]</ref> flat k-NN, SVMs <ref type="bibr" coords="5,134.77,238.67,12.45,6.12" target="#b17">[15]</ref> flat k-NN, learning-to-rank <ref type="bibr" coords="5,134.77,246.64,12.45,6.12" target="#b15">[13]</ref> flat Logistic regression, learning-to-rank <ref type="bibr" coords="5,134.77,254.61,8.48,6.12" target="#b3">[1]</ref> flat LSA <ref type="bibr" coords="5,134.77,262.58,12.45,6.12">[26]</ref> flat Learning-to-rank</p><p>Baselines. During the first challenge two systems were served as baseline systems. The first one, dubbed BioASQ Baseline, follows an unsupervised approach to tackle the problem and so it is expected that the systems developed by the participants will outperform it. The second baseline is a state-of-theart method called Medical Text Indexer <ref type="bibr" coords="5,312.80,359.37,10.52,8.74" target="#b10">[8]</ref> which is developed by the National Library of Medicine<ref type="foot" coords="5,221.67,369.75,3.97,6.12" target="#foot_4">5</ref> and serves as a classification system for articles of MED-LINE. MTI is used by curators in order to assist them in the annotation process.</p><p>The new annotator is an extension of the system presented in <ref type="bibr" coords="5,407.95,395.23,15.50,8.74" target="#b18">[16]</ref> with the approaches of the last year's winner <ref type="bibr" coords="5,285.92,407.19,14.61,8.74" target="#b26">[24]</ref>. Consequently, we expected the baseline to difficult to beat.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Task 2b</head><p>As mentioned above, the second task of the challenge is split into two phases. In the first phase, where the goal is to annotate questions with relevant concepts, documents, snippets and RDF triples 8 teams with 22 systems participated. In the second phase, where team are requested to submit exact and paragraph-sized answers for the questions, 7 teams with 18 different systems participated.</p><p>The system presented in <ref type="bibr" coords="5,256.95,529.57,15.50,8.74" target="#b19">[17]</ref> relies on the Hana Database for text processing. It uses the Stanford CoreNLP package for tokenizing the questions. Each of the token is then sent to the BioPortal and to the Hana database for concept retrieval. The concepts retrieved from the two stores are finally merged to a single list that is used to retrieve relevant text passages from the documents at hand. To this end, four different types of queries are sent to the BioASQ services. Overall, the approach achieves between 0.18 and 0.23 F-measure.</p><p>The approach proposed by NCBI <ref type="bibr" coords="5,294.63,613.33,15.50,8.74">[26]</ref> for Task 2b can be used in combination with the approach by the same group for Task 2a. In phase A, NCBI's framework used the cosine similarity between question and sentence to compute their similarity. The best scoring sentence from an abstract was chosen as relevant snippet for an answer. Concept recognition was achieved by a customized dictionary lookup algorithm in combination with MetaMap. For phase B, tailored approaches were used depending on the question types. For example, a manual set of rules was crafted to determine the answers to factoid and list questions based on the benchmark data for 2013. The system achieved an F-measure of up to betwen 0.2% (RDf triples) and 38.48% (concepts). It performed very well on Yes/No questions (up to 100% accuracy). Factoid and list questions led to an MRR of up to 20.57%.</p><p>In <ref type="bibr" coords="6,161.69,227.98,10.52,8.74" target="#b7">[5]</ref> the authors participated only in the document retrieval of phase A and in the generation of ideal answers in phase B. The Indri search engine is used to index the PubMed articles and different models are used to retrieve documents like pseudo-relevance feedback, sequential dependence model and semantic concept-enriched dependence model where the recognised UMLS concepts in the query are used as additional dependence features for ranking documents. For the generation of ideal answers the authors retrieve sentences from documents and identify the common keywords. Then the sentences are ranked according to the number of times these keywords appear in each of them and finally the top ranked m are used to form the ideal answer.</p><p>The authors of <ref type="bibr" coords="6,216.52,348.92,15.50,8.74" target="#b14">[12]</ref> propose a method for the retrieval of relevant documents and snippets of task 2b. They develop a figure-inspired text retrieval method as a way of retrieving documents and text passages from biomedical publications. The method is based on the insight that for biomedical publications, the figures play an important role to the point that the captions can be used to provide abstract like summaries. The proposed approach uses an Information Retrieval perspective on the problem. In principle, the followed steps are: (i) the question in enriched by query expansion with information from UMLS, Wikipedia, and Figures, (ii) a ranking of full documents and snippets is retrieved from a corpus of PubMed Central Articles which is the set of full-text available articles, (iii) features are extracted for each document and snippet that provide proof of its relevance for the question and (iv) the documents/snippets are re-ranked with a learning-to-rank approach.</p><p>In the context of phase B of task 2b in <ref type="bibr" coords="6,313.02,505.72,14.61,8.74">[18]</ref>, the authors attempted to replicate the work that already exists in literature and was presented in the BioASQ 2013 workshop <ref type="bibr" coords="6,178.46,529.63,14.61,8.74" target="#b27">[25]</ref>. They provided exact answers only for the factoid questions. Their system tries to extract the lexical answer type by manipulating the words of the question. Then, the relevant snippets of the question which are provided as inputs for this tasks are processed with the 2013 release of MetaMap <ref type="bibr" coords="6,433.27,565.50,10.52,8.74" target="#b4">[2]</ref> in order to extract candidate answers.</p><p>Baselines. Two baselines were used in phase A. The systems return the list of the top-50 and the top-100 entities respectively that may be retrieved using the keywords of the input question as a query to the BioASQ services. As a result, two lists for each of the main entities (concepts, documents, snippets, triples) are produced, of a maximum length of 50 and 100 items respectively.</p><p>For the creation of a baseline approach in Task 2B Phase B, three approaches were created that address respectively the answering of factoid and lists questions, summary questions, and yes/no questions <ref type="bibr" coords="7,344.01,142.90,14.61,8.74" target="#b27">[25]</ref>. The three approaches were combined into one system, and they constitute the BioASQ baseline for this phase of Task 2B. The baseline approach for the list/factoid questions utilizes and ensembles a set of scoring schemes that attempt to prioritize the concepts that answer the question by assuming that the type of the answer aligns with the lexical answer type (type coercion). The baseline approach for the summary questions introduces a multi-document summarization method using Integer Linear Programming and Support Vector Regression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Task 2a</head><p>During the evaluation phase of the Task 2a, the participants submitted their results on a weekly basis to the online evaluation platform of the challenge<ref type="foot" coords="7,452.84,312.72,3.97,6.12" target="#foot_5">6</ref> . The evaluation period was divided into three batches containing 5 test sets each. 18 teams were participated in the task with a total of 61 systems. 12,628,968 articles with 26,831 labels (20.31GB) were provided as training data to the participants. Table <ref type="table" coords="7,205.75,362.12,4.98,8.74" target="#tab_1">2</ref> shows the number of articles in each test set of each batch of the challenge.  Table <ref type="table" coords="8,177.53,228.76,4.98,8.74" target="#tab_2">3</ref> presents the correspondence of the systems for which a description was available and the submitted systems in Task 2a. The systems MTIFL, MTI-Default and BioASQ Baseline were the baseline systems used throughout the challenge. MTIFL and MTI-Default refer to the NLM Medical Text Indexer system <ref type="bibr" coords="8,167.80,276.58,14.61,8.74" target="#b18">[16]</ref>. Systems that participated in less than 4 test sets in each batch are not reported in the results <ref type="foot" coords="8,249.81,286.96,3.97,6.12" target="#foot_6">7</ref> .</p><p>According to <ref type="bibr" coords="8,209.37,300.63,10.52,8.74" target="#b8">[6]</ref> the appropriate way to compare multiple classification systems over multiple datasets is based on their average rank across all the datasets. On each dataset the system with the best performance gets rank 1.0, the second best rank 2.0 and so on. In case that two or more systems tie, they all receive the average rank. Tables 4 presents the average rank (according to MiF and LCA-F) of each system over all the test sets for the corresponding batches. Note, that the average ranks are calculated for the 4 best results of each system in the batch according to the rules of the challenge<ref type="foot" coords="8,302.47,382.74,3.97,6.12" target="#foot_7">8</ref> . The best ranked system is highlighted with bold typeface.</p><p>First, we can observe that several systems outperforms the strong MTI baseline in terms of MiF and LCA measures exhibiting state-of-the-art performances. During the first batch the flat classification approach (Asclepius system) used in <ref type="bibr" coords="8,134.77,444.22,14.61,8.74">[18]</ref>. In the other two batches the learning-to-rank systems proposed by NCBI (L2R systems) and the Fudan University (Antinomyra systems) ranked as the best performed ones occupying the first two places in both measures.</p><p>According to the available descriptions the only systems that made of use of the MeSH hierarchy were the ones introduced by <ref type="bibr" coords="8,346.29,492.18,14.61,8.74" target="#b21">[19]</ref>. The top-down hierarchical systems, cole hce1, cole hce2 and cole hce ne achieved mediocre results. while the utai rebayct systems had poor performances. For the systems based on a Bayesian network this behavior was expected as they cannot scale well to large problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Task 2b</head><p>Phase A. Table <ref type="table" coords="8,207.44,591.17,4.98,8.74" target="#tab_4">5</ref> presents the statistics of the training and test data provided to the participants. The evaluation included five test batches. For the phase A of Task 2b the systems were allowed to submit responses to any of the corresponding Table <ref type="table" coords="9,164.52,115.91,4.13,7.89">4</ref>. Average ranks for each system across the batches of the challenge for the measures MiF and LCA-F. A hyphenation symbol (-) is used whenever the system participated in less than 4 times in the batch. types of annotations, that is documents, concepts, snippets and RDF triples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>System</head><p>For each of the categories we rank the systems according to the Mean Average Precision (MAP) measure <ref type="bibr" coords="9,251.68,644.16,9.96,8.74" target="#b5">[3]</ref>. The final ranking for each batch is calculated as the average of the individual rankings in the different categories. The detailed results for Task 2b phase A can be found in http://bioasq.lip6.fr/results/ 2b/phaseA/. Focusing on the specific categories, (e.g., concepts or documents) for the Wishart system we observe that it achieves a balanced behavior with respect to the baselines (Table <ref type="table" coords="10,241.89,323.27,4.98,8.74" target="#tab_6">7</ref> and<ref type="table" coords="10,272.01,323.27,32.49,8.74" target="#tab_5">Table 6</ref>). This is evident from the value of Fmeasure which is much higher that the values of the two baselines. This can be explained on the fact that the Wishart-S1 system responded with short lists while the baselines return always long lists (50 and 100 items respectively). Similar observations hold also for the other four batches, the results of which are available online. Phase B. In the phase B of Task 2b the systems were asked to report exact and ideal answers. The systems were ranked according to the manual evaluation of ideal answers by the BioASQ experts <ref type="bibr" coords="10,299.33,644.16,9.96,8.74" target="#b5">[3]</ref>. For reasons of completeness we report also the results of the systems for the exact answers. Table <ref type="table" coords="11,177.98,234.61,4.98,8.74" target="#tab_7">8</ref> shows the results for the exact answers for the first batch of task 2a. In case that systems didn't provide exact answers for a particular kind of questions we used the symbol "-". The results of the other batches are available at http://bioasq.lip6.fr/results/2b/phaseB/. From those results we can see that the systems are achieving a very high (&gt; 90% accuracy) performance in the yes/no questions. The performance in factoid and list questions is not as good indicating that there is room for improvements. Again, the system of Wishart (Wishart-S3) for example shows consistent performance as it manages to answer relatively well in all kinds of questions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>The participation to the second BioASQ challenge signalizes an uptake of the significance of biomedical question answering in the research community. We monitored an increased participation of both Tasks 2a and 2b. The baseline that we used this year in Task 2a incorporated techniques from last year's winning system. Although we had more data and thus more possible sources of errors (but also more training data), the best system in the first challenge clearly outperformed the baseline. This suggest an improvement of large-scale classification systems over the last year. The results achieved in Task 2b also suggest that the state of the art was pushed a step further. Consequently, we regard the outcome of the challenge as a success towards pushing the research on bio-medical information systems a step further. In future editions of the challenge, we aim to provide even more benchmark data derived from a community-driven acquisition process.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,239.82,406.67,135.71,7.89"><head>F e b r u a r y 4 MFig. 1 .</head><label>41</label><figDesc>Fig. 1. The time plan of Task 2a.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="3,134.77,225.97,345.81,7.89;3,134.77,236.95,20.52,7.86"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. The time plan of Task 2b. The two phases for each batch run in consecutive days.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,134.77,162.60,284.65,50.31"><head>Table 1 .</head><label>1</label><figDesc>Technologies used by participants in Task 2a.</figDesc><table coords="5,134.77,185.83,248.88,27.08"><row><cell>Reference</cell><cell>Approach</cell><cell>Technologies</cell></row><row><cell>[18]</cell><cell>flat</cell><cell>SVMs, MetaLabeler [22]</cell></row><row><cell>[18]</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,137.45,405.57,341.76,213.47"><head>Table 2 .</head><label>2</label><figDesc>Statistics on the test datasets of Task 2a.</figDesc><table coords="7,137.45,427.06,341.76,191.99"><row><cell>Batch</cell><cell>Articles</cell><cell>Annotated Articles</cell><cell>Labels per article</cell></row><row><cell>1</cell><cell>4,440</cell><cell>3,263</cell><cell>13.20</cell></row><row><cell></cell><cell>4,721</cell><cell>3,716</cell><cell>13.13</cell></row><row><cell></cell><cell>4,802</cell><cell>3,783</cell><cell>13.32</cell></row><row><cell></cell><cell>3,579</cell><cell>2,341</cell><cell>13.02</cell></row><row><cell></cell><cell>5,299</cell><cell>3,619</cell><cell>13.07</cell></row><row><cell>Subtotal</cell><cell>23,321</cell><cell>16,722</cell><cell>13.15</cell></row><row><cell>2</cell><cell>4,085</cell><cell>3,322</cell><cell>13.05</cell></row><row><cell></cell><cell>3,496</cell><cell>2,752</cell><cell>12.28</cell></row><row><cell></cell><cell>4,524</cell><cell>3,265</cell><cell>12.90</cell></row><row><cell></cell><cell>5,407</cell><cell>3,848</cell><cell>13.23</cell></row><row><cell></cell><cell>5,454</cell><cell>3,642</cell><cell>13.58</cell></row><row><cell>Subtotal</cell><cell>22,966</cell><cell>16,829</cell><cell>13.01</cell></row><row><cell>3</cell><cell>4,342</cell><cell>2,996</cell><cell>12.71</cell></row><row><cell></cell><cell>8,840</cell><cell>5,783</cell><cell>13.37</cell></row><row><cell></cell><cell>3,702</cell><cell>2,737</cell><cell>13.32</cell></row><row><cell></cell><cell>4,726</cell><cell>3,225</cell><cell>13.90</cell></row><row><cell></cell><cell>4,533</cell><cell>3,196</cell><cell>12.70</cell></row><row><cell>Subtotal</cell><cell>26,143</cell><cell>17,929</cell><cell>13.20</cell></row><row><cell>Total</cell><cell>72,430</cell><cell>51,480</cell><cell>13.12</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,157.69,115.91,299.97,7.89"><head>Table 3 .</head><label>3</label><figDesc>Correspondence of reference and submitted systems for Task 2a.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="10,134.77,163.08,345.81,106.76"><head>Table 5 .</head><label>5</label><figDesc>Statistics on the training and test datasets of Task 2b. All the numbers for the documents, snippets, concepts and triples refer to averages.</figDesc><table coords="10,169.26,197.27,274.16,72.57"><row><cell cols="6">Batch Size # of documents # of snippets # of concepts # of triples</cell></row><row><cell cols="2">training 310</cell><cell>14.28</cell><cell>18.70</cell><cell>7.11</cell><cell>9.00</cell></row><row><cell>1</cell><cell>100</cell><cell>7.89</cell><cell>9.64</cell><cell>6.50</cell><cell>24.48</cell></row><row><cell>2</cell><cell>100</cell><cell>11.69</cell><cell>14.71</cell><cell>4.24</cell><cell>204.85</cell></row><row><cell>3</cell><cell>100</cell><cell>8.66</cell><cell>10.80</cell><cell>5.09</cell><cell>354.44</cell></row><row><cell>4</cell><cell>100</cell><cell>12.25</cell><cell>14.58</cell><cell>5.18</cell><cell>58.70</cell></row><row><cell>5</cell><cell>100</cell><cell>11.07</cell><cell>13.18</cell><cell>5.07</cell><cell>271.68</cell></row><row><cell cols="2">total 810</cell><cell>11.83</cell><cell>14.92</cell><cell>5.93</cell><cell>116.30 9</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="10,134.77,412.96,344.44,161.89"><head>Table 6 .</head><label>6</label><figDesc>Results for batch 1 for documents in phase A of Task2b.</figDesc><table coords="10,134.77,436.19,344.44,138.66"><row><cell>System</cell><cell>Mean</cell><cell>Mean</cell><cell>Mean</cell><cell>MAP</cell><cell>GMAP</cell></row><row><cell></cell><cell>Precision</cell><cell>Recall</cell><cell>F-measure</cell><cell></cell><cell></cell></row><row><cell>SNUMedinfo1</cell><cell>0.0457</cell><cell>0.5958</cell><cell>0.0826</cell><cell>0.2612</cell><cell>0.0520</cell></row><row><cell>SNUMedinfo3</cell><cell>0.0457</cell><cell>0.5947</cell><cell>0.0826</cell><cell>0.2587</cell><cell>0.0501</cell></row><row><cell>SNUMedinfo2</cell><cell>0.0451</cell><cell>0.5862</cell><cell>0.0815</cell><cell>0.2547</cell><cell>0.0461</cell></row><row><cell>SNUMedinfo4</cell><cell>0.0457</cell><cell>0.5941</cell><cell>0.0826</cell><cell>0.2493</cell><cell>0.0468</cell></row><row><cell>SNUMedinfo5</cell><cell>0.0459</cell><cell>0.5947</cell><cell>0.0829</cell><cell>0.2410</cell><cell>0.0449</cell></row><row><cell>Top 100 Baseline</cell><cell>0.2274</cell><cell>0.4342</cell><cell>0.2280</cell><cell>0.1911</cell><cell>0.0070</cell></row><row><cell>Top 50 Baseline</cell><cell>0.2290</cell><cell>0.3998</cell><cell>0.2296</cell><cell>0.1888</cell><cell>0.0059</cell></row><row><cell>main system</cell><cell>0.0413</cell><cell>0.2625</cell><cell>0.0678</cell><cell>0.1168</cell><cell>0.0015</cell></row><row><cell>Biomedical Text Ming</cell><cell>0.2279</cell><cell>0.2068</cell><cell>0.1665</cell><cell>0.1101</cell><cell>0.0014</cell></row><row><cell>Wishart-S2</cell><cell>0.1040</cell><cell>0.1210</cell><cell>0.0793</cell><cell>0.0591</cell><cell>0.0002</cell></row><row><cell>Wishart-S1</cell><cell>0.1121</cell><cell>0.1077</cell><cell>0.0806</cell><cell>0.0535</cell><cell>0.0002</cell></row><row><cell>UMass-irSDM</cell><cell>0.0185</cell><cell>0.0499</cell><cell>0.0250</cell><cell>0.0256</cell><cell>0.0001</cell></row><row><cell>Doc-Figdoc-UMLS</cell><cell>0.0185</cell><cell>0.0499</cell><cell>0.0250</cell><cell>0.0054</cell><cell>0.0001</cell></row><row><cell>All-Figdoc-UMLS</cell><cell>0.0185</cell><cell>0.0499</cell><cell>0.0250</cell><cell>0.0047</cell><cell>0.0001</cell></row><row><cell>All-Figdoc</cell><cell>0.0175</cell><cell>0.0474</cell><cell>0.0236</cell><cell>0.0043</cell><cell>0.0001</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="11,134.77,115.91,344.44,90.16"><head>Table 7 .</head><label>7</label><figDesc>Results for batch 1 for concepts in phase A of Task2b.</figDesc><table coords="11,134.77,139.14,344.44,66.93"><row><cell>System</cell><cell>Mean</cell><cell>Mean</cell><cell>Mean</cell><cell>MAP</cell><cell>GMAP</cell></row><row><cell></cell><cell>Precision</cell><cell>Recall</cell><cell>F-measure</cell><cell></cell><cell></cell></row><row><cell>Wishart-S1</cell><cell>0.4759</cell><cell>0.5421</cell><cell>0.4495</cell><cell>0.6752</cell><cell>0.1863</cell></row><row><cell>Wishart-S2</cell><cell>0.4759</cell><cell>0.5421</cell><cell>0.4495</cell><cell>0.6752</cell><cell>0.1863</cell></row><row><cell>Top 100 Baseline</cell><cell>0.0523</cell><cell>0.8728</cell><cell>0.0932</cell><cell>0.5434</cell><cell>0.3657</cell></row><row><cell>Top 50 Baseline</cell><cell>0.0873</cell><cell>0.8269</cell><cell>0.1481</cell><cell>0.5389</cell><cell>0.3308</cell></row><row><cell>main system</cell><cell>0.4062</cell><cell>0.5593</cell><cell>0.4018</cell><cell>0.4006</cell><cell>0.1132</cell></row><row><cell>Biomedical Text Ming</cell><cell>0.1250</cell><cell>0.0929</cell><cell>0.0950</cell><cell>0.0368</cell><cell>0.0002</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="11,134.77,360.82,344.44,106.10"><head>Table 8 .</head><label>8</label><figDesc>Results for batch 1 for concepts in phase A of Task2b.</figDesc><table coords="11,134.77,384.05,344.44,82.87"><row><cell>System</cell><cell>Yes/no</cell><cell></cell><cell>Factoid</cell><cell></cell><cell></cell><cell>List</cell><cell></cell></row><row><cell></cell><cell cols="7">Accuracy Strict Acc. Lenient Acc. MRR Precision Recall F-measure</cell></row><row><cell>Biomedical Text Ming</cell><cell>0.9375</cell><cell>0.1852</cell><cell>0.1852</cell><cell>0.1852</cell><cell>0.0618</cell><cell>0.0929</cell><cell>0.0723</cell></row><row><cell>system 2</cell><cell>0.9375</cell><cell>0.0370</cell><cell>0.1481</cell><cell>0.0926</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>system 3</cell><cell>0.9375</cell><cell>0.0370</cell><cell>0.1481</cell><cell>0.0926</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>Wishart-S3</cell><cell>0.8438</cell><cell>0.4074</cell><cell>0.4444</cell><cell>0.4259</cell><cell>0.4836</cell><cell>0.3619</cell><cell>0.3796</cell></row><row><cell>Wishart-S2</cell><cell>0.8438</cell><cell>0.4074</cell><cell>0.4444</cell><cell>0.4259</cell><cell>0.5156</cell><cell>0.3619</cell><cell>0.3912</cell></row><row><cell>main system</cell><cell>0.5938</cell><cell>0.0370</cell><cell>0.1481</cell><cell>0.0926</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>BioASQ Baseline</cell><cell>0.5313</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.0351</cell><cell>0.0844</cell><cell>0.0454</cell></row><row><cell>BioASQ Baseline 2</cell><cell>0.5000</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>0.0351</cell><cell>0.0844</cell><cell>0.0454</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,635.53,164.75,7.47"><p>http://www.ncbi.nlm.nih.gov/pubmed/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,144.73,646.48,155.34,7.47"><p>http://www.ncbi.nlm.nih.gov/mesh/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,144.73,657.44,150.63,7.47"><p>http://www.ncbi.nlm.nih.gov/pmc/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,144.73,656.80,198.81,7.86"><p>http://www.ncbi.nlm.nih.gov/books/NBK25499/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="5,144.73,656.80,157.99,7.86"><p>http://ii.nlm.nih.gov/MTI/index.shtml</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="7,144.73,657.44,98.85,7.47"><p>http://bioasq.lip6.fr</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="8,144.73,634.88,335.85,7.86;8,144.73,645.84,207.09,7.86"><p>According to the rules of BioASQ, each system had to participate in at least 4 test sets of a batch in order to be eligible for the prizes.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7" coords="8,144.73,656.80,201.61,7.86"><p>http://bioasq.lip6.fr/general information/Task1a/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,227.20,152.14,114.39,6.12" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="8,311.45,152.14,30.14,6.12">Sisyphus</title>
		<author>
			<persName coords=""><forename type="first">Hippocrates</forename><surname>Asclepius</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="8,227.20,160.11,212.81,6.12" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="8,227.20,160.11,205.97,6.12">cole hce1, cole hce2, cole hce ne, utai rebayct, utai rebayct</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,227.20,184.02,18.65,6.12;8,134.77,191.99,31.85,6.12;8,227.20,191.99,132.17,6.12;12,134.77,163.30,62.93,10.52" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="8,257.94,191.99,101.43,6.12;12,134.77,163.30,62.93,10.52">MTI-Default, bioasq baseline References</title>
		<author>
			<persName coords=""><forename type="first">Mtifl</forename><surname>L2r* Baselines</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,190.17,241.82,7.86;12,151.52,201.50,329.05,7.86;12,151.52,212.46,224.17,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,317.87,190.17,66.91,7.86;12,151.52,201.50,308.23,7.86">Automatic classi cation of pubmed abstracts with latent semantic indexing: Working notes</title>
		<author>
			<persName coords=""><forename type="first">Joel</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adams</forename></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steven</forename><surname>Bedrick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,151.52,212.46,194.67,7.86">Proceedings of Question Answering Lab at CLEF</title>
		<meeting>Question Answering Lab at CLEF</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,223.79,337.62,7.86;12,151.52,234.75,329.06,7.86;12,151.52,245.71,122.40,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,333.62,223.79,146.95,7.86;12,151.52,234.75,130.71,7.86">An overview of MetaMap: historical perspective and recent advances</title>
		<author>
			<persName coords=""><forename type="first">Alan</forename><forename type="middle">R</forename><surname>Aronson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Franois-Michel</forename><surname>Lang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,293.76,234.75,186.82,7.86;12,151.52,245.71,44.63,7.86">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="229" to="236" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,257.04,337.62,7.86;12,151.52,268.00,329.06,7.86;12,151.52,278.96,329.05,7.86;12,151.52,289.92,220.75,7.86" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="12,387.93,278.96,92.65,7.86;12,151.52,289.92,53.32,7.86">Evaluation Framework Specifications</title>
		<author>
			<persName coords=""><forename type="first">Georgios</forename><surname>Balikas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ioannis</forename><surname>Partalas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aris</forename><surname>Kosmopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sergios</forename><surname>Petridis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Prodromos</forename><surname>Malakasiotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ioannis</forename><surname>Pavlopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ion</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nicolas</forename><surname>Baskiotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eric</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thierry</forename><surname>Artieres</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Patrick</forename><surname>Gallinari</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="5" to="2013" />
		</imprint>
	</monogr>
	<note>Project deliverable D4</note>
</biblStruct>

<biblStruct coords="12,142.96,301.25,337.62,7.86;12,151.52,312.21,232.98,7.86" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="12,267.85,301.25,212.72,7.86;12,151.52,312.21,33.25,7.86">From ranknet to lambdarank to lambdamart: An overview</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">C</forename><surname>Christopher</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Burges</surname></persName>
		</author>
		<idno>MSR-TR-2010-82</idno>
		<imprint>
			<date type="published" when="2010-06">June 2010</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="12,142.96,323.54,337.62,7.86;12,151.52,334.50,329.06,7.86;12,151.52,345.46,125.13,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="12,296.36,323.54,184.22,7.86;12,151.52,334.50,206.21,7.86">Classification and retrieval of biomedical literatures: Snumedinfo at clef qa track bioasq 2014</title>
		<author>
			<persName coords=""><forename type="first">Sungbin</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jinwook</forename><surname>Choi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,382.54,334.50,98.05,7.86;12,151.52,345.46,95.63,7.86">Proceedings of Question Answering Lab at CLEF</title>
		<meeting>Question Answering Lab at CLEF</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,356.79,337.62,7.86;12,151.52,367.75,213.39,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,220.04,356.79,256.74,7.86">Statistical Comparisons of Classifiers over Multiple Data Sets</title>
		<author>
			<persName coords=""><forename type="first">Janez</forename><surname>Demsar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,151.52,367.75,153.92,7.86">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="30" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,379.09,337.62,7.86;12,151.52,390.04,236.70,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="12,338.35,379.09,142.23,7.86;12,151.52,390.04,110.77,7.86">Recommending mesh terms for annotating biomedical articles</title>
		<author>
			<persName coords=""><forename type="first">Minlie</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aurlie</forename><surname>Nvol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhiyong</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,269.85,390.04,27.39,7.86">JAMIA</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="660" to="667" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,401.38,337.62,7.86;12,151.52,412.34,329.07,7.86;12,151.52,423.30,125.12,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="12,466.62,401.38,13.95,7.86;12,151.52,412.34,209.97,7.86">Recent enhancements to the nlm medical text indexer</title>
		<author>
			<persName coords=""><forename type="first">Susan</forename><forename type="middle">C</forename><surname>Schmidt Alan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">Aronson</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Mork</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dina</forename><surname>Demner-Fushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,383.66,412.34,96.93,7.86;12,151.52,423.30,95.63,7.86">Proceedings of Question Answering Lab at CLEF</title>
		<meeting>Question Answering Lab at CLEF</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.96,434.63,337.62,7.86;12,151.52,445.59,329.06,7.86;12,151.52,456.55,228.34,7.86" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="12,229.13,445.59,251.45,7.86;12,151.52,456.55,105.63,7.86">Evaluation Measures for Hierarchical Classification: a unified view and novel approaches</title>
		<author>
			<persName coords=""><forename type="first">Aris</forename><surname>Kosmopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ioannis</forename><surname>Partalas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eric</forename><surname>Gaussier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Georgios</forename><surname>Paliouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ion</forename><surname>Androutsopoulos</surname></persName>
		</author>
		<idno>CoRR, abs/1306.6802</idno>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,467.88,337.96,7.86;12,151.52,478.84,285.28,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,244.62,467.88,235.96,7.86;12,151.52,478.84,31.26,7.86">Rcv1: A new benchmark collection for text categorization research</title>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">D</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,190.78,478.84,172.73,7.86">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="361" to="397" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,490.17,337.97,7.86;12,151.52,501.13,329.06,7.86;12,151.52,512.09,109.45,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,217.62,490.17,243.27,7.86">ROUGE: A package for automatic evaluation of summaries</title>
		<author>
			<persName coords=""><forename type="first">Chin-Yew</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,151.52,501.13,278.57,7.86">Proceedings of the ACL workshop &apos;Text Summarization Branches Out</title>
		<meeting>the ACL workshop &apos;Text Summarization Branches Out<address><addrLine>Barcelona, Spain</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="74" to="81" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,523.42,337.96,7.86;12,151.52,534.38,329.06,7.86;12,151.52,545.34,157.54,7.86" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="12,287.93,523.42,192.64,7.86;12,151.52,534.38,24.44,7.86">UMass at BioASQ 2014: Figure-inspired text retrieval</title>
		<author>
			<persName coords=""><forename type="first">Jessa</forename><surname>Lingeman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Laura</forename><surname>Dietz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,194.37,534.38,286.20,7.86;12,151.52,545.34,129.21,7.86">2nd BioASQ Workshop: A challenge on large-scale biomedical semantic indexing and question answering</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,556.67,337.96,7.86;12,151.52,567.63,329.06,7.86;12,151.52,578.59,235.69,7.86" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="12,464.70,556.67,15.87,7.86;12,151.52,567.63,324.77,7.86">The fudan-uiuc participation in the bioasq challenge task 2a: The antinomyra system</title>
		<author>
			<persName coords=""><forename type="first">Ke</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Junqiu</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shengwen</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shanfeng</forename><surname>Zhu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,163.04,578.59,194.67,7.86">Proceedings of Question Answering Lab at CLEF</title>
		<meeting>Question Answering Lab at CLEF</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,589.92,337.96,7.86" xml:id="b16">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Yifeng</forename><surname>Liu</surname></persName>
		</author>
		<title level="m" coord="12,200.06,589.92,180.62,7.86">BioASQ System Descriptions (Wishart team)</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="12,142.61,601.26,337.96,7.86;12,151.52,612.22,251.71,7.86" xml:id="b17">
	<monogr>
		<title level="m" type="main" coord="12,273.39,601.26,207.19,7.86;12,151.52,612.22,151.01,7.86">NCBI at the 2013 BioASQ challenge task: Learning to rank for automatic MeSH Indexing</title>
		<author>
			<persName coords=""><forename type="first">Yuqing</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zhiyong</forename><surname>Lu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="12,142.61,623.55,337.96,7.86;12,151.52,634.51,232.06,7.86" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="12,384.12,623.55,96.46,7.86;12,151.52,634.51,204.08,7.86">The NLM Medical Text Indexer System for Indexing Biomedical Literature</title>
		<author>
			<persName coords=""><forename type="first">James</forename><surname>Mork</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antonio</forename><surname>Jimeno-Yepes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alan</forename><surname>Aronson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,142.61,645.84,337.97,7.86;12,151.52,656.80,224.17,7.86" xml:id="b19">
	<analytic>
		<title level="a" type="main" coord="12,220.66,645.84,241.51,7.86">Hpi in-memory-based database system in task 2b of bioasq</title>
		<author>
			<persName coords=""><forename type="first">Mariana</forename><surname>Neves</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,151.52,656.80,194.67,7.86">Proceedings of Question Answering Lab at CLEF</title>
		<meeting>Question Answering Lab at CLEF</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,119.67,337.96,7.86;13,151.52,130.63,329.05,7.86;13,151.52,141.59,329.07,7.86;13,151.52,152.55,329.06,7.86;13,151.52,163.51,66.73,7.86" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="13,331.34,130.63,149.23,7.86;13,151.52,141.59,261.57,7.86">Ensemble Approaches for Large-Scale Multi-Label Classification and Question Answering in Biomedicine</title>
		<author>
			<persName coords=""><forename type="first">Yannis</forename><surname>Papanikolaou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dimitrios</forename><surname>Dimitriadis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Grigorios</forename><surname>Tsoumakas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Manos</forename><surname>Laliotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nikos</forename><surname>Markantonatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ioannis</forename><surname>Vlahavas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,430.51,141.59,50.08,7.86;13,151.52,152.55,329.06,7.86;13,151.52,163.51,38.40,7.86">2nd BioASQ Workshop: A challenge on large-scale biomedical semantic indexing and question answering</title>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,174.47,337.96,7.86;13,151.52,185.43,329.06,7.86;13,151.52,196.39,329.06,7.86;13,151.52,207.35,120.83,7.86" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="13,449.63,174.47,30.95,7.86;13,151.52,185.43,325.14,7.86">Two hierarchical text categorization approaches for BioASQ semantic indexing challenge</title>
		<author>
			<persName coords=""><forename type="first">Francisco</forename><surname>Ribadas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luis</forename><surname>De Campos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Victor</forename><surname>Darriba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alfonso</forename><surname>Romero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,162.59,196.39,317.99,7.86;13,151.52,207.35,92.50,7.86">1st BioASQ Workshop: A challenge on large-scale biomedical semantic indexing and question answering</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,218.30,337.96,7.86;13,151.52,229.26,329.06,7.86;13,151.52,240.22,329.07,7.86;13,151.52,251.18,20.99,7.86" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="13,289.09,229.26,191.48,7.86;13,151.52,240.22,110.35,7.86">Cole and utai participation at the 2014 bioasq semantic indexing challenge</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Francisco</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Luis</forename><forename type="middle">M</forename><surname>Ribadas-Pena</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Victor</forename><surname>De Campos Ibanez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alfonso</forename><forename type="middle">E</forename><surname>Manuel Darriba-Bilbao</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Romero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,281.10,240.22,194.06,7.86">Proceedings of Question Answering Lab at CLEF</title>
		<meeting>Question Answering Lab at CLEF</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,262.14,337.96,7.86;13,151.52,273.10,329.07,7.86" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="13,307.13,262.14,173.44,7.86;13,151.52,273.10,115.05,7.86">A survey of hierarchical classification across different application domains</title>
		<author>
			<persName coords=""><forename type="first">Carlos</forename><forename type="middle">N</forename><surname>Jr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Alex</forename><forename type="middle">A</forename><surname>Silla</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Freitas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,274.88,273.10,137.40,7.86">Data Mining Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="31" to="72" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,284.06,337.96,7.86;13,151.52,295.02,329.06,7.86;13,151.52,305.98,291.28,7.86" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="13,348.56,284.06,132.01,7.86;13,151.52,295.02,78.68,7.86">Large scale multi-label classification via metalabeler</title>
		<author>
			<persName coords=""><forename type="first">Lei</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Suju</forename><surname>Rajan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vijay</forename><forename type="middle">K</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,249.04,295.02,231.54,7.86;13,151.52,305.98,83.62,7.86">Proceedings of the 18th international conference on World wide web, WWW &apos;09</title>
		<meeting>the 18th international conference on World wide web, WWW &apos;09<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="211" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,316.94,337.96,7.86;13,151.52,327.89,329.07,7.86;13,151.52,338.85,224.68,7.86" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="13,404.45,316.94,76.12,7.86;13,151.52,327.89,17.92,7.86">Mining Multi-label Data</title>
		<author>
			<persName coords=""><forename type="first">Grigorios</forename><surname>Tsoumakas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ioannis</forename><surname>Katakis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ioannis</forename><surname>Vlahavas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,363.25,327.89,117.33,7.86;13,151.52,338.85,78.49,7.86">Data Mining and Knowledge Discovery Handbook</title>
		<editor>
			<persName><forename type="first">Oded</forename><surname>Maimon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Lior</forename><surname>Rokach</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer US</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="page" from="667" to="685" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,349.81,337.96,7.86;13,151.52,360.77,329.06,7.86;13,151.52,371.73,329.06,7.86;13,151.52,382.69,56.85,7.86" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="13,151.52,360.77,233.06,7.86">Large-Scale Semantic Indexing of Biomedical Publications</title>
		<author>
			<persName coords=""><forename type="first">Grigorios</forename><surname>Tsoumakas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Manos</forename><surname>Laliotis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nikos</forename><surname>Markontanatos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ioannis</forename><surname>Vlahavas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,392.65,360.77,87.94,7.86;13,151.52,371.73,329.06,7.86;13,151.52,382.69,28.69,7.86">In 1st BioASQ Workshop: A challenge on large-scale biomedical semantic indexing and question answering</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,393.65,337.96,7.86;13,151.52,404.61,329.06,7.86;13,151.52,415.57,285.39,7.86" xml:id="b27">
	<analytic>
		<title level="a" type="main" coord="13,406.15,393.65,74.42,7.86;13,151.52,404.61,147.71,7.86">Answering Factoid Questions in the Biomedical Domain</title>
		<author>
			<persName coords=""><forename type="first">Dirk</forename><surname>Weissenborn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">George</forename><surname>Tsatsaronis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Schroeder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,321.42,404.61,159.16,7.86;13,151.52,415.57,257.06,7.86">1st BioASQ Workshop: A challenge on large-scale biomedical semantic indexing and question answering</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,426.52,337.96,7.86;13,151.52,437.48,329.07,7.86;13,151.52,448.44,175.00,7.86" xml:id="b28">
	<analytic>
		<title level="a" type="main" coord="13,325.53,426.52,155.04,7.86;13,151.52,437.48,261.48,7.86">Ncbi at the 2014 bioasq challenge task: large-scale biomedical semantic indexing and question answering</title>
		<author>
			<persName coords=""><forename type="first">Zhiyong</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yuqing</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chih-Hsuan</forename><surname>Wei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,434.71,437.48,45.88,7.86;13,151.52,448.44,145.50,7.86">Proceedings of Question Answering Lab at CLEF</title>
		<meeting>Question Answering Lab at CLEF</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.61,459.40,337.96,7.86;13,151.52,470.36,329.07,7.86;13,151.52,481.32,298.57,7.86" xml:id="b29">
	<analytic>
		<title level="a" type="main" coord="13,421.28,459.40,59.30,7.86;13,151.52,470.36,164.47,7.86">An Incemental Approach for MEDLINE MeSH Indexing</title>
		<author>
			<persName coords=""><forename type="first">Donhqing</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dingcheng</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ben</forename><surname>Carterette</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hongfang</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,336.18,470.36,144.41,7.86;13,151.52,481.32,270.23,7.86">1st BioASQ Workshop: A challenge on large-scale biomedical semantic indexing and question answering</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
