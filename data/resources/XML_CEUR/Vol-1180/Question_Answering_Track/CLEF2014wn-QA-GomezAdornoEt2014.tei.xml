<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,225.86,116.95,163.65,12.62;1,193.73,134.89,227.90,12.62;1,215.03,152.82,185.30,12.62">Graph-based Approach to the Question Answering Task Based on Entrance Exams</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,215.91,190.49,98.62,8.74"><forename type="first">Helena</forename><surname>Gómez-Adorno</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Centro de Investigación</orgName>
								<orgName type="institution">Instituto Politécnico Nacional</orgName>
								<address>
									<settlement>México</settlement>
									<region>D.F</region>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,325.08,190.49,67.13,8.74"><forename type="first">Grigori</forename><surname>Sidorov</surname></persName>
							<email>sidorov@cic.ipn.mx@www.gelbukh.com</email>
							<affiliation key="aff0">
								<orgName type="department">Centro de Investigación</orgName>
								<orgName type="institution">Instituto Politécnico Nacional</orgName>
								<address>
									<settlement>México</settlement>
									<region>D.F</region>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,221.80,202.44,52.86,8.74"><forename type="first">David</forename><surname>Pinto</surname></persName>
							<email>dpinto@cs.buap.mx</email>
							<affiliation key="aff1">
								<orgName type="department">Facultad de Ciencias de la Computación</orgName>
								<orgName type="institution">Benemérita Universidad Autónoma de Puebla</orgName>
								<address>
									<settlement>Puebla</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,304.59,202.44,84.50,8.74"><forename type="first">Alexander</forename><surname>Gelbukh</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Centro de Investigación</orgName>
								<orgName type="institution">Instituto Politécnico Nacional</orgName>
								<address>
									<settlement>México</settlement>
									<region>D.F</region>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,225.86,116.95,163.65,12.62;1,193.73,134.89,227.90,12.62;1,215.03,152.82,185.30,12.62">Graph-based Approach to the Question Answering Task Based on Entrance Exams</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">41E15500E2EBC8DD779CDB04EB881985</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Question answering system</term>
					<term>reading comprehension</term>
					<term>entrance exams</term>
					<term>graph-based representation</term>
					<term>graph similarity</term>
					<term>extraction of features from graphs</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the approach used in the system for the Question Answering Task based on Entrance Exams, which was presented at the CLEF 2014. The task aims to evaluate methods of text understanding with reading comprehension tests. The system should read a given document and answer multiple-choice questions about it. Our approach transforms the documents along with the multiple-choice answers into a graph-based representation that contains lexical, morphological, and syntactic features. After this, it traverses different paths both in the document itself and in the the graphs of the answers in order to find these features of the graphs. It is performed by counting text components: lemmas, PoS tags, grammatical tags. As the result of this procedure, the system constructs several feature vectors: one for each traversed graph. Finally, a cosine based similarity is calculated over these feature vectors in order to rank the multiple-choice answers and select the correct one-with the best similarity with the graph that corresponds to the text itself. Our system obtained a c@1 of 0.375, which was outperformed only by one system in the competition.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper we present the experiments carried out as part of the participation in the Question Answering track based on Entrance Exams presented at the CLEF 2014. The Entrance Exam task was proposed in 2013 as a pilot task <ref type="bibr" coords="1,458.93,657.11,10.52,8.74" target="#b0">[1]</ref> in the Question Answering for Machine Reading Evaluation Lab (QA4MRE), which was offered at the Conference and Labs of the Evaluation Forum (CLEF) since 2011 <ref type="bibr" coords="2,157.85,143.90,10.52,8.74" target="#b1">[2,</ref><ref type="bibr" coords="2,170.03,143.90,7.01,8.74" target="#b2">3]</ref>. The entrance exams task evaluates systems in the same situation, in which high school students are evaluated for entering a university. The challenge consists of reading a document and identifying a correct answer (from multiple choices) for a set of questions about the information that is expressed or implied in the text. The questions are written in the form of multiple choices; each question has 4 different options, and only one option is the correct answer. Exams are created by the Japanese National Center for University Admissions Tests. The Entrance Exams corpus is provided by NII's Todai Robot Project<ref type="foot" coords="2,476.12,226.01,3.97,6.12" target="#foot_0">1</ref> and NTCIR <ref type="foot" coords="2,186.93,237.97,3.97,6.12" target="#foot_1">2</ref> .</p><p>Since the first edition of QA4MRE task in 2011, and later in the 2012 and 2013, a single evaluation platform for the experimentation with new techniques and methodologies for this problem has provided. In this sense, we can take the systems presented at this conference as state of the art work in this research field.</p><p>The rest of the paper is organized as follows. Section 2 describes our approach and the system architecture. Section 3 presents the configuration of the submitted runs and the evaluation results. Finally, Section 4 presents the conclusions and outlines some directions of future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Architecture</head><p>For many problems in natural language processing, graph structure is an intuitive, natural and direct way to represent data. There exist several research works that have employed graphs for text representation in order to solve some particular problem <ref type="bibr" coords="2,219.47,441.99,9.96,8.74" target="#b3">[4]</ref>. We propose an approach based on a graph methodology for document understanding, which is described in detail before in <ref type="bibr" coords="2,424.72,453.94,9.96,8.74" target="#b4">[5]</ref>, and built the corresponding system. The system consists of the following submodules: document preprocessing, graph generation and answer validation. The general architecture is illustrated in Figure <ref type="figure" coords="2,290.66,489.81,3.87,8.74">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Document Preprocessing</head><p>First we perform document (pre)processing. An XML parser receives as input a structured corpus in XML format as it is shown in Figure <ref type="figure" coords="2,406.05,554.23,3.87,8.74">1</ref>. This XML file contains all the documents, along with their respective questions and multiple choice answers. An XML interpreter extracts the documents, questions and associated answers. It stores the questions and answers identifying them according to the document, to which they belong, in order to be used in further processing. Further, the questions associated to each document are analyzed, identifying the "question keywords" (what, where, when, who, etc.), and the result is passed to the next module. After this, hypothesis generation module formulates several candidate "answer hypotheses" as the modified versions of the original question, replacing these words with one of the possible answers given in the test data. For example, given the question: Who is the founder of the SING campaign? and the possible answer: Annie Lennox. The obtained hypothesis is: Annie Lennox is the founder of the SING campaign.</p><p>Afterwards, we perform anaphora resolution in the documents using the JavaRAP<ref type="foot" coords="3,175.86,202.10,3.97,6.12" target="#foot_2">3</ref> system. It was observed that applying anaphora resolution in QA systems improves the precision <ref type="bibr" coords="3,272.37,215.63,9.96,8.74" target="#b5">[6]</ref>.</p><p>The output of this module is the set of answer hypotheses along with their reference documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Graph Generation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Syntactic Parser</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Morphological Tagger</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Semantic Expansion</head><p>---------------------------------------------------------------- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Document</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Questions and Answers Associated Document</head><p>Fig. <ref type="figure" coords="3,245.39,532.51,4.13,7.89">1</ref>. Graph-based system architecture</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Graph Generation Module</head><p>In the graph generation module, text documents along with their hypotheses are parsed to produce their graph-based representation. For the graph representation we took into account various linguistic levels (lexical, syntactic, morphological and semantic relationships) in order to capture the majority of features present in the text. The process of the graph generation is performed by the following submodules:</p><p>Syntactic Parser is the base of the graph structure. We use the Stanford Dependency Parser<ref type="foot" coords="4,236.02,187.07,3.97,6.12" target="#foot_3">4</ref> for producing the parsed tree for each sentence of the documents. In this type of parsing, we detect grammatical relation between words of the sentences. Morphological Tagger obtains PoS tags of the words. For this, we used the Stanford Log linear Part-Of-Speech Tagger<ref type="foot" coords="4,334.75,235.07,3.97,6.12" target="#foot_4">5</ref> for English. The Lancaster stemmer algorithm was used in order to obtain word stems. Semantic Expansion uses the Wordnet taxonomy <ref type="bibr" coords="4,364.30,260.74,10.52,8.74" target="#b6">[7]</ref> in order to add semantic relations between nodes of the graphs, i.e., the graph is expanded using the taxonomy: some nodes are added.</p><p>As the result of this process, each document is represented as a tree rooted in a ROOT -0 node. The vertices to sub-trees represent all sentences in the document. The nodes of the trees represent word or lemmas of the sentences along with their part-of-speech tags. The vertices between nodes represent the dependency tags between these connected nodes and the frequency label shows the number of occurrences of the pair (initial node, final node) in the graph plus the frequency of the dependency tag of the same pair of nodes. In the same way all answer hypotheses are represented as trees with the same characteristics.</p><p>In Figure <ref type="figure" coords="4,196.18,400.95,4.98,8.74" target="#fig_0">2</ref> we present the graph-based representation for the hypothesis "Annie Lennox is the founder of the SING campaign", whereas Figure <ref type="figure" coords="4,446.86,412.90,4.98,8.74" target="#fig_1">3</ref> shows the graph-based representation for the first three sentences of the reference document associated to this question. The feature extraction starts by fixing the root node of the hypothesis graph as the initial node, whereas the selected final nodes correspond to the rest nodes of the hypothesis graph. We use the Dijkstra s Algorithm <ref type="bibr" coords="5,402.43,119.99,10.52,8.74" target="#b7">[8]</ref> for finding the shortest paths between the initial and each final node. After this, we count the occurrences of all the multi-level linguistic features considered in the text representation such as PoS tags and dependencies tags found in the path. The same procedure is performed with the document graph, using the pair of nodes identified in the hypothesis as the initial and final node. As the result of this procedure, we obtain two feature vectors: one for the answer hypothesis and another one for the reference document. This module was implemented in Python, using the NetworkX<ref type="foot" coords="5,178.79,214.06,3.97,6.12" target="#foot_5">6</ref> package for creation and manipulation of graphs. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Answer Validation Module</head><p>This module receives several feature vectors ( -→ f t,i ) for each text. Thus, the ref-</p><formula xml:id="formula_0" coords="5,134.77,604.53,338.08,15.57">erence document d is now represented by m features (d * = { --→ f d,1 , --→ f d,2 , ..., --→ f d,m }</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>), as well as the answer hypothesis h, (h</head><formula xml:id="formula_1" coords="5,309.95,617.96,110.95,15.57">* = { --→ f h,1 , --→ f h,2 , ..., --→ f h,m }),</formula><p>being m the number of different paths that can be traversed in both graphs.</p><p>We use the following cosine similarity measure for calculating the degree of similarity in each traversed path:</p><formula xml:id="formula_2" coords="6,168.40,149.52,307.95,101.62">Similarity(h * , d * ) = m i=1 Cosine( -→ f h,i , -→ f d,i ) = m i=1 -→ f h,i • -→ f d,i || -→ f h,i || • || -→ f d,i || = m i=1 |V | j=1 (f (h,i),j × f (d,i),j ) |V | j=1 (f (h,i),j ) 2 × |V | j=1 (f (d,i),j ) 2 . (<label>1</label></formula><formula xml:id="formula_3" coords="6,476.35,228.33,4.24,8.74">)</formula><p>After obtaining all similarity scores of the four hypotheses for each question, the hypothesis achieving the highest score is selected as the correct answer. We answered every question of the task using this methodology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Results</head><p>This section describes the data sets of the challenge used for evaluation of the systems. Additionally, the results obtained in the experiments are reported and discussed.</p><p>Following 2013 edition, the test set 2014 based on Entrance Exams was composed of tests for reading comprehension taken from the Japanese Center Test, which is a nation-wide achievement test for admission in Japanese universities.</p><p>The organizers released two different datasets, one for training and one for testing. Both data sets were composed of the following elements:</p><p>-12 test documents, -60 questions (5 questions for each document), -240 choices/options (4 for each question).</p><p>The main measure used in this evaluation is c@1, which is defined as shown in equation 2. This measure was defined in the QA4MRE task at CLEF 2011 with the purpose of allowing the systems to decide whether or not to answer a given question. The aim of this procedure is to reduce the amount of incorrect answers, maintaining the number of correct ones, i.e., a system is penalized for answering incorrectly and it is better not to answer at all if not sure:</p><formula xml:id="formula_4" coords="6,256.95,561.81,223.65,22.31">c@1 = 1 n (n R + n U n R n ),<label>(2)</label></formula><p>where: n R : number of correctly answered questions, n U : number of unanswered questions, n: total number of questions.</p><p>Table <ref type="table" coords="6,177.87,645.16,4.98,8.74" target="#tab_1">1</ref> presents the comparative results obtained in the QA 2014 competition for Entrance Exams. Approximately thirty runs were submitted to the competition from various research teams. We submitted eight runs with different configurations of the system. The run that ranked highest was cicnlp-8, which obtained a c@1 of 0.375 answering 21 questions correctly. At the reading comprehension level the run cicnlp-8 only passed 3 out of 12 tests, whereas the run cicnlp-2 passed 4 out of 12 tests. Even though the run cicnlp-2 passed one more test than our best run, it only obtained a c@1 of 0.303. In the last column of Table <ref type="table" coords="7,174.09,191.72,4.98,8.74" target="#tab_1">1</ref> we show the quantity of tests passed by the runs (tests with c@1 &gt; 0.5). Table <ref type="table" coords="7,177.73,393.92,4.98,8.74" target="#tab_2">2</ref> shows the features included in the graph-based representation and which of those features were used in the feature extraction technique for each of the eight configurations. Those configurations were selected during the evaluation process with the training dataset released by the organizers.</p><p>The cicnlp-1 run includes the words and the POS tags in the nodes of the graph-based representation, as well as the dependency tags, which represents the relation between each pair of nodes (vertices). Note that in this run we do not use lemmas in graph nodes and do not consider frequencies for the vertices. The features extracted in this run are PoS tags and dependency tags. In the case of the cicnlp-2 the graph representation is the same, but we add the word count to the extracted feature set. In case of the runs cicnlp-1 and cicnlp-2, we used an algorithm for obtaining all shortest path between an initial and a final node. The rest of the runs use the Dijkstra algorithm for obtaining only one shortest path.</p><p>The cicnlp-3 run includes the frequency count of the vertices (initial node to final node + dependency tags) in the same way as it is explained in Section 2.2. The cicnlp-4 uses the same graph representation and extracted features than run cicnlp-2, the only difference is the traversal algorithm.</p><p>The cicnlp-5 and cicnlp-6 runs apply the feature extraction technique when the words in the hypothesis graph are expanded with their corresponding set of synonyms (without applying the process of word sense disambiguation). The run cicnlp-6 uses stems instead of the full words in the graph-based representations. The features extracted in both runs are words (count), PoS tags (count) and dependency tags (count). The runs cicnlp-7 and cicnlp-8 apply the feature extraction technique when the words in the hypothesis graph are expanded with their corresponding set of hypernyms (without applying the process of word sense disambiguation). The run cicnlp-8 uses stems instead of the full words in the graph-based representations. The features extracted in both runs are PoS tags (count) and dependency tags (count). We found that as far as the reading level is concerned, different runs were able to pass different tests. For example, the run cicnlp-8 passed the tests 13, 16 and 18; the run cicnlp-3 passed the tests 13, 14, 15 and 16; the run cicnlp-6 passed the tests 13, 16 and 23. In future, we plan to combine different runs, and in this manner we would be able to pass 6 out of 12 tests. Besides, the run cicnlp-8 passed the test 13 correctly answering all questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion and Future Work</head><p>We described the approach and the system developed as a part of our participation of QA task 2014 based on Entrance Exams. The approach uses a graph structure for representing the documents and the answer hypotheses. It extracts linguistic features from both graphs-documents and answer hypotheses-by traversing shortest paths. The features are further used for computing the similarity between the document and the answer hypotheses.</p><p>We sent eight runs to the competition. The best run (cicnlp-8 ) of our system achieves a c@1 of 0.375, which was outperformed only by one system.</p><p>For future work, we hope that the use of domain-specific techniques of question answering will improve the performance of the algorithm for this particular problem. Textual entailment, named entity recognition, analysis of the type of question can improve the final results of our system in the task.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,134.77,559.83,345.81,7.89;4,134.77,570.81,84.54,7.86"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Graph-based representation of the hypothesis "Annie Lennox is the founder of the SING campaign"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,134.77,498.78,345.81,7.89;5,134.77,509.76,37.23,7.86"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Example of the graph-based representation of a reference document (3 first sentences</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,221.53,276.52,165.41,235.66"><head>Hypothesis Features Extractor (traversing graphs) Answer Selection Final Answer Similarity Computation Answer Validation Hypotheses + Documents XML Document Document Processing XML Interpreter Question Analysis -Anaphora Resolution Hypothesis Generator (Question + Answer)</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,146.28,235.84,322.80,130.68"><head>Table 1 .</head><label>1</label><figDesc>Results of participation in QA task 2014 based on Entrance Exams</figDesc><table coords="7,146.28,258.91,322.80,107.62"><row><cell>Run</cell><cell>Correctly Answered</cell><cell>Incorrectly Answered</cell><cell>Unanswered</cell><cell>c@1</cell><cell>Tests with c@1 &gt; 0.5</cell></row><row><cell>cicnlp-1</cell><cell>16</cell><cell>40</cell><cell>0</cell><cell>0.285</cell><cell>3/12</cell></row><row><cell>cicnlp-2</cell><cell>19</cell><cell>37</cell><cell>0</cell><cell>0.339</cell><cell>2/12</cell></row><row><cell>cicnlp-3</cell><cell>17</cell><cell>39</cell><cell>0</cell><cell>0.303</cell><cell>4/12</cell></row><row><cell>cicnlp-4</cell><cell>17</cell><cell>39</cell><cell>0</cell><cell>0.303</cell><cell>2/12</cell></row><row><cell>cicnlp-5</cell><cell>13</cell><cell>43</cell><cell>0</cell><cell>0.232</cell><cell>1/12</cell></row><row><cell>cicnlp-6</cell><cell>16</cell><cell>40</cell><cell>0</cell><cell>0.285</cell><cell>3/12</cell></row><row><cell>cicnlp-7</cell><cell>20</cell><cell>36</cell><cell>0</cell><cell>0.357</cell><cell>2/12</cell></row><row><cell>cicnlp-8</cell><cell>21</cell><cell>35</cell><cell>0</cell><cell>0.375</cell><cell>3/12</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,134.77,116.91,345.81,237.65"><head>Table 2 .</head><label>2</label><figDesc>Configurations of the graphs representation and the extracted features used in the runs.</figDesc><table coords="8,165.75,146.90,280.77,207.66"><row><cell></cell><cell></cell><cell cols="5">Representation schemes</cell><cell></cell><cell cols="3">Extracted features</cell></row><row><cell>Run</cell><cell>Words</cell><cell>POS tags</cell><cell>Dependency tags</cell><cell>Stemming</cell><cell>Frequency</cell><cell>Synonym expansion</cell><cell>Hypernym expansion</cell><cell>Words count</cell><cell>POS tags count</cell><cell>Dependency tags count</cell></row><row><cell>cicnlp-1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>cicnlp-2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>cicnlp-3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>cicnlp-4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>cicnlp-5</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>cicnlp-6</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>cicnlp-7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>cicnlp-8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,144.73,646.84,110.11,7.86"><p>http://21robot.org/About/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,144.73,657.80,179.30,7.86"><p>http://research.nii.ac.jp/ntcir/index-en.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,144.73,657.80,244.22,7.86"><p>http://wing.comp.nus.edu.sg/ qiu/NLPTools/JavaRAP.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,144.73,646.84,200.72,7.86"><p>http://nlp.stanford.edu/software/lex-parser.shtml</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="4,144.73,657.80,186.57,7.86"><p>http://nlp.stanford.edu/software/tagger.shtml</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="5,144.73,657.80,112.19,7.86"><p>https://networkx.github.io/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,138.35,211.33,342.23,7.86;9,146.91,222.29,291.96,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,329.08,211.33,151.50,7.86;9,146.91,222.29,45.53,7.86">Overview of QA4MRE 2013 Entrance Exams task</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Miyao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Forner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,214.45,222.29,186.47,7.86">CLEF (Online Working Notes/Labs/Workshop</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.35,230.98,342.24,10.13;9,146.91,244.21,333.67,7.86;9,146.91,255.17,327.96,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,207.24,244.21,273.34,7.86;9,146.91,255.17,101.54,7.86">Overview of QA4MRE at CLEF 2011: Question Answering for Machine Reading Evaluation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Forner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Á</forename><surname>Rodrigo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">F E</forename><surname>Sutcliffe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Forascu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Sporleder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,270.79,255.17,166.14,7.86">CLEF (Notebook Papers/Labs/Workshop</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.35,263.86,342.24,10.13;9,146.91,277.08,333.66,7.86;9,146.91,288.04,333.67,7.86;9,146.91,299.00,126.24,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,319.38,277.08,161.20,7.86;9,146.91,288.04,214.34,7.86">Overview of QA4MRE at CLEF 2012: Question Answering for Machine Reading Evaluation</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Peñas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">H</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Forner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Á</forename><surname>Rodrigo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">F E</forename><surname>Sutcliffe</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Sporleder</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Forascu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Benajiba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Osenova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,384.84,288.04,95.74,7.86;9,146.91,299.00,88.28,7.86">CLEF (Online Working Notes/Labs/Workshop</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.35,309.96,342.23,7.86;9,146.91,320.92,180.85,7.86" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="9,248.72,309.96,231.86,7.86;9,146.91,320.92,32.07,7.86">Graph-based natural language processing and information retrieval</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Mihalcea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Radev</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.35,331.88,342.23,7.86;9,146.91,342.84,333.66,7.86;9,146.91,353.77,69.99,7.89" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,376.98,331.88,103.60,7.86;9,146.91,342.84,212.20,7.86">A graph-based multi-level linguistic representation for document understanding</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Pinto</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Gómez-Adorno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">V</forename><surname>Ayala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><forename type="middle">K</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,367.63,342.84,112.95,7.86">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="93" to="102" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.35,364.76,342.22,7.86;9,146.91,375.71,333.67,7.86;9,146.91,386.67,261.72,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,260.41,364.76,220.16,7.86;9,146.91,375.71,91.01,7.86">Importance of pronominal anaphora resolution in question answering systems</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">L</forename><surname>Vicedo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ferrandez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,260.00,375.71,220.58,7.86;9,146.91,386.67,193.64,7.86">Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics (ACL 2000)</title>
		<meeting>the 38th Annual Meeting of the Association for Computational Linguistics (ACL 2000)</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="555" to="562" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.35,397.63,342.22,7.86;9,146.91,408.56,90.21,7.89" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,206.50,397.63,166.90,7.86">WordNet: A lexical database for English</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,384.71,397.63,95.86,7.86;9,146.91,408.59,21.75,7.86">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,138.35,419.55,342.23,7.86;9,146.91,430.48,132.53,7.89" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,216.12,419.55,207.01,7.86">A note on two problems in connexion with graphs</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">W</forename><surname>Dijkstra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,433.91,419.55,46.67,7.86;9,146.91,430.51,48.38,7.86">Numerische mathematik</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="269" to="271" />
			<date type="published" when="1959">1959</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
