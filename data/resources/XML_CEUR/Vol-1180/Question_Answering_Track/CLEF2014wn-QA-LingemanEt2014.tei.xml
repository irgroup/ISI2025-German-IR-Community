<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,223.10,117.91,161.98,10.52;1,203.09,135.84,209.17,10.52">UMass at BioASQ 2014</title>
				<funder ref="#_PzKqNhF">
					<orgName type="full">Umass Medical School</orgName>
				</funder>
				<funder ref="#_6qwX364">
					<orgName type="full">National Institutes of Health</orgName>
				</funder>
				<funder>
					<orgName type="full">Center for Intelligent Information Retrieval</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,236.37,173.55,67.90,6.64"><forename type="first">Jesse</forename><surname>Lingeman</surname></persName>
							<email>lingeman@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<settlement>Amherst</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,326.96,173.55,52.04,6.64"><forename type="first">Laura</forename><surname>Dietz</surname></persName>
							<email>dietz@cs.umass.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Computer Science</orgName>
								<orgName type="institution">University of Massachusetts</orgName>
								<address>
									<settlement>Amherst</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,223.10,117.91,161.98,10.52;1,203.09,135.84,209.17,10.52">UMass at BioASQ 2014</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">DEC9F2135F121101170B8B3CFE56585D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:38+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Building on our experience with retrieval of gures, gure summarization with sentences from text, we study the utility of gurebased features and techniques for text retrieval. Figure based approaches are compared to approaches using abstracts instead of gures. We also explore two dierent relevance models: one built using the Unied Medical Language System (UMLS) and one built using Wikipedia. We conduct several experiments exploring dierent feature combinations using a model built with the TREC Genomics track for submission to the 2014 BioASQ competition.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The BioASQ competition is about answering biomedical questions by extracting information from research publications on Pubmed. BioASQ oers several subtasks to participate in: retrieving Pubmed documents that contain an answer, retrieving snippets from those documents that contain an answer, retrieving relevant concepts or RDF triples, and extracting the answer from all retrieved material.</p><p>In a cooperation between the Center for Intelligent Information Retrieval and UMass Amherst and the BioNLP group at UMass Medical school in Worcester, we developed a gure-inspired text retrieval method as a new way of retrieving documents and text passages from biomedical publictions. Our method is based on the insight that for biomedical publications, the gures play a central role up to the point where their caption and references provide abstract-like summaries of the paper. In this work we build on our experience with gure summarization and gure ranking algorithms <ref type="bibr" coords="1,267.44,550.18,10.79,6.64" target="#b4">[5,</ref><ref type="bibr" coords="1,278.23,550.18,7.19,6.64" target="#b7">8,</ref><ref type="bibr" coords="1,285.42,550.18,7.19,6.64" target="#b0">1]</ref>.</p><p>We are test driving our gure-inspired retrieval method in the BioASQ competition, where we focus our participation on document and snippet retrieval.</p><p>As gures are the center of our attention, our methods rely on the availability of full text, e.g. in PMC format. Therefore we only retrieve documents and snippets contained in Pubmed Central. We notice that the available training data covers Pubmed Central only sparsely. Most queries in the gold standard contain just one publication from Pubmed Central; only 13 queries contained at least 10 documents in Pubmed Central. Since it is infeasible to dene a complete gold standard ahead of time, our mission is to identify new material from PMC 5319ac18b166e2b806000030 Is clathrin involved in E-cadherin endocytosis? plasma membranes we have found here that non-trans-interacting e-cadherin is constitutively endocytosed like integrin ligand-independent endocytosis that the formation of endocytosed vesicles of e-cadherin is clathrin dependent and that e-cadherin but not other cams at ajs and tjs including nectins claudins and occludin is selectively sorted into the endocytosed (PMC 15263019)</p><p>5319abc9b166e2b80600002d Is Rac1 involved in cancer cell invasion? cells was clearly demonstrated by rna interference assay rac1 depletion signicantly suppressed the frequency of invasion in both quiescent and igf-i-stimulated mda-mb-231 cells this indicates the necessity of rac1 for igf-i-induced cell invasion in the cells overexpression of rac1 has been <ref type="bibr" coords="2,248.73,249.21,58.87,9.02">(PMC 21961005)</ref> that answers the questions. To demonstrate the existence of relevant material</p><p>we show examples of relevant snippets in Table <ref type="table" coords="2,342.42,298.88,4.98,6.64" target="#tab_0">1</ref> and provide more examples in the result section.</p><p>In the absence of suitable training data on full documents, we develop and train our method on data from TREC Genomics track 2006 and 2007. Like Bioasq Task 2b(phase A), the Genomics TREC task focuses on retrieving relevant documents and snippets for biomedical questions. The distinctions lie in the use of the Highwire corpus. After training supervised models on the TREC data, they are applied to questions posed in the BioASQ competition.</p><p>Our approach takes an Information Retrieval perspective on the problem.</p><p>First, query expansion is performed with information from UMLS, Wikipedia, and Figures to enrich the question. Second, a ranking of full documents and snippets is retrieved from a corpus of articles from Pubmed Central. Third, we extract features for each document and snippet that indicate its relevance for the question and re-rank document/snippets with a supervised learning-to-rank approach.</p><p>2 Background: Information Retrieval This section introduces document retrieval models and query expansion techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Sequential Dependence Model</head><p>An early IR method called query likelihood employed an independence assumption within query terms to score documents with Dirichlet collection smoothing. For query terms q 1 , q 2 , ...q m , each document D in the collection is scored by a product of scores under each query term.</p><formula xml:id="formula_0" coords="2,197.35,636.49,283.24,31.77">score uni (q1,q2,...qm) (D) = log m i=1 #(q i , D) + µ #(qi,•) #(•,•) #(•, D) + µ<label>(1)</label></formula><p>We use the notation '•' to denote sums over all possible entries. In particular #(q i , D) refers to the term frequency of q i in the given document, #(q i , •) refers to the term frequency of q i in the corpus, and #(•, D) is the document length and #(•, •) number of terms in the collection. The scalar µ controls the amount of collection smoothing applied, and is a hyperparameter to be estimated. Good values of µ are in the range of <ref type="bibr" coords="3,268.98,178.77,20.48,8.74">[500,</ref><ref type="bibr" coords="3,291.12,178.77,21.22,8.74">5000]</ref>.</p><p>The query likelihood model is almost always outperformed by the sequential dependence model <ref type="bibr" coords="3,253.67,204.50,9.96,6.64" target="#b5">[6]</ref>, which also includes exact bigrams and windowed skip-bigrams. The unigram model above can be generalized to arbitrary count statistics, such as occurrences of a bigram "q i q i+1 " in document D to derive score bi . Furthermore, counting co-occurrences of the two terms q i and q i+1 in any order within a window of </p><formula xml:id="formula_1" coords="3,227.09,331.01,253.50,23.68">(D) = λ uni score uni (D) + λ bi score bi (D) + λ wbi score wbi (D) = &lt; λ, φ(D) &gt;<label>(2)</label></formula><p>The sequential dependence model requires setting of hyperparameters λ uni ,λ bi , λ wbi , and µ, where the λs can be estimated with machine learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Query Expansion</head><p>Keyword-based retrieval methods such as query likelihood and sequential dependence fail to retrieve documents that refer to the query terms via synonyms.</p><p>A solution is to expand the original query q 1 , q 2 , ...q m with additional terms t 1 , t 2 , ...t K so-called expansion terms. Methods for predicting expansion terms t i also provide condence weights w i . An expanded SDM query scores documents D by</p><formula xml:id="formula_2" coords="3,166.77,519.03,313.82,19.91">score Q (D) = score SDM (q1,q2,...qm) (D) + ω • i w i • score uni (ti) (D)<label>(3)</label></formula><p>The expanded retrieval model introduces another hyperparameter ω, which can be estimated along with λ using machine learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Pseudo-relevance Feedback</head><p>Additional expansion terms can be derived from external synonym resources or estimated with pseudo-relevance feedback. In pseudo relevance feedback the expansion terms are estimated from the document collection <ref type="bibr" coords="3,403.50,634.03,9.96,6.64" target="#b2">[3]</ref>. The approach is based on the assumption that the un-expanded retrieval model obtained high precision in the top ranks, but was lacking recall.</p><p>The procedure gathers a feedback ranking D 1 , D 2 , ..., D n from the documents from the collection which have the highest score under the un-expanded query, e.g. score SDM (D).</p><p>The next step derives distribution over terms from the feedback documents.</p><p>This involves taking the score of the document D i to approximate a relative retrieval probability of D i compared to the rest of the feedback set.</p><formula xml:id="formula_3" coords="4,178.18,202.46,302.41,24.80">p(D i |q 1 , ..., q m ) = 1 n j=1 exp score SDM (D j ) exp score SDM (D i )<label>(4)</label></formula><p>In addition, for each feedback document, a distribution over terms is derived as a language model.</p><formula xml:id="formula_4" coords="4,266.67,273.58,213.92,23.23">p(t|D i ) ∝ #(t, D i ) #(•, D i )<label>(5)</label></formula><p>These two parts are aggregated to estimate the term distribution for expansion. We derive the estimator as a mixture of document-specic language models where the document retrieval probabilitie govern the mixing weights.</p><formula xml:id="formula_5" coords="4,236.89,353.28,243.70,30.32">p(t) = n i=1 p(t|D i )p(D i |q 1 , ..., q m )<label>(6)</label></formula><p>The K most probable terms t i under this distribution, together with weights w = p(t i ) are predicted as expansion terms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Learning Hyperparameters</head><p>We exploit that a SDM retrieval model with query expansion falls into the family of log-linear models which can be eciently estimated with a learning-to-rank approach <ref type="bibr" coords="4,177.47,489.86,9.96,6.64" target="#b6">[7]</ref>. We represent each document by a feature vector with four entries: the document's score under the unigram model, as well as the bigram, windowbigram, and expansion model. We use the document relevance assessments from the training set to estimate a log-linear learning-to-rank model.</p><p>In this work we use the coordinate ascent learner from the RankLib 1 package optimizing for the metric mean-average precision (MAP).</p><p>The weights of the optimal learning-to-rank model are also the optimal settings λ uni ,λ bi , λ wbi and ω for the retrieval model. When the SDM model is expanded with multiple expansion models this learning-to-rank approach can be generalized appropriately.</p><p>This reduces the hyperparameters that need to be estimated by grid-tuning to the Dirichlet smoothing µ for SDM, and number of feedback document n and number of expansion terms K for each expansion model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Retrieval Approaches</head><p>In this section we detail how retrieval and query expansion approaches are combined to leverage gure information to derive a rst pass of bio-medical text retrieval. We discuss reranking techniques in Section 4. We refer to the target document collection as full documents, as we further extract pseudo-documents for gures and abstract.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Indexes</head><p>From the full documents in the collection, we create dierent retrieval indexes.</p><p>The full document index contains the documents in Pubmed Central document collection. The task is to retrieve relevant documents from this collection. The collection is converted into JSON format using the convertion tool provided by the BioASQ organizers. We index the all visible text as-is while preserving character osets and section information. The document preprocessing uses a special tokenizer that preserves the names of chemical compounds, genes and pathways.</p><p>We identify all gures in the original Pubmed central format and extract socalled figure documents for each of them. The gure document includes the caption of the gure, the sentences that reference the gure. In separate elds we also include sentences within a window of one and two sentences away from a gure reference. We use the gure documents for query expansion and feature generation.</p><p>In order to compare the expressiveness of gure documents to abstracts, we also create an index of abstracts that we swap in as a replacement for gure documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Document Retrieval</head><p>The most basic retrieval method uses the given query Q to obtain a ranking of full documents under the sequential dependence model. This ranking can be output directly [UMass-irSDM], or submitted to a feature-based re-ranking method (described in Section 4).</p><p>We can improve the ranking by expanding the original query with expansion terms (to obtain query Q ) to derive a ranking the full documents. To expand the query with pseudo-relevance feedback, we have dierent options. We can employ the gure document index [FigDoc Query Expansion] to retrieve a feedback run, compute term distributions according to the relevance model and expand the query Q. This approach is also applied to the index of abstract documents to derive the method [Abstract Query Expansion].</p><p>As an external source of synonyms we can also use Wikipedia. For that we create a full text index of a Wikipedia snapshot from January 2012 which contains articles for dierent entities, where some are targeting the biomedical domain. We cast the original query to our Wikipedia index and apply standard pseudo-relevance feedback [Wiki Query Expansion].</p><p>Alternatively, we expand the query using an external synonym dictionary. In this study we use the Unied Medical Language System (UMLS) <ref type="bibr" coords="6,420.97,132.77,10.52,6.64" target="#b3">[4,</ref><ref type="bibr" coords="6,431.48,132.77,7.01,6.64" target="#b1">2]</ref>. We look up all query terms q i and all query bi-grams q i q i+1 in the UMLS dictionary to build a pool of expansion terms. Prioritizing for terms that are returned by more than one lookup, we identify K expansion terms [UMLS Query Expansion].</p><p>In all approaches we learn the SDM parameters λ and expansion weight ω using 25% of the TREC Genomics queries as training data. We tune the hyperparameter µ of the sequential dependence model using grid-tuning on another 25% of the TREC queries as validation data. We select the maximal µ and according λ and ω and keep it xed for the remainder of the experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Snippet Retrieval</head><p>To participate in the snippet retrieval task, the goal is to break down the relevant documents into passages that are likely to contain the answer. In the eld of Information Retrieval this problem is known under the name Answer-Passage Retrieval.</p><p>The passage retrieval approach applies the document retrieval model to consecutive text segments inside the document, to create a ranking on the subdocument level. We chose a granularity of 50 words, which are shifted through the document in increments of 25 words. For eciency reasons we only consider documents in the high ranks for passage retrieval.</p><p>For each document, we only consider the highest ranking passage (called Max-Passage) in the following. <ref type="bibr" coords="6,134.77,428.77,6.72,8.96" target="#b3">4</ref> Feature-based Re-ranking Approaches</p><p>The ranking of full documents created by methods in Section 3 can be further improved with a supervised re-ranking approach. We use four main classes of features. IR Features ( the FigDoc index and we keep track how many and at which rank we retrieve gures for the respective document. We also keep track whether high ranking gures are referenced from the highest scoring passage, and measure the textual similarity between passage and high ranked captions. This allows to separate the false positives from the true positives: an article may be highly ranked because of something discussed in the related work or future work sections, however an article that may be slightly lower ranked but has relevant gure documents may be the more relevant document.</p><p>We also use features considering the document as a whole. We generate binary values for quality indicators, e.g., whether a document has gures, citations, and tables. We also generate features about the passages, such as number of gure references, number of citation references, number of table references, and the sum of all references in a passage. Binary features are also calculated for whether or not a passage is in a gure caption or in a document abstract.</p><p>Most of the generated features compare the tokens in the query to the tokens of some part of the document. Two measures are used to do this: Query Cover and TF-IDF. Query Cover is a simple proportion of how many of the query tokens appear in a particular part of the document. TF-IDF is similar, but each token is weighted by how frequent it appears in the corpus. If a token does not frequently appear in the corpus, but appears often in a part of the document, it gets a higher score than if it is a common token in the corpus. These measures are evaluated over dierent segments of the document: we obtain scores by comparing the query to the document abstracts, sentences in the document that reference a gure, a window of sentences around a gure reference, gure captions, and sentences in the document that reference a citation or table.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Experimental Evaluation</head><p>We train and validate our methods on test sets of the TREC Genomics track from the years 2006 and 2007. Both test sets make use of a collection of 162,259   the parameters also change across batches. A detailed list of which parameter has been used in which batch is given in Table <ref type="table" coords="10,341.33,259.89,3.87,6.64" target="#tab_9">9</ref>.</p><formula xml:id="formula_6" coords="9,194.89,151.58,227.52,127.31">no RM FigDoc Query Expansion X X X X X X IR Full Docs X X X X X X X X IR Figure Docs X X X Supervised Re-ranking X X X X X X Features IR Doc / Passage X X X X X X Features Full Docs (Text Only) X X X X Features Figures from Full Docs</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Retrieval and Reranking Methods</head><p>We study the impact of dierent components on the overall document retrieval eectiveness, by omitting some components from the pipeline as indicated in Table <ref type="table" coords="10,161.85,332.80,3.87,6.64">7</ref>. The most complete method, referred to as All-Figdoc-UMLS includes all elements of our pipeline: query expansion on the Figure Document index, retrieval of full documents with the expanded query, generation of various features for re-ranking. The feature sets include scores from the IR system as well as text-only features in addition to gure-related features as extracted from the full documents and Figure Documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Training Supervised Re-ranking on TREC Genomics</head><p>As only few BioASQ training queries have more than 10 positive documents in the Pubmed Central collection, we were hesitant to train the supervised reranking model on it. We learn the parameter vector for feature-based reranking on the TREC Genomics queries test set, using years 2006 and 2007 on the corpus of Highwire publications. We use 50% of the TREC queries for learning the supervision. As the supervision depends on IR hyperparameters, we apply the tuning heuristic above to 25% of the TREC queries (yielding λ uni = 0.77, λ bi = 0.005, λ wbi = 0.037, ω = 0.20 and µ = 2500).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Evaluation on TREC Genomics</head><p>We study dierent components of our methods on TREC Genomics holdout set.</p><p>We evaluate the Rerank All method (corresponding to system All-Figdoc-UMLS) method compared to variants of this approach that omit certain feature classes or steps in the retrieval pipeline. An overview of the evaluated methods is given in Table <ref type="table" coords="10,209.80,622.08,3.87,6.64" target="#tab_7">6</ref>.</p><p>The ocial evaluation metric of the TREC Genomics test set is mean-average precision (MAP) on the document ranking. The results on the development set are presented in Figure <ref type="figure" coords="10,239.52,657.94,3.87,6.64" target="#fig_0">1</ref>. We see that the re-ranking approaches gain a decent tems. In particular we varied the query expansion with external sources, from using UMLS to Wikipedia. This change is indicated in Table <ref type="table" coords="12,403.18,132.77,3.87,6.64">7</ref>.</p><p>Timing. The methods were run on a gridengine cluster each node having a 2.21GHz Intel Xeon CPU with 10GB of RAM (much more than necessary). Averaging the CPU time of 100 queries, we observe 21 seconds for irSDM, 35 seconds for All-FigDoc-UMLS (with Wikipedia Expansion), 41 seconds All-Abstract-UMLS, 25 seconds for All-FigDoc, 36 seconds for Doc-Figdoc-UMLS.</p><p>Results. After observing an abysmal score for all our systems on the ocial preliminary results, we manually inspected the quality of predicted snippets on rank one and two in 25 queries of batch 5 obtained by the irSDM method.</p><p>Table <ref type="table" coords="12,163.23,285.71,9.96,6.64" target="#tab_10">10</ref> displays some of the relevant snippets. We notice that many of the documents are not listed in the gold standard. An exception are the query on archeal genomes where we found a much more descriptive snippet than the one provided in the gold standard, and the query on Gray paleted syndrome, where our passage includes the ground truth passage.</p><p>We perform a more elaborate annotation on a subset of nine queries from batch 3 (irSDM). The results, measured in snippet precision at rank 10 (P@10) are presented in Table <ref type="table" coords="12,232.88,371.54,3.87,6.64" target="#tab_8">8</ref>. We see that the precision varies between 10% and 70%, but all queries have a non-zero precision. One of our common mistakes occurs when questions ask about a particular brand of medicine or active ingredient.</p><p>We notice that in such cases, a large percentage of retrieved snippets are about the disease in general, but do not mention the brand or ingredient. In the future, we intend to modify our approach by identifying such required words with an NLP tagger such as conditional random elds and discard snippets that do not contain the required word. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>For the UMass BioASQ submission we designed a gure-aware IR system which includes search-indexes of full document as well as gure captions and references. We use gures both as a resource for query expansion and test external source such as Wikipedia and UMLS as well. The retrieval approach is complemented by a supervised learning-to-rank method the includes features from IR, the document, gure features, and features from retrieving gure documents.</p><p>We evaluate against a very strong text-only baseline, which is outperformed on our development test set from the TREC Genomics track. We anticipate that including features from the gure-documents in both the retrieval methods and in reranking will improve the ranking of both document and snippets. 5319abc9b166e2b80600002d Is Rac1 involved in cancer cell invasion? cells was clearly demonstrated by rna interference assay rac1 depletion signicantly suppressed the frequency of invasion in both quiescent and igf-i-stimulated mda-mb-231 cells this indicates the necessity of rac1 for igf-i-induced cell invasion in the cells overexpression of rac1 has been (PMC 21961005, rank 1)</p><p>5311bcc2e3eabad021000005 Describe a diet that reduces the chance of kidney stones. stone promoters and inhibitors reducing deposition and excretion of small particles of caox from the kidney maintaining the antioxidant environment and reducing the chance of them being retained in the urinary tract number of herbal extracts and their isolated constituents have also shown (PMC 23112535, rank 1) for age study on the relationship of an animal-rich diet with kidney stone formation has shown that as the xed acid content of the diet increases urinary calcium excretion also increases the inability to compensate for animal protein-induced calciuric response may be risk factor for the (PMC 21369385, rank 2)</p><p>530cf4fe960c95ad0c000003 Could Catecholaminergic Polymorphic Ventricular Tachycardia (CPVT) cause sudden cardiac death? case of catecholaminergic polymorphic ventricular tachycardia introduction in reid et al.1 discovered catecholaminergic polymorphic ventricular tachycardia cpvt cpvt is known to cause syncope or sudden cardiac death and the three distinguishing features of cpvt has subsequently been described (PMC 19568611, rank 1) 52fe58f82059c6d71c00007a Do archaeal genomes contain one or multiple origins of replication? genomes in the genus bacillus such positive correlation cannot be explained by the pure c?u/t mutation bias archaeal genomes multiple replication origins are typically assumed for archaeal genome replication multiple origins of replication implies multiple changes in polarity in nucleotide (PMC 22942672, rank 1) 52e204a998d0239505000012 Which is the denition of pyknons in DNA? processed the sequences of the human and mouse genomes using the previously outlined pyknon discovery methodology see methods section as well as ref and generated the corresponding pyknon sets by denition each pyknon is recurrent motif whose sequence has minimum length minimum number of intact (PMC 18450818, rank 1) 52d8494698d0239505000007 Which genes have been found mutated in Gray platelet syndrome patients? nbeal2 is mutated in gray platelet syndrome and is required for biogenesis of platelet alpha-granules platelets are organelle-rich cells that transport granule-bound compounds to tissues throughout the body platelet ?-granules the most abundant platelet organelles store large proteins that when released promote platelet adhesiveness haemostasis and wound (PMC 21765412, rank 1)</p><p>52ce531f03868f1b06000031 Are retroviruses used for gene therapy? frequently employed forms of gene delivery in somatic and germline gene therapies retroviruses in contrast to adenoviral and lentiviral vectors can transfect dividing cells because they can pass through the nuclear pores of mitotic cells this character of retroviruses make them proper candidates (PMC 23210086, rank 2)</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="9,194.89,201.54,102.06,9.21;9,340.38,201.54,69.17,9.21;9,194.89,212.89,51.36,9.21;9,328.62,212.89,91.85,9.21;9,194.89,224.25,61.88,9.21;9,390.01,224.25,30.46,9.21;9,194.89,235.61,91.08,9.21;9,352.13,235.61,68.34,9.21;9,194.89,246.96,108.18,9.21;9,352.13,246.96,68.34,9.21;9,194.89,258.32,126.68,9.21;9,363.89,258.32,19.53,9.21;9,402.64,258.32,17.83,9.21;9,194.89,269.68,129.72,9.21;9,376.51,269.68,6.91,9.21;9,402.64,269.68,17.83,9.21;9,194.89,281.04,107.46,9.21;9,390.01,281.04,30.46,9.21"><head>Fig. 1 .</head><label>1</label><figDesc>FigDoc Query Expansion X X X X X X IR Full Docs X X X X X X X X IR Figure Docs X X X Supervised Re-ranking X X X X X X Features IR Doc / Passage X X X X X X Features Full Docs (Text Only) X X X X Features Figures from Full Docs X X X Features Figure Document X X X</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="10,134.77,120.07,163.12,7.64;10,134.77,140.34,345.84,6.64;10,134.77,152.29,345.84,6.64;10,134.77,162.42,345.33,10.39;10,134.77,174.38,345.83,8.74;10,134.77,188.16,345.84,6.64;10,134.77,198.29,345.84,8.74;10,134.77,212.07,65.30,6.64;10,149.71,224.02,335.87,6.64;10,134.77,235.98,345.84,6.64"><head></head><label></label><figDesc>for retrieval models are determined on the BioASQ training data, which we further subdivide into a 50% training-fold for log-linand a 50% validation-fold. We train the sequential dependence parameters λ uni ,λ bi , λ wbi and relevance model balance-weight ω in log-linear model fashion with coordinate ascent (using the RankLib package) on the training fold. We tune the Dirichlet smoothing parameter µ on a selection of 100, 1000, 2000, 2500, 3000 on the validation fold. The parameter settings change with the system. As we aggregate more BioASQ training data from the previous batch submissions (query for task 2b phase b),</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,208.53,115.11,198.30,9.21"><head>Table 1 .</head><label>1</label><figDesc>Examples of relevant snippets in PMC.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,134.77,252.32,345.84,89.38"><head></head><label></label><figDesc>8 terms in the document gives rise to the score under the windowed bigram model score wbi , where the marginal counts in the denominator #(•, D) are approximated by the document length.The sequential dependence model combines the scores of the document D</figDesc><table /><note coords="3,134.77,300.15,299.82,6.64;3,143.95,331.01,82.64,10.70"><p>under the unigram, bigram and window model as a log-linear model. score SDM (q1,q2,...qm)</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="6,134.77,478.57,345.84,186.02"><head>Table 2</head><label>2</label><figDesc>The main idea behind the gure and gure document features is to use gures as a way to easily isolate important text. There is a lot of technical content in articles, such as related work sections or details on the experimental setup, that are not necessarily relevant to the question being asked and can skew search results.</figDesc><table coords="6,134.77,657.94,345.84,6.64"><row><cell>Figures and gure-related passages, on the other hand, are usually describing</cell></row></table><note coords="6,275.32,478.57,205.28,6.64;6,134.77,489.86,345.82,7.53;6,134.77,501.81,345.83,7.53;6,134.77,514.43,345.84,6.64;6,134.77,525.72,345.83,7.53;6,134.77,537.68,345.84,7.53;6,134.77,550.30,345.84,6.64;6,134.77,561.59,345.83,7.53;6,134.77,574.21,345.84,6.64;6,134.77,586.16,345.84,6.64;6,134.77,598.12,59.76,6.64"><p><p><p><p><p>) are derived from the retrieval score under the unigram, bigram, windowed bigram, and expansion model. The Fiat Document Features (Table</p>3</p>) are based on similarity measures between the query and a semi-structured representation of the full document. Figure captions are included in the text, but not regarded in any special way. The Fiat Figure Features (Table 4) are designed to capture similarity of the query to gure-related information available in the semi-structured document. The fourth category are Figure Document Features (Table</p>5</p>) which are derived by retrieving gure documents (or abstracts), generate features for every gure, and aggregating across gures within the same document. A full list of features can be found in the appendix.</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="7,136.56,121.72,242.53,197.33"><head>Table 2 .</head><label>2</label><figDesc>IR Features for Reranking</figDesc><table coords="7,136.56,139.77,223.22,179.29"><row><cell>Feature Name Type Description</cell></row><row><cell>docscore docrank docexpscore docrecrank unidocscore unidocrecrank unidocexpscore IR Unigram model exponentiated score IR Overall score of the document IR Overall rank of the document IR Exponentiated score of the document IR Reciprocal rank of the document IR Unigram model score IR Unigram model rank unidocrecrank IR Unigram model reciprocal rank bidocscore IR Bigram model score bidocrank IR Bigram model rank bidocexpscore IR Bigram model exponentiated score bidocrecrank IR Bigram model reciprocal rank wbidocscore IR Windowed bigram model score wbidocrank IR Windowed bigram model rank wbidocexpscore IR Windowed bigram exponentiated score wbidocrecrank IR Windowed bigram reciprocal rank expdocscore IR Expansion model score expdocrank IR Expansion model rank expdocexpscore IR Exponentiated score of expansion model expdocrecrank IR Reciprocal rank of expansion model maxpsgscore IR Maximum passage score in the document maxpsgrank IR Highest rank of passage in document maxpsgexpscore IR Exponentiated maximum passage score maxpsgrecrank IR Reciprocal of highest ranked passage</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,136.56,339.45,310.12,144.19"><head>Table 3 .</head><label>3</label><figDesc>Document Features for Reranking IDF between query and the full text of the document fulltxt.query_cover Document QC of the full text of the document</figDesc><table coords="7,136.56,357.49,310.12,119.15"><row><cell>Feature Name</cell><cell>Type Description</cell></row><row><cell cols="2">abs.in_abstract tbl.tdf tbl.query_cover tbl.num_refs cite.tdf cite.query_cover cite.num_refs allrefs.tdf allrefs.query_cover Passage QC of references in passage to gures, tables, or citations Passage Is passage in abstract? Passage TF-IDF between passage and table captions Passage Query cover (QC) of referenced table captions Passage Number of references to tables in passage Passage TF-IDF between passage and Passage QC of sentences with references to citations Passage Number of citations in passage Passage TF-IDF to text with refs to gures, tables, or citations allrefs.num_refs Passage Number of references in this passage title.tdf Document TF-IDF between the query and the title title.query_cover Document QC of document title abs.tdf Document TF-IDF between the query and abstract abs.query_cover Document QC of the abstract of the document fulltxt.tdf Document TF-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="7,136.56,504.30,337.66,151.82"><head>Table 4 .</head><label>4</label><figDesc>Figure-Specic Features for Reranking</figDesc><table coords="7,136.56,522.34,337.66,133.77"><row><cell>Feature Name</cell><cell>Type Description</cell></row><row><cell cols="2">g.num_refs g.query_cover g.query_cover_caption g.tdf g.tdf_caption g.psg_caption_overlap g.in_caption g.refs.query_cover g.refs.query_cover_window1 Document QC 1 sentence window around gure-related sentences Passage Number of references to gures in passage Passage QC all gure-related sentences referenced in psg Passage QC of gure captions referenced in this passage Passage TF-IDF to gure related sentences referenced in psg Passage TF-IDF between query and referenced gure captions Passage Overlap between passage and referenced gure caption Passage Is this passage inside of a gure caption? Document QC of gure-related sentences g.refs.query_cover_window2 Document QC 2 sentence window around gure-related sentences g.refs.tdf Document TF-IDF of gure-related sentences g.refs.tdf_window1 Document TF-IDF 1 sentence window around gure-related sents g.refs.tdf_window2 Document TF-IDF 2 sentence window around gure-related sents g.cap.query_cover Document QC of gure captions in document g.cap.tdf Document TF-IDF between query and all gure captions in doc g.refs.has_gs Document Does this document have gures? g.refs.num_gs Document Number of gures in document</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="8,134.77,115.11,345.84,180.90"><head>Table 5 .</head><label>5</label><figDesc>Figure Document Features for Reranking FigDoc Average reciprocal rank of returned gure documents gdoc.maxreciprank FigDoc Maximum reciprocal rank of returned gure documents an important nding of the article. Here, we use the index of gure documents to extract features capturing the essence of ndings. The query is issues against</figDesc><table coords="8,136.56,133.16,296.06,109.34"><row><cell>Feature Name</cell><cell>Type Description</cell></row><row><cell cols="2">gdoc.avgscore gdoc.avgrank gdoc.gcount gdoc.gcount1 gdoc.gcount3 gdoc.gcount5 gdoc.gcount10 gdoc.gcount20 gdoc.gcount50 gdoc.gcount100 FigDoc Number of gure documents returned at rank 100 FigDoc Average score of gure documents for a given document FigDoc Average rank of gure documents for a given document FigDoc Total number of gure document returned FigDoc Number of gure documents returned at rank 1 FigDoc Number of gure documents returned at rank 3 FigDoc Number of gure documents returned at rank 5 FigDoc Number of gure documents returned at rank 10 FigDoc Number of gure documents returned at rank 20 FigDoc Number of gure documents returned at rank 50 gdoc.gcount1000 FigDoc Number of gure documents returned at rank 1000 gdoc.maxscore FigDoc Maximum score of returned gure documents gdoc.minrank FigDoc Minimum rank of returned gure documents gdoc.avgreciprank</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="9,143.73,115.11,327.89,79.58"><head>Table 6 .</head><label>6</label><figDesc>Overview of dierent methods used in the TREC Genomics evaluation.</figDesc><table coords="9,327.06,133.38,95.35,61.31"><row><cell>IR SDM</cell><cell>IR RM</cell><cell>Rerank IR</cell><cell>Rerank Doc</cell><cell>Rerank Fig</cell><cell>Rerank FigDoc</cell><cell>Rerank All</cell><cell>All</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="12,162.52,488.38,290.31,148.34"><head>Table 8 .</head><label>8</label><figDesc>P@10 of snippets returned by irSDM on nine selected queries.</figDesc><table coords="12,241.65,509.15,135.12,127.57"><row><cell>Query</cell><cell>P@10</cell></row><row><cell cols="2">52b2efcb4003448f55000005 0.1</cell></row><row><cell cols="2">52b2e97df828ad283c000012 0.2</cell></row><row><cell cols="2">52b2ed144003448f55000004 0.3</cell></row><row><cell cols="2">52b2ec944003448f55000002 0.6</cell></row><row><cell cols="2">52b06a68f828ad283c000005 0.7</cell></row><row><cell cols="2">52b2e409f828ad283c00000e 0.4</cell></row><row><cell cols="2">52b2ecd34003448f55000003 0.1</cell></row><row><cell cols="2">52b2e1d8f828ad283c00000c 0.2</cell></row><row><cell cols="2">52b2f09f4003448f55000008 0.2</cell></row><row><cell>average</cell><cell>0.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="14,134.77,173.58,345.81,429.49"><head>Table 9 .</head><label>9</label><figDesc>Retrieval parameters used by systems in dierent batches. Systems that only dier in the re-ranking share the same parameter settings. Dirichlet µ SDM Parameters λ uni , λ bi , λ wbi RM Weight ω</figDesc><table coords="14,136.56,219.06,311.82,384.01"><row><cell>UMass-irSDM</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Batch 1</cell><cell>3000</cell><cell>0.58, 0.11, 0.11</cell><cell>0.19</cell></row><row><cell>Batch 2</cell><cell>2500</cell><cell>0.768, 0.004, 0.036</cell><cell>0.26</cell></row><row><cell>Batch 3</cell><cell>2500</cell><cell>0.768, 0.004, 0.036</cell><cell>0.26</cell></row><row><cell>Batch 4</cell><cell>2500</cell><cell>0.768, 0.004, 0.036</cell><cell>0.26</cell></row><row><cell>Batch 5</cell><cell>3000</cell><cell>0.72, 0.12, 0.16</cell><cell>0.005</cell></row><row><cell>Doc-Figdoc-UMLS</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Batch 1</cell><cell>3000</cell><cell>0.58, 0.11, 0.11</cell><cell>0.19</cell></row><row><cell>Batch 2</cell><cell>3000</cell><cell>0.58, 0.11, 0.11</cell><cell>0.19</cell></row><row><cell>Batch 3</cell><cell>2500</cell><cell>0.768, 0.004, 0.036</cell><cell>0.26</cell></row><row><cell>Batch 4</cell><cell>2500</cell><cell>0.768, 0.004, 0.036</cell><cell>0.26</cell></row><row><cell>Batch 5</cell><cell>2500</cell><cell>0.768, 0.004, 0.036</cell><cell>0.26</cell></row><row><cell>All-Figdoc-UMLS</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Batch 1</cell><cell>3000</cell><cell>0.58, 0.11, 0.11</cell><cell>0.19</cell></row><row><cell>Batch 2</cell><cell>3000</cell><cell>0.58, 0.11, 0.11</cell><cell>0.19</cell></row><row><cell>Batch 3</cell><cell>2500</cell><cell>0.768, 0.004, 0.036</cell><cell>0.26</cell></row><row><cell>Batch 4</cell><cell>2500</cell><cell>0.768, 0.004, 0.036</cell><cell>0.26</cell></row><row><cell>Batch 5</cell><cell>2500</cell><cell>0.768, 0.004, 0.036</cell><cell>0.26</cell></row><row><cell>All-Figdoc</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Batch 1</cell><cell>2500</cell><cell>0.768, 0.004, 0.036</cell><cell>0.26</cell></row><row><cell>Batch 2</cell><cell>2500</cell><cell>0.768, 0.004, 0.036</cell><cell>0.26</cell></row><row><cell>Batch 3</cell><cell>2500</cell><cell>0.768, 0.004, 0.036</cell><cell>0.26</cell></row><row><cell>Batch 4</cell><cell>2500</cell><cell>0.768, 0.004, 0.036</cell><cell>0.26</cell></row><row><cell>Batch 5</cell><cell>2500</cell><cell>0.768, 0.004, 0.036</cell><cell>0.26</cell></row><row><cell>All-Abstract-UMLS</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Batch 1</cell><cell>NA</cell><cell>NA</cell><cell>NA</cell></row><row><cell>Batch 2</cell><cell>3000</cell><cell>0.56, -0.04, 0.04</cell><cell>0.36</cell></row><row><cell>Batch 3</cell><cell>3000</cell><cell>0.72, 0.12, 0.16</cell><cell>0.005</cell></row><row><cell>Batch 4</cell><cell>3000</cell><cell>0.56, -0.04, 0.04</cell><cell>0.36</cell></row><row><cell>Batch 5</cell><cell>3000</cell><cell>0.72, 0.12, 0.16</cell><cell>0.005</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="15,136.56,124.57,338.63,121.03"><head>Table 10 .</head><label>10</label><figDesc>Examples of relevant snippets in PMC found within the top 2.</figDesc><table coords="15,136.56,145.97,338.63,99.63"><row><cell>5319abb166e2b80600002f Which growth factors are known to be involved in the induction of EMT?</cell></row><row><cell>in emt induction additionally non-smad signaling pathways activated by tgf-? and cross-talk with other signaling</cell></row><row><cell>pathways including broblast growth factor fgf and tumor necrosis factor-? tnf-? signaling play important</cell></row><row><cell>roles in emt promotion induction of emt in tumor stromal cells by (PMC 22111550, rank 1)</cell></row><row><cell>5319ac18b166e2b806000030 Is clathrin involved in E-cadherin endocytosis?</cell></row><row><cell>plasma membranes we have found here that non-trans-interacting e-cadherin is constitutively endocytosed like</cell></row><row><cell>integrin ligand-independent endocytosis that the formation of endocytosed vesicles of e-cadherin is clathrin</cell></row><row><cell>dependent and that e-cadherin but not other cams at ajs and tjs including nectins claudins and occludin is</cell></row><row><cell>selectively sorted into the endocytosed (PMC 15263019, rank 1)</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="4,144.73,656.01,198.00,9.21"><p>http://people.cs.umass.edu/~vdang/ranklib.html</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work was supported in part by the <rs type="funder">Center for Intelligent Information Retrieval</rs>, in part by <rs type="funder">Umass Medical School</rs> subaward <rs type="grantNumber">RFS2014051</rs> under <rs type="funder">National Institutes of Health</rs> grant <rs type="grantNumber">5R01GM095476-04</rs>. Any opinions, ndings and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reect those of the sponsor.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_PzKqNhF">
					<idno type="grant-number">RFS2014051</idno>
				</org>
				<org type="funding" xml:id="_6qwX364">
					<idno type="grant-number">5R01GM095476-04</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>boost, whereas the dierences between dierent feature sets are neglegible. With a paired-t-test at signicance level α = 5%, we verify that Rerank All and Rerank Doc yield signicant improvements over both IR baselines (despite the overlap in error bars).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Submission to BioASQ</head><p>We restrict all rankings to the top 20 documents, and for each document we provide the best scoring snippet, yielding 20 snippets per system and query. We score snippets with the same retrieval model that we use for document retrieval.</p><p>Inspecting all top 50 documents, for each document we create snippet candidates by a sliding window of 50 terms (shifted by 25 terms) and only return the snippet with the highest score under the expanded retrieval model. The snippets are reranked by the retrieval score under the passage model and we only output the top 20 snippets. This means, that some snippets might stem from new documents.</p><p>The term windows are converted to section IDs and character osets. In the batch 1 submission, we did not incorporate whitespaces and XML formatting correctly. This has been corrected for all remaining batches.</p><p>Table <ref type="table" coords="11,163.94,369.95,4.13,5.89">7</ref>. Overview of dierent systems submitted to the BioASQ evaluation. 'X' denotes that the component was selected in all batches for this system. Components only selected in some batches are indicated with 'B'.</p><p>We modied the some components across dierent submitted batches, to maximize our knowledge gain in the light of the limitation to 5 submission sys-</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="13,138.35,402.82,342.23,9.21;13,146.91,413.78,333.66,9.21;13,146.91,424.74,244.84,9.21" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,233.18,402.82,247.40,9.21;13,146.91,413.78,135.61,9.21">Figsum: automatically generating structured text summaries for gures in biomedical literature</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,302.85,413.78,156.33,9.21">AMIA Annual Symposium Proceedings</title>
		<imprint>
			<publisher>American Medical Informatics Association</publisher>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,138.35,435.70,342.23,9.21;13,146.91,446.66,333.67,9.21;13,146.91,457.62,43.11,9.21" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="13,222.19,435.70,258.39,9.21;13,146.91,446.66,93.12,9.21">The Unied Medical Language System (UMLS): integrating biomedical terminology</title>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Bodenreider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,248.76,446.66,96.45,9.21">Nucleic Acids Research</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="267D" to="270" />
			<date type="published" when="2004-01">Jan 2004</date>
		</imprint>
	</monogr>
	<note>Database issue</note>
</biblStruct>

<biblStruct coords="13,138.35,468.58,342.23,9.21;13,146.91,479.54,333.66,9.21;13,146.91,490.50,333.66,9.21;13,146.91,501.45,172.76,9.21" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,255.85,468.58,131.24,9.21">Relevance based language models</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<idno type="DOI">10.1145/383952.383972</idno>
		<ptr target="http://doi.acm.org/10.1145/383952.383972" />
	</analytic>
	<monogr>
		<title level="m" coord="13,407.37,468.58,73.21,9.21;13,146.91,479.54,333.66,9.21;13,146.91,490.50,82.21,9.21;13,290.18,490.50,39.82,9.21">Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 24th annual international ACM SIGIR conference on Research and development in information retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page">120127</biblScope>
		</imprint>
	</monogr>
	<note>SIGIR &apos;01</note>
</biblStruct>

<biblStruct coords="13,138.35,512.41,342.23,9.21;13,146.91,523.37,290.85,9.21" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="13,354.21,512.41,126.38,9.21;13,146.91,523.37,27.03,9.21">The Unied Medical Language System</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">A</forename><surname>Lindberg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">L</forename><surname>Humphreys</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">T</forename><surname>Mccray</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,181.52,523.37,145.95,9.21">Methods of Information in Medicine</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">281291</biblScope>
			<date type="published" when="1993-08">Aug 1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,138.35,534.33,342.23,9.21;13,146.91,545.29,82.53,9.21" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,211.21,534.33,215.30,9.21">Learning to Rank Figures within a Biomedical Article</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,433.09,534.33,47.49,9.21">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2014">MAR 13 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,138.35,556.25,342.23,9.21;13,146.91,567.21,333.67,9.21;13,146.91,578.17,333.67,9.21;13,146.91,589.13,248.25,9.21" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="13,251.71,556.25,210.60,9.21">A markov random eld model for term dependencies</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<idno type="DOI">10.1145/1076034.1076115</idno>
		<ptr target="http://dx.doi.org/10.1145/1076034.1076115" />
	</analytic>
	<monogr>
		<title level="m" coord="13,146.91,567.21,333.67,9.21;13,146.91,578.17,161.60,9.21;13,366.98,578.17,38.97,9.21">Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 28th annual international ACM SIGIR conference on Research and development in information retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page">472479</biblScope>
		</imprint>
	</monogr>
	<note>SIGIR &apos;05</note>
</biblStruct>

<biblStruct coords="13,138.35,600.08,342.23,9.21;13,146.91,611.04,315.63,9.21" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,250.16,600.08,210.40,9.21">Linear feature-based models for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10791-006-9019-z</idno>
		<ptr target="http://dx.doi.org/10.1007/s10791-006-9019-z" />
	</analytic>
	<monogr>
		<title level="j" coord="13,466.76,600.08,13.82,9.21;13,146.91,611.04,20.62,9.21">Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">257274</biblScope>
			<date type="published" when="2007-06">Jun 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,138.35,622.00,342.23,9.21;13,146.91,632.96,225.82,9.21" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="13,277.02,622.00,203.55,9.21;13,146.91,632.96,92.15,9.21">Automatic gure ranking and user interfacing for intelligent gure search</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">P</forename><surname>Ramesh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,246.05,632.96,41.21,9.21">PLoS One</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page">12983</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
