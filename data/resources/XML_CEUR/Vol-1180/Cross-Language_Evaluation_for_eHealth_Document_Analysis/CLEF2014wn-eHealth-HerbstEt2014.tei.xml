<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,138.05,116.95,339.24,12.62;1,166.45,134.89,282.45,12.62;1,144.48,155.14,326.40,10.52;1,263.15,169.08,89.05,10.52">Applying In-Memory Technology for Automatic Template Filling in the Clinical Domain Working Notes on Task 2 of the ShARe/CLEF eHealth Challenge 2014</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,231.95,205.52,65.14,8.74"><forename type="first">Konrad</forename><surname>Herbst</surname></persName>
							<email>k.herbst@stud.uni-heidelberg.de</email>
							<affiliation key="aff1">
								<orgName type="department">Institute of Pharmacy and Molecular Biotechnology Im</orgName>
								<orgName type="institution">University of Heidelberg</orgName>
								<address>
									<addrLine>Neuenheimer Feld 364</addrLine>
									<postCode>69120</postCode>
									<settlement>Heidelberg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,307.65,205.52,68.53,8.74"><forename type="first">Cindy</forename><surname>FÃ¤hnrich</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Platform and Integration Concepts Chair</orgName>
								<orgName type="institution">Hasso Plattner Institute Enterprise</orgName>
								<address>
									<addrLine>August-Bebel-Str. 88</addrLine>
									<postCode>14482</postCode>
									<settlement>Potsdam</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,204.29,217.48,64.84,8.74"><forename type="first">Mariana</forename><surname>Neves</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Platform and Integration Concepts Chair</orgName>
								<orgName type="institution">Hasso Plattner Institute Enterprise</orgName>
								<address>
									<addrLine>August-Bebel-Str. 88</addrLine>
									<postCode>14482</postCode>
									<settlement>Potsdam</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,299.06,217.48,107.54,8.74"><forename type="first">Matthieu-P</forename><surname>Schapranow</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Platform and Integration Concepts Chair</orgName>
								<orgName type="institution">Hasso Plattner Institute Enterprise</orgName>
								<address>
									<addrLine>August-Bebel-Str. 88</addrLine>
									<postCode>14482</postCode>
									<settlement>Potsdam</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,138.05,116.95,339.24,12.62;1,166.45,134.89,282.45,12.62;1,144.48,155.14,326.40,10.52;1,263.15,169.08,89.05,10.52">Applying In-Memory Technology for Automatic Template Filling in the Clinical Domain Working Notes on Task 2 of the ShARe/CLEF eHealth Challenge 2014</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">879C77617714EDB097DE759BC064C6F2</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Medical Reports</term>
					<term>Template Filling</term>
					<term>In-Memory Technology</term>
					<term>Entity Recognition</term>
					<term>Text Extraction</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We present a research prototype for systematic template filling based on in-memory database technology. Entity extraction and normalization is based on domain-specific dictionaries and customized rules set building on top of related work of the medical field. The prototype called HPI proves feasibility of in-memory technology to enhance workflows in the field of efficient text processing and analysis. With our approach, the iterative process of dictionary and rule refinement for enhancing text analysis results shifts from a time-consuming task with long waiting hours to a continuous workflow. In the context of the challenge's task, our prototype achieves an overall average accuracy of 0.769 and an overall F1 measure of up to 0.323.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Professional health care requires a constant documentation of all patient-related data, such as history of clinical events. This clinical data is stored in a humanreadable format, such as text files, since it supports the daily work of the clinical personnel. This data is only available in an unstructured format, which makes its automatic processing a complex task. However, for the sake of fault prevention, comparison, performance optimization, and subsequent clinical research, the important information must be efficiently extracted from the unstructured data for further processing. This task requires methods from Information Extraction (IE), which is a specific subdomain of Natural Language Processing (NLP).</p><p>The second task of the 2014 CLEF eHealth challenge requires the extraction of information from unstructured clinical data to fill specific templates, i.e. fixed sets of different semantic classes depending on the IE purpose <ref type="bibr" coords="2,420.83,179.82,10.52,8.74" target="#b1">[2,</ref><ref type="bibr" coords="2,435.96,179.82,7.75,8.74" target="#b2">3,</ref><ref type="bibr" coords="2,448.32,179.82,7.01,8.74" target="#b5">6]</ref>. The following classes are required to be identified: Negation Indicator (NI), Subject Class (SC), Uncertainty Indicator (UI), Course Class (CC), Severity Class (SV), Conditional Class (CO), Generic Class (GC), Body Location (BL), Doctime Class (DT), and Temporal Expression (TE). Within these classes, values can be stored either as recognized text span, i.e. where the entity was determined within the input text, or as inferred concept normalization. A lexical cue value describing the found occurrence of the entity within the input text can be determined for all class types except for DT.</p><p>We as team HPI participated in the context of a student internship in this challenge. We designed a research system incorporating lasted In-Memory Database (IMDB) technology to enable systematic filling of templates of the required classes using unstructured data from Electronic Medical Records (EMR). IMDB technology has proven to have major advances for analyzing big enterprise and medical data, e.g. to support medical doctors in identifying better treatments for cancer patients and other fields of life sciences <ref type="bibr" coords="2,406.70,359.19,15.50,8.74" target="#b12">[13,</ref><ref type="bibr" coords="2,425.69,359.19,7.75,8.74" target="#b7">8,</ref><ref type="bibr" coords="2,436.93,359.19,11.62,8.74" target="#b13">14]</ref>. Thus, IMDB supports a) the interactive processing of EMR data, which b) enables fast, iterative design of productive systems for TE and its analysis. We rely on a columnar IMDB and make use of the built-in Text Analysis (TA) functionality for our research prototype. Additionally, we complement data provided for training with additional external data sources and extract relevant entities as described in Sect. 2.1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head><p>In the following, we describe data used in our system, its architectural details, and highlight the advantages of using IMDB technology.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data</head><p>For the training phase, we used a data set of 300 documents taken from version 2.5 of the Multiparameter Intelligent Monitoring in Intensive Care (MIMIC II) database <ref type="bibr" coords="2,192.39,573.38,10.52,8.74" target="#b4">[5,</ref><ref type="bibr" coords="2,206.92,573.38,7.01,8.74" target="#b8">9]</ref>. This data is comprised of a corpus and annotations of deidentified clinical reports from intensive care patients from the United States of America (USA). These reports are classified into four types: discharge summary, echo report, electrocardiogram report, and radiology report. All documents are unstructured text documents, i.e. they are written in natural language without specific formatting.</p><p>In addition to the training data, we integrated the SNOMED Clinical Terms (SNOMED CT) data from the Unified Medical Language System (UMLS) ver-sion 2013AB to improve our entity recognition capabilities for mentions of diseases and body locations <ref type="bibr" coords="3,247.26,131.95,14.61,8.74" target="#b14">[15]</ref>. From this database, we used all concepts with a semantic type that is related to a disease, disorder, or body location. Tab. 2.1 provides a detailed overview of what concepts and semantic types we have incorporated. These concepts sum up to a data set of &gt;183k concepts, i.e. entities that can be used for entity recognition in the training data summing up to more entries than the complete SNOMED CT data set. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Using In-Memory Database Technology for Data Processing</head><p>For accomplishing the challenge's task, we designed a research prototype incorporating the latest IMDB technology. It enables us to store and process structured and unstructured data within a single system as it has several building blocks as presented by Plattner <ref type="bibr" coords="4,245.02,131.95,9.96,8.74" target="#b6">[7]</ref>. In the following paragraphs, we introduce selected building blocks and how we benefit from them for accomplishing our task.</p><p>Relevant Data Kept in Main Memory IMDB technology enables fast access of required data directly from main memory. This contrasts to most traditional approaches processing data from files that reside on disk space and must be loaded into main memory. When thinking of the ever-increasing amounts of data, this strategy will not be feasible anymore in the long run. Therefore, IMDB technology offers us an alternative processing strategy that addresses performance requirements of our application.</p><p>Lightweight Compression Those techniques refer to a data storage representation that consumes less space than its original pendant. A columnar database storage layout supports such lightweight compression techniques, e.g. dictionary encoding which maps all unique values to a uniform format <ref type="bibr" coords="4,388.62,310.84,9.96,8.74" target="#b6">[7]</ref>. For example, suppose we have a list of people as data set where one column contains the gender. For this column, there exist only two unique values, i.e. "male" and "female". With dictionary encoding, these two values are mapped to integer representations, e.g. "male"=1 and "female"=2, and stored in the column instead of the original values. This requires less storage space and also reduces the amount of data that has to be transferred from and to main memory.</p><p>Multi-Core and Parallelization Modern system architectures are designed to provide multiple CPUs with each of them having separate cores. This capacity should be fully exploited by parallelizing application execution to achieve maximum processing speed. The incorporated IMDB platform supports this and provides built-in parallelization. With that, we do not need to apply parallelization strategies on our own but still have maximum runtime performance in processing our input data.</p><p>Entity and Feature Extraction Any kinds of text, such as the medical reports that have to be processed in this challenge, are considered as unstructured data. Thus, it cannot be processed automatically unless a machine-readable data model exists for automatic interpretation, e.g. a semantic ontology. Our incorporated IMDB platform offers a range of features for text processing, of which the relevant ones for us are those for entity and feature extraction. Entity and feature extraction refers to the identification of relevant keywords and names of entities from documents. Dictionaries and individual extraction rules can customize this. Dictionaries list one or more entity types, each of which containing any number of entities that in turn contain a standard form name and any number of synonyms. Extraction rules use formal syntax to define entities of a specific type. This allows formulating patterns that match tokens by using a literal string, a regular expression, a word stem, or a word's part of speech.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">System Design</head><p>Fig. <ref type="figure" coords="5,154.52,139.35,4.98,8.74">1</ref> presents our system architecture in Functional Modeling Concepts (FMC) notation <ref type="bibr" coords="5,174.55,151.30,9.96,8.74" target="#b3">[4]</ref>. Medical reports as test data and a dictionary that has been generated from the training data in advance serve as input for our system. This data is imported once into our IMDB. The input template documents must now be automatically filled with concrete values for cue and normalization attributes.</p><p>The system itself is divided into two components: Our IMDB platform, which performs among others linguistic pre-processing tasks, e.g. entity extraction via dictionaries, and a Python module for template filling.</p><p>In-Memory Database Relevant data is imported into our IMDB. The data is comprised of the medical reports whose templates must be filled, the SNOMED CT subset, and a list for each slot type with entities that have been extracted from the training data before. From this data, we create scientific medical dictionaries and add individual extraction rules to facilitate entity recognition and extraction of the different slot types.</p><p>Dictionaries We build customized dictionaries to identify slot types NI, SC, UI, CC, SV, CO, GC, BL, and TE in the given medical reports. For extraction and normalization of DD and BL slot types, we compile a dictionary based on the imported SNOMED CT data set. Entities of remaining slot types are extracted and normalized by a dictionary derived from training data. Fig. <ref type="figure" coords="5,470.65,383.29,9.96,8.74" target="#fig_0">2a</ref> depicts such a dictionary in XML format. Entities can easily be organized into categories, normalized by a standard form and enriched by additional variant definitions. The given example lists the semantic type Body Part, Organ, or Organ Component in blue letters. Afterwards, the concept definition with its normalization, i.e., the standard form, is defined in black letters. Finally, possible entities owning the defined normalization are listed in yellow letters. As a result, the phrase skeletal muscle structure of abdomen has the normalization C0000739 and will be assigned to the BL slot type when detected in any text document.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CGUL Rules</head><p>We define extraction rules in Custom Grouper User Language (CGUL) to identify DT slot types <ref type="bibr" coords="5,295.48,514.22,14.61,8.74" target="#b10">[11]</ref>. CGUL is a sentence-based language that allows pattern matching by using character or token-based regular expressions combined with linguistic attributes to define custom entity types. Fig. <ref type="figure" coords="5,470.08,538.13,10.52,8.74" target="#fig_0">2b</ref> shows two example CGUL rules for extracting entities that have before and before overlap as normalization. By using Part-of-Speech (POS) tags in the rules, we can access and extract the grammatical tense of a sentence. In the given examples highlighted in purple color, we want to identify structures that first contain a noun (Nn) after which comes a verb in either past (V-Past) or past participle (V-PaPart) tense. Means to identify nouns, verbs, and tenses are provided by default by our IMDB platform.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Entity Recognition and Extraction</head><p>With the created dictionaries and CGUL rules at hand, we can trigger the actual process of entity extraction within our IMDB.</p><p>Fig. <ref type="figure" coords="6,153.45,571.22,3.87,8.74">1</ref>: Architecture of our research prototype in Fundamental Modeling Concepts (FMC) notation. In addition to small preprocessing steps of dictionary creation and data import, our prototype consists of the two main components In-Memory Database (IMDB) and a Template Filling Engine. Main processing is conducted inside these two components. For that, we create a full text index on the medical reports for which we have to fill out the templates <ref type="bibr" coords="8,229.74,131.95,14.61,8.74" target="#b9">[10]</ref>. The full text index is automatically managed by our IMDB, which performs linguistic processing, i.e., language and encoding identification, segmentation, case normalization, stemming, and tagging, and entity and fact extraction based on the provided dictionaries and CGUL rules <ref type="bibr" coords="8,442.48,167.81,14.61,8.74" target="#b11">[12]</ref>. The result of this process is a dedicated database table that contains the extracted entities that have been found in the medical reports, their normalization, slot type, and location within the document. These details can be directly used for template filling.</p><p>Template Filling Our template filling engine is based on Python v. 2.7.7 and takes extracted entities together with their normalization, slot type, medical report it occurred in, and location within the medical report, i.e. text spans, as input. These details are associated to the corresponding templates, which requires matching the text spans identified by our approach. The DD mentions provided by default in the test data are used as "anchor" to determine entities of the same template. If this has been accomplished, the templates are filled with the corresponding cues and normalizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Conducted Experiments</head><p>In the following, we present experiments conducted in terms of data and evaluation metrics used. We provide experiment results according to the presented metrics and discuss relevant findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Data and Metrics Used</head><p>For evaluating the performance of our system, we used a test data set provided by the challenge. Analogously to the initial training data, this data set is comprised of a set of 133 medical reports with template documents assigned. In contrast to the training data, the templates' attributes, i.e. cue and normalization values for each slot type, are empty. In our experiments, we aim at filling both cue and normalization values and by that to participate in tasks 2a and b of the challenge.</p><p>We use accuracy and F 1 measure as common measures used in pattern recognition and information retrieval for evaluation of the derived normalization and cue values, respectively <ref type="bibr" coords="8,239.17,578.82,9.96,8.74" target="#b0">[1]</ref>. We determine performance for the overall result set and per slot type. Eq. 1 defines the computation of accuracy for a given set of normalization values N as fraction of the amount of slot values for which a correct normalization has been derived and the overall amount of slot values for which a normalization has been derived.</p><formula xml:id="formula_0" coords="8,250.87,646.03,229.72,22.31">Accuracy(N ) = |N correct | |N |<label>(1)</label></formula><p>Eq. 2, Eq. 3, and Eq. 4 depict computation of F1 measure to assess quality of the detected cue values, which is the harmonic mean of precision and recall. With regards to examining performance for a concrete slot type or their overall set, C is the set of all cue values detected by our approach, whereas C true contains all true cue values. C correct is the set of all cue values that have been correctly identified by our approach and is also expressed as C correct = C true â© C. The definition of the term "correct" varies for strict and relaxed evaluation. The former checks if a derived cue value equals the correct one, whereas the latter still considers a cue value as correct if it overlaps with the true value. Precision depicts the fraction of retrieved instances that are relevant, i.e., in this context how many of the true cue values have been identified by our approach. Recall depicts the fraction of relevant instances that are retrieved, i.e. how many of the cue values identified by our approach are contained in the set of "true" cue values.</p><formula xml:id="formula_1" coords="9,220.34,297.66,260.25,22.31">F 1 (C) = 2 Ã Recall(C) Ã P recision(C) Recall(C) + P recision(C)<label>(2)</label></formula><formula xml:id="formula_2" coords="9,229.55,330.92,251.04,23.23">Recall(C) = |C correct | |C correct | + |C true \ C|<label>(3)</label></formula><formula xml:id="formula_3" coords="9,221.72,364.18,258.87,23.23">P recision(C) = |C correct | |C correct | + |C \ C true |<label>(4)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results and Discussion</head><p>Table <ref type="table" coords="9,162.45,460.11,3.87,8.74">2</ref>: Summarized results for task 2a with results for accuracy, F 1 measure, precision, and recall. The results achieved by our prototype are summarized in Tab. 3.2 and Tab. 3.2 for tasks 2a and 2b, respectively. For many of the slots, our results for task 2b, i.e. cue values derived, were quite lower than the ones obtained for task 2a, i.e. normalized values derived. For instance, we achieved 90-100 percent of accuracy for the slot types CC and GC, but only 21 and 14 percent F 1 -measure, respectively, for the relaxed evaluation of task 2b. Although this is expected, as exact (or relaxed) mention spans are harder to be correctly extracted than the corresponding normalized values, we still investigate possible mistakes on the offsets in our submissions and future error analysis will shed some light on the discrepancies between the results for both tasks.</p><p>Our strategy for the BL slot, which had relied on the dictionaries derived from the SNOMED CT terminology, achieved 50 percent of accuracy. A future error analysis will also show whether false negatives were due to concepts that are not present in the SNOMED CT terminology, to missing synonyms for existing concepts or on the matching approach that was used. Nevertheless, the relaxed evaluation of task 2b shows that our dictionary matching approach provides good precision, i.e. 60 percent, given the complexity of the anatomical nomenclature.</p><p>Extraction of values for slot type DT was a hard task and results were quite low for all teams. This is because it requires a more careful analysis of the language, such as analyzing verb tenses and time expressions. However, we believe that our approach of using CGUL rules is appropriate for extracting this information but more rules should be created for this purposes as well as a revision of the existing ones.</p><p>Therefore, the used dictionaries and rules instead of the underlying IMDB system induce the presented results. If those dictionaries are refined, e.g. by including other data sources than SNOMED CT or adapting extraction rules, we are convinced that the overall performance of our system will improve.</p><p>However, the focus of this work is rather on showing the general applicability and feasibility of in-memory technology for processes that involve processing and analysis of unstructured text. One iteration to improve text analysis results, starting with refining dictionaries and ending with receiving the final results, i.e. the filled templates from the test data, takes minutes with our system instead of hours or days with traditional approaches. This proves that in-memory technology provides advantages also for the field of information extraction and can contribute to establishing efficient and alternative processing strategies in that area.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>The ShARe/CLEF eHealth challenge 2014 aims to facilitate the research on information extraction within the biomedical domain. As follow-up to 2013's challenge, participants were asked to identify semantically related mentions to disorder mentions and fill out templates with normalization and cue values for the detected entities.</p><p>In the context of a student internship, we designed a research prototype for entity extraction based on IMDB technology that proves feasibility for efficient text processing. Evaluation results show that our rules and dictionaries currently applied require optimization by refining dictionaries or extraction rules. However, our prototype allows us to extend existing extraction rules and dictionaries in a constant manner and to verify them instantly. Thus, the task of iterative improvement of text analysis results becomes a continuous process.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="7,134.77,510.14,345.84,8.74;7,134.77,522.09,345.83,8.74;7,134.77,534.05,345.84,8.74;7,134.77,546.00,345.84,8.74;7,134.77,557.96,28.89,8.74;7,134.77,381.01,345.83,100.66"><head>Fig. 2 :</head><label>2</label><figDesc>Fig.2: Examples for (a) dictionary entry and (b) CGUL rules for entity recognition. An entry in a dictionary is comprised of the slot type, its normalization format and concrete entities listed. CGUL rules allow entity recognition via matching lexicographical patterns, e.g. by identifying nouns (Nn), verbs (V), or tenses.</figDesc><graphic coords="7,134.77,381.01,345.83,100.66" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,134.77,234.38,345.84,334.42"><head>Table 1 :</head><label>1</label><figDesc>Overview of the SNOMED CT subset incorporated in our research prototype. We selected concepts assigned to semantic types that are either related to Diseases/Disorders (DD) or Body Locations (BL). The overall amount of concepts used from SNOMED CT sums up to &gt;183k concepts that are used for entity recognition in the training data.</figDesc><table coords="3,179.39,307.69,238.06,261.11"><row><cell>Semantic Type (Slot Type)</cell><cell># Concepts</cell></row><row><cell>Disease or Syndrome (DD)</cell><cell>34,600</cell></row><row><cell>Injury or Poisoning (DD)</cell><cell>26,703</cell></row><row><cell>Neoplastic Process (DD)</cell><cell>9,082</cell></row><row><cell>Congenital Abnormality (DD)</cell><cell>6,337</cell></row><row><cell>Pathologic Function (DD)</cell><cell>5,364</cell></row><row><cell>Mental or Behavioral Dysfunction (DD)</cell><cell>2,745</cell></row><row><cell>Signs and Symptoms (DD)</cell><cell>2,734</cell></row><row><cell>Acquired Abnormality (DD)</cell><cell>1,795</cell></row><row><cell>Anatomical Abnormality (DD)</cell><cell>1,475</cell></row><row><cell>Cell or Molecular Dysfunction (DD)</cell><cell>382</cell></row><row><cell>Experimental Model of Disease (DD)</cell><cell>3</cell></row><row><cell>Body Part, Organ, or Organ Component (BL)</cell><cell>59,027</cell></row><row><cell>Body Location or Region (BL)</cell><cell>10,797</cell></row><row><cell>Body Space or Junction (BL)</cell><cell>6,994</cell></row><row><cell>Tissue (BL)</cell><cell>4,130</cell></row><row><cell>Body Substance (BL)</cell><cell>2,793</cell></row><row><cell>Cell (BL)</cell><cell>2,602</cell></row><row><cell>Cell Component (BL)</cell><cell>2,602</cell></row><row><cell>Embryonic Structure (BL)</cell><cell>2,110</cell></row><row><cell>Body System (BL)</cell><cell>787</cell></row><row><cell>Anatomical Structure (BL)</cell><cell>111</cell></row><row><cell>Fully Formed Anatomical Structure (BL)</cell><cell>8</cell></row><row><cell>Total</cell><cell>183,181</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="10,134.77,128.36,345.83,166.65"><head>Table 3 :</head><label>3</label><figDesc>Summarized results for task 2b with results for F 1 measure, precision, and recall for both strict and relaxed evaluation.</figDesc><table coords="10,191.49,165.80,227.80,129.21"><row><cell cols="2">Cue Slot Type F1 Measure</cell><cell>Precision</cell><cell>Recall</cell></row><row><cell></cell><cell cols="3">strict relaxed strict relaxed strict relaxed</cell></row><row><cell>Cue BL</cell><cell cols="3">0.098 0.363 0.165 0.611 0.070 0.258</cell></row><row><cell>Cue CC</cell><cell cols="3">0.210 0.283 0.145 0.196 0.378 0.510</cell></row><row><cell>Cue CO</cell><cell cols="3">0.076 0.317 0.050 0.209 0.157 0.658</cell></row><row><cell>Cue GC</cell><cell cols="3">0.096 0.139 0.056 0.081 0.325 0.470</cell></row><row><cell>Cue NI</cell><cell cols="3">0.332 0.465 0.349 0.488 0.317 0.444</cell></row><row><cell>Cue SC</cell><cell cols="3">0.100 0.151 0.057 0.086 0.411 0.620</cell></row><row><cell>Cue SV</cell><cell cols="3">0.345 0.396 0.293 0.336 0.420 0.483</cell></row><row><cell>Cue TE</cell><cell cols="3">0.000 0.000 0.000 0.000 0.000 0.000</cell></row><row><cell>Cue UI</cell><cell cols="3">0.138 0.306 0.094 0.209 0.258 0.572</cell></row><row><cell>Overall</cell><cell cols="3">0.159 0.323 0.154 0.314 0.163 0.332</cell></row></table></figure>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="12,143.62,171.80,336.98,8.74;12,152.48,183.75,328.13,8.74;12,152.48,195.71,67.58,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,262.69,171.80,217.92,8.74;12,152.48,183.75,96.35,8.74">Quality and Complexity Measures for Data Linkage and Deduplication</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Christen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Goiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,272.18,183.75,145.24,8.74">Quality Measures in Data Mining</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="127" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,143.62,207.66,336.98,8.74;12,152.48,219.62,124.59,8.74" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="12,245.03,207.66,235.58,8.74;12,152.48,219.62,124.59,8.74">The ShARe Schema for the Syntactic and Semantic Annotation of Clinical Texts</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Elhadad</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="12,143.62,231.57,336.98,8.74;12,152.48,243.53,67.61,8.74" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<title level="m" coord="12,237.57,231.57,205.89,8.74">ShARe/CLEF eHealth Evaluation Lab 2014</title>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,143.62,255.48,336.99,8.74;12,152.48,267.44,285.63,8.74" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="12,317.07,255.48,163.54,8.74;12,152.48,267.44,162.24,8.74">Fundamental Modeling Concepts: Effective Communication of IT Systems</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>KnÃ¶pfel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Grone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Tabeling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,143.62,279.39,336.98,8.74;12,152.48,291.35,328.13,9.02;12,152.48,303.30,142.58,8.74" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="12,279.06,279.39,201.54,8.74;12,152.48,291.35,42.62,8.74">Task 2 Data Set of the ShARe/CLEF eHealth Challenge</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">L</forename><surname>Mowery</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Velupillai</surname></persName>
		</author>
		<ptr target="http://clefehealth2014.dcu.ie/task-2/2014-dataset" />
		<imprint>
			<date type="published" when="2014-06">2014. Jun, 2014. Jun 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,143.62,315.26,336.99,8.74;12,152.48,327.21,328.12,9.02;12,152.48,339.17,23.80,8.74" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="12,277.92,315.26,202.69,8.74">Task 2: ShARe/CLEF eHealth Evaluation Lab</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">L</forename><surname>Mowery</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Velupillai</surname></persName>
		</author>
		<ptr target="http://clefehealth2014.dcu.ie/task-2" />
		<imprint>
			<date type="published" when="2014-06">2014. Jun, 2014. Jun 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,143.62,351.12,336.98,8.74;12,152.48,363.08,256.16,8.74" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="12,213.36,351.12,267.24,8.74;12,152.48,363.08,140.09,8.74">A Course in In-Memory Data Management: The Inner Mechanics of In-Memory Databases</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Plattner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013">2013</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>1st edn.</note>
</biblStruct>

<biblStruct coords="12,143.62,375.03,336.99,8.74;12,152.48,386.99,328.13,8.74;12,152.48,398.94,201.23,8.74" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="12,345.86,375.03,134.74,8.74;12,152.48,386.99,328.13,8.74;12,152.48,398.94,94.66,8.74">High-Performance In-Memory Genome Data Analysis: How In-Memory Database Technology Accelerates Personalized Medicine</title>
		<editor>Plattner, H., Schapranow, M.P.</editor>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,143.62,410.90,336.98,8.74;12,152.48,422.85,328.13,8.74;12,152.48,434.81,65.86,8.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,232.28,410.90,248.33,8.74;12,152.48,422.85,203.36,8.74">Multiparameter Intelligent Monitoring in Intensive Care II (MIMIC-II): A Public-Access ICU Database</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Saeed</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,364.25,422.85,99.99,8.74">Clinical Care Medicine</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="952" to="960" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,143.25,446.76,337.34,9.02;12,152.48,458.72,328.12,9.02;12,152.48,470.68,131.48,8.74" xml:id="b9">
	<monogr>
		<ptr target="http://help.sap.de/hana/SAP_HANA_SQL_and_System_Views_Reference_en.pdf" />
		<title level="m" coord="12,199.09,446.76,209.75,8.74">SAP HANA SQL and System Views Reference</title>
		<imprint>
			<date type="published" when="2011-06">Jun, 2014. Jun 2011</date>
		</imprint>
		<respStmt>
			<orgName>SAP AG</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="12,143.25,482.63,337.35,8.74;12,152.48,495.30,308.60,8.30;12,152.48,506.54,313.27,9.02" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G</forename><surname>Sap</surname></persName>
		</author>
		<ptr target="https://help.sap.com/businessobject/product_guides/boexir4/en/sbo401_ds_tdp_lang_ref_en.pdf" />
		<title level="m" coord="12,215.98,482.63,259.82,8.74">Text Data Processing Language Reference Guide</title>
		<imprint>
			<date type="published" when="2011-06">Jun, 2014. Jun 2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,143.25,518.50,337.35,8.74;12,152.48,530.45,328.13,9.02;12,152.48,542.41,263.88,9.02" xml:id="b11">
	<monogr>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">G</forename><surname>Sap</surname></persName>
		</author>
		<ptr target="http://help.sap.com/hana/SAP_HANA_Text_Analysis_Language_Reference_Guide_en.pdf" />
		<title level="m" coord="12,204.35,518.50,276.25,8.74;12,152.48,530.45,11.62,8.74">SAP HANA Text Analysis Language Reference Guide V. 1.0</title>
		<imprint>
			<date type="published" when="2014-05">Jun, 2014. May 2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,143.25,554.36,337.35,8.74;12,152.48,566.32,328.12,8.74;12,152.48,578.27,294.74,8.74" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="12,270.99,554.36,209.62,8.74;12,152.48,566.32,237.45,8.74">Mobile Real-time Analysis of Patient Data for Advanced Decision Support in Personalized Medicine</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">P</forename><surname>Schapranow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,415.90,566.32,64.71,8.74;12,152.48,578.27,263.74,8.74">Proceedings of the 5th Int&apos;l Conf on eHealth, Telemed, and Social Medicine</title>
		<meeting>the 5th Int&apos;l Conf on eHealth, Telemed, and Social Medicine</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,143.25,590.23,337.36,8.74;12,152.48,602.18,328.13,8.74;12,152.48,614.14,128.88,8.74" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="12,468.16,590.23,12.45,8.74;12,152.48,602.18,279.16,8.74">In-Memory Computing Enabling Real-time Genome Data Analysis</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">P</forename><surname>Schapranow</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>HÃ¤ger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>FÃ¤hnrich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Plattner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,439.59,602.18,41.02,8.74;12,152.48,614.14,66.89,8.74">Advances in Life Sciences</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,143.25,626.09,337.35,8.74;12,152.48,638.05,328.12,9.02;12,152.48,650.00,44.42,8.74" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="12,177.47,626.09,303.14,8.74;12,152.48,638.05,33.33,8.74">National Library of Medicine: Unified Medical Language System (UMLS)</title>
		<author>
			<persName coords=""><forename type="first">U</forename><forename type="middle">S</forename></persName>
		</author>
		<ptr target="http://www.nlm.nih.gov/research/umls/" />
		<imprint>
			<date type="published" when="2013-07">Jun, 2014. Jul 2013</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
