<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,342.78,116.95,114.63,12.62;1,165.61,134.89,284.13,12.62;1,236.64,152.82,142.09,12.62">eHealth 2014: A Learning-to-Rank Approach for Medical Document Retrieval</title>
				<funder ref="#_tNkrWaK">
					<orgName type="full">Natural Sciences &amp; Engineering Research Council</orgName>
					<orgName type="abbreviated">NSERC</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,244.17,191.07,43.03,8.74"><forename type="first">Jiajin</forename><surname>Wu</surname></persName>
						</author>
						<author role="corresp">
							<persName coords="1,309.89,191.07,61.30,8.74"><forename type="first">Jimmy</forename><surname>Huang</surname></persName>
							<email>jhuang@yorku.ca</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">York University at CLEF</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">School of Information Technology</orgName>
								<orgName type="laboratory">Information Retrieval and Knowledge Management Research Lab</orgName>
								<orgName type="institution">York University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,342.78,116.95,114.63,12.62;1,165.61,134.89,284.13,12.62;1,236.64,152.82,142.09,12.62">eHealth 2014: A Learning-to-Rank Approach for Medical Document Retrieval</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D9D9E5A56BDCDD8AD2C3BD787D86B180</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We used learning-to-rank methods for training ranking model. Due to the limited number of training queries, we split them and conducted 5-fold cross validation. We set the proportion of training and testing as 4 : 6. For the features used in learning the model, a total of 231 features that are from multiple information retrieval models with different parameter settings were adopted. For the baseline run, we used Random Forest method to train the models with 5-fold cross validation. Only the binary relevance information were taken into account while training the model. Five trained models from 5-fold cross validation were used on the testing data to predict scores, and then we used equal weights to linearly combine the results given by different models. For run #5, we used 8 learning to rank methods to train models separately and linearly combine them together, and the binary relevance judgment was used as well. For run #6 and #7, graded relevance were taken into consideration. The difference between run 6# and #7 is that for run #6, multiple learning-to-rank methods were used while for run #7, only Random Forest method was used. The best result of the four runs is achieved by run #5, which used multiple models combination based on binary relevance judgment.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>These working notes serve to present the experimental method presented by YorkU in the CLEF eHealth 2014 task 3a <ref type="bibr" coords="1,314.22,573.43,10.52,8.74" target="#b6">[7]</ref> which consists of retrieving relevant medical documents for the user queries. Five training queries and fifty testing queries were provided in the task. The goal of the task is to retrieve relevant documents from approximate one million medical documents for the user queries. For more details about this task and related tasks, please refer to <ref type="bibr" coords="1,417.90,621.25,14.61,8.74" target="#b9">[10]</ref>. Our main objective in performing this task is to provide a solution that requires no manual tuning of parameters. Secondly, we want to test the performance of learning-torank <ref type="bibr" coords="1,158.13,657.11,15.50,8.74" target="#b10">[11]</ref> method in medical document retrieval.</p><p>To achieve the main goal, we used supervised learning-to-rank method based on the provided five training queries to train the models. Due to the limitedness of training dataset, we used various strategies to combine the trained models and tested on the testing set in order to get balanced results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Learning-to-Rank</head><p>Learning-to-rank is a new type of method in information retrieval (IR), which has been merged in the past decade. Different from traditional ranking models in IR, learning-to-rank adopts machine learning approaches to solve the ranking problem. Similarly to other machine learning methods, learning-to-rank methods are based on features and in most cases are supervised methods, which means labeled training data is required. One edge of this type of methods is that it saves the pain for tuning parameters which is usually time consuming and tedious in traditional IR models. In the previous study of medical IR, traditional IR models were used extensively <ref type="bibr" coords="2,231.49,340.77,9.96,8.74" target="#b3">[4]</ref>, <ref type="bibr" coords="2,248.10,340.77,9.96,8.74" target="#b8">[9]</ref>, but learning-to-rank has rarely been studied.</p><p>In this work, we used an in-house IR platform to do first pass retrieval for the training dataset. Multiple retrieval models with different parameter settings were used to retrieve relevant documents for the training queries. Based on the qrels information (relevance judgment) for the five training queries provided in the task dataset, and the retrieval results from first pass retrieval, the candidate training documents were selected. Only those documents appearing in the qrels and has more than m non-zero scores from the n retrieval results were selected. Where n stands for the total number of retrieval models accounting same retrieval model with different parameter settings as different models. n in this work is 231, and m was chosen as 180. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset</head><p>We only participated in task 3a, which is a standard TREC-style IR task using (a) the 2012 crawl of approximately one million medical documents made available by the EU-FP7 Khresmoi project<ref type="foot" coords="3,306.09,178.54,3.97,6.12" target="#foot_0">1</ref> in plain text form which was used in CLEF eHealth 2013's Task 3 and (b) a new 2014 set of English general public queries that individuals may realistically pose based on the content of their discharge summaries. This collection contains documents covering a broad set of medical topics, and does not contain any patient information. The documents in the collection come from several online sources, including the Health On the Net organization certified websites, as well as well-known medical sites and databases (e.g. Genetics Home Reference, ClinicalTrial.gov, Diagnosia). Queries are generated from the discharge summaries used in Tasks 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Metric</head><p>Evaluation will focus on P@5, P@10, NDCG@5, NDCG@10, but other suitable IR evaluation measures will also be computed for the submitted runs (eg. MAP). P@N indicates the percentage of relevant documents within the top N results. NDCG <ref type="bibr" coords="3,168.68,353.82,10.52,8.74" target="#b7">[8]</ref> stands for normalized discounted cumulative gain, which is another common metric for evaluating models in information retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Baseline Run</head><p>As the baseline run, only title and description in the query can be used and no external resource (including discharge summary, corpora, ontology, etc) can be used. To keep it simple, we used single learning-to-rank model based on the binary relevance judgment to train our model. So far there are plenty of methods in the literature, and we chose to use RankLib <ref type="foot" coords="3,334.07,460.19,3.97,6.12" target="#foot_1">2</ref> , an open source learning-to-rank package which implements eight popular algorithms: MART <ref type="bibr" coords="3,406.72,473.72,9.96,8.74" target="#b5">[6]</ref>, RankNet <ref type="bibr" coords="3,467.32,473.72,9.96,8.74" target="#b1">[2]</ref>, RankBoost <ref type="bibr" coords="3,185.71,485.67,9.96,8.74" target="#b4">[5]</ref>, AdaRank <ref type="bibr" coords="3,245.56,485.67,14.61,8.74" target="#b13">[14]</ref>, Coordinate Ascent <ref type="bibr" coords="3,349.89,485.67,14.61,8.74" target="#b11">[12]</ref>, LambdaMART <ref type="bibr" coords="3,439.48,485.67,14.61,8.74" target="#b12">[13]</ref>, List-Net <ref type="bibr" coords="3,153.94,497.63,10.52,8.74" target="#b2">[3]</ref> and Random Forests <ref type="bibr" coords="3,261.47,497.63,9.96,8.74" target="#b0">[1]</ref>. So our concern is that which algorithm should be chosen as baseline method.</p><p>For this sake, we conducted five-fold cross validation using all the eight algorithms on training dataset. Table <ref type="table" coords="3,284.13,533.49,4.98,8.74">2</ref> lists the cross validation setting, where the number represents the id of training queries.</p><p>The model that was used as baseline method is Random Forest, which achieved the best average result over the five folds in terms of precision at 10.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Other Runs</head><p>As our run #5, multiple models binary relevance (MMBR) run trained models using all eight methods with the same five-fold cross validation setting as baseline As run #6, multiple models graded relevance (MMGR) run trained models in the same way as MMBR, only different in that using graded relevance of training data. As run #7, single model graded relevance run trained model using Random Forest on five-fold cross validation. For MMBR and MMGR, the combination of multiple models are required. Since the scores range given by different models vary, the combination was conducted on top of normalization of the scores. We rescaled ranking scores to the range of [0 -1] using Formula 1,</p><formula xml:id="formula_0" coords="4,263.72,597.68,212.62,23.23">X = X -X min X max -X min (<label>1</label></formula><formula xml:id="formula_1" coords="4,476.35,604.41,4.24,8.74">)</formula><p>where X is the normalized score, X the original score, X min and X max the minimal and maximal of the scores given by the model for that particular query. The performance comparison of the four submitted runs is shown in Figure <ref type="figure" coords="4,472.85,657.11,3.87,8.74">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion</head><p>As is seen in Figure <ref type="figure" coords="5,231.93,158.24,3.87,8.74">1</ref>, the best result was achieved by run #5. Notice the difference between baseline run and run #5 is that baseline run is based on single model, while run #5 uses combination of multiple models. This shows that the single model, even though it achieves the best result in training dataset, is not better than the linear equal weights combination of multiple models in the testing dataset. Baseline run and run #5 are relatively better than the other two runs. The main difference is that baseline run and run #5 are trained using binary relevance judgment, while run #6 and run #7 are trained using graded relevance judgment. This somewhat surprises us in that, the graded relevance provides more information to the learning-to-rank model about the ranking of documents, thus naturally should result in a better ranking model. But the result is contrary to this intuition. We attribute this to that the more relevance information confuses the learning models due to the shortage of training queries rather than being beneficial for the model learning.</p><p>The comparison of our best result (run #5) with the median results of all submitted runs is shown in Figure <ref type="figure" coords="6,288.30,131.95,3.87,8.74" target="#fig_1">2</ref>. It shows that, on approximate half of the queries, our best result is comparable to other systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>In this paper, we describe our methods for medical document retrieval for task 3 in CLEF eHealth 2014. Based on supervised learning-to-rank methods, we have developed four strategies to conduct our experiments. The combination of multiple models using binary relevance judgment is more preferable than others. In the future, we plan to further research learning-to-rank in medical document retrieval, for example, 1) how domain specific features could benefit the model training, 2) how could unlabeled data be assistant in building ranking model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,134.77,428.59,345.81,7.89;4,134.77,439.58,194.82,7.86;4,134.77,217.52,378.09,196.30"><head>Table 2 . 4 Fig. 1 .</head><label>241</label><figDesc>Fig. 1. Comparison of average precision, precision at 10 and normalized discounted cumulative gain at 10 results for submitted runs</figDesc><graphic coords="4,134.77,217.52,378.09,196.30" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,166.62,521.95,282.10,7.89;5,134.77,255.18,358.40,252.00"><head>Fig. 2 .</head><label>2</label><figDesc>Fig. 2. Per-topic comparison between Run #5 and the other systems.</figDesc><graphic coords="5,134.77,255.18,358.40,252.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,246.86,501.86,121.64,96.81"><head>Table 1 .</head><label>1</label><figDesc>Training dataset</figDesc><table coords="2,246.86,522.66,121.64,76.01"><row><cell cols="3">Query # relevant # irrelevant</cell></row><row><cell>1</cell><cell>23</cell><cell>18</cell></row><row><cell>2</cell><cell>25</cell><cell>17</cell></row><row><cell>3</cell><cell>37</cell><cell>13</cell></row><row><cell>4</cell><cell>31</cell><cell>10</cell></row><row><cell>5</cell><cell>18</cell><cell>22</cell></row><row><cell>total</cell><cell>134</cell><cell>80</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="2,134.77,633.20,345.84,32.65"><head>Table 1</head><label>1</label><figDesc>lists the numbers of relevant/irrelevant documents provided by the dataset. As is show in this table, the available documents for training are quite limited.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,144.73,646.84,104.00,7.86"><p>http://www.khresmoi.eu/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,144.73,657.80,195.50,7.86"><p>http://people.cs.umass.edu/ vdang/ranklib.html</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This research is supported by the research grant from the <rs type="funder">Natural Sciences &amp; Engineering Research Council (NSERC) of Canada</rs> and the <rs type="grantName">Early Researcher Award/Premier's Research Excellence Award</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_tNkrWaK">
					<orgName type="grant-name">Early Researcher Award/Premier&apos;s Research Excellence Award</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,142.96,423.22,277.13,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,203.75,423.22,61.96,7.86">Random forests</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,273.37,423.22,70.86,7.86">Machine Learning</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="32" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,434.74,337.62,7.86;6,151.52,445.70,329.06,7.86;6,151.52,456.66,329.07,7.86;6,151.52,467.61,92.40,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,184.16,445.70,161.69,7.86">Learning to rank using gradient descent</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Shaked</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Renshaw</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Lazier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Deeds</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Hullender</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,367.33,445.70,113.26,7.86;6,151.52,456.66,225.26,7.86">Proceedings of the 22Nd International Conference on Machine Learning, ICML &apos;05</title>
		<meeting>the 22Nd International Conference on Machine Learning, ICML &apos;05<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="89" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,479.13,337.62,7.86;6,151.52,490.09,329.06,7.86;6,151.52,501.05,329.06,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,351.25,479.13,129.33,7.86;6,151.52,490.09,116.49,7.86">Learning to rank: From pairwise approach to listwise approach</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Qin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-F</forename><surname>Tsai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,286.75,490.09,193.83,7.86;6,151.52,501.05,126.73,7.86">Proceedings of the 24th International Conference on Machine Learning, ICML &apos;07</title>
		<meeting>the 24th International Conference on Machine Learning, ICML &apos;07<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="129" to="136" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,512.56,337.62,7.86;6,151.52,523.52,157.82,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,364.69,512.56,115.89,7.86;6,151.52,523.52,85.61,7.86">York university at trec 2011: Medical records track</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Daoud</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kasperowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Miao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,256.58,523.52,22.95,7.86">TREC</title>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,535.03,337.62,7.86;6,151.52,545.99,286.93,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,355.70,535.03,124.88,7.86;6,151.52,545.99,101.42,7.86">An efficient boosting algorithm for combining preferences</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,260.94,545.99,83.60,7.86">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="933" to="969" />
			<date type="published" when="2003-12">Dec. 2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,557.50,337.62,7.86;6,151.52,568.46,163.85,7.86" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,223.72,557.50,252.41,7.86">Greedy function approximation: A gradient boosting machine</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">H</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,151.52,568.46,77.36,7.86">Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="1189" to="1232" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,579.97,337.62,7.86;6,151.52,590.93,329.06,7.86;6,151.52,601.89,234.51,7.86" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,216.85,590.93,263.73,7.86;6,151.52,601.89,82.00,7.86">Share/clef ehealth evaluation lab 2014, task 3: User-centred health information retrieval</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Pecina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Mueller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,252.69,601.89,105.00,7.86">Proceedings of CLEF 2014</title>
		<meeting>CLEF 2014</meeting>
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,613.41,337.62,7.86;6,151.52,624.36,199.27,7.86" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,279.00,613.41,197.52,7.86">Cumulated gain-based evaluation of ir techniques</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Järvelin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kekäläinen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,151.52,624.36,89.66,7.86">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="422" to="446" />
			<date type="published" when="2002-10">Oct. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,142.96,635.88,337.62,7.86;6,151.52,646.84,329.06,7.86;6,151.52,657.80,177.25,7.86" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,276.75,635.88,203.82,7.86;6,151.52,646.84,92.52,7.86">Semantic matching models for medical information retrieval: A case study</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Kasperowicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,281.87,646.84,198.72,7.86;6,151.52,657.80,148.99,7.86">the Proceedings of the 2012 Advances in Health Informatics Conference (AHIC 2012)</title>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,120.67,337.96,7.86;7,151.52,131.63,329.06,7.86;7,151.52,142.59,329.07,7.86;7,151.52,153.55,210.15,7.86" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,415.10,131.63,65.48,7.86;7,151.52,142.59,156.31,7.86">Overview of the share/clef ehealth evaluation lab 2014</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Schrek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Leroy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">L</forename><surname>Mowery</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Velupillai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">W</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Martinez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,332.91,142.59,108.65,7.86">Proceedings of CLEF 2014</title>
		<title level="s" coord="7,450.23,142.59,30.36,7.86;7,151.52,153.55,136.86,7.86">Lecture Notes in Computer Science (LNCS</title>
		<meeting>CLEF 2014</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,164.51,337.97,7.86;7,151.52,175.47,170.63,7.86" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,196.61,164.51,167.40,7.86">Learning to rank for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">T.-Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,371.79,164.51,108.80,7.86;7,151.52,175.47,85.91,7.86">Foundations and Trends in Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="225" to="331" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,186.42,337.96,7.86;7,151.52,197.38,214.95,7.86" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="7,297.13,186.42,183.45,7.86;7,151.52,197.38,32.07,7.86">Linear feature-based models for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,191.24,197.38,85.91,7.86">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="257" to="274" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,208.34,337.96,7.86;7,151.52,219.30,227.36,7.86" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="7,342.33,208.34,138.25,7.86;7,151.52,219.30,70.84,7.86">Adapting boosting for information retrieval measures</title>
		<author>
			<persName coords=""><forename type="first">Q</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Burges</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">M</forename><surname>Svore</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,230.79,219.30,36.66,7.86">Inf. Retr</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="254" to="270" />
			<date type="published" when="2010-06">June 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,142.61,230.26,337.96,7.86;7,151.52,241.22,329.05,7.86;7,151.52,252.18,329.07,7.86;7,151.52,263.14,92.40,7.86" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="7,229.45,230.26,232.02,7.86">Adarank: A boosting algorithm for information retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,151.52,241.22,329.05,7.86;7,151.52,252.18,216.63,7.86">Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;07</title>
		<meeting>the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;07<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="391" to="398" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
