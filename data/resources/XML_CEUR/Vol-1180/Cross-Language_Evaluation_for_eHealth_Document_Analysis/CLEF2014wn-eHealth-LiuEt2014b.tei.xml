<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,153.85,116.95,307.67,12.62;1,238.76,134.89,137.84,12.62">Mining Disorder Attributes with Rules and Statistical Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,190.82,172.56,52.27,8.74"><forename type="first">Xiaohua</forename><surname>Liu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">DIRO</orgName>
								<orgName type="institution">Universit de Montral</orgName>
								<address>
									<postCode>H3C 3J7</postCode>
									<region>Qubec</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,250.74,172.56,47.29,8.74"><forename type="first">Xiaojie</forename><surname>Liu</surname></persName>
							<email>xiaojie@iro.umontreal.ca</email>
							<affiliation key="aff0">
								<orgName type="department">DIRO</orgName>
								<orgName type="institution">Universit de Montral</orgName>
								<address>
									<postCode>H3C 3J7</postCode>
									<region>Qubec</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,305.68,172.56,38.97,8.74"><forename type="first">Wei</forename><surname>Shen</surname></persName>
							<email>shenwei@iro.umontreal.ca</email>
							<affiliation key="aff0">
								<orgName type="department">DIRO</orgName>
								<orgName type="institution">Universit de Montral</orgName>
								<address>
									<postCode>H3C 3J7</postCode>
									<region>Qubec</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,372.09,172.56,52.45,8.74"><forename type="first">Jianyun</forename><surname>Nie</surname></persName>
							<email>nie@iro.umontreal.ca</email>
							<affiliation key="aff0">
								<orgName type="department">DIRO</orgName>
								<orgName type="institution">Universit de Montral</orgName>
								<address>
									<postCode>H3C 3J7</postCode>
									<region>Qubec</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,153.85,116.95,307.67,12.62;1,238.76,134.89,137.84,12.62">Mining Disorder Attributes with Rules and Statistical Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6260E4DC1BEAD66DAA299FC18E39230C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>attribute extraction</term>
					<term>rule</term>
					<term>classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This working note describes our approach to CLEF 2014 task 2a. It also reports our experimental results and discusses some future work we want to explore.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The CLEF 2014 task 2a<ref type="foot" coords="1,250.01,338.20,3.97,6.12" target="#foot_0">1</ref> aims to provide the normalized value for each of 10 attributes of each disease/disorder mention template. Each mention template consists of the mention's Unified Medical Language System concept unique identifiers (CUI) and mention boundaries, and a pointer to the report from which that mention template is extracted.</p><p>Each disease/disorder mention has the following 10 different attributes: Negation Indicator, Subject Class, Uncertainty Indicator, Course Class, Severity Class, Conditional Class, Generic Class, DocTime Class, Temporal Expression, and Body Location. The normalized value for any of the first nine of the attributes comes from a list of possible values, such as "yes", "no" for Negation Indicator. Normalized values for the tenth attribute-Body Location-come from the UMLS CUIs.</p><p>We decompose the task into 10 sub tasks, and consider each sub task as a classification problem, and accordingly design a classifier for each of the 10 attributes. We find that for some attributes, using simple rules, e.g., always setting it to some value, yields better results than statical learning. Therefore, in addition to developing some classifiers based on machine learning, we also build some rule based classifiers. Most of the rules are automatically extracted from the annotated training data. Furthermore, we manually create a few rules, for example, some regular expressions to identify time expressions.</p><p>The main goal of our experiments is to figure out the effective features or rules for each attribute extraction task. In our first attempt, we focus on such features and rules that can be directly extracted from the training data, not using any additional resources, such as WordNet <ref type="bibr" coords="1,356.98,614.74,9.96,8.74" target="#b1">[2]</ref>, UMLS. While designing features, we only consider local features which can be easily extracted from a text window with the disease/disorder mention in the center.</p><p>For some attributes, such as Generic Class and Negation Indicator, our system works well. But for some attributes, such as DocTime Class, it performs bad. We hope to better understand the reasons once the test data with the ground truth is released.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our Approach</head><p>In our experiments, we design a classifier for each attribute. With cross validation on the training data, we find in most cases statistical classifiers achieve the best performance than rule bases systems. However, for "Body Location", since there are many possible values, a statistical classifier does not work. We also find that for some attribute, such as "Course Class", always setting it to a default value gives the best performance.</p><p>In what follows, we describe details of each classifier. Note that for each attribute, the type of classifier and the features sets are determined with 10 fold cross validation on the training corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Negation Indicator Classifier</head><p>We train a classifier with LIBLINEAR<ref type="foot" coords="2,313.92,357.50,3.97,6.12" target="#foot_1">2</ref> . While training, we set the type of solver to L1-regularized logistic regression, i.e., -s 6, and the regularization and experimental loss trade-off parameter to 3, i.e., -c 3.</p><p>We consider the following features in a text windows of size 17 with the mention in the middle: 1) uni-gram on the left/right of the mention; and 2) bigram on the left/right of the mention. For each n-gram, we append ":L" (":R") to its end, indicating it is on the left (right) of the mention.</p><p>On the official test data, its accuracy is 0.922.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Subject Class Classifier</head><p>We train a classifier with LIBLINEAR with -s 6 and -c 3. We use only uni-gram in a text windows of size 17 with the mention in the middle. For each uni-gram, we also consider its position. For example, feature "weight:3" ("weight:-3")means "weight" is on the right (left) of the mention, and there are two words between them. On the official test data, its accuracy is 0.611.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Uncertainty Indicator Classifier</head><p>We train a classifier with LIBLINEAR with -s 6 and -c 3. We use two sets of features in a text windows of size 17 with the mention in the middle: uni-gram with position, the same features as used for Negation Indicator Classifier; and bi-gram features with ":L" or ":R" as suffix. On the official test data, its accuracy is 0.923.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Course Class Classifier</head><p>We always set its value to "true". On the official test data, its accuracy is 0.961.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Severity Class Classifier</head><p>We build a rule based system for this attribute. First we extract all clue words for each severity class. For example, for "SEVERE", we get clue words like "acute","sharp","critical". Then we consider all words (context words) in a text window of size 5 with the mention in the middle and select the severity class that consists of the greatest number of clue words that appear in the text window. If there is a draw, we randomly choose one from them. And in case there are no rules to apply, we use the default value.</p><p>On the official test data, its accuracy is 0.611. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Conditional Class Classifier</head><p>We always set its value to "false". On the official test data, its accuracy is 0.936.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">Generic Class Classifier</head><p>We train a classifier with LIBLINEAR with -s 6 and -c 3. We use only uni-gram with position as features in a text windows of size 17 with the mention in the middle. On the official test data, its accuracy is 1.000.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.8">Body Location Classifier</head><p>Since there are potentially many body location labels, a statistical classifier with a fixed number of labels will not work. Therefore, we build a rule based classifier for this attribute. Each rule is is a clue word body location pair, which are automatically extracted from annotations. Here are some examples: (inferoapical,C1299408), (liver,C0223884). The procedure of extracting rules is similar to what we have done for Severity Class. With the mined rules, we select the body location that has the greatest number of clue words that occur in the mention.</p><p>In case of a tie, we randomly choose one from them. On the official test data, its accuracy is 0.635.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.9">DocTime Class Classifier</head><p>We always set its value to "OVERLAP". On 10-fold cross validation, it outperforms Support Vector Machines (SVMs) <ref type="bibr" coords="4,316.97,298.59,10.52,8.74" target="#b0">[1]</ref> based classifier (with an accuracy of 0.411) and other rule based classifiers. However, on the official test data, its accuracy is very low, i.e., 0.024.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.10">Temporal Expression Classifier</head><p>We build a rule base classifier for this attribute. We run two steps to construct the rules: 1) first we extract clues words for each "Temporal Expression", i.e., DATE, DURATION and TIME; and 2) we manually compile regular expressions based on the clue words to make them more general.</p><p>Step 2 is necessary because that clue words related to temporal expression are often long, and contain concrete numbers, making them hard to be matched. , where "DATE","DURATION" are labels. In total, we have 30 regular expression based rules.</p><p>To do the prediction, we consider a text window of size 11 with the mention in the middle, to which we apply all the compiled regular expressions. Finally we choose the label that has the greatest number of matched regular expressions. In case of a tie, we randomly choose one; in case not any regular expression is matched, we choose the default value, i.e., "none".</p><p>On the official test data, its accuracy is 0.824.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Conclusions and Future Work</head><p>We build 10 classifiers to handle Task 2a. These classifiers can be organized into three groups: the first group of classifiers always predict the same value. In our current experiments, we don't use any external resources, and don't use any features more complicated than n-grams. In future we would like to consider more resources and more advanced features, such as features from the values of related attributes, particularly for the attributes on which our current approach does not work well.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,361.20,432.94,119.41,8.74;4,134.77,444.89,345.83,8.74;4,134.77,456.85,338.40,8.74;4,134.77,468.80,339.56,8.74;4,134.77,480.76,86.67,8.74"><head></head><label></label><figDesc>Here are some examples of such rules: DATE ←\d{4}-\d{2}-\d{2}, DURATION ← ((several) | (\d+) | (one)|(two)|(three)|(four)|(five)|(six)|(seven)|(eight)|(nine)|(ten))\s+((minute) |(second)|(hour)|(day)|(week)|(wk)|(month)|(year)|(yr)|(mn))s?\s+((duration) |(interval)|(history))</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,136.20,298.03,324.33,227.52"><head>Table 1 .</head><label>1</label><figDesc>Clue Words for Each Severity Class.</figDesc><table coords="3,136.20,318.80,324.33,206.74"><row><cell>Severity</cell><cell>Clue Words</cell></row><row><cell>Class</cell><cell></cell></row><row><cell>SEVERE</cell><cell>acute severe,sharp,rapid,significant,critical,flash,abrupt</cell></row><row><cell></cell><cell>acute onset,severely moderate to severe,significantly</cell></row><row><cell></cell><cell>greater, pleuritic, moderately severe acute to subacute</cell></row><row><cell></cell><cell>subacute, mild,extremely,advanced, high grade, profound extreme</cell></row><row><cell></cell><cell>moderately to severely,acutely,markedly,high-grade,crushing</cell></row><row><cell></cell><cell>severity marked,moderate-severe,more marked,extensive</cell></row><row><cell></cell><cell>sharp or knife-like,moderate-to-severe sub acute</cell></row><row><cell></cell><cell>moderate to large sized, breakthrough, substantial</cell></row><row><cell></cell><cell>coarse, massively critically high, sudden onset,volatile</cell></row><row><cell></cell><cell>massive,considerable</cell></row><row><cell cols="2">MODERATE moderately,mildly,mild,moderate,modest,mild to moderate,dense</cell></row><row><cell></cell><cell>mild-moderate,markedly,mild-to-moderate,moderate to large</cell></row><row><cell></cell><cell>subacute,significant,mildy,large-to-moderate</cell></row><row><cell cols="2">UNMARKED worsening,severity,elevated,increase</cell></row><row><cell>SLIGHT</cell><cell>trace,mild,slight,minimal,minimally,minimally displaced</cell></row><row><cell></cell><cell>mildly,slightly,modest,minor,partially,much lesser extent</cell></row><row><cell></cell><cell>minimal amounts,minimal amount,trivial,partial,min,little</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,134.77,645.16,345.84,20.69"><head></head><label></label><figDesc>This strategy works very well for Course Class and Conditional Class, but does not work for DocTime Class; the second group of classifiers are based on rules mined from clue words of disease/disorder mentions. The rules are used for majority based voting to output the prediction. Classifiers for Severity Class, Body Location and Temporal Expression belong to this group; the third group of classifiers are based on SVMs and mainly use n-gram features extracted from a text window with the mention in the middle. There are 4 instances in this group, i.e., classifiers for Negation Indicator, Subject Class, Uncertainty Indicator and Generic Class. Except for the classifier for Subject Class attribute, the classifiers in this group perform well with an accuracy of more than 0.900 on the official test data.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,144.73,657.80,200.55,7.86"><p>http://clefehealth2014.dcu.ie/task-2/2014-dataset</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,144.73,657.80,178.23,7.86"><p>http://www.csie.ntu.edu.tw/ cjlin/liblinear/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="5,138.35,330.88,342.22,7.86;5,146.91,341.84,333.67,8.11;5,146.91,353.45,61.19,7.47" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,210.50,330.88,243.74,7.86">A tutorial on support vector machines for pattern recognition</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</author>
		<idno type="DOI">10.1023/A:1009715923555</idno>
		<ptr target="http://dx.doi.org/10.1023/A:1009715923555" />
	</analytic>
	<monogr>
		<title level="j" coord="5,460.74,330.88,19.84,7.86;5,146.91,341.84,85.16,7.86">Data Min. Knowl. Discov</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="121" to="167" />
			<date type="published" when="1998-06">Jun 1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,138.35,363.76,342.22,7.86;5,146.91,374.72,114.29,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,203.15,363.76,162.60,7.86">Wordnet: A lexical database for english</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,373.55,363.76,107.02,7.86;5,146.91,374.72,44.66,7.86">COMMUNICATIONS OF THE ACM</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="39" to="41" />
			<date type="published" when="1995">1995</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
