<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,193.83,116.98,227.69,12.60;1,184.17,134.92,247.01,12.60;1,139.53,152.85,336.30,12.60;1,254.16,170.78,107.05,12.60">Optimizing Apache cTAKES for Disease/Disorder Template Filling: Team HITACHI in 2014 ShARe/CLEF eHealth Evaluation Lab</title>
				<funder>
					<orgName type="full">United States National Institutes of Health</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,167.81,208.36,66.06,8.80"><forename type="first">Nishikant</forename><surname>Johri</surname></persName>
							<email>nishikant@hitachi.co.in</email>
							<affiliation key="aff0">
								<orgName type="department">Research and Development Centre</orgName>
								<orgName type="institution">Hitachi India Pvt Ltd</orgName>
								<address>
									<settlement>Bangalore</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Central Research Laboratory</orgName>
								<orgName type="institution">Hitachi, Ltd</orgName>
								<address>
									<country key="JP">Japan</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,245.83,208.36,55.13,8.80"><forename type="first">Yoshiki</forename><surname>Niwa</surname></persName>
							<email>yoshiki.niwa.tx@hitachi.com</email>
							<affiliation key="aff2">
								<orgName type="institution">International Institute of Information Technology</orgName>
								<address>
									<settlement>Hyderabad</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,333.10,208.36,118.92,8.80"><forename type="first">Veera</forename><surname>Raghavendra Chikka</surname></persName>
							<email>raghavendra.ch@research.iiit.ac.in</email>
						</author>
						<title level="a" type="main" coord="1,193.83,116.98,227.69,12.60;1,184.17,134.92,247.01,12.60;1,139.53,152.85,336.30,12.60;1,254.16,170.78,107.05,12.60">Optimizing Apache cTAKES for Disease/Disorder Template Filling: Team HITACHI in 2014 ShARe/CLEF eHealth Evaluation Lab</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">E382BA6493212134B2CB17741A54DB40</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:37+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Natural language processing</term>
					<term>information extraction</term>
					<term>Apache cTAKES</term>
					<term>UMLS</term>
					<term>relation extraction</term>
					<term>dictionary matching</term>
					<term>CRF</term>
					<term>SVM</term>
					<term>rule based assertion</term>
					<term>structural parsing</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes an information extraction system developed by team Hitachi for "Disease/Disorder Template filling" task organized by ShARe/CLEF eHealth Evaluation Lab 2014. We approached the task by building a baseline system using Apache cTAKES. We submitted two separate runs; in our first run, rule based assertion module predict the norm slot value of assertion attributes excluding training data knowledge. However assertion module is changed to machine learningbased in second run. We trained models for Course modifiers, Severity modifier and Body Location relation extractor and applied a variety of rule based post processing including structural parsing. We performed two layer search on UMLS dictionary for refinement of body location. Eventually, we created rules for temporal expression extraction and also used them as features for model training of DocTime. We followed a dictionary matching technique for cue slot value detection in Task 2b. Evaluation result of test data showed that our system performed very well in both subtasks. We achieved the highest accuracy 0.868 in norm value detection, strict F1-score 0.576 and relaxed F1-score 0.724 in cue slot value identification, indicating promising enhancement on baseline system.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>With the widespread usage of electronic health record (EHR), a large amount of healthcare data is being generated, posing massive challenges in doing effective analysis for stakeholders (administrators, care providers and researchers) and foreshadowing text mining as one of the dominant fields of research in medical domain. The adoption of natural language processing (NLP) in healthcare has opened a door for patients' better understanding on their health and paved the way for advanced research in medical field.</p><p>For the past few years, numerous healthcare research organizations have focused their efforts toward unraveling the enigmatic nature of clinical text and promoting research in medical domain. In this series, ShARe/CLEF eHealth Evaluation Lab 2013 introduced three challenging tasks on NLP and information retrieval (IR) and extended them to ShARe/CLEF eHealth Evaluation Lab 2014 in which we submitted our system for information extraction task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Task Description</head><p>Task 2 "Information extraction from clinical text: Disease/Disorder Template Filling" in CLEF eHealth 2014 is an extension of CLEF eHealth 2013 task "Named entity recognition and normalization of disorders" <ref type="bibr" coords="2,393.32,275.54,9.96,8.80" target="#b0">[1]</ref>.</p><p>In template filling task, the participants have been provided with a corpus of de-identified healthcare reports along with an empty template for each disease/disorder mentioned in the report. The template consists of mention's UMLS <ref type="bibr" coords="2,134.77,323.36,10.52,8.80" target="#b1">[2]</ref> CUI, span offset of mention and a list of unfilled value slots for 10 attributes: Negation Indicator, Subject Class, Uncertainty Indicator, Course Class, Severity Class, Conditional Class, Generic Class, Body Location, DocTime Class, and Temporal Expression. The participants have to prepare a system which can predict the norm value for each attribute value slot from a list of possible norm values. An optional task on cue slot value identification (span offset of lexical cue) is also conducted in which participants are asked to find the span offset of each attribute from healthcare reports.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Corpus Description</head><p>As the task is an extension of CLEF eHealth 2013 tasks, the resulting dataset of CLEF eHealth 2013 Task 1 and Task 2 has been served as training corpus for system development in CLEF eHealth 2014. The training corpus consists of 4 types of healthcare reports: Discharge summary, Radiology report, ECHO report and ECG report, while test data has only Discharge summaries. Table <ref type="table" coords="2,475.62,502.88,4.98,8.80" target="#tab_0">1</ref> describes corpus statistics. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Processing Pipeline and Approaches</head><p>We approached the task by building a baseline system using Apache clinical Text Analysis and Knowledge Extraction System (cTAKES) <ref type="bibr" coords="3,396.51,154.54,10.52,8.80" target="#b2">[3,</ref><ref type="bibr" coords="3,409.60,154.54,7.01,8.80" target="#b3">4]</ref>. Although few cTAKES modules are still under development, we followed its clinical pipeline for development of baseline system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">System Architecture</head><p>Apache cTAKES is a NLP framework specifically built for processing medical text. Figure <ref type="figure" coords="3,192.72,237.72,4.98,8.80" target="#fig_0">1</ref> depicts our system architecture built upon cTAKES. It takes clinical text as input, applies cTAKES preprocessing steps followed by individual module's process and finally the generated result is supplied to Template Filler which ultimately resolves norm value and identifies cue slot value of attributes. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">cTAKES Preprocessing</head><p>Our system relies on cTAKES for preprocessing of clinical text. We analyzed the training corpus and modified sentence detector module to overcome the problem of fallible end of sentence. We merged two or more sentences which erroneously cover a single disease/disorder mention. On the other hand, we overcome the disjoint disease/disorder problem by using last text span as target disease/disorder because in most of the disjoint training examples last text span represents disease/disorder and consequently it can predict attribute norm values too. For example, in the disjoint span "left atrium ... dilated", dilated is used as target disease/disorder. The majority of preprocessing is accomplished using cTAKES components. Sentence detection is followed by tokenization, part of speech tagging and NPchunking. Tokenization is followed by context dependent tokenization which classifies tokens into various categories such as number-token, date-token, timetoken, range-token etc. Finally, dependency parser and semantic role labeler (SRL) are applied over tokenized data providing dependency relationship between semantic arguments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Processing Individual Modules</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Assertion:</head><p>Our system uses cTAKES assertion module to determine norm value of Negation Indicator, Uncertainty Indicator, Condition Class, Subject Class and Generic Class. Assertion attributes can be determined using machine learning as well as rule based approach. We submitted separate runs for both the approaches.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Rule Based Assertion:</head><p>In rule based assertion, NegEx <ref type="bibr" coords="4,384.54,356.50,10.52,8.80" target="#b4">[5]</ref> algorithm has been used to predict whether the mentioned disease/disorder is negated, more specifically it resolves the polarity of sentence. It requires predefined negation phrases which have been divided into two groups pseudo-negation and actual-negation. Pseudo negation consists of phrases that appear to indicate negation but instead identify double negative ("not ruled out") and ambiguous phrasing ("unremarkable"). For instance, in the sentence "Ambulating without difficulty, chest pain free, and without further evidence of bleeding", all diseases ambulating, chest pain and bleeding are negated by pseudo negation phrases without difficulty, free and without further evidence of respectively. On the other hand, actual negation phrase denies disease or finding when used in a window of +/-5 tokens including stop words. For example, in the sentence "Ext: No clubbing, cyanosis or edema" all the findings are negated by No phrase.</p><p>The Assertion module predicts uncertainty and conditional class by scoring the target phrase using list of words with predefined uncertainty/conditional values. For example if, risk, evaluate, when, check are some typical words with high conditional score. Similarly, uncertain, differentiate, suspect are tokens having high uncertainty score. For scoring, it also uses POS tags and token entries present in the left window of mentioned disease.</p><p>We used cTAKES feature selection for subject class identification. The feature set includes token, SRL argument, dependency path and SRL dependent token of all the persons who appeared in the sentence mentioning disease/disorder. A rule based approach is applied over the selected features. For example, if system does not find any feature, the subject is patient. If donor and family member both features are true, the subject will be donor_family_member. Similarly other cases have been introduced to predict the subject experiencing disease/disorder.</p><p>As per the training dataset, there is no entry asserting generic attribute in whole dataset. However, we used generic classifier of assertion module to classify the generic attribute.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Using Assertion models:</head><p>In machine learning method, we used ClearTK <ref type="bibr" coords="5,470.09,177.66,10.52,8.80" target="#b5">[6]</ref> framework for feature extraction and trained separate models for each assertion attribute on training data.</p><p>Apache cTAKES provides method for feature selection for assertion attribute. All assertion attributes have a common feature list which includes word, wordstem, tokens within -/+ 5 window and bag of words within -/+ 3 window of disease/disorder mention. An additional feature word score is derived by taking mean of contextual token distance from the mentioned disease/disorder.</p><p>For each attribute, some additional features are added along with the common feature list. Negation dependency features are used for polarity detection. For subject class, all features of rule based approach along with outcomes are used in training subject class model. Unlike negation indicator and subject class no additional features are used for training uncertainty and conditional class models. In contrast to other assertion attributes, generic attribute does not have any positive classification in training data; however it does have cue slot value which made it easier to prepare generic classifier. Generic model also employed features and outcomes derived from rule based approach.</p><p>Assertion cue slot identification: For assertion attributes, we followed a dictionary matching approach for cue slot identification. We created stem dictionaries from training data comprising stems of attribute's keywords. Table <ref type="table" coords="5,475.63,428.25,4.98,8.80" target="#tab_1">2</ref> shows sample stem dictionaries of assertion attributes. Dictionary matching is performed on the sentence mentioning disease/disorder. Negation indicator's cue slot value is determined by extracting nearest negation phase present in the left window of mentioned disease/disorder. However complete window is considered when extracting uncertainty, conditional and generic class cue slots. In contrast to other attributes, subject class cue slot is identified using dictionary matching over SRL arguments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Relation Extraction:</head><p>Apache cTAKES treats the task of locating body sites and severity modifier as a relation extraction problem <ref type="bibr" coords="6,436.65,131.89,9.96,8.80" target="#b6">[7]</ref>. When handling body location finding, we evaluated the results of cTAKES relation extractor and found scope of improvement by applying rule based post processing; however because of promising results of severity and course class, our system completely relied on relation extractor for severity and course class identification.</p><p>Body Location Extraction: Body Location is the most critical attribute in template filling task concerning CUI ambiguity of clinical concepts. Figure <ref type="figure" coords="6,475.63,227.97,4.98,8.80">2</ref> depicts a typical sequence of algorithms applied for body location finding.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 2. Sequence of algorithms applied for body location finding</head><p>As a preprocessing step in body location identification, we built a lucene [8] based dictionary comprising all UMLS concepts of body parts falling into different semantic types defined by CLEF eHealth 2014 <ref type="bibr" coords="6,389.29,391.47,9.96,8.80" target="#b7">[9]</ref>. We indexed first term as well as full text of concept in order to implement a layered search approach.</p><p>In first layer of search, dictionary lookup is applied over NP chunks, providing entity mention annotations (body part, anatomical sites and their associated CUIs). After annotating entity mentions, features are generated for all possible pairs of disease and entity mentions. For example, in the sentence "patient has severe pain in left shoulder while right shoulder is normal", pain is disease and left shoulder and right shoulder are two body locations. In this case, two training instances pain .. left shoulder and pain .. right shoulder (true and false respectively) are generated to find the relationship between arguments. We trained support vector machine (SVM) model for location_of relation extractor using cTAKES relation extractor module and training dataset. However machine learning method failed to identify some body location relations. For instance, in the sentence "Ext: trace bilateral lower ext edema; R groin small hematoma, no bruits", Ext is an abbreviation of Extremities (body location) but machine learning model could not detect it.</p><p>In order to find the missing body locations, we apply a second layer of search enabling structural parsing which determines body location in sections, subsections and headings of the document especially in ECHO REPORT and DIS-CHARGE SUMMARY. Section headings play an important role when relating disease with the body location especially in section containing very short/long sentences such as "Neck: No JVD. JVP 7 cm. No carotid bruits". Here Neck is the target body location for disease JVD, JVP and carotid bruits. Following are few sentences where section heading determines relationship.</p><p>• MITRAL VALVE: The mitral valve leaflets are mildly thickened. There is mild mitral annular calcification. Mild (1+) mitral regurgitation is seen. • AORTIC VALVE: Normal aortic valve leaflets <ref type="bibr" coords="7,357.21,180.64,12.22,8.80" target="#b2">(3)</ref> Another missing body location case is when body location is present within disease/disorder mention itself. For example, the sentence "There is a mild mitral annular calcification" has mitral annular calcification as disease and mitral annular as target body location which machine learning system could not detect in many instances. Therefore, in second layer search, we find body locations within mentioned disease/disorder.</p><p>After extracting relationship between body part and disease, we expand body part text chunks to +/-5 token windows. For example, in the sentence EGD showed food compaction in the lower third of the esophagus and gastroesophageal junction, first layer search finds esophagus which is expanded to lower third of the esophagus and hence overlapping results are transformed into strict results resolving CUI ambiguity to some extent.</p><p>Finally the problem of ambiguity is tackled. For example, UMLS search on Sinus gives CUI C1305231, but in ECG reports Sinus implicitly refers to Coronary Sinus (C0456944). Similarly, in sentence "intact in all four extremities to LT, PP, cold", extremities CUIs are C0015385 and C0278454 but the correct CUI is C0278454. In order to resolve ambiguity, we prepared separate dictionaries for each report type. Each dictionary includes anatomical sites pertaining to the report type. For example, ECG dictionary includes heart, chambers and other heart components. However, dictionaries have been created from supplied training data and CUI ambiguity has been resolved by considering most frequent CUI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Severity and Course Class: cTAKES relation extractor provides degree_of</head><p>relation which enlightens the degree to which a disease/disorder is modified. Using cTAKES modifier extractor and supplied training data, we prepared two separate conditional random field (CRF) machine learning models for severity and course modifier. For CRF training, feature set contains only tokens covered and POS tags. After annotating severity modifiers using CRF model, features are generated for all possible pairs of disease mention and severity modifiers and similar to body location relation extraction, SVM models are trained for degree_of relation.</p><p>Once relationship is determined, normalization of modifier is approached using synonym stem dictionaries. We collected all the nearest synonyms of norm values and prepared a dictionary comprising stem of severity modifiers and their synonyms present in training data. The same approach has been followed for course class identification and normalization. Table <ref type="table" coords="8,359.88,119.93,4.98,8.80" target="#tab_3">3</ref> shows sample stem dictionaries of severity and course modifiers. Similarly, temporal expression has been extracted from heading "Date/Time:" in ECHO report and from "DATE:" in radiology report.</p><p>On the other hand, discharge summaries include more critical temporal patterns. We built finite state machines (FSM) for numerical date and time patterns. Besides FSM, we also developed an algorithm to find textual temporal expressions.</p><p>The algorithm divides all the temporal keywords into various classes. Table <ref type="table" coords="8,134.77,537.50,4.98,8.80" target="#tab_4">4</ref> shows typical keywords representing time. We created patterns shown in Table <ref type="table" coords="8,134.77,549.46,3.87,8.80" target="#tab_5">5</ref>, which can match non-space separated time expressions such as 1day before, hd2, x1 yr, 5am, 12p.m etc. Another Table <ref type="table" coords="8,320.52,561.41,4.98,8.80" target="#tab_6">6</ref> contains adjuster and modifier that usually occurs before and after the time keywords. All other words are considered in NONE category including stop-words.</p><p>The algorithm first generates temporal equivalence of sentence, mapping each token to one of the classes listed in Table <ref type="table" coords="8,323.11,609.23,3.87,8.80" target="#tab_4">4</ref>, Table <ref type="table" coords="8,362.67,609.23,4.98,8.80" target="#tab_5">5</ref> or Table <ref type="table" coords="8,412.21,609.23,3.87,8.80" target="#tab_6">6</ref>. It then looks up for chunks having class of Table <ref type="table" coords="8,299.05,621.19,4.98,8.80" target="#tab_4">4</ref> and Table <ref type="table" coords="8,357.33,621.19,4.98,8.80" target="#tab_5">5</ref> and expands them to left and right window by using adjusters and modifiers in Table <ref type="table" coords="8,394.54,633.14,4.98,8.80" target="#tab_6">6</ref> until two adjacent NONE or stop-word appear. For example, in the sentence "On the evening of postoperative day three, the patient had another short 7-beat run of ventricular tachycardia", evening has class PartOfDay and day has Unit, so it is expanded to evening of postoperative day three because next two tokens are NONE or stopword. Furthermore, we relate disease/disorder to the nearest temporal expression when multiple temporal expressions are found in a sentence. Once temporal expression is found, it has to be classified into one of the three norm values DATE, TIME or DURATION. Table <ref type="table" coords="10,379.43,179.71,4.98,8.80" target="#tab_7">7</ref> shows the classes and corresponding dictionary categories and keywords. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Evaluation</head><p>Our system was developed on a training set (298 reports) and evaluated on a test set (133 reports) supplied by the organizer. All machine learning models are optimized using 10-fold cross validation on the training data; however no additional annotations are used throughout the development.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Evaluation metric</head><p>According to the organizer's evaluation criteria, evaluation focuses on accuracy for Task 2a (norm value detection) and F1-score for Task 2b (cue slot identification), defined as strict F1-score (span is identical to the reference standard span) and relaxed F1-score (span overlaps reference standard span). Each task has been evaluated by overall performance as well as attribute type.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Results</head><p>As reported by the organizer, our system achieved the best results in both of the information extraction tasks: Task 2a (norm value detection) and Task 2b (cue slot value identification). Table <ref type="table" coords="11,295.47,165.34,4.98,8.80" target="#tab_8">8</ref> shows overall performance of our system in Task 2a and Task 2b. Table <ref type="table" coords="11,270.61,177.30,4.98,8.80" target="#tab_9">9</ref> shows per attribute type result for both tasks. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Discussion</head><p>As shown by the evaluation results, our system outperformed not only in overall evaluation but also in majority of attribute type evaluations; however measures also insinuate the scope of improvement in our system.</p><p>In Task 2a, our system (0.868) achieved an improvement of 0.025 in overall accuracy benchmarking with respect to second best team (0.843). We submitted two runs, TeamHITACHI.1 employed rule based assertion while TeamHI-TACHI.2 predicted assertion attribute using machine learning method. Result in Table <ref type="table" coords="12,175.98,167.75,4.98,8.80" target="#tab_8">8</ref> shows that machine learning method (0.868) improved the results by 0.014 in comparison to rule based assertion system (0.854). On the other hand, in Task 2b, our system's performance is best among all the submitted systems; however low F1-score clearly implies the scope of improvement in cue slot identification.</p><p>According to the attribute wise evaluation, our system obtained the highest accuracy in 7 out of 10 attributes in Task 2a. As body location was the most critical attribute, our system achieved the highest accuracy 0.797 in mapping body location to UMLS CUI. The difference between strict F1-score 0.735 and relaxed F1-score 0.874 for body location cue slot identification suggests amendment of dictionaries and optimization of dictionary lookup algorithm. Another concerning attribute which achieved least accuracy 0.328 is DocTime class, albeit highest among all the systems. One possible feature enhancement for DocTime relation could be inclusion of features other than sentence feature because when a disease is described in more than one sections, all section's information contribute in prediction. For example, in the document "He has a history of schizoaffective disorder and anxiety..... Schizoaffective disorder: restarted psychiatric medications once he was awake enough to eat.", schizoaffective disorder is patient's history as well as current problem, but anxiety has history only, therefore, schizoaffective disorder should be assigned BEFORE_OVERLAP and anxiety should be assigned BEFORE DocTime class. At last, our rule based temporal expression extractor did not perform well (accuracy 0.773) and ranked 9th in the normalization task, indicating refinement of temporal rules.</p><p>For Task 2b, we deliberately focused on relaxed F1-score in cue slot value identification, consequently the overall relaxed F1-score (0.724) exceeded the overall strict F1-score (0.576). The low F1-score of assertion attributes insinuate ineffectiveness of dictionary matching method for assertion attribute tagging. It will remain an open ended problem for future works.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>The paper described our method and pipeline employed to fill the disease/disorder template in our submission to Task 2 of ShARe/CLEF eHealth Evaluation Lab 2014. We began with the baseline system development using Apache cTAKES and incorporated many cTAKES modules in our system. We developed several wrappers comprising machine learning and rule based techniques for norm value detection of various attributes. We performed rule based post processing including dictionary matching to identify attribute's cue slot value. The evaluation results demonstrated that our system achieved the best accuracy in both norm and cue slot value identification task, indicating promising enhancement over baseline system. However the results also signify the scope of improvement in some modules, especially in cue slot identification.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,134.77,494.83,345.81,8.02;3,134.77,505.89,345.81,7.92;3,134.77,516.84,138.44,7.92;3,152.52,304.43,310.31,175.75"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. System Architecture and Processing Pipeline built upon Apache cTAKES. The grey components are modified or rebuilt while other components remain unchanged from original cTAKES framework.</figDesc><graphic coords="3,152.52,304.43,310.31,175.75" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,369.43,180.64,77.12,8.80;7,141.74,194.75,162.00,8.80;7,141.74,208.85,312.56,8.80"><head></head><label></label><figDesc>. No AS. No AR. • Cardiac: RRR. S1/S2. No M/R/G • Extremities: No C/C/E bilaterally, 2+ radial, DP and PT pulses b/l.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,142.82,545.86,329.70,91.77"><head>Table 1 .</head><label>1</label><figDesc>Statistics of training and test data</figDesc><table coords="2,142.82,569.82,329.70,67.81"><row><cell>Report type</cell><cell cols="2">Training dataset</cell><cell></cell><cell>Test dataset</cell></row><row><cell></cell><cell cols="4">#reports #annotations #reports #annotations</cell></row><row><cell cols="2">DISCHARGE SUMMARY 136</cell><cell>9098</cell><cell>133</cell><cell>8003</cell></row><row><cell>RADIOLOGY REPORT</cell><cell>54</cell><cell>831</cell><cell>0</cell><cell>0</cell></row><row><cell>ECHO REPORT</cell><cell>54</cell><cell>1429</cell><cell>0</cell><cell>0</cell></row><row><cell>ECG REPORT</cell><cell>54</cell><cell>196</cell><cell>0</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,192.45,473.26,230.46,8.02"><head>Table 2 .</head><label>2</label><figDesc>Sample stem dictionary for assertion attributes</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,144.03,497.22,327.29,67.81"><head>Subject Negation Indicator Uncertainty Conditional Generic</head><label></label><figDesc></figDesc><table coords="5,144.03,513.27,327.29,51.75"><row><cell>father</cell><cell>no evidence of</cell><cell>differentia</cell><cell>if</cell><cell>recommended</cell></row><row><cell>mother</cell><cell>no sign of</cell><cell>uncertain</cell><cell>Concern</cell><cell>consult</cell></row><row><cell>famil</cell><cell>negative</cell><cell>potential</cell><cell>protect</cell><cell>sign</cell></row><row><cell>parent</cell><cell>absent</cell><cell>probab</cell><cell>when</cell><cell>service</cell></row><row><cell cols="2">paternal without</cell><cell>suspec</cell><cell>indicat</cell><cell>mention</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,134.77,163.19,345.84,277.92"><head>Table 3 .</head><label>3</label><figDesc>Sample list of severity and course modifiers with synonym stems</figDesc><table coords="8,147.03,187.15,313.90,116.65"><row><cell>Modifier type</cell><cell>Class</cell><cell>Synonym stems</cell></row><row><cell></cell><cell>severe</cell><cell>advanc, bad, dart, elevat,</cell></row><row><cell>Severity Modifier</cell><cell>slight</cell><cell>small, little, minimal, niggl</cell></row><row><cell></cell><cell>moderate</cell><cell>check, control, mild, moderat</cell></row><row><cell></cell><cell>increased</cell><cell>increas, high, advanc, ascend, addition</cell></row><row><cell></cell><cell>improved</cell><cell>improv, normal, better, come-back, well</cell></row><row><cell>Course Modifier</cell><cell>resolved decreased</cell><cell>recover, regain, block-up, ceas, clear decreas, contract, declin, degenerat, dim</cell></row><row><cell></cell><cell>changed</cell><cell>chang, evolv, moving, transform</cell></row><row><cell></cell><cell>worsened</cell><cell>worse, spoil, swell, tough, wretch</cell></row></table><note coords="8,134.77,351.02,345.83,8.90;8,134.77,363.08,345.84,8.80;8,134.77,375.03,345.84,8.80;8,134.77,386.99,345.83,8.80;8,134.77,398.94,345.84,8.80;8,134.77,410.90,169.31,8.80;8,140.99,432.22,339.61,8.90"><p><p><p>2.3.3 Temporal Expression Extraction:</p>We approached temporal expression finding with a rule based technique. Most of the temporal expression in ECHO, ECG and RADIOLOGY reports are taken either from document header or from DATE/TIME heading. For example, in the following header of ECG report, '2016-01-05'(DATE) is the temporal expression which has been extracted during structural parsing of document.</p>-83601||||1114||||23168||||ECG_REPORT||||2016-01-05 03:57:00.0|||| |||| |||| ||||</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,158.51,151.96,293.86,124.65"><head>Table 4 .</head><label>4</label><figDesc>Time classes and keywords</figDesc><table coords="9,158.51,175.92,293.86,100.69"><row><cell>Time Class</cell><cell>Keywords</cell></row><row><cell>Unit</cell><cell>second, month, week, year, decade, century, y, m, d etc</cell></row><row><cell>PartOfDay</cell><cell>morning, afternoon, evening, night, overnight</cell></row><row><cell>DayOfWeek</cell><cell>monday, tuesday, mon, tue, wed etc</cell></row><row><cell>MonthOfYear</cell><cell>january, february, march, jan, feb, mar etc</cell></row><row><cell>SeasonOfYear</cell><cell>spring, summer, fall, autumn, winter</cell></row><row><cell>Time</cell><cell>now, today, tonight, yesterday, noon, a.m</cell></row><row><cell>Duration</cell><cell>times, duration, interval, x</cell></row><row><cell>Date</cell><cell>hd, pod</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="9,185.95,358.90,243.45,80.81"><head>Table 5 .</head><label>5</label><figDesc>Derived time classes and regular expression</figDesc><table coords="9,185.95,382.85,243.45,56.85"><row><cell>Derived Time Classes</cell><cell>Regular Expression</cell></row><row><cell>INT_ROMAN</cell><cell>\d+\B(st|nd|rd|th)\b</cell></row><row><cell>DUR_UNIT</cell><cell>\d+\B(UNIT)(DURATION)\b</cell></row><row><cell>TIME_UNIT</cell><cell>\d+\B(UNIT)( TIME)\b</cell></row><row><cell>DATE_UNIT</cell><cell>\b(DATE)\B\d+</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="9,158.58,522.00,298.19,102.73"><head>Table 6 .</head><label>6</label><figDesc>Adjuster and Modifier keywords</figDesc><table coords="9,158.58,545.96,298.19,78.77"><row><cell>Adjuster</cell><cell>Keywords</cell></row><row><cell>Number</cell><cell>All integers, one, two, three, twenty, thirty, hundred etc</cell></row><row><cell cols="2">TimeReference previous, previously, recent, recently etc</cell></row><row><cell>Frequency</cell><cell>every, each, hourly, daily, frequently</cell></row><row><cell>Adjuster</cell><cell>last, past, previous, ago, next, prior, throughout</cell></row><row><cell>Modifier</cell><cell>few, half, within</cell></row><row><cell>PrePost</cell><cell>preoperative, postoperative, preop, postop, pre-surgical,</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="10,134.77,221.42,345.84,268.86"><head>Table 7 .</head><label>7</label><figDesc>Temporal expression class, their categories and keywords</figDesc><table coords="10,134.77,245.38,345.84,244.91"><row><cell>Class</cell><cell>Categories</cell><cell>Keywords</cell></row><row><cell>DURATION</cell><cell>DUR_UNIT, Duration, SeasonOfYear,</cell><cell>year, month, day, week, year, wk , period, century, Past, over, within, since, throughout, through, several</cell></row><row><cell>TIME</cell><cell>TIME_UNIT, PartOfDay, TimeAnnotation</cell><cell>ago, before, after, prior, earlier, hour, min, sec, am, pm</cell></row><row><cell></cell><cell>Prepost, DATE_UNIT, Date,</cell><cell></cell></row><row><cell>DATE</cell><cell>MonthOfYear, Year, INT_ROMAN, DayOfWeek,</cell><cell>postoperative, pod, day, date</cell></row><row><cell></cell><cell>DateAnnoation</cell><cell></cell></row><row><cell cols="3">2.3.4 DocTime Extraction: DocTime class indicates temporal relation</cell></row><row><cell cols="3">between a disease/disorder and document authoring time. We used cTAKES</cell></row><row><cell cols="3">DocTime module with some enhancement of feature selection. The feature set</cell></row><row><cell cols="3">included in DocTime module contains tokens and POS tags within +/-3 window</cell></row><row><cell cols="3">of mentioned disease/disorder, tense of nearby verb, section heading and closest</cell></row><row><cell cols="3">verb. Along with these features, we also integrated time expression features found</cell></row><row><cell cols="2">during temporal expression extraction phase.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="11,145.33,209.40,324.68,128.69"><head>Table 8 .</head><label>8</label><figDesc>Overall performance of our system in Task 2a and Task 2b</figDesc><table coords="11,145.33,233.36,324.68,104.73"><row><cell>Task</cell><cell>System</cell><cell></cell><cell cols="2">Overall Result</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="4">Accuracy F1-score Precision Recall</cell></row><row><cell>(2a)</cell><cell>TeamHITACHI.2 TeamHITACHI.1</cell><cell>0.868 0.854</cell><cell>0.499 0.478</cell><cell>0.485 0.453</cell><cell>0.514 0.506</cell></row><row><cell>(2b) (Strict)</cell><cell>TeamHITACHI.2 TeamHITACHI.1</cell><cell></cell><cell>0.576 0.573</cell><cell>0.535 0.535</cell><cell>0.624 0.616</cell></row><row><cell>(2b) (Relaxed)</cell><cell>TeamHITACHI.2 TeamHITACHI.1</cell><cell></cell><cell>0.724 0.719</cell><cell>0.672 0.672</cell><cell>0.784 0.773</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="11,139.05,388.45,337.21,173.48"><head>Table 9 .</head><label>9</label><figDesc>Per attribute type result for Task 2a and Task 2b</figDesc><table coords="11,139.05,412.40,337.21,149.52"><row><cell>Attribute type</cell><cell>Task 2a</cell><cell></cell><cell></cell><cell>Task 2b</cell></row><row><cell></cell><cell>Accuracy</cell><cell cols="2">F1-score</cell><cell>Precision</cell><cell>Recall</cell></row><row><cell></cell><cell></cell><cell cols="4">Strict Relax Strict Relax Strict Relax</cell></row><row><cell>Body Location</cell><cell>0.797</cell><cell cols="4">0.735 0.874 0.754 0.897 0.717 0.853</cell></row><row><cell>Course Class</cell><cell>0.971</cell><cell>0.6</cell><cell>0.67</cell><cell cols="2">0.567 0.632 0.638 0.712</cell></row><row><cell>Conditional Class</cell><cell>0.978</cell><cell cols="4">0.352 0.801 0.382 0.869 0.326 0.743</cell></row><row><cell>DocTime Class</cell><cell>0.328</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Generic Class</cell><cell>0.99</cell><cell cols="3">0.203 0.304 0.213 0.32</cell><cell>0.193 0.289</cell></row><row><cell>Negation Indicator</cell><cell>0.969</cell><cell cols="4">0.775 0.926 0.804 0.962 0.747 0.893</cell></row><row><cell>Subject Class</cell><cell>0.993</cell><cell cols="4">0.119 0.165 0.066 0.092 0.589 0.814</cell></row><row><cell>Severity Class</cell><cell>0.982</cell><cell cols="2">0.828 0.85</cell><cell cols="2">0.836 0.857 0.821 0.843</cell></row><row><cell>Temporal Expression</cell><cell>0.773</cell><cell cols="2">0.239 0.37</cell><cell>0.201 0.31</cell><cell>0.297 0.458</cell></row><row><cell>Uncertainty Indicator</cell><cell>0.96</cell><cell cols="4">0.419 0.672 0.381 0.612 0.465 0.746</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>We would like to thank <rs type="institution">International Institute of Information Technology, Hyderabad India</rs> for providing us technical assistance through survey of existing technologies and implementation of severity and course class dictionaries. We are also very thankful to task organizers of CLEF eHealth 2014, who were funded by the <rs type="funder">United States National Institutes of Health</rs>.</p></div>
			</div>
			<listOrg type="funding">
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="13,142.85,278.25,343.18,8.80;13,151.70,290.21,328.90,8.80;13,151.70,302.16,22.69,8.80" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="13,356.49,278.25,129.53,8.80;13,151.70,290.21,124.60,8.80">Overview of the ShARe/CLEF eHealth Evaluation Lab 2013</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Salantera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sanna</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,344.75,290.21,131.31,8.80">the Proceedings of CLEF 2013</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.85,318.33,361.70,9.08;13,151.70,331.18,26.15,8.18" xml:id="b1">
	<monogr>
		<ptr target="http://www.nlm.nih.gov/research/umls/" />
		<title level="m" coord="13,151.70,318.33,178.23,8.80">UMLS (Unified Medical Language System</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.85,346.46,337.76,8.80;13,151.70,358.41,328.90,8.80;13,151.70,370.37,328.90,8.80;13,151.70,382.32,323.99,8.80" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="13,274.07,358.41,206.53,8.80;13,151.70,370.37,328.90,8.80;13,151.70,382.32,20.70,8.80">Mayo clinical Text Analysis and Knowledge Extraction System (cTAKES): architecture, component evaluation and applications</title>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">K</forename><surname>Savova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Masanz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">V</forename><surname>Ogren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">C</forename><surname>Kipper-Schuler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">G</forename><surname>Chute</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,184.00,382.32,105.80,8.80">J Am Med Inform Assoc</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="507" to="513" />
			<date type="published" when="2010-09">Sep. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.85,398.49,337.76,8.80;13,151.70,411.34,130.76,8.18" xml:id="b3">
	<monogr>
		<ptr target="http://ctakes.apache.org/" />
		<title level="m" coord="13,151.70,398.49,323.88,8.80">Apache cTAKES (clinical Text Analysis and Knowledge Extraction System</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.85,426.62,337.76,8.80;13,151.70,438.57,328.89,8.80;13,151.70,450.53,328.90,8.80;13,151.70,462.48,83.03,8.80" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="13,250.15,438.57,230.45,8.80;13,151.70,450.53,159.86,8.80">A Simple Algorithm for Identifying Negated Findings and Diseases in Discharge Summaries</title>
		<author>
			<persName coords=""><forename type="first">Wendy</forename><forename type="middle">W</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Will</forename><surname>Bridewell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gregory</forename><forename type="middle">F</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bruce</forename><forename type="middle">G</forename><surname>Buchanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,335.33,450.53,145.27,8.80">Journal of Biomedical Informatics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="301" to="310" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.85,478.65,337.75,8.80;13,151.70,490.61,328.89,8.80;13,151.70,502.56,328.91,8.80;13,151.70,514.52,268.28,8.80" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="13,366.24,478.65,114.35,8.80;13,151.70,490.61,163.08,8.80">ClearTK: a framework for statistical natural language processing</title>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">V</forename><surname>Ogren</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">G</forename><surname>Wetzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">J</forename><surname>Bethard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="13,326.83,490.61,153.77,8.80;13,151.70,502.56,328.91,8.80;13,151.70,514.52,229.34,8.80">Unstructured Information Management Architecture Workshop at the Conference of the German Society for Computational Linguistics and Language Technology</title>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.85,530.69,337.75,8.80;13,151.70,542.64,328.89,8.80;13,151.70,554.60,125.23,8.80" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="13,203.82,542.64,263.80,8.80">Discovering body site and severity modifiers in clinical texts</title>
		<author>
			<persName coords=""><forename type="first">Dmitriy</forename><surname>Dligach</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steven</forename><surname>Bethard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lee</forename><surname>Becker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Timothy</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Guergana</forename><forename type="middle">K</forename><surname>Savova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,475.47,542.64,5.12,8.80;13,151.70,554.60,99.21,8.80">J Am Med Inform Assoc</title>
		<imprint>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.85,586.94,337.76,8.80;13,151.70,598.89,328.89,8.80;13,151.70,610.85,206.51,8.80" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="13,345.10,598.89,135.50,8.80;13,151.70,610.85,101.12,8.80">Overview of the ShARe/CLEF eHealth Evaluation Lab</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Leroy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Schreck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Mowery</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Velupillai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Ww Chapman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Palotti</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="13,142.48,627.02,338.12,8.80;13,151.70,638.97,328.89,8.80;13,151.70,650.93,34.18,8.80" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="13,431.40,627.02,49.19,8.80;13,151.70,638.97,290.80,8.80">The ShARe Schema for the Syntactic and Semantic Annotation of Clinical Texts</title>
		<author>
			<persName coords=""><surname>Elhadad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>O'gorman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Palmer</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Savova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="13,453.72,638.97,26.87,8.80;13,151.70,650.93,29.30,8.80">Under Review</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
