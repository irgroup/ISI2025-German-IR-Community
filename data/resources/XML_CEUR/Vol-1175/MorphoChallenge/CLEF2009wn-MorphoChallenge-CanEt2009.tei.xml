<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,97.44,148.86,408.12,15.15;1,214.68,170.78,173.64,15.15">Unsupervised Learning of Morphology by Using Syntactic Categories</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,233.56,204.67,45.13,8.74"><forename type="first">Burcu</forename><surname>Can</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of York York</orgName>
								<address>
									<postCode>YO10 5DD</postCode>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,287.14,204.67,82.30,8.74"><forename type="first">Suresh</forename><surname>Manandhar</surname></persName>
							<email>suresh@cs.york.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of York York</orgName>
								<address>
									<postCode>YO10 5DD</postCode>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,97.44,148.86,408.12,15.15;1,214.68,170.78,173.64,15.15">Unsupervised Learning of Morphology by Using Syntactic Categories</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6CD2F162BCEE2EA6A8C82B4366929B8C</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>1.2 [Artificial Intelligence]: 1.2.6 Learning 1.2.7 Natural Language Processing Algorithms</term>
					<term>Experimentation Morphological Analysis</term>
					<term>Syntax</term>
					<term>Unsupervised Learning</term>
					<term>Clustering</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents a method for unsupervised learning of morphology that exploits the syntactic categories of words. Previous research [4][12]  on learning of morphology and syntax has shown that both kinds of knowledge affect each other making it possible to use one type of knowledge to help the other. In this work, we make use of syntactic information i.e. Part-of-Speech (PoS) tags of words to aid morphological analysis. We employ an existing unsupervised PoS tagging algorithm for inducing the PoS categories. A distributional clustering algorithm is developed for inducing morphological paradigms.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Morphological analysis is a crucial subtask for most Natural Language Processing (NLP) problems: Machine Translation, Question Answering, Information Retrieval, Part-of-Speech Tagging etc. Morphological segmentation is a preprocessing step before a full morphological analysis can be done. For applications dealing with large corpora morphological segmentation requires dealing with sparseness of data. For example, a verb can have thousands of different forms in languages like Finnish <ref type="bibr" coords="1,144.16,636.50,60.46,8.74">(Karlsson [13]</ref>) and often all the different forms are not seen during training.</p><p>Morphology learning has been an active research topic since Harris <ref type="bibr" coords="1,398.17,660.42,15.50,8.74" target="#b10">[11]</ref> proposed the distributional hypothesis. One of the earliest works on morphology learning using Harris's ideas is Déjean and Norm's method <ref type="bibr" coords="1,179.84,684.33,9.96,8.74" target="#b7">[8]</ref>. In this work <ref type="bibr" coords="1,253.31,684.33,9.96,8.74" target="#b7">[8]</ref>, Déjean and Norm find the most frequent morphemes on the given unannotated text, and by using this morpheme list, he segments the given text morphologically. Since then, there has been huge amount of progress made in the field. We can classify these into the following approaches: Minimum Description Length (MDL) model, Letter Successor Variety (LSV) model, Semantic models (ex: Latent Semantic Analysis -LSA), Probabilistic models.</p><p>MDL based models (Brent <ref type="bibr" coords="2,224.82,135.93,9.96,8.74" target="#b1">[2]</ref>, Brent et. al. <ref type="bibr" coords="2,299.54,135.93,9.96,8.74" target="#b2">[3]</ref>, Goldsmith <ref type="bibr" coords="2,365.31,135.93,10.79,8.74" target="#b8">[9]</ref>[10], Creutz and Lagus <ref type="bibr" coords="2,479.09,135.93,10.79,8.74" target="#b6">[7]</ref>) aim to minimize the space used by the corpus and the model by morphologically segmenting the words in the corpus. LSV model has been employed by Bordag <ref type="bibr" coords="2,345.74,159.84,10.52,8.74" target="#b0">[1]</ref> that used letter frequencies to find split points in the words. Snover et. al. <ref type="bibr" coords="2,262.42,171.80,15.50,8.74" target="#b15">[16]</ref> describe a probabilistic model in which morphological paradigms are created gradually by choosing the number of stems, morphemes, paradigms in a probabilistic, and generative manner. Another generative model is due to Creutz <ref type="bibr" coords="2,445.55,195.71,10.52,8.74" target="#b5">[6]</ref> in which the lengths and the frequencies of the morphemes are used as prior information. Schone and Jurafsky <ref type="bibr" coords="2,107.08,219.62,15.50,8.74" target="#b14">[15]</ref> used LSA to capture the semantic relatedness of words to aid morphological segmentation.</p><p>All the above work has been primarily employed to learn simple i.e. non-recursive concatenative morphology but they do not directly address the recursive nature of the morphology of agglutinative languages. Monson <ref type="bibr" coords="2,237.02,267.44,15.50,8.74" target="#b13">[14]</ref> proposed a system for handling the morphology of agglutinative languages. His system achieved a precision of 52% on Turkish as evaluated in the Morpho Challenge Workshop, 2008.</p><p>There has been some work on the joint unsupervised learning of morphology and PoS tags. Hu et. al. <ref type="bibr" coords="2,118.76,327.21,15.50,8.74" target="#b11">[12]</ref> extends the minimum description length (MDL) based framework due to Goldsmith <ref type="bibr" coords="2,502.48,327.21,10.52,8.74" target="#b8">[9]</ref> to explore the link between morphological signatures and PoS tags. Clark and Tim <ref type="bibr" coords="2,447.51,339.17,10.52,8.74" target="#b3">[4]</ref> experiments with the fixed endings of the words for PoS clustering. So morphologically similar words tend to belong into the same PoS cluster.</p><p>Our current work can be viewed is in a similar direction. In particular, we show that unsupervised PoS tagging can be effectively employed for learning of morphology. However, the work presented here is not a method for simultaneous learning of PoS categories and morphology. It is limited to learning of morphology given that PoS categories already been induced using an unsupervised PoS tagger.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Inducing Syntactic Categories</head><p>For the induction of syntactic categories, we used Clark's distributional clustering approach <ref type="bibr" coords="2,502.49,489.58,10.52,8.74" target="#b4">[5]</ref> which can be considered as an instance of average link clustering. Although it should be emphasised that any other method for unsupervised induction of PoS tags can be substituted without affecting the method presented in this paper. Following Clark's approach, each word is clustered by using its context. A context consists of the previous word, and the following word. Each word has a context distribution over all ordered pairs of left-context/right-context words. To measure the distributional similarity between words, KL divergence is used which is defined as:</p><formula xml:id="formula_0" coords="2,243.55,593.69,269.45,26.35">D(p q) = x p(x) log p(x) q(x)<label>(1)</label></formula><p>where p, q are the context distributions of the words being compared and x ranges over contexts.</p><p>In his approach <ref type="bibr" coords="2,160.93,650.68,9.96,8.74" target="#b4">[5]</ref>, the probability of a context for a target word is defined as:</p><formula xml:id="formula_1" coords="2,170.58,672.60,342.42,9.65">p(&lt; w 1 , w 2 &gt;) = p(&lt; c(w 1 ), c(w 2 ) &gt;)p(w 1 |c(w 1 ))p(w 2 |c(w 2 ))<label>(2)</label></formula><p>where c(w 1 ), c(w 2 ) denote the PoS cluster of words w 1 , w 2 respectively.</p><p>The algorithm requires the number of clusters K to be specified in advance. In addition to the K clusters, one spare cluster is employed containing all unclustered words. During each iteration, one word is chosen from the spare cluster having the minimum KL divergence with one of the K clusters. For each cluster, its context distribution is computed as the averaged distribution of all words in the cluster. In addition, the KL divergence between clusters are computed after each iteration and clusters are merged if the divergence is below a manually set threshold.</p><p>We set K=77, the number of tags defined in CLAWS tagset used for tagging the BNC (British National Corpus). We used the same number of clusters for Turkish and German. Final clusters show that PoS clusters are related with the major syntactic categories. The system finds PoS clusters that can be identified as proper nouns, verbs in past tense form, verbs in present continuous form, nouns, adjectives, adverbs, and so on. Some sample clusters are given below for English:</p><p>Cluster 1: much far badly deeply strongly thoroughly busy rapidly slightly heavily neatly widely closely easily profoundly readily eagerly Cluster 2: made found held kept bought heard played left passed finished lost changed etc Cluster 3: should may could would will might did does etc Cluster 4: working travelling flying fighting running moving playing turning etc Cluster 5: people men women children girls horses students pupils staff families etc</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Inducing Mophological Paradigms</head><p>After the induction of the syntactic categories, the conditional probability of each morpheme x given its PoS cluster c, p(x|c), is computed. The possible morphemes in each PoS cluster is found by splitting each word in each cluster at all split points, and the morphemes are ranked, and sorted according to their maximum likelihood estimates in each PoS cluster.</p><p>A list of highest ranked morphemes are given in Table <ref type="table" coords="3,345.12,489.58,4.98,8.74" target="#tab_0">1</ref> for English, German, and Turkish. </p><formula xml:id="formula_2" coords="3,118.13,577.39,366.73,44.60">1 -s 1 -n,-en 1 -i,-si,-ri 2 -d,-ed 2 -e,-te 2 -mak,-mek,-mesi,-masi 3 -ng,-ing 3 -g,-ng,-ung 3 -an,-en 4</formula><p>-y,-ly 4 -r,-er 4 -r,ar,er,-ler,-lar 5 -s,-rs,-ers 5 -n,-en,-rn,-ern 5 -r,-ir,-dir,-Ir,-dIr 6 -ing,-ng,g 6 -ch,-ich,-lich 6 -e,-a</p><p>This ranking is used to eliminate the potential non-morphemes with a low conditional probability hence reducing the search space. In the next step, morphemes across PoS clusters are incrementally merged forming the basis of the paradigm capturing mechanism. In each iteration, a morpheme pair across two different PoS cluster with the highest number of common stems is chosen for merging. Once a morpheme pair is merged the words that belong to this newly formed paradigm are removed from their respective PoS clusters. Once a word is assigned to a paradigm, it cannot be part of any other paradigm. Thus, we postulate that a word can only belong to a single morphological paradigm.</p><p>Since, in our current framework, morphemes are tied to PoS clusters our definition of paradigm deviates from that of Goldsmith <ref type="bibr" coords="4,235.07,147.89,10.52,8.74" target="#b8">[9]</ref> in that a paradigm φ is a list of morpheme/cluster pairs i.e. φ = {m 1 /c 1 , . . . , m n /c n }. Associated with each paradigm is a list of stems i.e. the list of stems that can combine with each of the morphemes m i to produce a word belonging to the c i PoS category.</p><p>Algorithm 1 describes the complete paradigm capturing process. Some examples of sample paradigms captured are given below: English: ed ing : reclaim aggravat hogg trimm expell administer divert register stimulat shap rehabilitat exempt stiffen spar deceiv contaminat disciplin implement stabiliz feign mistreat extricat mimick alert seal etc s d : implicate ditche amuse overcharge equate despise torpedoe curse plie supersede preclude snare tangle eclipse relinquishe ambushe reimburse alienate conceive vetoe waive envie negotiate diagnose etc er ing : brows wring worship cropp cater stroll zipp moneymak tun chok hustl angl windsurf swindl cricket painkill climb heckl improvis scream scaveng panhandl lawmak bark clean lifesav beekeep toast matchmak bodybuild etc e ed : subsid liquidat redecorat exorcis amputat fertiliz reshap regulat foreclos infring eradicat reverberat chim centralis restructur crippl rehabilitat symbolis reinstat etc ly er : dark cheap slow quiet fair light high poor rich cool quick broad deep bright calm crisp mild clever etc 0 s : benchmark instrument pretzel wheelchair scapegoat spike infomercial catastrophe beard paycheck reserve abduction Turkish: i e : zemin faaliyetin torenler secim incelemeler eyalet nem takvim makineler yontemin becerisin gorusmeler teknigin merkezin iklim goruntuler etc i a : cevab bakimin mektuplar esnaf olayin akisin miktar kayd yasamay bulgular sular masraflarin heyecanin kalan haklarin anlamin etc i in : sanayiin degerlerin esin denizler duman teminat erkekler kurullarin birbirin vatandaslarimiz gelismesin milletvekillerin partisin de e : bolgesin duzeyin yonetimin dergisin sektorun birimlerin bolgelerin tumun bolumlerin tesislerin donemin kongresin evin etc mesi en : izlen yurutul degis uretil gerceklestiril desteklen gelistiril etc i 0 : iman cekim mahkemelerin orneklem gaflet yazman sanat trendler mahalleler eviniz hamamlar piller ogretim olimpiyat German: r n : kurze ehemalige eidgenoessische professionelle erste bescheidene ungewoehnliche ethnische unbekannte besondere nationalsozialistische deutsche e en : praechtig gesichert dauerhaft bescheiden vereinbart biologisch natuerlich oekumenisch kantonal unterirdisch wissenschaftlich nahegelegen chinesisch t en : funktionier konkurrier schneid mitwirk ansteig plaedier pfeif aufklaer schluck ausgleich weitermach abhol ankomm spazier speis aussteig aufhoer er ung : versteiger unterdrueck erneuer vermarkt beschleunig besetz geschaeftsfuehr wirtschaftsfoerder finanzverwalt verhandl s 0 : potential instrument flohmarkt vorhang pilotprojekt idol rechner thriller ensemble bebauungsplan empfinden defekt aufschwung Remove all words in c 1 with morpheme m 1 and associate these words with φ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>9:</head><p>Remove all words in c 2 with morpheme m 2 and associate these words with φ. for all Paradigms φ 1 , φ 2 such that Acc(φ 1 , φ 2 ) &gt; T , where T is a threshold do 12:</p><p>Create new merged paradigm φ = φ 1 ∪ φ 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>13:</head><p>Associate all words from φ 1 and φ 2 into φ 14:</p><p>Delete paradigms φ 1 , φ 2 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>15:</head><p>end for 16: until No morpheme pair consisting of at least one common stem is left</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Merging Paradigms</head><p>For capturing more general paradigms, paradigm merging is performed. We rank potential paradigms by the ratio of common stems with the total number of stems captured by the paradigm. More precisely, given paradigms φ 1 , φ 2 , let P be the total number of common stems. Let N 1 be the total number of stems in φ 1 that are not present in φ 2 . Similarly, let N 2 be the total number of stems in φ 2 that are not present in φ 1 . Then, we can define the expected paradigm accuracy of φ 1 with respect to φ 2 by:</p><formula xml:id="formula_3" coords="5,267.17,467.74,241.59,23.22">Acc 1 = P P + N 1 (<label>3</label></formula><formula xml:id="formula_4" coords="5,508.76,474.48,4.24,8.74">)</formula><p>Acc 2 is defined analogously. We use the average of Acc 1 and Acc 2 to compute the combined (averaged) expected accuracy of the merged paradigms φ 1 , φ 2 :</p><formula xml:id="formula_5" coords="5,238.18,540.32,274.82,25.77">Acc(φ 1 , φ 2 ) = P P +N1 + P P +N2 2<label>(4)</label></formula><p>During each iteration, all the paradigm pairs having an expected accuracy greater than a given threshold value are merged. Once two paradigms are merged, stems that occur in only one of the paradigms inherit the morphemes from the other paradigm. This mechanism helps create a more general paradigm and helps recover missing word forms. Thus, although some of the word forms do not exist in the corpus, it becomes possible to capture these forms. Some example paradigms that are found by the system are given below: English: es ing e ed: sketch chew nipp debut met factor profit occurr err trudg participat necessitat stomp streak siphon stroll sprint drizzl firm climax gestur whipp roll tripp stemm dangl shuffl kindl broker chalk latch rippl collaborat chok summ propp pedal paralyz parad plough cramm slack wad saddl conjur tipp gallop totall catalogu bundl barg whittl retaliat straighten tick peek jabb slimm s ing ed 0: benchmark mothball weed snicker thread queue jack paw yacht implement import bracket whoop conflict spoof stunt bargain honor bird fingerprint excerpt handcuff veil comment Turkish: u a e i : yapabileceklerin kredisin hizmetleri'n sevdikleriniz yeter' transferlerin sevkin elimiz tehlikelerin sas mucizey tehditlerin bakir muhasebesin ed gayrimenkuller ecevit' defterim izlemelerin tescilin minarey tahsilin lastikler yerlestirmey i lar li in : ruhsat semt ikilem reaksiyonlar harc tip prim gidilmis kaldirmis degistirmis bulunmayacak aktarmis bulunacak kapanacak yazilabilecek devredilmis degisecek gelmemis German: er 0 e en: kassiert beguenstigt eingeholt genuegt angelastet beruehrt beinhaltet zurueckgegeben beschleunigt initiiert abgestellt bewirkt mitgenommen abgebrochen beruhigt besichtigt te ung er ten t en lich e : fahr gebrauch blockier identifizier studier entfalt gestalt agier passier sprech berat tausch kauf such weck beug erreich bearbeit beobacht erleid ueberrasch halt helf oeffn pruef uebertreff bezahl spring fuell toet 0 te t er : lichtenberg limburg hill trier elmshorn dreieich praunheim heusenstamm heddernheim hellersdorf schmitt muehlheim lueneburg kassel schluechtern preungesheim rodgau bieber osnabrueck rodheim muenchen london lissabon seoul wedding treptow</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Morphological Segmentation</head><p>For Morpho Challenge 2009, we first clustered all the words in the given corpora thereby creating a set of PoS clusters. We then followed the steps described in the previous sections to induce the morphological paradigms.</p><p>Wordlists as provided in Morpho Challenge 2009 contain the list of words that need to be segmented. To assign a PoS cluster to given word, w from the wordlist, the context distribution of w is first computed. The word is assigned the PoS cluster with the minimal KL divergence. In this case, we only consider words with a frequency greater than 10 to eliminate noise.</p><p>To segment the words in the word lists, first the word is checked if it exists in one of the existing paradigms. We followed different algorithms for known, unknown and compound words:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Handling known words</head><p>If the word exists in one of the paradigms, it is segmented by using the morpheme in the paradigm in which the word is found. For example, if a paradigm exists as given below: s ing ed 0 : benchmark mothball weed snicker thread queue jack paw yacht implement import bracket whoop If a word 'importing' is to be morphologically analyzed, it is automatically segmented by using the morpheme 'ing'.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Handling unknown words</head><p>If the word does not exist in any of the paradigms, a sequence of segmentation rules are applied. By using the paradigms, we created a morpheme dictionary to split the words which do not belong to any of the paradigms. All the morphemes in each paradigm are included in the morpheme dictionary if in any of the paradigm the initial letters of the morphemes are not the same. If the initial letters of the all morphemes in the same paradigm are the same, the longest morpheme is included in the dictionary. Using the morpheme dictionary, the word is scanned from the rightmost letter to check if any of the endings of the word exist in the dictionary. The longest letter sequence (of the word) existing in the dictionary is chosen to split the word. The same process is repeated after splitting the word until no split can be applied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Handling compounds</head><p>For the compounds, such as 'hausaufhaben' in German, or 'railway' in English, for both known, and unknown words a recursive approach is performed. The compounding rules split a word recursively from the rightmost end to the left. If an ending sequence of letters exists as a word in the corpus, the sequence is split, and the same procedure is repeated until no valid internal word part is a valid word itself in the corpus. When there are multiple matches the longest match is chosen. This recursive search is also able to find the prefixes as it searches for the valid sub-words in the words.</p><p>Algorithm for the segmentation of the words is given in Algorithm 2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 2 Morphological Segmentation</head><p>1: for all For each given word, w, to be segmented do</p><formula xml:id="formula_6" coords="7,95.37,350.56,6.59,6.99">2:</formula><p>if w already exists in a paradigm φ then If possible split u recursively from the rightmost end by using the morpheme dictionary as u = s 1 + . . . + s n otherwise s 1 = u 8:</p><p>If possible split s 1 into its sub-words recursively from the rightmost end as s 1 = w 1 + . . . + w n 9: end for</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Results</head><p>The model is evaluated in Morpho Challenge 2009 competition. Here we describe the datasets we used, our model parameters, and finally we give our evaluation results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Datasets</head><p>We used the datasets given by Morpho Challenge 2009, and Cross Language Evaluation Forum (CLEF) to train our system on 3 different languages: English, German, and Turkish. For PoS clustering, we used the given corpora by Morpho Challenge 2009<ref type="foot" coords="7,370.05,604.77,3.97,6.12" target="#foot_0">1</ref> . For the clustering of the words in the word lists to be segmented we used the datasets supplied by CLEF organization<ref type="foot" coords="7,465.34,616.73,3.97,6.12" target="#foot_1">2</ref> . We used the CLEF dataset to obtain context distributions of the words in German, and in English. For Turkish, we used a collection manually collected newspaper archives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Model Parameters</head><p>Our model is unsupervised, but it requires two prior parameters to be manually set. First, the threshold t on the conditional probability of the morpheme given its PoS cluster, P (m|c), needs to be fixed. We tested different values of this parameter for each language to find a suitable value through trail and error and we set t = 0.1. Thus, only morphemes, m, with P (m|c) &gt; 0.1 were considered. Second, the threshold on the expected accuracy, T , of merging two paradigms φ 1 , φ 2 given in Equation 4 needs to be set. Smaller values of this threshold leads to bigger paradigms with more stems, but it decreases the accuracy. Several experiments were performed to find its optimum value for different languages and a value of T = 0.75 was chosen. Both thresholds t and T once set were unchanged across all experiments reported in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Evaluation &amp; Results</head><p>The system was evaluated in Competition 1 of Morpho Challenge 2009. Precision is calculated by sampling pairs of words with the same morpheme(s) from the system output and checking this against the gold standard. Recall is calculated in a similar way but this time pairs of words with the same morpheme(s) are sampled from the gold standard and checked against the system output. F-measure is the harmonic mean of the precision, and the recall:</p><formula xml:id="formula_7" coords="8,226.75,296.56,286.25,25.65">F -measure = 1 1 P recision + 1 Recall<label>(5)</label></formula><p>Evaluation results corresponding to the English language are given in Table <ref type="table" coords="8,439.02,342.82,3.87,8.74" target="#tab_1">2</ref>. Evaluation results corresponding to the German language are given in Table <ref type="table" coords="8,439.64,422.51,3.87,8.74" target="#tab_2">3</ref>. We conducted two different experiments for German. In the first experiment, we used only the compounding rules (see Section 5.3 ) for the German word list. Since German heavily consists of compounds, the results in Table <ref type="table" coords="8,177.40,458.37,4.98,8.74" target="#tab_2">3</ref> show that the compounding rules have high precision but low recall. In the second experiment, we used the unsupervised model developed in this paper. Evaluation results for Turkish are given in Table <ref type="table" coords="8,317.60,560.04,3.87,8.74" target="#tab_3">4</ref>. Two different experiments were conducted for Turkish. In the first experiment, a validity check was performed while splitting the word recursively to decide whether to split the word. The validity check simply checks the membership of the given word in the Turkish corpus. If the rest of the word after splitting one morpheme exists in the corpus, the validity condition is assumed to be met. In the second experiment, no validity check is performed. Instead the morpheme dictionary is used. The morpheme dictionary is constructed from the learnt morphological paradigms by extracting all the morphemes to create a dictionary. The word is split recursively from the rightmost end by matching these with the morphemes in the morpheme dictionary. Our experiments show that the precision gets higher when a validity check is done but the recall is reduced. Since the Turkish dataset does not include all the forms of every word, the validity check is not reliable leading to a lower recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion &amp; Future Work</head><p>In this paper, we have developed a model for unsupervised morphology learning that exploits the PoS categories induced by an unsupervised PoS tagger. To our knowledge there has been very lim- ited work on combined learning of syntactic categories and morphology. Our results demonstrate that it is meaningful to use the syntactic categorial information for morphology learning. One problem with the current approach is that it requires a large amount of corpus for PoS clustering. If a word does not have enough context information due to corpus size, it can not be clustered.</p><p>The system then segments this by using just the morpheme dictionary. This in turn leads to inaccurate segmentations. The current system also requires manual setting of some thresholds. Furthermore, the system is very sensitive to these thresholds.</p><p>In the near future, we plan to address the above issues with the current model. In particular, we are interested in generative models for joint learning of morphology and PoS categories.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,90.00,111.74,327.65,8.77;5,95.37,125.00,251.39,8.74;5,95.37,136.96,416.66,8.74;5,95.37,148.92,264.26,8.74;5,95.37,160.84,43.50,8.77;5,95.37,174.19,6.59,6.99;5,156.75,172.80,126.88,9.68;5,95.37,186.14,6.59,6.99;5,206.56,184.78,306.44,9.65;5,206.56,196.74,64.32,8.74;5,95.37,210.05,6.59,6.99;5,206.56,208.69,207.78,9.65;5,95.37,222.01,6.59,6.99"><head>Algorithm 1 1 : 2 : 3 :: repeat 5 : 1 , c 2 do 6 : 7 :</head><label>11235167</label><figDesc>Algorithm for paradigm capturing using syntactic categories Apply unsupervised PoS clustering to the input corpus For each PoS cluster c and morpheme m, compute maximum likelihood estimates of p(m | c) Keep all m (in c) with p(m | c) &gt; t, where t is a threshold 4for all PoS clusters c Pick morphemes m 1 in c 1 and m 2 in c 2 with the highest number of common stems Store φ = {m 1 /c 1 , m 2 /c 2 } as the new paradigm 8:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,95.37,362.52,6.59,6.99;7,146.79,361.15,129.39,8.74;7,95.37,374.47,6.59,6.99;7,126.86,373.08,18.20,8.77;7,95.37,386.43,6.59,6.99;7,146.79,385.07,26.12,8.74;7,95.37,398.38,6.59,6.99;7,126.86,396.99,27.98,8.77;7,95.37,410.34,6.59,6.99"><head>3 :</head><label>3</label><figDesc>Split w using φ as w = u + m</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,118.13,530.37,323.59,43.41"><head>Table 1 :</head><label>1</label><figDesc>Some high ranked potential morphemes in PoS clusters</figDesc><table coords="3,118.13,552.68,319.39,21.09"><row><cell>English</cell><cell>German</cell><cell>Turkish</cell></row><row><cell cols="2">Cluster Morphemes Cluster Morphemes</cell><cell>Cluster Morphemes</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,204.82,372.05,193.36,34.78"><head>Table 2 :</head><label>2</label><figDesc>Evaluation results for English</figDesc><table coords="8,204.82,385.74,193.36,21.09"><row><cell cols="4">Language Precision Recall F-measure</cell></row><row><cell>English</cell><cell>58.52%</cell><cell>44.82%</cell><cell>50.76%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,180.63,499.56,241.74,44.80"><head>Table 3 :</head><label>3</label><figDesc>Evaluation results for German</figDesc><table coords="8,180.63,511.31,241.74,33.05"><row><cell>Language</cell><cell cols="3">Precision Recall F-measure</cell></row><row><cell>German -compound</cell><cell>73.16%</cell><cell>15.27%</cell><cell>25.27%</cell></row><row><cell>German -normal</cell><cell>57.67%</cell><cell>42.67%</cell><cell>49.05%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,180.36,118.94,242.28,44.80"><head>Table 4 :</head><label>4</label><figDesc>Evaluation results for Turkish</figDesc><table coords="9,180.36,130.69,242.28,33.05"><row><cell>Language</cell><cell cols="3">Precision Recall F-measure</cell></row><row><cell>Turkish (validity)</cell><cell>73.03%</cell><cell>8.89%</cell><cell>15.86%</cell></row><row><cell>Turkish (no validity)</cell><cell>41.39%</cell><cell>38.13%</cell><cell>39.70%</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="7,105.24,718.57,161.90,6.99"><p>http://www.cis.hut.fi/morphochallenge2009</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="7,105.24,728.08,407.76,6.99;7,90.00,737.54,423.00,6.99;7,90.00,747.01,164.59,6.99"><p>http://www.clef-campaign.org/. English datasets: Los Angeles Times 1994 (425 mb), Glasgow Herald 1995 (154 mb). German datasets: Frankfurter Rundschau 1994 (320 mb), Der Spiegel 1994/95 (63 mb), SDA German 1994 (144 mb), SDA German 1995 (141 mb)</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,110.48,351.24,402.52,8.74;9,110.48,363.19,402.52,8.74;9,110.48,375.15,258.01,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,187.18,351.24,308.58,8.74">Unsupervised and knowledge-free morpheme segmentation and analysis</title>
		<author>
			<persName coords=""><forename type="first">Stephan</forename><surname>Bordag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,110.48,363.19,402.52,8.74;9,110.48,375.15,158.50,8.74">Advances in Multilingual and Multimodal Information Retrieval: 8th Workshop of the Cross-Language Evaluation Forum (CLEF)</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="881" to="891" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,395.08,402.52,8.74;9,110.48,407.03,402.52,8.74;9,110.48,418.99,22.69,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="9,189.08,395.08,319.98,8.74">Minimal generative models: A middle ground between neurons and triggers</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Brent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,124.24,407.03,384.92,8.74">Proceedings of the 5th International Workshop on Artificial Intelligence and Statistics</title>
		<meeting>the 5th International Workshop on Artificial Intelligence and Statistics</meeting>
		<imprint>
			<date type="published" when="1993">1993</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,438.91,402.52,8.74;9,110.48,450.87,402.52,8.74;9,110.48,462.82,90.83,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,410.01,438.91,102.99,8.74;9,110.48,450.87,164.58,8.74">Discovering morphemic suffixes a case study in MDL induction</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sreerama</forename><forename type="middle">K</forename><surname>Brent</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Murthy</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Lundberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,294.44,450.87,214.72,8.74">Fifth International Workshop on AI and Statistics</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="264" to="271" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,482.75,402.52,8.74;9,110.48,494.70,402.52,8.74;9,110.48,506.66,309.80,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="9,261.83,482.75,251.17,8.74;9,110.48,494.70,123.70,8.74">Combining distributional and morphological information for part of speech induction</title>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Issco</forename><surname>Tim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,259.93,494.70,253.08,8.74;9,110.48,506.66,220.16,8.74">Proceedings of the 10th Annual Meeting of the European Association for Computational Linguistics (EACL)</title>
		<meeting>the 10th Annual Meeting of the European Association for Computational Linguistics (EACL)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="59" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,526.58,402.52,8.74;9,110.48,538.54,347.12,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,192.84,526.58,278.97,8.74">Inducing syntactic categories by context distribution clustering</title>
		<author>
			<persName coords=""><forename type="first">Alexander</forename><surname>Clark</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,496.20,526.58,16.80,8.74;9,110.48,538.54,257.56,8.74">The Fourth Conference on Natural Language Learning (CoNLL)</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="91" to="94" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,558.46,402.52,8.74;9,110.48,570.42,402.53,8.74;9,110.48,582.37,212.80,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,191.09,558.46,321.91,8.74;9,110.48,570.42,89.01,8.74">Unsupervised segmentation of words using prior distributions of morph length and frequency</title>
		<author>
			<persName coords=""><forename type="first">Mathias</forename><surname>Creutz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,220.50,570.42,292.51,8.74;9,110.48,582.37,113.41,8.74">Proceedings of the 41st Annual Meeting on Association for Computational Linguistics (ACL)</title>
		<meeting>the 41st Annual Meeting on Association for Computational Linguistics (ACL)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="280" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,602.30,402.52,8.74;9,110.48,614.25,358.92,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,265.25,602.30,163.72,8.74">Unsupervised discovery of morphemes</title>
		<author>
			<persName coords=""><forename type="first">Mathias</forename><surname>Creutz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Krista</forename><surname>Lagus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,451.52,602.30,61.48,8.74;9,110.48,614.25,270.56,8.74">Proceedings of the ACL workshop on Morphological and phonological learning</title>
		<meeting>the ACL workshop on Morphological and phonological learning</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="21" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,634.18,402.52,8.74;9,110.48,646.13,128.21,8.74" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="9,258.63,634.18,254.37,8.74;9,110.48,646.13,97.74,8.74">Morphemes as necessary concept for structures discovery from untagged corpora</title>
		<author>
			<persName coords=""><forename type="first">Hervé</forename><surname>Déjean</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Basse</forename><surname>Norm</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,666.06,402.52,8.74;9,110.48,678.01,170.45,8.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,187.56,666.06,273.76,8.74">Unsupervised learning of the morphology of a natural language</title>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Goldsmith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,470.23,666.06,42.77,8.74;9,110.48,678.01,73.87,8.74">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="153" to="198" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,697.94,402.52,8.74;9,110.48,709.89,243.16,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,192.77,697.94,260.94,8.74">An algorithm for the unsupervised learning of morphology</title>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Goldsmith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,480.52,697.94,32.49,8.74;9,110.48,709.89,94.11,8.74">Natural Language Engineering</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="353" to="371" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,729.82,341.12,8.74" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,216.85,729.82,102.11,8.74">Distributional structure</title>
		<author>
			<persName coords=""><forename type="first">Zellig</forename><surname>Sabbettai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Harris</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,327.59,729.82,21.28,8.74">Word</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="146" to="162" />
			<date type="published" when="1954">1954</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,112.02,402.52,8.74;10,110.48,123.98,402.52,8.74;10,110.48,135.93,241.14,8.74" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,341.63,112.02,171.38,8.74;10,110.48,123.98,104.68,8.74">Using morphology and syntax together in unsupervised learning</title>
		<author>
			<persName coords=""><forename type="first">Yu</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Matveeva</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Goldsmith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Sprague</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,235.76,123.98,277.24,8.74;10,110.48,135.93,126.01,8.74">Proceedings of the Workshop on Psychocomputational Models of Human Language Acquisition</title>
		<meeting>the Workshop on Psychocomputational Models of Human Language Acquisition</meeting>
		<imprint>
			<date type="published" when="2005-06">June, 2005</date>
			<biblScope unit="page" from="20" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,155.86,236.24,8.74" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="10,178.29,155.86,72.75,8.74">Finnish grammar</title>
		<author>
			<persName coords=""><forename type="first">Fred</forename><surname>Karlsson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>WSOY</publisher>
			<pubPlace>Juva</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,175.78,402.52,8.74;10,110.48,187.74,402.52,8.74;10,110.48,199.69,105.52,8.74" xml:id="b13">
	<monogr>
		<title level="m" type="main" coord="10,195.03,175.78,317.97,8.74;10,110.48,187.74,30.49,8.74">Paramor: From Paradigm Structure to Natural Language Morphology Induction</title>
		<author>
			<persName coords=""><forename type="first">Christian</forename><surname>Monson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
		<respStmt>
			<orgName>Language Technologies Institute, School of Computer Science, Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="10,110.48,219.62,402.52,8.74;10,110.48,231.57,368.61,8.74" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,278.09,219.62,234.91,8.74;10,110.48,231.57,74.11,8.74">Knowledge-free induction of morphology using latent semantic analysis</title>
		<author>
			<persName coords=""><forename type="first">Patrick</forename><surname>Schone</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><surname>Jurafsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,205.56,231.57,184.30,8.74">Proceedings of CoNLL-2000 and LLL-2000</title>
		<meeting>CoNLL-2000 and LLL-2000</meeting>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="67" to="72" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,251.50,402.52,8.74;10,110.48,263.45,402.52,8.74;10,110.48,275.41,284.20,8.74" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,379.24,251.50,133.76,8.74;10,110.48,263.45,302.40,8.74">Unsupervised learning of morphology using a novel directed search algorithm: taking the first step</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Matthew</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gaja</forename><forename type="middle">E</forename><surname>Snover</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><forename type="middle">R</forename><surname>Jarosz</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Brent</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,434.69,263.45,78.31,8.74;10,110.48,275.41,254.02,8.74">Proceedings of the ACL workshop on Morphological and phonological learning</title>
		<meeting>the ACL workshop on Morphological and phonological learning</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
