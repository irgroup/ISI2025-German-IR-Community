<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,98.37,148.86,406.26,15.15;1,207.36,170.78,188.29,15.15">UNED at iCLEF 2009: Analysis of Multilingual Image Search Sessions</title>
				<funder>
					<orgName type="full">Regional Government of Madrid</orgName>
				</funder>
				<funder ref="#_j7WTbng">
					<orgName type="full">Research Network MAVIR</orgName>
				</funder>
				<funder ref="#_WJFpfBj">
					<orgName type="full">Spanish Government</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,168.42,204.67,63.55,8.74"><forename type="first">Víctor</forename><surname>Peinado</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ETSI Informática</orgName>
								<orgName type="laboratory">NLP &amp; IR Group</orgName>
								<orgName type="institution">UNED c</orgName>
								<address>
									<addrLine>Juan del Rosal, 16</addrLine>
									<postCode>E-28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,239.99,204.67,111.92,8.74"><forename type="first">Fernando</forename><surname>López-Ostenero</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ETSI Informática</orgName>
								<orgName type="laboratory">NLP &amp; IR Group</orgName>
								<orgName type="institution">UNED c</orgName>
								<address>
									<addrLine>Juan del Rosal, 16</addrLine>
									<postCode>E-28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,374.59,204.67,59.98,8.74"><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">ETSI Informática</orgName>
								<orgName type="laboratory">NLP &amp; IR Group</orgName>
								<orgName type="institution">UNED c</orgName>
								<address>
									<addrLine>Juan del Rosal, 16</addrLine>
									<postCode>E-28040</postCode>
									<settlement>Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,98.37,148.86,406.26,15.15;1,207.36,170.78,188.29,15.15">UNED at iCLEF 2009: Analysis of Multilingual Image Search Sessions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">4CE15586DFDDD1BDCC194E7C7EB97569</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.3 Information Search and Retrieval</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.5.2 User Interfaces cross-language information retrieval, interactive systems, image search, known-item retrieval task flickr, images, log analysis</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we summarize the analysis performed on the logs of multilingual image search provided by iCLEF09 and its comparison with the logs released in the iCLEF08 campaign. We have processed more than one million log lines in order to identify and characterize 5, 243 individual search sessions.</p><p>We focus on the analysis of users' behavior and their performance trying to find possible correlations between: a) the language skills of the users and the annotation language of the target images; and b) the final outcome of the search session.</p><p>We have observed that the proposed task can be considered as easy, even though users with no competence in the annotation language of the images tend to perform more interactions and to use cross-language facilities more frequently. Usage of relevance feedback is remarkably low, but successful users use it more often.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper we summarize the analysis performed on the logs of multilingual image search provided in the iCLEF 2009 track <ref type="bibr" coords="1,238.78,636.50,10.52,8.74" target="#b1">[2]</ref> and its comparison with the logs released in the iCLEF 2008 campaign <ref type="bibr" coords="1,134.83,648.46,9.96,8.74" target="#b0">[1]</ref>.</p><p>In the search logs provided by the organizers individual search sessions can be easily identified. Each session starts when a registered user is shown a target image and finishes when the user finds the image or decides to give up. The logs collects all the interactions occurred in the meantime: monolingual and multilingual queries launched, query refinements, navigation across the results ranking, hints showed by the system, usage of the personal dictionaries and other cross-language facilities, etc. These logs are automatically generated by the FlickLing search engine. Please see <ref type="bibr" coords="1,502.48,720.19,10.52,8.74" target="#b2">[3]</ref> for a complete description on the interface's functionalities and the logs.</p><p>Last year <ref type="bibr" coords="2,150.39,112.02,10.52,8.74" target="#b4">[5]</ref> we focused on the analysis of possible correlations between the language skills of the users and the annotation language of the target images, along with the usage of some of the specific cross-language facilities FlickLing features. In this work we are going to focus on the analysis of users' behavior and their performance trying to find possible correlations between: a) the language skills of the users and the annotation language of the target images; and b) the final outcome of the search session. Being aware of the differences between both groups of users involved in an interactive experiment and between both pools of images used, we are replicating the analysis trying to find out new correlations and reinforce or discard the evidences observed.</p><p>The remainder of the paper is as follows: Section 2 describes the processing tasks and the characterization of the search sessions performed on the iCLEF logs. Next, we discuss some correlations found between our users' search behavior and their profile according to their language skills (Sections 3) and the final outcome of their search sessions (Section 4). Then, in Section 5 we present additional data of our study based on the questionnaires collected during the experiments. Finally, in Section 6 we draw some general conclusions and move forward to propose future work lines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">iCLEF Logs Processing</head><p>The logs provided by the iCLEF organization in 2009 were considerably smaller than last year's corpus. Table <ref type="table" coords="2,152.90,346.11,4.98,8.74" target="#tab_0">1</ref> shows some of the most relevant statistics of both raw logs. Of course, we had many users who registered and tried just a few searches. As last year, for the current analysis, we are going to focus only on those users who, regardless of their final outcome, were able to complete at least 15 search sessions and filled in the overall questionnaire. We think that these users finished the experiment (even though they could go on searching at will) and became experienced enough using FlickLing. Table <ref type="table" coords="2,319.26,593.87,4.98,8.74" target="#tab_1">2</ref> shows some of the most relevant statistics of both logs considering only the mentioned sub-sets of users.</p><p>Notice that we are going to analyze more than one million log lines generated by 98 users and containing 5, 243 search sessions and more than 62, 000 queries. Comparing a collection of logs generated in an interactive image search experiment with different users and two different sets of target images is not straightforward, but we think these figures are large enough to reach quantitatively meaningful conclusions.</p><p>So, we have processed the logs in order to obtain a rich characterization of the search sessions: the user and her behavior, the target image and the usefulness of the search and translations facilities provided by flickling. As in our previous work <ref type="bibr" coords="2,328.41,701.47,9.96,8.74" target="#b3">[4]</ref>, we have extracted 115 features for each session, capturing the complete user's profile according to her language skills, the target image's profile, and the usage of the interface's functionalities. The first hint provided by the system when the user decides to quit is always the language in which the target image is annotated. Since or monolingual search (depending on the user's language skills), we have also tracked the user's behavior before and after asking for this first hint.</p><p>In the following sections we present the analyses performed on these two sub-sets of search sessions according to the language skills of the users (Section 3) and considering the final outcome of the search sessions (Section 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Analysis According to Language Skills</head><p>We have divided our search sessions into three different 'profiles' according to the user's language skills with respect to the annotation language of the target image. On one hand, "active" denotes the sessions where the image was annotated in a language in which the user was able to read and write fluently. On the other hand, "passive" sessions are those where the target language was partially understandable by the user, but the user could not make queries in that language (e.g. images annotated in Italian for most Spanish or French speakers). Finally "unknown" refers to sessions when the image is annotated in languages completely unfamiliar for the user.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Users' Behavior</head><p>While the iCLEF08 corpus has samples enough under these categories (2, 345 sessions for active, 535 for passive and 760 for unknown), iCLEF09 corpus has no active sessions at all and has a great majority of unknown sessions (only 18 are passive and 1585 are unknown). The explanation for this is in the different characteristics of the target images proposed each year. Last year the image corpus was fully multilingual but most of the images could be easily found by simply searching in English and Spanish, the most popular languages among our users. This year, on the contrary, the image corpus was collected trying to avoid images annotated in English and stressing carefully on Dutch and German. Our users were coming basically from Romania, Italy and Spain, with little knowledge in these languages.</p><p>Table <ref type="table" coords="3,132.46,648.12,4.98,8.74" target="#tab_2">3</ref> shows the number of samples per profile, the average values for success rate (was the image found?) and the average number of hints requested per search session for each year's logs, along with the aggregate values.</p><p>According to the figures, it seems that the degree of success was high in all cases. In the iCLEF08 corpus, active and passive speakers performed similarly (passive users asking for more hints, though): they successfully found the target image 84% and 82% of the times, respectively. On the other hand, as expected, users with no competence in the annotation language obtained 73% of success rate and asked for more hints <ref type="bibr" coords="3,288.79,731.81,4.03,8.74">(</ref> In the iCLEF09 corpus, the division in profiles does not allow to find clear correlations because of the lack of samples. Unknown users, nonetheless, were able to successfully find the image 90% of the times, while asking for 2.43 hints, a smiliar figure compared to iCLEF08. It's worth noticing that hints in iCLEF09 were more specific and concrete than in iCLEF08. Thus, even though most of the target images were annotated in an unknown language, asking for hints was definitely more useful this year.</p><p>Finally, in the the aggregate figures, it can be observed that while all three profiles present a similar success rate, the unknown users asks for more hints than users with some degree of competence in the annotation language of the image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Cognitive Effort</head><p>We have grouped under the name "cognitive effort" some of the most usual interactions occurred in a traditional search interface, namely: launching queries, exploring the ranking of results beyond the first page (each page contains 20 items), and using relevance feedback (words provided by Flickr related to the query terms, and the tags associated to each image retrieved in the ranking of results). So, Table <ref type="table" coords="4,184.10,526.01,4.98,8.74" target="#tab_3">4</ref> shows the figures related to these interactions for each user profile in both FlickLing's monolingual and multilingual environments.</p><p>In the iCLEF08 logs, as expected, active and passive users launch more queries in the monolingual environment, while unknown users, who are supposed to need some translation functionalities to find the image, launch more multilingual queries using FlickLing's facilities. As far as the ranking exploration is concerned, the same pattern appears: active and passive users cover more ranking pages while querying in monolingual and unknown users explore the ranking more deeply while querying in multilingual.</p><p>Analyzing the iCLEF09 results, we cannot draw any clear conclusions but if we ignore the 18 samples corresponding to passive users, we find the unknown users again performed more interactions in the multilingual environment: more queries launched and more ranking explorations.</p><p>Usage of relevance feedback facilities, as shown in previous works (see <ref type="bibr" coords="4,408.93,657.51,10.30,8.74" target="#b4">[5]</ref>), is very low for both logs collections. But even with small variations, active and passive players used relevance feedback more often with monolingual searches and unknown players used it more often in the multilingual environment.</p><p>Analyzing the aggregate data we can maintain the following conclusions: active and passive users employed more cognitive effort in monolingual searches while unknown users needed more cognitive effort in multilingual searches in order to reach a similar performance, as shown in Section 3. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Usage of Specific Cross-Language Refinement Facilities</head><p>The dictionaries used by FlickLing were not optimal. In order to cover the six languages considered in the experiment, freely-available general-purpose dictionaries were used. To rectify some of the translation errors, FlickLing allows users to promote and penalize the translations appearing in the general dictionaries of its multilingual environment. This changes are incorporated into a personal dictionary for each user and do not affect other players' translations. When characterizing the search sessions, we also took into consideration the usage of this functionality by our users.</p><p>In general, the usage of the personal dictionary was low. Table <ref type="table" coords="5,378.40,474.21,4.98,8.74" target="#tab_4">5</ref> shows the average percentage of search sessions in which users manipulated their personal dictionary by adding new translations, promoting good translation options and removing bad ones, and the average query terms modified by these manipulations. In iCLEF08, unknown users manipulated their personal dictionary about three times (0.17) more often than active (0.06) and passive (0.05) players, and consequently the number of query terms modified was also higher (0.11). If we compare both log collections, we observe how in iCLEF09, where the usage of cross-language facilities was more expected, was also increased (0.4). As far as the aggregate data are concerned, we can observe that the more lack of language skills a user has, the more she uses these cross-language facilities.</p><formula xml:id="formula_0" coords="5,279.23,533.10,44.54,8.77">iCLEF08</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Analysis According to Search Session's Outcome</head><p>In the following sections we are going to analyze users' behavior according to the final outcome of the search sessions. In order to find some correlations about the most successful strategies used by our users, we are going to divide the sessions into two categories: on one hand, "success" refers to those sessions where users were, with or without hints, able to find the proposed target image. On the other hand, "fail" refers to those sessions where the user decided to quit before finding the image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Users' Behavior</head><p>As we saw in Section 3.1, we are going to analyze users' behavior but stressing now on the final outcome of the search sessions. If we see Table <ref type="table" coords="6,311.28,344.57,3.87,8.74" target="#tab_5">6</ref>, the first detail to be noted is the number and percentage of samples of each category: 81.95% of success samples in iCLEF08, 89.77% in iCLEF09 and 84.34% in the aggregate results confirm that finding the proposed images was an easy task. Regarding the average number of hints requested, users in successful sessions asked for 2.32 and 2.38 hints in iCLEF08 and iCLEF09, respectively. Users in failed sessions asked for a similar quantity of hints in iCLEF09 (2.77), while in iCLEF08 the number of hints is lower (1.74).</p><p>Finally, in the aggregate results we can observe that asking for hints seems to have been a good strategy to find the target image, in spite of the score loss, since users in successful sessions asked for 2.34 hints compared to 1.95 for failed sessions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Cognitive Effort</head><p>Analyzing the cognitive effort with respect to the outcome of the search session, our aim is to find some correlation about what strategy was the most convenient for our users to find the images in the iCLEF experiment proposed.</p><p>As shown in Table <ref type="table" coords="7,194.75,112.02,3.87,8.74" target="#tab_6">7</ref>, in the iCLEF08 logs, successful users launched more queries in the monolingual environment than in the multilingual one (4.05 vs. 3.36), while unsuccessful players does not show differences 3.76 vs. 3.79). On the other hand, in the iCLEF09 logs, successful users launched more multilingual queries than monolingual (4.02 vs. 3.65). This can be explained, as mentioned above, because of the kind of the image collection, which was designed to force the multilingual searches. This fact can also be seen in the number of explorations of the ranking, slightly higher than in iCLEF09 (2.48 and 2.93 vs. 2.13 and 2.26). Lastly, in general, users in failed sessions seems to have performed more interactions in the monolingual environment. As the last columns of the table show, the usage of relevance feedback was very low in both categories, being higher in monolingual in iCLEF08 and multilingual in iCLEF09. In general, but still with little differences, successful users tended to use relevance feedback more frequently.</p><formula xml:id="formula_1" coords="7,279.23,218.73,44.54,8.77">iCLEF08</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Usage of Specific Cross-Language Refinement Facilities</head><p>Finally, regarding the manipulation of the personal dictionary (see Table <ref type="table" coords="7,417.43,518.04,3.87,8.74" target="#tab_7">8</ref>), successful users in iCLEF08 used it slightly more often than those who failed (0.08 vs. 0.06). In iCLEF09, the general usage is much more higher, but the pattern is reproduced upside down: unsuccessful players tended to manipulate their dictionaries more often (0.62 vs. 0.46).</p><p>In the aggregate data corresponding to both logs we can observe that successful players used this functionality more frequently (0.2 vs. 0.17).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Questionnaire analysis: Users' Perception on the Task</head><p>Along with the interactions of the users and the information of the search sessions, iCLEF logs also contain two types of questionnaires: one is shown every time the user finishes a search session and it contains questions about the target image and the development of the search. The other questionnaire is shown when the user has completed 15 search sessions and raises overall questions about the task itself, the usefulness of the interface functionalities and the user's performance.</p><p>In this analysis we are going to focus only on the former one, specially in the following questions:</p><p>Which, in your opinion, are the most challenging aspects of the task? 83% of participants from iCLEF08 and 85% from iCLEF09 agree or strongly agree that "Selecting/finding appropriate translations for the terms in my query" was the most challenging aspect of the task. Users from both years also agree or strongly agree with other answers such as "Finding the correct terms to express an image in my own native language", "Handling multiple target languages at the same time" and "Finding the target image in very large sets of results" in about 80% of the cases.</p><p>Which interface facilities did you find most useful? In both years, cross-language functionalities such as the automatic translation and the possibility of maintaining a personal dictionary are more valued than relevance feedback facilities, specially among the iCLEF09 users. 80% of the users from 2009 agree with the usefulness of the personal dictionary, against the 59% who agree with the usefulness of the additional query terms suggested by the system.</p><p>Which interface facilities did you miss? Up to seven different facilities not implemented in the current version of FlickLing are proposed in this question. Among the iCLEF08 users, the most popular answers with an agreement rate about 75% were "The classification of search results in different tabs according to the image caption languages" and "A system able to select the translations for my query terms better".</p><p>As far as the iCLEF09 users are concerned, the most popular answers with more than 80% of support were, along with "A system able to select the translations for my query terms better", "Bilingual dictionaries with a better coverage" and "Detection and translation of multi-word expressions". These answers seem to be accordance with the fact that iCLEF09 users needed to interact more frequently in a multilingual environment with cross-language tools that could be improved.</p><p>How did you select/find the best translations for your query terms? Again a question in accordance to the different users' and images' profiles in both campaigns. While the most popular answer for the iCLEF08 users was "Using my knowledge of target languages whenever possible" (around 90%), iCLEF09 users opted for "Using additional dictionaries and other on-line sources" in 82% of the cases. .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions and Future Work</head><p>In this paper we have summarized the analysis performed on the logs of multilingual image search provided by iCLEF09 and its comparison with the logs released in the iCLEF08 campaign. We have processed more than one million log lines in order to identify and characterize 5, 243 individual search sessions. Each session starts when a registered user is shown a target image and finishes when the user finds the image or decides to give up. Besides, the logs collects all the interactions occurred in the meantime: monolingual and multilingual queries launched, query refinements, navigation across the results ranking, hints showed by the system, usage of the personal dictionaries and other cross-language facilities, etc.</p><p>In this work we have focused on the analysis of users' behavior and their performance trying to find possible correlations between: a) the language skills of the users and the annotation language of the target images; and b) the final outcome of the search session.</p><p>Among the conclusions observed in this work, we can mention:</p><p>• The proposed task was easy, since all users' profiles reach more than 80% of success rate. Users with no competence in the annotation language of the image tend to ask for more hints.</p><p>• Users with some knowledge in the annotation language of the images employ more cognitive effort in monolingual searches, while users without skills need more cognitive effort in multilingual searches in order to reach a similar performance.</p><p>• As expected, the more lack of language skills a user has, the more she uses cross-language facilities.</p><p>• Given the features of the two images collections, in iCLEF08, where most of the images were annotated in known languages, successful users launched more queries in the monolingual environment. On the other hand, in iCLEF09, where multilingual needs were forced on purpose, successful users launched more multilingual queries.</p><p>• Usage of relevance feedback is remarkably low, but successful users tended to use it more frequently.</p><p>• Questionnaires show that cross-language facilities are seen as very positive when proposed in a multilingual search scenario.</p><p>• The answers collected in the questionnaires are in accordance with the fact that iCLEF09 users needed to interact more frequently in a multilingual environment with cross-language tools that could be improved.</p><p>As part of the future work, we're currently widening this study analyzing users' behavior across time as they go ahead in the experiment finishing more and more search sessions, in order to find useful correlations about how they learn to interact with the system and how they test different search strategies.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,156.59,368.35,289.83,162.53"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the logs provided by the iCLEF organization</figDesc><table coords="2,186.73,368.35,229.55,140.67"><row><cell></cell><cell>2008</cell><cell>2009</cell></row><row><cell>registered users</cell><cell>305</cell><cell>130</cell></row><row><cell>log lines</cell><cell cols="2">1, 483, 806 617, 947</cell></row><row><cell>valid search sessions</cell><cell>5, 101</cell><cell>2, 410</cell></row><row><cell>images found</cell><cell>4, 033</cell><cell>2, 149</cell></row><row><cell>images not found</cell><cell>1, 068</cell><cell>261</cell></row><row><cell>hints asked</cell><cell>11, 044</cell><cell>5, 805</cell></row><row><cell>monolingual queries</cell><cell>37, 125</cell><cell>13, 037</cell></row><row><cell>multilingual queries</cell><cell>36, 504</cell><cell>17, 872</cell></row><row><cell>promoted translations</cell><cell>584</cell><cell>725</cell></row><row><cell>penalized translations</cell><cell>215</cell><cell>353</cell></row><row><cell>image descriptions shown</cell><cell>418</cell><cell>100</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,90.00,110.40,423.00,206.32"><head>Table 2 :</head><label>2</label><figDesc>Statistics of the sub-sets of logs analyzed this fact may turn the initial fully multilingual search (target images can be tagged in up to six different languages, e.g.: Dutch, English, French, German, Italian and Spanish) into a bilingual</figDesc><table coords="3,191.43,110.40,220.14,140.67"><row><cell></cell><cell>2008</cell><cell>2009</cell></row><row><cell>considered users</cell><cell>65</cell><cell>33</cell></row><row><cell>log lines</cell><cell cols="2">841, 957 357, 703</cell></row><row><cell>valid search sessions</cell><cell>3, 640</cell><cell>1, 603</cell></row><row><cell>images found</cell><cell>2, 983</cell><cell>1, 439</cell></row><row><cell>images not found</cell><cell>657</cell><cell>164</cell></row><row><cell>hints asked</cell><cell>8, 093</cell><cell>3, 886</cell></row><row><cell>monolingual queries</cell><cell>23, 060</cell><cell>8, 461</cell></row><row><cell>multilingual queries</cell><cell>20, 607</cell><cell>10, 463</cell></row><row><cell>promoted translations</cell><cell>223</cell><cell>525</cell></row><row><cell>penalized translations</cell><cell>70</cell><cell>246</cell></row><row><cell>image descriptions shown</cell><cell>126</cell><cell>42</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,292.82,731.81,24.19,8.74"><head>Table 3 :</head><label>3</label><figDesc>2.42).</figDesc><table coords="4,166.92,111.19,269.16,180.13"><row><cell></cell><cell></cell><cell>iCLEF08</cell><cell></cell></row><row><cell>result</cell><cell cols="3">samples success rate # hints requested</cell></row><row><cell>active</cell><cell>2, 345</cell><cell>85%</cell><cell>2.14</cell></row><row><cell>passive</cell><cell>535</cell><cell>82%</cell><cell>2.22</cell></row><row><cell>unknown</cell><cell>760</cell><cell>73%</cell><cell>2.42</cell></row><row><cell></cell><cell></cell><cell>iCLEF09</cell><cell></cell></row><row><cell>result</cell><cell cols="3">samples success rate # hints requested</cell></row><row><cell>active</cell><cell>0</cell><cell>-</cell><cell>-</cell></row><row><cell>passive</cell><cell>18</cell><cell>78%</cell><cell>1.22</cell></row><row><cell>unknown</cell><cell>1, 585</cell><cell>90%</cell><cell>2.43</cell></row><row><cell></cell><cell cols="2">iCLEF08 + iCLEF09</cell><cell></cell></row><row><cell>result</cell><cell cols="3">samples success rate # hints requested</cell></row><row><cell>active</cell><cell>2, 345</cell><cell>85%</cell><cell>2.14</cell></row><row><cell>passive</cell><cell>553</cell><cell>82%</cell><cell>2.12</cell></row><row><cell>unknown</cell><cell>2, 345</cell><cell>84%</cell><cell>2.45</cell></row></table><note coords="4,134.70,304.44,373.16,8.74"><p>User's behavior according to language skills: average success rate and hints requested</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,132.61,741.20,7.75,8.74"><head>Table 4 :</head><label>4</label><figDesc>1. Cognitive effort according to language skills: typed queries, ranking exploration and usage of relevance feedback</figDesc><table coords="5,124.68,111.19,353.64,215.99"><row><cell></cell><cell></cell><cell></cell><cell>iCLEF08</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">competence typed queries ranking exploration relevance feedback</cell></row><row><cell></cell><cell cols="3">mono multi mono</cell><cell>multi</cell><cell>mono</cell><cell>multi</cell></row><row><cell>active</cell><cell>4.03</cell><cell>3.28</cell><cell>2.09</cell><cell>1.92</cell><cell>0.03</cell><cell>0.03</cell></row><row><cell>passive</cell><cell>4.16</cell><cell>3.31</cell><cell>2.83</cell><cell>2.24</cell><cell>0.05</cell><cell>0.02</cell></row><row><cell>unknown</cell><cell>3.81</cell><cell>4.02</cell><cell>2.36</cell><cell>2.81</cell><cell>0.07</cell><cell>0.09</cell></row><row><cell></cell><cell></cell><cell></cell><cell>iCLEF09</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">competence typed queries ranking exploration relevance feedback</cell></row><row><cell></cell><cell cols="3">mono multi mono</cell><cell>multi</cell><cell>mono</cell><cell>multi</cell></row><row><cell>active</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>passive</cell><cell>4.72</cell><cell>11.06</cell><cell>2.78</cell><cell>11.11</cell><cell>0</cell><cell>0</cell></row><row><cell>unknown</cell><cell>3.48</cell><cell>3.89</cell><cell>1.76</cell><cell>2.43</cell><cell>0.01</cell><cell>0.03</cell></row><row><cell></cell><cell></cell><cell cols="3">iCLEF08 + iCLEF09</cell><cell></cell><cell></cell></row><row><cell cols="7">competence typed queries ranking exploration relevance feedback</cell></row><row><cell></cell><cell cols="3">mono multi mono</cell><cell>multi</cell><cell>mono</cell><cell>multi</cell></row><row><cell>active</cell><cell>4.03</cell><cell>3.28</cell><cell>2.09</cell><cell>1.92</cell><cell>0.03</cell><cell>0.03</cell></row><row><cell>passive</cell><cell>4.18</cell><cell>3.56</cell><cell>2.83</cell><cell>2.53</cell><cell>0.05</cell><cell>0.02</cell></row><row><cell>unknown</cell><cell>3.57</cell><cell>3.91</cell><cell>1.96</cell><cell>2.55</cell><cell>0.03</cell><cell>0.05</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,107.13,545.46,388.74,201.59"><head>Table 5 :</head><label>5</label><figDesc></figDesc><table coords="5,110.78,545.46,381.43,179.73"><row><cell>competence</cell><cell cols="2">dictionary manipulations query terms modified</cell></row><row><cell>active</cell><cell>0.06</cell><cell>0.04</cell></row><row><cell>passive</cell><cell>0.05</cell><cell>0.03</cell></row><row><cell>unknown</cell><cell>0.17</cell><cell>0.11</cell></row><row><cell></cell><cell>iCLEF09</cell><cell></cell></row><row><cell>competence</cell><cell cols="2">dictionary manipulations query terms modified</cell></row><row><cell>active</cell><cell>-</cell><cell>-</cell></row><row><cell>passive</cell><cell>6.56</cell><cell>1.67</cell></row><row><cell>unknown</cell><cell>0.4</cell><cell>0.16</cell></row><row><cell></cell><cell>iCLEF08 + iCLEF09</cell><cell></cell></row><row><cell>competence</cell><cell cols="2">dictionary manipulations query terms modified</cell></row><row><cell>dictionary manipulations</cell><cell>query terms modified</cell><cell></cell></row><row><cell>active</cell><cell>0.06</cell><cell>0.04</cell></row><row><cell>passive</cell><cell>0.27</cell><cell>0.08</cell></row><row><cell>unknown</cell><cell>0.33</cell><cell>0.14</cell></row></table><note coords="5,146.70,738.31,349.17,8.74"><p>Usage of specific cross-language refinement facilities according to language skills</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,90.00,403.46,423.00,178.08"><head>Table 6 :</head><label>6</label><figDesc>User's behavior according to search session outcome: average success rate and hints requested</figDesc><table coords="6,185.93,403.46,231.15,144.26"><row><cell></cell><cell></cell><cell>iCLEF08</cell><cell></cell></row><row><cell>result</cell><cell>samples</cell><cell>%</cell><cell># hints requested</cell></row><row><cell>success</cell><cell>2, 983</cell><cell>81.95%</cell><cell>2.32</cell></row><row><cell>fail</cell><cell>657</cell><cell>18.05%</cell><cell>1.74</cell></row><row><cell></cell><cell></cell><cell>iCLEF09</cell><cell></cell></row><row><cell>result</cell><cell>samples</cell><cell>%</cell><cell># hints requested</cell></row><row><cell>success</cell><cell>1, 439</cell><cell>89.77%</cell><cell>2.38</cell></row><row><cell>fail</cell><cell>164</cell><cell>10.23%</cell><cell>2.77</cell></row><row><cell></cell><cell cols="3">iCLEF08 + iCLEF09</cell></row><row><cell>result</cell><cell>samples</cell><cell>%</cell><cell># hints requested</cell></row><row><cell>success</cell><cell>4, 422</cell><cell>84.34%</cell><cell>2.34</cell></row><row><cell>fail</cell><cell>821</cell><cell>15.66%</cell><cell>1.95</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="7,90.00,231.09,423.00,201.59"><head>Table 7 :</head><label>7</label><figDesc>Cognitive effort according to the search session outcome: typed queries, ranking exploration and usage of relevance feedback</figDesc><table coords="7,124.68,231.09,353.64,167.77"><row><cell cols="7">competence typed queries ranking exploration relevance feedback</cell></row><row><cell></cell><cell cols="3">mono multi mono</cell><cell>multi</cell><cell>mono</cell><cell>multi</cell></row><row><cell>success</cell><cell>4.05</cell><cell>3.36</cell><cell>2.22</cell><cell>2.13</cell><cell>0.05</cell><cell>0.04</cell></row><row><cell>fail</cell><cell>3.76</cell><cell>3.79</cell><cell>2.39</cell><cell>2.26</cell><cell>0.05</cell><cell>0.02</cell></row><row><cell></cell><cell></cell><cell></cell><cell>iCLEF09</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">competence typed queries ranking exploration relevance feedback</cell></row><row><cell></cell><cell cols="3">mono multi mono</cell><cell>multi</cell><cell>mono</cell><cell>multi</cell></row><row><cell>success</cell><cell>3.65</cell><cell>4.02</cell><cell>1.89</cell><cell>2.48</cell><cell>0.02</cell><cell>0.03</cell></row><row><cell>fail</cell><cell>1.96</cell><cell>3.23</cell><cell>0.79</cell><cell>2.93</cell><cell>0.01</cell><cell>0.02</cell></row><row><cell></cell><cell></cell><cell cols="3">iCLEF08 + iCLEF09</cell><cell></cell><cell></cell></row><row><cell cols="7">competence typed queries ranking exploration relevance feedback</cell></row><row><cell></cell><cell cols="3">mono multi mono</cell><cell>multi</cell><cell>mono</cell><cell>multi</cell></row><row><cell>success</cell><cell>3.92</cell><cell>3.58</cell><cell>2.11</cell><cell>2.24</cell><cell>0.04</cell><cell>0.04</cell></row><row><cell>fail</cell><cell>3.4</cell><cell>3.67</cell><cell>2.07</cell><cell>2.4</cell><cell>0.04</cell><cell>0.02</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="8,90.00,111.19,423.00,190.03"><head>Table 8 :</head><label>8</label><figDesc>Usage of specific cross-language refinement facilities according to the search session outcome</figDesc><table coords="8,110.78,111.19,381.43,156.21"><row><cell></cell><cell>iCLEF08</cell><cell></cell></row><row><cell>competence</cell><cell cols="2">dictionary manipulations query terms modified</cell></row><row><cell>success</cell><cell>0.08</cell><cell>0.05</cell></row><row><cell>fail</cell><cell>0.06</cell><cell>0.05</cell></row><row><cell></cell><cell>iCLEF09</cell><cell></cell></row><row><cell>competence</cell><cell cols="2">dictionary manipulations query terms modified</cell></row><row><cell>success</cell><cell>0.46</cell><cell>0.17</cell></row><row><cell>fail</cell><cell>0.62</cell><cell>0.18</cell></row><row><cell></cell><cell>iCLEF08 + iCLEF09</cell><cell></cell></row><row><cell>competence</cell><cell cols="2">dictionary manipulations query terms modified</cell></row><row><cell>dictionary manipulations</cell><cell>query terms modified</cell><cell></cell></row><row><cell>success</cell><cell>0.2</cell><cell>0.09</cell></row><row><cell>fail</cell><cell>0.17</cell><cell>0.07</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work has been partially supported by the <rs type="funder">Regional Government of Madrid</rs> under the <rs type="funder">Research Network MAVIR</rs> (<rs type="grantNumber">S-0505/TIC-0267</rs>) and the <rs type="funder">Spanish Government</rs> under project <rs type="projectName">Text-Mess</rs> (<rs type="grantNumber">TIN2006-15265-C06-02</rs>).</p><p>We would also like to thank <rs type="person">Javier Artiles</rs> for his intensive work during the implementation of the FlickLing interface and all the collaborators involved in collecting the image corpus and the testing stage.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_j7WTbng">
					<idno type="grant-number">S-0505/TIC-0267</idno>
				</org>
				<org type="funded-project" xml:id="_WJFpfBj">
					<idno type="grant-number">TIN2006-15265-C06-02</idno>
					<orgName type="project" subtype="full">Text-Mess</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="9,105.50,707.73,407.51,8.74;9,100.52,719.69,412.49,8.74;9,100.52,731.64,412.48,8.74;9,100.52,743.60,199.51,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,271.96,707.73,241.05,8.74;9,100.52,719.69,100.52,8.74">Overview of iCLEF 2008: search log analysis for Multilingual Image Retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Karlgren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,225.62,719.69,287.38,8.74;9,100.52,731.64,344.78,8.74">Evaluating Systems for Multilingual and Multimodal Information Access. 9th Workshop of the Cross-Language Evaluation Forum (CLEF 2008)</title>
		<title level="s" coord="9,492.11,731.64,20.89,8.74;9,100.52,743.60,54.96,8.74">Denmark. LNCS</title>
		<meeting><address><addrLine>Aarhus</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5706</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,105.50,112.02,337.55,8.74" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="10,272.35,112.02,84.85,8.74">Overview of iCLEF</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Karlgren</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
	<note>This volume</note>
</biblStruct>

<biblStruct coords="10,105.50,131.95,407.50,8.74;10,100.52,143.90,412.48,8.74;10,100.52,155.86,79.95,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,405.01,131.95,107.99,8.74;10,100.52,143.90,110.03,8.74">FlickLing: a multilingual search interface for Flickr</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Peinado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Artiles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Barker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>López-Ostenero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,234.23,143.90,195.00,8.74">Working Notes for the CLEF 2008 Workshop</title>
		<meeting><address><addrLine>Aarhus, Denmark</addrLine></address></meeting>
		<imprint>
			<date>17-19 September</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,105.50,175.78,407.51,8.74;10,100.52,187.74,412.49,8.74;10,100.52,199.69,234.20,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,359.45,175.78,153.55,8.74;10,100.52,187.74,233.79,8.74">UNED at iCLEF 2008: Analysis of a Large Log of Multilingual Image Searches in Flickr</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Peinado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Artiles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>López-Ostenero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,359.66,187.74,153.35,8.74;10,100.52,199.69,41.16,8.74">Working Notes for the CLEF 2008 Workshop</title>
		<meeting><address><addrLine>Aarhus, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">September 17-18. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,105.50,219.62,407.50,8.74;10,100.52,231.57,412.49,8.74;10,100.52,243.53,412.49,8.74;10,100.52,255.48,197.68,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,358.84,219.62,154.16,8.74;10,100.52,231.57,67.69,8.74">Log Analysis of Multilingual Image Search in Flickr</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Peinado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Artiles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>López-Ostenero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,192.02,231.57,320.98,8.74;10,100.52,243.53,297.06,8.74">Evaluating Systems for Multilingual and Multimodal Information Access. 9th Workshop of the Cross-Language Evaluation Forum (CLEF 2008)</title>
		<meeting><address><addrLine>Aarhus, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Verlag</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5706</biblScope>
			<biblScope unit="page" from="236" to="242" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
