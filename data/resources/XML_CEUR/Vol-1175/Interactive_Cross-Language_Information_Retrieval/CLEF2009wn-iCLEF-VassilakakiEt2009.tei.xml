<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,151.34,115.96,312.67,12.62">Users&apos; Perceptions of Searching in FlickLing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,151.53,154.10,84.32,8.74"><forename type="first">Evgenia</forename><surname>Vassilakaki</surname></persName>
							<email>evgenia.vassilakaki@student.mmu.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. Information &amp; Communications</orgName>
								<orgName type="institution">MMU</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,243.38,154.10,69.78,8.74"><forename type="first">Frances</forename><surname>Johnson</surname></persName>
							<email>f.johnson@mmu.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. Information &amp; Communications</orgName>
								<orgName type="institution">MMU</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,321.28,154.10,52.33,8.74"><forename type="first">R</forename><forename type="middle">J</forename><surname>Hartley</surname></persName>
							<email>r.j.hartley@mmu.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. Information &amp; Communications</orgName>
								<orgName type="institution">MMU</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,400.73,154.10,63.09,8.74"><forename type="first">David</forename><surname>Randall</surname></persName>
							<email>d.randall@mmu.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="department">Dept. Information &amp; Communications</orgName>
								<orgName type="institution">MMU</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,151.34,115.96,312.67,12.62">Users&apos; Perceptions of Searching in FlickLing</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">789B5658E8C16DAD678A845B2F015197</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Multilingual Information Retrieval</term>
					<term>User Behaviour</term>
					<term>User Image Seeking Behaviour</term>
					<term>Flickr</term>
					<term>FlickLing</term>
					<term>iCLEF</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This study aims to explore users' image seeking behaviour when searching for known, non-annotated images across languages in FlickLing. In particular, the investigation reported in this paper aims to demonstrate the value in focusing on user's trust and confidence in the exploration of seeking behaviour to reveal users' perceptions of the tasks involved when searching across languages. The task assigned to our 24 users was to search for three specific images described in Dutch, German and Spanish consecutively. In this context, four different methods, both qualitative and quantitative (questionnaires, observation, retrospective thinking aloud and interviews) were employed. Preliminary finding regarding users' switching between the two modes, users' thinking of languages and their answers to the two questionnaires on trust and confidence are only reported here. It appears from our preliminary findings that there is variation in our users perceptions of searching for images across languages and their approach to using translations and that this occurs regardless of the amount or type of help or guidance given.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The development of efficient and effective Cross Language Information Retrieval (CLIR) systems depends not only on the implementation of the various techniques for organizing linguistic resources but also on users' adaptation and usage. The interactive CLEF (iCLEF) track in Cross Language Evaluation Forum (CLEF) provides the participants with the necessary environment to run interactive experiments and focus on users' image seeking behaviour in multilingual environments. This is our second year participating in iCLEF track focusing on users' behaviour while searching across languages in FlickLing.</p><p>In the iCLEF2008 paper <ref type="bibr" coords="1,257.81,608.30,9.96,8.74" target="#b3">[4]</ref>, the aim of the study was to explore users' image seeking behaviour when searching for the three known, non-annotated images across languages in FlickLing. In particular, three research questions were addressed: a) identify the reasons that determined our users' choice of a specific mode (monolingual/ multilingual), b) examine if and/or to what extent users were thinking about languages when searching and retrieving images and c) examine if and/or to what extent users were paying attention to translations when searching and retrieving images. Four different methods, both qualitative and quantitative were adopted to answer these questions. A questionnaire was used to collect data on the users' knowledge of foreign languages, previous experience in searching for images, in searching across languages and previous experience with Flickr. An observation sheet was designed to help the facilitator take notes and to record comments and remarks made by the users on specific elements of their search behaviour. These notes further aided the formulation of questions during the interviews. In addition, retrospective thinking aloud was implemented to shed light on the users' actions and thoughts. Screen capture software was used to record a search session and this was then played back to the user asking them to describe what they were doing and what they were thinking. Finally, semi-structured interviews were carried out with each participant focusing on further explaining their specific actions, comments and remarks stated during the whole study. For further information on the way these methods were employed see <ref type="bibr" coords="2,182.14,310.28,9.96,8.74" target="#b3">[4]</ref>, <ref type="bibr" coords="2,198.74,310.28,9.96,8.74" target="#b4">[5]</ref>.</p><p>The iCLEF2008 small study <ref type="bibr" coords="2,278.01,325.93,10.52,8.74" target="#b3">[4]</ref> showed that less than half of our ten users appeared to consider identification of the language important in retrieving the images. The majority either lacked confidence in using the different languages or they were so focused on retrieving the images and completing the task that they were not thinking about languages. Only four out of the ten users tried to identify the language of the images and interact with the translations. These users judged the translations as poor because either they were not retrieved, they were not corresponding to users' search terms or they were retrieving irrelevant results. As a consequence, users were losing interest and trust in translations resulting in no usage of them or not paying attention to them.</p><p>The iCLEF2008 study also revealed some insight into users' trust in searching in a multilingual environment such as FlickLing and a possible relationship between trust and the use of translations, to search for the images in different languages. In addition, it provided some indication that users' confidence has an impact when searching for images across languages and that confidence may or may not be affected by users' knowledge of foreign languages. In this context, a follow up study was designed for iCLEF2009 drawing from the lessons learned from the iCLEF2008 paper <ref type="bibr" coords="2,259.47,532.87,10.52,8.74" target="#b3">[4]</ref> and focusing on users' trust and confidence as revealed and/ or formulated in multilingual environments. As a consequence, the iCLEF2009 paper again aims to explore users' image seeking behaviour when searching known, non-annotated images across languages. In particular, the investigation reported in this paper aims to demostrate the value in focusing on user's trust and confidence in the investigation of seeking behaviour to reveal users' perceptions of the tasks involved when searching across languages.</p><p>The remainder of this paper is structured as follows: a description of the methods employed and the way the study was carried out are outlined in section 2. An initial analysis of the findings is given in sections 3. Finally, we conclude by summarizing the current indications of users' behaviour in section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head><p>In this section, further details on the test object, the task, the users and the methods employed are illustrated.</p><p>Test Object: This study used the FlickLing multilingual search engine for images as developed and provided by iCLEF organizers <ref type="bibr" coords="3,380.38,177.91,9.96,8.74" target="#b3">[4]</ref>. The same set up of the interface was kept for this year's participants to carry out their interactive studies.</p><p>Task: As in the iCLEF2008 paper, our users were asked to search for the first three known, non annotated images given after login in FlickLing. The users did not know in advance in which of the six languages supported by FlickLing (English, German, Dutch, French, Italian and Spanish) the three images were described. As a result, users had to use all the features and different modes (monolingual/ multilingual) provided by FlickLing to search the three images across languages.</p><p>As opposed to last year's study, the three images were pre-selected and presented to all 24 users so that the seeking behaviour and the thoughts recorded for each user referred to the experience of searching for the same three images. The three images were described in Dutch, German and Spanish consecutively. Drawing from <ref type="bibr" coords="3,198.08,345.28,10.52,8.74" target="#b3">[4]</ref> during the selection process all English described images were excluded as it was found that the majority of the users used English keywords to search for the given images and only a landmark or a piece of writing would trigger them to search across languages before going for the hints. As a result, no English images were given in an attempt to encourage users to think about languages and interact with the translations.</p><p>In addition, the images selected had both a 'heading' and at least three 'tags' describing them in order to provide our users with as many entry points to these images as possible. This emerged from the iCFLEF2008 study <ref type="bibr" coords="3,433.15,440.92,10.52,8.74" target="#b3">[4]</ref> as users complained when the images lacked either a heading or tags making their task of finding it more difficult. Furthermore, all three images included a distinctive landmark or a piece of writing that hinted at the language of the image. Again the 2008 study highlighted the users behaviour in using details in the image to identify the language of the image. Furthermore, there was no order of easy, medium and hard to find images adopted and applied in both studies since there was not such a distinction in FlickLing.</p><p>In this context, it should be also noted that during this year's study, words like task, or study were carefully avoided both from the written instructions read to the users and during the process of recruitment. Again drawing from <ref type="bibr" coords="3,459.38,560.48,10.52,8.74" target="#b3">[4]</ref> it was found that the users were obsessed with finding the images and completing the task "successfully" and that this competitive behaviour may have been influenced by the request for users to take part in the FlickLing task.</p><p>User Sample: This study used a sample of twenty four (24) users, eighteen (18) female and six (6) male ranging in age from 18 to 32 and only one stated above 32. In addition, eleven out of the twenty four users were 1st year undergraduate students, five 2nd year undergraduate students and the remaining eight postgraduate students all studying at Manchester Metropolitan University (MMU). Furthermore, twenty two users were English Native speakers and the remaining two were Greek and Finnish native speakers. Eight were monolingual, two bilinguals and sixteen users stated knowledge of one or more foreign languages (this includes the two bilingual users who stated knowledge of additional foreign languages). In particular, the eight monolingual users were English native speakers, one of the bilinguals had Bengali as a native language, with an excellent knowledge of English and a basic knowledge of French and Spanish and the second user stated Urdu and English as native languages, a basic knowledge for German, Dutch, Italian and Spanish, a good knowledge for French and an excellent knowledge of Hindi. Finally, from the fourteen remaining users the two non English native speakers stated an excellent knowledge of English, seven users stated a basic and one very good knowledge of German, seven users stated a basic, one good, one very good and one excellent knowledge of French, two users stated a basic and one excellent knowledge of Italian, one stated a basic knowledge of Dutch and finally five users stated a basic knowledge of Spanish (see Table <ref type="table" coords="4,182.14,298.32,3.87,8.74" target="#tab_0">1</ref>). All the twenty four users stated their experience in searching for images. In particular, five of them search for images very often, eight of them often, eight of them sometimes and the remaining three users rarely. In addition, eight out of the twenty four users have searched on the web for an image in a language other than their native. These users employ mainly their own language skills (29%), an online (24%) and hard copy dictionary (24%) consecutively, an online translator (13%) and the help of a friend (10%). The main reason for doing so was for school projects and assignments. The remaining sixteen users who are searching images only in their native language explained that they "never needed to".</p><p>In regards to previous experience with Flickr, eighteen out of the twenty four have never used Flickr and explained "never heard of it", "never needed to", "I have not got around to using it" etc. Only six users have used Flickr in the past mainly for searching images (57%), sharing images (29%) and "been directed to it by Google" (14%).</p><p>Instructions: In iCLEF2008 study, the same written instructions were read to all users yet it was observed that the majority of users would use the Help instructions and ask for additional clarifications both regarding the task and the various features of FlickLing. In the context of trying to investigate to what extent instructions may affect or not users' trust and confidence in FlickLing and again retain an element of control in order to compare the findings, three different texts of instructions were written and used in the iCLEF2009 study. In particular, the users were divided in three different groups upon arrival. Each group was provided with different level of instructions of the given task going from 'no' to 'detailed' information regarding both the task and the functionality of FlickLing's features. In particular, the information given to the first group was kept on a 'need to know basis' (see Appendix: Task Instructions). Users were given the minimum information necessary to understand and complete the task assigned. No explanation was given of the different fields and features employed in FlickLing or how they could register and login. On the contrary, users were left alone to discover the multilingual environment and form their search strategies to retrieve the three given images.</p><p>The second group of users beside the general instructions concerning the task were also informed about the languages that FlickLing supports and in which the three images can be described (see Appendix: Task Instructions). In addition, further information concerning the features of FlickLing were briefly mentioned before describing them after login. This was a way of preparing (even unconsciously) the users for what was to be described thoroughly afterwards, on first login. Users were also instructed about the registration process but the information given was kept to what each field stands for rather than how it functions. In this context, information about the fields and features of FlickLing was again provided after login but it was limited to what each field stands for rather than disclosing their functionality. This element was left to users to explore on their own while interacting with the interface.</p><p>The users in the third group were given the same instructions with the second group with the difference that the functionality of the features in FlickLing was also disclosed (see Appendix: Task Instructions). In particular, the languages supported in FlickLing and in which the images could be searched across and instructions concerning the registration process and how the various fields function were thoroughly described to these users. In addition, the fields found in FlickLing and their functionality were also presented and thoroughly explained to the users in a more technical way. This group was given all the information available on the task and the Flick-Ling interface, information focusing on both what is in there and how it functions. These were explained in order to release users from the burden of exploring it on their own. In addition, it was done to meet the purpose of providing different level of information between the three groups.</p><p>The assignment of users to each group was done based on users' knowledge of foreign languages. In particular, based on the number of foreign languages of which they have some knowledge, the users were assigned to a specific group. This was done in the context of equally assigning users with no knowledge of foreign languages, knowledge of only one foreign language and knowledge of more than one foreign languages across the three groups. In this way, homogeneity of the user sample distributed to the three groups in regards of knowledge of languages was enabled.</p><p>Data Collection: The same four methods, both qualitative and quantitative (questionnaire, observation, retrospective thinking aloud and interviews) were used for both studies. The adoption of the same methods was agreed on the basis that these methods enabled us to draw insights on different aspects of users' characteristics and/or search behaviours. In addition, the defined order of their implementation enabled us to gradually gain a better and a more comprehensive insight into users' actions and thoughts and formulation of relevant questions. Moreover, the way of combining the chosen methods contributed to offset their weaknesses and draw on their strengths enabling a better and more comprehensive understanding of users' image seeking behaviour in multilingual environments <ref type="bibr" coords="6,196.48,265.23,9.96,8.74" target="#b4">[5]</ref>. In particular, further description of the differences and similarities between the way the four methods were designed and applied for both studies is given below.</p><p>Questionnaires: In the iCLEF2008 study one questionnaire was adopted and implemented inquiring on users' native language, level of comprehension for a series of foreign languages, previous experience in searching for images, in searching across languages and in using Flickr and finally user demographics. This questionnaire was also adopted in the iCLEF2009 study because it successfully enabled the definition of the user sample characteristics and users' previous experience in each of the sections of interest and the formulation of relevant questions during interviews <ref type="bibr" coords="6,238.39,387.56,9.96,8.74" target="#b4">[5]</ref>. In addition, one more question was included in this questionnaire as a supplement regarding the means users employ to search across languages. This question was derived from users' comments during retrospective thinking of the iCLEF2008 study when they were describing the way in which they search across languages.</p><p>In addition to the first questionnaire, two more questionnaires were designed and implemented inquiring on users' trust and confidence which also emerged from <ref type="bibr" coords="6,158.43,474.02,9.96,8.74" target="#b3">[4]</ref>. The second questionnaire consisted of a series of statements reflecting on users' trust and confidence in general when they are searching for images on the web. A predefined six points scale (Don't Know, Not at all, A little, So-So, Very Much So, Totally) was provided for users to choose for each statement. These statements did not exceed ten and they were implemented as a second part of the first questionnaire. This was done both for presentation reasons and in an attempt to relief users from the extra hassle of having to complete two different questionnaires on arrival.</p><p>The third questionnaire had the same format as the second questionnaire. It consisted of a series of statements with a predefined scale of six points answers reflecting this time users' trust and confidence in FlickLing and its various features (monolingual/ multilingual mode, translations, hints etc). These statements did not exceed twelve in number. These two questionnaires were used to formulate an idea of each users' trust and confidence both in general and in particular in FlickLing and formulate relevant questions during the interviews. Finally, all three questionnaires were employed to gather information on specific aspects of this study. At the same time, they all contributed to the same goal to explore users' image seeking behaviour in multilingual environments.</p><p>Observation: This study adopted again the same observation sheet as designed for the iCLEF2008 study <ref type="bibr" coords="7,284.01,157.08,9.96,8.74" target="#b3">[4]</ref>. It was kept the same because it proved valuable for making notes on specific actions of users while performing the task and formulating relevant questions during interviews. In addition, it enabled the facilitator to note down specific user's expressions while performing the task and use those to engage users in conversation shading light on the specific actions and thoughts of users reflecting on the reasons why <ref type="bibr" coords="7,362.05,216.85,9.96,8.74" target="#b4">[5]</ref>.</p><p>Retrospective Thinking Aloud: This study also employed the retrospective thinking aloud method to reflect on users thoughts and action when searching for images across languages. This method belongs to the Think Aloud Protocols and it is a widely used method for usability testing of software and interfaces <ref type="bibr" coords="7,134.77,278.85,9.96,8.74" target="#b1">[2]</ref>. It was adopted and applied in the same way and using the same screen capture software as in the iCLEF2008 study <ref type="bibr" coords="7,323.21,290.80,9.96,8.74" target="#b3">[4]</ref>. The same method was adopted because during the iCLEf2008 study it enabled the facilitator to gain insights on users' information seeking behaviours, identifying the reasons why users were behaving in this way and asking relevant questions during interviews <ref type="bibr" coords="7,438.43,326.67,9.96,8.74" target="#b4">[5]</ref>.</p><p>Interviews: The same method of interview was also adopted in this study as in the iCLEF2008 study <ref type="bibr" coords="7,254.52,352.80,10.52,8.74" target="#b3">[4]</ref> because it contributed to further clarifying users' comments and sayings during retrospective thinking aloud, facilitator's notes on the observation sheet and users' answers in the questionnaires. These interviews were again semi-structured and kept as brief as possible because users were already tired because of the retrospective thinking aloud and they were not willing to spend more time on responding to additional questions <ref type="bibr" coords="7,422.58,412.58,9.96,8.74" target="#b4">[5]</ref>.</p><p>In general, the same methods were adopted and applied in the same order because they succeeded in gathering and verifying the validity and reliability of the data on users' image seeking behaviour in multilingual environments. The weaknesses posed by every method was also considered and tackled by employing a mixed methods research so that the weaknesses of one approach were offset by the strengths of others <ref type="bibr" coords="7,299.39,486.53,9.96,8.74" target="#b4">[5]</ref>. Although the same methods was used and implemented in the same order, minor changes and adjustments to the aim of this year study was considered important in an attempt to focus more on users' trust and confidence when searching for images in multilingual environments.</p><p>iCLEF2009 Study's Experimental Procedure: This study consisted of 24 individual sessions which lasted on average one hour and a half each. Each user on arrival was given the two questionnaires in the form of one to fill in. Based on users' number of foreign languages as they would define them in the first questionnaire, the facilitator would assign them a specific group (e.g. 1st, 2nd or 3rd). In addition, a number (01, 02, 03 etc) was also assigned to each user based on users' arrival in order to ensure the anonymity of the data. Once the user had the questionnaire completed, the facilitator read the relevant instructions depending on which group the user was assigned. The users then started the task while the facilitator observed and took notes. After the completion of the task, users were asked to fill in the last questionnaire. Users were then asked, based on the video capturing their search session, to describe their actions and reflect their thoughts. At the same time, the facilitator took notes of users sayings and scanned through the two last questionnaires focusing on specific patterns regarding users' trust and confidence. Finally, a brief interview followed enabling the facilitator to ask questions based on the notes taken throughout the process to further clarify users' image seeking behaviour.</p><p>Data Analysis: The data gathered throughout the study were then analyzed to shed light on the different aspects of users' actions and perceptions. In particular, the questionnaires were processed in order to define the user sample's characteristics (see Table <ref type="table" coords="8,268.03,227.85,4.43,8.74" target="#tab_0">1</ref>) and users' level of trust and confidence both in general (see Table <ref type="table" coords="8,215.56,239.80,4.43,8.74">5</ref>) and in FlickLing (see Table <ref type="table" coords="8,348.55,239.80,3.87,8.74">6</ref>). In addition, the transcripts based on retrospective thinking aloud and interviews were used to reveal users justifications of their actions and thoughts as well as their answers in the two questionnaires on trust and confidence. Furthermore, the videos based on users' image seeking behaviour were used to identify the specific actions of users and reflect back to users justifications and thoughts recorded during retrospective thinking aloud.</p><p>The transcripts based on retrospective thinking aloud only were further analyzed in regards to specific elements such as: a) users' switching between the modes (monolingual/ multilingual) throughout the three images (see Table <ref type="table" coords="8,475.61,348.66,4.98,8.74" target="#tab_2">3</ref> and 4), b) users' thinking about languages throughout the task (see Table <ref type="table" coords="8,468.97,360.61,3.87,8.74" target="#tab_1">2</ref>), c) what triggered the users to think about the language of each image, d) the reasons why they were giving up on each image, e) why they were using the hints each time for each image and their actions after taking each hint, f) users' comments regarding trust and confidence. In addition, the users' explanations of their answers in the two questionnaires on trust and confidence during interviews were also identified and grouped. In particular, for each user specific comments were identified regarding a) users' trust in general, b) users' trust in FlickLing and c) whether their trust remained the same or changed throughout the task. The same was done for users' comments regarding confidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Findings</head><p>The small scale iCLEF2008 study laid the foundations and revealed the reasons why users were switching between the two modes, the extend to which they were thinking about languages and paying attention to translations consecutively. The current study aims to extend and reveal users' perceptions of the tasks involved when searching across languages based on these behaviours and the expressed justifications. In the context of a preliminary analysis and interpretation of the data collected, we can report the following in regards to users' perceptions when searching for known, non-annotated images across languages. In particular, data collected from the retrospective thinking analysis, the questionnaires on trust and confidence and the videos recorded will be presented in an attempt to identify users' perceptions when searching across languages.</p><p>One important element in the process of identifying users' perceptions is the extent to which they were thinking about languages throughout the three images. In particular (see Table <ref type="table" coords="9,239.36,142.90,3.87,8.74" target="#tab_1">2</ref>), on the first image thirteen users did not think about languages before going for the first hint, six of whom were from the first group, three from the second and four from the third group. In addition, five users were thinking about languages from the beginning of the task, one of whom belonged to the first group and two to the second and third consecutively. Furthermore, six users started the task without thinking about languages but at some point before taking the hint started realizing that they needed to search across languages. It is also interesting to note that nineteen out of twenty four users started thinking about languages after taking the hint. Four users misinterpreted the hint on language and used it as a keyword. One user did not use the hints at all.</p><p>In terms of the second image, eight users started searching without thinking about languages, five of whom were from the first group, one from the second and two from the third. In addition, ten users were thinking about languages, three of whom from the first and second group consecutively and four from the third. Five users started without thinking about languages but at some point before going for the hint realized that they would need to search across languages, four of whom were from the second and one from the third group. Only one user started with a perception of languages but at some point he realized that he was actually trying to search only in English and he belonged to the third group. On the second image, non of the users misinterpreted the hint and used it as a keyword and again one user did not make use of the hints.</p><p>In regards to the last image, ten users again started without thinking about languages, four of whom were from the first, five from the second and one from the third group. In contrast twelve were thinking about languages, four of whom were from the first group, three from the second and five from the third. Two users started thinking about languages after spending sometime searching for the image but before going for the hint, these belonged to the third group. On the third image, again no users misintepreted the hint and this time four of them did not make use of the hints.</p><p>It is interesting to point out that only three users were thinking about languages and trying to search for the three images across languages from the beginning and throughout the task. The rest of the users either did not think about languages throughout the three images and only the hint triggered them to think about it or at some point either on the first or the second image started to understand that they would need to search across languages.</p><p>Of particular interest is some of users' remarks regarding the task of searching across languages: " but I didn't know what else to write or what I should do, because I didn't know any languages and things like searching in other languages", "even though I am writing in Dutch it doesn't necessarily mean that it will bring up different images or any more images", "but I didn't think that it would affect, especially that it would affect the search that you would use because you would have Dutch as a language to search so, I just kept on typing English search", "ok it's making me do more that just search, it's making me use other languages for me to search and then I was happier because I could search a Spanish word which I obviously don't speak", "searching in different languages seems, sounds like it would be much harder than searching in English", "I just found that I had to think about a lot of things like you have to find the image and try to translate it as well as find out if it is in English...it took me a while to grasp, what I was meant to be doing for this one, like I realized it had to be in a different language the image but actually I was looking for keywords...".</p><p>Another aspect of users perception of searching across languages is the use of the two modes (monolingual/multilingual) (see Table <ref type="table" coords="10,387.30,253.05,4.98,8.74" target="#tab_3">3</ref> and<ref type="table" coords="10,416.57,253.05,32.07,8.74" target="#tab_5">Table 4</ref>). Four out of twenty four users stayed and used only one mode throughout the three images. In particular, three used only the monolingual mode and one only the multilingual mode throughout the three images. In terms of the rest twenty users, on the first image ten were switching between the two modes, eight used only the monolingual mode and the remaining two only the multilingual. On the second image, sixteen users were again switching between the two modes and four used only the multilingual mode. On the last image, seventeen users were switching between the modes, two were using only the monolingual and one the multilingual mode.</p><p>In the context of investigating users' perceptions of the tasks involved when searching for images across languages, users' degree of trust in applications and confidence in their searching and language skills were also monitored both with the two questionnaires employed, the users' comments during retrospective thinking aloud and the individual interviews. In regards to the second questionnaire (see Table <ref type="table" coords="10,224.57,434.93,3.87,8.74">5</ref>), the majority of the twenty four users have "Not at all" confidence in their language skills to search for images across languages on the web (S9), trust "A little" online translators to help them translate a text (S3), for languages of which they have some knowledge, they trust "A little" provided translations for searching on the web (S5) and they trust "A little" for use the search terms suggested to them by search engines on the web (S6).</p><p>In addition, the majority of the twenty four users trust "So-so" 1 applications on the web to help them do the things they want to do (S1), the results that search engines on the web give (S2), and they have "So-so" confidence in their personal skills and abilities to search for images on the web (S8). Furthermore, the majority of the twenty four users answered equally that for languages they do not understand, they trust "A little" and "So-so" provided translations for searching on the web (S4). The majority again equally stated that they trust "Soso" and "Very much so" Help instructions to understand the use of interfaces (S7). Finally, the majority of users who have experience in searching on the web across languages stated that they have "Very much so" confidence when searching images across languages because of their relevant experience.</p><p>In terms of the third questionnaire (see Table <ref type="table" coords="11,350.90,143.16,3.87,8.74">6</ref>), the majority of the twenty four users stated they "Don't know" for the statement "I trusted the help instructions to guide me through FlickLing (S8)". In addition, the majority had "Not at all" condence in their language skills to search for the images across languages in FlickLing (S11). The majority of users had "A little" condence in their personal skills to search for the images in FlickLing (S10) and in their experience that they were gaining in FlickLing for searching the images across languages (S12). In addition, the majority "So-so" trusted the results that FlickLings both monolingual and multilingual mode gave them (S1 and S2), trusted "So-so" the translations FlickLing gives for languages they do not know (S4) and they are "So-so" condent that FlickLing helped them search across languages for the images (S9). Finally, the majority trusted "Very much so" FlickLing to translate their query (S3), the translations FlickLing gives for languages they understand (S5), FlickLing to suggest search terms (S6) and the hints provided by FlickLing to search for the images (S7).</p><p>The second goal of the analysis would be to identify the reasons why users were or were not thinking about languages on each image and throughout the task. In addition, the reasons why the four users used only one mode for searching across languages and why the rest were either switching between the two or using just one mode while searching for the three images are to be further analyzed. In terms of users' trust and confidence, further analysis is intended to combine the data gathered from questionnaires, retrospective thinking aloud and interviews to shed light on the reasons why users provided the following answers to the 2nd and 3rd Questionnaires and determine whether trust and confidence are factors affecting users' perceptions of the tasks involved when searching across languages. Finally, to meet our aim to gain insight into users search behaviour and use of translations further analysis will be carried out on data such as users' comments regarding the three given images, their comments regarding their language skills, and their interpretation and usage of the translation mechanism. It appears from our preliminary findings that there is variation in our users perceptions of searching for images across languages and their approach to using translations and that this occurs regardless of the amount or type of help or guidance given. Further analysis of the data collected on users perceptions of the task and their explanation for their actions may provide further insight into understanding the user in the design and development of multilingual retrieval systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusion</head><p>This study aimed at exploring users' image seeking behaviour when searching for known, non-annotated images across languages in FlickLing. In particular, this paper aimed to demonstrate the value in focusing on user's trust and confidence in the investigation of image seeking behaviour to reveal users' perceptions of the tasks involved when searching across languages. The task assigned to our 24 users was to search for the three images given to them after first login. These images were described in Dutch, German and Spanish consecutively. In this context, four different methods, both qualitative and quantitative (questionnaires, observation, retrospective thinking aloud and interviews) were employed to meet its research question.</p><p>Preliminary findings regarding users' switching between the two modes, users' thinking of languages and their answers to the two questionnaires on trust and confidence were only reported due to the inability to process the large amount of data collected in such a short period of time. Nonetheless, it appears from our preliminary findings that there is variation in our users perceptions of searching for images across languages and their approach to using translations and that this occurs regardless of the amount or type of help or guidance given. Further analysis of the data will provide a better understanding of users' behaviour and perceptions so as to build cross-language information retrieval systems that better serve users.</p><p>First Group Task Instructions -The organizers would like to thank you for sparing some of your time to participate in this study. -I would like you first to fill in this short questionnaire on basic background knowledge. -This study uses FlickLing, a multilingual interface for searching images across languages. You are asked to use this interface to search the first three images given to you after login. The images given can be described in any of the following six (6) languages: English, German, Dutch, French, Italian and Spanish. You will not know in advance in which of these languages the images provided are described. Therefore, you need to use the features supported by the FlickLing interface in order to search the three (3) images across languages. -At this point, the organizers feel the need to remind you that it is the system and not you that is being evaluated and that you should perform as usual, spending as much time as you would have normally spent on searching. -You will be asked to fill in another short questionnaire after completing the searches for the three images. -Your search session will be system captured and played back to you. You will then be asked to describe your thoughts and actions while searching for the three images. The facilitator will encourage you to keep on describing your thoughts and actions when going to silence. A digital recorder will be used to tape your description. -At the end, a short length interview will take place between you and the facilitator that will be also taped. -I would now ask you to register as a member of the MMU team and start searching for the images.</p><p>Second Group Task Instructions -The organizers would like to thank you for sparing some of your time to participate in this study. -I would like you first to fill in this short questionnaire on basic background knowledge. -This study uses FlickLing, a multilingual interface for searching images across languages. You are asked to use this interface to search the first three images given to you after login. The images given can be described in any of the following six (6) languages: English, German, Dutch, French, Italian and Spanish. You will not know in advance in which of these languages the images provided are described. Therefore, you need to use the features (Help instructions, monolingual/multilingual mode, translations, suggested terms, give up button and hints) supported by FlickLing interface in order to search the three (3) images across languages. -At this point, the organizers feel the need to remind you that it is the system and not you that is being evaluated and that you should perform as usual, spending as much time as you would have normally spent on searching.</p><p>-You will be asked to fill in another short questionnaire after completing the searches for the three images. -Your search session will be system captured and played back to you. You will then be asked to describe your thoughts and actions while searching for the three images. The facilitator will encourage you to keep on describing your thoughts and actions when going to silence. A digital recorder will be used to tape your description. -At the end, a short length interview will take place between you and the facilitator that will be also taped. -I would now guide you through registration for login to the FlickLing. You need to click on 'register' button. First, you need to type in an 'email account' and provide a 'password'. Choose your 'native language' from the menu and the 'language of the interface' again from the ones in the relevant menu. Determine your team from the scroll down menu as 'MMU' team. Choose from the menu the 'level of comprehension' for the six languages supported by FlickLing and then click on 'ok'. -You are now ready to use the FlickLing interface and search for the three images. As you can see on your left, you have the first image. You can click on it in order to bring it forward and see it in detail. Two modes are provided, the monolingual and multilingual. On the monolingual, you write in one language and you get results only in the language of your query. On multilingual mode, you write your query in one language and you can determine in which languages of the six supported by FlickLing you can get results. On the right side of the search box, you will get each time the translations. Each time, you can cross out or provide a new translation for each desired language. You can also use the suggested terms provided by the system and the tags found in the images of the results. At any time, you can give up on a photo or make use of the hints provided by FlickLing. -You can now start searching for the three images.</p><p>Third Group Task Instructions -The organizers would like to thank you for giving some of your time to participate in this study. -I would like you first to fill in this short questionnaire on basic background knowledge. -This study uses FlickLing, a multilingual interface for searching images across languages. You are asked to use this interface to search the first three images given to you after login. The images given can be described in any of the following six (6) languages: English, German, Dutch, French, Italian and Spanish. You will not know in advance in which of these languages the images provided are described. Therefore, you need to use the features (Help instructions, monolingual/multilingual mode, translations, suggested terms, give up button and hints) supported by FlickLing interface in order to search the three (3) images across languages.</p><p>-At this point, the organizers feel the need to remind you that it is the system and not you that is being evaluated and that you should perform as usual, spending as much time as you would have normally spent on searching. -You will be asked to fill in another short questionnaire after completing the searches for the three images. -Your search session will be system captured and played back to you after completing the searches. You will then be asked to describe your thoughts and actions while searching for the three images. The facilitator will encourage you to keep on describing your thoughts and actions when going to silence. A digital recorder will be used to tape your description. -At the end, a short length interview will take place between you and the facilitator that will be also taped. -I would now guide you through registration for login to FlickLing. You need to click on 'register' button. First, you need to type in an 'email account' and provide a 'password'. Choose your 'native language' from the menu and the 'language of the interface' again from the ones in the relevant menu. Determine your team from the scroll down menu as 'MMU' team. Choose from the menu the 'level of comprehension' for the six languages supported by FlickLing and then click on 'ok'. -You are now ready to use the FlickLing interface and search for the three images. As you can see on your left side, you have the first image. You can click on it in order to bring it forward and see it in detail. By clicking on ok button, you go back to your previous screen. Two modes are provided, the monolingual and multilingual. In the monolingual, you search in one language and you get results only in the language of your query. In multilingual mode, you can determine in which language you write the query from the drop down menu and in which languages you get results by crossing out the relevant language buttons. If you do not cross out a language button then you get translations and consecutively results in all six languages. On the right side of the search box, you will get with each query the relevant translations. The system retrieves at the same time your search terms and the provided translations, so there is no need to retype the translations in the search box. Each time, you can cross out or provide a new translation for each language by clicking on the translation. You can use the suggested terms provided by the system after each search underneath your image by clicking on the term and selecting one of the options provided (include only this word, include this word to the rest of the query, include the translation of this word to the query). You can also use the tags found in the images of the results again by clicking on the tag and selecting one of the options provided (include only this word, include this word to the rest of the query, include the translation of this word to the query). The results are presented underneath your image and are listed in pages. The number of the pages varies according to the number of results. At any time, you can give up on a photo by clicking on the give up button found on the bottom side of the image. After clicking on the give up button, you can either make use of the hints provided by FlickLing or decide to skip this image and go for the next one. The system provides a number of hints, disclosing each time the language in which the image is described and the terms that retrieve this image. You can use as many hints as you wish by repeating the same steps (giving up and going for the hint button). You can now start searching for the three images.</p><p>Appendix: Analysis Tables   S4= I trusted the translations FlickLing gives for languages I do not know. S5= I trusted the translations FlickLing gives for languages I understand. S6= I trusted FlickLing to suggest search terms. S7= I trusted the hints provided by FlickLing to search for the images. S8= I trusted the help instructions to guide me through FlickLing S9= I am confident that FlickLing helped me search across languages for the images. S10= I had confidence in my personal skills to search for the images in FlickLing. S11= I had confidence in my language skills to search for the images across languages in FlickLing. S12= I had confidence in the experience that I was gaining in FlickLing for searching the images across languages.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,201.27,331.45,212.82,86.92"><head>Table 1 .</head><label>1</label><figDesc>Users' Knowledge of non-native Languages</figDesc><table coords="4,220.66,331.45,174.04,76.01"><row><cell cols="5">Language Basic Good Very Good Excellent</cell></row><row><cell>English</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>2</cell></row><row><cell>German</cell><cell>7</cell><cell>1</cell><cell>0</cell><cell>0</cell></row><row><cell>French</cell><cell>7</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Italian</cell><cell>2</cell><cell>0</cell><cell>0</cell><cell>1</cell></row><row><cell>Dutch</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Spanish</cell><cell>5</cell><cell>0</cell><cell>0</cell><cell>0</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="17,134.77,173.23,189.39,467.72"><head>Table 2 .</head><label>2</label><figDesc>Users' Thinking About Languages</figDesc><table coords="17,134.77,173.23,189.39,467.72"><row><cell>Group User ID</cell><cell></cell><cell></cell><cell cols="2">TAL</cell><cell></cell><cell></cell></row><row><cell>Images</cell><cell>1st</cell><cell></cell><cell cols="2">2nd</cell><cell>3rd</cell><cell></cell></row><row><cell></cell><cell cols="6">BH AH BH AH BH AH</cell></row><row><cell>G1 01</cell><cell>N</cell><cell>Y</cell><cell>N</cell><cell>Y</cell><cell>N</cell><cell>Y</cell></row><row><cell>G1 04</cell><cell>N</cell><cell>Y</cell><cell>N</cell><cell>Y</cell><cell>N</cell><cell>Y</cell></row><row><cell>G1 07</cell><cell>N</cell><cell>N</cell><cell>Y</cell><cell>Y</cell><cell>N</cell><cell>Y</cell></row><row><cell>G1 10</cell><cell>N</cell><cell>Y</cell><cell>N</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell></row><row><cell>G1 13</cell><cell>N</cell><cell>Y</cell><cell>N</cell><cell>Y</cell><cell>N</cell><cell>Y</cell></row><row><cell>G1 16</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell></row><row><cell>G1 21</cell><cell cols="2">N/Y Y</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell></row><row><cell>G1 23</cell><cell>N</cell><cell>N</cell><cell>N</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell></row><row><cell>G2 02</cell><cell>N</cell><cell>Y</cell><cell>N</cell><cell>Y</cell><cell>N</cell><cell>Y</cell></row><row><cell>G2 05</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell><cell>N</cell><cell>Y</cell></row><row><cell>G2 09</cell><cell cols="2">N/Y Y</cell><cell>Y</cell><cell>Y</cell><cell cols="2">Y N/A</cell></row><row><cell>G2 11</cell><cell>N</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell><cell>N</cell><cell>Y</cell></row><row><cell>G2 14</cell><cell>N</cell><cell cols="3">Y N/Y Y</cell><cell>N</cell><cell>Y</cell></row><row><cell>G2 17</cell><cell>Y</cell><cell cols="3">Y N/Y Y</cell><cell>Y</cell><cell>Y</cell></row><row><cell>G2 19</cell><cell cols="4">N/Y Y N/Y Y</cell><cell>Y</cell><cell>Y</cell></row><row><cell>G2 22</cell><cell cols="6">N/Y Y N/Y N/A N N/A</cell></row><row><cell>G3 03</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell></row><row><cell>G3 06</cell><cell>N</cell><cell>Y</cell><cell>Y</cell><cell cols="3">Y N/Y Y</cell></row><row><cell>G3 08</cell><cell>N</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell><cell cols="2">Y N/A</cell></row><row><cell>G3 12</cell><cell>N</cell><cell cols="3">N Y/N Y</cell><cell>Y</cell><cell>Y</cell></row><row><cell>G3 15</cell><cell cols="2">N/Y Y</cell><cell>N</cell><cell cols="3">Y N/Y Y</cell></row><row><cell>G3 18</cell><cell cols="4">N/Y N N/Y Y</cell><cell cols="2">N N/A</cell></row><row><cell>G3 20</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell></row><row><cell>G3 24</cell><cell cols="3">N N/A N</cell><cell>Y</cell><cell>Y</cell><cell>Y</cell></row><row><cell>Table 2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">TAL= Thinking About Languages</cell><cell></cell><cell></cell></row><row><cell cols="3">BH= Before taking Hint</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">AH= After taking Hint</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Y= Yes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>N= No</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="5">N/Y= No at first and then Yes</cell><cell></cell><cell></cell></row><row><cell cols="5">Y/N= Yes at first and then No</cell><cell></cell><cell></cell></row><row><cell cols="3">N/A= Non Applicable</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="18,134.78,456.11,172.88,7.89"><head>Table 3 .</head><label>3</label><figDesc>Users' Switching Between Modes</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="18,134.77,500.67,146.45,44.63"><head>Table 3</head><label>3</label><figDesc></figDesc><table coords="18,134.77,512.66,146.45,32.65"><row><cell>SBM= Switching Between Modes</cell></row><row><cell>Y= Yes</cell></row><row><cell>N= No</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="19,166.71,462.08,120.84,7.89"><head>Table 4 .</head><label>4</label><figDesc>Users Modes' Usage</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="19,134.77,512.63,223.52,56.59"><head>Table 4</head><label>4</label><figDesc>SBM= Switching Between Modes M&amp;M= Both Monolingual and Multilingual Modes OMN= Only Monolingual Mode OML= Only Multilingual Mode Table 6 S= Statement S1= I trusted the results that FlickLing's monolingual mode gave me. S2= I trusted the results that FlickLing's multilingual mode gave me. S3= I trusted FlickLing to translate my query.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="10,144.73,634.88,335.87,7.86;10,144.73,645.84,282.41,7.86"><p>A predefined six points scale (Don't know!, Not at all, A little, So-so, Very much so, Totally) was given to users to choose for each statement (see section</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1" coords="10,430.79,645.84,49.80,7.86;10,144.73,656.80,29.77,7.86"><p>2: Questionnaires).</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix: Task Instructions</head><p>This study used three different groups of users. These users received different levels of information about the task to be carried out and the interface to be employed. The full text of the instructions provided to each group of users (1st, 2nd and 3rd) is outlined here. The reader can find a detailed description of these in the relevant chapter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Answers</head><p>S1 S2 S3 S4 S5 S6 S7 S8 S9 S10 Don't know! 0 0 2 4 3 0 2 0 1 1 Not at all 0 0 2 1 0 2 2 0 7 0 A little 4 4 9 7 9 8 5 1 5 3 So-so 12 14 6 7 5 7 7 10 4 1 Very much so 7 6 5 5 7 7 7 9 5 5 Totally 1 0 0 0 0 0 1 4 2 0 Table <ref type="table" coords="20,234.00,247.22,4.13,7.89">5</ref>. Users' Answers to the 2nd Questionnaire  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="12,138.35,350.01,342.24,7.86;12,146.91,360.97,333.68,7.86;12,146.91,371.93,333.68,7.86;12,146.91,382.89,333.68,7.86;12,146.91,393.85,132.72,7.86" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="12,296.90,350.01,183.69,7.86;12,146.91,360.97,127.29,7.86">Overview of iCLEF 2008: Search Log Analysis for Multilingual Image Retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Karlgren</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,366.76,360.97,113.84,7.86;12,146.91,371.93,333.68,7.86;12,146.91,382.89,122.42,7.86">Evaluating Systems for Multilingual and Multimodal Information Access 9th Workshop of the Cross-Language Evaluation Forum, CLEF 2008</title>
		<editor>
			<persName><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Aarhus, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Springer LNCS</publisher>
			<date type="published" when="2008">September 17-19, 2008</date>
		</imprint>
	</monogr>
	<note>Revised Selected Papers</note>
</biblStruct>

<biblStruct coords="12,138.35,404.39,342.24,7.86;12,146.91,415.35,333.68,7.86;12,146.91,426.30,168.97,7.86" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="12,309.55,404.39,171.04,7.86;12,146.91,415.35,259.36,7.86">Retrospective vs. Concurrent Think-aloud Protocols: Testing the Usability of an Online Library Catalogue</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Haak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Jong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">J</forename><surname>Schellens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,414.07,415.35,66.52,7.86;12,146.91,426.30,87.57,7.86">Behaviour &amp; Information Technology</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="339" to="351" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.35,436.84,342.24,7.86;12,146.91,447.80,333.68,7.86;12,146.91,458.76,309.20,7.86" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="12,146.91,447.80,333.68,7.86;12,146.91,458.76,188.35,7.86">Observing Users, Designing Clarity: A Case Study on the User-centered Design of a Cross-language Information Retrieval System</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Petrelli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Demetriou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Herring</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="12,342.84,458.76,31.87,7.86">JASIST</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="923" to="934" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="12,138.35,469.30,342.24,7.86;12,146.91,480.26,333.68,7.86;12,146.91,491.22,333.68,7.86;12,146.91,502.18,333.68,7.86;12,146.91,513.13,132.72,7.86" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="12,380.47,469.30,100.12,7.86;12,146.91,480.26,121.82,7.86">A Study of Users Image Seeking Behaviour in Flickling</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Vassilakaki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">J</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Randall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,365.06,480.26,115.53,7.86;12,146.91,491.22,333.68,7.86;12,146.91,502.18,122.42,7.86">Evaluating Systems for Multilingual and Multimodal Information Access 9th Workshop of the Cross-Language Evaluation Forum, CLEF 2008</title>
		<editor>
			<persName><surname>Peters</surname></persName>
		</editor>
		<meeting><address><addrLine>Aarhus, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Springer LNCS</publisher>
			<date type="published" when="2008">September 17-19, 2008</date>
		</imprint>
	</monogr>
	<note>Revised Selected Papers</note>
</biblStruct>

<biblStruct coords="12,138.35,523.67,342.24,7.86;12,146.91,534.63,333.68,7.86;12,146.91,545.59,333.68,7.86;12,146.91,556.55,223.34,7.86" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="12,407.55,523.67,73.04,7.86;12,146.91,534.63,333.68,7.86;12,146.91,545.59,85.23,7.86">Users Image Seeking Behaviour in Multilingual Environments: experience in combining qualitative and quantitative data</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Vassilakaki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">J</forename><surname>Hartley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Randall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,250.05,545.59,230.54,7.86;12,146.91,556.55,82.99,7.86">International Conference on Qualitative and Quantitative Methods in Libraries</title>
		<meeting><address><addrLine>Chania, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-05">2009. May 2009</date>
			<biblScope unit="page" from="26" to="29" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
