<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,115.15,148.86,372.70,15.15;1,114.77,170.78,373.47,15.15">Prior Art Search using International Patent Classification Codes and All-Claims-Queries</title>
				<funder ref="#_KUrBtET">
					<orgName type="full">Volkswagen Foundation</orgName>
				</funder>
				<funder ref="#_pudRUJW">
					<orgName type="full">German Ministry of Education and Research (BMBF)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,187.79,204.67,67.98,8.74;1,255.77,203.10,1.36,6.12"><forename type="first">György</forename><surname>Szarvas</surname></persName>
						</author>
						<author>
							<persName coords="1,261.85,204.67,76.98,8.74"><forename type="first">Benjamin</forename><surname>Herbert</surname></persName>
						</author>
						<author>
							<persName coords="1,346.74,204.67,68.47,8.74"><forename type="first">Iryna</forename><surname>Gurevych</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">UKP Lab</orgName>
								<orgName type="institution">Technische Universität Darmstadt</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">Research Group on Artificial Intelligence</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,115.15,148.86,372.70,15.15;1,114.77,170.78,373.47,15.15">Prior Art Search using International Patent Classification Codes and All-Claims-Queries</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7DF7EAE81BB2D02CE7CDA0D99D1289D1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing; H.3.3 Information Search and Retrieval Measurement</term>
					<term>Performance</term>
					<term>Experimentation Patent Information Retrieval</term>
					<term>Invalidity Search</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this study, we describe our system at the Intellectual Property track of the 2009 Cross-Language Evaluation Forum campaign (CLEF-IP). The CLEF-IP track addressed prior art search for patent applications. We used the Apache Lucene IR library to conduct experiments with the traditional TF-IDF-based ranking approach, indexing both the textual content of each patent and the IPC codes assigned to each document. We formulated our queries by using all claims and the title of a patent application in order to measure the (weighted) lexical overlap between topics and prior art candidates. We also formulated a language-independent query using the IPC codes of a document to improve the coverage and to obtain a more accurate ranking of candidates. Additionally, we used the IPC taxonomy (the categories and their short descriptive texts) to create a Concept Based Query Expansion [14] model for measuring the semantic overlap between topics and prior art candidates and tried to incorporate this information to our system's ranking process. Probably due to an insufficient length of definition texts in the IPC taxonomy (used to define the concept mapping of our model), incorporating the concept based similarity measure did not improve our performance and was thus excluded from the final submission. Using the extended boolean vector space model of Lucene, our system remained efficient and still yielded fair performance: it achieved the 6th best Mean Average Precision score out of 14 participating systems on 500 topics, and the 4th best score out of 9 participants on 10.000 topics.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The CLEF-IP 2009 track was organized by Matrixware and the Information Retrieval Facility. The goal of this track was to investigate the application of IR methods for patent retrieval. The task was to perform prior art search, which is a special type of search with the goal of verifying the originality of a patent. If another patent or document is found that already covers a very similar invention and no sufficient originality is given in a patent, it would no longer be valid. In the case of a patent application, this would prohibit the acceptance. If a patent is already accepted, opposition can render a patent invalid with citations of prior art they found. Therefore, finding even a single prior art document can be crucial in the process, as it can have direct effect on the decision about patentability, or withdrawal of the patent application.</p><p>Prior art search is usually performed manually at patent offices by experts over millions of documents. The process often takes several days and requires strict documentation and experienced professionals. It would be beneficial if IR methods could ease this task or improve the efficacy of search.</p><p>Major challenges associated with finding prior art are the following:</p><p>• The usage of vocabulary and grammar is not enforced and depends on the authors.</p><p>• In order to cover a wide field of applications, many times very general formulations and vague language are used.</p><p>• Some authors might try to disguise the information contained in a patent for taking actions against people that infringe a patent later.</p><p>• The description of inventions frequently uses new vocabulary, as probably no such thing existed before.</p><p>• Since patents can be submitted in three different languages even in the European Union, information constituting prior art might be described in a different language than the patent under investigation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Dataset &amp; Task</head><p>For the challenge, a collection of 1.9 million patent documents from the European Patent Office (EPO) was used. The documents in this collection correspond to approximately 1 million individual patents filed between 1985 and 2000 (thus one patent can have several files, with different versions/types of information). The patents are in the English, German, or French language. The language distribution is not equal: 69% of the patents are English, 23% are German, and 7% are French. The patents are given in an XML format and supply detailed information, e.g. title, description, abstract, claims, inventors, classification, abstract, etc. For more information about the dataset see the track web page<ref type="foot" coords="2,240.96,507.41,3.97,6.12" target="#foot_0">1</ref> . The main challenge of the track was to find prior art for the given topic documents. Several tasks were defined: the Main task, where topics corresponded to full patent documents, and the multilingual tasks, where only the title and claim fields were given in a single language (English, German, or French) and prior art documents were expected to be retrieved in any of these three languages.</p><p>Relevance assessments were compiled automatically using the citations to prior art documents found in the EPO files of the topic patent applications. The training data for the challenge consisted of 500 topics and relevant prior art. The evaluation was carried out on an unseen document set of size 500 (Small), 1.000 (Medium) and 10.000 (XLarge evaluation) topics, respectively.</p><p>The main goals of Patent Retrieval systems can be characterized as to achieve:</p><p>• high recall, as single result can invalidate a patent application, or</p><p>• high precision at top ranks to provide results that require less manual analysis by a patent expert.</p><p>For a more detailed description of the task, participating groups, the dataset and overall results, please see the challenge description paper: <ref type="bibr" coords="2,278.40,712.22,14.61,8.74" target="#b14">[15]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Related work</head><p>Patent retrieval has been studied extensively by the IR research community, within the scope of scientific workshops and patent retrieval shared tasks. In the early 2000s several workshops were organized at major Computational Linguistics conferences <ref type="bibr" coords="3,371.98,154.32,15.49,8.74" target="#b10">[11,</ref><ref type="bibr" coords="3,391.05,154.32,7.75,8.74" target="#b7">8]</ref> devoted to analyzing and discussing the applicability of IR techniques to patent document collections, and to assess the special characteristics of patent data compared to other genres.</p><p>Since 2003, Patent Information Retrieval has been studied within the scope of the NTCIR evaluation campaigns, mainly focusing to retrieval of patents in Japanese, and patent abstracts in English. At NTCIR-3, a patent retrieval task was given. The goal was to build technical surveys from two years of patent data <ref type="bibr" coords="3,224.48,226.05,14.61,8.74" target="#b9">[10]</ref>. Topics were given as newspaper articles and a memorandum from a person who is interested in a technical survey about a topic mentioned in the articles.</p><p>Invalidity Search was addressed at NTCIR-4 <ref type="bibr" coords="3,296.38,249.96,10.52,8.74" target="#b3">[4]</ref> using a document collection of Japanese patents published between 1993 and 2002. Using the claims in a topic patent, the task was to find a list of patents that invalidate the claims in the topic. Additionally, the passages that are in conflict with the topic had to be found. As a cross-lingual challenge, patents were also partially translated to English.</p><p>The same setup was given for the patent retrieval task at NTCIR-5, but with a larger number of topics. For some topics, passages that invalidate claims for a patent document had to be returned. More information about the task can be found in <ref type="bibr" coords="3,308.18,333.65,9.96,8.74" target="#b4">[5]</ref>.</p><p>At NTCIR-6, the first English patent retrieval task was introduced <ref type="bibr" coords="3,404.80,345.60,9.96,8.74" target="#b5">[6]</ref>. The objective of the English task at NTCIR-6 was Invalidity Search using a collection of English patents from the US Patent &amp; Trademark Office (USPTO). Topic documents were also patents from the USPTO. Relevance assessments were compiled using the citations in the topic documents, similarly to the CLEF-IP 2009 challenge.</p><p>The 2009 Intellectual Property challenge <ref type="bibr" coords="3,287.43,405.38,15.50,8.74" target="#b14">[15]</ref> at the Cross-Language Evaluation Forum campaign extended the scope of Invalidity Search to all the official languages of European Patent Office (i.e. English, German and French) using a collection of over 1 million patents in multiple languages. Another major difference between the NTCIR-6 and the CLEF-IP task was that here multiple manually assigned patent classification codes were available to each document, while at NTCIR-6 all patents were assigned a single label.</p><p>For the NTCIR-3 Workshop Iwayama et al. <ref type="bibr" coords="3,304.33,477.11,10.52,8.74" target="#b8">[9]</ref> indexed nouns, verbs, adjectives and out-ofdictionary words of patents and performed retrieval using newspaper articles as topics. They stated that patent retrieval was not significantly different from retrieval on newspaper items for the technical survey task. This made it promising to rely on the classical retrieval models also for invalidity search.</p><p>Fujii (2007) <ref type="bibr" coords="3,160.63,536.89,10.52,8.74" target="#b2">[3]</ref> employed word-based indexing for invalidity search and employed a citation based score to improve the ranking of retrieval results. The use of citation information was not allowed at the CLEF-IP challenge as the same information was used to compile relevance assessments for the challenge.</p><p>Subtopic analysis was performed by Takagi et al. ( <ref type="formula" coords="3,332.98,584.71,18.45,8.74">2004</ref>) <ref type="bibr" coords="3,359.88,584.71,15.50,8.74" target="#b15">[16]</ref> for invalidity search tasks. By analyzing and finding subtopics contained in target documents, multiple queries were built. For each query a search was carried out on the document database, resulting in a list of relevant patent documents. Unlike Takagi et al. we decided to use single queries for whole topic documents due to time constraints.</p><p>Several previous studies aimed at going beyond the traditional keyword-matching and apply a semantic retrieval approach for patents. For example, Patent Cafe<ref type="foot" coords="3,374.94,654.86,3.97,6.12" target="#foot_1">2</ref> uses Latent Semantic Analysis to implement a semantic search engine for patent texts. The recent EU project called PATExpert <ref type="bibr" coords="3,90.00,680.35,15.50,8.74" target="#b16">[17]</ref> uses manually crafted ontologies for concept based retrieval of patents. On the other hand to our best knowledge Concept Based Query Expansion <ref type="bibr" coords="3,337.37,692.30,15.50,8.74" target="#b13">[14]</ref> has not yet been explored in Patent Retrieval.</p><p>The main findings of recent evaluation campaigns were that traditional IR methods work reasonably for patent collections, but the special language used in patent texts and the use of different terminology might pose problems to keyword-based retrieval. Many studies point out the importance of exploiting the manually assigned topic labels (i.e. the patent classification codes assigned to applications by patent experts) for more efficient retrieval. The task overview papers of the above mentioned evaluation campaigns, the state of the art survey <ref type="bibr" coords="4,410.75,147.89,10.52,8.74" target="#b1">[2]</ref> of PATExpert and a recent survey on Patent informatics <ref type="bibr" coords="4,248.90,159.84,10.52,8.74" target="#b0">[1]</ref> provide a good overview of work related to this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our Approach</head><p>In this section, we discuss our system submitted to the challenge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Data Characterization</head><p>For most patents, several files were available, corresponding to different versions of the patent (an application text is subject to change during the evaluation process).</p><p>We decided not to use all the different versions available for the patent, but used the most upto-date version. We considered the latest version to contain the most authoritative information. If a specific field used by our system was missing from that version, we extracted the respective information from the latest source that included the particular field. In our system, we used the information provided under the claims, abstract, description, title and IPC codes fields only.</p><p>Exploiting other, potentially useful sections of patent applications such as authors or date was omitted so far.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Preprocessing</head><p>To create the indices, we employed Lucene and performed the following preprocessing steps:</p><p>• Sentence splitting based on the Java BreakIterator implementation.</p><p>• Tokenization based on the Java BreakIterator (for the French documents we also used apostrophes as token boundaries: e.g. d'un was split to d and un).</p><p>• Stopword removal using manually crafted stopword lists. We started with general purpose stopword lists containing determiners, pronouns, etc. for each language, and appended them with highly frequent terms manually. We considered each frequent word (appearing in several hundreds of thousand of documents) a potential stopword and included it in the list, if we judged it as a generic term or a domain specific stopword, that is not representative of the patent content. For example, a large number of patent documents contain words like figure (used in figure captions and also to refer to the pictures in the text), or invention (it usually occurred in the 1st sentence of the documents). Since we lacked the necessary domain expertise to evaluate each term properly, stopword lists compiled by experts could easily improve our system to some extent.</p><p>• for the German language, we applied dictionary-based compound splitting <ref type="bibr" coords="4,439.91,602.06,15.50,8.74" target="#b11">[12]</ref> <ref type="foot" coords="4,455.41,600.48,3.97,6.12" target="#foot_2">3</ref> .</p><p>• Stemming using the Porter algorithm <ref type="foot" coords="4,278.37,620.41,3.97,6.12" target="#foot_3">4</ref> .</p><p>The preprocessing pipeline was set up using the Unstructured Information Management Architecture (UIMA), a framework for the development of component based Natural Language Processing (NLP) applications. We used the DKPro Information Retrieval framework <ref type="bibr" coords="4,428.36,665.82,14.61,8.74" target="#b12">[13]</ref>, which provides efficient and configurable UIMA components for common NLP and Information Retrieval tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Retrieval</head><p>The basis of our system is the extended boolean vector space model as implemented by Lucene. We queried the indices described below and combined the results in a post-processing step in order to incorporate information from both the text and the IPC codes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.1">Indices</head><p>In order to employ Lucene for patent retrieval, we created a separate index for each language using only fields for the corresponding language. That is, for example, for the German index, only fields with a language attribute set to DE were used.</p><p>For each patent, we extracted the text of a selection of fields (e.g. title only, title &amp; claim, claim &amp; abstract &amp; description -limited to n words). The concatenated fields were preprocessed as described above. For each patent, a single document was added to the Lucene index, and the patentNumber field to identify the patent.</p><p>Topic documents were indexed similarly in a separate topic index, in order to have the topic texts preprocessed in the same manner as the document collection. We created topic indices using the title and claim fields in each language. All the text in these fields was used to formulate the queries, without any particular further filtering. This way our system ranked documents according to their lexical overlap with the topic patent.</p><p>To exploit the IPC codes assigned to the patents, a separate index was created containing only the IPC categories of the documents. This information could provide a language independent ranking measure of the domain overlap between the query and documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.2">Queries</head><p>In this section, we describe how the query is formulated for each topic.</p><p>For the main task, such topic documents were selected that had their title and claim fields available in all three languages. Moreover, since these documents were full patent applications they contained further fields, optionally in one or more languages, but we did not use any of these additional fields.</p><p>We created a separate query for each language and ran it against the document collection index of the corresponding language. Each query contained the whole content of the two above mentioned fields, with each query term separated by the OR query operator.</p><p>For the language specific tasks, only the title and claim fields of the corresponding language were made available. We performed the same retrieval step as for the main task, but restricted the search to the respective language index. E.g., for the French subtask, we used only the French title and claims fields to formulate our query and performed retrieval only on the French document index.</p><p>To measure the weighted overlap of the IPC codes, a separate query was formulated that included all IPC codes assigned to the topic document (again, each query term OR-ed together).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.3">Result Fusion</head><p>As a result, our system retrieved three ranked lists of patent documents, one result list for each of the three language indices. Since the majority of the true positive documents for the training topics shared at least one full IPC code<ref type="foot" coords="5,261.91,644.26,3.97,6.12" target="#foot_4">5</ref> with the topic patent, we decided to filter our results to contain only such documents that shared an IPC code with the topic. Additionally, we acquired one result list from the IPC code index. We normalized each single list to have a maximum relevance value of 1.0 for the top ranked document in order to make the scores comparable to each other.</p><p>To prepare our system output for the language specific subtasks, we added the relevance scores returned by the IPC and the textual query and ranked the results according to the resulting relevance score. For the combination of results, we normalized the lists and then used the following formula:</p><formula xml:id="formula_0" coords="6,130.43,122.22,148.39,14.38">Score(d) = Score IP C (d)+Scoretext(d) 2</formula><p>For the Main task submission, the three language-specific lists had to be combined in order to end up with a single ranked list of results. To do this, we took the highest language specific result from the three individual lists for each document. That is, each document was ranked according to its highest relevance score in the Main task submission: Score main (d) = M AX(Score EN (d), Score DE (d), Score F R (d)).</p><p>Whenever our system retrieved less then 1000 individual documents using the above described procedure, we appended the result list with documents retrieved by the same steps, but applying a less restrictive IPC code filter. This means that at the end of the list, we included such documents that shared only a higher level IPC category <ref type="foot" coords="6,284.27,231.04,3.97,6.12" target="#foot_5">6</ref> , but not an exact code with the topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head><p>In this section we present the performance statistics of the system submitted to the CLEF-IP challenge and report on some additional experiments performed after the submission deadline. We provide Mean Average Precision (MAP) as the main evaluation metric, in accordance with the official CLEF-IP evaluation. Since precision at top rank positions is extremely important for systems that are supposed to assist manual work, like prior art search, we always indicate Precision at 1 and 10 retrieved documents (P@1 and P@10) for comparison<ref type="foot" coords="6,376.93,345.58,3.97,6.12" target="#foot_6">7</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Challenge submission</head><p>We used the processing pipeline discussed above to extract text from different fields of patent applications. We experimented with indexing single fields, and some combinations thereof. In particular, we used only titles, only claims, only description or a combination of title and claims for indexing.</p><p>As the claims field is the legally important field, we decided to include the whole claims field in the indices for the submitted system. We used an arbitrarily chosen threshold of 800 words for the indexed document size. That is, for patents with a short claims field, we added some text from their abstract or description respectively, to have at least 800 words in the index for each patent. When the claims field alone was longer than 800 words, we used the whole field. This way, we tried to provide a more or less uniform-length representation of each document to make the retrieval results less sensitive to document length. We did not have time during the challenge timeline to find the text size threshold that gave optimal performance for our system, so this 800 words limit was chosen arbitrarily -motivated by the average size of claims sections.</p><p>Table <ref type="table" coords="6,132.35,548.85,4.98,8.74" target="#tab_0">1</ref> shows the MAP, P@1 and P@10 values of the system configurations we tested during the CLEF-IP challenge development period, for the Main task, on the 500 training topics. These were: 1) system using IPC-code index only; 2) system using text-based index only; 3) system using text-based index only, result list filtered for matching IPC code; 4) combination of result lists of 1) and 2); 5) combination of result lists of 1) and 3).</p><p>The bold line in Table <ref type="table" coords="6,208.27,608.63,4.98,8.74" target="#tab_0">1</ref> represents our submitted system. The same configuration gave the best scores on the training topic set for each individual language. Table <ref type="table" coords="6,403.79,620.58,4.98,8.74" target="#tab_1">2</ref> shows the scores of this system configuration for each language and the Main task on the 500 training and on the 10000 evaluation topics. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Nr</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Post submission experiments</head><p>After the submission deadline, we ran several additional experiments to gain a better insight to the performance limitations of our system. We only experimented with the English subtask, for the sake of simplicity and for time constraints. First, we experimented with different weightings for accumulating evidence from the text-and IPC-based indices. The results are summarized in Table <ref type="table" coords="7,90.00,415.18,3.87,8.74">3</ref>. The results indicate that slightly higher weight to text-based results would have been beneficial to performance in general. Using 0.6/0.4 weights, as suggested by Table <ref type="table" coords="7,423.33,427.13,3.87,8.74">3</ref>, would have given 0.1202 MAP score for English, on the 10k evaluation set -which is a 0.4% point improvement.</p><p>Weight MAP 0.0 / 1.0 0.0684 0.1 / 0.9 0.0771 0.2 / 0.8 0.0821 0.3 / 0.7 0.0939 0.4 / 0.6 0.1046 0.5 / 0.5 0.1157 0.6 / 0.4 0.1198 0.7 / 0.3 0.1180 0.8 / 0.2 0.1102 0.9 / 0.1 0.1046 1.0 / 0.0 0.0997 Table <ref type="table" coords="7,119.35,625.79,3.87,8.74">3</ref>: MAP scores on Train 500 with different weightings of the combined text / IPC results.</p><p>We also examined retrieval performance using different document length thresholds. That is, we extracted the first 400, 800, 1600 or 3200 words of the concatenated claim, abstract and description fields to see whether more text improves the performance. Table <ref type="table" coords="7,433.77,673.91,4.98,8.74">4</ref> shows the MAP scores for these experiments. The results show that only a slight improvement could be reached by using more text for indexing documents. Using 1600 words as the document size threshold, as suggested by Table <ref type="table" coords="7,176.50,709.78,3.87,8.74">4</ref>, would have given 0.1170 MAP score for English, on the 10k evaluation set -which is only a marginal improvement over the submitted configuration.</p><p>The best performing configuration we obtained during the submission period included a filtering step to discard any resulting document that did not have any IPC code shared with the topic. This Method MAP 400 words max 0.1116 800 words max 0.1161 1600 words max 0.1184 3200 words max 0.1177 fulltext 0.1147 Table <ref type="table" coords="8,133.59,202.82,3.87,8.74">4</ref>: MAP scores for English on Train 500 with different document length thresholds.</p><p>way, retrieval was actually constrained to the cluster of documents that had some overlapping IPC labeling. A natural idea was to evaluate whether creating a separate index for these clusters (and thus having in-cluster term weighting schemes and ranking) is beneficial to performance. Results of this cluster-based retrieval approach are reported in Table <ref type="table" coords="8,358.52,270.51,3.87,8.74">5</ref>.</p><p>The best paramater settings of our system (i.e. one using 1600 words as document length treshold, 0.6/0.4 weights for text/IPC indices, respectively and separate indices for the cluster of documents with a matching IPC code for each topic -the bold line in Table <ref type="table" coords="8,429.78,306.38,3.87,8.74">5</ref>.) showed a MAP score of 0.1243, P@1 of 0.2223 and p@10 of 0.0937 on the 10.000 documents size evaluation set, for English. This is a 0.8% point improvement in MAP compared to our submitted system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>MAP 800 words 0.5/0.5 weights (text/IPC) 0.1203 800 words 0.6/0.4 weights (text/IPC) 0.1223 1600 words 0.5/0.5 weights (text/IPC) 0.1202 1600 words 0.6/0.4 weights (text/IPC) 0.1252 Table <ref type="table" coords="8,133.59,432.99,3.87,8.74">5</ref>: MAP scores for English on Train 500 with different document length thresholds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>In the previous section, we introduced the results we obtained during the challenge timeline, together with some follow-up experiments. We think our relatively simple approach gave fair results, our submission ended 6th out of 14 participating systems on the Small evaluation set of 500 topics<ref type="foot" coords="8,147.63,534.01,3.97,6.12" target="#foot_7">8</ref> and 4th out of 9 systems on the larger evaluation set of 10000 topics. Taking into account that only one participating system achieved remarkably higher MAP scores, and the simplicity of our system, we find these results promising.</p><p>We attribute these promising results to the efficient use of IPC information to enhance keywordsearch. Our experiments demonstrated that the several ways we employed IPC codes to restrict/focus text search (i.e. filtering according to IPC, retrieval based on IPC codes, local search in the cluster of patents with matching IPC) all improved retrieval performance. We also tried to incorporate the whole IPC taxonomy to extend the traditional vector space model based retrieval similarly to Qui and Frey's <ref type="bibr" coords="8,212.58,631.22,15.50,8.74" target="#b13">[14]</ref> Concept Based Query Expansion technique. Unfortunately, this approach did not improve the performance of our system, most probably due to the very short descriptive information given in the IPC taxonomy for each category. We think that this approach would be particularly promising if a version of the taxonomy with a reasonable amount of descriptive text for its categories were available.</p><p>We also discussed in detail that during the challenge development period, we made several arbitrary choices regarding system parameter settings and that (even though we chose reasonably well performing parameter values), tuning these parameters could have improved the accuracy of the system to some extent. The limitations of our approach are obvious though:</p><p>• First, as our approach mainly measures lexical overlap between the topic patent and prior art candidates, such prior art items that use significantly different vocabulary to describe their innovations are most probably missed by the system.</p><p>• Second, without any sophisticated keyword / terminology extraction from the topic claims, our queries are long and probably contain irrelevant terms that puts a burden on the system's accuracy.</p><p>• Third, the patent documents provided by the organizers were quite comprehensive, containing detailed information on inventors, assignees, priority dates etc. Out of these information types we only used the IPC codes and some of the textual description of patents.</p><p>• Last, since we made the compromise to search among documents with a matching IPC code (and only extend to documents with a matching main category when we had insufficient number of retrieved documents in the first step), we obviously lost the chance of retrieving such prior art items that have different IPC classification from the patent being investigated.</p><p>We think these patents are possibly the most challenging and important items to find -since they are more difficult to discover for humans as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Error analysis</head><p>We examined a few topics manually to assess the typical sources of errors produced by our system. Our findings nicely agree with the claims above. Restricting the search for the cluster with a matching IPC code reduces the search space to a few thousand of documents on average. On the other hand, our system configuration results in losing 11% of the prior art items entirely (i.e. those that do not have even a main IPC category shared with the topic patent) and in very low chances of retrieving another 10% of the prior art (i.e. those that share only a main IPC category but not an exact IPC code). Besides these issues, the system is able to retrieve the majority of the remaining relevant documents within the top ranked 1000 results.</p><p>Poor ranking (that is, having relevant items ranked low in the list) comes from the lack of selection of meaningful search terms from the topic patents. Since many patents discuss very similar topics, usually there are a number of documents with substantial overlap, but relevance is defined more by the presence or absence of a very few very specific terms or phrases (we only consider unigrams for retrieval). This is the most obvious place for improvement regarding our system.</p><p>A typical example is the topic patent with id EP-1474501 <ref type="foot" coords="9,359.64,549.25,3.97,6.12" target="#foot_8">9</ref> . This patent had 16 true positive (TP) documents in the collection. Out of these, we retrieved 12 and missed 4 -3 having not even a main IPC category shared with the topic<ref type="foot" coords="9,278.35,573.16,7.94,6.12" target="#foot_9">10</ref> and 1 sharing only main category <ref type="foot" coords="9,437.21,573.16,7.94,6.12" target="#foot_10">11</ref> . We also got a TP document top ranked (EP-0767824 ), which is indeed very similar to the topic: IPC codes and whole phrases and sentence parts match between them. The rest of the TPs on the other hand came ranked low (under the 100th). We saw the main reason for this in many documents having a large vocabulary overlap with the topic, but having different technical terms like materials, names of chemicals, etc. -aspects that really make the difference in a prior art search setting. We think that an intelligent selection of query terms would have resulted in ranking the relevant documents higher here.</p><p>In this study, we demonstrated that even a simple Information Retrieval system measuring the IPC-based and lexical overlap between a topic and prior art candidates works reasonably well: our system gives a True Positive (prior art) top ranked for little more than 20% of the topics. We believe that a simple visualization approach, e.g. displaying content in a parallel view highlighting textual/IPC overlaps could be an efficient assistant tool for manual prior art search (performed at Patent Offices).</p><p>On the other hand, our experiments conducted within the scope of the CLEF 2009 Intellectual Property challenge might not provide a good insight to the precision of such systems: to our knowledge only such topics were selected for evaluation that were actually opposed by third parties (in other words only such patents were used for evaluation purposes that actually were questionable regarding their novelty). This also emphasizes that our system probably would be usable only for assisting manual search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Future work</head><p>As follow up research, we plan to extend our system in several different ways. We showed that local and global term weightings behave differently in retrieving prior art documents. A straightforward extension would be therefore to incorporate both to improve our results further. Similarly, experimenting with other weighting schemes than the one implemented in Lucene is another straightforward way to extend our system.</p><p>More important, we plan to further investigate the possibilities of incorporating semantic similarity measures to the retrieval process, complementary to lexical overlap. For this -since we don't have access to an IPC taxonomy with sufficient textual descriptions -we plan to experiment with the concept based query expansion model when Wikipedia is used as a source of background knowledge <ref type="bibr" coords="10,138.16,419.22,10.52,8.74" target="#b6">[7]</ref> for constructing the concept-based text representation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="7,162.61,110.79,277.78,183.75"><head>Table 1 :</head><label>1</label><figDesc>Performance on Main task, 500 train topics.</figDesc><table coords="7,162.61,110.79,277.78,183.75"><row><cell cols="2">. Method</cell><cell>MAP</cell><cell>P@1</cell><cell>P@10</cell></row><row><cell cols="2">(1) IPC only</cell><cell>0.0685</cell><cell>0.1140</cell><cell>0.0548</cell></row><row><cell cols="2">(2) Text only</cell><cell>0.0719</cell><cell>0.1720</cell><cell>0.0556</cell></row><row><cell cols="2">(3) Text only -filtered</cell><cell>0.0997</cell><cell>0.1960</cell><cell>0.0784</cell></row><row><cell cols="2">(4) IPC and text</cell><cell>0.1113</cell><cell>0.2140</cell><cell>0.0856</cell></row><row><cell cols="5">(5) IPC and text -filtered 0.1212 0.2160 0.0896</cell></row><row><cell></cell><cell>Train 500</cell><cell></cell><cell cols="2">Evaluation 10k</cell></row><row><cell>Task</cell><cell cols="4">MAP P@1 P@10 MAP P@1 P@10</cell></row><row><cell>English</cell><cell cols="4">0.1157 0.2160 0.0876 0.1163 0.2025 0.0876</cell></row><row><cell cols="5">German 0.1067 0.2140 0.0818 0.1086 0.1991 0.0813</cell></row><row><cell>French</cell><cell cols="4">0.1034 0.1940 0.0798 0.1005 0.1770 0.0774</cell></row><row><cell>Main</cell><cell cols="4">0.1212 0.2160 0.0896 0.1186 0.2025 0.0897</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,123.87,317.64,355.25,8.74"><head>Table 2 :</head><label>2</label><figDesc>Performance scores for different subtasks on training and test topic sets.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,105.24,732.28,302.62,6.64"><p>http://www.ir-facility.org/the_irf/clef-ip09-track/data-characteristics</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,105.24,747.01,107.03,6.99"><p>http://www.patentcafe.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,105.24,697.28,215.94,6.64"><p>http://www.drni.de/niels/s9y/pages/bananasplit.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,105.24,706.78,118.56,6.64"><p>http://snowball.tartarus.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="5,105.24,736.49,407.76,6.99;5,90.00,745.96,117.57,6.99"><p>For example A61K-6/027, corresponding to Preparations for dentistry -Use of non-metallic elements or compounds thereof, e.g. carbon.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="6,105.24,663.42,407.76,6.99;6,90.00,672.89,98.66,6.99"><p>Here we took into account only the 3 top levels of the IPC hierarchy. For example A61K, corresponding to Preparations for dentistry.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="6,105.24,682.39,407.76,6.99;6,90.00,691.85,423.00,6.99;6,90.00,701.32,224.90,6.99"><p>During system development we always treated all citations as equally relevant documents, so we only present such evaluation here. For more details and analysis of performance on highly relevant items (e.g. those provided by the opposition) please see the task description paper<ref type="bibr" coords="6,299.37,701.32,12.42,6.99" target="#b14">[15]</ref>.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7" coords="8,105.24,722.44,407.76,6.99;8,90.00,731.90,297.67,6.99"><p>Since the larger evaluation set included the small one, we consistently reported results on the largest set possible. For more details about performance statistics on the smaller sets, please see<ref type="bibr" coords="8,374.50,731.90,13.17,6.99" target="#b14">[15]</ref> </p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8" coords="9,105.24,677.35,197.52,6.99"><p>Lubricating compositions / IPC:C10M as main topic</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10" xml:id="foot_9" coords="9,105.24,686.86,407.76,6.99;9,90.00,696.32,423.00,6.99;9,90.00,705.79,288.92,6.99"><p>Having detergent compositions / IPC:C11D; macromolecular compounds obtained by reactions only involving carbon-to-carbon unsaturated bonds / IPC:C08F and shaping or joining of plastics / B29C and containers for storage or transport of articles or materials / IPC:B65D as their main topics</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11" xml:id="foot_10" coords="9,105.24,715.29,407.76,6.99;9,90.00,724.75,297.97,6.99"><p>Both on lubricating compositions, but the topic categorized as a mixture, while the prior art document categorized according to its main component (different 4th and 5th level classification)</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6">Acknowledgements</head><p>This work was supported by the <rs type="funder">German Ministry of Education and Research (BMBF)</rs> under grant '<rs type="projectName">Semantics-and Emotion-Based Conversation Management in Customer Support (SIGMUND)</rs>', No. <rs type="grantNumber">01ISO8042D</rs>, and by the <rs type="funder">Volkswagen Foundation</rs> as part of the <rs type="programName">Lichtenberg-Professorship Program</rs> under the grant No. <rs type="grantNumber">I/82806</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_pudRUJW">
					<idno type="grant-number">01ISO8042D</idno>
					<orgName type="project" subtype="full">Semantics-and Emotion-Based Conversation Management in Customer Support (SIGMUND)</orgName>
				</org>
				<org type="funding" xml:id="_KUrBtET">
					<idno type="grant-number">I/82806</idno>
					<orgName type="program" subtype="full">Lichtenberg-Professorship Program</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,110.48,564.62,402.52,8.74;10,110.48,576.58,402.52,8.74;10,110.48,588.53,80.87,8.74" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="10,298.15,564.62,214.85,8.74;10,110.48,576.58,286.64,8.74">Review of the state-of-the-art in patent information and forthcoming evolutions in intelligent patent informatics</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Bonino</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ciaramella</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Corno</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
			<publisher>World Patent Information</publisher>
		</imprint>
	</monogr>
	<note>in press</note>
</biblStruct>

<biblStruct coords="10,110.48,608.46,402.52,8.74" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="10,174.02,608.46,204.73,8.74">Patexpert -state of the art in patent processing</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Brügmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006">2006</date>
			<publisher>ISJB</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="10,110.48,628.38,402.53,8.74;10,110.48,640.34,402.52,8.74;10,110.48,652.29,214.55,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,152.24,628.38,204.49,8.74">Enhancing patent retrieval by citation analysis</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Fujii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,378.94,628.38,134.06,8.74;10,110.48,640.34,398.68,8.74">Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 30th annual international ACM SIGIR conference on Research and development in information retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="793" to="794" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,672.22,402.52,8.74;10,110.48,684.17,402.52,8.74;10,110.48,696.13,380.15,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,270.67,672.22,237.46,8.74">The patent retrieval task in the fourth NTCIR workshop</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Fujii</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Iwayama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,124.30,684.17,388.69,8.74;10,110.48,696.13,158.43,8.74">Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 27th annual international ACM SIGIR conference on Research and development in information retrieval<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="560" to="561" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,110.48,716.05,402.52,8.74;10,110.48,728.01,320.19,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,287.70,716.05,203.40,8.74">Overview of patent retrieval task at NTCIR-5</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Fujii</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Iwayama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,110.48,728.01,221.43,8.74">Proceedings of the Fifth NTCIR Workshop Meeting</title>
		<meeting>the Fifth NTCIR Workshop Meeting</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="269" to="277" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,110.48,112.02,402.52,8.74;11,110.48,123.98,348.40,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,285.26,112.02,227.74,8.74;11,110.48,123.98,38.94,8.74">Overview of the patent retrieval task at the ntcir-6 workshop</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Fujii</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Iwayama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,171.16,123.98,188.96,8.74">Proceedings of NTCIR-6 Workshop Meeting</title>
		<meeting>NTCIR-6 Workshop Meeting</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="359" to="365" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,110.48,143.90,402.52,8.74;11,110.48,155.86,402.52,8.74;11,110.48,167.81,198.45,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,264.91,143.90,248.09,8.74;11,110.48,155.86,117.62,8.74">Computing Semantic Relatedness using Wikipedia-based Explicit Semantic Analysis</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Markovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,253.71,155.86,259.29,8.74;11,110.48,167.81,90.32,8.74">Proceedings of the 20th International Joint Conference on Artificial Intelligence</title>
		<meeting>the 20th International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="1606" to="1611" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,110.48,187.74,402.52,8.74;11,110.48,199.69,365.07,8.74" xml:id="b7">
	<monogr>
		<title level="m" coord="11,261.12,187.74,251.88,8.74;11,110.48,199.69,43.49,8.74">Proceedings of the ACL-2003 Workshop on Patent Corpus Processing</title>
		<editor>
			<persName><forename type="first">M</forename><surname>Iwayama</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Fujii</surname></persName>
		</editor>
		<meeting>the ACL-2003 Workshop on Patent Corpus Processing<address><addrLine>Morristown, NJ, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,110.48,219.62,402.53,8.74;11,110.48,231.57,240.41,8.74;11,395.41,231.57,117.59,8.74;11,110.48,243.53,402.52,8.74;11,110.48,255.48,310.62,8.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="11,342.96,219.62,170.04,8.74;11,110.48,231.57,240.41,8.74">An empirical study on retrieval models for different document genres: patents and newspaper</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Iwayama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Fujii</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Marukawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,408.60,231.57,104.40,8.74;11,110.48,243.53,402.52,8.74;11,110.48,255.48,86.13,8.74">SIGIR &apos;03: Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="251" to="258" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,110.48,275.41,402.52,8.74;11,110.48,287.36,260.75,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="11,322.47,275.41,190.53,8.74;11,110.48,287.36,3.87,8.74">Overview of patent retrieval task at NTCIR-3</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Iwayama</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Fujii</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Takano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,135.10,287.36,205.51,8.74">Proceedings of the NTCIR-3 Workshop Meeting</title>
		<meeting>the NTCIR-3 Workshop Meeting</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,110.48,307.29,402.52,8.74;11,110.48,319.24,257.73,8.74" xml:id="b10">
	<monogr>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Kando</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">K</forename><surname>Leong</surname></persName>
		</author>
		<title level="m" coord="11,234.01,307.29,274.27,8.74">Workshop on Patent Retrieval SIGIR 2000 -Workshop Report</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="28" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,110.48,339.17,402.52,8.74;11,110.48,351.12,294.87,8.74" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="11,161.85,339.17,241.01,8.74">Zur Morphologie und Semantik von Nominalkomposita</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Langer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,427.19,339.17,85.81,8.74;11,110.48,351.12,206.13,8.74">Tagungsband der 4. Konferenz zur Verarbeitung naturlicher Sprache</title>
		<imprint>
			<date type="published" when="1998">1998</date>
			<biblScope unit="page" from="83" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,110.48,371.05,402.52,8.74;11,110.48,383.00,402.52,8.74;11,110.48,394.96,402.52,8.74;11,110.48,406.91,198.56,8.74" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="11,110.48,383.00,273.89,8.74">Flexible UIMA Components for Information Retrieval Research</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Zesch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">C</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Bernhard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Ignatova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Gurevych</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Mühlhäuser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,405.00,383.00,108.00,8.74;11,110.48,394.96,392.03,8.74">Proceedings of the LREC 2008 Workshop &apos;Towards Enhanced Interoperability for Large HLT Systems: UIMA for NLP</title>
		<meeting>the LREC 2008 Workshop &apos;Towards Enhanced Interoperability for Large HLT Systems: UIMA for NLP<address><addrLine>Marrakech, Morocco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-05">May 2008</date>
			<biblScope unit="page" from="24" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,110.48,426.84,402.52,8.74;11,110.48,438.79,402.52,8.74;11,110.48,450.75,259.05,8.74" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="11,205.03,426.84,135.23,8.74">Concept based query expansion</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Qiu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">P</forename><surname>Frei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,361.13,426.84,151.88,8.74;11,110.48,438.79,402.52,8.74;11,110.48,450.75,34.57,8.74">SIGIR &apos;93: Proceedings of the 16th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1993">1993</date>
			<biblScope unit="page" from="160" to="169" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,110.48,470.68,402.52,8.74;11,110.48,482.63,402.52,8.74;11,110.48,494.59,211.96,8.74" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="11,299.86,470.68,213.14,8.74;11,110.48,482.63,115.50,8.74">CLEF-IP 2009: retrieval experiments in the Intellectual Property domain</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Roda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Tait</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Piroi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Zenz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,248.76,482.63,264.24,8.74;11,110.48,494.59,114.32,8.74">Working Notes of the 10th Workshop of the Cross Language Evaluation Forum (CLEF)</title>
		<meeting><address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,110.48,514.51,402.52,8.74;11,110.48,526.47,402.52,8.74;11,110.48,538.42,402.52,8.74;11,110.48,550.38,146.42,8.74" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="11,283.70,514.51,229.30,8.74;11,110.48,526.47,250.68,8.74">Associative Document Retrieval by Query Subtopic Analysis and its Application to Invalidity Patent Search</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Takaki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Fujii</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ishikawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,386.86,526.47,126.14,8.74;11,110.48,538.42,327.66,8.74">Proceedings of the thirteenth ACM international conference on Information and knowledge management</title>
		<meeting>the thirteenth ACM international conference on Information and knowledge management<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="399" to="405" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,110.48,570.30,402.52,8.74;11,110.48,582.26,402.52,8.74;11,110.48,594.21,278.30,8.74" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="11,338.80,582.26,174.20,8.74;11,110.48,594.21,69.46,8.74">Towards Content-oriented Patent Document Processing</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Wanner</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Baeza-Yates</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Brügmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Codina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Diallo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Escorsa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Giereth</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Kompatsiaris</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Papadopoulos</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Pianta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,188.79,594.21,112.95,8.74">World Patent Information</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="33" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
