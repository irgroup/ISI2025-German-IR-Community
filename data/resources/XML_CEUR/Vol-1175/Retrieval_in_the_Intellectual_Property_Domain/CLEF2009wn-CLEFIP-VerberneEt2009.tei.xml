<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,101.61,148.86,399.78,15.15;1,247.59,170.78,107.82,15.15">Prior art retrieval using the claims section as a bag of words</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,228.14,204.67,68.41,8.74"><forename type="first">Suzan</forename><surname>Verberne</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Foraging Lab</orgName>
								<orgName type="institution">Radboud University Nijmegen</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,319.24,204.67,55.63,8.74"><forename type="first">Eva</forename><surname>D'hondt</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory">Information Foraging Lab</orgName>
								<orgName type="institution">Radboud University Nijmegen</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,101.61,148.86,399.78,15.15;1,247.59,170.78,107.82,15.15">Prior art retrieval using the claims section as a bag of words</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">2DCF77F16031131F75AC99E1803603D0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:22+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing; H.3.3 Information Search and Retrieval Indexing</term>
					<term>Bag-of-Words</term>
					<term>Queries Prior Art Retrieval</term>
					<term>CLEF-IP</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe our participation in the 2009 CLEF-IP task, which was targeted at priorart search for topic patent documents. Our system retrieved patent documents based on a standard bag-of-words approach for both the Main Task and the English Task. In both runs, we extracted the claim sections from all English patents in the corpus and saved them in the Lemur index format with the patent IDs as DOCIDs. These claims were then indexed using Lemur's BuildIndex function. In the topic documents we also focussed exclusively on the claims sections. These were extracted and converted to queries by removing stopwords and punctuation. We did not perform any term selection. We retrieved 100 patents per topic using Lemur's RetEval function, retrieval model TF-IDF. Compared to the other runs submitted for the track, we obtained good results in terms of nDCG (0.46) and moderate results in terms of MAP (0.054).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The CLEF-IP track was launched by the Information Retrieval Facility (IRF) in 2009 to investigate IR techniques for patent retrieval <ref type="foot" coords="1,235.29,620.98,3.97,6.12" target="#foot_0">1</ref> . It is part of the CLEF 2009 evaluation campaign <ref type="foot" coords="1,460.54,620.98,3.97,6.12" target="#foot_1">2</ref> .</p><p>The task of the track is: "to find patent documents that constitute prior art to a given patent". The given patent in this task description serves as a topic for the retrieval task. The Main Task is to retrieve prior art for topic patents in any of the three following languages: English, French and German. Three facultative subtasks use parallel monolingual topics in one of these three languages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Our methodology 2.1 Data selection</head><p>The CLEF-IP corpus consists of EPO documents with publication date between 1985 and 2000, covering English, French, and German patents (1,958,955 patent-documents pertaining to 1,022,388 patents, 75GB) <ref type="bibr" coords="2,159.44,178.13,9.96,8.74" target="#b2">[3]</ref>. The XML documents in the corpus do not correspond to one complete patent each but one patent can consist of multiple XML files (representing documents that were produced at different stages of a patent realization).</p><p>We decided to focus on the claims sections of the patents, because we found that many of the English patent documents did not contain abstracts. Moreover, we expected the claims section to be the most informative part of a patent.</p><p>In the CLEF-IP 2009 track the participating teams were provided with 4 different sets of topics (S,M,L,XL). We opted to do runs on the smallest set (the S data set) for both the Main and the English task. This set contained 500 topics. Because the information in these topics was different for both tasks (the topics for the Main Task contained the abstract content as well as the full information of the granted patent except for citation information, while the topic patents for the English Task only contained the title and claims elements of the granted patent <ref type="bibr" coords="2,441.70,309.64,10.30,8.74" target="#b2">[3]</ref>), we focussed only on the (English) claims sections from all topic patents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Query formulation</head><p>There has been much research on the topic of query term extraction/query formulation <ref type="bibr" coords="2,472.65,367.87,9.96,8.74" target="#b0">[1]</ref>. However, we chose not to distil any query terms from the extracted claims section but took all words in the claims section as one long query (weighted in retrieval with TF-IDF). The reason for this was twofold. First, adding a term selection step in the retrieval process makes the retrieval process more prone to errors because it requires the development of a smart selection process. Second, by weighting the query and document terms using TF-IDF, a form of term selection is carried out in the retrieval and ranking process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Indexing using Lemur</head><p>We extracted the claims sections from all English patents in the corpus. after we had removed all XML markup from the texts in a preprocessing script. Since a patent may consist of multiple XML documents, which correspond to the different stages of the patent realization process, one patent can contain more than one claims section. In the index file, we concatenated the claims sections pertaining to one patent ID into one document. We saved all patent claims in the Lemur index format with the patent IDs as DOCIDs. They were then indexed using the BuildIndex function of Lemur with the indri IndexType and a stop word list for general English 3 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>We performed runs for the Main and English Task with the methodology described above. Since we used the same set-up for both runs, we obtained the same results. These results are in Table <ref type="table" coords="2,90.00,636.29,3.87,8.74" target="#tab_0">1</ref>. The first row shows the results that are obtained if all relevant assignments are taken into consideration; the second row contains the results for the highly-relevant citations only <ref type="bibr" coords="2,472.65,648.25,9.96,8.74" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>Although the results that we obtained with our ClaimsBOW approach may seem poor on first sight, they are not bad compared to the results that were obtained in runs by other participants. In terms of nDCG, our run performs well (ranked 6th of 70 runs); in terms of MAP our results </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,90.00,118.94,437.08,126.44"><head>Table 1 :</head><label>1</label><figDesc>Results for the clefip-run 'ClaimsBOW' on the small topic set using English claims sections for both the Main Task and the English Task. .0428 0.0314 0.0080 0.2479 0.0777 0.1074 0.2479 0.0646 0.4567 are moderate (ranked around 35th of 70 runs). The low performance achieved by almost all runs (except for the one submitted by Humboldt University) shows that the task at hand is a difficult one.</figDesc><table coords="3,95.98,142.59,431.10,45.00"><row><cell></cell><cell>P</cell><cell>P5</cell><cell>P10</cell><cell>P100</cell><cell>R</cell><cell>R5</cell><cell>R10</cell><cell>R100</cell><cell>MAP nDCG</cell></row><row><cell>All</cell><cell cols="9">0.0129 0.0668 0.0494 0.0129 0.2201 0.0566 0.0815 0.2201 0.0540 0.4567</cell></row><row><cell>Highly-</cell><cell>0.0080 0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>relevant</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,105.24,701.26,193.38,6.99"><p>See http://www.ir-facility.org/the irf/clef-ip09-track</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,105.24,710.77,131.27,6.99"><p>See http://www.clef-campaign.org/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="3,105.50,291.41,407.50,8.74;3,105.50,303.36,287.72,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="3,185.24,291.41,307.25,8.74">Query Terms Extraction from Patent Document for Invalidity Search</title>
		<author>
			<persName coords=""><forename type="first">Kazuya</forename><surname>Konishi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="3,105.50,303.36,188.96,8.74">Proceedings of NTCIR-5 Workshop Meeting</title>
		<meeting>NTCIR-5 Workshop Meeting</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="312" to="317" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="3,105.50,323.29,407.50,8.74;3,105.50,335.24,214.31,8.74" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="3,326.00,323.29,154.08,8.74">CLEF-IP 2009 Evaluation Summary</title>
		<author>
			<persName coords=""><forename type="first">Florina</forename><surname>Piroi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Giovanna</forename><surname>Roda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Veronika</forename><surname>Zenz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>Information Retrieval Facility</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="3,105.50,355.17,407.50,8.74;3,105.50,367.12,191.34,8.74" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="3,326.34,355.17,137.58,8.74">CLEF-IP 2009 Track Guidelines</title>
		<author>
			<persName coords=""><forename type="first">Florina</forename><surname>Piroi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Giovanna</forename><surname>Roda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Veronika</forename><surname>Zenz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>Information Retrieval Facility</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
