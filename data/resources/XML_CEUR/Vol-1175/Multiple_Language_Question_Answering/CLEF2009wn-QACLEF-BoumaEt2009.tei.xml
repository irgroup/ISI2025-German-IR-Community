<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,93.09,148.86,416.82,15.15">Wikipedia entity retrieval for Dutch and Spanish</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,230.40,182.75,59.27,8.74"><forename type="first">Gosse</forename><surname>Bouma</surname></persName>
							<email>g.bouma@rug.nl</email>
							<affiliation key="aff0">
								<orgName type="department">Information Science</orgName>
								<orgName type="institution">University of Groningen</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,312.35,182.75,60.24,8.74"><forename type="first">Sergio</forename><surname>Duarte</surname></persName>
							<email>sergio.duarte@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Information Science</orgName>
								<orgName type="institution">University of Groningen</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,93.09,148.86,416.82,15.15">Wikipedia entity retrieval for Dutch and Spanish</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C28D90BD4977E00B874BFAA183B1DE67</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Management]: Languages-Query Languages Measurement, Performance, Experimentation Entity Ranking, Wikipedia, Linguistic Analysis, Dutch, Spanish Attractiepark, Atrractiepark, atrractie park, park, [ ], ident, dn24615 Berg in Chili, Berg, berg, berg, [ Chili ], isa, dn32731 Amerikaans stripauteur, stripauteur, strip auteur, auteur, [ Amerikaans ], isa, dn25105</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We developed two systems (for Dutch and Spanish) for the GikiCLEF task, in which Wikipedia pages have to be found that match a description in natural language. We concentrated on linguistic analysis of the query, for mapping the question onto the most relevant Wikipedia categories, and for extracting additional constraints that matching pages have to satisfy. In addition, for Spanish we experimented with query expansion for improved recall of the IR process. In both the Dutch and Spanish system we tried to incorporate additional knowledge sources (WordNet, Yago, DbPedia) for better question analysis and retrieval results. The Dutch system obtained a GikiCLEF score of 2.5 (7th overall and 7th for Dutch). The Spanish system was still under development at the time of the official evaluation, and performed poorly. We show that the completed system would have performed well at the 2009 task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The GikiCLEF entity retrieval task offers a number of challenges for traditional IR systems. Relevant Wikipedia pages for queries such as List the basic elements of the cassata are not easily found on the basis of keyword index. One reason is that apart from relevance, it is also important to return only pages that satisfy a given category (i.e. not the page for cassata itself). A second reason is that the additional constraints are typically so that they require more than simple keyword matching. Numerical constraints (more than 1 million inhabitants) and non-trivial geographical constraints (born in the Bohemian Forest) require reasoning over numbers and geographical locations.</p><p>For this reason, we were especially interested in developing a system that incorporates knowledge from external sources (i.e. WordNet) and which uses knowledge harvested from Wikipedia itself (i.e. property-value tuples extracted from infoboxes).</p><p>The system we developed for Dutch uses a Dutch Wordnet as part of the module that determines appropriate categories for pages that can be retrieved. Furthermore, it has access to relational information harvested from infoboxes in Dutch Wikipedia and expanded with information extracted from infoboxes found in English Wikipedia. The Spanish system uses, among others, cross-language links and English Wordnet for query expansion. For Dutch we were able to use an existing full parsing system for syntactic analysis of the question. For Spanish, an existing POS tagger was combined with a NE tagger trained on CONLL data.</p><p>It should be noted that the Spanish system was still under development when results had to be submitted. As a consequence, we were not able to submit a single run combining the results for Dutch and Spanish. We describe the Dutch and Spanish system in sections 2 and 3, respectively. Some suggestions for future work are given in section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Dutch</head><p>The Dutch system for the GikiCLEF task consists of a module for query analysis, which predicts approppriate categories for a given query, and which tries to identify additional constraints that returned pages must satisfy, and an IR component which returns the most relevant pages based on an index that was developed for the QA task of CLEF 2008. We use a simple ranking scheme that prefers pages that satisfy the categorical constraints, the additional constraints (if any are found), and finally ranks all pages that satisfy these conditions on the basis of the IR score. At most 15 pages are returned.</p><p>The goal of query analysis is to identify words in the input that can be used to predict the most appropriate Wikipedia category for a query (e.g. African capital), and to identify additional constraints that matching pages have to satisfy (e.g. more than one million inhabitants). We use a syntactic parser for Dutch <ref type="bibr" coords="2,214.25,381.98,15.50,8.74" target="#b9">[10]</ref> to parse the query. From the parse result, we extract root forms, part-of-speech labels, and dependency relations.</p><p>Below, we first describe how category labels are predicted, and next how additional constraints are identified. We conclude with a discussion of the results obtained for Dutch, including error analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Predicting Category Labels</head><p>Wikipedia pages are typically classified into one or more categories such as Dutch author. Queries often contain phrases that are similar to the category labels used to classify Wikipedia pages (i.e. writers from the Netherlands. However, as queries rarely contain a phrase that literally matches a Wikipedia category, we try to find the optimal Wikipedia category matching a query.</p><p>To this end, we parsed all category labels used in Dutch Wikipedia using the Alpino parser, and stored the head noun, its stem, and its root form (for compounds). Furthermore, for each category a list of content words modifying the head noun is stored. Finally, head nouns are linked to a corresponding word in a Dutch Wordnet (Cornetto 1 , <ref type="bibr" coords="2,350.96,559.76,14.76,8.74" target="#b10">[11]</ref>). An identity-link is established if there are no modifiers, and the head noun is found in the wordnet. An isa-link is established if the root form can be found in the wordnet. For instance the category labels Attractiepark (Amusement park), Berg in Chili (Mountain in Chile) and Amerikaans stripauteur (American comic book author) are stored as 2. Wikipedia categories are retrieved whose wordnet id matches with one of the ids found for the given headnoun, 3. A score for the retrieved category is computed, based on the overlap between modifiers present in the query and the category label, 4. The highest scoring category labels are selected.</p><p>Potential head nouns are all nouns in the query which are not themselves part of a phrase that is a modifier to a noun. Note that we do not use the isa-relationships between categories in Wikipedia. This was motivated by <ref type="bibr" coords="3,244.27,221.61,9.96,8.74" target="#b8">[9]</ref>, who observe that the Wikipedia category system contains many non-taxonomic links. As an alternative, they propose to link categories for individual Wikipedia pages to (English) WordNet word senses, and to use the WordNet hypernym relations as an alternative for category isa-relations. We created a similar resource for Dutch <ref type="bibr" coords="3,457.90,257.47,9.97,8.74" target="#b2">[3]</ref>.</p><p>Given a query such as Welke Nederlandse violisten... (which Dutch violin players...), the noun violisten (with stem violist) is identified as a potential head. Matching categories are Duits violist, Amerikaans jazzviolist, Amerikaans altviolist, Nederlands violist, Nederlands jazzviolist, etc. The latter two are selected as the most relevant categories, as they contain a modifier Nederlands that also occurs as a modifier in the query.</p><p>The link to the wordnet allows us to search using synonym and hypernym relations. That is, if a query contains the word schrijver (writer), we might still consider Amerikaans stripauteur as a matching category label, as schrijver and auteur (author) are synonyms. Given the query musikant (musician), we also find violist. A problem with this approach is that the linking of Wikipedia labels to wordnet senses requires word sense disambiguation, as most nouns have multiple meanings in wordnet. We solved this problem for Dutch by choosing the predominant word sense on the basis of distributional similarity data obtained from a large Dutch corpus, following the idea of <ref type="bibr" coords="3,499.71,400.94,9.97,8.74" target="#b7">[8]</ref>. This method is not perfect, however, and this has a negative effect on the selection of Wikipedia categories. All categories for sharks and snakes, for instance, are linked to wordnet senses denoting negative characterizations of female persons. As a consequence, queries for vrouw (women) may match with Wikipedia categories for snakes and sharks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Templates</head><p>Apart from a categorical constraint, queries often impose numerical or geographical constraints on what constitutes a valid answer: geboren in het Bohemer woud, geboren in Alaska (born in Bohemia, born in Alaska), met twee of drie Michelinsterren, met meer dan 10.000 studenten (with two or three Michelin stars, with more than 10,000 students). Such constraints are not easily checked using a plain IR engine, as a page may contain both the words born and Alaska, without containing the information that Alaska was the birthplace of the entity described by the page. Numerical expressions like more than 10,000 students can be satisfied by pages which do not contain the number 10,000.</p><p>Many Wikipedia pages contain a so-called infobox, expressing the most relevant information for a given entity. For instance, web pages for universities usually mention the number of students in the infobox (see figure <ref type="figure" coords="3,201.89,614.59,3.88,8.74" target="#fig_0">1</ref>).</p><p>We stored all information in all infoboxes in Dutch Wikipedia and stored the result as relation tuples Page, Attribute, Value . As English Wikipedia typically contains more elaborate infoboxes for a given entity than the corresponding Dutch page, we also automatically expanded the set of relation tuples with tuples harvested from English Wikipedia. Attribute names were automatically translated into Dutch as well (see <ref type="bibr" coords="3,239.77,674.36,10.52,8.74" target="#b1">[2]</ref> for details).</p><p>For queries such as Nederlandse universiteiten met meer dan 10.000 studenten (Dutch universities with more than 10,000 students), question analysis finds the constraint more than(students, 10000). For potentially matching pages P , we can now check whether there exists a tuple P , students, V where V &gt; 10000. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Results and Error Analysis</head><p>Our system returned 638 answers, 36 were correct. Thus we obtained a precision of 0.05 and a GikiCLEF score of 2.4 (7th). For Dutch only, we returned 502 answers, of which 22 were correct (0.04 precision, 0.9 GikiCLEF score).</p><p>Identification of appropriate Wikipedia categories on the basis of the queries turned out to be hard. In only 17 out of 50 questions, one or more categories were identified that were considered appropriate for identifying the correct pages. In 9 cases, no category could be found. This happened for instance for queries containing uncommon (compound) nouns (basiselementen, Formule-1-rijders, talentenjachtwinnaars (basic elements, Formula 1 drivers, talent show winners), but also for common nouns such as plaatsen, bergtoppen en skioorden (mountain tops, ski resorts, and places), which are not used as category labels in Wikipedia, and which also could not be linked to categories using synonyms. Errors are caused by nouns such as landen and rivieren (countries and rivers), which correspond to highly general Wikipedia categories, for which several tens of more specific subcategories exist, covering a large number of Wikipedia pages. Such categories are not very selective, and easily lead the system to prefer results from a subcategory unrelated to the input question. Sometimes, the wrong noun in the query was selected as the head noun of the category.</p><p>Additional numerical and geographical constraints were only correctly identified for two questions. This module was not effective during the experiments.</p><p>Finally, we noted that the IR module performed poorly in terms of recall. This means that many of the pages that fall within one of the categories identified for a question were not in the set of pages retrieved by means of IR. As a consequence, such pages cannot be ranked on the basis of their IR score.</p><p>The Spanish system was developed to extract entities (wikipages) from the Wikipedia Spanish Collection according an input topic given in natural language. The input topics are parsed to obtain noun phrases (NPs) representing two types of information: The target named entity (NE) type and the restrictions or constraints on the desired NEs.</p><p>The target NE type is defined with a set of Wikipedia categories and a set of Yago and DBpedia classes. These items are obtained using a text search on an IR engine (Lucene). We built independent indexes containing the Wikipedia categories titles and the list of Yago and DBpedia types. Although this matching can be also done using a simple look-up table, we think that this approach is more convenient because the query expansion methods described in section 3.3 can be applied in a transparent fashion.</p><p>A candidate entity set is constructed from the wikipages belonging to these Wikipedia categories. Given that the wikipages of the same category can have different NEs types, we clean the set by ignoring the entities that do not correspond to the target YAGO/DBPedia classes.</p><p>To evaluate the restrictions on the NEs, we first map the NPs that specify constraints to Wikipedia categories as it was done with the mapping of the NE type. Additionally, we obtain the wikipages associated with the NEs mentioned in these NPs. We construct a set of wikipages for each NP adding the members of the categories found and the wikipages of the NE. The phrases that cannot be mapped to categories or do not mention any NE are matched in the text content or infobox of the set of wikipages constructed.</p><p>This matching is done using the IR engine, for this purpose a temporal index is created with the pages of these sets. Pages scored below a threshold are deleted. In the final step, we create a second set of candidate entities by including the entities that point to or are pointed from the entities of the restriction sets, as it is done in the WikipediaListQA@wlv system <ref type="bibr" coords="5,447.88,396.85,9.97,8.74" target="#b4">[5]</ref>. This set is also filtered to include only those entities that match the target NE type. We return as result the intersection of the two candidate entity sets (the one created with the first target NE type noun phrases and the one created with the restriction noun phrases). We return only one set in case the other one is empty. In the following sections we describe in further details the main features used in the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Shallow parsing of the input topic</head><p>The input topics are parsed by first tagging the tokens with their POS and then extracting the NPs. We observed that the NE type is commonly specified in the first NP encountered in the user's topic. This is the case for all the GikiCLEF topics in Spanish. Further information concerning these NEs (restrictions) is specified in the NPs functioning as object of the sentence or postmodifiers of the main NP. These two NPs are frequently separated by relative pronouns such as that or in which. In more complex sentences the phrases are separated by verb elements. Thus, first the verb phrases or relative pronouns are detected to split the NPs that refer to the NE type and the ones that refer to the restrictions. This is done by matching the tokens with the relative pronoun POS tags and with a list of common particles used to introduce relative clauses such as: en los cuales (in which), en la que (inside which), por el que (along which), a la que (whom) and so on. Similarly, verb phrases are extracted by matching the rule (Aux Verb)* (Verb) (Adv)*. This process leads to a list of NPs in which the first element defines the NE type. Each one of these NPs is further subdivided to allowing only prepositional phrases as post-modifiers. This further splitting is carried out because the motivation is to match Wikipedia Categories to these NPs and the categories are commonly described by short NPs.</p><p>Applying this method on the topic Nombre los lugares de Italia que haya visitado Ernest Hemingway a lo largo de su vida (List the Italian places where Ernest Hemingway visited during his life) lead to the following phrases: {lugares de Italia}, {Ernest Hemingway}, {a lo largo de su vida}.</p><p>The POS tagging is performed using the OpenNLP POS Spanish tagger which employs a maximum entropy model to predict the POS of each word. We encountered some inaccuracies using this tagger on the GikiCLEF topics and other simple sentences, making it hard to identify phrases using methods based on the POS. For this reason a procedure was designed to tune the results and increase the accuracy of the tagger. First, missing nouns and numbers are detected using the Stanford NER parser <ref type="bibr" coords="6,181.86,147.89,12.40,8.74" target="#b6">[7]</ref> <ref type="foot" coords="6,194.26,146.31,3.97,6.12" target="#foot_0">2</ref> . Misclassified tags belonging to the closed POS classes such as determiners, conjunctions and prepositions are corrected by looking up a table with a comprehensive list of words with these POS classes. This list is extracted from the EAGLES tag definition of the Technical University of Catalonia (UPC) and from Wikipedia. Currently this list contains around 420 items. Further inconsistencies are detected by checking contextual and lexical rules to find sequences of POS that are unfeasible in the Spanish grammar. Similar rules are used to detect the most likely correct tag.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Yago and DBpedia resources</head><p>Yago is a semantic knowledge base extracted from Wikipedia and WordNet <ref type="bibr" coords="6,431.43,265.89,9.96,8.74" target="#b8">[9]</ref>. Yago contains more than 2 million entities and 20 million facts about these entities which are available to the public under the GNU license. Particularly, we are utilizing the Yago type definition which assigns a set of types to each Wikipage in the English collection. This ontological classification is based on the conceptual categories of Wikipedia and the WordNet synsets <ref type="bibr" coords="6,386.34,313.71,12.04,8.74" target="#b8">[9]</ref>. We found 4930 different types in the data which were translated to Spanish by using the cross-lingual dictionary and then cleaning and completing the results by hand. The cross-lingual dictionary extracted contains 112.099 entries.</p><p>Conversely, DBpedia is a community effort to extract information from Wikipedia and interlink this information with other knowledge bases available on the Web <ref type="bibr" coords="6,382.64,373.49,9.97,8.74" target="#b0">[1]</ref>. We particularly employed the types defined in the DBpedia Ontology and the set of types assigned to the wikipages in the English collection. This ontology was hand-generated from the Wikipedia infoboxes and it contains 170 classes. Although the hand-generated mapping does not cover all the possible infoboxes and properties present in the Wikipedia collection, the most frequent infoboxes are included and normalized. Since the types are defined only for English, we translate the 170 classes to Spanish manually.</p><p>The filtering of entities in a set is performed applying the following steps for each entity:</p><p>1. Obtain the English name of the Spanish Wikipage using the cross-lingual links 2. Fetch the types of the English Wikipage in the Yago/DBpedia data 3. Intersect the types fetched in step 2 with the target NE types obtained from the input question. If the size of the intersection is below n 3 , discard the Spanish Wikipage under evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Query processing and expansion</head><p>The queries are constructed including the nouns, adjectives and adverbs of the NPs. These tokens are expanded using three query expansion methods:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Ontological Expansion</head><p>In this expansion method we employed the DBpedia ontology to include in the query all the types under the hierarchy of the DBpedia types found in the input NPs. In this ontology the classes and subclasses are related with the hypernymy semantic relation. For instance if the user requires information about german artists, the algorithm expand the terms to include german writers, comedians, actors, etc., since writer, comedian and actor are types under the type artist as it is shown in figure <ref type="figure" coords="6,159.55,705.15,3.88,8.74" target="#fig_1">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">WordNet Expansion</head><p>WordNet <ref type="bibr" coords="7,133.46,279.40,10.52,8.74" target="#b5">[6]</ref> is used to include the synonyms of the nouns in the input sentence. We made use of the cross-lingual links of Wikipedia to translate the target Spanish word to English. Then we extracted the synonyms of the English nouns and these are translated back to Spanish using again the cross-lingual links. Although the coverage of this method is low given that we are only using the dictionary built from the cross-lingual links, we found that this method led to a slight increase of the performance of the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Redirect Links Expansion</head><p>We found that the redirect links can be exploited to normalize and nominalize entity names. These links are used in Wikipedia to let the user refer to an entity using alternative names and word forms such as: pseudonyms (e.g. Samuel Langhorne Clemens redirects to Marc Twain), abbreviations, common misspelling forms (e.g. Condoleeza Rice redirects to Condoleezza Rice), alternative spellings (e.g. colour redirects to color ) and other adjectival forms (e.g. Peruvian redirects to Peru). The dictionary of redirect links extracted from the GikiCLEF Wikipedia collection contains 113.790 Spanish entries. Nonetheless missing pairs of country-demonyms were added to the dictionary since this type of information is frequently used in the GikiCLEF topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Results</head><p>Unfortunately by the official submission deadline the system was still on its middle development stages, for this reason it was only possible to submit a result list with a system implementing very few of the features described above which lead to poor results. Nonetheless, we collected all the results submitted by the 17 participants to build a list with the correct answers for the 50 topics included in this track edition. We utilized this list to evaluate the performance of our final system and evaluate the impact of the ontological resources and the query expansion methods. This list contains 105 correct answers in Spanish. We evaluated our system using all the query expansion procedures, the category expansion and the ontological resources and we obtained a GikiCLEF score of 4.08 (0.168 precision and 0.238 recall). These results are highly promising given that the system would rank in the fourth position among the 17 participants of the task (considering only Spanish) and because we only processed the Spanish Wikipedia collection, which is significantly less developed and completed than the English collection.</p><p>A baseline system was set to evaluate the performance gain obtained by the used of the DBpedia resources, the query expansion methods and the category expansion. This system excludes the used of all these features. The results are summarized in table 1. From these results we observed that the query expansion methods and the Yago/DBpedia type filtering provide the greatest overall performance gain in the system.</p><p>Similarly, we evaluate the performance gain obtained by each query expansion method. As baseline we include the Yago/DBpedia filtering because the query expansions techniques are also  <ref type="table" coords="8,384.77,323.80,3.88,8.74" target="#tab_1">2</ref>. We found that the query expansion based on the Wikipedia redirect links contributes the most to increase the overall performance of the system. Redirect links are commonly used to obtain the country that corresponds to demonyms or adjectival forms expressed in the topics. This situation appears in 46% of the Spanish GikiCLEF topics.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,201.55,388.19,199.91,8.74;4,234.19,108.86,134.63,254.25"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Infobox for University of Groningen</figDesc><graphic coords="4,234.19,108.86,134.63,254.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,119.54,229.19,363.91,8.74;7,154.69,108.86,293.63,95.25"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Fragment of DBPedia Ontology showing the subclasses of the type Artist</figDesc><graphic coords="7,154.69,108.86,293.63,95.25" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="8,147.27,110.43,308.47,158.86"><head>Table 1 :</head><label>1</label><figDesc>Performance gain for some of the features of the system</figDesc><table coords="8,147.27,110.43,308.47,158.86"><row><cell>Setting</cell><cell cols="4">GikiCLEF score Precision Recall</cell></row><row><cell>Baseline (B)</cell><cell></cell><cell>0.73</cell><cell>0.06</cell><cell>0.11</cell></row><row><cell>B. +Yago/DBpedia</cell><cell></cell><cell>1.42</cell><cell>0.80</cell><cell>0.13</cell></row><row><cell>B. +Query Expansion</cell><cell></cell><cell>1.83</cell><cell>0.96</cell><cell>0.18</cell></row><row><cell>B. +Category Expansion</cell><cell></cell><cell>1.18</cell><cell>0.08</cell><cell>0.13</cell></row><row><cell>Setting</cell><cell></cell><cell cols="3">GikiCLEF score Precision Recall</cell></row><row><cell cols="2">Base + Yago/DBpedia (B-YD)</cell><cell>1.42</cell><cell>0.80</cell><cell>0.13</cell></row><row><cell>B-YD. + Semantic Exp.</cell><cell></cell><cell>1.52</cell><cell>0.90</cell><cell>0.14</cell></row><row><cell>B-YD. +Redirect L. Exp.</cell><cell></cell><cell>1.92</cell><cell>0.11</cell><cell>0.16</cell></row><row><cell>B-YD. +WordNet Exp.</cell><cell></cell><cell>1.56</cell><cell>0.94</cell><cell>0.14</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="8,90.00,291.98,342.58,40.56"><head>Table 2 :</head><label>2</label><figDesc>Performance gain for the query expansion methods used in the matching of types. Results are summarized in table</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="6,105.24,724.08,346.29,6.99"><p>This NER was trained using the Spanish data provided in the shared task of CoNLL 2002<ref type="bibr" coords="6,442.60,724.08,8.93,6.99" target="#b3">[4]</ref> </p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="4">Conclusions</head><p>We have developed two systems for Wikipedia entity retrieval based on linguistic analysis of the query, query expansion, and incorporation of knowledge harvested from Wikipedia itself, and from external knowledge sources. Both systems have their own strenghts and weaknesses. Linguistic analysis is smoother for Dutch, given the fact that we could use a full parser in combination with a Dutch Wordnet. The Spanish system uses more shallow syntactic analysis and consults Wordnet through cross-language links. On the other hand, the IR component of the Spanish system is much more sophisticated and more targeted towards the task of entity retrieval.</p><p>An obvious direction for future work is to develop an integrated system that employs sophisticated IR for both languages, and which also remedies some of the weaker aspects of the linguistic analysis for Spanish.</p></div>
			</div>
			<div type="availability">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>.let.vu.nl/oz</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct coords="8,110.48,588.75,402.52,8.74;8,110.48,600.71,402.52,8.74;8,110.48,612.66,22.69,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,171.22,600.71,182.20,8.74">Dbpedia: A nucleus for a web of open data</title>
		<author>
			<persName coords=""><forename type="first">Sören</forename><surname>Auer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christian</forename><surname>Bizer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Georgi</forename><surname>Kobilarov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jens</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Richard</forename><surname>Cyganiak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zachary</forename><surname>Ives</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,361.28,600.71,79.21,8.74">The Semantic Web</title>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="722" to="735" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,632.59,402.52,8.74;8,110.48,644.55,402.52,8.74;8,110.48,656.50,402.53,8.74;8,110.48,668.46,298.36,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,274.13,632.59,238.87,8.74;8,110.48,644.55,42.64,8.74">Cross-lingual Alignment and Completion of Wikipedia Templates</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Bouma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Duarte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Islam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,172.78,644.55,340.21,8.74;8,110.48,656.50,339.08,8.74">Proceedings of the Third International Workshop on Cross Lingual Information Access: Addressing the Information Need of Multilingual Societies (CLIAWS3)</title>
		<meeting>the Third International Workshop on Cross Lingual Information Access: Addressing the Information Need of Multilingual Societies (CLIAWS3)<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="61" to="69" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,688.38,402.52,8.74;8,110.48,700.34,402.51,8.74;8,110.48,712.29,81.17,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,182.37,688.38,240.38,8.74">Linking Dutch Wikipedia Categories to EuroWordNet</title>
		<author>
			<persName coords=""><forename type="first">Gosse</forename><surname>Bouma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,450.37,688.38,62.64,8.74;8,110.48,700.34,328.05,8.74">Proceedings of the 19th Computational Linguistics in the Netherlands meeting (CLIN 19)</title>
		<meeting>the 19th Computational Linguistics in the Netherlands meeting (CLIN 19)<address><addrLine>Groningen, the Netherlands</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,732.22,333.18,8.74" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="8,168.45,732.22,245.36,8.74">Resources on named entity recognition and classification</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Carreras</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,112.02,402.52,8.74;9,110.48,123.98,402.52,8.74;9,110.48,135.93,68.80,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,182.50,112.02,311.09,8.74">Getting geographical answers from Wikipedia: the GikiP pilot at CLEF</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Santos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,110.48,123.98,359.58,8.74">Cross Language Evaluation Forum: Working Notes for the CLEF 2008 Workshop</title>
		<meeting><address><addrLine>Aarhus, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,155.86,386.78,8.74" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="9,205.89,155.86,180.20,8.74">WordNet: An Electronic Lexical Database</title>
		<author>
			<persName coords=""><forename type="first">Christiane</forename><surname>Fellbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998</date>
			<publisher>MIT</publisher>
			<pubPlace>Cambridge</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,175.78,402.52,8.74;9,110.48,187.74,402.52,8.74;9,110.48,199.69,212.64,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,286.12,175.78,226.88,8.74;9,110.48,187.74,167.84,8.74">Incorporating non-local information into information extraction systems by Gibbs sampling</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Grenager</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,303.61,187.74,209.38,8.74;9,110.48,199.69,182.48,8.74">Proceedings of the 43nd Annual Meeting of the Association for Computational Linguistics</title>
		<meeting>the 43nd Annual Meeting of the Association for Computational Linguistics</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,219.62,402.52,8.74;9,110.48,231.57,326.10,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,392.39,219.62,120.61,8.74;9,110.48,231.57,107.89,8.74">Unsupervised acquisition of predominant word senses</title>
		<author>
			<persName coords=""><forename type="first">Diana</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Rob</forename><surname>Koeling</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julie</forename><surname>Weeds</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Carroll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,226.92,231.57,113.08,8.74">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="553" to="590" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,251.50,402.51,8.74;9,110.48,263.45,402.52,8.74;9,110.48,275.41,268.82,8.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,397.52,251.50,115.48,8.74;9,110.48,263.45,42.84,8.74">Yago: a core of semantic knowledge</title>
		<author>
			<persName coords=""><forename type="first">Fabian</forename><forename type="middle">M</forename><surname>Suchanek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gjergji</forename><surname>Kasneci</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Gerhard</forename><surname>Weikum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,176.23,263.45,336.78,8.74;9,110.48,275.41,16.42,8.74">WWW &apos;07: Proceedings of the 16th international conference on World Wide Web</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="697" to="706" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,295.33,402.52,8.74;9,110.48,307.29,402.52,8.74;9,110.48,319.24,362.68,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,204.73,295.33,150.94,8.74">At last parsing is now operational</title>
		<author>
			<persName coords=""><forename type="first">Gertjan</forename><surname>Van Noord</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,301.15,307.29,211.85,8.74;9,110.48,319.24,274.44,8.74">TALN06. Verbum Ex Machina. Actes de la 13e conference sur le traitement automatique des langues naturelles</title>
		<editor>
			<persName><forename type="first">Piet</forename><surname>Mertens</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Cedrick</forename><surname>Fairon</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Anne</forename><surname>Dister</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Patrick</forename><surname>Watrin</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="20" to="42" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,339.17,402.52,8.74;9,110.48,351.12,402.52,8.74" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,347.79,339.17,165.21,8.74;9,110.48,351.12,143.42,8.74">Integrating lexical units, synsets, and ontology in the cornetto database</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Vossen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Maks</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Segers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Van Der</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Vliet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,274.31,351.12,112.92,8.74">Proceedings of LREC-2008</title>
		<meeting>LREC-2008<address><addrLine>Marrakech, Morocco</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
