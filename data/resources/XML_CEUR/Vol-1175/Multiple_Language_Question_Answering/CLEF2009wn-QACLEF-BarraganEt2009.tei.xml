<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,154.56,70.40,302.45,11.91;1,198.24,85.64,215.28,11.91">INAOE at QAST 2009: Evaluating the usefulness of a phonetic codification of transcriptions</title>
				<funder ref="#_uE9HdVu">
					<orgName type="full">CONACYT</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,141.18,113.22,106.93,8.54"><forename type="first">Alejandro</forename><surname>Reyes-Barragán</surname></persName>
							<email>alejandroe@hotmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Optics and Electronics (INAOE)</orgName>
								<orgName type="laboratory">Laboratory of Language Technologies National Institute of Astrophysics</orgName>
								<address>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,255.06,113.22,92.77,8.54"><forename type="first">Luis</forename><surname>Villaseñor-Pineda</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Optics and Electronics (INAOE)</orgName>
								<orgName type="laboratory">Laboratory of Language Technologies National Institute of Astrophysics</orgName>
								<address>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,367.81,113.22,102.83,8.54"><forename type="first">Manuel</forename><surname>Montes-Y-Gómez</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Optics and Electronics (INAOE)</orgName>
								<orgName type="laboratory">Laboratory of Language Technologies National Institute of Astrophysics</orgName>
								<address>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,154.56,70.40,302.45,11.91;1,198.24,85.64,215.28,11.91">INAOE at QAST 2009: Evaluating the usefulness of a phonetic codification of transcriptions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C5944FE81C1D65614917D75BE83C22D4</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries Measurement, Performance, Experimentation Question Answering, Spontaneous Speech Transcriptions, Phonetic Codification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the participation of the Laboratory of Language Technologies of INAOE at the QAST 2009 track. This participation was mainly focused on the evaluation of an enriched representation of transcriptions based on their phonetic codification. The idea that motivated the development of this new representation was to reduce the impact of the transcription errors by characterizing words with similar pronunciations through the same phonetic code. The achieved results were unsatisfactory since they indicate the phonetic information had no impact on the answer accuracy, even for those cases considering the transcriptions of lower quality.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Question Answering (QA) has become a promising research field whose aim is to provide more natural access to information than traditional document retrieval techniques. In essence, a QA system is a kind of search engine that allows users to pose questions using natural language instead of an artificial query language, and that returns exact answers to the questions instead of a list of entire documents <ref type="bibr" coords="1,345.81,461.22,75.31,8.54" target="#b0">(Burger et al., 2001)</ref>.</p><p>Most QA developments have focused on searching answers for written questions from collections containing written texts. However, due to the great amount of information appearing in spoken documents, such as telephone conversations, meetings, speeches and broadcast news, some recent approaches have begun to address the task of QA in automatic speech transcriptions 1 (Turno et al., 2008).</p><p>The initial idea to tackle this problem was to apply the same techniques used in traditional textual-based QA. Nevertheless, this idea did not seem completely appropriate due to existence of (several) mistakes on the automatic transcriptions.</p><p>The mistakes generated by an automatic speech recognition (ASR) system may be caused by different circumstances, ranging from the presence of noise in the recording to the presence of unknown terms (e.g., proper nouns that are out of its dictionary), but in general, most of them are approximations of the phonetic production of the original words. Based on this fact, in this paper we propose to enrich the representation of the transcriptions by including their phonetic codification. The purpose of this representation is to reduce the impact of the transcription errors by characterizing words with similar pronunciations through the same phonetic code. In particular, we propose using the Soundex codes <ref type="bibr" coords="1,279.75,613.62,99.79,8.54" target="#b2">(Odell and Russell, 1918)</ref> to enrich the representation of transcriptions.</p><p>It is important to mention that the idea of using a phonetic codification for indexing automatic transcriptions of speech is not completely new. There was some early attempt to use the Soundex codes for indexing names with the aim of finding all their pronunciation variants <ref type="bibr" coords="1,308.83,657.18,108.60,8.54" target="#b4">(Raghavan and Allan, 2004)</ref>. Continuing this idea, we applied the phonetic codification indiscriminately to all transcription words, and evaluated the impact of using this codification in the task of spoken document retrieval (Reyes- <ref type="bibr" coords="2,347.11,330.60,82.77,8.54" target="#b5">Barragán et al., 2008)</ref>. In this paper we go a step forward and evaluate the usefulness of this codification in the task of QA in speech transcriptions (QAST).</p><p>The rest of the paper is organized as follows. Section 2 describes the main modules of the proposed system. Then, Section 3 presents the evaluation results. Finally, Section 4 gives our conclusions and describes some ideas for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Description</head><p>Figure <ref type="figure" coords="2,119.19,415.14,4.73,8.54" target="#fig_0">1</ref> shows the general architecture of our QAST system. This system follows the traditional architecture, including modules for question processing, passage retrieval and answer extraction; nevertheless, it considers the phonetic codification from queries and passages as additional information.</p><p>Given that our participation at QAST 2009 was mainly oriented to evaluated the usefulness of considering the phonetic codification, we intentionally restricted the scope of system to English (tasks T1a and T1b), and to respond questions whose answer is a named entity. In particular, we considered only three types of named entities: dates, quantities and general proper names.</p><p>The following sections describe the main modules of the proposed system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Named Entity Recognition</head><p>The first step in the processing of the transcriptions considered the labeling of named entities. This process was achieved by FreeLing <ref type="bibr" coords="2,178.59,542.94,83.60,8.54" target="#b1">(Carreras et al., 2004)</ref>, a tool that allow recognizing dates, quantities and proper names. Moreover, given that some documents are speeches from the European Parliament, it was necessary to add a set of regular expressions to identify some colloquial expressions related to dates, such as: today, in the future, now, a week ago, in the years to come, etc.</p><p>It is important to clarify that we did not apply the same NE recognition process for all given transcriptions 2 . In particular, it was impossible to use FreeLing on C-transcriptions. However, given that our interest was to evaluate the impact of using a phonetic codification, especially from transcriptions of low quality, we decided to apply a naïve method assuming that the NE recognition problem was resolved. This method considered the identification of named entities using an ad-hoc catalogue built from the entities recognized from the automatic transcriptions A and B. 2 Each task has four different transcriptions, one manual and three automatic (A, B and C), being the transcription A the one with the best quality and the C the one with the lowest. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Passage segmentation</head><p>Once finished the process of NE recognition, the transcriptions were segmented into passages of 24 words (named entities were considered as single words), and, after that, adjacent passages were overlapped by 12 words. We considered passages of 24 words because it corresponds to the average length of the sentences of the manual transcriptions.</p><p>It is important to comment that the application of this process was motivated by our aim of simplifying the final process of answer extraction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Phonetic codification</head><p>Phonetic codifications attempt to represent words with similar pronunciations by the same code. Among all existing phonetic codification algorithms, Soundex is the most widely known. It was originally proposed for dealing with the problem of having different spelling variations of the same name (e.g., Lewinsky vs. Lewinskey) <ref type="bibr" coords="3,114.46,215.58,96.63,8.54" target="#b2">(Odell and Russell, 1918)</ref>, and since then it has been applied in several database applications for indexing surnames, for instance, it has been used in the U.S. census.</p><p>The Soundex algorithm is based on the phonetic classification of human speech sounds (bilabial, labiodental, dental, alveolar, velar, and glottal), which in turn are based on where we put our lips and tongue to make sounds. The algorithm itself is straightforward since it does not require of backtracking or multiple passes over the input word. This algorithm is as follows:</p><p>1. Capitalize all letters in the word and drop all punctuation marks. 2. Retain the first letter of the word. 3. Change all occurrence of the following letters to '0' (zero):</p><p>'A', E', 'I', 'O', 'U', 'H', 'W', 'Y'. 4. Change letters from the following sets into the given digit:</p><formula xml:id="formula_0" coords="3,101.94,341.04,139.67,73.81">1 = 'B', 'F', 'P', 'V' 2 = 'C', 'G', 'J', 'K', 'Q', 'S', 'X', 'Z' 3 = 'D','T' 4 = 'L' 5 = 'M','N' 6 = 'R' 5.</formula><p>Remove all pairs of equal digits occurring beside each other from the string resulted after step (4). 6. Remove all zeros from the string that results from step (5) 7. Pad the string resulted from step <ref type="bibr" coords="3,241.69,428.09,11.00,8.54" target="#b6">(6)</ref> with trailing zeros and return only the first six positions. The output code will be of the form &lt;uppercase letter&gt; &lt;digit&gt; &lt;digit&gt; &lt;digit&gt; &lt;digit&gt; &lt;digit&gt;.</p><p>Using this algorithm, both "Robert" and "Rupert" return the same string "R16300", whereas "Rubin" yields "R15000". In our case (refer to Figure <ref type="figure" coords="3,245.67,466.43,3.42,8.54" target="#fig_0">1</ref>), we applied the Soundex algorithm to both passages and queries in order to construct their phonetic codifications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Query and passage representation</head><p>Once we obtained the phonetic codification from the passages and the query, we constructed their enriched representations. These representations exclude non-content words but include information about named entities as well as some phonetic codes. Table <ref type="table" coords="3,227.63,539.75,4.73,8.54" target="#tab_0">1</ref> shows an example of the enriched representation from a passage. S36352 W62000 F65200 S53600 F43000 L20000 F40000 A16522 D23300 S15320 Enriched representation starting work &lt;NOM&gt; Frank Sinatra &lt;/NOM&gt; felt like fellow appearances decided &lt;NOM&gt; seventies &lt;/NOM&gt; S36352 W62000 F65200 S53600 F43000 L20000 F40000 A16522 D23300 S15320</p><p>The enriched representation of a query is very similar to that from a passage; nevertheless, it also includes information about the expected answer type. In our implementation we only consider three basic types of expected answers (date, quantity and proper name), which exactly correspond to the kinds of NEs recognized across the passages. The determination of the expected answer type was carried out in the question classification module (refer to Figure <ref type="figure" coords="4,151.31,112.86,3.95,8.54" target="#fig_0">1</ref>) using a set of manually constructed regular expressions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Passage retrieval and answer extraction</head><p>In order to take advantage of all information contained in the enriched representations of passages and queries we decided using Indri <ref type="bibr" coords="4,182.19,164.46,89.14,8.54" target="#b6">(Strohman et al., 2005)</ref> as search engine. Indri allowed us to determine a difference importance of each term by assigning them different weights in accordance to their type. For example, for the question "when do we need this strategic program for cohesion?", whose expected answer type is DATE, we built the following query: (8.0 DATE) (2.0 strategic program cohesion) (1.0 S36322 P62650 C25000), giving much more importance to the expected answer type (a weigh of 8.0), followed by the terms of the query (with a weight of 2.0) and finally to the phonetic codes (a weight of 1.0). These weights were determined empirically from the available training data.</p><p>Once retrieved the passages by Indri, we extracted from each passage the entities corresponding to the expected answer type. All extracted answers were ordered in accordance to the position of their source passage (we put first answers from the first passage, then answers extracted from the second passage and so on), and the top five answers were selected as candidate answers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>This section presents the experiments that were carried out and discuses the achieved results. As was previously mentioned, our system was limited to English tasks T1a and T1b. The difference between these tasks is the kind of queries, while queries from task T1a are written questions, the ones from task T1b correspond to transcriptions from oral spontaneous questions.</p><p>In order to evaluate the relevance of the phonetic codifications we sent two runs for each transcription of both tasks: run INAOE1 did not include phonetic information, whereas run INAOE2 employed the proposed enriched representations.</p><p>Results corresponding to manual transcriptions are shown in Table <ref type="table" coords="4,366.55,390.48,3.52,8.54" target="#tab_1">2</ref>. For task T1a, that uses written questions, the results are practically the same with and without the phonetic codifications. In other words, the inclusion of the phonetic information was not advantageous, but neither it was prejudicial. In the case of the task T1b, where the questions are oral transcriptions, it is possible to observe an improvement using the phonetic codification, which indicates that the phonetic codification is useful and allow retrieving a greater amount of relevant passages. Tables <ref type="table" coords="4,130.78,570.78,4.73,8.54" target="#tab_3">3</ref> and<ref type="table" coords="4,156.35,570.78,4.73,8.54">4</ref> show the results of including the phonetic information when automatic transcriptions were used. The results indicate that the phonetic information had no impact on the achieved accuracy, even for those cases considering the transcriptions of lower quality or oral questions <ref type="foot" coords="4,356.88,592.28,2.83,5.11" target="#foot_1">3</ref> . This unexpected behavior may be due to the fact that the phonetic codification reduces the size of the vocabulary, that is, there are less phonetic codes than words. For example, in transcription A there are 4,032 different words and only 2,415 phonetic codes. This reduction increased the number of "irrelevant" passages associated to each query, and, therefore, it produced an unfavorable effect. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>The present work explored the impact of the phonetic codification in the task of question answering in speech transcriptions. The proposed system enriched the representation of the automatic transcriptions with their corresponding phonetic codes (Soundex codes). To focus our participation in the evaluation of the phonetic codification, it was limited to questions whose answer was a named entity, simplifying in this way the processes of passage retrieval and answer extraction.</p><p>As it can be noticed from the results section, the phonetic codification -at least in the way we implementeddid not produce any improvement on the answer accuracy. Despite these results, the use of the phonetic codification should not be discarded completely; it is necessary to make a deeper analysis in order to identify its possible advantages. This is supported by the fact that we achieved some improvement when the phonetic codification was applied to manual transcriptions from the task T1b. In this case the performance was almost the same to that achieved with written questions, indicating that it was possible to decrease -in some degree-the error introduced by the automatic speech recognition system.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,196.26,310.56,230.55,8.54"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. General architecture of the proposed QAST system</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,137.40,562.01,337.06,101.40"><head>Table 1 .</head><label>1</label><figDesc>Example of an enriched passage representation</figDesc><table coords="3,137.40,575.94,337.06,87.47"><row><cell>Manual transcription</cell><cell>I am starting to know what &lt;NOM&gt; Frank Sinatra &lt;/NOM&gt; must have</cell></row><row><cell>(show it for reference)</cell><cell>felt like as his &lt;NOM&gt; farewell &lt;/NOM&gt; appearances staggered on</cell></row><row><cell></cell><cell>into his seventies</cell></row><row><cell cols="2">Automatic transcription I am starting to work I do not know what &lt;NOM&gt; Frank Sinatra</cell></row><row><cell></cell><cell>&lt;/NOM&gt; must have felt like as his fellow appearances decided on in</cell></row><row><cell></cell><cell>the seventies</cell></row><row><cell>After elimination of</cell><cell>starting work &lt;NOM&gt; Frank Sinatra &lt;/NOM&gt; felt like fellow appear-</cell></row><row><cell>stopwords</cell><cell>ances decided seventies</cell></row><row><cell>Phonetic codification</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,121.56,467.16,367.16,89.81"><head>Table 2 . Results for manual transcriptions Without phonetic transcription With phonetic transcription Task Run id #Questions with at least 1 correct answer MRR ACC Run id #Questions with at least 1 correct answer MRR ACC</head><label>2</label><figDesc></figDesc><table coords="4,121.56,519.48,366.71,37.49"><row><cell>T1a (written questions)</cell><cell>INAOE1</cell><cell>54</cell><cell>0.36</cell><cell>27 % INAOE2</cell><cell>51</cell><cell>0.36</cell><cell>28 %</cell></row><row><cell>T1b (spontaneous oral questions)</cell><cell>INAOE1</cell><cell>35</cell><cell>0.27</cell><cell>22 % INAOE2</cell><cell>47</cell><cell>0.34</cell><cell>26 %</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,126.36,69.36,359.06,87.65"><head>Table 3 .</head><label>3</label><figDesc>Results for automatic transcriptions from Task T1a</figDesc><table coords="5,126.36,84.84,359.06,72.17"><row><cell></cell><cell cols="4">Without phonetic transcription</cell><cell cols="3">With phonetic transcription</cell></row><row><cell></cell><cell></cell><cell>#Questions</cell><cell></cell><cell></cell><cell></cell><cell>#Questions</cell><cell></cell></row><row><cell>Transcription</cell><cell>Run id</cell><cell>with at least 1</cell><cell cols="2">MRR ACC</cell><cell>Run id</cell><cell>with at least 1</cell><cell cols="2">MRR ACC</cell></row><row><cell></cell><cell></cell><cell>correct answer</cell><cell></cell><cell></cell><cell></cell><cell>correct answer</cell><cell></cell></row><row><cell>A</cell><cell>INAOE1</cell><cell>41</cell><cell>0.3</cell><cell cols="2">23 % INAOE2</cell><cell>42</cell><cell>0.29</cell><cell>22 %</cell></row><row><cell>B</cell><cell>INAOE1</cell><cell>29</cell><cell>0.22</cell><cell cols="2">17 % INAOE2</cell><cell>30</cell><cell>0.22</cell><cell>17 %</cell></row><row><cell>C</cell><cell>INAOE1</cell><cell>34</cell><cell>0.28</cell><cell cols="2">25 % INAOE2</cell><cell>35</cell><cell>0.28</cell><cell>24 %</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,126.36,172.74,359.06,87.71"><head>Table 3 .</head><label>3</label><figDesc>Results for automatic transcriptions from Task T1b</figDesc><table coords="5,126.36,188.28,359.06,72.17"><row><cell></cell><cell cols="4">Without phonetic transcription</cell><cell cols="3">With phonetic transcription</cell></row><row><cell></cell><cell></cell><cell>#Questions</cell><cell></cell><cell></cell><cell></cell><cell>#Questions</cell><cell></cell></row><row><cell>Transcription</cell><cell>Run id</cell><cell>with at least 1</cell><cell cols="2">MRR ACC</cell><cell>Run id</cell><cell>with at least 1</cell><cell cols="2">MRR ACC</cell></row><row><cell></cell><cell></cell><cell>correct answer</cell><cell></cell><cell></cell><cell></cell><cell>correct answer</cell><cell></cell></row><row><cell>A</cell><cell>INAOE1</cell><cell>40</cell><cell>0.3</cell><cell cols="2">24 % INAOE2</cell><cell>41</cell><cell>0.29</cell><cell>23 %</cell></row><row><cell>B</cell><cell>INAOE1</cell><cell>30</cell><cell>0.22</cell><cell cols="2">16 % INAOE2</cell><cell>31</cell><cell>0.22</cell><cell>16 %</cell></row><row><cell>C</cell><cell>INAOE1</cell><cell>33</cell><cell>0.28</cell><cell cols="2">25 % INAOE2</cell><cell>34</cell><cell>0.27</cell><cell>23 %</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,96.24,703.32,320.60,7.67"><p>These transcriptions are the result of applying an automatic speech recognition (ASR) system.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="4,96.60,682.56,423.98,7.67;4,99.36,692.94,421.21,7.67;4,99.36,703.32,317.62,7.67"><p>It is important to mention that due to the particular treatment of the named entities in transcription C, the results using this transcription are not directly comparable with those from transcriptions A and B. However, it is possible to observe the effect caused by the inclusion of the phonetic codification, which is the main goal of this work.</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><p>Acknowledgements. This work was done under partial support of <rs type="funder">CONACYT</rs> (Project Grant <rs type="grantNumber">83459</rs>). We also like to thank to the CLEF organizing committee for the resources provided.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_uE9HdVu">
					<idno type="grant-number">83459</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,94.75,505.32,425.79,8.54;5,108.24,516.24,127.27,8.54" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,175.01,505.32,345.53,8.54;5,108.24,516.24,24.80,8.54">Issues, Tasks and Program Structures to Roadmap Research in Question &amp; Answering (Q&amp;A)</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Burger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,150.15,516.24,34.37,8.54">TREC 10</title>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,94.75,527.10,425.83,8.54;5,108.24,538.02,412.35,8.54;5,108.24,548.94,171.84,8.54" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,320.22,527.10,177.14,8.54">An Open-Source Suite of Language Analyzers</title>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Carreras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Chao</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ll</forename><surname>Padró</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Padró</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Freeling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,504.26,527.10,16.32,8.54;5,108.24,538.02,383.82,8.54">Proceedings of the 4th International Conference on Languages Resources and Evaluation (LREC 2004)</title>
		<meeting>the 4th International Conference on Languages Resources and Evaluation (LREC 2004)</meeting>
		<imprint>
			<publisher>European Language Resources Association</publisher>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,94.75,559.74,351.16,8.54" xml:id="b2">
	<analytic>
		<title/>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">K</forename><surname>Odell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">C</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,216.53,559.74,81.28,8.54">U.S. Patent Numbers</title>
		<imprint>
			<biblScope unit="page">1435663</biblScope>
			<date type="published" when="1918">1918. 1922</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,448.92,559.74,71.72,8.54;5,108.24,570.66,95.39,8.54" xml:id="b3">
	<analytic>
		<title/>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">C</forename><surname>Washington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,108.24,570.66,67.99,8.54">U.S. Patent Office</title>
		<imprint>
			<date type="published" when="1918">1918</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,94.75,581.52,425.94,8.54;5,108.24,592.44,412.36,8.54;5,108.24,603.30,412.42,8.54;5,108.24,614.16,87.55,8.54" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,199.08,581.52,234.12,8.54">Using Soundex Codes for Indexing Names in ASR documents</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Allan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,450.21,581.52,70.48,8.54;5,108.24,592.44,412.36,8.54;5,108.24,603.30,354.20,8.54">Proceedings of the Workshop on Interdisciplinary Approaches to Speech Indexing and Retrieval at Human Language Technology Conference and North American chapter of Association of Computational Linguistics</title>
		<meeting>the Workshop on Interdisciplinary Approaches to Speech Indexing and Retrieval at Human Language Technology Conference and North American chapter of Association of Computational Linguistics<address><addrLine>Boston, MA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="22" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,94.75,625.08,425.76,8.54;5,108.24,636.00,412.50,8.54;5,108.24,646.86,215.31,8.54" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,396.90,625.08,123.61,8.54;5,108.24,636.00,106.05,8.54">A Soundex-based Approach for Spoken Document Retrieval</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Reyes-Barragán</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Villaseñor-Pineda</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Montes-Y-Gómez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,220.41,636.00,300.33,8.54;5,108.24,646.86,152.46,8.54">Mexican International Conference of Artificial Intelligence, MICAI 2008. Lecture Notes in Artificial Intelligence 5317</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,94.75,657.72,425.73,8.54;5,108.24,668.64,412.29,8.54;5,108.24,679.50,21.22,8.54" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,325.77,657.72,194.71,8.54;5,108.24,668.64,47.34,8.54">A Language-Model based Search Engine for Complex Queries</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Strohman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Metzler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Turtle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">B</forename><surname>Croft</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Indri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,173.76,668.64,265.94,8.54">Proceedings of the International Conference on Intelligence Analysis</title>
		<meeting>the International Conference on Intelligence Analysis<address><addrLine>McLean, VA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005-05">May 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,94.75,690.42,425.68,8.54;5,108.24,701.28,405.38,8.54" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,418.46,690.42,77.06,8.54">Overview of QAST</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Turmo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">R</forename><surname>Comas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Lamel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Moureau</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mostefa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,108.24,701.28,377.76,8.54">Proceedings of the CLEF 2008 Workshop on Cross-Language Information Retrieval and Evaluation</title>
		<meeting>the CLEF 2008 Workshop on Cross-Language Information Retrieval and Evaluation</meeting>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
