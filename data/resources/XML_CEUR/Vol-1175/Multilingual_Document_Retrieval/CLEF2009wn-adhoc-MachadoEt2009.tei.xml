<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,143.88,151.57,318.90,12.64;1,134.52,168.97,326.34,12.64;1,139.68,186.37,316.13,12.64;1,240.72,203.77,113.87,12.64">Experiments with N-Gram Prefixes on a Multinomial Language Model versus Lucene&apos;s off-the-shelf ranking scheme and Rocchio Query Expansion (TEL@CLEF Monolingual Task)</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,205.08,242.20,61.38,8.96"><forename type="first">Jorge</forename><surname>Machado</surname></persName>
							<email>jorge.r.machado@ist.utl.pt</email>
							<affiliation key="aff0">
								<orgName type="department">Departmento de Engenharia Informática</orgName>
								<orgName type="institution">Technical University of Lisbon</orgName>
								<address>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,274.80,242.20,58.47,8.96"><forename type="first">Bruno</forename><surname>Martins</surname></persName>
							<email>bruno.martins@ist.utl.pt</email>
							<affiliation key="aff0">
								<orgName type="department">Departmento de Engenharia Informática</orgName>
								<orgName type="institution">Technical University of Lisbon</orgName>
								<address>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,341.52,242.20,56.98,8.96"><forename type="first">José</forename><surname>Borbinha</surname></persName>
							<email>jose.borbinha@ist.utl.pt</email>
							<affiliation key="aff0">
								<orgName type="department">Departmento de Engenharia Informática</orgName>
								<orgName type="institution">Technical University of Lisbon</orgName>
								<address>
									<country key="PT">Portugal</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,143.88,151.57,318.90,12.64;1,134.52,168.97,326.34,12.64;1,139.68,186.37,316.13,12.64;1,240.72,203.77,113.87,12.64">Experiments with N-Gram Prefixes on a Multinomial Language Model versus Lucene&apos;s off-the-shelf ranking scheme and Rocchio Query Expansion (TEL@CLEF Monolingual Task)</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">1161BBD4C9410724492A6417FC3BD56A</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Language Model</term>
					<term>Vector Space Model</term>
					<term>Lucene</term>
					<term>Rocchio QE</term>
					<term>Stemming</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe our participation in the TEL@CLEF task of the CLEF 2009 ad-hoc track, where we measured the retrieval performance of LGTE, an index engine for Geo-Temporal collection which is mostly based on Lucene, together with extensions for query expansion and multinomial language modelling. We experiment an N-Gram stemming model to improve our last year experiments which consisted in combinations of query expansion, Lucene's off-the-shelf ranking scheme and the ranking scheme based on multinomial language modeling. The N-Gram stemming model was based in a linear combination of N-Gram, with n between 2 and 5, using weight factors obtained by learning from last year topics and assessments. The rochio ranking function was also adapted to implement this N-Gram model. Results show that this stemming technique together with query expansion and multinomial language modeling both result in increased performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>One task of the ad-hoc track at the 2009 edition of the Cross Language Evaluation Forum (CLEF) addresses the problem of searching and retrieving relevant items from collections of bibliographic records from The European Library (TEL@CLEF). Three target collections were provided, each corresponding to a monolingual retrieval task where we participated:</p><p>• TEL Catalogue records in English. Copyright British Library (BL)</p><p>• TEL Catalogue records in French. Copyright Bibliothèque Nationale de France (BnF) • TEL Catalogue records in German. Copyright Austrian National Library (ONB) The evaluation task aimed at investigating the best approaches for retrieval from library catalogues, where the information is frequently very sparse and often stored in unexpected languages. This paper describes the participation of the Technical University of Lisbon at the TEL@CLEF task. Our experiments aimed at measuring the retrieval performance of the LGTE<ref type="foot" coords="2,166.32,172.30,3.00,5.40" target="#foot_0">1</ref> tool which is implementing the IR service of DIGMAP <ref type="foot" coords="2,403.80,172.30,3.00,5.40" target="#foot_1">2</ref> , an EU-funded project which addresses the development of services for virtual digital libraries of materials related to historical cartography <ref type="bibr" coords="2,313.68,195.64,10.69,8.96" target="#b6">[7]</ref>. DIGMAP collects bibliographic metadata from European national libraries and other relevant third-party providers (e.g. collections with descriptions available through OAI-PMH), aiming to provide advanced searching and browsing mechanisms that combine thematic, geographic and temporal aspects. In case of success, the ultimate goal of the project is to become fully integrated into The European Library. The LGTE is the DIGMAP text retrieval service which is mostly based on Lucene, together with extensions for using query expansion and multinomial language modeling. A previous version of the system was described in the MSc thesis of Machado <ref type="bibr" coords="2,305.40,287.56,11.59,8.96" target="#b3">[4]</ref> and we are now in the process of developing extensions for geo-temporal information retrieval <ref type="bibr" coords="2,372.00,299.08,10.69,8.96" target="#b7">[8]</ref>.</p><p>Like last year in CLEF, we experimented combinations query expansion, Lucene's off-the-shelf ranking scheme and the ranking scheme based on multinomial language modeling, but this year we include an N-Gram model for degraded collections proposed by Parapar in <ref type="bibr" coords="2,220.80,345.04,10.69,8.96" target="#b8">[9]</ref>. We adapt this model to our records collections using only N-Gram prefixes instead of the usual sliding window N-Grams. We also perform several experiments on how to use this model in Rochio selection formula for query expansion with encourage results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The experimental environment</head><p>The underlying IR system used in our submissions is based on Lucene<ref type="foot" coords="2,428.88,444.58,3.00,5.40" target="#foot_2">3</ref> , together with a multinomial language modeling extension developed at the University of Amsterdam and a query expansion extension developed by Neil Rubens. The following subsections detail these components. We adapt our model to use a linear combination of scores using several N-Gram indexes. We also adapt the ranking function defined by Rochio to make use of the N-Gram indexes and the weights assigned to each one of those indexes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Lucene's off-the-shelf retrieval model</head><p>We started with Lucene's off-the-shelf retrieval model. For a collection D, document d and query q, the ranking score is given by the formula bellow:</p><formula xml:id="formula_0" coords="2,168.36,600.61,298.45,29.48">ranking(q,d) = tf t,q ⋅ idf t norm q t ∈q ∑ ⋅ tf t,d ⋅ idf t norm d ⋅ coord q,d ⋅ weight t (<label>1</label></formula><formula xml:id="formula_1" coords="2,466.81,610.36,3.90,8.96">)</formula><p>where:</p><p>(2)</p><p>Lucene has been extensively used in previous editions of the CLEF, NTCIR and TREC joint evaluation experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Lucene extension based on multinomial language modeling</head><p>We experimented with a Lucene extension that implements a retrieval scheme based on estimating a language model (LM) for each document, using the formula described by Hiemstra <ref type="bibr" coords="3,219.36,349.84,10.69,8.96" target="#b1">[2]</ref>. This extension was developed at the Informatics Institute of the University of Amsterdam 4 . For any given query, it ranks the documents with respect to the likelihood that the document's LM generated the query:</p><formula xml:id="formula_2" coords="3,199.68,386.40,271.03,23.12">∏ ∈ ⋅ ∝ = q t d t P d P q d P q d ranking ) | ( ) ( ) | ( ) , (<label>(3)</label></formula><p>In the formula, d is a document and t is a term in query q. The probabilities are reduced to rank-equivalent logs of probabilities. To account for data sparseness, the likelihood P(t|d) is interpolated using Jelinek-Mercer smoothing:</p><formula xml:id="formula_3" coords="3,194.04,455.10,276.67,24.46">P(d | q) = P(d) ⋅ ((1-λ) ⋅ P(t | D) + λ ⋅ P(t | d)) t ∈q ∏ (4)</formula><p>In the formula, D is the collection and λ is a smoothing parameter (in our experiments set to the default value of 0.15). The model needs to estimate three probabilities: the prior probability of the document, P(d); the probability of observing a term in a document, P(t|d) and the probability of observing the term in the collection, P(t|D). Assuming the query terms to be independent, and using a linear interpolation of a document model and a collection model to estimate the probability of a query term, the probabilities can be estimated using maximum likelihood estimates: <ref type="bibr" coords="3,459.00,587.44,11.71,8.96" target="#b4">(5)</ref> This language modeling approach has been used in past experiments within the CLEF, NTCIR and TREC joint evaluation campaigns -see for example Ahn et. Al <ref type="bibr" coords="4,124.80,172.60,10.69,8.96" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">N-Gram ranking scheme</head><p>The N-Grams stemming technique is very used in corpus resultant from OCR processes because many times the text brings OCR errors. This technique consists in tokenizing the words with a sliding window into tokens of size N, with N assuming several sizes. This process is applied both in documents and queries to increase retrieval performance.</p><p>The original N-Grams stemming does not fit very well in our problem because our records were not obtained from OCR processes. On other hand using this technique turns the stemming phase a language independent process, which was our main focus. For that reason, we used a simplistic approach for the N-Grams model which consist in suffixes removal starting in character N+1 and use the prefix for indexing purposes.</p><p>Recent experiments related in <ref type="bibr" coords="4,262.32,343.60,11.71,8.96" target="#b8">[9]</ref> by Parapar demonstrate that using independent N-Grams indexes, for example from 2 to 5 grams, and combining the individual ranks in a linear combination can improve the results when we find good parameter values to weight each independent index. Our objective was to use this technique. We tokenize our terms in five different ways each of which to create a different inverted file. We create four files with prefixes of N-Grams (2 to 5 grams) and one file with the original terms. The formula to calculate the final score is illustrated by the formula 6 introduced in <ref type="bibr" coords="4,187.80,424.12,10.69,8.96" target="#b8">[9]</ref>. <ref type="bibr" coords="4,441.96,464.44,11.71,8.96" target="#b5">(6)</ref> In formula d is the document α, β, γ, δ and ε are the weights assigned to each independent score. To implement this feature in Lucene we re-implement the term scorers of the text models (off-the-shelf and language model) to calculate the score.</p><p>The system was trained through experiments with 2008 AdHoc topics and relevance judgments. We found a set of optimal parameter values to weight each inverted file independently. Table <ref type="table" coords="4,264.00,539.32,4.98,8.96" target="#tab_0">1</ref> shows the optimal values found for each index in each collection. We found that bi-grams worsen the results so we set their weight to zero in the three collections. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Rocchio query expansion</head><p>The fact that there are frequently occurring spelling variations and synonyms for any query term degrades the performance of standard techniques for ad-hoc retrieval.</p><p>To overcome this problem, we experimented with the method for pseudo feedback query expansion proposed by Rocchio <ref type="bibr" coords="5,288.36,206.56,10.69,8.96" target="#b2">[3]</ref>. The Lucene extension from the LucQE project5 implements this approach. On test data from the 2004 TREC Robust Retrieval Track, LucQE achieved a MAP score of 0.2433 using Rocchio query expansion.</p><p>Assuming that the top D documents returned for an original query qi are relevant, a better query qi+1 can be given by the terms resulting from the formula bellow:</p><formula xml:id="formula_4" coords="5,213.36,282.99,256.96,29.55">q i+1 = α ⋅ q i + β | D | ⋅ termWeight (d r ) d r ∈D ∑<label>(7)</label></formula><p>In the formula, α and β are tuning parameters. In our experiments, they were set to the default values of 1.0 and 0.75. The system was trained through experiments with 2008 AdHoc topics and relevance judgments. We found an optimal value of 64 terms for English topics and 40 terms for French and German topics. The terms were extracted from the highest ranked documents (i.e. the |D| parameter) from the original query qi. With the training we obtain optimal values using 7 documents in English and French topics and 8 documents in German topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">N-Grams and Rocchio query expansion</head><p>In order to deal with N-Gram prefix stemming we need to adapt the Rochio formula. Three techniques were experimented but only the third one improves the results:</p><p>• First of all we try to use a list of expansion tokens with a fixed size of tokens of each inverted file (2,3,4,5 Grams and terms), let's say the 15 most relevant tokens of each inverted file. The boosting factors were calculated using the original formula of Rochio to rank terms independently in the different indexes (Inverted File for terms and N-Grams from 2 to 5). To smooth the boosting factor in the expanded query we used the weight of each inverted file (2,3,4,5 Grams and terms) found in training experiments (see Table <ref type="table" coords="5,459.96,544.42,3.58,8.88" target="#tab_0">1</ref>). This doesn't work.</p><p>• Second of all we picked up all terms of each top document, we tokenize them to obtain the 2,3,4,5 Grams tokens and we calculate the term relevance using as ranking function of Rochio formula in each inverted file and then we apply the linear combination introduced in section 2.3. This will give the rank of the term. The expanded query was build with the 5 projections of the term, 2-5 Grams tokens and the term, using the ranking calculated with the linear combination as boosting factor. Didn't work at all. • Third and our best approach which really improves the results was in first place calculate, independently in each inverted file, the score for each possible N-Grams tokens and terms present in top documents. In second place we order them independently of their source file (2-5Grams or term) and pick the most relevant ones. We calculate the score using Rochio formula for the pairs, source inverted file and token, and we smooth it with the respective weight presented in Table <ref type="table" coords="6,333.48,195.64,4.98,8.96" target="#tab_0">1</ref> depending on the inverted file. Finally the tokens were ordered by score ignoring their source file and finally the highest scored tokens were used. The score was used as boost factor in final query (e.g.: absolute:information^0.53 index5grams:retrie^0.02, etc).</p><p>Our third experiment method turns weak the tokens from less weighted indexes like 2-Grams, and 3-Grams. This fact makes that tokens from weak indexes only were picked if they were very relevant. Expanded queries were mainly composed by tokens of 4-5 Grams and terms. On other hand we presence that all queries had tokens from all indexes. With this technique we deal with all indexes in the same way taking into account that terms from less weighted indexes should be penalized and putted in the same bag.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Processing the topics and the document collections</head><p>Before the actual indexing, the document collections (i.e. the bibliographic records) were passed through the following pre-processing operations:</p><p>• Field Weighting -The bibliographic records composing the collections from the TEL@CLEF experiment contain structured information in the form of document fields such as title or subject. We use the scheme proposed by Robertson et. al <ref type="bibr" coords="6,458.88,436.24,11.71,8.96" target="#b4">[5]</ref> to weight the different document field according to their importance. Instead of changing the ranking formulas in order to introduce boosting factors, we generate virtual documents in which the content of some specific fields is repeated. The combination used in our experiments is based on repeating the title field three times, the subject field twice and keeping the other document fields unchanged. • Normalization -The structured documents were converted to unstructured documents for the process of indexing, removing the XML tags and putting the element's contents in separate sentences.</p><p>Topic processing was fully automatic and the queries submitted to the IR engine were generated using all parts of the topics (i.e. title, description and narrative). The generation of the actual queries from the query topics was based on the following sequence of processing operations:</p><p>• Parsing and Normalisation -All characters were reduced to the lowercase unaccented equivalents (i.e. "Ö" reduced to "o" and "É" to "e" etc.) in order to maximise matching. • Stop Word Removal -Stopword lists were used to remove terms that carry little meaning and would otherwise introduce noise. The considered stop words came from the minimized lists distributed with Lucene, containing words such as articles, pronouns, prepositions, conjunctions or interjections. For English, French and German, these lists contained 120, 155 and 231 terms, respectively. • Retrieval -The resulting queries were submitted to the IR system, which had been used to index the document collections. In some of the submitted runs, variations of the Porter <ref type="bibr" coords="7,188.76,196.36,11.71,8.96" target="#b0">[1]</ref> stemming algorithm specific to the language of the collection were used on both the queries and the documents. The stemming algorithms came from the Snowball package <ref type="foot" coords="7,223.92,218.98,3.00,5.40" target="#foot_4">6</ref> .</p><p>Lucene internally normalizes documents and queries to lower case, also removing stop-words. However, explicitly introducing these operations when processing the topics, has the advantage of facilitating the development of more advanced topic processing (e.g. adding query expansion methods).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The experimental story</head><p>We submitted 12 official runs to the CLEF evaluation process, a total of 4 runs for each of the languages/collections under consideration in the monolingual task. The runs were selected from those whose obtain best results with the 2008 topics. The conditions under test for each of the submitted runs are as follows: In Table <ref type="table" coords="7,174.36,536.32,4.98,8.96" target="#tab_1">2</ref> the key LM is the multinomial language model and VS is the Lucene off-the-shelf standard vector space model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>Table <ref type="table" coords="7,165.12,613.12,4.98,8.96" target="#tab_2">3</ref> shows the obtained results for the official runs that make up our TEL@CLEF experiments. The results show that, in terms of the mean average precision (MAP), the weighted N-Grams model outperforms our other submissions. The Rochio query expansion technique together with N-Grams model works fine and improves the results significantly. The weight N-Grams model was better than porter stemming in all situations. We present now the complete set of experiments using both text models, vector space and language model. We combine all possible situations using rochio query expansion and our different stemming approaches. We demonstrate that these two techniques, stemming and query expansion, improve the results when used alone and even more when combined. We demonstrate that the linear combination of N-Grams is many times better then porter stemming and can be used with rochio query expansion using our term selection method what improves the results even more. Table <ref type="table" coords="8,414.72,411.16,4.98,8.96" target="#tab_3">4</ref> resumes the obtained results in terms of MAP (Mean Average Precision), P@5 (Precision in first 5 results) and P@10 (Precision in first 10 results) for all possible combinations in the three languages. In French collection the experiment of the rochio query expansion with porter stemming is worst than using just porter stemming, the same is not true with the N-Grams thechnique which inclusively outperfoms all other experiments except language model with porter stemming that is a very strong run, also one of our best runs in 2008 experiments. The obtained results support the hypotheses that using Rocchio query expansion together with N-Grams weighted model and a ranking scheme based on language modeling can be beneficial to the CLEF ad-hoc task. The N-Grams prefix stemming linearly combined using tokens of different grams and terms outperform the Porter stemming technique in most scenarios especially when the linguistic stemmers are not appropriate. Using this technique with different text models appear to be independent from those models if the terms score is used independently in the formulas. Unlike last year where our experiments result in poor results both in French and German collections, this year we could obtain very encourage results. Like last year we presence that multinomial language model is almost equal to vector space model in majority of situations. On other hand the multinomial language model has the advantage that we could train it very easily tuning the language model parameters, which was not our objective in this experiment, so we believe that language model has potential to return even better results than vector space model.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,183.48,585.57,228.50,48.58"><head>Table 1 .</head><label>1</label><figDesc>Descriptions for the eight diferent submited scenarios</figDesc><table coords="4,191.52,603.17,212.28,30.98"><row><cell>Lanuage</cell><cell>Term</cell><cell>5-grams prefix</cell><cell>4-grams prefix</cell><cell>3-grams prefix</cell></row><row><cell>English</cell><cell>0.45</cell><cell>0,27</cell><cell>0,25</cell><cell>0,03</cell></row><row><cell>French</cell><cell>0.53</cell><cell>0,24</cell><cell>0,22</cell><cell>0,01</cell></row><row><cell>German</cell><cell>0,55</cell><cell>0,23</cell><cell>0,21</cell><cell>0,01</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,155.04,399.93,283.95,121.06"><head>Table 2 .</head><label>2</label><figDesc>Descriptions for the eight diferent submited scenarios</figDesc><table coords="7,155.04,417.53,283.95,103.46"><row><cell>RUN</cell><cell>Text Retrieval Model</cell><cell>Language</cell><cell>Stemmer</cell><cell>Query Expansion</cell></row><row><cell>1</cell><cell>LM</cell><cell>EN</cell><cell>Porter (snowball)</cell><cell>Rochio</cell></row><row><cell>2</cell><cell>VS</cell><cell>EN</cell><cell>Porter (snowball)</cell><cell>Rochio</cell></row><row><cell>3</cell><cell>LM -NGrams</cell><cell>EN</cell><cell>2-5Grams and Term</cell><cell>RochioN-Grams</cell></row><row><cell>4</cell><cell>VS -NGrams</cell><cell>EN</cell><cell>2-5Grams and Term</cell><cell>RochioN-Grams</cell></row><row><cell>5</cell><cell>LM -NGrams</cell><cell>FR</cell><cell>2-5Grams and Term</cell><cell>No</cell></row><row><cell>6</cell><cell>VS -NGrams</cell><cell>FR</cell><cell>2-5Grams and Term</cell><cell>No</cell></row><row><cell>7</cell><cell>LM -NGrams</cell><cell>FR</cell><cell>2-5Grams and Term</cell><cell>RochioN-Grams</cell></row><row><cell>8</cell><cell>VS -NGrams</cell><cell>FR</cell><cell>2-5Grams and Term</cell><cell>RochioN-Grams</cell></row><row><cell>9</cell><cell>LM</cell><cell>DE</cell><cell>Porter (snowball)</cell><cell>Rochio</cell></row><row><cell>10</cell><cell>VS</cell><cell>DE</cell><cell>Porter (snowball)</cell><cell>Rochio</cell></row><row><cell>11</cell><cell>LM -NGrams</cell><cell>DE</cell><cell>2-5Grams and Term</cell><cell>RochioN-Grams</cell></row><row><cell>12</cell><cell>VS -NGrams</cell><cell>DE</cell><cell>2-5Grams and Term</cell><cell>RochioN-Grams</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,133.44,184.41,328.57,141.61"><head>Table 3 .</head><label>3</label><figDesc>Results for the official runs submitted to TEL@CLEF</figDesc><table coords="8,133.44,201.81,328.57,124.22"><row><cell></cell><cell></cell><cell cols="2">English</cell><cell></cell><cell></cell><cell cols="2">French</cell><cell></cell><cell></cell><cell cols="2">German</cell><cell></cell></row><row><cell></cell><cell>RUN 1</cell><cell>RUN 2</cell><cell>RUN 3</cell><cell>RUN 4</cell><cell>RUN 5</cell><cell>RUN 6</cell><cell>RUN 7</cell><cell>RUN 8</cell><cell>RUN 9</cell><cell>RUN 10</cell><cell>RUN 11</cell><cell>RUN 12</cell></row><row><cell>num_q</cell><cell>50</cell><cell>50</cell><cell>50</cell><cell>50</cell><cell>50</cell><cell>50</cell><cell>50</cell><cell>50</cell><cell>50</cell><cell>50</cell><cell>50</cell><cell>50</cell></row><row><cell>num_ret</cell><cell>50000</cell><cell>50000</cell><cell>50000</cell><cell>50000</cell><cell>50000</cell><cell>50000</cell><cell>50000</cell><cell>50000</cell><cell>50000</cell><cell>50000</cell><cell>50000</cell><cell>50000</cell></row><row><cell>num_rel</cell><cell>2527</cell><cell>2527</cell><cell>2527</cell><cell>2527</cell><cell>1853</cell><cell>1853</cell><cell>1853</cell><cell>1853</cell><cell>1559</cell><cell>1559</cell><cell>1559</cell><cell>1559</cell></row><row><cell>num_rel_ret</cell><cell>1988</cell><cell>2039</cell><cell>1960</cell><cell>2095</cell><cell>1314</cell><cell>1369</cell><cell>1439</cell><cell>1457</cell><cell>1005</cell><cell>1036</cell><cell>1137</cell><cell>1173</cell></row><row><cell>map</cell><cell>0,4143</cell><cell>0,4012</cell><cell>0,424</cell><cell>0,4393</cell><cell>0,2526</cell><cell>0,2508</cell><cell>0,2653</cell><cell>0,2641</cell><cell>0,2891</cell><cell>0,281</cell><cell>0,3049</cell><cell>0,3005</cell></row><row><cell>gm_ap</cell><cell>0,254</cell><cell>0,2615</cell><cell>0,2379</cell><cell>0,2401</cell><cell>0</cell><cell>0,1358</cell><cell>0</cell><cell>0,132</cell><cell>0</cell><cell>0</cell><cell>0,1749</cell><cell>0,1648</cell></row><row><cell>ndcg</cell><cell>0,6358</cell><cell>0,64</cell><cell>0,6285</cell><cell>0,6432</cell><cell>0,4812</cell><cell>0,5004</cell><cell>0,5073</cell><cell>0,519</cell><cell>0,469</cell><cell>0,4626</cell><cell>0,5242</cell><cell>0,5211</cell></row><row><cell>R-prec</cell><cell>0,3953</cell><cell>0,3833</cell><cell>0,4018</cell><cell>0,401</cell><cell>0,2802</cell><cell>0,2635</cell><cell>0,2781</cell><cell>0,2666</cell><cell>0,3092</cell><cell>0,2861</cell><cell>0,3102</cell><cell>0,306</cell></row><row><cell>bpref</cell><cell>0,3756</cell><cell>0,3677</cell><cell>0,3897</cell><cell>0,4062</cell><cell>0,2435</cell><cell>0,2301</cell><cell>0,2525</cell><cell>0,2504</cell><cell>0,2689</cell><cell>0,2583</cell><cell>0,2865</cell><cell>0,2943</cell></row><row><cell>recip_rank</cell><cell>0,1659</cell><cell>0,198</cell><cell>0,1574</cell><cell>0,1089</cell><cell>0,1243</cell><cell>0,1805</cell><cell>0,1635</cell><cell>0,2157</cell><cell>0,1776</cell><cell>0,154</cell><cell>0,2273</cell><cell>0,1386</cell></row><row><cell>P5</cell><cell>0,696</cell><cell>0,664</cell><cell>0,672</cell><cell>0,676</cell><cell>0,496</cell><cell>0,48</cell><cell>0,512</cell><cell>0,476</cell><cell>0,516</cell><cell>0,54</cell><cell>0,524</cell><cell>0,508</cell></row><row><cell>P10</cell><cell>0,592</cell><cell>0,556</cell><cell>0,568</cell><cell>0,572</cell><cell>0,408</cell><cell>0,4</cell><cell>0,41</cell><cell>0,388</cell><cell>0,44</cell><cell>0,41</cell><cell>0,416</cell><cell>0,424</cell></row><row><cell>P15</cell><cell>0,5307</cell><cell>0,4987</cell><cell>0,496</cell><cell>0,5133</cell><cell>0,3613</cell><cell>0,3427</cell><cell>0,372</cell><cell>0,348</cell><cell>0,3947</cell><cell>0,3747</cell><cell>0,38</cell><cell>0,3773</cell></row><row><cell>P20</cell><cell>0,482</cell><cell>0,458</cell><cell>0,462</cell><cell>0,469</cell><cell>0,345</cell><cell>0,319</cell><cell>0,338</cell><cell>0,314</cell><cell>0,359</cell><cell>0,347</cell><cell>0,35</cell><cell>0,337</cell></row><row><cell>P30</cell><cell>0,426</cell><cell>0,4033</cell><cell>0,4113</cell><cell>0,4193</cell><cell>0,2987</cell><cell>0,2833</cell><cell>0,2987</cell><cell>0,2773</cell><cell>0,296</cell><cell>0,292</cell><cell>0,2847</cell><cell>0,28</cell></row><row><cell>P100</cell><cell>0,2408</cell><cell>0,2326</cell><cell>0,2332</cell><cell>0,2452</cell><cell>0,1624</cell><cell>0,161</cell><cell>0,1652</cell><cell>0,1716</cell><cell>0,1438</cell><cell>0,1406</cell><cell>0,149</cell><cell>0,1506</cell></row><row><cell>P200</cell><cell>0,1478</cell><cell>0,1491</cell><cell>0,1453</cell><cell>0,1566</cell><cell>0,0985</cell><cell>0,0996</cell><cell>0,1001</cell><cell>0,109</cell><cell>0,084</cell><cell>0,0811</cell><cell>0,0883</cell><cell>0,0894</cell></row><row><cell>P500</cell><cell>0,0728</cell><cell>0,0742</cell><cell>0,073</cell><cell>0,077</cell><cell>0,0473</cell><cell>0,0482</cell><cell>0,0496</cell><cell>0,0517</cell><cell>0,0376</cell><cell>0,0378</cell><cell>0,041</cell><cell>0,0423</cell></row><row><cell>P1000</cell><cell>0,0398</cell><cell>0,0408</cell><cell>0,0392</cell><cell>0,0419</cell><cell>0,0263</cell><cell>0,0274</cell><cell>0,0288</cell><cell>0,0291</cell><cell>0,0201</cell><cell>0,0207</cell><cell>0,0227</cell><cell>0,0235</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,142.32,514.89,310.81,139.57"><head>Table 4 .</head><label>4</label><figDesc>Results for the official runs submitted to TEL@CLEF</figDesc><table coords="8,142.32,533.25,310.81,121.22"><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>English</cell><cell></cell><cell></cell><cell>French</cell><cell></cell><cell></cell><cell>German</cell><cell></cell></row><row><cell>Model</cell><cell>Stemm</cell><cell>QE</cell><cell>MAP</cell><cell>P@5</cell><cell>P@10</cell><cell>MAP</cell><cell>P@5</cell><cell>P@10</cell><cell>MAP</cell><cell>P@5</cell><cell>P@10</cell></row><row><cell>VS</cell><cell>no</cell><cell>no</cell><cell>0.3403</cell><cell>0.6360</cell><cell>0.5200</cell><cell>0.2030</cell><cell>0.4400</cell><cell>0.3380</cell><cell>0.1357</cell><cell>0.3080</cell><cell>0.2340</cell></row><row><cell>LM</cell><cell>no</cell><cell>no</cell><cell>0.3496</cell><cell>0.6480</cell><cell>0.5260</cell><cell>0.2255</cell><cell>0.4680</cell><cell>0.4020</cell><cell>0.1480</cell><cell>0.3160</cell><cell>0.2680</cell></row><row><cell>VS</cell><cell>Porter</cell><cell>no</cell><cell>0.3710</cell><cell>0.6320</cell><cell>0.5500</cell><cell>0.2338</cell><cell>0.4360</cell><cell>0.3640</cell><cell>0.2372</cell><cell>0.4920</cell><cell>0.3720</cell></row><row><cell>LM</cell><cell>Porter</cell><cell>no</cell><cell>0.3829</cell><cell>0.6800</cell><cell>0.5480</cell><cell>0.2647</cell><cell>0.4760</cell><cell>0.3860</cell><cell>0.2473</cell><cell>0.5040</cell><cell>0.3880</cell></row><row><cell>VS</cell><cell>2-5Grams</cell><cell>no</cell><cell>0.3966</cell><cell>0.6760</cell><cell>0.5620</cell><cell>0.2508</cell><cell>0.4800</cell><cell>0.4000</cell><cell>0.2439</cell><cell>0.4800</cell><cell>0.3680</cell></row><row><cell>LM</cell><cell>2-5Grams</cell><cell>no</cell><cell>0.3902</cell><cell>0.6800</cell><cell>0.5500</cell><cell>0.2526</cell><cell>0.4960</cell><cell>0.4080</cell><cell>0.2524</cell><cell>0.4880</cell><cell>0.3880</cell></row><row><cell>VS</cell><cell>no</cell><cell>Rochio</cell><cell>0.3712</cell><cell>0.6240</cell><cell>0.5400</cell><cell>0.2015</cell><cell>0.4320</cell><cell>0.3420</cell><cell>0.1725</cell><cell>0.3320</cell><cell>0.2740</cell></row><row><cell>LM</cell><cell>no</cell><cell>Rochio</cell><cell>0.3778</cell><cell>0.6200</cell><cell>0.5420</cell><cell>0.2213</cell><cell>0.4280</cell><cell>0.3500</cell><cell>0.1921</cell><cell>0.3320</cell><cell>0.3060</cell></row><row><cell>VS</cell><cell>Porter</cell><cell>Rochio</cell><cell>0.4012</cell><cell>0.6640</cell><cell>0.5560</cell><cell>0.2186</cell><cell>0.4240</cell><cell>0.3380</cell><cell>0.2810</cell><cell>0.5400</cell><cell>0.4100</cell></row><row><cell>LM</cell><cell>Porter</cell><cell>Rochio</cell><cell>0.4143</cell><cell>0.6960</cell><cell>0.5920</cell><cell>0.2391</cell><cell>0.4240</cell><cell>0.3500</cell><cell>0.2891</cell><cell>0.5160</cell><cell>0.4400</cell></row><row><cell>VS</cell><cell>2-5Grams</cell><cell>Rochio 2-5Grams</cell><cell>0.4393</cell><cell>0.6760</cell><cell>0.5720</cell><cell>0.2641</cell><cell>0.4760</cell><cell>0.3880</cell><cell>0.3005</cell><cell>0.5080</cell><cell>0.4240</cell></row><row><cell>LM</cell><cell>2-5Grams</cell><cell>Rochio 2-5Grams</cell><cell>0.4240</cell><cell>0.6720</cell><cell>0.5680</cell><cell>0.2653</cell><cell>0.5120</cell><cell>0.4100</cell><cell>0.3049</cell><cell>0.5240</cell><cell>0.4160</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,130.08,665.13,216.82,8.10"><p>http://code.google.com/p/digmap/wiki/LuceneGeoTemporal</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,130.08,675.69,78.42,8.10"><p>http://www.dgmap.eu</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,130.08,686.13,86.58,8.10"><p>http://lucene.apache.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_3" coords="5,130.08,686.13,116.86,8.10"><p>http://lucene-qe.sourceforge.net/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_4" coords="7,130.08,686.13,100.06,8.10"><p>http://snowball.tartarus.org/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="9,128.20,392.01,342.52,8.10;9,136.20,402.33,334.50,8.10;9,136.20,412.65,66.60,8.10" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="9,190.20,392.01,121.43,8.10">An algorithm for suffix stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,165.84,402.33,130.69,8.10">Readings in Information Retrieval</title>
		<editor>
			<persName><forename type="first">Sparck</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Willett</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename></persName>
		</editor>
		<meeting><address><addrLine>San Francisco</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="1980">1997. 1980</date>
			<biblScope unit="page" from="313" to="316" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,128.20,423.09,342.55,8.10;9,136.20,433.41,255.24,8.10" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="9,188.88,423.09,185.07,8.10">Using Language Models for Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hiemstra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>Centre for Telematics and Information Technology, University of Twente</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Ph.D. Thesis</note>
</biblStruct>

<biblStruct coords="9,128.20,443.73,342.41,8.10;9,136.20,454.05,334.53,8.10;9,136.20,464.49,24.12,8.10" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="9,193.68,443.73,276.94,8.10;9,136.20,454.05,24.56,8.10">Relevance Feedback in Information Retrieval: In: The SMART Retrieval System</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">J</forename><surname>Rocchio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,169.20,454.05,183.17,8.10">Experiments in Automatic Document Processing</title>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="1971">1971</date>
			<biblScope unit="page" from="313" to="323" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,128.20,474.81,342.52,8.10;9,136.20,485.13,323.04,8.10" xml:id="b3">
	<monogr>
		<title level="m" type="main" coord="9,189.84,474.81,252.21,8.10">Mitra: A Metadata Aware Web Search Engine for Digital Libraries</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Machado</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
		<respStmt>
			<orgName>Departamento de Engenharia Informática, Technical University of Lisbon</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">M.Sc. Thesis</note>
</biblStruct>

<biblStruct coords="9,128.21,495.45,110.80,8.10;9,258.00,495.45,212.58,8.10;9,136.20,505.89,334.50,8.10;9,136.20,516.21,334.53,8.10;9,136.20,526.53,136.56,8.10" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,302.88,495.45,167.70,8.10;9,136.20,505.89,19.22,8.10">Simple BM25 extension to multiple weighted fields</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,172.08,505.89,298.62,8.10;9,136.20,516.21,91.78,8.10;9,431.04,516.21,36.49,8.10">Proceedings of the Thirteenth ACM international Conference on information and Knowledge Management</title>
		<meeting>the Thirteenth ACM international Conference on information and Knowledge Management<address><addrLine>Washington, D.C., USA; New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004">November 08 -13, 2004. 2004</date>
			<biblScope unit="page" from="42" to="49" />
		</imprint>
	</monogr>
	<note>CIKM &apos;04</note>
</biblStruct>

<biblStruct coords="9,128.21,536.85,342.47,8.10;9,136.20,547.29,334.62,8.10;9,136.20,557.61,193.55,8.10" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,270.96,547.29,142.56,8.10">The University of Amsterdam at TREC</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">D</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Balog</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">S</forename><surname>Fissaha</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Jijkoun</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kamps</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>De Rijke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Erik</forename><surname>Tjong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kim</forename><surname>Sang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,438.84,547.29,31.98,8.10;9,136.20,557.61,163.16,8.10">Working Notes for the 2005 Text Retrieval Conference</title>
		<imprint>
			<date type="published" when="2005">2005. 2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,128.21,567.93,342.49,8.10;9,136.20,578.25,334.50,8.10;9,136.20,588.57,334.57,8.10;9,136.20,599.01,99.12,8.10" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,344.52,567.93,126.18,8.10;9,136.20,578.25,87.39,8.10">DIGMAP: A service for searching and browsing old maps</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Pedrosa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Luzio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Manguinhas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Martins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,243.60,578.25,227.10,8.10;9,136.20,588.57,61.10,8.10;9,385.44,588.57,34.90,8.10">Proceedings of the 8th ACM/IEEE-CS Joint Conference on Digital Libraries</title>
		<meeting>the 8th ACM/IEEE-CS Joint Conference on Digital Libraries<address><addrLine>Pittsburgh PA, PA, USA; New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">June 16 -20, 2008. 2008</date>
			<biblScope unit="page" from="431" to="431" />
		</imprint>
	</monogr>
	<note>JCDL &apos;08</note>
</biblStruct>

<biblStruct coords="9,128.21,609.33,342.42,8.10;9,136.20,619.65,334.50,8.10;9,136.20,629.97,310.05,8.10" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="9,304.64,609.33,165.98,8.10;9,136.20,619.65,77.82,8.10">LGTE: Lucene Extensions for Geo-Temporal Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Machado</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Martins</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Borbinha</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009-04">2009. April 2009</date>
			<pubPlace>Toulouse</pubPlace>
		</imprint>
	</monogr>
	<note>paper will be presented at the European Conference on Information Retrieval, at Workshop on Geographic Information on Internet</note>
</biblStruct>

<biblStruct coords="9,128.21,640.41,342.55,8.10;9,136.20,650.73,334.53,8.10;9,136.20,661.05,77.34,8.10" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,336.24,640.41,134.52,8.10;9,136.20,650.73,148.44,8.10">Revisiting N-gram Based Models for Retrieval in Degraded Large Collections</title>
		<author>
			<persName coords=""><forename type="first">Javier</forename><forename type="middle">;</forename><surname>Parapar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ana</forename><forename type="middle">;</forename><surname>Freire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Álvaro</forename><surname>Barreiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,295.08,650.73,172.14,8.10">European Conference on Information Retrieval</title>
		<meeting><address><addrLine>Toulouse</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-04">2009. April 2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
