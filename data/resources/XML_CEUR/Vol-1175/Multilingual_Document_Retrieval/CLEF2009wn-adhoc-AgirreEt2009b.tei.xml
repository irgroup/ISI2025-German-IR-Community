<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,119.28,97.87,364.41,17.23;1,188.04,119.83,226.76,17.23">Using semantic relatedness and word sense disambiguation for (CL)IR</title>
				<funder ref="#_yCCkTpj">
					<orgName type="full">KNOW</orgName>
				</funder>
				<funder ref="#_r5F57Ng">
					<orgName type="full">Basque Government</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,195.72,160.07,57.54,9.96"><forename type="first">Eneko</forename><surname>Agirre</surname></persName>
							<email>e.agirre@ehu.es</email>
							<affiliation key="aff0">
								<orgName type="laboratory">IXA NLP Group</orgName>
								<orgName type="institution">University of the Basque Country. Donostia</orgName>
								<address>
									<country>Basque Country</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,263.76,160.07,62.93,9.96"><forename type="first">Arantxa</forename><surname>Otegi</surname></persName>
							<email>arantza.otegi@ehu.es</email>
							<affiliation key="aff0">
								<orgName type="laboratory">IXA NLP Group</orgName>
								<orgName type="institution">University of the Basque Country. Donostia</orgName>
								<address>
									<country>Basque Country</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,337.20,160.07,65.92,9.96"><forename type="first">Hugo</forename><surname>Zaragoza</surname></persName>
							<email>hugoz@yahoo-inc.com</email>
							<affiliation key="aff1">
								<orgName type="institution">Yahoo! Researech</orgName>
								<address>
									<settlement>Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,119.28,97.87,364.41,17.23;1,188.04,119.83,226.76,17.23">Using semantic relatedness and word sense disambiguation for (CL)IR</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">8CA379447BD773D66DE9D0924CD2E2B8</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>I.2 [Artificial Intelligence]: I.2.7 Natural Language Processing Robust Retrieval, CLIR, Word Sense Disambiguation, Lexical Relatedness, Document Expansion</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we report the experiments for the CLEF 2009 Robust-WSD task, both for the monolingual (English) and the bilingual (Spanish to English) subtasks. Our main experimentation strategy consisted on expanding and translating the documents, based on the related concepts of the documents. For that purpose we applied a stateof-the art semantic relatedness method based on WordNet. The relatedness measure was used with and without WSD information. Even if we obtained positive results in our training and development datasets, we did not manage to improve over the baseline in the monolingual case. The improvement over the baseline in the bilingual case is marginal. We plan to further work on this technique, which has attained positive results in the passage retrieval for question answering task at CLEF (ResPubliQA).</p><p>.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Our goal is to test whether Word Sense Disambiguation (WSD) information can be beneficial for Cross Lingual Information Retrieval (CLIR) or monolingual Information Retrieval (IR). WordNet has been previously used to expand the terms in the query with some success <ref type="bibr" coords="1,421.28,575.51,10.43,9.96" target="#b2">[3,</ref><ref type="bibr" coords="1,434.35,575.51,7.79,9.96" target="#b3">4,</ref><ref type="bibr" coords="1,444.67,575.51,7.79,9.96" target="#b4">5,</ref><ref type="bibr" coords="1,455.10,575.51,6.95,9.96" target="#b6">7]</ref>. WordNetbased approaches need to deal with ambiguity, which proves difficult given the little context available to disambiguate the word in the query effectively. In our experience document expansion works better than topic expansion (see our results of the last edition in <ref type="bibr" coords="1,399.33,611.39,10.29,9.96" target="#b5">[6]</ref>). Bearing this in mind, this edition we have mainly focused on documents, using a more elaborate expansion strategy. We have applied a state-of-the-art semantic relatedness method based on WordNet <ref type="bibr" coords="1,452.92,635.27,10.43,9.96" target="#b0">[1]</ref> in order to select the best terms to expand the documents. The relatedness method can optionally use the WSD information provided by the organizers.</p><p>The remainder of this paper is organized as follows. Section 2 describes the experiments carried out. Section 3 presents the results obtained. Finally, Section 4 draws the conclusions and mentions future work.</p><p>Our main experimentation strategy consisted on expanding the documents, based on the related concepts of the documents. The steps of our retrieval system are the following. We first expand translate the topics. In a second step we extract the related concepts of the documents, and expand the documents with the words linked to these concepts in WordNet. Then we index these new expanded documents, and finally, we search for the queries in the indexes in various combinations. All steps are described sequentially.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Expansion and translation strategies of the topics</head><p>WSD data provided to the participants was based on WordNet version 1.6. Each word sense has a WordNet synset assigned with a score. Using those synset codes and the English and Spanish wordnets, we expanded the topics. In this way, we generated different topic collections using different approaches of expansion and translation, as follows:</p><p>• Full expansion of English topics: expansion to all synonyms of all senses.</p><p>• Best expansion of English topics: expansion to the synonyms of the sense with highest WSD score for each word, using either UBC or NUS disambiguation data (as provided by organizers).</p><p>• Translation of Spanish topics: translation from Spanish to English of the first sense for each word, taking the English variants from WordNet.</p><p>In both cases we used the Spanish and English wordnet versions provided by the organizers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Query construction</head><p>We constructed queries using the title and description topic fields. Based on the training topics, we excluded some words and phrases from the queries, such as find, describing, discussing, document, report for English and encontrar, describir, documentos, noticias, ejemplos for Spanish. After excluding those words and taking only nouns, adjectives, verbs and numbers, we constructed several queries for each topic using the different expansions of the topics (see Section 2.1) as follows:</p><p>• Original words.</p><p>• Both original words and expansions for the best sense of each word.</p><p>• Both original words and all expansions for each word.</p><p>• Translated words, using translations for the best sense of each word. If a word had no translation, the original word was included in the query.</p><p>The first three cases are for the monolingual runs, and the last one for the bilingual run which translated the query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Expansion and translation strategies of the documents</head><p>Our document expansion strategy was based on semantic relatedness. For that purpose we used UKB<ref type="foot" coords="2,112.32,629.11,3.95,6.37" target="#foot_0">1</ref> , a collection of programs for performing graph-based Word Sense Disambiguation and lexical similarity/relatedness using a pre-existing knowledge base, in this case WordNet 1.6.</p><p>Given a document, UKB returns a vector of scores for each concept in WordNet. The higher the score, the more related is the concept to the given document. In our experiments we used different approaches to represent each document:</p><p>• using all the synsets of each word of the document.</p><p>• using only the synset with highest WSD score for each word, as given by the UBC disambiguation data (provided by the organizers).</p><p>In both cases, UKB was initialized using the WSD weights: each synset was weighted with the score returned by the disambiguation system, that is, each concept was weighted according to the WSD weight of the corresponding sense of the target word.</p><p>Once UKB outputs the list of related concepts, we took the highest-scoring 100 or 500 concepts and expanded them to all variants (words in the concept) as given by WordNet. For the bilingual run, we took the Spanish variants. In both cases we used the Spanish and English wordnet versions provided by the organizers.</p><p>The variants for those expanded concepts were included in two new fields of the document representation; 100 concepts in the first field and 400 concepts in the second field. This way, we were able to use the original words only, or also the most related 100 concepts, or the original words and the most related 500 concepts. We will get back to this in Section 2.4 and Section 2.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Indexing</head><p>We indexed the new expanded documents using the MG4J search-engine <ref type="bibr" coords="3,422.27,277.67,9.89,9.96" target="#b1">[2]</ref>. MG4J makes it possible to combine several indices over the same document collection. We created one index for each field: one for the original words, one for the expansion of the top 100 concepts, and another one for the expansion of the following 400 concepts. Porter stemming was used as per usual.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Retrieval</head><p>We carried out several retrieval experiments combining different kind of queries with different kind of indices. We used the training data to perform extensive experimentation, and choose the ones with best MAP results in order to produce the test topic runs.</p><p>The different kind of queries that we had prepared are those explained in Section 2.2. Our experiments showed that original words were getting good results, so in the test runs we used only the queries with original words.</p><p>MG4J allows multi-index queries, where one can specify which of the indices one wants to search in, and assign different weights to each index. We conducted different experiments, by using the original words alone (the index made of original words) and also by using one or both indices with the expansion of concepts, giving different weight to the original words and the expanded concepts. The best weights were then used in the test set, as explained in the following Section.</p><p>We used the BM25 ranking function with the following parameters: 1.0 for k1 and 0.6 for b. We did not tune these parameters.</p><p>The submitted runs are described in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>Table <ref type="table" coords="3,117.10,569.63,5.03,9.96" target="#tab_0">1</ref> summarizes the results of our submitted runs. The IR process is the same for all the runs and the main differences between them is the expansion strategy. The characteristics of each run are as follows:</p><p>• monolingual without WSD:</p><p>-EnEnNowsd: original terms in topics; original terms in documents.</p><p>• monolingual with WSD:</p><p>-EnEnAllSenses100Docs: original terms in topics; both original and expanded terms of 100 concepts, using all senses for initializing the semantic graph. The weight of the index that included the expanded terms: 0.25.</p><p>-EnEnBestSense100Docs: original terms in topics; both original and expanded terms of 100 concepts, using best sense for initializing the semantic graph. The weight of the index that included the expanded terms: 0.25.</p><p>-EnEnBestSense500Docs: original terms in topics; both original and expanded terms of 500 concepts, using best sense for initializing the semantic graph. The weight of the index that included the expanded terms: 0.25.</p><p>• bilingual without WSD:</p><p>-EsEnNowsd: translated terms in topics (from Spanish to English); original terms in documents (in English).</p><p>• bilingual with WSD:</p><p>-EsEn1stTopsAllSenses100Docs: translated terms in topics (from Spanish to English); both original and expanded terms of 100 concepts, using all senses for initializing the semantic graph. The weight of the index that included the expanded terms: 0.15.</p><p>-EsEn1stTopsBestSense500Docs: translated terms in topics (from Spanish to English); both original and expanded terms of 100 concepts, using best sense for initializing the semantic graph. The weight of the index that included the expanded terms: 0.15.</p><p>-EsEnAllSenses100Docs: original terms in topics (in Spanish); both original terms (in English) and translated terms (in Spanish) in documents, using all senses for initializing the semantic graph. The weight of the index that included the expanded terms: 1.00.</p><p>-EsEnBestSense500Docs: original terms in topics (in Spanish); both original terms (in English) and translated terms (in Spanish) in documents, using best sense for initializing the semantic graph. The weight of the index that included the expanded terms: 1.60.</p><p>The weight of the index which was created using the original terms of the documents was 1.00 for all the runs. Regarding monolingual results, we can see that using the best sense for representing the document when initializing the semantic graph achieves slightly higher results with respect to using all senses. Besides, we obtained better results when we expanded the documents using 500 concepts than using only 100 (compare the results of the runs EnEnBestSense100Docs and EnEnBestSense500Docs). However, we did not achieve any improvement over the baseline with neither WSD or semantic relatedness information. We have to mention that we did achieve improvement in the training data, but the difference was not significant<ref type="foot" coords="4,391.68,673.51,3.95,6.37" target="#foot_1">2</ref> .</p><p>With respect to the bilingual results, EsEn1stTopsBestSense500Docs obtains the best result, although the difference with respect to the baseline run is not statistically significant. This is different to the results obtained using the training data, where the improvements using the semantic expansion were remarkable. It is not very clear whether translating the topics from Spanish to English or translating the documents from English to Spain is better, since we got better results in the first case in the testing phase (see runs called ...1stTops... in the Table <ref type="table" coords="5,452.66,121.19,3.88,9.96" target="#tab_0">1</ref>), but not in the training phase.</p><p>In our experiments we did not make any effort to deal with hard topics, and we only paid attention to improvements in Mean Average Precision (MAP) metric. In fact, we applied the settings which proved best in training data according to MAP. Another option could have been to optimize the parameters and settings according to Geometric Mean Average Precision (GMAP) values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions and future work</head><p>We have described our experiments and the results obtained in both monolingual and bilingual tasks at Robust-WSD Track at CLEF 2009. Our main experimentation strategy consisted on expanding the documents based on a semantic relatedness algorithm.</p><p>The objective of carrying out different expansion strategies was to study if WSD information and semantic relatedness could be used in an effective way in (CL)IR. After analyzing the results, we have found that those expansion strategies were not very helpful, especially in the monolingual task.</p><p>For the future, we want to analyze why we have not achieved higher gains using the semantic expansion, as the same strategy obtained remarkable improvements in the passage retrieval task (ResPubliQA).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,130.32,432.95,342.57,141.72"><head>Table 1 :</head><label>1</label><figDesc>Results for submitted runs</figDesc><table coords="4,130.32,452.39,342.57,122.28"><row><cell></cell><cell></cell><cell>runId</cell><cell>map</cell><cell>gmap</cell></row><row><cell cols="2">monolingual no WSD</cell><cell>EnEnNowsd</cell><cell cols="2">0.3826 0.1707</cell></row><row><cell></cell><cell cols="2">with WSD EnEnAllSenses100Docs</cell><cell cols="2">0.3654 0.1573</cell></row><row><cell></cell><cell></cell><cell>EnEnBestSense100Docs</cell><cell cols="2">0.3668 0.1589</cell></row><row><cell></cell><cell></cell><cell>EnEnBestSense500Docs</cell><cell cols="2">0.3805 0.1657</cell></row><row><cell>bilingual</cell><cell>no WSD</cell><cell>EsEnNowsd</cell><cell cols="2">0.1805 0.0190</cell></row><row><cell></cell><cell cols="2">with WSD EsEn1stTopsAllSenses100Docs</cell><cell cols="2">0.1827 0.0193</cell></row><row><cell></cell><cell></cell><cell cols="3">EsEn1stTopsBestSense500Docs 0.1838 0.0198</cell></row><row><cell></cell><cell></cell><cell>EsEnAllSenses100Docs</cell><cell cols="2">0.1402 0.0086</cell></row><row><cell></cell><cell></cell><cell>EsEnBestSense500Docs</cell><cell cols="2">0.1772 0.0132</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,105.24,696.52,238.47,7.97"><p>The algorithm is publicly available at http://ixa2.si.ehu.es/ukb/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,105.24,693.40,230.91,7.97"><p>We used paired Randomization Tests over MAPs with α=0.05</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work has been supported by <rs type="funder">KNOW</rs> (<rs type="grantNumber">TIN2006-15049-C03-01</rs>) and <rs type="projectName">KYOTO</rs> (<rs type="grantNumber">ICT-2007-211423</rs>). <rs type="person">Arantxa Otegi</rs>'s work is funded by a PhD grant from the <rs type="funder">Basque Government</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_yCCkTpj">
					<idno type="grant-number">TIN2006-15049-C03-01</idno>
					<orgName type="project" subtype="full">KYOTO</orgName>
				</org>
				<org type="funding" xml:id="_r5F57Ng">
					<idno type="grant-number">ICT-2007-211423</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,105.47,476.63,407.28,9.96;5,105.48,488.63,407.18,9.96;5,105.48,500.51,407.00,9.96;5,105.48,512.51,163.18,9.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,419.94,476.63,92.81,9.96;5,105.48,488.63,300.88,9.96">A study on similarity and relatedness using distributional and WordNet-based approaches</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Soroa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Alfonseca</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Kravalova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pasca</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,431.63,488.63,81.03,9.96;5,105.48,500.51,407.00,9.96;5,105.48,512.51,40.49,9.96">Proceedings of annual meeting of the North American Chapter of the Association of Computational Linguistics (NAACL)</title>
		<meeting>annual meeting of the North American Chapter of the Association of Computational Linguistics (NAACL)<address><addrLine>Boulder, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-06">June 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.47,532.31,407.33,9.96;5,105.48,544.19,407.13,9.96;5,105.48,556.19,318.57,9.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,211.97,532.31,72.17,9.96">MG4J at TREC</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Boldi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Vigna</surname></persName>
		</author>
		<ptr target="http://mg4j.dsi.unimi.it/" />
	</analytic>
	<monogr>
		<title level="m" coord="5,142.77,544.19,310.19,9.96">The Fourteenth Text REtrieval Conference (TREC 2005) Proceedings</title>
		<editor>
			<persName><forename type="first">Ellen</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Lori</forename><forename type="middle">P</forename><surname>Buckland</surname></persName>
		</editor>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2005">2005. 2005</date>
			<biblScope unit="volume">number</biblScope>
			<biblScope unit="page" from="500" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.47,575.99,407.33,9.96;5,105.48,587.87,181.26,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,244.49,575.99,268.31,9.96;5,105.48,587.87,37.83,9.96">Information retrieval using word senses: Root sense tagging approach</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Seo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Rim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,164.72,587.87,90.72,9.96">Proceedings of SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.47,607.67,407.23,9.96;5,105.48,619.67,283.77,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,267.64,607.67,245.06,9.96;5,105.48,619.67,140.56,9.96">An effective approach to document retrieval via utilizing wordnet and recognizing phrases</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,267.11,619.67,90.84,9.96">Proceedings of SIGIR</title>
		<meeting>SIGIR</meeting>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.47,639.47,407.23,9.96;5,105.48,651.35,314.21,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,238.61,639.47,163.73,9.96">Word sense disambiguation in queries</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Meng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,424.24,639.47,88.47,9.96;5,105.48,651.35,282.49,9.96">Proceedings of ACM Conference on Information and Knowledge Management (CIKM)</title>
		<meeting>ACM Conference on Information and Knowledge Management (CIKM)</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,105.47,671.15,407.17,9.96;5,105.48,683.15,407.15,9.96;5,105.48,695.03,395.47,9.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,261.23,671.15,251.42,9.96;5,105.48,683.15,254.90,9.96">IXA at CLEF 2008 Robust-WSD task: using Word Sense Disambiguation for (Cross Lingual) Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Otegi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Agirre</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Rigau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,384.97,683.15,127.67,9.96;5,105.48,695.03,112.04,9.96">Working Notes of the Cross-Lingual Evaluation Forum</title>
		<meeting><address><addrLine>Aarhus, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.47,61.43,407.14,9.96;6,105.48,73.43,351.14,9.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,274.85,61.43,217.19,9.96">UCM-Y!R at CLEF2008 Robust and WSD tasks</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Pérez-Agüera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Zaragoza</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,105.48,73.43,236.46,9.96">Working Notes of the Cross-Lingual Evaluation Forum</title>
		<meeting><address><addrLine>Aarhus, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
