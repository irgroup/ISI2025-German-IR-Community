<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,129.72,98.63,343.69,15.51;1,251.88,120.59,99.36,15.51">Multilingual Query Expansion for CLEF Adhoc-TEL</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,269.76,154.31,63.74,9.62"><forename type="first">Ray</forename><forename type="middle">R</forename><surname>Larson</surname></persName>
							<email>ray@sims.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,129.72,98.63,343.69,15.51;1,251.88,120.59,99.36,15.51">Multilingual Query Expansion for CLEF Adhoc-TEL</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">0E371A3ACC4F3477D4C6022039340AEF</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing; H.3.3 Information Search and Retrieval Algorithms</term>
					<term>Performance</term>
					<term>Measurement Cheshire II</term>
					<term>Logistic Regression</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In this paper we will briefly describe the approaches taken by the Cheshire (Berkeley) Group for the CLEF Adhoc-TEL 2009 tasks (Mono and Bilingual retrieval). Recognizing that many potentially relevant documents in each of the TEL sub-collections are in other languages, we tried to use multiple translations of the topics for searching each subcollection, combined into a single query. Overall this strategy performed very poorly compared to the the basic monolingual approach used last year (and repeated for one run in each language this year). We haven't yet completed our analysis of the reasons for this (we suspect that results were evaluated expecting the retrieved items to also be in the same language as the topic).</p><p>Once again this year we used probabilistic text retrieval based on logistic regression and incorporating blind relevance feedback for all of the runs. All translation for bilingual tasks was performed using the LEC Power Translator PC-based MT system. Our results this year, however, were surprising poor compared to last year's results. Some testing has shown that, for some cases, unexpected hyphenations in the machine translation and untranslated words were to blame. It may also be the case that others have significantly improved their approaches for this task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Each the collections used in the CLEF Adhoc TEL track are considered to be "mainly" in a particular language (English for BL, French for BNF, and German for ONB), according to the language codes of the records, only about half of each collection was in that main language, with virtually all other languages represented by one or more entries in one or another of the collections. German, French, English, and Spanish records were available in all of collections. This overlap of languages presents an interesting multilingual search (and evaluation) problem, and we attempted to address it this year by using tranlations of topics into each of the other languages and combining those translations with the original topic in some of our submissions.</p><p>This paper concentrates on the retrieval algorithms and evaluation results for Berkeley's official submissions for the Adhoc-TEL 2008 track. All of the runs were automatic without manual intervention in the queries (or translations). We submitted nine Monolingual runs (three German, three English, and three French) and 12 Bilingual runs (four for each target language German, English and French, with both expanded and unexpanded topics).</p><p>This paper first describes the retrieval algorithms used for our submissions, followed by a discussion of the processing used for the runs. We then examine the results obtained for our official runs, and finally present conclusions and future directions for Adhoc-TEL participation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">The Retrieval Algorithms</head><p>Note that this section is virtually identical to one that appears in our papers from previous CLEF participation and appears here for reference only <ref type="bibr" coords="2,297.10,235.55,12.58,9.62" target="#b7">[8,</ref><ref type="bibr" coords="2,312.86,235.55,8.10,9.62" target="#b6">7]</ref> The basic form and variables of the Logistic Regression (LR) algorithm used for all of our submissions was originally developed by Cooper, et al. <ref type="bibr" coords="2,119.16,259.55,9.91,9.62" target="#b4">[5]</ref>. As originally formulated, the LR model of probabilistic IR attempts to estimate the probability of relevance for each document based on a set of statistics about a document collection and a set of queries in combination with a set of weighting coefficients for those statistics. The statistics to be used and the values of the coefficients are obtained from regression analysis of a sample of a collection (or similar test collection) for some set of queries where relevance and nonrelevance has been determined. More formally, given a particular query and a particular document in a collection P (R | Q, D) is calculated and the documents or components are presented to the user ranked in order of decreasing values of that probability. To avoid invalid probability values, the usual calculation of P (R | Q, D) uses the "log odds" of relevance given a set of S statistics, s i , derived from the query and database, such that:</p><formula xml:id="formula_0" coords="2,235.08,385.50,277.96,30.50">log O(R | Q, D) = b 0 + S i=1 b i s i (1)</formula><p>where b 0 is the intercept term and the b i are the coefficients obtained from the regression analysis of the sample collection and relevance judgements. The final ranking is determined by the conversion of the log odds form to probabilities:</p><formula xml:id="formula_1" coords="2,232.44,465.21,280.60,25.12">P (R | Q, D) = e log O(R|Q,D) 1 + e log O(R|Q,D)<label>(2)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">TREC2 Logistic Regression Algorithm</head><p>For Adhoc-TEL we used a version the Logistic Regression (LR) algorithm that has been used very successfully in Cross-Language IR by Berkeley researchers for a number of years <ref type="bibr" coords="2,442.52,534.71,11.84,9.62" target="#b2">[3]</ref>. The formal definition of the TREC2 Logistic Regression algorithm used is: c k are the k coefficients obtained though the regression analysis.</p><formula xml:id="formula_2" coords="2,184.08,574.66,328.96,133.18">log O(R|C, Q) = log p(R|C, Q) 1 -p(R|C, Q) = log p(R|C, Q) p(R|C, Q) = c 0 + c 1 * 1 |Q c | + 1 |Qc| i=1 qtf i ql + 35 + c 2 * 1 |Q c | + 1 |Qc| i=1 log tf i cl + 80 (3) -c 3 * 1 |Q c | + 1 |Qc| i=1 log ctf i N t + c 4 *</formula><p>If stopwords are removed from indexing, then ql, cl, and N t are the query length, document length, and collection length, respectively. If the query terms are re-weighted (in feedback, for example), then qtf i is no longer the original term frequency, but the new weight, and ql is the sum of the new weight values for the query terms. Note that, unlike the document and collection lengths, query length is the "optimized" relative frequency without first taking the log over the matching terms.</p><p>The coefficients were determined by fitting the logistic regression model specified in log O(R|C, Q) to TREC training data using a statistical software package. The coefficients, c k , used for our official runs are the same as those described by Chen <ref type="bibr" coords="3,320.65,421.91,13.51,9.62" target="#b0">[1]</ref>. These were: c 0 = -3.51, c 1 = 37.4, c 2 = 0.330, c 3 = 0.1937 and c 4 = 0.0929. Further details on the TREC2 version of the Logistic Regression algorithm may be found in Cooper et al. <ref type="bibr" coords="3,321.15,445.79,10.00,9.62" target="#b3">[4]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Blind Relevance Feedback</head><p>In addition to the direct retrieval of documents using the TREC2 logistic regression algorithm described above, we have implemented a form of "blind relevance feedback" as a supplement to the basic algorithm. The algorithm used for blind feedback was originally developed and described by Chen <ref type="bibr" coords="3,115.44,527.99,10.00,9.62" target="#b1">[2]</ref>. Blind relevance feedback has become established in the information retrieval community due to its consistent improvement of initial search results as seen in TREC, CLEF and other retrieval evaluations <ref type="bibr" coords="3,179.77,551.87,10.00,9.62" target="#b5">[6]</ref>. The blind feedback algorithm is based on the probabilistic term relevance weighting formula developed by Robertson and Sparck Jones <ref type="bibr" coords="3,358.97,563.87,9.87,9.62" target="#b8">[9]</ref>.</p><p>Blind relevance feedback is typically performed in two stages. First, an initial search using the original topic statement is performed, after which a number of terms are selected from some number of the top-ranked documents (which are presumed to be relevant). The selected terms are then weighted and then merged with the initial query to formulate a new query. Finally the reweighted and expanded query is submitted against the same collection to produce a final ranked list of documents. Obviously there are important choices to be made regarding the number of top-ranked documents to consider, and the number of terms to extract from those documents. For ImageCLEF this year, having no prior data to guide us, we chose to use the top 10 terms from 10 top-ranked documents. The terms were chosen by extracting the document vectors for each of the 10 and computing the Robertson and Sparck Jones term relevance weight for each document. This weight is based on a contingency table where the counts of 4 different conditions for combinations </p><formula xml:id="formula_3" coords="4,187.08,91.93,228.37,34.68">doc R t N t -R t N t Not in doc R -R t N -N t -R + R t N -N t R N -R N</formula><p>of (assumed) relevance and whether or not the term is, or is not in a document. Table <ref type="table" coords="4,478.93,160.43,4.98,9.62" target="#tab_1">1</ref> shows this contingency table.</p><p>The relevance weight is calculated using the assumption that the first 10 documents are relevant and all others are not. For each term in these documents the following weight is calculated:</p><formula xml:id="formula_4" coords="4,255.24,216.18,257.80,30.29">w t = log Rt R-Rt Nt-Rt N -Nt-R+Rt (4)</formula><p>The 10 terms (including those that appeared in the original query) with the highest w t are selected and added to the original query terms. For the terms not in the original query, the new "term frequency" (qtf i in main LR equation above) is set to 0.5. Terms that were in the original query, but are not in the top 10 terms are left with their original qtf i . For terms in the top 10 and in the original query the new qtf i is set to 1.5 times the original qtf i for the query. The new query is then processed using the same LR algorithm as shown in Equation <ref type="formula" coords="4,404.05,312.83,4.98,9.62">4</ref>and the ranked results returned as the response for that topic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Approaches for Adhoc-TEL</head><p>In this section we describe the specific approaches taken for our submitted runs for the Adhoc-TEL task. First we describe the indexing and term extraction methods used, and then the search features we used for the submitted runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Indexing and Term Extraction</head><p>The Cheshire II system uses the XML structure of the documents to extract selected portions for indexing and retrieval. Any combination of tags can be used to define the index contents. Table <ref type="table" coords="4,131.52,650.87,4.98,9.62" target="#tab_2">2</ref> lists the indexes created by the Cheshire II system for the Adhoc-TEL database and the document elements from which the contents of those indexes were extracted. The "Used" column in Table <ref type="table" coords="4,127.81,674.87,4.98,9.62" target="#tab_2">2</ref> indicates whether or not a particular index was used in the submitted Adhoc-TEL runs. As the table shows we used only the topic index, which contains most of the content-bearing parts of records, for all of our submitted runs. These tables and the indexes extracted are identical to last year's for Adhoc TEL.</p><p>For all indexing we used language-specific stoplists to exclude function words and very common words from the indexing and searching. The German language runs did not use decompounding in the indexing and querying processes to generate simple word forms from compounds. The Snowball stemmer was used by Cheshire for language-specific stemming.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Search Processing</head><p>Searching the Adhoc-TEL collection using the Cheshire II system involved using TCL scripts to parse the topics and submit the title and description from the topics. For monolingual search tasks we used the topics in the appropriate language (English, German, and French), for bilingual tasks the topics were translated from the source language to the target language using the LEC Power Translator PC-based machine translation system. For query expansion in the monolingual tasks we took two approaches. The first (denoted by an "X" at the end of names in Table <ref type="table" coords="6,278.42,440.75,4.46,9.62" target="#tab_3">3</ref>) used the topic in the specific language as a basis for machine translation to the other main languages (e.g. for English, the English topics were translated to French and German) and the translations were added to the topic. The second (denoted by "3" at the ends of the names in Table <ref type="table" coords="6,312.02,476.51,4.46,9.62" target="#tab_3">3</ref>) used the supplied monolingual topics in the other main languages (e.g., for English, the monolingual French and German topics were added to the English).</p><p>Query expansion in the bilingual tasks (denoted by "X" at the end of the names in Table <ref type="table" coords="6,504.13,512.39,4.46,9.62" target="#tab_3">3</ref>) added the source topics from the translation and an additional translation of the topics to the other main language (e.g., for English topics translated to German, the original English was added to the translated German and an English to French translation was also added). In effect, the expanded monolingual and bilingual topics were actually multilingual topic descriptions.</p><p>The scripts for each run submitted the topic elements as they appeared in the topic or expanded topic to the system for TREC2 logistic regression searching with blind feedback. Both the "title" and "description" topic elements were combined into a single probabilistic query and searched using the "topic" index as described in Table <ref type="table" coords="6,290.30,608.03,3.90,9.62" target="#tab_3">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results for Submitted Runs</head><p>The summary results (as Mean Average Precision) for the submitted bilingual and monolingual runs for English German and French are shown in Table <ref type="table" coords="6,342.29,674.75,3.90,9.62" target="#tab_3">3</ref>, the Recall-Precision curves for these runs are also shown in Figures <ref type="figure" coords="6,227.90,686.75,80.38,9.62" target="#fig_0">1 (for monolingual</ref>) and 2 (for bilingual). In Figures <ref type="figure" coords="6,462.27,686.75,4.98,9.62" target="#fig_0">1</ref> and<ref type="figure" coords="6,490.60,686.75,4.98,9.62" target="#fig_2">2</ref>   names for the individual runs represent the language codes, which can easily be compared with full names and descriptions in Table <ref type="table" coords="7,251.31,452.63,4.98,9.62" target="#tab_3">3</ref> (since each language combination has only a single run).</p><p>Table <ref type="table" coords="7,132.36,464.63,4.98,9.62" target="#tab_3">3</ref> indicates runs that had the highest overall MAP for the task by asterisks next to the run name.</p><p>The results in Table <ref type="table" coords="7,195.96,488.51,4.98,9.62" target="#tab_3">3</ref> show, for the most part, the type of query expansion that we tried was a dismal failure. The only exception was in bilingual German where the expanded English to German topic achieved a very slight performance edge over the unexpanded topic. Overall, we see no benefit to this kind of expansion in the results.</p><p>Once again we obtained particularly poor performance in monolingual German, due in part to our lack of support for decompounding (affecting many topics this year).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>Our overall results this year compared poorly with others, which was a bit of a surprise considering the how the same approach fared last year. We are starting to conduct some analyses to try to determine the causes of variation between last year and this. One very obvious change is that a new version of the MT software was used this time. Because this is a commercial product and new installations replace the old, we cannot do comparative testing directly, but we do have the translations produced last year for last year's topics, so we plan to do a comparison on that basis. One thing that we noticed with this year's topics was that translations from German often had compound terms included in the translation as hyphenated terms (e.g., "color-therapy" for "Farbentherapie"). To see what effect this might have had in some runs we translated the hyphens in such cases to spaces and reran some experiments. The results of this re-test showed that for the German to English bilingual task we were able to obtain a MAP of 0.2613 compared to 0.2238 in our official results.</p><p>Just as this paper was about to be submitted, it occurred to us that the data, unlike the German and other data we had used in other CLEF tracks, was in UTF-8 instead of ISO-8859-1 encoding. We realized that the version of the Snowball stemmer we had used for all of our submitted runs was based on the ISO encoding and not UTF. This could explain the low scores (particularly for French and German) since the stemming process was ineffective and identically inflected stems only were matched in retrieval.</p><p>Often it is the simplest things overlooked that lead to problems.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="6,90.00,69.11,423.19,9.62"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Berkeley Monolingual Runs -German (top left), English (top right) and French (lower)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,499.24,686.75,13.79,9.62"><head></head><label></label><figDesc>the</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,90.00,69.11,423.05,9.62;7,90.00,81.11,30.64,9.62"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Berkeley Bilingual Runs -To German (top left), To English (top right) and To French (lower)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,178.68,68.63,245.72,33.26"><head>Table 1 :</head><label>1</label><figDesc>Contingency table for term relevance weighting Relevant Not Relevant In</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,172.20,492.47,258.56,131.50"><head>Table 2 :</head><label>2</label><figDesc>Cheshire II Indexes for Adhoc-TEL 2006</figDesc><table coords="4,172.20,502.90,258.56,121.07"><row><cell>Name</cell><cell>Description</cell><cell>Content Tags</cell><cell>Used</cell></row><row><cell>recid</cell><cell>Document ID</cell><cell>id</cell><cell>no</cell></row><row><cell>names</cell><cell>Author Names</cell><cell>dc:creator, dc:contributor</cell><cell>no</cell></row><row><cell>title</cell><cell>Item Title</cell><cell>dc:title, dcterms:alternate</cell><cell>no</cell></row><row><cell>topic</cell><cell cols="2">Content Words dc:title, dcterms:alternate</cell><cell>yes</cell></row><row><cell></cell><cell></cell><cell>dc:subject, dc:description</cell><cell></cell></row><row><cell cols="2">anywhere Entire record</cell><cell>record</cell><cell>no</cell></row><row><cell>date</cell><cell>Date of Pub.</cell><cell>dcterms:issued</cell><cell>no</cell></row><row><cell>lang</cell><cell>Language</cell><cell>dc:language</cell><cell>no</cell></row><row><cell>subject</cell><cell>Subject terms</cell><cell>dc:subject</cell><cell>no</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,156.60,68.63,289.73,425.62"><head>Table 3 :</head><label>3</label><figDesc>Submitted Adhoc-TEL Runs</figDesc><table coords="5,156.60,79.06,289.73,415.19"><row><cell>Run Name</cell><cell>Description</cell><cell>Type</cell><cell>MAP</cell></row><row><cell>MODET2FB</cell><cell>Monolingual German</cell><cell cols="2">TD auto 0.1478 *</cell></row><row><cell>MODET2FBX</cell><cell>Monolingual German</cell><cell>TD auto</cell><cell>0.1230</cell></row><row><cell></cell><cell>+English and French Trans.</cell><cell></cell><cell></cell></row><row><cell>MODET2FB3</cell><cell>Monolingual German</cell><cell>TD auto</cell><cell>0.1331</cell></row><row><cell></cell><cell>+English and French Trans.</cell><cell></cell><cell></cell></row><row><cell>MOENT2FB</cell><cell>Monolingual English</cell><cell cols="2">TD auto 0.3267 *</cell></row><row><cell>MOENT2FBX</cell><cell>Monolingual English</cell><cell>TD auto</cell><cell>0.2224</cell></row><row><cell></cell><cell>+German and French Trans.</cell><cell></cell><cell></cell></row><row><cell>MOENT2FB3</cell><cell>Monolingual English</cell><cell>TD auto</cell><cell>0.2291</cell></row><row><cell></cell><cell>+German and French Trans.</cell><cell></cell><cell></cell></row><row><cell>MOFRT2FB</cell><cell>Monolingual French</cell><cell cols="2">TD auto 0.2070 *</cell></row><row><cell>MOFRT2FBX</cell><cell>Monolingual French</cell><cell>TD auto</cell><cell>0.1456</cell></row><row><cell></cell><cell>+German and English Trans.</cell><cell></cell><cell></cell></row><row><cell>MOFRT2FB3</cell><cell>Monolingual French</cell><cell>TD auto</cell><cell>0.1684</cell></row><row><cell></cell><cell>+German and English Trans.</cell><cell></cell><cell></cell></row><row><cell>BIENDET2FB</cell><cell>Bilingual English⇒German</cell><cell>TD auto</cell><cell>0.1031</cell></row><row><cell cols="2">BIENDET2FBX Bilingual English⇒German</cell><cell cols="2">TD auto 0.1150 *</cell></row><row><cell></cell><cell>+ French and English</cell><cell></cell><cell></cell></row><row><cell>BIFRDET2FB</cell><cell>Bilingual French⇒German</cell><cell>TD auto</cell><cell>0.0991</cell></row><row><cell cols="2">BIFRDET2FBX Bilingual French⇒German</cell><cell>TD auto</cell><cell>0.0882</cell></row><row><cell></cell><cell>+ French and English</cell><cell></cell><cell></cell></row><row><cell>BIDEENT2FB</cell><cell>Bilingual German⇒English</cell><cell>TD auto</cell><cell>0.2238</cell></row><row><cell cols="2">BIDEENT2FBX Bilingual German⇒English</cell><cell>TD auto</cell><cell>0.1598</cell></row><row><cell></cell><cell>+ German and French</cell><cell></cell><cell></cell></row><row><cell>BIFRENT2FB</cell><cell>Bilingual French⇒English</cell><cell cols="2">TD auto 0.2478 *</cell></row><row><cell cols="2">BIFRENT2FBX Bilingual French⇒English</cell><cell>TD auto</cell><cell>0.1666</cell></row><row><cell></cell><cell>+ French and German</cell><cell></cell><cell></cell></row><row><cell>BIDEFRT2FB</cell><cell>Bilingual German⇒French</cell><cell>TD auto</cell><cell>0.1652</cell></row><row><cell cols="2">BIDEFRT2FBX Bilingual German⇒French</cell><cell>TD auto</cell><cell>0.1131</cell></row><row><cell></cell><cell>+ German and English</cell><cell></cell><cell></cell></row><row><cell>BIENFRT2FB</cell><cell>Bilingual English⇒French</cell><cell cols="2">TD auto 0.1677 *</cell></row><row><cell cols="2">BIENFRT2FBX Bilingual English⇒French</cell><cell>TD auto</cell><cell>0.1365</cell></row><row><cell></cell><cell>+ English and German</cell><cell></cell><cell></cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,105.48,236.03,407.66,9.62;8,105.48,247.91,407.50,9.62;8,105.48,259.91,407.37,9.62;8,105.48,271.91,407.48,9.62;8,105.48,283.79,141.84,9.62" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,166.45,236.03,298.15,9.62">Multilingual information retrieval using english and chinese queries</title>
		<author>
			<persName coords=""><forename type="first">Aitao</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,421.32,247.91,91.66,9.62;8,105.48,259.91,407.37,9.62;8,105.48,271.91,83.18,9.62">Evaluation of Cross-Language Information Retrieval Systems: Second Workshop of the Cross-Language Evaluation Forum, CLEF-2001</title>
		<title level="s" coord="8,429.36,271.91,83.60,9.62;8,105.48,283.79,89.65,9.62">Springer Computer Scinece Series LNCS</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Martin</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Kluck</surname></persName>
		</editor>
		<meeting><address><addrLine>Darmstadt, Germany</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2001-09">September 2001. 2002</date>
			<biblScope unit="volume">2406</biblScope>
			<biblScope unit="page" from="44" to="58" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.48,303.71,407.60,9.62;8,105.48,315.71,94.81,9.62" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="8,166.92,303.71,213.64,9.62">Cross-Language Retrieval Experiments at CLEF</title>
		<author>
			<persName coords=""><forename type="first">Aitao</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002. 2003</date>
			<publisher>Springer</publisher>
			<biblScope unit="volume">2785</biblScope>
			<biblScope unit="page" from="28" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.49,335.63,407.67,9.62;8,105.48,347.63,350.66,9.62" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,248.79,335.63,264.37,9.62;8,105.48,347.63,169.07,9.62">Multilingual information retrieval using machine translation, relevance feedback and decompounding</title>
		<author>
			<persName coords=""><forename type="first">Aitao</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fredric</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,284.04,347.63,92.95,9.62">Information Retrieval</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="149" to="182" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.49,367.55,407.64,9.62;8,105.48,379.43,407.61,9.62;8,105.48,391.43,53.89,9.62" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,283.36,367.55,229.76,9.62;8,105.48,379.43,195.69,9.62">Full Text Retrieval based on Probabilistic Equations with Coefficients fitted by Logistic Regression</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">S</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,320.88,379.43,159.94,9.62">Text REtrieval Conference (TREC-2)</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.48,411.35,407.56,9.62;8,105.48,423.35,407.58,9.62;8,105.48,435.23,407.89,9.62;8,105.48,447.23,101.65,9.62" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,375.06,411.35,137.98,9.62;8,105.48,423.35,106.59,9.62">Probabilistic retrieval based on staged logistic regression</title>
		<author>
			<persName coords=""><forename type="first">William</forename><forename type="middle">S</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Fredric</forename><forename type="middle">C</forename><surname>Gey</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Daniel</forename><forename type="middle">P</forename><surname>Dabney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,232.92,423.35,280.14,9.62;8,105.48,435.23,180.46,9.62">15th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<meeting><address><addrLine>Copenhagen, Denmark; New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1992">June 21-24. 1992</date>
			<biblScope unit="page" from="198" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.48,467.15,407.70,9.62;8,105.48,479.15,407.77,9.62;8,105.48,491.03,22.93,9.62" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,173.65,467.15,335.66,9.62">Probabilistic retrieval, component fusion and blind feedback for XML retrieval</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Larson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,118.80,479.15,48.10,9.62">INEX 2005</title>
		<title level="s" coord="8,291.41,479.15,190.77,9.62">Lecture Notes in Computer Science, LNCS</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">3977</biblScope>
			<biblScope unit="page" from="225" to="239" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.48,510.95,407.32,9.62;8,105.48,522.95,407.35,9.62;8,105.48,534.95,407.49,9.62;8,105.48,546.83,22.93,9.62" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,176.65,510.95,254.84,9.62">Cheshire at geoclef 2007: Retesting text retrieval baselines</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Larson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,452.76,510.95,60.05,9.62;8,105.48,522.95,234.59,9.62">8th Workshop of the Cross-Language Evaluation Forum, CLEF 2007</title>
		<meeting><address><addrLine>Budapest, Hungary; Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09-21">September 19-21, 2007. September 2008</date>
			<biblScope unit="volume">5152</biblScope>
			<biblScope unit="page" from="811" to="814" />
		</imprint>
	</monogr>
	<note>Revised Selected Papers</note>
</biblStruct>

<biblStruct coords="8,105.48,566.75,407.57,9.62;8,105.48,578.75,407.59,9.62;8,105.48,590.63,407.77,9.62;8,105.48,602.63,230.55,9.62" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,178.33,566.75,334.72,9.62;8,105.48,578.75,136.54,9.62">Experiments in classification clustering and thesaurus expansion for domain specific cross-language retrieval</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Ray</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Larson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,264.60,578.75,248.47,9.62;8,105.48,590.63,48.21,9.62">8th Workshop of the Cross-Language Evaluation Forum, CLEF 2007</title>
		<meeting><address><addrLine>Budapest, Hungary; Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-09-21">September 19-21, 2007. September 2008</date>
			<biblScope unit="volume">5152</biblScope>
			<biblScope unit="page" from="188" to="195" />
		</imprint>
	</monogr>
	<note>Revised Selected Papers</note>
</biblStruct>

<biblStruct coords="8,105.48,622.55,407.54,9.62;8,105.48,634.55,328.46,9.62" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,281.32,622.55,158.14,9.62">Relevance weighting of search terms</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">Sparck</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,450.36,622.55,62.67,9.62;8,105.48,634.55,181.66,9.62">Journal of the American Society for Information Science</title>
		<imprint>
			<biblScope unit="page" from="129" to="146" />
			<date type="published" when="1976-06">May-June 1976</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
