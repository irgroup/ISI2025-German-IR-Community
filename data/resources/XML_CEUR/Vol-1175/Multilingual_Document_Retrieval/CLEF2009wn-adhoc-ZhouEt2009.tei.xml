<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,122.64,146.03,357.69,18.08;1,147.08,167.95,308.82,18.08">Language Modeling and Document Re-Ranking: Trinity Experiments at TEL@CLEF-2009</title>
				<funder>
					<orgName type="full">Centre for Next Generation Localisation</orgName>
				</funder>
				<funder ref="#_SANZNFS">
					<orgName type="full">Science Foundation Ireland</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,206.72,201.32,54.77,12.55"><forename type="first">Dong</forename><surname>Zhou</surname></persName>
							<email>dongzhou1979@hotmail.com</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Centre for Next Generation Localisation</orgName>
								<orgName type="institution" key="instit1">University of Dublin</orgName>
								<orgName type="institution" key="instit2">Trinity College</orgName>
								<address>
									<settlement>Dublin</settlement>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">School of Computer and Communication</orgName>
								<orgName type="institution">Hunan University</orgName>
								<address>
									<postCode>410082</postCode>
									<settlement>Changsha</settlement>
									<region>Hunan</region>
									<country key="CN">China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,324.26,201.32,67.05,12.55"><forename type="first">Vincent</forename><surname>Wade</surname></persName>
							<email>vincent.wade@cs.tcd.ie</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Centre for Next Generation Localisation</orgName>
								<orgName type="institution" key="instit1">University of Dublin</orgName>
								<orgName type="institution" key="instit2">Trinity College</orgName>
								<address>
									<settlement>Dublin</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,122.64,146.03,357.69,18.08;1,147.08,167.95,308.82,18.08">Language Modeling and Document Re-Ranking: Trinity Experiments at TEL@CLEF-2009</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">21929CEFD2916F216AD9EAFBA8A44F57</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing-Indexing methods</term>
					<term>Linguistic processing</term>
					<term>H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval-Search process Experimentation, Measurement Language Modeling, Smoothing, Document Re-Ranking, Latent Dirichlet Allocation, Cross-Language Information Retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents a report on our participation in the CLEF-2009 monolingual and bilingual ad hoc TEL@CLEF tasks involving three different languages: English, French and German. Language modeling is adopted as the underlying information retrieval model. While the data collection is extremely sparse, smoothing is particular important when estimating a language model. The main purpose of the monolingual task is to compare different smoothing strategies and investigate the effectiveness of each alternative. This retrieval model is then used alongside a document re-ranking method based on Latent Dirichlet Allocation (LDA) which exploits the implicit structure of the documents with respect to original queries for the monolingual and bilingual tasks. Experimental results demonstrated that three smoothing strategies behave differently across testing languages while LDA-based document re-ranking method should be considered further in order to bring significant improvement over the baseline language modeling systems in the cross-language setting.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This year's participation in the CLEF 2009 ad hoc monolingual and bilingual track was motivated by a desire to compare different smoothing strategies applied to language modeling for library data retrieval as well as test and extend a newly developed document re-ranking method.</p><p>Language modeling has been successfully applied to the problem of ad hoc retrieval <ref type="bibr" coords="1,435.01,705.25,10.79,10.46" target="#b3">[4,</ref><ref type="bibr" coords="1,447.73,705.25,7.47,10.46" target="#b4">5,</ref><ref type="bibr" coords="1,457.13,705.25,7.19,10.46" target="#b5">6]</ref>. It provides an attractive information model due to its theoretical foundations. The basic idea behind this approach is extremely simple -estimate a language model for each document and/or a query, and rank documents by the likelihood of the query (with respect to the document language model) or by the distance between the two models. The main object of smoothing is to adjust the maximum likelihood estimator of a language model so that it will be more accurate <ref type="bibr" coords="2,242.73,122.31,10.58,10.46" target="#b6">[7]</ref>.</p><p>However, previous success over news collection data does not necessarily mean it will be efficient over the library data. Firstly the data is actually multilingual: all collections to a greater or lesser extent contain records pointing to documents in other languages. However this is not a major problem because the majority of documents in the test collection are written in main languages of those test collections. Furthermore, documents written in different languages tend not to match the queries in main languages. The main characteristic of the data is that it is very different from the newspaper articles and news agency dispatches previously used in the CLEF. The data tends to be very sparse. Many records contain only title, author and subject heading information; other records provide more detail (see the experiment section on what fields are chosen to include). The average document lengths are 14.66 for BL and 24.19 for BNF collections after pre-processing, respectively.</p><p>Recently, there is a trend of exploring the hidden structure of documents to re-rank results <ref type="bibr" coords="2,477.41,253.81,10.79,10.46" target="#b1">[2,</ref><ref type="bibr" coords="2,491.47,253.81,7.47,10.46" target="#b2">3,</ref><ref type="bibr" coords="2,502.21,253.81,7.19,10.46" target="#b7">8]</ref>. We addressed in the previous work that there are two important factors that should be taken into account when designing any re-ranking algorithms: the original queries and initial retrieval scores. Based on this observation, we introduce a new document re-ranking method based on Latent Dirichlet Allocation (LDA) <ref type="bibr" coords="2,90.01,301.64,10.78,10.46" target="#b0">[1,</ref><ref type="bibr" coords="2,104.52,301.64,8.30,10.46" target="#b8">9]</ref> which exploits implicit structure of the documents with respect to original queries. Rather than relying on graph-based techniques as in <ref type="bibr" coords="2,248.05,313.59,10.79,10.46" target="#b4">[5,</ref><ref type="bibr" coords="2,261.02,313.59,8.30,10.46" target="#b5">6]</ref> to identify the internal structure, the approach tries to directly model the latent structure of "topics" or "concepts" in the initial retrieval set. Then we can compute the distance between queries and initial retrieval results based on latent semantic information inferred. Experiments in <ref type="bibr" coords="2,152.75,349.46,11.61,10.46" target="#b8">[9]</ref> demonstrated the effectiveness of the proposed method in monolingual retrieval. In this experiment, we try to extend the approach to cross-language information retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Language Modeling</head><p>Smoothing a data set typically means creating an approximating function that attempts to capture important patterns in the data, while leaving out noise or other fine-scale structures/rapid phenomena. In language modeling, the simplest reason to use smoothing is to not assign a zero probability to unseen words. The accuracy of smoothing is directly related to the retrieval performance.</p><p>Given a text sequence (either a query or a document), the probability distribution can be regarded as a probabilistic language model M d or M q from each document d or each query q. In other words, it assumes that there is an underlying language model which "generates" a term (sequence) <ref type="bibr" coords="2,444.86,509.71,10.58,10.46" target="#b0">[1]</ref>. The unigram language model is utilized here. There are several ways to estimate the probabilities. Let g(w ∈ d) denotes the number of times the term w occurs in a document d (same idea can be used on a query). The Maximumlikelihood estimation (MLE) of w with respect to d is defined as:</p><formula xml:id="formula_0" coords="2,251.33,566.00,261.67,25.67">MLE d w = g(w ∈ d) ∑ w g(w ∈ d) (1)</formula><p>We choose to use three representative methods that are widely used in previous research and relatively efficient to implement. The Jelinek-Mercer method, the Bayesian smoothing using Dirichlet priors, and the absolute discounting method. The description of the methods could be found in <ref type="bibr" coords="2,409.10,619.75,11.61,10.46" target="#b6">[7]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Document Re-Ranking</head><p>The intuition behind the document re-ranking method is the hidden structural information among the documents: similar documents are likely to have the same hidden information with respect to a query. In other words, if a group of documents are talking about the same topic which shares a strong similarity with a query, in our method they will get allocated similar ranking as they are more likely to be relevant to the query. In addition, the refined ranking scores should be relevant to the initial ranking scores, which, in the experiments conducted in this paper, are combined together with the re-ranking score either using a linear fashion. The distance between a query and a document in this method adopts the KL divergence between the query terms and document terms and through a linear combination of the re-ranking scores based on initial ranker and the latent document re-ranker.</p><p>This method could be found in great detail in <ref type="bibr" coords="3,293.51,361.04,10.58,10.46" target="#b8">[9]</ref>. We apply this method into the cross-language reranking by concatenating texts from different languages into several dual-language documents and a single dual-language query. An LDA analysis of these texts results in a multilingual semantic space in which terms from both languages are presented. Hence force the re-ranking process can be carried out by directly model the latent structure of multilingual "topics" or "concepts" in this enriched initial retrieval set. The similarity of "contexts" in which the terms appear is guaranteed to capture the inter-relationship between texts in different languages.</p><p>3 Experimental Setup</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview of the Experimental Process</head><p>All of the documents in the experiment were indexed using the Lemur toolkit <ref type="foot" coords="3,399.17,507.93,3.69,7.74" target="#foot_0">1</ref> . Prior to indexing, Porter's stemmer and a stopword list<ref type="foot" coords="3,207.46,519.88,3.69,7.74" target="#foot_1">2</ref> were used for the English documents. We use a French analyzer <ref type="foot" coords="3,486.22,519.88,3.69,7.74" target="#foot_2">3</ref> and a German analyzer to analyze French and German documents. The query sets consist of 50 topics, all of which were used in the experiment. Each topic is composed of several parts such as: Title, Description, Narrative. We chose to conduct Title+Description runs as queries. The queries are processed similarly to the treatment in the test collections. The chosen fields used in the indexing and searching are shown in the Table <ref type="table" coords="3,114.37,581.07,3.74,10.46">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Experimental Runs</head><p>In order to investigate the effectiveness of various techniques, we performed a retrieval experiment with several permutations. These experimental runs are denoted as follows:</p><p>For monolingual retrieval: LM-DIR: This part of the experiment involved retrieving documents from the test collection using language modeling with Bayesian smoothing method using Dirichlet prior.</p><p>LM-ABS: as above, except that the absolute discounting smoothing method was used. LM-JM: as above, except that the Jelinek-Mercer smoothing method was adopted. For bilingual retrieval: GOOGLETRANS: In this part of the experiment, documents were retrieved from the test collection using the Google Translator for translating the queries. (It is worth to note that due to the submission restrictions this is an unofficial measurement.) GOOGLETRANS-LDA: Here we retrieved documents from the document collection using query translations suggested by the Google Translator, then directly re-rank the retrieval results using the translated query with the proposed LDA based document re-ranking method.</p><p>GOOGLETRANS-SLDA: Here we retrieved documents from the document collection using query translations suggested by the Google Translator, then we conducted a multilingual corpus with documents written in both query and document languages. Re-ranking was performed by apply the LDA based method on this multilingual space (with the translated and the original query).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Monolingual Task</head><p>In this section we compare three smoothing methods across different languages in the library search (Table <ref type="table" coords="4,90.01,477.00,3.60,10.46" target="#tab_1">2</ref>). As we conducted queries using the title and description fields, they could be considered as long informative queries. Previous research on news and web data suggested that on average, Jelinek-Mercer is better than Dirichlet and absolute discounting in metrics like non-interpolated average precision, precision at 10 and 20 documents while both Jelinek-Mercer and Dirichlet clearly have a better average precision than absolute discounting. The German monolingual runs demonstrated the same observation where Jelnek-Mercer is better than Dirichlet, which is subsequently better than absolute discounting.</p><p>English and French runs showed a different behaviour. Absolute discounting is a clear winner of three smoothing methods while Jelinek-Mercer still perform better than Dirichlet. If explained by the two different roles in the query likelihood retrieval method <ref type="bibr" coords="4,311.69,572.64,10.58,10.46" target="#b6">[7]</ref>, Dirichlet method performs better as it is good for the estimation role (as for shorter queries). So that it consistently demonstrate the worst performance across all the languages. However, Jelinek-Mercer performs best for longer queries and should be good for the role of query modeling. This is the case for the German runs while not for English and French runs where absolute discounting substitute the Jelinek-Mercer's role in the modeling process. The results suggest that smoothing methods tend to be sensitive for distinct languages and different test collections.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Bilingual Task</head><p>We now turn to the bilingual tasks to study the LDA-based re-ranking method. The main experimental results are presented in Table <ref type="table" coords="4,210.10,691.57,3.74,10.46" target="#tab_2">3</ref>, for all three languages. The first question we are interested in is how the re-ranking method performs directly over the bilingual retrieval results (taken as a whole). It is shown that our methods bring improvements upon the Google translator baselines in all of the 6 relevant comparisons. Another observation is that in many cases, the method can outperform the baselines for all the evaluation metrics. With respect to the bilingual re-ranking, the method showed some improvements over the Googe translator and direct re-ranking methods in the X2EN and X2DE runs in terms of mean average precision. The performance is somewhat disappoint in the X2FR runs. Furthermore, although there are some improvements, the difference are not large enough in terms of MAP. However, regarding to the precision at 5 documents the method could demonstrate higher performance than simple re-ranking. This shows that the method is a promising direction but need further investigation.</p><p>It is worth mentioning that the combination of methods used in this experiment could achieve very good overall performance as nearly all of our selected monolingual and bilingual runs are among top five participants in CLEF 2009 (except in the French monolingual task) such as: TCDENRUN2 absolute discounting, English monolingual TCDDERUN1 Dirichlet prior, German monolingual TCDDEENRUN3 Google translator with SLDA, German-English bilingual TCDDEFRRUN2 Google translator with LDA, German-French bilingual TCDENDERUN3 Google translator with SLDA, English-German bilingual</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper we have described our contribution to the CLEF 2009 ad hoc monolingual and bilingual tracks. Our monolingual experiment involved the comparison of three different smoothing strategies applied to language modeling approach for library data retrieval. We also made a first attempt to extend the previously proposed document re-ranking method to cross-language information retrieval. Experimental results demonstrated that smoothing methods tend to behave differently in the library search and across testing languages. They also showed that LDA-based document re-ranking method should be considered further in order to bring significant improvement over the baseline language modeling systems in the crosslanguage setting.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,95.98,117.15,411.15,126.61"><head>Table 2 :</head><label>2</label><figDesc>Retrieval results for monolingual task</figDesc><table coords="4,95.98,135.19,411.15,108.56"><row><cell>Run ID</cell><cell cols="3">source target description</cell><cell>MAP</cell><cell>bpref</cell><cell>P@5</cell><cell>P@10</cell></row><row><cell cols="2">TCDENRUN1 EN</cell><cell>EN</cell><cell>LM-DIR</cell><cell cols="2">0.2905 0.3001</cell><cell>0.4560</cell><cell>0.4140</cell></row><row><cell cols="2">TCDENRUN2 EN</cell><cell>EN</cell><cell>LM-ABS</cell><cell cols="2">0.4035 0.4054</cell><cell>0.6160</cell><cell>0.5640</cell></row><row><cell cols="2">TCDENRUN3 EN</cell><cell>EN</cell><cell>LM-JM</cell><cell cols="2">0.3696 0.3658</cell><cell>0.5680</cell><cell>0.5060</cell></row><row><cell>TCDFRRUN1</cell><cell>FR</cell><cell>FR</cell><cell>LM-DIR</cell><cell cols="2">0.1451 0.1570</cell><cell>0.2000</cell><cell>0.1740</cell></row><row><cell>TCDFRRUN2</cell><cell>FR</cell><cell>FR</cell><cell>LM-ABS</cell><cell cols="2">0.1745 0.1767</cell><cell>0.2320</cell><cell>0.2380</cell></row><row><cell>TCDFRRUN3</cell><cell>FR</cell><cell>FR</cell><cell>LM-JM</cell><cell cols="2">0.1723 0.1765</cell><cell>0.2520</cell><cell>0.2280</cell></row><row><cell cols="2">TCDDERUN1 DE</cell><cell>DE</cell><cell>LM-DIR</cell><cell cols="2">0.2577 0.2615</cell><cell>0.4480</cell><cell>0.3760</cell></row><row><cell cols="2">TCDDERUN2 DE</cell><cell>DE</cell><cell>LM-ABS</cell><cell cols="2">0.2397 0.2397</cell><cell>0.4280</cell><cell>0.3540</cell></row><row><cell cols="2">TCDDERUN3 DE</cell><cell>DE</cell><cell>LM-JM</cell><cell cols="2">0.2686 0.2653</cell><cell>0.4520</cell><cell>0.3840</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,95.98,117.15,411.15,211.79"><head>Table 3 :</head><label>3</label><figDesc>Retrieval results for bilingual task</figDesc><table coords="5,95.98,135.19,411.15,193.74"><row><cell>Run ID</cell><cell cols="3">source target description</cell><cell>MAP</cell><cell>bpref</cell><cell>P@5</cell><cell>P@10</cell></row><row><cell>TCDFRENRUN1</cell><cell>FR</cell><cell>EN</cell><cell>GOOGLETRANS</cell><cell cols="2">0.3481 0.3526</cell><cell>0.5760</cell><cell>0.5220</cell></row><row><cell>TCDFRENRUN2</cell><cell>FR</cell><cell>EN</cell><cell>GOOGLETRANS-LDA</cell><cell cols="2">0.3488 0.3527</cell><cell>0.5720</cell><cell>0.5220</cell></row><row><cell>TCDFRENRUN3</cell><cell>FR</cell><cell>EN</cell><cell>GOOGLETRANS-SLDA</cell><cell cols="2">0.3500 0.3535</cell><cell>0.5760</cell><cell>0.5140</cell></row><row><cell cols="2">TCDDEENRUN1 DE</cell><cell>EN</cell><cell>GOOGLETRANS</cell><cell cols="2">0.3411 0.3500</cell><cell>0.5700</cell><cell>0.5040</cell></row><row><cell cols="2">TCDDEENRUN2 DE</cell><cell>EN</cell><cell>GOOGLETRANS-LDA</cell><cell cols="2">0.3500 0.3596</cell><cell>0.5760</cell><cell>0.5040</cell></row><row><cell cols="2">TCDDEENRUN3 DE</cell><cell>EN</cell><cell>GOOGLETRANS-SLDA</cell><cell cols="2">0.3505 0.3602</cell><cell>0.5880</cell><cell>0.5040</cell></row><row><cell>TCDENFRRUN1</cell><cell>EN</cell><cell>FR</cell><cell>GOOGLETRANS</cell><cell cols="2">0.1579 0.1572</cell><cell>0.2520</cell><cell>0.2320</cell></row><row><cell>TCDENFRRUN2</cell><cell>EN</cell><cell>FR</cell><cell>GOOGLETRANS-LDA</cell><cell cols="2">0.1591 0.1573</cell><cell>0.2520</cell><cell>0.2340</cell></row><row><cell>TCDENFRRUN3</cell><cell>EN</cell><cell>FR</cell><cell>GOOGLETRANS-SLDA</cell><cell cols="2">0.1576 0.1561</cell><cell>0.2560</cell><cell>0.2320</cell></row><row><cell>TCDDEFRRUN1</cell><cell>DE</cell><cell>FR</cell><cell>GOOGLETRANS</cell><cell cols="2">0.1618 0.1743</cell><cell>0.2680</cell><cell>0.2300</cell></row><row><cell>TCDDEFRRUN2</cell><cell>DE</cell><cell>FR</cell><cell>GOOGLETRANS-LDA</cell><cell cols="2">0.1633 0.1752</cell><cell>0.2600</cell><cell>0.2300</cell></row><row><cell>TCDDEFRRUN3</cell><cell>DE</cell><cell>FR</cell><cell>GOOGLETRANS-SLDA</cell><cell cols="2">0.1624 0.1739</cell><cell>0.2600</cell><cell>0.2260</cell></row><row><cell cols="2">TCDENDERUN1 EN</cell><cell>DE</cell><cell>GOOGLETRANS</cell><cell cols="2">0.1901 0.1923</cell><cell>0.3480</cell><cell>0.2900</cell></row><row><cell cols="2">TCDENDERUN2 EN</cell><cell>DE</cell><cell>GOOGLETRANS-LDA</cell><cell cols="2">0.1910 0.1922</cell><cell>0.3480</cell><cell>0.2920</cell></row><row><cell cols="2">TCDENDERUN3 EN</cell><cell>DE</cell><cell>GOOGLETRANS-SLDA</cell><cell cols="2">0.1935 0.1944</cell><cell>0.3480</cell><cell>0.2920</cell></row><row><cell>TCDFRDERUN1</cell><cell>FR</cell><cell>DE</cell><cell>GOOGLETRANS</cell><cell cols="2">0.1826 0.2053</cell><cell>0.3480</cell><cell>0.2700</cell></row><row><cell>TCDFRDERUN2</cell><cell>FR</cell><cell>DE</cell><cell>GOOGLETRANS-LDA</cell><cell cols="2">0.1840 0.2063</cell><cell>0.3520</cell><cell>0.2780</cell></row><row><cell>TCDFRDERUN3</cell><cell>FR</cell><cell>DE</cell><cell>GOOGLETRANS-SLDA</cell><cell cols="2">0.1839 0.2050</cell><cell>0.3560</cell><cell>0.2760</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,104.35,719.79,91.01,8.37"><p>http://www.lemurproject.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,104.35,729.59,106.96,8.37"><p>ftp://ftp.cs.cornell.edu/pub/smart/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,104.35,739.40,78.68,8.37"><p>http://lucene.apache.org/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6">Acknowledgments</head><p>This research is supported by the <rs type="funder">Science Foundation Ireland</rs> (Grant <rs type="grantNumber">07/CE/I1142</rs>) as part of the <rs type="funder">Centre for Next Generation Localisation</rs> (www.cngl.ie) at <rs type="institution">University of Dublin, Trinity College</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_SANZNFS">
					<idno type="grant-number">07/CE/I1142</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,106.59,132.62,406.41,10.46;6,106.60,144.57,110.96,10.46" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,321.09,132.62,101.09,10.46">Latent dirichlet allocation</title>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
		<idno>. 944937</idno>
	</analytic>
	<monogr>
		<title level="j" coord="6,428.99,132.62,80.14,10.46">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,106.59,164.50,406.41,10.46;6,106.60,176.46,406.41,10.46;6,106.60,188.42,406.41,10.46;6,106.60,200.37,37.36,10.46" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,231.06,164.50,281.95,10.46;6,106.60,176.46,80.57,10.46">Pagerank without hyperlinks: structural re-ranking using links induced by language models</title>
		<author>
			<persName coords=""><forename type="first">Oren</forename><surname>Kurland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<idno>. 1076087</idno>
	</analytic>
	<monogr>
		<title level="m" coord="6,212.05,176.46,300.96,10.46;6,106.60,188.42,207.81,10.46">Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 28th annual international ACM SIGIR conference on Research and development in information retrieval<address><addrLine>Salvador, Brazil</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="306" to="313" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,106.59,220.30,406.42,10.46;6,106.60,232.25,406.40,10.46;6,106.60,244.20,406.42,10.46;6,106.60,256.16,37.36,10.46" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,231.20,220.30,281.82,10.46;6,106.60,232.25,66.44,10.46">Respect my authority!: Hits without hyperlinks, utilizing cluster-based language models</title>
		<author>
			<persName coords=""><forename type="first">Oren</forename><surname>Kurland</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lillian</forename><surname>Lee</surname></persName>
		</author>
		<idno>. 1148188</idno>
	</analytic>
	<monogr>
		<title level="m" coord="6,196.83,232.25,316.17,10.46;6,106.60,244.20,188.91,10.46">Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 29th annual international ACM SIGIR conference on Research and development in information retrieval<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="83" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,106.59,276.08,406.41,10.46;6,106.60,288.04,406.40,10.46;6,106.60,300.00,352.73,10.46" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,251.50,276.08,222.89,10.46">A language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Jay</forename><forename type="middle">M</forename><surname>Ponte</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,495.19,276.08,17.81,10.46;6,106.60,288.04,406.40,10.46;6,106.60,300.00,82.20,10.46">Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 21st annual international ACM SIGIR conference on Research and development in information retrieval<address><addrLine>Melbourne, Australia</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="1998">1998. 291008</date>
			<biblScope unit="page" from="275" to="281" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,106.59,319.92,406.41,10.46;6,106.60,331.88,406.40,10.46;6,106.60,343.83,303.78,10.46" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,236.41,319.92,195.71,10.46">Lda-based document models for ad-hoc retrieval</title>
		<author>
			<persName coords=""><forename type="first">Xing</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Croft</surname></persName>
		</author>
		<idno>. 1148204</idno>
	</analytic>
	<monogr>
		<title level="m" coord="6,452.75,319.92,60.25,10.46;6,106.60,331.88,406.40,10.46;6,106.60,343.83,32.65,10.46">Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 29th annual international ACM SIGIR conference on Research and development in information retrieval<address><addrLine>Seattle, Washington, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="178" to="185" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,106.59,363.76,406.41,10.46;6,106.60,375.71,406.41,10.46;6,106.60,387.66,302.48,10.46" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,255.06,363.76,257.95,10.46;6,106.60,375.71,72.92,10.46">Model-based feedback in the language modeling approach to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<idno>. 502654</idno>
	</analytic>
	<monogr>
		<title level="m" coord="6,195.74,375.71,317.27,10.46;6,106.60,387.66,48.36,10.46">Proceedings of the tenth international conference on Information and knowledge management</title>
		<meeting>the tenth international conference on Information and knowledge management<address><addrLine>Atlanta, Georgia, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="403" to="410" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,106.59,407.59,406.41,10.46;6,106.60,419.55,301.06,10.46" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,258.54,407.59,254.47,10.46;6,106.60,419.55,81.20,10.46">A study of smoothing methods for language models applied to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<idno>. 984322</idno>
	</analytic>
	<monogr>
		<title level="j" coord="6,194.90,419.55,84.19,10.46">ACM Trans. Inf. Syst</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="179" to="214" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,106.59,439.48,406.41,10.46;6,106.60,451.43,406.41,10.46;6,106.60,463.38,406.41,10.46;6,106.60,475.34,119.96,10.46" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,498.62,439.48,14.39,10.46;6,106.60,451.43,185.13,10.46">Improving web search results using affinity graph</title>
		<author>
			<persName coords=""><forename type="first">Benyu</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hua</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Yi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Lei</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wensi</forename><surname>Xi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Weiguo</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zheng</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wei-Ying</forename><surname>Ma</surname></persName>
		</author>
		<idno>. 1076120</idno>
	</analytic>
	<monogr>
		<title level="m" coord="6,310.44,451.43,202.57,10.46;6,106.60,463.38,294.74,10.46">Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 28th annual international ACM SIGIR conference on Research and development in information retrieval<address><addrLine>Salvador, Brazil</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="504" to="511" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,106.59,495.26,406.41,10.46;6,106.60,507.22,406.41,10.46;6,106.60,519.18,197.03,10.46" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,236.31,495.26,110.47,10.46">Latent document re-ranking</title>
		<author>
			<persName coords=""><forename type="first">Dong</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Vincent</forename><surname>Wade</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,366.75,495.26,146.25,10.46;6,106.60,507.22,282.80,10.46">Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing</title>
		<meeting>the 2009 Conference on Empirical Methods in Natural Language Processing<address><addrLine>Singapore</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="1571" to="1580" />
		</imprint>
	</monogr>
	<note>EMNLP 2009)</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
