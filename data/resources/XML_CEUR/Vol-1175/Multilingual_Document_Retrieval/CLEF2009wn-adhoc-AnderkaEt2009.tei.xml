<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,108.60,148.73,386.13,15.51;1,90.00,170.69,423.18,15.51">Evaluating Cross-Language Explicit Semantic Analysis and Cross Querying at TEL@CLEF 2009</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,185.40,203.00,72.71,10.86"><forename type="first">Maik</forename><surname>Anderka</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Media</orgName>
								<orgName type="institution">Media Systems Bauhaus University Weimar</orgName>
								<address>
									<postCode>99421</postCode>
									<settlement>Weimar</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,273.85,203.00,65.86,10.86"><forename type="first">Nedim</forename><surname>Lipka</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Media</orgName>
								<orgName type="institution">Media Systems Bauhaus University Weimar</orgName>
								<address>
									<postCode>99421</postCode>
									<settlement>Weimar</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,355.34,203.00,62.18,10.86"><forename type="first">Benno</forename><surname>Stein</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Media</orgName>
								<orgName type="institution">Media Systems Bauhaus University Weimar</orgName>
								<address>
									<postCode>99421</postCode>
									<settlement>Weimar</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,108.60,148.73,386.13,15.51;1,90.00,170.69,423.18,15.51">Evaluating Cross-Language Explicit Semantic Analysis and Cross Querying at TEL@CLEF 2009</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6D95D0E704FA8218EDDADC484CE00308</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries Measurement, Performance, Experimentation Cross-Language Information Retrieval, Cross-Language Explicit Semantic Analysis, Wikipedia, Cross Querying</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our participation in the TEL@CLEF task of the CLEF 2009 adhoc track. The task is to retrieve items from various multilingual collections of library catalog records, which are relevant to a user's query. Two different strategies are employed: (i) the Cross-Language Explicit Semantic Analysis, CL-ESA, where the library catalog records and the queries are represented in a multilingual concept space that is spanned by aligned Wikipedia articles, and, (ii) a Cross Querying approach, where a query is translated into all target languages using Google Translate and where the obtained rankings are combined. The evaluation shows that both strategies outperform the monolingual baseline and achieve comparable results.</p><p>Furthermore, inspired by the Generalized Vector Space Model we present a formal definition and an alternative interpretation of the CL-ESA model. This interpretation is interesting for real-world retrieval applications since it reveals how the computational effort for CL-ESA can be shifted from the query phase to a preprocessing phase.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Cross-language information retrieval, CLIR, is the task of retrieving documents from a target collection written in a language different from the language of a user's query. CLIR systems give multilingual users the possibility to express queries in any language, e.g., their native language, and to obtain result documents in all languages they are familiar with. Since CLIR is not restricted to collections in the query language more sources can be included in the retrieval process, and the chance to fulfill a particular information need of a multilingual user is higher. Another use case for CLIR techniques is cross-language plagiarism detection, where the query corresponds to a suspicious document and the target collection is a reference corpus with original documents <ref type="bibr" coords="2,499.69,123.43,10.00,9.96" target="#b2">[3]</ref>.</p><p>The Cross-Language Evaluation Forum, CLEF, provides an infrastructure for the evaluation of information retrieval systems, both monolingual and cross-lingual. We participated in the TEL@CLEF task of the CLEF 2009 ad-hoc track, which aims at the evaluation of systems to retrieve relevant items from multilingual collections of library catalog records. The main challenges of this task are the multilinguality and the sparsity of the dataset. We used two different CLIR approaches to tackle this task; the paper in hand outlines and discusses these approaches and the achieved results.</p><p>The first approach is Cross-Language Explicit Semantic Analysis, CL-ESA, which is a multilingual retrieval model to access cross-language similarity between text documents <ref type="bibr" coords="2,438.59,230.95,10.00,9.96" target="#b2">[3]</ref>. The CL-ESA model exploits a document-aligned comparable corpus such as Wikipedia in order to map the query and the documents into a common multilingual concept space <ref type="bibr" coords="2,400.80,254.95,10.45,9.96" target="#b2">[3,</ref><ref type="bibr" coords="2,415.56,254.95,6.97,9.96" target="#b3">4]</ref>. We also present a formal definition and an alternative interpretation for the CL-ESA model, which is inspired by the Generalized Vector Space Model, GVSM. Our view is mathematically equivalent to the original idea of the CL-ESA model; it reveals how the computational effort for CL-ESA can be shifted from the query phase to a preprocessing phase.</p><p>In the second approach, called Cross Querying, each query is translated into all target languages. The particular rankings are used in a combined fashion considering the most likely language of the documents. The evaluation on the TEL@CLEF collections shows that both CLIR approaches are able to outperform the monolingual baseline. In the bilingual subtask, querying with a foreign language, Cross Querying achieves nearly the same or even higher results compared to the monolingual subtask; the performance of the CL-ESA is lower compared to the monolingual results.</p><p>The paper is organized as follows. Section 2 describes the target collection used in the TEL@CLEF task along with the evaluation procedure. Section 3 defines the general CL-ESA model, our formalization, and details of the CL-ESA implementation employed in the experiments. Section 4 presents the Cross Querying approach, Section 5 discusses the evaluation, and Section 6 concludes with an outlook.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">TEL@CLEF dataset and Evaluation Procedure</head><p>In this year's TEL@CLEF task three target collections, provided by The European Library<ref type="foot" coords="2,505.92,499.35,3.97,6.97" target="#foot_0">1</ref> , TEL, are used. The collections are labeled BL, ONB, and BNF, and mainly contain information in English, German, and French respectively (see Table <ref type="table" coords="2,328.47,524.71,3.88,9.96" target="#tab_0">1</ref>). The collections are comprised of library catalog records, referring to different types of items such as articles, books, or videos. The data is provided in structured form and represented in XML. Each library catalog record has several fields containing meta information and content information that describe the particular item. Typical meta information fields are author, rights, or publisher, and typical content information fields are title, description, subject, or alternative. In our experiments we focus on the content information fields. A major difficulty is the sparsity of the available information: for many records only few fields are given.</p><p>The user's information need is specified by 50 topics that are provided by CLEF in the three main languages of the target collections, namely English, German, and French. A topic consists of two fields: a title, containing 2-4 keywords, and a description, containing 1-2 sentences that specify the item of interest in greater detail. The topics are used to construct the queries.</p><p>The TEL@CLEF task is divided into a monolingual and a bilingual subtask. The aim in both subtasks is to retrieve documents (library catalog records) from the target collections, which are most relevant to a query; for each query the results are submitted as a ranked list of documents. In the monolingual subtask the language of the query and the main language of the collection are the same, while in the bilingual subtask the language of the query is different from the main language of the collection. We submitted runs for both subtasks and for all three languages.  <ref type="bibr" coords="3,154.21,326.83,10.00,9.96" target="#b1">[2]</ref>, and was proposed by Potthast et al. <ref type="bibr" coords="3,325.01,326.83,9.91,9.96" target="#b2">[3]</ref>. This section presents a formal definition of the CL-ESA model that reveals its close connection to the Generalized Vector Space Model, GVSM <ref type="bibr" coords="3,124.21,350.71,10.00,9.96" target="#b4">[5]</ref>: the ESA model and the GVSM can be transformed into each other <ref type="bibr" coords="3,451.32,350.71,9.91,9.96" target="#b0">[1]</ref>. It follows immediately that this is also true for the CL-ESA model and the cross-lingual extension of the Generalized Vector Space Model, CL-GVSM <ref type="bibr" coords="3,287.41,374.71,9.91,9.96" target="#b5">[6]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Formal Definition</head><p>Let d i be a real-world document written in language L i , and let d i be a bag-of-word-based representation of d i , encoded as a vector of normalized term frequency weights over a universal term vocabulary V i . V i contains all used terms for language L i . A set D i of document representations defines a term-document matrix A Di , where each column in A Di corresponds to a vector d i ∈ D i .</p><p>Definition 1 (ESA Representation <ref type="bibr" coords="3,263.40,480.67,12.51,9.96" target="#b0">[1]</ref>) Let D * i be a collection of index documents written in language L i . The ESA representation d iESA of a document d i with representation d i is defined as follows:</p><formula xml:id="formula_0" coords="3,261.72,514.97,251.32,15.11">d iESA = A T D * i • d i ,<label>(1)</label></formula><p>where A T designates the matrix transpose of A.</p><p>The rationale of this definition becomes clear if one considers that the weight vectors i ∈ D * is a list of index documents written in language L i ∈ L. D * is a document-aligned comparable corpus, i.e., for each language L i ∈ L the n-th index document in D * i ∈ D * describes the same concept. The CL-ESA similarity, ϕ CL-ESA (q j , d i ), between a query q j in language L j and a document d i in language L i is computed as cosine similarity ϕ of the ESA representations of q j and d i : </p><formula xml:id="formula_1" coords="3,90.00,555.98,422.52,24.31">d * i ∈ D * i and d i are normalized: ||d * i || = ||d i || = 1, for each d * i ∈ D * i .</formula><formula xml:id="formula_2" coords="3,170.64,708.65,342.40,15.11">ϕ CL-ESA (q j , d i ) = ϕ(q j ESA , d iESA ) = ϕ(A T D * j • q j , A T D * i • d i ) (2)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Original interpretation Alternative interpretation</head><formula xml:id="formula_3" coords="4,122.40,148.44,355.37,46.20">View (i) View (ii) ϕ CL-ESA (q j , d i ) = ϕ(A T D * j • q j , A T D * i • d i ) (q T j • G j,i ) • d i q T j • (G j,i • d i ) Runtime complexity O(l • |D * | + |D * |) O(l • |V j | + l) O(l)</formula><p>Due to the alignment of the index collections D * j and D * i the ESA representations of q j and d i are comparable. Definition 2 is equivalent to the definition of the CL-GSVM similarity ϕ CL-GVSM (q j , d i ) given in <ref type="bibr" coords="4,226.81,245.59,10.00,9.96" target="#b5">[6]</ref>, which means that, in analogy to <ref type="bibr" coords="4,391.48,245.59,10.00,9.96" target="#b0">[1]</ref>, the CL-ESA model and the CL-GVSM can be directly transformed into each other:</p><formula xml:id="formula_4" coords="4,168.60,277.85,344.44,14.99">ϕ CL-ESA (q j , d i ) = ϕ(A T D * j • q j , A T D * i • d i ) = ϕ CL-GVSM (q j , d i ) (3)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Alternative Interpretation</head><p>The original idea of the CL-ESA model is to map both query and documents into a multilingual concept space, as it is expressed in Equation <ref type="formula" coords="4,282.73,338.95,3.90,9.96">2</ref>. Note that Equation 2 can be rearranged as follows:</p><formula xml:id="formula_5" coords="4,167.28,361.25,345.76,15.11">ϕ CL-ESA (q j , d i ) = ϕ(A T D * j • q j , A T D * i • d i ) = q T j • A D * j • A T D * i • d i<label>(4)</label></formula><p>In particular, the matrix</p><formula xml:id="formula_6" coords="4,214.44,383.09,73.02,14.87">A D * j • A T D * i = G j,i</formula><p>can be computed in advance since it is independent from a particular q j or d i . Hence:</p><formula xml:id="formula_7" coords="4,233.40,419.57,279.64,13.00">ϕ CL-ESA (q j , d i ) = q T j • G j,i • d i<label>(5)</label></formula><p>The rationale of Equation 5 becomes apparent if one recognizes</p><formula xml:id="formula_8" coords="4,90.00,439.25,423.01,24.26">G j,i = A D * j • A T D * i as |V j | × |V i | term co-occurrence matrix.</formula><p>The n-th row in A D * j corresponds to the distribution of the n-th term t n ∈ V j over the index documents in D * j ; likewise, the m-th row in A D * i corresponds to the distribution of the m-th term t m ∈ V i over the index documents in D * i . Recall that the index documents in D * j and D * i are aligned. I.e., the value in the n-th row and the m-th column of G j,i quantifies the similarity between the distributions of t j and t i given the concepts described by the index documents in D * j and D * i . The CL-ESA similarity computation of Equation 5 can be viewed in two ways:</p><p>(i) As a translation of the query representation q j into the space of the document representation d i : ϕ CL-ESA (q j , d i ) = (q T j • G j,i ) • d i , or, (ii) as a translation of the document representation d i into the space of the query representation q j : ϕ CL-ESA (q j , d i ) = q T j • (G j,i • d i ). These views are different from the original idea of the CL-ESA model where both the query representation and the document representation are mapped into a common multilingual concept space (see Equation <ref type="formula" coords="4,179.76,631.63,3.88,9.96">2</ref>). From a mathematical standpoint Equation 2 and Equation 5 are equivalent; however, implementing CL-ESA based on the alternative interpretation yields a considerable runtime improvement in practical retrieval applications. Table <ref type="table" coords="4,363.12,655.51,4.98,9.96" target="#tab_1">2</ref> contrasts the interpretations and the related runtime complexities. Here, we assume a closed retrieval situation where from a given target collection D i in language L i the most similar documents to a query q j in language L j are desired. CLIR with CL-ESA is straightforward: computation of ϕ CL-ESA (q j , d i ) for each d i ∈ D i and ranking by decreasing CL-ESA similarity.</p><p>Under the original interpretation the ESA representations d iESA of the documents d i ∈ D i can be computed in advance. At retrieval time the query is mapped into the concept space in O(l • |D * |), where l denotes the number of query terms. The computation of the cosine similarity between the ESA representations q j ESA and d iESA requires O(|D * |). Under the alternative interpretation the matrix G j,i can be computed in advance. Note that in practical applications l ≪ |D * |, since a reasonable index collection size |D * | is 10 000, which shows the substantial performance improvement under the alternative interpretation and View (ii) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Usage in TEL@CLEF</head><p>In this subsection we describe implementation details of the CL-ESA model we used in our submission. The best parameter setting was determined by analyzing unofficial experiments of the TEL@CLEF 2008 dataset.</p><p>Query and Document Construction. We use the original words of both topic fields, title and description, as queries. The documents are constructed by merging the text of the three record fields title, subject, and alternative. We assume that the language of these fields is the same within one record; however, this assumption may be violated in some cases since the collections contain multilingual records. Records without these fields are omitted in the experiments (see Table <ref type="table" coords="5,117.36,292.03,3.88,9.96" target="#tab_0">1</ref>). Index Collection. As index collection Wikipedia is employed. We restrict the multilinguality of our model to the three main languages of the target collections: English, German, and French. Based on a Wikipedia snapshot from March 2009 about 169 000 articles per language can be aligned and fulfill several filter criteria, e.g., to contain more than 100 words or not to be a disambiguation or redirection page. All articles are used as index documents.</p><p>As term weighting schema tf • idf is used. Query and document words are stemmed using the Snowball stemmers. To speed-up the CL-ESA similarity computation all values below a threshold of ǫ = 0.025 are discarded.</p><p>Language Detection. While the language of the queries is determined by the corresponding topics the language of the documents is unknown since the collections are multilingual and no language meta information is provided. In the experiments we resort to a simple "detection by stop words" approach for the three main languages; if the detection fails the main language of the collection is assumed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Cross Querying</head><p>Cross querying is a straightforward approach for CLIR systems. We subsume the fields of a topic in one query which is translated in the other languages. With each of the translations we compute a set of rankings by retrieving against each document field. The rankings are merged with respect to their cosine similarities. Additionally, the scores are multiplied by a boosting constant. Definition 3 (Cross Querying) Let L = {L 1 , . . . , L k } denote a set of natural languages and let F = {F 1 , . . . , F k } denote a set of document fields. lang : D → L, lang(d) → L i estimates the language of a document d. d, q, and q Li are the representations of a document d, a query q and the translation of q in language L i . Then the cross querying similarity, ϕ CQ (q, d), of a query q and a document d is defined as follows:</p><formula xml:id="formula_9" coords="5,167.64,637.75,341.14,27.09">ϕ CQ (q, d) = Fi∈F b • ϕ(q lang(d) , d Fi ) + L i ∈L, L i =lang(d) ϕ(q Li , d Fi ) , (<label>6</label></formula><formula xml:id="formula_10" coords="5,508.78,637.75,4.25,9.96">)</formula><p>where ϕ is the cosine similarity and b the boosting constant.</p><p>The name "Cross Querying" reflects the fact that |L| × |F | rankings are merged by querying in each language in each field. The applied parameters are as follows:</p><p>Query and Document Construction. The words of both topic fields, title and description, are used as queries and translated to each L i ∈ L, with L = {German, F rench, English}. The selection of the document fields corresponds to title and subject.</p><p>As term weighting schema tf • idf is used. Query and document words are stemmed using the Snowball stemmers while stop words are removed. The queries are translated with Google Translate; the boosting constant b is based on the unofficial evaluation on the TEL@CLEF 2008 dataset.</p><p>Language Detection. In order to estimate the language of d with lang(d) we take the corpus language of the associated evaluation run. "Bilingual English" the graph for "CL-ESA-de" shows the results of querying the English collection with German topics using the CL-ESA. Cross Querying achieves nearly the same or even higher results compared to the monolingual situation, whereas the performance of the CL-ESA is lower in contrast to the monolingual results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion and Future Work</head><p>The evaluation results for the TEL@CLEF task show that both CLIR approaches CL-ESA and Cross Querying are able to outperform the monolingual baseline-though the absolute results are still improvable. Furthermore, we have presented a formal definition and an alternative interpretation for the CL-ESA model, which is interesting for real-world retrieval applications since it reveals how the computational effort for CL-ESA can be shifted from the query phase to a preprocessing phase.</p><p>As for future work, CL-ESA and Cross Querying will benefit if more languages are taken into account. Currently, German, English, and French are used, but the target collections comprise more languages. For documents from other languages an inconsistent CL-ESA representation is computed. CL-ESA also needs a reliable language detection mechanism in order to compute a consistent representation; note that we used a rather simple approach in our experiments.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,378.00,568.75,135.04,9.96;3,90.00,580.75,390.12,10.34;3,480.12,579.86,4.08,5.29;3,480.12,585.89,2.82,6.40;3,487.44,580.75,18.27,9.96;3,505.68,579.86,4.08,5.29;3,505.68,585.89,2.82,6.40;3,510.24,580.75,2.77,9.96;3,90.00,592.75,276.93,10.34;3,367.20,591.86,4.08,5.29;3,366.96,597.77,2.82,6.40;3,371.88,592.75,141.11,10.34;3,90.00,604.63,125.75,9.96;3,90.00,628.63,422.94,10.65;3,90.00,640.51,42.48,9.96;3,132.72,639.62,4.08,5.29;3,141.36,640.51,25.17,9.96;3,166.80,639.62,4.08,5.29;3,166.56,645.27,3.97,6.97;3,171.24,640.85,30.46,9.31;3,201.96,639.62,4.08,5.29;3,201.72,645.89,4.23,6.40;3,206.64,640.51,196.53,9.96;3,403.44,639.62,4.08,5.29"><head></head><label></label><figDesc>Hence, each entry in the ESA representation d iESA of a document d i is the cosine similarity between d i and some vector d * i ∈ D * i . Put another way, d i is compared to each index document in D * i , and d iESA is comprised of the respective cosine similarities. Definition 2 (CL-ESA Similarity) Let L = {L 1 , . . . , L k } denote a set of natural languages, and let D * = {D * 1 , . . . , D * k } be a set of index collections where each D *</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="7,90.00,389.35,422.92,9.96;7,90.00,401.44,344.06,8.27"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Evaluation results of the bilingual runs. The plots show the standard recall levels vs. interpolated precision. The table show the results in terms of mean average precision, MAP.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,90.00,118.39,423.02,218.40"><head>Table 1 :</head><label>1</label><figDesc>Statistics of the three target collections BL, ONB, BNF, used in the TEL@CLEF task.</figDesc><table coords="3,328.44,135.63,129.60,7.20"><row><cell>BL</cell><cell>ONB</cell><cell>BNF</cell></row></table><note coords="3,90.00,314.95,423.02,9.96;3,90.00,326.83,61.84,9.96"><p>Cross-Language Explicit Semantic Analysis, CL-ESA, is a generalization of the Explicit Semantic Analysis, ESA</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,177.84,118.39,247.22,9.96"><head>Table 2 :</head><label>2</label><figDesc>The different interpretations of the CL-ESA model.</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,105.24,746.52,226.75,7.97"><p>The European Library: http://www.theeuropeanlibrary.org/.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation Results</head><p>The results of the monolingual subtask and the bilingual subtask are shown in Figure <ref type="figure" coords="6,487.22,229.03,4.98,9.96">1</ref> and Figure <ref type="figure" coords="6,121.45,240.91,4.98,9.96">2</ref> respectively.  We submitted an additional baseline to the monolingual subtask using state-of-the-art retrieval technology: since in this subtask the language of the topics is equal to the main language of the target collection, the ranking is based on the cosine similarities of the tf •idf -weighted bag-of-words representations of the topics and the documents.</p><p>Each plot in Figure <ref type="figure" coords="6,189.99,625.27,4.98,9.96">1</ref> corresponds to one target collection and shows the baseline along with the results achieved under Cross Querying, CL-ESA, and CL-ESA with automatic language detection, CL-ESA-LD. Both Cross Querying and CL-ESA clearly outperform the baseline. The variation between the two approaches is small, except for the German collection where Cross Querying outperforms CL-ESA at low recall levels. At higher recall levels CL-ESA is better, which explains a slightly higher mean average precision on the English and the French collections. Using CL-ESA along with the automatic language detection improves the performance only for the French collection, which indicates that this collection contains a larger fraction of non-French documents.</p><p>In the bilingual subtask the language of the queries is different from the main language of the target collection. Each plot in Figure <ref type="figure" coords="6,278.07,732.79,4.98,9.96">2</ref> corresponds to one target collection that is queried in the two other languages, using both Cross Querying and CL-ESA. For example, in the plot  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="7,105.48,696.91,395.31,9.96;7,105.48,708.91,383.06,9.96;7,105.48,720.91,315.86,9.96" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,250.48,696.91,155.27,9.96">The ESA Retrieval Model Revisited</title>
		<author>
			<persName coords=""><forename type="first">Maik</forename><surname>Anderka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,434.88,709.25,53.66,9.18;7,105.48,721.25,165.21,9.18">32th Annual International ACM SIGIR Conference</title>
		<editor>
			<persName><forename type="first">Mark</forename><surname>Sanderson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">James</forename><surname>Allan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Justin</forename><surname>Zobel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Javed</forename><forename type="middle">A</forename><surname>Aslam</surname></persName>
		</editor>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2009-07">July 2009</date>
			<biblScope unit="page" from="670" to="671" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.48,111.43,367.49,9.96;8,105.48,123.43,402.55,9.96;8,105.48,135.31,270.28,9.96" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,300.92,111.43,172.06,9.96;8,105.48,123.43,191.13,9.96">Computing Semantic Relatedness using Wikipedia-based Explicit Semantic Analysis</title>
		<author>
			<persName coords=""><forename type="first">Evgeniy</forename><surname>Gabrilovich</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Shaul</forename><surname>Markovitch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,317.76,123.77,190.27,9.18;8,105.48,135.65,157.76,9.18">Proceedings of The 20th International Joint Conference for Artificial Intelligence</title>
		<meeting>The 20th International Joint Conference for Artificial Intelligence<address><addrLine>Hyderabad, India</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.48,155.35,407.55,9.96;8,105.48,167.23,389.56,9.96;8,105.48,179.23,387.83,9.96;8,105.48,191.11,368.59,9.96;8,105.48,203.11,113.19,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,329.59,155.35,183.44,9.96;8,105.48,167.23,24.91,9.96">A Wikipedia-Based Multilingual Retrieval Model</title>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Potthast</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Benno</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maik</forename><surname>Anderka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,173.88,179.57,238.17,9.18">30th European Conference on IR Research, ECIR 2008</title>
		<title level="s" coord="8,128.76,191.11,193.18,9.96">LNCS of Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Craig</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Iadh</forename><surname>Ounis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Vassilis</forename><surname>Plachouras</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ian</forename><surname>Ruthven</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Ryen</forename><forename type="middle">W</forename><surname>White</surname></persName>
		</editor>
		<meeting><address><addrLine>Glasgow; Berlin Heidelberg New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">4956</biblScope>
			<biblScope unit="page" from="522" to="530" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.48,223.03,404.76,9.96;8,105.48,235.03,281.29,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,261.44,223.03,248.81,9.96;8,105.48,235.03,32.97,9.96">Cross-lingual information retrieval with explicit semantic analysis</title>
		<author>
			<persName coords=""><forename type="first">Philipp</forename><surname>Sorg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Philipp</forename><surname>Cimiano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,159.24,235.37,195.93,9.18">Working Notes for the CLEF 2008 Workshop</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.48,254.95,402.23,9.96;8,105.48,266.83,388.03,9.96;8,105.48,278.83,398.27,9.96;8,105.48,290.83,126.87,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,366.67,254.95,141.04,9.96;8,105.48,266.83,100.45,9.96">Generalized vector spaces model in information retrieval</title>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">K M</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wojciech</forename><surname>Ziarko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Patrick</forename><forename type="middle">C N</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,226.56,267.17,266.95,9.18;8,105.48,279.17,313.82,9.18">SIGIR &apos;85: Proceedings of the 8th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1985">1985</date>
			<biblScope unit="page" from="18" to="25" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,105.48,310.75,398.08,9.96;8,105.48,322.63,402.02,9.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,449.30,310.75,54.26,9.96;8,105.48,322.63,231.26,9.96">Translingual information retrieval: learning from bilingual corpora</title>
		<author>
			<persName coords=""><forename type="first">Yiming</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jaime</forename><forename type="middle">G</forename><surname>Carbonell</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ralf</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Robert</forename><forename type="middle">E</forename><surname>Frederking</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,345.36,322.97,52.46,9.18">Artif. Intell</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="323" to="345" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
