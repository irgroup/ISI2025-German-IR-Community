<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,149.64,71.81,291.85,15.54;1,441.24,69.82,4.50,9.96">HIT2Lab at CLEF: an Exploration to TEL Task *</title>
				<funder ref="#_wGWQZcV">
					<orgName type="full">Science and Technology Break-through Project of Heilongjiang</orgName>
				</funder>
				<funder ref="#_37KAhs3">
					<orgName type="full">Project of the Natural Science Foundation of Heilongjiang Province</orgName>
				</funder>
				<funder ref="#_VeE6TqW">
					<orgName type="full">Key Project of the National Science Foundation of China</orgName>
				</funder>
				<funder ref="#_H5TZFZP">
					<orgName type="full">National Science Foundation of China</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,128.04,99.69,51.18,11.03"><forename type="first">He</forename><surname>Xiaoning</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Harbin University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,187.44,99.69,49.02,11.03"><forename type="first">Qi</forename><surname>Haoliang</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Heilongjiang Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,244.68,99.69,59.10,11.03"><forename type="first">Wang</forename><surname>Peidong</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Harbin University of Science and Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,312.00,99.69,52.50,11.03"><forename type="first">Yang</forename><surname>Muyun</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Harbin Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,372.72,99.69,36.05,11.03"><forename type="first">Li</forename><surname>Sheng</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Harbin Institute of Technology</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,417.00,99.69,47.14,11.03"><forename type="first">Lei</forename><surname>Guohua</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Heilongjiang Institute of Technology</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,149.64,71.81,291.85,15.54;1,441.24,69.82,4.50,9.96">HIT2Lab at CLEF: an Exploration to TEL Task *</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">82F22649CA2E7F4165E82516719ADE09</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing; H.3.3 Information Search and Retrieval Cross-lingual Information Retrieval</term>
					<term>Query Translation</term>
					<term>KL-divergence</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This is the first time HIT 2 Lab has participated in CLEF. The Adhoc TEL task used a collection of electronic card catalog records from British Library, it is different from all the text retrieval tasks we've ever involved. In our runs, we used language modeling approach for retrieval model and incorporated pseudo-feedback, which have been proved effective in previous experiments. For bilingual tasks, we used Google translation service for query translation. We also adopted methods that have showed good effects in TEL 2009 task, including a stopword list provided by UniNE and partial fields indexing.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>HIT <ref type="bibr" coords="1,101.28,417.91,3.24,7.17" target="#b1">2</ref> Lab is the joint lab between Harbin Institute of Technology and Heilongjiang Institute of Technology. We are currently interested in several natural language processing tasks, including information retrieval, text classification, web data mining, and etc. Since this is the first time we've taken part in TEL@CLEF task, we've focused on getting familiar with the task and implementing the methods which produced the best results in TEL@CLEF 2008. We took lemur toolkit to build up our retrieval platform <ref type="bibr" coords="1,211.32,476.71,7.56,7.17" target="#b0">[1]</ref> . For monolingual retrieval, we experimented language model and pseudo relevance feedback, for bilingual retrieval, we experimented query translation based on Google translation service.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methodology</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Indexing</head><p>TEL@CLEF 2009 involves the British Library collection, which is consisted of electronic card catalog records <ref type="bibr" coords="1,100.44,568.39,7.56,7.17" target="#b1">[2]</ref> . The dataset has several features, such as:</p><p>-The data is sparse, that is, each document has very few texts.</p><p>-A document is organized in several fields, for example, a &lt;dc:title&gt; field indicates the title of the record.</p><p>-The data is multilingual, only about half of the collection is in English.</p><p>It is convenient to treat the whole text in a document as unstructured text, however, some have noticed that removal of several useless fields can help to improve the retrieval performance <ref type="bibr" coords="1,441.72,627.19,15.12,7.17">[3][4]</ref> . For example, &lt;mods:location&gt; field includes a text version that indicates the name and location of the repository responsible for the stewardship of the resource and its content, such field is regardless of the document's content. During indexing process, we only kept such five fields: relation, tableOfContents, abstract, subject, and title, other fields were abandoned.</p><p>We also used porter stemmer to normalize the terms. To eliminate the influence of very high frequent words, we used the stopword list released by UniNE last year.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Retrieval Model</head><p>Language modeling approach has been used widely in information retrieval researches. KL-divergence is a language model for information retrieval <ref type="bibr" coords="2,239.64,128.59,7.56,7.17" target="#b4">[5]</ref> which makes language models from both the document and query, then measures the similarity between the estimated models. Given two probability mass functions p(x) and q(x), The KL-divergence between p and q is defined as:</p><formula xml:id="formula_0" coords="2,242.88,165.50,109.38,25.79">= x x q x p x p q p D ) ( ) ( log ) ( ) || (</formula><p>Given the two models generated from document and query, we can model the risk of returning a document d as relevant to a query q by KL-divergence between their respective language models <ref type="bibr" coords="2,407.40,202.87,7.56,7.17" target="#b5">[6]</ref> :</p><formula xml:id="formula_1" coords="2,215.52,216.27,163.96,23.78">= = t d q q q d M t P M t P M t P M M KL q d R ) | ( ) | ( log ) | ( ) || ( ) ; (</formula><p>where d is a document, q is a query. M d and M d are the language models for documents and queries language model respectively. P(t|M q ) and P(t|M d ) are the probabilities that term t appears in M q and M d .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Pseudo Feedback</head><p>Pseudo feedback is a technique to improve information retrieval performance, it has proven to be an effective strategy for improving retrieval accuracy in all retrieval models. The method is to do normal retrieval to find an initial set of most relevant documents, then assume that the top k ranked documents are relevant, and finally to do relevance feedback as before under this assumption. The feedback model we used in this year's TEL task is as follows <ref type="bibr" coords="2,100.56,333.79,7.56,7.17" target="#b6">[7]</ref> :</p><formula xml:id="formula_2" coords="2,253.08,341.70,103.06,37.66">( ) ( ) k k q q P q q c, P R c P ... ... ) | ( 1 1</formula><p>where q i is an arbitrary query term, and c could be any possible representation concept. P(c, q 1 ...q k ) is calculated as follows:</p><p>( )</p><formula xml:id="formula_3" coords="2,202.68,406.27,203.32,23.72">D k k D P D q q P D c P = q q c, P ) ( ) | ... ( ) | ( ... 1 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Query Translation for Bilingual Retrieval</head><p>Cross-language information retrieval is a subfield of information retrieval dealing with retrieving information written in a language different from the language of the user's query. For example, a user may pose their query in Chinese but retrieve relevant documents written in English. One commonly used method is to translate the query into document language, called query translation. Online translation service based query translation has been proved to be an effective resource for cross-lingual information retrieval <ref type="bibr" coords="2,454.44,500.35,7.56,7.17" target="#b7">[8]</ref> . We submitted bilingual retrieval runs based on query translation. Chinese queries are translated into English by Google translation service and then a mono lingual retrieval on the target collection is performed.</p><p>Experimental results showed that most queries have been translated well. For example, the title of the first query is translated as "Arctic animals", which is the same as the English version; and its description is translated as "Find the Arctic fauna species and of related documents." while the original one is "Find documents about arctic fauna species". However there were still incorrectly translated topics. the title and description of topic 41 are "Sailing for Beginners" and "Find publications suitable for beginners or non-experts that provide information on any kind of sailing or boating", and after it is translated into Chinese manually and translated back into English by Google translation, the contents of the two fields became "Portal navigation" and "Suitable for beginners or find information about non-professionals of any type of sailing or rowing motion information publications". Portal navigation and sailing for beginners are definitely two different concepts, and so it caused the average precision of this topic to be 0%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments and Results</head><p>We submitted both monolingual and bilingual runs. Since we are familiar with English collection retrieval tasks, all our runs used only the English version dataset which is called TEL corpus from Britain Library as mentioned above. 50 topics are released for monolingual retrieval subtask. Since we are the only one who asked for Chinese version topics in bilingual retrieval subtask, we were responsible for translating the topics into</p><p>Chinese. An undergraduate student who did not take part in the task took the charge of this job, and we required an associate professor from Harbin Institute of Technology to proof the translated topics.</p><p>For monolingual runs, we experimented with KL-divergence method and pseudo feedback. We compared partial fields indexing with full indexing, the effectiveness of stopword list provided by UniNE was also tested. For bilingual runs, we experimented with query translation based on Google translation. We also tried a corpus based method which takes a Chinese-English parallel corpus for converting Chinese topics to English version, however it did not show good performance on TEL@CLEF 2008 data, and we analyzed that the bad performance was due to the limit of the corpus we used. That is, the parallel corpus we used was too small and couldn't reveal the true performance of the method, so we did not use the method in this year's task.</p><p>Monolingual results without pseudo are listed below. All the experiments took KL-divergence as retrieval model. Run tag including "u" means running with UniNE stopword list, "p" means partial indexing, "t" means title field of the topic is used, "d" means description field is used, and "td" means title and description field are used. From the results we see that title combining with description can improve retrieval performance, especially after applying UniNE stopword list which effectively cut down meaningless terms in topics. Partial indexing also gets positive effect, and so suggests a potential research direction for the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 1. Monolingual results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head><p>Bilingual results are as follows. The retrieved documents set we submitted used pseudo feedback. The top 10 documents returned for each topic were considered to be relevant. We submitted 4 runs for monolingual subtask and 3 runs for bilingual subtask, the evaluation results of these runs are listed below. The meanings of "u", "p", "t", "d", "td" are as mentioned above, and "ft" means how many terms were contained in the expanded query generated from pseudo relevant documents. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,191.88,452.97,208.14,59.27"><head>Table 2 . Bilingual results</head><label>2</label><figDesc></figDesc><table coords="3,191.88,464.97,208.14,47.27"><row><cell>Method</cell><cell>Average Precision</cell><cell>Binary Preference</cell><cell>R Precision</cell></row><row><cell>kl-u-p-t</cell><cell>0.2766</cell><cell>0.2767</cell><cell>0.2864</cell></row><row><cell>kl-u-p-td</cell><cell>0.3047</cell><cell>0.3115</cell><cell>0.3292</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,159.96,595.89,274.74,120.47"><head>Table 3 . Submitted run results</head><label>3</label><figDesc></figDesc><table coords="3,159.96,607.89,274.74,108.47"><row><cell>Method</cell><cell>Subtask</cell><cell>Average Precision</cell><cell>Binary Preference</cell><cell>R Precision</cell></row><row><cell>kl-u-p-td</cell><cell>monolingual</cell><cell>0.3390</cell><cell>0.3420</cell><cell>0.3688</cell></row><row><cell>kl-u-p-td-ft20</cell><cell>monolingual</cell><cell>0.3924</cell><cell>0.3810</cell><cell>0.4037</cell></row><row><cell>kl-u-p-td-ft40</cell><cell>monolingual</cell><cell>0.3936</cell><cell>0.3808</cell><cell>0.4051</cell></row><row><cell>kl-u-p-t-ft40</cell><cell>monolingual</cell><cell>0.3503</cell><cell>0.3422</cell><cell>0.3618</cell></row><row><cell>kl-u-p-td-ft20</cell><cell>bilingual</cell><cell>0.3523</cell><cell>0.3415</cell><cell>0.3614</cell></row><row><cell>kl-u-p-td-ft40</cell><cell>bilingual</cell><cell>0.3527</cell><cell>0.3410</cell><cell>0.3613</cell></row><row><cell>kl-u-p-t-ft40</cell><cell>bilingual</cell><cell>0.3172</cell><cell>0.3192</cell><cell>0.3335</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="4">Conclusion</head><p>While classic language model coupled with pseudo feedback is suitable for the TEL task, particular features of the TEL corpus can also benefit to the retrieval performance. Different fields in TEL collection have different affect, and removal of some fields that have no relation with the document content can help to improve retrieval performance. Combining title and description field in a topic also works, especially after applying a stopword list.</p><p>Query translation based on online translation service works well for cross-lingual information retrieval. Online translation service is able to translate the most queries correctly, although there are a small portion of the queries be translated as absolutely different meaning from their real meaning.</p><p>There are still many issues to consider, including document fields weighting, the collection's multilinguality and the document contents' insufficiency. We will explore such issues in future work.</p></div>
			</div>
			<div type="funding">
<div><p>This work is done at <rs type="institution">HIT 2 Lab, Heilongjiang Institute of Technology</rs>. The research is supported by the <rs type="funder">Key Project of the National Science Foundation of China</rs> (<rs type="grantNumber">60736044</rs>), <rs type="funder">National Science Foundation of China</rs> (<rs type="grantNumber">60873105</rs>), the <rs type="funder">Science and Technology Break-through Project of Heilongjiang</rs> (<rs type="grantNumber">GZ07A108</rs>), the <rs type="funder">Project of the Natural Science Foundation of Heilongjiang Province</rs> (<rs type="grantNumber">F2007-14</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_VeE6TqW">
					<idno type="grant-number">60736044</idno>
				</org>
				<org type="funding" xml:id="_H5TZFZP">
					<idno type="grant-number">60873105</idno>
				</org>
				<org type="funding" xml:id="_wGWQZcV">
					<idno type="grant-number">GZ07A108</idno>
				</org>
				<org type="funding" xml:id="_37KAhs3">
					<idno type="grant-number">F2007-14</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="4,84.00,231.34,362.62,9.96" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="4,84.00,231.34,250.98,9.96">The Lemur Toolkit for Language Modeling and Information Retrieval</title>
		<ptr target="http://www.lemurproject.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="4,85.44,241.90,439.15,9.96;4,84.84,252.46,257.37,9.96" xml:id="b1">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Giorgio</forename><forename type="middle">M</forename><surname>Eneko Agirre1</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Nicola</forename><surname>Di Nunzio</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Ferro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Carol</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Peters</surname></persName>
		</author>
		<title level="m" coord="4,420.72,241.90,103.86,9.96;4,84.84,252.46,230.55,9.96">CLEF 2008: Ad Hoc Track Overview. 9th workshop of the cross-language evaluation forum</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,84.60,263.02,439.96,9.96;4,84.84,273.58,140.58,9.96" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,268.08,263.02,75.75,9.96">UniNE at CLEF</title>
		<author>
			<persName coords=""><forename type="first">Ljiljana</forename><surname>Dolamic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Claire</forename><surname>Fautsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,351.60,263.02,172.95,9.96;4,84.84,273.58,116.07,9.96">TEL, Perisan and Robust. 9th workshop of the cross-language evaluation forum</title>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,84.00,284.14,428.22,9.96" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,144.24,284.14,127.52,9.96">JHU Ad Hoc Experiments at CLEF</title>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Mcnamee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,296.88,284.14,190.83,9.96">9th workshop of the cross-language evaluation forum</title>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,84.96,294.70,439.50,9.96;4,84.84,305.26,106.41,9.96" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,208.56,294.70,315.90,9.96;4,84.84,305.26,31.61,9.96">Document Language Models, Query Models, and Risk Minimization for Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chengxiang</forename><surname>Zhai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,122.28,305.26,42.07,9.96">SIGIR 2001</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,84.96,315.82,439.54,9.96;4,84.84,326.38,231.21,9.96" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,213.72,315.82,221.81,9.96">Model-based feedback in the KL-divergence retrieval model</title>
		<author>
			<persName coords=""><forename type="first">Cheng-Xiang</forename><surname>Zhai</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">John</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,453.96,315.82,70.54,9.96;4,84.84,326.38,203.95,9.96">Tenth International Conference on Information and Knowledge Management</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,84.00,336.94,321.09,9.96" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="4,208.56,336.94,121.23,9.96">Relevance based language models</title>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">Bruce</forename><surname>Victor Lavrenko</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Croft</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,336.12,336.94,42.07,9.96">SIGIR 2001</title>
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,84.24,347.50,440.22,9.96;4,84.84,358.06,249.42,9.96" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="4,285.60,347.50,238.86,9.96;4,84.84,358.06,28.24,9.96">CLEF 2008 Ad-Hoc Track: On-line Processing Experiments with Xtrieval</title>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Jens K Ursten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Maximilian</forename><surname>Wilhelm</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Eibl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,118.92,358.06,190.83,9.96">9th workshop of the cross-language evaluation forum</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
