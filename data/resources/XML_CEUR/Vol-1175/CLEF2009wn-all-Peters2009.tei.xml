<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,206.28,106.61,182.81,12.58;1,193.86,131.87,207.61,12.58">What happened in CLEF 2009 Introduction to the Working Notes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,273.12,162.84,49.23,9.02"><forename type="first">Carol</forename><surname>Peters</surname></persName>
							<email>carol.peters@isti.cnr.it</email>
							<affiliation key="aff0">
								<orgName type="department">Istituto di Scienza e Tecnologie dell&apos;Informazione (ISTI-CNR)</orgName>
								<address>
									<settlement>Pisa</settlement>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="laboratory">Coordination CLEF</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Istituto di Scienza e Tecnologie dell&apos;Informazione</orgName>
								<orgName type="institution">Consiglio Nazionale delle Ricerche</orgName>
								<address>
									<settlement>Pisa</settlement>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department" key="dep1">Adaptive Informatics Research Centre</orgName>
								<orgName type="department" key="dep2">School of Library and Information Science</orgName>
								<orgName type="institution">Helsinki University of Technology</orgName>
								<address>
									<settlement>Berlin</settlement>
									<country key="FI">Finland</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Business Information Systems</orgName>
								<orgName type="institution" key="instit1">Humboldt-Universität zu Berlin</orgName>
								<orgName type="institution" key="instit2">University of Applied Sciences Western Switzerland</orgName>
								<address>
									<settlement>Sierre</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">CEA LIST</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff6">
								<orgName type="department">Center for Autonomous Systems and Communication Technologies (CELCT)</orgName>
								<orgName type="laboratory">Center for Evaluation of Language</orgName>
								<orgName type="institution">Royal Institute of Technology</orgName>
								<address>
									<country>Sweden, Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff7">
								<orgName type="department">Centrum voor Wiskunde</orgName>
								<orgName type="institution">en Informatica (CWI)</orgName>
								<address>
									<settlement>Amsterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
							<affiliation key="aff8">
								<orgName type="department">Computer Science Department</orgName>
								<orgName type="laboratory">Computer Vision and Multimedia Lab</orgName>
								<orgName type="institution">University of the Basque Country</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff9">
								<orgName type="institution">University of Geneva</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff10">
								<orgName type="department">Database Research Group</orgName>
								<orgName type="institution">University of Tehran</orgName>
								<address>
									<country key="IR">Iran</country>
								</address>
							</affiliation>
							<affiliation key="aff11">
								<orgName type="department">Department of Computer Science &amp; Information Systems</orgName>
								<orgName type="institution">University of Limerick</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
							<affiliation key="aff12">
								<orgName type="department">Department of Information Engineering</orgName>
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
							<affiliation key="aff13">
								<orgName type="department">Department of Information Science</orgName>
								<orgName type="institution">University of Hildesheim</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff14">
								<orgName type="department">Department of Information Studies</orgName>
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff15">
								<orgName type="department">Department of Medical Informatics and Clinical Epidemiology</orgName>
								<orgName type="institution">Oregon Health and Science University</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff16">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">University Hospitals and University of Geneva</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff17">
								<orgName type="department">Department of Medical Informatics</orgName>
								<orgName type="institution">Aachen University of Technology (RWTH)</orgName>
								<address>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff18">
								<orgName type="department">Evaluations and Language Resources Distribution Agency Sarl</orgName>
								<orgName type="laboratory">GERiiCO</orgName>
								<orgName type="institution">Fraunhofer Institute for Digital Media Technology (IDMT)</orgName>
								<address>
									<settlement>Paris, Ilmenau</settlement>
									<country>France, Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff19">
								<orgName type="institution">Université de Lille</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff20">
								<orgName type="laboratory">Information Retrieval Facility (IRF)</orgName>
								<orgName type="institution">Idiap Research Institute</orgName>
								<address>
									<country>Switzerland, Austria</country>
								</address>
							</affiliation>
							<affiliation key="aff21">
								<orgName type="department">Lenguajes y Sistemas Informáticos</orgName>
								<orgName type="laboratory">Laboratoire d&apos;Informatique pour la Mécanique et les Sciences de l&apos;Ingénieur (LIMSI)</orgName>
								<orgName type="institution">Universidad Nacional de Educación a Distancia</orgName>
								<address>
									<settlement>Orsay, Madrid</settlement>
									<country>France, Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff22">
								<orgName type="laboratory" key="lab1">Linguateca</orgName>
								<orgName type="laboratory" key="lab2">SINTEF ICT</orgName>
								<address>
									<country key="NO">Norway</country>
								</address>
							</affiliation>
							<affiliation key="aff23">
								<orgName type="laboratory">Linguistic Modelling Laboratory</orgName>
								<orgName type="institution">Bulgarian Academy of Sciences</orgName>
								<address>
									<country key="BG">Bulgaria</country>
								</address>
							</affiliation>
							<affiliation key="aff24">
								<orgName type="department">Matrixware Information Services</orgName>
								<address>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
							<affiliation key="aff25">
								<orgName type="department">Mediamatics</orgName>
								<orgName type="institution">Delft University of Technology</orgName>
								<address>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
							<affiliation key="aff26">
								<orgName type="institution">Mitre Corporation</orgName>
								<address>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff27">
								<orgName type="laboratory">NLE Lab</orgName>
								<orgName type="institution">National Institute of Standards and Technology</orgName>
								<address>
									<settlement>Gaithersburg</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff28">
								<orgName type="institution">Universidad Politènica de Valencia</orgName>
								<address>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
							<affiliation key="aff29">
								<orgName type="institution" key="instit1">Research Institute for Artificial Intelligence</orgName>
								<orgName type="institution" key="instit2">Romanian Academy</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
							<affiliation key="aff30">
								<orgName type="institution">Romanian Institute for Computer Science</orgName>
								<address>
									<country key="RO">Romania</country>
								</address>
							</affiliation>
							<affiliation key="aff31">
								<orgName type="institution">Royal Institute of technology (KTH)</orgName>
								<address>
									<settlement>Stockholm</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
							<affiliation key="aff32">
								<orgName type="department">School of Computing</orgName>
								<orgName type="institution">Dublin City University</orgName>
								<address>
									<country key="IE">Ireland</country>
								</address>
							</affiliation>
							<affiliation key="aff33">
								<orgName type="department">Swedish Institute of Computer Science</orgName>
								<address>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
							<affiliation key="aff34">
								<orgName type="department">TALP Research Center</orgName>
								<orgName type="institution">Universitat Politécnica de Catalunya</orgName>
								<address>
									<settlement>Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,206.28,106.61,182.81,12.58;1,193.86,131.87,207.61,12.58">What happened in CLEF 2009 Introduction to the Working Notes</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">C2235A5A26FBDC9193ACB910E2E56CAA</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The objective of the Cross Language Evaluation Forum 1 is to promote research in the field of multilingual system development. This is done through the organisation of annual evaluation campaigns in which a series of tracks designed to test different aspects of mono-and cross-language information retrieval (IR) are offered. The intention is to encourage experimentation with all kinds of multilingual information access -from the development of systems for monolingual retrieval operating on many languages to the implementation of complete multilingual multimedia search services. This has been achieved by offering an increasingly complex and varied set of evaluation tasks over the years. The aim is not only to meet but also to anticipate the emerging needs of the R&amp;D community and to encourage the development of next generation multilingual IR systems. These Working Notes contain descriptions of the experiments conducted within CLEF 2009 -the tenth in a series of annual system evaluation campaigns. The results of the experiments will be presented and discussed in the CLEF 2009 Workshop, 30 September -2 October, Corfu, Greece. The final papers -revised and extended as a result of the discussions at the Workshop -together with a comparative analysis of the results will appear in the CLEF 2009 Proceedings, to be published by Springer in their Lecture Notes for Computer Science series. Since CLEF 2005, the Working Notes are published in electronic format only and are distributed to participants at the Workshop on a memory stick together with a printed volume of Extended Abstracts. The Working Notes for all the ten CLEF campaigns can be found in electronic form on the CLEF website at www.clef-campaign.org. Both the 2009 Working Notes and Book of Abstracts are divided into ten sections, corresponding to the eight main evaluation tracks, the experimental pilot task, and another evaluation initiative using CLEF data: Morpho Challenge 2009. Appendices are also included containing run statistics for the Ad Hoc and Grid@CLEF tracks, and a list of all participating institutions. The main features of the 2009 campaign are briefly outlined in the following sections in order to provide the necessary background to the experiments reported in the rest of the Working Notes.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Tracks and Tasks in CLEF 2009</head><p>CLEF 2009 offered eight main tracks designed to evaluate the performance of systems for:</p><p>• multilingual textual document retrieval (Ad Hoc)</p><p>• interactive cross-language retrieval (iCLEF)</p><p>• multiple language question answering (QA@CLEF)</p><p>• cross-language retrieval in image collections (ImageCLEF)</p><p>• multilingual information filtering (INFILE@CLEF)</p><p>• cross-language video retrieval (VideoCLEF)</p><p>• intellectual property (CLEF-IP) -New this year • log file analysis (LogCLEF) -New this year An experimental pilot task was also offered:</p><p>• Grid Experiments (Grid@CLEF)</p><p>In addition, Morpho Challenge 2009 was organized in collaboration with CLEF as part of the EU Network of Excellence Pascal Challenge Program 2 . The Morpho Challenge participants will meet separately, before the main CLEF workshop on the morning of Wednesday 30 September, to discuss their results.</p><p>1 Since the beginning of 2008, CLEF is included in the activities of the TrebleCLEF Coordination Action, funded by the Seventh Framework Programme of the European Commission. For information on TrebleCLEF, see www.trebleclef.eu. <ref type="bibr" coords="1,70.92,746.56,3.00,5.40">2</ref> Morpho Challenge is part of the EU Network of Excellence Pascal: http://www.cis.hut.fi/morphochallenge2009/ Here below we give a brief overview of the various activities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multilingual Textual Document Retrieval (Ad Hoc):</head><p>The aim of this track is to promote the development of monolingual and cross-language textual document retrieval systems. From 2000 -2007, the track exclusively used collections of European newspaper and news agency documents. Last year the focus of the track was considerably widened: we introduced very different document collections, a non-European target language, and an information retrieval (IR) task designed to attract participation from groups interested in natural language processing (NLP). The 2009 Ad Hoc track was to a large extent a repetition of last year's track, with the same three tasks: Tel@CLEF, Persian@CLEF, and Robust-WSD. An important objective has been to create good reusable test collections for each of them The track was thus structured in three distinct streams. The first task offered monolingual and cross-language search on library catalog records and was organized in collaboration with The European Library (TEL)<ref type="foot" coords="2,96.42,192.07,3.24,5.83" target="#foot_0">3</ref> . The second task resembled the ad hoc retrieval tasks of previous years but this time the target collection was a Persian newspaper corpora. The third task was the robust activity which used word sense disambiguated (WSD) data. Multilingual Question Answering (QA@CLEF): This track has offered monolingual and cross-language question answering tasks since 2003. QA@CLEF 2009 proposed three exercises: ResPubliQA, QAST and GikiCLEF:</p><p>• ResPubliQA: The hypothetical user considered for this exercise is a person close to the law domain interested in making inquiries on European legislation. Given a pool of 500 independent natural language questions, systems must return the passage that answers each question (not the exact answer) from the JRC-Acquis collection of EU parliamentary documentation. Both questions and documents are translated and aligned for a subset of languages. Participating systems could perform the task in Basque, Bulgarian, English, French, German, Italian, Portuguese, Romanian and Spanish.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>•</head><p>QAST: The aim of the third QAST exercise was to evaluate QA technology in a real multilingual speech scenario in which written and oral questions (factual and definitional) in different languages are formulated against a set of manually and automatically transcribed audio recordings related to speech events in those languages. The scenario proposed was the European Parliament sessions in English, Spanish and French. • GikiCLEF: Following the previous GikiP pilot at GeoCLEF 2008, the task focused on open list questions over Wikipedia that require geographic reasoning, complex information extraction, and cross-lingual processing, for collections in Bulgarian, Dutch, English, German, Italian, Norwegian (both Bokmål and Nynorsk), Portuguese and Romanian or Spanish. The track was organized by a number of institutions (one for each target language), and jointly coordinated by CELCT, Trento, Italy, and UNED, Madrid, Spain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cross-Language Retrieval in Image Collections (ImageCLEF):</head><p>This track evaluated retrieval from visual collections; both text and visual retrieval techniques were employed. A number of challenging tasks were offered:</p><p>• multilingual ad-hoc retrieval from a photo collection concentrating on diversity in the results; • a photographic annotation task using a simple ontology;</p><p>• retrieval from a large scale, heterogeneous collection of Wikipedia images with user-generated textual metadata, and queries in several languages; • medical image retrieval (with visual, semantic and mixed topics in several languages); • medical image annotation;</p><p>• detection of semantic categories from robotic images (non-annotated collection, concepts to be detected).</p><p>A large number of organisations have been involved in the complex coordination of these tasks. They include: Sheffield University, UK; University of Applied Sciences Western Switzerland; Oregon Health and Science University, USA; University of Geneva, Switzerland; CWI, The Netherlands; IDIAP, Switzerland. The ImageCLEF track has organised a separate one day workshop on visual information retrieval evaluation in collaboration with the Theseus project; this will be held immediately before the main CLEF workshop, on 29 September at the University of Corfu.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Multilingual Information Filtering (INFILE@CLEF): INFILE (INformation, FILtering &amp; Evaluation</head><p>) is a cross-language adaptive filtering evaluation track sponsored by the French National Research Agency. INFILE has extended the last filtering track of TREC 2002 as follows. It uses a corpus of 100,000 Agence France Press comparable newswires for Arabic, English and French; evaluation is performed using an automatic querying of test systems with a simulated user feedback. Each system can use the feedback at any time to increase performance. The track has been coordinated by the Evaluation and Language resources Distribution Agency (ELDA), France; University of Lille, France; and CEA LIST, France.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Cross-Language Video Retrieval (VideoCLEF):</head><p>VideoCLEF 2009 is dedicated to developing and evaluating tasks involving access to video content in a multilingual environment. Participants were provided with a corpus of video data (Dutch-language television, predominantly documentaries) accompanied by speech recognition transcripts. In 2009, there were three tasks: "Subject Classification", which involved automatically tagging videos with subject labels; "Affect", which involved classifying videos according to characteristics beyond their semantic content; ``Finding Related Resources Across Languages", which involved linking video to material on the same subject in a different language. The track was jointly coordinated by Delft University of Technology and Dublin City University, Ireland.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Intellectual Property (CLEF-IP):</head><p>This was the first year for the CLEF-IP track. The purpose of the track was twofold: to encourage and facilitate research in the area of patent retrieval by providing a large clean data set for experimentation; to create a large test collection of patents in the three main European languages for the evaluation of cross-lingual information access. The track focused on the task of prior art search. A large test collection for evaluation purposes was created by exploiting patent citations. The collection consists of a corpus of 1,9 million patent documents and 10,000 topics with an average of 6 relevance assessments per topic. Log file analysis (LogCLEF): LogCLEF is an evaluation initiative for the analysis of queries and other logged activities as expression of user behaviour. The goal is the analysis and classification of queries in order to understand search behaviour in multilingual contexts and ultimately to improve search systems. The track used log data from the files of The European Library. Grid Experiments (Grid@CLEF): This experimental pilot is planned as a long term activity with the aim of: looking at differences across a wide set of languages; identifying best practices for each language; helping other countries to develop their expertise in the IR field and create IR groups. Participants had to conduct experiments according to the CIRCO (Coordinated Information Retrieval Components Orchestration) protocol, an XML-based framework which allows for a distributed, loosely-coupled, and asynchronous experimental evaluation of Information Retrieval (IR) systems. The track is coordinated jointly by University of Padua, Italy, National Institute of Standards and Technology, USA. Unsupervised Morpheme Analysis (Morpho Challenge): Morpheme analysis is particularly useful in speech recognition, information retrieval and machine translation for morphologically rich languages where the amount of different word forms is very large. In Morpho Challenge 2009 unsupervised algorithms that provide morpheme analyses for words in different languages were evaluated in various practical applications. The evaluations consisted of: 1) a comparison to grammatical morphemes,2) using morphemes instead of words in information retrieval tasks, and 3) combining morpheme and word based systems in statistical machine translation tasks. The evaluation languages in 2009 were: Finnish, Turkish, German, English and Arabic. The track was coordinated by Helsinki University of Technology and Cambridge University Engineering Department.</p><p>Details on the technical infrastructure and the organisation of all these tracks can be found in the track overview reports in this volume, collocated at the beginning of the relevant sections. Figure <ref type="figure" coords="3,397.56,648.78,5.01,9.02">1</ref> shows the ratio of participants per track. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CLEF 2009 Tracks</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Test Collections</head><p>The CLEF test collections are made up of documents, topics and relevance assessments. The topics are created to simulate particular information needs from which the systems derive the queries to search the document collections. System performance is evaluated by judging the results retrieved in response to a topic with respect to their relevance, and computing the relevant measures, depending on the methodology adopted by the track. The document sets that have been used to build the test collections in CLEF 2009 included: </p><formula xml:id="formula_0" coords="4,82.92,423.79,55.11,12.26">• A subset</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">CLEF &amp; TrebleCLEF</head><p>CLEF is organized mainly through the voluntary efforts of many different institutions and research groups. Section 1 gives the groups responsible for the coordination of this year's tracks. A full list of the people and groups involved in the organization of CLEF2009 is given at the end of this paper. However, the central coordination has always received some support from the EU IST programme under the unit for Digital Libraries and Technology Enhanced Learning, mainly within the framework of the DELOS Network of Excellence. CLEF 2008 and 2009 are organized under the auspices of TrebleCLEF, a Coordination Action of the Seventh Framework Programme, Theme ICT 1-4-1.</p><p>TrebleCLEF is building on and extending the results already achieved by CLEF. The objective is to support the development and consolidation of expertise in the multidisciplinary research area of multilingual information access and to promote a dissemination action in the relevant application communities. The aim is to</p><p>• Provide applications that need multilingual search solutions with the possibility to identify the technology which is most appropriate • Assist technology providers to develop competitive multilingual search solutions. Information on the activities of TrebleCLEF can be found on the project website.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Technical Infrastructure</head><p>TrebleCLEF supports a data curation approach within CLEF as an extension to the traditional methodology in order to better manage, preserve, interpret and enrich the scientific data produced, and to effectively promote the transfer of knowledge. The current approach to experimental evaluation is mainly focused on creating comparable experiments and evaluating their performance whereas researchers would also greatly benefit from an integrated vision of the scientific data produced, together with analyses and interpretations, and from the possibility of keeping, re-using, and enriching them with further information. The way in which experimental results are managed, made accessible, exchanged, visualized, interpreted, enriched and referenced is an integral part of the process of knowledge transfer and sharing towards relevant application communities.</p><p>The University of Padua has thus developed DIRECT: Distributed Information Retrieval Evaluation Campaign Tool<ref type="foot" coords="5,90.30,305.77,3.24,5.83" target="#foot_1">4</ref> , a digital library system for managing the scientific data and information resources produced during an evaluation campaign. A preliminary version of DIRECT was introduced into CLEF in 2005 and subsequently tested and developed in the CLEF 2006 and 2007 campaigns. It has been further developed under TrebleCLEF.</p><p>DIRECT currently manages the technical infrastructure for several of the CLEF tracks and tasks: Ad Hoc, ImageCLEFphoto, GridCLEF, providing procedures to handle:</p><p>the track set-up, harvesting of documents, management of the registration of participants to tracks; the submission of experiments, collection of metadata about experiments, and their validation; the creation of document pools and the management of relevance assessment; the provision of common statistical analysis tools for both organizers and participants in order to allow the comparison of the experiments; the provision of common tools for summarizing, producing reports and graphs on the measured performances and conducted analyses.</p><p>DIRECT is designed and implemented by Giorgio Di Nunzio, Nicola Ferro and Marco Dussin.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Participation</head><p>Researchers from 117 different academic and industrial institutions submitted runs in CLEF 2009: 81 from Europe, 18 from N.America; 16 from Asia, 1 from S.America and 1 from Africa. The breakdown of participation of groups per track is as follows: Ad Hoc 28(26); iCLEF 6(6); QA@CLEF 25(29); ImageCLEF 62(42); INFILE 5(1); VideoCLEF 7(5); CLEF-IP 15; LogCLEF 6; Grid@CLEF 2; MorphoChallenge 9(6).Last years figures are given between brackets where applicable. A list of these institutions and indications of the tracks in which they participated is included in an Appendix to these Working Notes. Figure <ref type="figure" coords="5,357.11,566.17,5.01,9.02">2</ref> shows the trend in participation over the years and Figure <ref type="figure" coords="5,140.08,577.69,5.01,9.02">3</ref> shows the shift in focus as new tracks are added. As can be seen, the number of groups participating in the Ad Hoc, iCLEF, QA and VideoCLEF tracks is almost the same as last year, there has been a rise of interest in INFILE and participation in the two new tracks (LogCLEF and CLEF-IP) is encouraging. The most popular track is without doubt ImageCLEF which, with a notable increase from the 42 groups of last year, is now dominating the scene. This gives some cause for reflection as ImageCLEF is the track least concerned with multilinguality. However, recognising that multilingual information access is a truly multidisciplinary domain, one of the main objectives of CLEF has always been to create a forum where researchers from a wide range of areas can get together. CLEF is perhaps one of the few platforms where groups working in many different areas (e.g. Information Retrieval, Natural Language Processing, Image Processing, Speech Recognition, Log Analysis, etc., etc. ) have a chance to see what others are doing, and discuss and compare ideas. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Workshop</head><p>As has been stated, CLEF aims at creating a strong CLIR/MLIA research and development community. The Workshop plays an important role by providing the opportunity for all the groups that have participated in the evaluation campaign to get together comparing approaches and exchanging ideas. The work of the groups participating in this year's campaign will be presented in plenary and parallel paper and poster sessions. There will also be break-out sessions for more in-depth discussion of the results of individual tracks and intentions for the future. The final sessions will include discussions on ideas for the future. Overall, the Workshop should provide an ample panorama of the current state-of-the-art and the latest research directions in the multilingual information retrieval area. I very much hope that it will prove an interesting, worthwhile and enjoyable experience for all those who participate.</p><p>The final programme and the presentations at the Workshop are posted on the CLEF website at http://www.clef-campaign.org.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">The Future of CLEF</head><p>CLEF has been running for almost ten years now with the main goal of sustaining the growth of excellence in language processing and multilingual information access (MLIA) across language boundaries within the global context of the multilingual Web. Over the years, strongly motivated by the need to promote the study and utilisation of languages other than English on the Internet, a core network of research institutions involved with CLEF, with some support for the central coordination mainly from the DELOS Network of Excellence for Digital Libraries, has produced the following significant results:</p><p>• Creation of a very active multidisciplinary international research community, with strong interactions with both TREC and NTCIR including coordination of schedules and activities; • Investigation of core issues in MLIA which enable effective transfer over language boundaries, including the development of multiple language processing tools (e.g. stemmers, word decompounders, part-of-speech taggers); creation of linguistic resources (e.g. multilingual dictionaries and corpora); implementation of appropriate cross-language retrieval models and algorithms for different tasks and languages; • Creation of important reusable test collections and resources in diverse media for a large number of European languages, representative of the major European language typologies; • Significant and quantifiable improvements in the performance of MLIA systems; However, since CLEF began the associated technologies, services and users of multilingual IR systems have been in continual evolution, with many new factors and trends influencing the field. For example, the growth of the Internet has been exponential with respect to the number of users and languages used regularly for global information dissemination. The expectations and habits of users are constantly changing, together with the ways in which they interact with content and services, often creating new and original ways of exploiting them. Language barriers are no longer seen as inviolable and there is a growing dissatisfaction with the technologies currently available to overcome them. This constantly evolving scenario poses challenges to the research community which must react to these new trends and emerging needs. CLEF initially assumed a user model reflecting simple information seeking behaviour: the retrieval of a list of relevant items in response to a single query that could then be used for further consultation in various languages and media types. This simple scenario of user interaction has allowed researchers to focus their attention on studying core technical issues for CLIR systems and associated components. If we are to continue advancing the state-of-the-art in multilingual information access technologies, we now need to rethink and update this user model. We have to study and evaluate multilingual issues from a communicative perspective rather than a purely retrieval one. We need to examine the interactions between four main entities: users, their tasks, languages, and content in order to understand how these factors impact on the design and development of MLIA systems. It is not sufficient to successfully cross the language boundary, results must be retrieved in a form that is interpretable and reusable. Future cross-language system evaluation campaigns must activate new forms of experimental evaluation -laboratory and interactive -in order to foster the development of MLIA systems more adherent to the new user needs. We need a deeper understanding of the interaction between multicultural and information proactive users, multilingual content, language-dependent tasks, and the enabling technologies consisting of MLIA systems and their components. At the same time, benchmarking efforts must prove their usefulness for industrial take-up; evaluation initiatives risk being seen as irrelevant for system developers if the data they investigate are not of realistic scale and if the use cases and scenarios tested do not appear valid. Future editions of CLEF should thus introduce a new series of evaluation cycles which move beyond the current set-up, impacting on: • Methodology definition: evolution of the current evaluation paradigm, developing new models and metrics to describe the needs and behavior of the new multicultural and multi-tasking users; • System building: driving the development of MLIA systems and assessing their conformity with respect to the newly identified user needs, tasks, and models; • Results assessment: measuring all aspects of system &amp; component performance including response times, usability, and user satisfaction; • Community building: promoting the creation of a multidisciplinary community of researchers which goes beyond the existing CLEF community by building bridges to other relevant research domains such as the MT, information science and user studies sectors, and to application communities, such as the enterprise search, legal, patent, educational, cultural heritage and infotainment areas; • Validation of technology: providing a reasonably comprehensive typology of use cases and usage scenarios for multilingual search, validated through user studies, to enable reuse of appropriate resources and to enable common evaluation schemes; • Technology transfer: guaranteeing that the results obtained are demonstrated as useful for industrial deployment. Achieving this goal will require further synergy between various research communities including machine translation, information retrieval, question answering, information extraction, and representatives from end user groups. If this programme is to be implemented, it is clear that CLEF -or any similar evaluation initiative -needs a solid underlying management and coordination structure We feel that the ten year milestone may be the right point to pause for a moment to rethink carefully the best way in which to continue to ensure that the programme of activities is viable, consistent and coherent and that CLEF can successfully scale up and embrace new communities and technological paradigms.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,186.54,325.68,222.26,9.02"><head></head><label></label><figDesc>Figure 1. CLEF 2009: Participation Track by Track</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,142.89,427.02,384.77,9.02;4,100.92,438.48,75.89,9.02;4,82.92,447.49,259.37,12.26;4,82.92,459.67,444.68,12.26;4,100.92,474.42,119.40,9.02;4,82.92,483.37,187.46,12.26;4,82.92,495.61,444.72,12.26;4,100.92,510.30,53.93,9.02;4,82.92,519.31,444.57,12.26;4,100.92,534.00,84.24,9.02;4,82.92,543.01,243.90,12.26;4,82.92,555.19,338.81,12.26;4,82.92,567.43,444.72,12.26;4,100.92,582.12,155.06,9.02;4,82.92,591.13,286.91,12.26;4,82.92,603.31,411.50,12.26;4,82.92,615.55,395.44,12.26;4,70.92,630.24,407.98,9.02"><head></head><label></label><figDesc>of the CLEF multilingual corpus of news documents in 14 European languages (Ad Hoc WSD-Robust task) • Hamshahri Persian newspaper corpus (Ad Hoc Persian task) • Library catalog records in English, French, German plus log files provided by The European Library (Ad Hoc TEL task and LogCLEF) • Flickr web-based image database (iCLEF) • ResPubliQA document collection, a subset of the JRC Acquis corpus of European legislation (QAatCLEF: ResPubliQA) • Transcripts of European parliamentary sessions in English and Spanish, and French news broadcasts (QAatCLEF: QAST) • BELGAPICTURE image collection (ImageCLEFPhoto) • Multilingual collections of Wikipedia documents and images (ImageCLEFwiki) • Articles and images from Radiology and Radiography; IRMA collection for medical image annotation (ImageCLEFmed and medAnnotation) • Dutch and English documentary television programs (VideoCLEF) • Agence France Press (AFP) comparable newswire stories in Arabic, French and English (INFILE) • Patent documents in English, French and German from the European Patent Office (CLEF-IP) Acknowledgements of the valuable contribution of the data providers is given at the end of this paper.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="6,206.70,331.56,182.07,9.02"><head></head><label></label><figDesc>Figure 2. CLEF 2000 -2009: Participation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,70.91,217.14,453.71,164.42"><head></head><label></label><figDesc>The track was coordinated jointly by ISTI-CNR and Padua University, Italy; the University of the Basque Country, Spain; with the collaboration of the Database Research Group, University of Tehran, Iran. In iCLEF, cross-language search capabilities are studied from a user-inclusive perspective. A central research question is how best to assist users when searching information written in unknown languages, rather than how best an algorithm can find information written in languages different from the query language. Since 2006, iCLEF has based its experiments on Flickr, a large-scale,</figDesc><table coords="2,70.92,246.12,203.74,9.02"><row><cell>Interactive Cross-Language Retrieval (iCLEF):</cell></row></table><note coords="2,70.91,292.09,453.57,9.02;2,70.91,303.61,453.58,9.02;2,70.91,315.07,453.63,9.02;2,70.91,326.60,453.57,9.02;2,70.91,338.06,453.34,9.02;2,70.91,349.56,453.49,9.04;2,70.92,361.02,453.52,9.02;2,70.91,372.54,34.18,9.02"><p>web-based image database where image annotations constitute a naturally multilingual folksonomy. In an attempt to encourage greater participation in user-orientated experiments, a new task was designed for 2008 and has had a continuation in 2009. The main novelty has been to focus experiments on a shared analysis of a large search log, generated by iCLEF participants from a single search interface provided by the iCLEF organizers. The focus is, therefore, on search log analysis rather than on system design. The idea is to study the behaviour of users in an (almost) naturalistic search scenario, having a much larger data set than in previous iCLEF campaigns. The track was coordinated by UNED, Madrid, Spain; Sheffield University, UK; Swedish Institute of Computer Science, Sweden.</p></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_0" coords="2,76.20,748.53,143.21,8.10"><p>See http://www.theeuropeanlibrary.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_1" coords="5,76.44,748.41,85.25,8.10"><p>http//direct.dei.unipd.it/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>It would be impossible to run the CLEF evaluation initiative and organize the annual workshops without considerable assistance from many groups. CLEF is organized on a distributed basis, with different research groups being responsible for the running of the various tracks. My gratitude goes to all those who have been involved in the coordination of the 2009 campaigns. A list of the main institutions involved is given in the following pages. Here below, let me thank just some of the people responsible for the coordination of the different tracks. My apologies to all those I have not managed to mention:</p><p>• <rs type="person">Abolfazl AleAhmad</rs>, <rs type="person">Hadi Amiri</rs>, <rs type="person">Eneko Agirre</rs>, <rs type="person">Giorgio Di Nunzio</rs>, <rs type="person">Nicola Ferro</rs>, <rs type="person">Nicolas Moreau</rs>, <rs type="person">Arantxa Otegi</rs> and <rs type="person">Vivien Petras</rs> for the Ad Hoc Track • <rs type="person">Paul Clough</rs>, <rs type="person">Julio Gonzalo</rs> and <rs type="person">Jussi Karlgren</rs> for <rs type="person">iCLEF</rs> • <rs type="person">Iñaki Alegria</rs>, <rs type="person">Davide Buscaldi</rs>, <rs type="person">Luís Miguel Cabral</rs>, <rs type="person">Pere R. Comas</rs>, <rs type="person">Corina Forascu</rs>, <rs type="person">Pamela Forner</rs>, <rs type="person">Olivier Galibert</rs>, <rs type="person">Danilo Giampiccolo</rs>, <rs type="person">Nicolas Moreau</rs>, <rs type="person">Djamel Mostefa</rs>, <rs type="person">Petya Osenova</rs>, <rs type="person">Anselmo Peñas</rs>, <rs type="person">Álvaro Rodrigo</rs>, <rs type="person">Sophie Rosset</rs>, <rs type="person">Paolo Rosso</rs>, <rs type="person">Diana Santos</rs>, <rs type="person">Richard Sutcliff</rs> and <rs type="person">Jordi Turmo</rs> for QA@CLEF • <rs type="person">Brian Bakke</rs>, <rs type="person">Steven Bedrick</rs>, <rs type="person">Barbara Caputo</rs>, <rs type="person">Paul Clough</rs>, <rs type="person">Peter Dunker</rs>, <rs type="person">Thomas Deselaers</rs>, <rs type="person">Thomas Deserno</rs>, <rs type="person">Ivan Eggel</rs>, <rs type="person">Mark Oliver Güld</rs>, <rs type="person">William Hersh</rs>, <rs type="person">Patric Jensfelt</rs>, <rs type="person">Charles E. Kahn Jr.</rs>, <rs type="person">Jana Kludas</rs>, <rs type="person">Jayashree Kalpathy-Cramer</rs>, <rs type="person">Henning Müller</rs>, <rs type="person">Stefanie Nowak</rs>, <rs type="person">Monica Lestari Paramita</rs>, <rs type="person">Andrzej Pronobis</rs>, <rs type="person">Saïd Radhouani</rs>, <rs type="person">Mark Sanderson</rs>, <rs type="person">Tatiana Tommasi</rs>, <rs type="person">Theodora Tsikrika</rs> and <rs type="person">Petra Welter</rs> for <rs type="person">ImageCLEF</rs> • <rs type="person">Romaric Besançon</rs>, <rs type="person">Stéphane Chaudiron</rs>, <rs type="person">Khalid Choukri</rs>, <rs type="person">Meriama Laïb</rs>, <rs type="person">Djamel Mostefa</rs> and <rs type="person">Ismaïl Timimi</rs> for <rs type="person">INFILE</rs> • <rs type="person">Gareth J.F. Jones</rs>, <rs type="person">Martha Larson</rs> and <rs type="person">Eamonn Newman</rs> for <rs type="person">VideoCLEF</rs> • <rs type="person">Florina Piroi</rs>, <rs type="person">Giovanna Roda</rs>, <rs type="person">John Tait</rs> and <rs type="person">Veronika Zenz</rs> for CLEF-IP • <rs type="person">Maristella Agosti</rs>, <rs type="person">Giorgio Di Nunzio</rs>, <rs type="person">Christine Doran</rs>, <rs type="person">Inderjeet Mani</rs>, <rs type="person">Thomas Mandl</rs>, <rs type="person">Julia Maria Schulz</rs> and <rs type="person">Alexander Yeh</rs> for <rs type="person">LogCLEF</rs> • <rs type="person">Nicola Ferro</rs> and <rs type="person">Donna Harman</rs> for <rs type="person">GridCLEF</rs> • <rs type="person">Graeme W. Blackwood</rs>, <rs type="person">William Byrne Mikko Kurimo</rs>, <rs type="person">Ville T. Turunen</rs> and <rs type="person">Sami Virpioja</rs> for MorphoChallenge at CLEF • <rs type="person">Marco Duissin</rs>, <rs type="person">Giorgio Di Nunzio</rs> and <rs type="person">Nicola Ferro</rs> for developing and managing the DIRECT</p><p>infrastructure. I should also like to thank the members of the <rs type="institution">CLEF Steering Committee</rs> who have assisted me with their advice and suggestions throughout this campaign. Furthermore, I gratefully acknowledge the support of all the data providers and copyright holders. Without their contribution, this evaluation activity would be impossible. Finally, I should like to express my gratitude to <rs type="person">Francesca Borri</rs> and <rs type="person">Alessandro Nardi</rs> in Pisa and <rs type="person">Giannis Tsakonas</rs> in Corfu for their assistance in the organisation of the CLEF 2009 Workshop.</p></div>
			</div>			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CLEF Steering Committee</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Providers</head><p>The support of all the data providers and copyright holders that have contributed to the creation of the CLEF test collections over the years is gratefully acknowledged, and in particular:</p><p>• The Los Angeles Times, for the American-English newspaper collection.</p><p>• SMG Newspapers (The Herald) for the British-English newspaper collection. • The British Library, Bibliothèque Nationale de France and the Austrian National Library for the library catalog records forming part of The European Library (TEL) • The European Library (TEL) for use of TEL log files • Tumba! web search engine of the Faculdade de Ciências da Universidade de Lisboa (FCUL), Portugal, for logfile querying • InformationsZentrum Sozialwissen-schaften, Bonn, for the GIRT social science database. </p></div>			</div>
			<div type="references">

				<listBibl/>
			</div>
		</back>
	</text>
</TEI>
