<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,178.29,148.72,71.48,15.51;1,277.74,148.72,147.04,15.51">SZTAKI</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,151.55,182.52,65.62,9.62"><forename type="first">Bálint</forename><surname>Daróczy</surname></persName>
							<email>daroczyb@ilab.sztaki.hu</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,230.45,182.52,58.11,9.62"><forename type="first">István</forename><surname>Petrás</surname></persName>
							<email>petras@ilab.sztaki.hu</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,301.85,182.52,83.56,9.62"><forename type="first">András</forename><forename type="middle">A</forename><surname>Benczúr</surname></persName>
							<email>benczur@ilab.sztaki.hu</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,398.68,182.52,52.77,9.62"><forename type="first">Zsolt</forename><surname>Fekete</surname></persName>
							<email>zsfekete@ilab.sztaki.hu</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,191.79,196.47,72.68,9.62"><forename type="first">Dávid</forename><surname>Nemeskey</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,277.76,196.47,57.49,9.62"><forename type="first">Dávid</forename><surname>Siklósi</surname></persName>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,348.55,196.47,62.67,9.62"><forename type="first">Zsuzsa</forename><surname>Weiner</surname></persName>
							<email>weiner@ilab.sztaki.hu</email>
							<affiliation key="aff0">
								<orgName type="laboratory" key="lab1">Data Mining and Web search Research Group</orgName>
								<orgName type="laboratory" key="lab2">Informatics Laboratory Computer and Automation Research Institute</orgName>
								<orgName type="institution">Hungarian Academy of Sciences</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,178.29,148.72,71.48,15.51;1,277.74,148.72,147.04,15.51">SZTAKI</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A534A87014AC2CFBE457E70158972149</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Managment]: Languages-Query Languages Measurement, Performance, Experimentation Image segmentation, SIFT, Gaussian mixtures, Okapi BM25, rank aggregation</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Our approach to the ImageCLEF 2009 tasks is based on image segmentation, SIFT keypoints and Okapi BM25 based text retrieval. We use feature vectors to describe the visual content of an image segment, a keypoint or the entire image. The features include color histograms, a shape descriptor as well as a 2D Fourier transform of a segment and an orientation histogram of detected keypoints. We trained a Gaussian Mixture Model (GMM) to cluster the feature vectors extracted from the image segments and keypoints independently. The normalized Fisher gradient vector computed from GMM of SIFT descriptors is a well known technique to represent an image with only one vector. Novel to our method is the combination of Fisher vectors for keypoints with those of the image segments to improve classification accuracy. We introduced training and correlation based combining methods to further improve classification quality.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper we describe our approach to the ImageCLEF Photo, WikiMediaMM and Photo Annotation 2009 evaluation campaigns <ref type="bibr" coords="1,266.47,640.26,15.50,9.62" target="#b10">[11,</ref><ref type="bibr" coords="1,286.21,640.26,12.73,9.62" target="#b16">17,</ref><ref type="bibr" coords="1,303.20,640.26,11.62,9.62" target="#b11">12]</ref>. ImageCLEF Photo is over 498,920 images from Belga News Agency, WikiMediaMM is over the INEX MM image database of approximately 150,000 images and Photo Annotation is over the MIR Flickr 25.000 image dataset. The images are associated with unstructured and noisy textual annotations in English. The first two campaigns are ad-hoc image retrieval tasks: find as many relevant images as possible from the image collections. The third campaign requires image classification into 53 concepts organized in a small ontology.</p><p>The key feature of our solution in both cases is to combine text based and content based image retrieval. Our method is similar to the method we applied last year for ImageCLEF Photo <ref type="bibr" coords="1,499.73,723.95,9.96,9.62" target="#b5">[6]</ref>. Our CBIR method is based on segmentation of the image and on the comparison of features of the segments. We use the Hungarian Academy of Sciences search engine <ref type="bibr" coords="2,416.69,111.79,10.52,9.62" target="#b1">[2]</ref> as our information retrieval system that is based on Okapi BM25 <ref type="bibr" coords="2,293.83,123.75,15.50,9.62" target="#b15">[16]</ref> and query expansion by thesaurus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Image processing</head><p>We transform images into a feature space both in order to define their similarity for ad hoc retrieval and to apply classifiers over them for annotation. For image processing we deploy both SIFT keypoints <ref type="bibr" coords="2,160.53,201.84,10.52,9.62" target="#b7">[8]</ref> and image segmentation <ref type="bibr" coords="2,282.70,201.84,10.52,9.62" target="#b4">[5,</ref><ref type="bibr" coords="2,296.42,201.84,12.73,9.62" target="#b13">14,</ref><ref type="bibr" coords="2,312.36,201.84,7.76,9.62" target="#b3">4,</ref><ref type="bibr" coords="2,323.31,201.84,7.01,9.62" target="#b8">9]</ref>. While SIFT is a standard procedure, we describe our home developed segmenter in more detail below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Segmentation</head><p>Our segmentation algorithm is based on a graph of the image pixels where the eight neighbors of a pixel are connected by edges. The weight of an edge is equal to the Euclidean distance of the pixels in the RGB space. We proceed in the order of increasing edge weight as in a minimum spanning tree algorithm except that we do not merge segments if their size and the similarity of their boundary edges are above a threshold. In the algorithm we use the notation B(S 1 , S 2 ) = average weight of edges connecting S 1 and S 2 .</p><p>The algorithm consists of several iterations of the above minimum spanning tree type procedure. In the first iteration we join sturdily coherent pixels into segments. In further iterations we gradually increase the limits in order to enlarge segments and reach a required number of them.</p><p>The algorithm is called with three parameters τ 1 , τ 2 and τ 3 where the first is initialized to be the difference of the minimal and maximal edge weight in the graph while the other two are chosen to have values 40 and 50, respectively. Algorithm 1 Algorithm Segmentation(I src , τ 1 , τ 2 , τ 3 ).</p><p>for all pixels p do define segment S p = {p} τ (S p ) ← τ 1 {Joining sturdily coherent pixels} for all neighboring pixel pairs (p, q) in the order of edge weight do if S p = S q and min{τ (S p ), τ (S q )} &gt; B(S p , S q ) then</p><formula xml:id="formula_0" coords="2,119.89,524.11,206.44,33.23">S p ← S p ∪ S q τ (S p ) ← τ (S p ) * |S p | + τ (S q ) * |S q | |S p | + |S q | + B(S p , S q )</formula><p>{Segment enlargement} while we reach the prescribed number of segments do for all neighboring pixel pairs (p, q) in the order of edge weight do if S p = S q and min(|S p |, |S q |) &lt; τ 2 and B(S p , S q ) &lt; τ 3 then S p ← S p ∪ S q τ 2 ← τ 2 * 1.2 and τ 3 = τ 3 * 1.3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Feature extraction</head><p>We performed colour, shape, orientation and texture feature extraction over the segments and environment of keypoints of images. This resulted in approximately 0.5 -7 thousand keypoint descriptors in 128 dimensions and in approximately 0.2 thousand segment descriptors in 350 dimensions. The following features were extracted for each segment: mean RGB histogram; mean HSV histogram; normalized RGB histogram; normalized HSV histogram; normalized contrast histogram; shape moments (up to 3 rd order); DFT phase and amplitude. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Image Similarity</head><p>For ad hoc image retrieval we considered segmentation based image similarity only. We extracted features for color histogram, shape and texture information for every segment. In addition we used contrast and 2D Fourier coefficients. The discrete Fourier transformation was sampled along a zig-zag order, i.e. the low frequency components were included. An asymmetric distance function is defined in the above feature space as</p><formula xml:id="formula_1" coords="3,229.14,313.34,144.73,20.87">d(D i , D j ) = k min ℓ dist(S ik , S jℓ )</formula><p>where {S dt : t ≥ 1} denotes the set of segments of image D d . Finally image similarity rank was obtained by substracting the above distance from a sufficiently large constant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">The base text search engine</head><p>We use the Hungarian Academy of Sciences search engine <ref type="bibr" coords="3,346.03,411.82,10.52,9.62" target="#b1">[2]</ref> as our information retrieval system based on Okapi BM25 ranking <ref type="bibr" coords="3,227.12,423.77,15.50,9.62" target="#b15">[16]</ref> with the proximity of query terms taken into account <ref type="bibr" coords="3,483.53,423.77,15.50,9.62" target="#b14">[15,</ref><ref type="bibr" coords="3,502.49,423.77,7.01,9.62" target="#b2">3]</ref>. We deployed stopword removal and stemming by the Porter stemmer. We extended of stop word list with terms such as "photo" or "image" that are frequently used in annotations but does not have a distinctive meaning in this task.</p><p>We applied query term weighting to distinguish definite and rough query terms, the latter may be obtained from the topic description or a thesaurus. We multiplied the BM25 score of each query term by its weight; the sum of the scores gave the final rank.</p><p>We used a linear combination of the text based and image similarity based scores for ad hoc retrieval. We considered the text based score more accurate used small weight for the content based score.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">The WikipediaMM Task</head><p>We preprocessed the annotation text by regular expressions to remove author and copyright information. We made no differentiation between the title and the body of the annotation.</p><p>Since file names often contain relevant keywords and also often as substring, we gave score proportional to the length of the matching substring. Since the indexing of all substrings is infeasible, we only performed this step for those documents that already matched at least one query term in their body.</p><p>For the WikipediaMM task we also deployed query expansion by an online thesaurus<ref type="foot" coords="3,485.20,656.54,3.97,4.98" target="#foot_0">1</ref> . We added groups of synonyms with reduces weight so that only the score of the first few best performing synonym was added to the final score to avoid overscoring long lists of synonyms.</p><p>As seen in Table <ref type="table" coords="3,182.08,693.73,3.87,9.62" target="#tab_0">1</ref>, our CBIR score improved performance in terms of MAP for the price of worse early precision. In this experiment expansion by thesaurus did not help. We preprocessed the annotation text by regular expressions to remove photographer and agency information. This step was in particular important to get rid of the false positives for Belgiumrelated queries as the majority of the images has the Belga News Agency as annotated source.</p><p>Since the annotation was very noisy, we could only approximately cleanse the corpus.</p><p>As the main difference from the WikimediaMM task, since almost all queries were related to names of people or places, we did not deploy the thesaurus. Some of the topics had description (denoted by CT in the topic set as well as in Table <ref type="table" coords="4,315.99,307.25,4.43,9.62" target="#tab_1">2</ref>) that we added with weight 0.1.</p><p>We modified our method to achieve greater diversity within the top 20. For each topic in the ImageCLEF Photo set, relevant images were manually clustered into sub-topics. Evaluation was based on two measures: precision at 20 and cluster recall at rank 20, the percentage of different clusters represented in the top 20.</p><p>The topics of this task were of two different types and we processed them separately in order to optimize for cluster recall. The first set of topics included subtopics; we merged the hit lists of the subtopics by one by one. The last subtopic typically contained terms from other subtopics negated; we fed the query with negation into the retrieval engine.</p><p>The other class of topics had no subtopics; here we proceeded as follows. Let Orig(i) be the ith document (0 ≤ i &lt; 999) and OrigSc(i) be the score of this element on the original list for a given query Q j . We modified these scores by giving penalties to the scores of the documents based on their Kullback-Leibler distance. We used the following algorithm.</p><p>Algorithm 2 Algorithm Re-ranking 1. New (0) = Orig(0) and NewSc(0) = OrigSc(0)</p><formula xml:id="formula_2" coords="4,102.18,511.68,219.18,61.77">2. For i = 1 to 20 (a) New(i) = argmax k {CL i (k) |i &lt;= k &lt; 999} (b) NewSc(i) = max{CL i (k) |i &lt;= k &lt; 999} (c) For ℓ = 0 to (i -1)</formula><p>NewSc(ℓ) = NewSc(ℓ) + c(i)</p><formula xml:id="formula_3" coords="4,104.94,611.74,191.65,14.40">Here CL i (k) = OrigSc(k) + α i-1 l=0 KL(i, k)</formula><p>, where α is a tunable parameter and KL(i, k) is the Kullback-Leibler distance of the ith and kth documents. We used a correction term c(i) at</p><p>Step (2c) to ensure that the new scores will be also in descending order.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">The Photo Annotation Task</head><p>The Photo Annotation data consisted of 5000 annotated training and 13000 test images. Our overall procedure is shown in Fig. <ref type="figure" coords="4,238.47,705.22,3.87,9.62" target="#fig_0">1</ref>. We used the bag-of-visual words (BOV) generative approach in combination with the Fisher kernels method for images <ref type="bibr" coords="4,343.42,717.17,15.51,9.62" target="#b12">[13,</ref><ref type="bibr" coords="4,361.94,717.17,7.01,9.62" target="#b0">1]</ref>. As a first step we extracted low level features from each image. These features include the SIFT key points and the color image segment descriptors such as shape, color histogram as described in Section 2.2. We produced a global visual vocabulary that approximate the per-image distribution of the low level features by clustering with a 64 dimensional GMM. First we obtained a variable number of visual words per image that we processed by Fisher kernels. The resulting kernel from different feature combinations were used as training input for a binary linear classifier (L 2 logistic regression). We used a held-out set to rank each row from the Fisher kernel. After computing the results for all of the 53 concepts, a matrix of dimensionality N × 53 holds the concept detection results, where N is the number of images.</p><p>The concept detection results from different kernels can be combined. We followed two approaches. The first one described in Section 6.2 exploits the connection between the concepts of the training annotation while the second one (Section 6.3) applies another round of training to learn the best combination of the individual concept detectors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1">Feature generation and modeling</head><p>To reduce the size of the feature vectors we modeled them with 64 Gaussians. The classical EM algorithm with diagonal covariance matrix assumption was used for the computation of the mixture parameters. To get fixed sized image descriptors we computed g-1+g×D×2 dimensional normalized Fisher vectors per images <ref type="bibr" coords="5,259.64,733.26,15.50,9.62" target="#b12">[13,</ref><ref type="bibr" coords="5,279.32,733.26,7.01,9.62" target="#b0">1]</ref>, where D = 128 is the dimension of the low level feature vectors. The t × t Fisher kernel matrix contained the L1 distances of all training images from themselves. There are t = 5000 training images. We computed the Fisher kernels for several low level feature type combinations. Such combinations were: SIFT+image segments, SIFT+global image features, etc. We used the resulting Fisher kernels for training binary linear classifiers (L2-regularized logistic regression classifier from the LibLinear package <ref type="bibr" coords="6,448.87,493.22,10.79,9.62" target="#b6">[7]</ref>) for each of the k = 53 concepts. For prediction we used the s × t kernel matrix with the trained linear classifiers, where s = 13000 denotes the number of test images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2">Correlation based combination</head><p>From the annotations of the training images we computed the auto-correlation matrix (Fig. <ref type="figure" coords="6,501.40,563.13,3.87,9.62" target="#fig_1">2</ref>).</p><p>Using this matrix we exploited the common knowledge of annotations about the relationship between the concepts. With this matrix we reweighted the output of the predictors. Let us denote A the t × k annotation matrix. Each entry of A is either 0 or 1. Moreover, let C = [c ij ] be the k × k symmetric correlation matrix where c ij = corr (a i , a j ), a i is the i th column of A, corr (x, y) = cov (x, y) / (std (x) • std (y)) is the normalized correlation coefficient. Let P denote the t × k matrix composed from the outputs of the predictors. Rows correspond to images, while columns correspond to concepts. The combined prediction is computed</p><formula xml:id="formula_4" coords="6,280.50,666.80,41.29,10.39">P C = P C</formula><p>The improvement is shown in Table <ref type="table" coords="6,249.55,687.46,3.87,9.62">3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3">Log-odds based combination</head><p>Our combination of the classifiers is inspired by the log-odds averaging by Lynam and Cormack <ref type="bibr" coords="6,90.00,745.41,14.61,9.62" target="#b9">[10]</ref>. We first made a 10-fold crossvalidation on the training data to score every image by every </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Conclusion</head><p>• For image classification, we successfully combined a pure keypoint based and a region based method, two image processing algorithms that complement each other. Further improvement could be to include the hierarchical relationship of the concepts into the combination procedure that would result in a directed graph to describe Concept A → Concept B relation- • For image retrieval our content based score improved the text score in combination. The use of the thesaurus and other query expansion techniques needs further analysis and refinement.</p><p>• We took minimal effort for optimizing for diversity; while our results were strong in MAP, optimization with stronger parameters could have helped.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="5,208.40,499.75,186.25,9.62;5,148.50,98.96,306.00,396.00"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Our image annotation procedure</figDesc><graphic coords="5,148.50,98.96,306.00,396.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="6,90.00,390.94,423.02,9.62;6,90.00,402.90,422.99,9.62;6,90.00,414.85,422.98,9.62;6,90.00,426.81,283.59,9.62"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The auto-correlation matrix of the training annotation visualized as a graph. This graph was used to re-weight the output of the predictors. Positive weights mean positive correlation between concepts. Connection can be expressed in verbal form, e.g. "Landscape Nature correlates with Trees, Sky, Water, Plants, Clouds as well as with Outdoor "</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="7,90.00,364.54,422.99,9.62;7,90.00,376.50,422.99,9.62;7,90.00,388.45,422.99,9.62;7,90.00,400.41,423.01,9.62;7,90.00,412.37,423.01,9.62;7,90.00,424.32,423.01,9.62;7,90.00,436.28,76.68,9.62;7,90.00,468.10,422.99,9.62;7,90.00,480.06,422.99,9.62;7,90.00,492.01,423.00,9.62;7,90.00,503.97,423.01,9.62;7,90.00,515.92,423.01,9.62;7,90.00,527.87,79.45,9.62"><head>Table 3 :</head><label>3</label><figDesc>Results of the predictors on the test data without and with combinations. Column AUC contains the output of the predictors using SIFT and segmentation feature vectors. Next column shows the results after combining the previous column with the autocorrelation matrix of the training annotation data. "log-odds" column contains the output of the combination of predictors using log-odds. The following prediction methods were combined: segmentation and SIFT, global features only, SIFT only, segmentation only , global and SIFT features, global features and segmentation classifier. Then for every classifier we calculated the log-odds as a feature by taking the logarithm of the fraction of the number of positive images with lower score over the number of negative images with higher score. Finally, we trained a logit-boost classifier over this feature set. The predictors were trained with the following feature sets: segmentation and SIFT (two fine tuned runs); global features only; SIFT only; segmentation only; global and SIFT features; global features and segmentation.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,187.06,118.71,225.55,81.16"><head>Table 1 :</head><label>1</label><figDesc>WikiMediaMM ad hoc search evaluation.</figDesc><table coords="3,187.06,128.47,225.55,71.39"><row><cell></cell><cell>MAP</cell><cell>P10</cell><cell>P20</cell></row><row><cell>Image+Text</cell><cell cols="3">0.1699 0.2867 0.2389</cell></row><row><cell>Text</cell><cell cols="3">0.1676 0.2911 0.2411</cell></row><row><cell cols="4">Image+Text+Thesaurus 0.1604 0.2778 0.2200</cell></row><row><cell>Text+Thesaurus</cell><cell cols="3">0.1583 0.2667 0.2122</cell></row><row><cell>Image</cell><cell cols="3">0.0068 0.0244 0.0144</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,90.00,118.71,391.63,105.01"><head>Table 2 :</head><label>2</label><figDesc>ImageCLEF Photo ad hoc search evaluation.</figDesc><table coords="4,90.00,130.41,391.63,93.31"><row><cell></cell><cell cols="2">F-measure P5</cell><cell>P20</cell><cell>CR5</cell><cell>CR20 MAP</cell></row><row><cell>Text CT</cell><cell>0.6449</cell><cell cols="3">0.5 0.64 0.5106 0.6363 0.49</cell></row><row><cell>Text</cell><cell>0.6394</cell><cell cols="3">0.52 0.68 0.4719 0.6430 0.50</cell></row><row><cell>Image+Text CT</cell><cell>0.6315</cell><cell cols="3">0.49 0.64 0.4319 0.6407 0.48</cell></row><row><cell>Image</cell><cell>0.1727</cell><cell cols="3">0.02 0.03 0.2282 0.2826</cell><cell>0</cell></row><row><cell cols="5">5 The Photo Retrieval Task: Optimizing for Diversity</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,183.00,657.26,233.66,83.09"><head>Table 4</head><label>4</label><figDesc></figDesc><table coords="7,183.00,657.26,233.66,83.09"><row><cell cols="3">: ImageCLEF2009-PhotoAnnotation results</cell></row><row><cell></cell><cell>EER</cell><cell>AUC</cell></row><row><cell>Segmentation</cell><cell cols="2">0.346106 0.707860</cell></row><row><cell>SIFT</cell><cell cols="2">0.322632 0.733264</cell></row><row><cell>SIFT + Segmentation</cell><cell cols="2">0.296315 0.771324</cell></row><row><cell cols="3">SIFT + Segmentation + Cross 0.291718 0.773133</cell></row><row><cell>Log Odds combination</cell><cell cols="2">0.304113 0.746300</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,105.25,724.86,88.79,7.30"><p>http://thesaurus.com/</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,110.48,228.48,402.50,9.62;8,110.47,240.43,331.05,9.62" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,417.31,228.48,95.67,9.62;8,110.47,240.43,65.15,9.62">XRCE&apos;s Participation to ImageCLEF</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Ah-Pine</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Cifarelli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clinchant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Csurka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Renders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,218.54,240.43,191.91,9.62">Working Notes of the 2008 CLEF Workshop</title>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,259.60,402.50,9.62;8,110.47,271.55,402.53,9.62;8,110.47,283.51,301.34,9.62" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,248.74,271.55,243.83,9.62">Searching a small national domain-preliminary report</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>András</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Károly</forename><surname>Benczúr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eszter</forename><surname>Csalogány</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dániel</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tamás</forename><surname>Fogaras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Máté</forename><surname>Sarlós</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eszter</forename><surname>Uher</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Windhager</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,110.47,283.51,268.56,9.62">Proceedings of the 12th World Wide Web Conference (WWW)</title>
		<meeting>the 12th World Wide Web Conference (WWW)</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,302.67,402.52,9.62;8,110.47,314.64,402.53,9.62;8,110.47,326.59,78.60,9.62" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,366.24,302.67,146.75,9.62;8,110.47,314.64,165.18,9.62">Term proximity scoring for ad-hoc retrieval on very large text collections</title>
		<author>
			<persName coords=""><forename type="first">Stefan</forename><surname>Büttcher</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Charles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Brad</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Lushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,297.76,314.64,44.11,9.62">SIGIR &apos;06</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="621" to="622" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,345.76,402.51,9.62;8,110.47,357.71,402.53,9.62;8,110.47,369.67,256.34,9.62" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,432.26,345.76,80.73,9.62;8,110.47,357.71,368.10,9.62">Blobworld: Image segmentation using expectation-maximization and its application to image querying</title>
		<author>
			<persName coords=""><forename type="first">Chad</forename><surname>Carson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Serge</forename><surname>Belongie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hayit</forename><surname>Greenspan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jitendra</forename><surname>Malik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,488.89,357.71,24.11,9.62;8,110.47,369.67,150.37,9.62">IEEE Trans. Pattern Anal. Mach. Intell</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1026" to="1038" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,388.83,402.54,9.62;8,110.47,400.79,169.45,9.62" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,252.52,388.83,256.33,9.62">Image categorization by learning and reasoning with regions</title>
		<author>
			<persName coords=""><forename type="first">Yixin</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><forename type="middle">Z</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,110.47,400.79,90.49,9.62">J. Mach. Learn. Res</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="913" to="939" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,419.95,402.52,9.62;8,110.47,431.91,402.53,9.62;8,110.47,443.87,402.50,9.62;8,110.47,455.83,402.53,9.62;8,110.47,467.78,402.53,9.62;8,110.47,479.73,402.52,9.62;8,110.47,491.69,76.69,9.62" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,213.52,431.91,221.60,9.62">Cross-modal image retrieval with parameter tuning</title>
		<author>
			<persName coords=""><forename type="first">Bálint</forename><surname>Daróczy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Zsolt</forename><surname>Fekete</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mátyás</forename><surname>Brendel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Simon</forename><surname>Rácz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">András</forename><surname>Benczúr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Dávid</forename><surname>Siklósi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Attila</forename><surname>Pereszlényi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,427.80,455.83,85.21,9.62;8,110.47,467.78,402.53,9.62;8,110.47,479.73,76.54,9.62">Evaluating Systems for Multilingual and Multimodal Information Access -9th Workshop of the Cross-Language Evaluation Forum</title>
		<title level="s" coord="8,196.11,479.73,154.66,9.62">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Danilo</forename><surname>Giampiccol</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Vivien</forename><surname>Petras</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Anselmo</forename><surname>Peñas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thomas</forename><surname>Mandl</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Gareth</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nikko</forename><surname>Kurimo</surname></persName>
		</editor>
		<meeting><address><addrLine>Aarhus, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-09">September 2008</date>
		</imprint>
	</monogr>
	<note>printed in 2009</note>
</biblStruct>

<biblStruct coords="8,110.48,510.85,402.54,9.62;8,110.47,522.81,384.80,9.62" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,394.15,510.85,118.87,9.62;8,110.47,522.81,100.19,9.62">LIBLINEAR: A library for large linear classication</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">E</forename><surname>Fan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Hsieh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><forename type="middle">R</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,219.11,522.81,186.95,9.62">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="1871" to="1874" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,541.98,402.51,9.62;8,110.47,553.94,307.52,9.62" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,161.73,541.98,225.23,9.62">Object recognition from local scale-invariant features</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">G</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,405.40,541.98,107.60,9.62;8,110.47,553.94,87.34,9.62">International Conference on Computer Vision</title>
		<meeting><address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1150" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,573.11,402.53,9.62;8,110.47,585.06,402.52,9.62;8,110.47,597.01,374.52,9.62" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,276.75,573.11,232.06,9.62">Image similarity search with compact data structures</title>
		<author>
			<persName coords=""><forename type="first">Qin</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Moses</forename><surname>Charikar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kai</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,123.15,585.06,389.85,9.62;8,110.47,597.01,122.26,9.62">CIKM &apos;04: Proceedings of the Thirteenth ACM International Conference on Information and Knowledge Management</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2004">2004</date>
			<biblScope unit="page" from="208" to="217" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,616.18,402.52,9.62;8,110.47,628.13,402.52,9.62;8,110.47,640.09,90.81,9.62" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,324.80,616.18,108.54,9.62">On-line spam filter fusion</title>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">R</forename><surname>Lynam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Cormack</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">R</forename><surname>Cheriton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,441.09,616.18,71.91,9.62;8,110.47,628.13,398.68,9.62">Proc. of the 29th international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>of the 29th international ACM SIGIR conference on Research and development in information retrieval</meeting>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="123" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,659.25,402.52,9.62;8,110.47,671.22,377.79,9.62" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,271.27,659.25,241.72,9.62;8,110.47,671.22,129.58,9.62">Overview of the CLEF 2009 large scale visual concept detection and annotation task</title>
		<author>
			<persName coords=""><forename type="first">Stefanie</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Dunker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,261.07,671.22,196.10,9.62">Working Notes for the CLEF 2009 Workshop</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,690.39,402.52,9.62;8,110.47,702.34,370.60,9.62" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,312.35,690.39,200.65,9.62;8,110.47,702.34,100.52,9.62">Diversity in photo retrieval: overview of the ImageCLEFPhoto task</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Paramita</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Clough</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,253.87,702.34,196.11,9.62">Working Notes for the CLEF 2009 Workshop</title>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.47,721.51,402.50,9.62;8,110.47,733.46,402.51,9.62;8,110.47,745.41,43.71,9.62" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,239.38,721.51,269.35,9.62">Fisher kernels on visual vocabularies for image categorization</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Perronnin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Dance</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,123.61,733.46,280.38,9.62;8,440.40,733.46,38.99,9.62">IEEE Conference on Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note>CVPR&apos;07</note>
</biblStruct>

<biblStruct coords="9,110.48,111.79,402.52,9.62;9,110.48,123.75,378.43,9.62" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,314.83,111.79,198.17,9.62;9,110.48,123.75,137.14,9.62">Region-based image retrieval using integrated color, shape, and location index</title>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">G</forename><surname>Prasad</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">K</forename><surname>Biswas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">K</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,256.39,123.75,127.34,9.62">Comput. Vis. Image Underst</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="193" to="233" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,143.67,402.52,9.62;9,110.48,155.62,162.07,9.62" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,266.49,143.67,246.51,9.62;9,110.48,155.62,18.63,9.62">Term proximity scoring for keyword-based retrieval systems</title>
		<author>
			<persName coords=""><forename type="first">Yves</forename><surname>Rasolofo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,150.65,155.62,22.21,9.62">ECIR</title>
		<imprint>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="207" to="218" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,175.55,402.52,9.62;9,110.48,187.51,193.59,9.62" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,332.22,175.55,159.59,9.62">Relevance weighting of search terms</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Karen</forename><forename type="middle">Sparck</forename><surname>Jones</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,110.48,187.51,119.26,9.62">Document retrieval systems</title>
		<imprint>
			<biblScope unit="page" from="143" to="160" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,110.48,219.39,402.50,9.62;9,110.48,231.34,266.77,9.62" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,282.12,219.39,230.87,9.62;9,110.48,231.34,18.14,9.62">Overview of the WikipediaMM task at ImageCLEF 2009</title>
		<author>
			<persName coords=""><forename type="first">Theodora</forename><surname>Tsikrika</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jana</forename><surname>Kludas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,150.04,231.34,196.11,9.62">Working Notes for the CLEF 2009 Workshop</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
