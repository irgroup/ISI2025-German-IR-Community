<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,130.83,146.21,341.33,18.08;1,90.00,168.13,422.97,18.08">Medical Image Retrieval and Automatic Annotation: VPA-SABANCI at ImageCLEF 2009</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,120.59,203.19,55.52,10.46"><forename type="first">Devrim</forename><surname>Unay</surname></persName>
							<email>unay@sabanciuniv.edu</email>
						</author>
						<author>
							<persName coords="1,184.41,203.19,69.19,10.46"><forename type="first">Octavian</forename><surname>Soldea</surname></persName>
							<email>octavian@sabanciuniv.edu</email>
						</author>
						<author>
							<persName coords="1,261.34,203.19,98.52,10.46"><forename type="first">Sureyya</forename><surname>Ozogur-Akyuz</surname></persName>
						</author>
						<author>
							<persName coords="1,368.23,203.19,57.56,10.46"><forename type="first">Mujdat</forename><surname>Cetin</surname></persName>
							<email>mcetin@sabanciuniv.edu</email>
						</author>
						<author>
							<persName coords="1,433.54,203.19,48.87,10.46"><forename type="first">Aytul</forename><surname>Ercil</surname></persName>
							<email>aytulercil@sabanciuniv.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Faculty of Engineering Sciences</orgName>
								<orgName type="laboratory">Computer Vision and Pattern Analysis (VPA) Laboratory</orgName>
								<orgName type="institution">Natural</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Sabanci University</orgName>
								<address>
									<settlement>Istanbul</settlement>
									<country key="TR">Turkey</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,130.83,146.21,341.33,18.08;1,90.00,168.13,422.97,18.08">Medical Image Retrieval and Automatic Annotation: VPA-SABANCI at ImageCLEF 2009</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">7024EB87FEC45006523CC1DBEC375336</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>I.4 [Image Processing and Computer Vision]: I.4.7 Feature Measurement</term>
					<term>I.4.10 Image Representation</term>
					<term>I.5 [Pattern Recognition]: I.5.2 Design Methodology</term>
					<term>I.5.4. Applications</term>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software Measurement, Performance, Experimentation Content-based image retrieval, Medical image annotation, Image processing, Evaluation, Hierarchical classification</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Advances in the medical imaging technology has lead to an exponential growth in the number of digital images that needs to be acquired, analyzed, classified, stored and retrieved in medical centers. As a result, medical image classification and retrieval has recently gained high interest in the scientific community. Despite several attempts, such as the yearly-held ImageCLEF Medical Image Annotation Competition, the proposed solutions are still far from being sufficiently accurate for real-life implementations.</p><p>In this paper we summarize the technical details of our experiments for the Im-ageCLEF 2009 medical image annotation task. We use a direct and two hierarchical classification schemes that employ support vector machines and local binary patterns, which are recently developed low-cost texture descriptors. The direct scheme employs a single SVM to automatically annotate X-ray images. The two proposed hierarchical schemes divide the classification task into sub-problems. The first hierarchical scheme exploits ensemble SVMs trained on IRMA sub-codes. The second learns from subgroups of data defined by frequency of classes. Our experiments show that hierarchical annotation of images by training individual SVMs over each IRMA sub-code dominates its rivals in annotation accuracy with increased process time relative to the direct scheme.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>Digital medical images, such as standard radiographs (X-Ray) and computed tomography (CT) images, represent a huge part of the data that need to be stored, archived, retrieved, and shared among medical centers. Manual labeling of this data is not only time consuming, but also errorprone due to inter/intra-observer variations. In order to realize an accurate classification of digital medical images one needs to develop tools that allow high performance automatic image annotation, i.e. a given image is automatically labeled with a text or a code without any user interaction.</p><p>Several attempts in the field of medical images have been performed in the past. For example, the WebMRIS system <ref type="bibr" coords="2,189.42,216.04,10.52,10.46" target="#b2">[3]</ref> aims at retrieving cervical spinal X-Ray images, whereas the ASSERT system <ref type="bibr" coords="2,122.13,228.00,10.52,10.46" target="#b7">[8]</ref> focuses on retrieving CT images of lung. While these efforts consider retrieving a specific body part only, other initiatives have been taken in order to retrieve multiple body parts.</p><p>The ImageCLEF Medical Image Annotation task, run as part of the Cross-Language Evaluation Forum (CLEF) campaign, is a yearly held medical image annotation challenge that aims in automatic classification of an X-Ray image archive containing more than 12,000 images randomly taken from the medical routine. The ImageCLEF Medical Annotation dataset contains images of different body parts of people from different ages, of different genders, under varying viewing angles and with or without pathologies.</p><p>A potent classification system requires the image data to be translated into a more compact and more manageable representation containing descriptive features. Several feature representations have been investigated in the past for such a classification task. Among others, image features, such as average value over the complete image or its sub-regions <ref type="bibr" coords="2,386.86,359.50,10.52,10.46" target="#b6">[7]</ref> and color histograms <ref type="bibr" coords="2,499.71,359.50,9.96,10.46" target="#b3">[4]</ref>, have been investigated. Recently in <ref type="bibr" coords="2,258.31,371.46,9.96,10.46" target="#b1">[2]</ref>, texture features like local binary patterns (LBP) <ref type="bibr" coords="2,502.49,371.46,10.52,10.46" target="#b5">[6]</ref> have been shown to outperform other types of low-level image features in classification of X-Ray images. Subsequently in <ref type="bibr" coords="2,205.87,395.37,14.61,10.46" target="#b9">[10]</ref>, it has been shown that retaining only the relevant features by applying attribute selection on local binary patterns achieves comparable classification accuracies with smaller feature sets, thus leading to reduced processing time and storage space requirements.</p><p>A less investigated path is to exploit from hierarchical organization of medical data, such as the ImageCLEF data labeled by the IRMA coding system, using ensemble classifiers. Accordingly, in this paper we explore the annotation performance of two hierarchical classification schemes based on IRMA sub-codes and frequency of classes, and compare them to the well-known single-classifier scheme over the ImageCLEF-2009 Medical Annotation dataset.</p><p>The paper is organized as follows. Section 2 presents our feature extraction and classification steps in detail. Then, in Section 3 we introduce the image database and the experimental evaluation process performed. And finally, Sections 4 and 5, present corresponding results and our conclusions, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Feature Extraction</head><p>We extract spatially enhanced local binary patterns as features from each image in the database. LBP <ref type="bibr" coords="2,113.18,613.99,10.52,10.46" target="#b5">[6]</ref> is a gray-scale invariant local texture descriptor with low computational complexity. The LBP operator labels image pixels by thresholding a neighborhood of each pixel with the center value and considering the results as a binary number. The neighborhood is formed by a symmetric neighbor set of P pixels on a circle of radius R. Formally, given a pixel at (x c ,y c ), the resulting LBP code can be expressed in the decimal form as follows :</p><formula xml:id="formula_0" coords="2,227.03,683.01,285.97,31.41">LBP P,R (x c , y c ) = P -1 n=0 s(i n -i c )2 n (1)</formula><p>where n runs over the P neighbors of the central pixel, i c and i n are the gray-level values of the central pixel and the neighbor pixel, and s(x) is 1 if x ≥ 0 and 0 otherwise. After labeling an image with a LBP operator, a histogram of the labeled image f l (x, y) can be defined as</p><formula xml:id="formula_1" coords="3,204.64,308.15,22.11,11.35">H i =</formula><p>x,y</p><formula xml:id="formula_2" coords="3,245.57,308.15,263.19,11.35">I(f l (x, y) = i), i = 0, . . . , L -1 (<label>2</label></formula><formula xml:id="formula_3" coords="3,508.76,308.15,4.24,10.46">)</formula><p>where L is the number of different labels produced by the LBP operator, and I(A) is 1 if A is true and 0 otherwise.</p><p>The derived LBP histogram contains information about the distribution of local micro-patterns, such as edges, spots and flat areas, over the image. Following <ref type="bibr" coords="3,351.34,372.27,9.96,10.46" target="#b5">[6]</ref>, not all LBP codes are informative, therefore we use the uniform version of LBP and reduce the number of informative codes from 256 to 59 (58 informative bins + one bin for noisy patterns). As in <ref type="bibr" coords="3,385.50,396.17,9.96,10.46" target="#b1">[2]</ref>, we divide the images into 4x4 non-overlapping sub-regions and concatenate the LBP histograms extracted from each region into a single, spatially enhanced feature histogram (Figure <ref type="figure" coords="3,345.62,420.09,3.87,10.46" target="#fig_0">1</ref>). This step aims at obtaining a more local description of the image.</p><p>Finally, we obtain a total of 944 features per image. In order to avoid domination of attributes with greater numeric ranges over small ones, we linearly scale each feature to [-1,+1] range before presenting them to the classifier.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Image Annotation</head><p>In this work we use a support vector machine (SVM) based learning framework to automatically annotate the images. SVM <ref type="bibr" coords="3,211.05,526.14,10.52,10.46" target="#b0">[1]</ref> is a popular machine learning algorithm that provide good results for general classification tasks in the computer vision and medical domains: e.g. nine of the ten best models in ImageCLEFmed 2006 competition were based on SVM <ref type="bibr" coords="3,407.30,550.05,9.96,10.46" target="#b4">[5]</ref>. In a nutshell, SVM maps data to a higher-dimensional space using kernel functions and performs linear discrimination in that space by simultaneously minimizing the classification error and maximizing the geometric margin between the classes. Among all available kernel functions for data mapping in SVM, Gaussian radial basis function is the most popular choice, and therefore it is used here.In this work we used LibSVM<ref type="foot" coords="3,475.48,608.76,3.97,7.32" target="#foot_0">1</ref> library (version 2.89) for SVM and empirically found its optimum parameters on the dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Direct Annotation Scheme</head><p>In the direct annotation scheme, we classify images by using a single SVM with one versus all multi-class model.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Hierarchical Annotation Schemes</head><p>To the contrary, hierarchical schemes break down the annotation task to sub-problems by dividing the data into subgroups based on 1) IRMA sub-codes (H-1), and 2) frequency of classes (H-2).</p><p>In the IRMA coding system, images are categorized in a hierarchical manner based on four subcodes describing image modality, image orientation, body region examined, and biological system investigated. Accordingly, in our IRMA sub-codes based hierarchical scheme we train a separate SVM for each sub-code and merge their predictions to form the final decision, as illustrated in Figure <ref type="figure" coords="4,121.43,583.97,3.87,10.46" target="#fig_1">2</ref>.</p><p>On the contrary, the second hierarchical scheme successively divides the data into sub-groups based on frequency of classes and trains a separate SVM on each sub-group (Figure <ref type="figure" coords="4,478.24,607.88,3.87,10.46" target="#fig_2">3</ref>). Let L 1 , L 2 , . . . , L n be the set of classes in the training set and m ∈ N be a positive integer parameter. Without loss of generality, assume L 1 , L 2 , . . . , L n are sorted in their decreasing cardinality values. We divide the training set in a sequence clusters</p><formula xml:id="formula_4" coords="4,90.00,643.74,423.01,24.81">C 1 , C 2 , . . . , C k , such that C 1 = {L 1 , L 2 , . . . , L m , U 1 } , C 2 = {L m+1 , L m+2 , . . . , L 2m , U 2 } , where U 1 = n i=m+1 L i , U 2 = n i=2m L i ,</formula><p>and so on, see Figure <ref type="figure" coords="4,187.61,667.65,3.87,10.46" target="#fig_2">3</ref>. For each C i we train a SVM. Let S i be the SVM trained on C i . When classifying, we begin from S 1 . If S 1 suggests one of the L 1 , L 2 , . . . , L m labels, then we consider this result a valid classification. If the result is U 1 , then we proceed further to S 2 . We follow recursively this procedure, until we eventually reach S k , which finishes the classification procedure. Note that we adjust C k to include only L i labels. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,90.01,230.49,423.00,10.46;3,90.00,242.45,329.30,10.46;3,192.53,109.04,217.94,108.00"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: The image is divided into 4x4 non-overlapping sub-regions from which LBP histograms are extracted and concatenated into a single, spatially enhanced histogram.</figDesc><graphic coords="3,192.53,109.04,217.94,108.00" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,90.01,216.09,423.00,10.46;4,90.00,228.05,423.01,10.46;4,136.06,109.33,330.66,93.21"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: Illustration of hierarchical classification based on IRMA sub-codes. A separate SVM is trained for each sub-code, and final decision is formed by concatenating predictions of each SVM.</figDesc><graphic coords="4,136.06,109.33,330.66,93.21" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="4,90.01,439.55,379.39,10.46;4,469.40,443.59,3.97,7.32;4,473.86,439.55,39.14,10.46;4,90.00,451.51,54.82,10.46;4,144.82,455.54,3.97,7.32;4,149.29,451.51,11.20,10.46;4,160.50,455.54,3.97,7.32;4,164.97,451.51,11.22,10.46;4,176.20,455.54,3.97,7.32;4,180.67,451.51,107.44,10.46;4,288.11,455.54,3.97,7.32;4,292.58,451.51,65.89,10.46;4,358.47,455.54,3.97,7.32;4,362.94,451.51,11.20,10.46;4,374.14,455.54,3.97,7.32;4,378.62,451.51,11.22,10.46;4,389.85,455.54,3.97,7.32;4,394.32,451.51,57.61,10.46;4,89.31,259.67,424.39,166.97"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Illustration of second hierarchical SVM scheme for m = 2. The first cluster, C 1 , consists of classes {L 1 , L 2 , U 1 } . The second cluster, C 2 , consists of {L 3 , L 4 , U 2 } , and so on.</figDesc><graphic coords="4,89.31,259.67,424.39,166.97" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="6,176.91,660.19,18.40,10.46;6,267.19,660.19,158.90,10.46;6,176.91,672.54,97.88,10.46;6,321.68,672.54,5.82,10.46;6,388.16,672.54,9.66,10.46;6,176.91,684.50,106.04,10.46;6,319.19,684.50,10.81,10.46;6,388.16,684.50,9.66,10.46;6,176.91,696.45,106.04,10.46;6,318.93,696.45,11.32,10.46;6,388.15,696.45,9.66,10.46;6,90.01,718.31,423.00,10.46;6,90.00,730.27,322.07,10.46;6,416.79,728.37,32.03,7.32;6,429.27,736.25,7.07,7.32;6,453.81,730.27,59.19,10.46;6,90.00,742.22,318.41,10.46"><head>Table 4 :</head><label>4</label><figDesc>Computational expense of significant VPA-SABANCI runs for testing on a PC with 2.40GHz processor and 6GB RAM. T = 1.83min, M = 140MB, and k = #classes m with m being the split parameter defined in Section 2.2.2. Typically, k &gt; 4 in our case.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,105.24,695.35,201.26,8.37"><p>Available at http://www.csie.ntu.edu.tw/ cjlin/libsvm</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The aim is to automatically classify the test set using four different label sets including 57 to 193 distinct classes. A more detailed explanation of the database and the tasks can be found in <ref type="bibr" coords="5,492.24,313.23,9.96,10.46" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Evaluation</head><p>We evaluate our SVM-based learning using two schemes depending on the availability of test data labels: 1)5-fold cross validation if test data labels are missing, and 2)ImageCLEF error counting scheme, otherwise. In the former scheme, the training database is partitioned into five subsets. Each subset is used once for testing while the rest are used for training, and the final result is assigned as the average of the five validations. Note that for each validation all classes were equally divided among the folds. We measure the overall classification performance using accuracy, which is the number of correct predictions divided by the total number of images. To the contrary, the error counting scheme is introduced by the contest organizers to compare all runs submitted. Further details on this scheme can be found in <ref type="bibr" coords="5,296.54,455.14,9.96,10.46" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Runs Submitted</head><p>As Computer Vision and Pattern Analysis (VPA) Laboratory of Sabanci University, we submitted three different runs to the ImageCLEF 2009 medical image annotation task. One obtained by the direct scheme (VPA-SABANCI-1), and two with the hierarchical schemes (VPA-SABANCI-2 and -3). For each run, the optimum parameter setting was realized by trial-and-error.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>In this section, we present the results obtained by the proposed annotation schemes. In Table <ref type="table" coords="5,508.02,592.06,4.98,10.46">1</ref> we observe the results realized on the training database with 5-fold cross-validation. Hierarchical scheme based on IRMA sub-codes clearly outperforms the others, especially in terms of the 2007, 2008 and overall accuracies.</p><p>Table <ref type="table" coords="5,132.39,639.87,4.98,10.46">2</ref> provides a detailed performance comparison of the direct scheme and the IRMA subcodes based hierarchical one over 2007 and 2008 labels. Simplifying the classification task by training a separate SVM over each sub-code, considerably improves the final accuracy relative to the usage of a single SVM. Furthermore, 2008 accuracies of individual SVMs excel those of 2007 despite higher number of classes (thus a more difficult classification problem). The underlying reason for this observation may be attributed to the more realistic labels of 2008.</p><p>In Table <ref type="table" coords="5,144.15,711.61,4.98,10.46">3</ref> we present the results achieved on the test dataset in terms of prediction errors. As observed, IRMA sub-codes based hierarchical scheme (H-1) outperforms its rivals again. With this performance, VPA-SABANCI-2 run is ranked 7 th among 18 runs submitted to the competition. Table <ref type="table" coords="6,137.21,325.50,4.98,10.46">4</ref> demonstrates the computational requirements of the proposed schemes for testing. As observed, hierarchical schemes require over 4-fold resources than the direct scheme on a single processor architecture. Nevertheless, this additional requirement can be canceled out by parallel processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>In this paper we have introduced a classification work with the aim of automatically annotating X-Ray images. We have explored the annotation performances of two hierarchical classification schemes based on individual SVMs trained on IRMA sub-codes and frequency of classes, and compared the results with the popular single-classifier scheme. Our experiments on the ImageCLEF-2009 Medical Annotation database revealed that breaking the annotation problem down to subproblems by training individual SVMs over each IRMA sub-code outperforms its rivals in terms of annotation accuracy with the compromise of increased computational expense.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="6,110.48,542.50,402.52,10.46;6,110.48,554.46,201.50,10.46" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,184.01,542.50,265.62,10.46">A tutorial on support vector machines for pattern recognition</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J C</forename><surname>Burges</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,457.85,542.50,55.15,10.46;6,110.48,554.46,109.58,10.46">Data Mining and Knowledge Discovery</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="121" to="167" />
			<date type="published" when="1998">1998</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,574.22,402.52,10.46;6,110.48,586.18,402.53,10.46;6,110.48,598.14,120.32,10.46" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,275.95,574.22,219.07,10.46">Automatic detection of body parts in x-ray images</title>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Jacquet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Jeanne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Unay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,110.48,586.18,229.69,10.46;6,375.37,586.18,58.55,10.46">Mathematical Methods in Biomedical Image Analysis</title>
		<imprint>
			<publisher>IEEE Computer Society Workshop on</publisher>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
	<note>MMBIA 2009</note>
</biblStruct>

<biblStruct coords="6,110.48,617.91,402.54,10.46;6,110.48,629.86,402.53,10.46;7,110.48,110.53,402.52,10.46;7,110.48,122.49,110.03,10.46" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,465.26,617.91,47.75,10.46;6,110.48,629.86,202.57,10.46">WebMIRS: web-based medical information retrieval system</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">R</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">R</forename><surname>Pillemer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">C</forename><surname>Lawrence</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G.-H</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Neve</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">R</forename><surname>Thoma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,482.44,629.86,30.56,10.46;7,110.48,110.53,308.91,10.46">Society of Photo-Optical Instrumentation Engineers (SPIE) Conference Series</title>
		<editor>
			<persName><forename type="first">I</forename><forename type="middle">K</forename><surname>Sethi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Jain</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="1997-12">December 1997</date>
			<biblScope unit="volume">3312</biblScope>
			<biblScope unit="page" from="392" to="403" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,142.41,402.53,10.46;7,110.48,154.37,246.19,10.46" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,316.63,142.41,196.38,10.46;7,110.48,154.37,53.83,10.46">Multilevel feature extraction and x-ray image classification</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Mueen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">Sapian</forename><surname>Baba</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zainuddin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,172.57,154.37,82.37,10.46">J. Applied Sciences</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1224" to="1229" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,174.29,402.53,10.46;7,110.48,186.26,402.52,10.46;7,110.48,198.21,266.40,10.46" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,426.38,174.29,86.63,10.46;7,110.48,186.26,271.15,10.46">Overview of the imageclefmed 2006 medical retrieval and medical annotation tasks</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deserno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,400.66,186.26,112.34,10.46;7,110.48,198.21,168.11,10.46">Evaluation of Multilingual and Multi-modal Information Retrieval</title>
		<imprint>
			<date type="published" when="2007">2007</date>
			<biblScope unit="page" from="595" to="608" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,218.13,402.54,10.46;7,110.48,230.09,402.53,10.46;7,110.48,242.04,192.76,10.46" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="7,301.46,218.13,211.56,10.46;7,110.48,230.09,204.96,10.46">Multiresolution gray-scale and rotation invariant texture classification with local binary patterns</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Pietikainen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Maenpaa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,324.21,230.09,184.77,10.46;7,110.48,242.04,95.85,10.46">Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="971" to="987" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note>IEEE Transactions on</note>
</biblStruct>

<biblStruct coords="7,110.48,261.97,402.52,10.46;7,110.48,273.92,402.52,10.46;7,110.48,285.88,229.49,10.46" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,334.81,261.97,178.19,10.46;7,110.48,273.92,332.98,10.46">Medical image retrieval with probabilistic multi-class support vector machine classifiers and adaptive similarity fusion</title>
		<author>
			<persName coords=""><forename type="middle">M</forename><surname>Md</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">C</forename><surname>Rahman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Desai</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Bhattacharya</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,453.81,273.92,59.20,10.46;7,110.48,285.88,130.82,10.46">Computerized Medical Imaging and Graphics</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="95" to="108" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,305.81,402.53,10.46;7,110.48,317.76,402.52,10.46;7,110.48,329.72,170.63,10.46" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,473.61,305.81,39.40,10.46;7,110.48,317.76,335.27,10.46">Assert: a physician-in-the-loop content-based retrieval system for hrct image databases</title>
		<author>
			<persName coords=""><forename type="first">C.-R</forename><surname>Shyu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">E</forename><surname>Brodley</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C</forename><surname>Kak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kosaka</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">M</forename><surname>Aisen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">S</forename><surname>Broderick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,454.67,317.76,58.33,10.46;7,110.48,329.72,65.44,10.46">Comput. Vis. Image Underst</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="111" to="132" />
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,349.64,402.52,10.46;7,110.48,361.60,317.23,10.46" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,355.20,349.64,157.80,10.46;7,110.48,361.60,99.93,10.46">Overview of the CLEF 2009 medical image annotation track</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tommasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Welter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">M</forename><surname>Deserno</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,217.88,361.60,111.91,10.46">CLEF working notes 2009</title>
		<meeting><address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,381.52,402.53,10.46;7,110.48,393.47,402.54,10.46;7,110.48,405.43,317.53,10.46" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,340.71,381.52,172.29,10.46;7,110.48,393.47,139.70,10.46">Automatic Annotation of X-ray Images: A Study on Attribute Selection</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Unay</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Soldea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ekin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Cetin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Ercil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,275.52,393.47,237.50,10.46;7,110.48,405.43,286.09,10.46">Medical Content-based Retrieval for Clinical Decision Support (MCBR-CDS) Workshop in conjunction with MICCAI&apos;09</title>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
