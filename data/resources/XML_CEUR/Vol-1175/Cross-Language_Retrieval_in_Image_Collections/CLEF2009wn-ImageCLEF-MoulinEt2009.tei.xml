<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,147.08,115.93,321.32,14.35;1,291.54,133.87,32.32,14.35">Combining text/image in WikipediaMM task 2009</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,138.94,171.79,79.72,9.96"><forename type="first">Christophe</forename><surname>Moulin</surname></persName>
							<email>christophe.moulin@univ-st-etienne.fr</email>
						</author>
						<author>
							<persName coords="1,226.78,171.79,52.28,9.96"><forename type="first">Cécile</forename><surname>Barat</surname></persName>
							<email>cecile.barat@univ-st-etienne.fr</email>
						</author>
						<author>
							<persName coords="1,286.99,171.79,68.60,9.96"><forename type="first">Cédric</forename><surname>Lemaître</surname></persName>
							<email>cedric.lemaitre@univ-st-etienne.fr</email>
						</author>
						<author>
							<persName coords="1,363.56,171.79,57.20,9.96"><forename type="first">Mathias</forename><surname>Géry</surname></persName>
							<email>mathias.gery@univ-st-etienne.fr</email>
						</author>
						<author>
							<persName coords="1,428.76,171.79,47.65,9.96;1,244.23,183.74,36.77,9.96"><forename type="first">Christophe</forename><surname>Ducottet</surname></persName>
							<email>ducottet@univ-st-etienne.fr</email>
						</author>
						<author>
							<persName coords="1,288.93,183.74,82.20,9.96"><forename type="first">Christine</forename><surname>Largeron</surname></persName>
							<email>largeron@univ-st-etienne.fr</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Université de Lyon</orgName>
								<address>
									<postCode>F-69003</postCode>
									<settlement>Lyon</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">CNRS UMR5516</orgName>
								<orgName type="institution">Université de Saint-Étienne</orgName>
								<address>
									<postCode>F-42000</postCode>
									<settlement>Saint-Étienne</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="laboratory">Laboratoire Hubert Curien</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,147.08,115.93,321.32,14.35;1,291.54,133.87,32.32,14.35">Combining text/image in WikipediaMM task 2009</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9E407DD78824D55D76BA7BA5A2095C5F</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper reports our multimedia information retrieval experiments carried out for the ImageCLEF track 2009. In 2008, we proposed a multimedia document model defined as a vector of textual and visual terms weighted using a tf.idf approch <ref type="bibr" coords="1,345.97,322.38,9.20,8.97" target="#b4">[5]</ref>. For our second participation, our goal was to improve this previous model in the following ways: 1) use of additional information for the textual part (legend and image bounding text extracted from the original documents, 2) use of different image detectors and descriptors, 3) new text / image combination approach. Results allow to evaluate the benefits of these different improvements.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>ImageCLEFwiki is a multimedia collection where each document is composed of text and one image. User needs are represented by queries ("topics"), which are also multimedia. Therefore, a multimedia document model is necessary to handle such a collection. In 2008, we proposed a first model that combines text and image information for multimedia retrieval <ref type="bibr" coords="1,322.40,492.53,9.96,9.96" target="#b4">[5]</ref>. This year, we improve our model adding textual information and using different detectors and descriptors for the visual information. Moreover we use a linear combination to merge our textual and visual results. After presenting our model, we will explain the submitted runs and the obtained results. We will finish by introducing our future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Visual and textual document model</head><p>The document model we defined for ImageCLEF 2008 lets us rank documents depending on the query using different methods. Firstly, we explain the key features of our approach to rank documents according to a query using only textual information. Secondly, we describe how we extend the method to handle the visual information. Finally, we present our method for combining textual and visual results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Textual representation model</head><p>As in the vector space model introducted by Salton et al. <ref type="bibr" coords="2,398.59,137.91,9.96,9.96" target="#b6">[7]</ref>, we represent a document d i as a vector of weights w i,j . Each w i,j corresponds to the importance of the term t j in the document d i computed by multiplying tf i,j and idf j , where tf i,j is the term frequency that characterizes the frequency of the term t j in the document d i . The idf j is the inverse document frequency that quantifies the importance of the term t j over the corpus of documents. w i,j is high when the term t j is frequent in the document d i but rare in the others. We use tf i,j and idf j defined in the Okapi formula by Robertson et al <ref type="bibr" coords="2,367.51,221.60,10.51,9.96" target="#b5">[6]</ref> by :</p><formula xml:id="formula_0" coords="2,240.33,242.21,133.50,27.59">tf i,j = k 1 n i,j n i,j + k 2 (1 -b + b |di| davg )</formula><p>where n i,j is the occurrence of the term t j in the document d i , |d i | the size of the document d i and d avg the average size of all documents in the corpus and k 1 , k 2 and b are three constants.</p><formula xml:id="formula_1" coords="2,230.32,325.08,153.52,23.97">idf j = log |D| -|{d i |u j ∈ d i }| + 0.5 |{d i |t j ∈ d i }| + 0.5</formula><p>where |D| is the size of the corpus and |{d i |t j ∈ d i }| the number of documents where the term t j occurs at least one time.</p><p>If we consider a query q k as a short document, we can represent it as a vector of weights. A score is then computed between the query q k and a document d i as shown in table <ref type="table" coords="2,229.25,403.44,3.87,9.96">1</ref>. The main difference between score 1 and score 2 is the representation of the query. In the first score, the weight of the query is defined by its tf only while in the second score the weight is equal to tf.idf . Note that for tf k,j , b = 0 because |d k | and |d avg | are not defined for a query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Scoring</head><p>Parameters Parameters tfi,j tf k,j score 1 (q k , di) = k1 = 2.2 k1 = 8 <ref type="table" coords="2,215.50,567.15,4.13,6.38">1</ref>. Scoring equations and their default parameters <ref type="bibr" coords="2,412.45,566.70,12.19,8.97" target="#b7">[8]</ref>.</p><formula xml:id="formula_2" coords="2,186.61,506.71,197.74,66.83">t j ∈q k tfi,jidfjtf k,j k2 = 1.2 k2 = 7 b = 0.75 b = 0 score 2 (q k , di) = k1 = 1 k1 = 1 t j ∈q k tfi,jidfjtf k,j idfj k2 = 1 k2 = 1 b = 0.5 b = 0 Table</formula><p>Different sources of text are available. The legend provided with images is often very short and sometimes useless: for example, when the text deals with the copyright of the image or when it gives details about the user who uploaded the image. In order to gain information, we aim at using the original text extracted from the wikipedia documents in which images appear. We consider a text fragment aroung the image. The size of the window is tuned using wikipediaMM 2008 collection as a training collection. We add this text to the legend of the image and we index both the added text and the original legend. The indexing is performed with the Lemur software <ref type="bibr" coords="3,296.43,166.25,12.26,9.96" target="#b7">[8]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Visual representation model</head><p>In order to combine the visual information with the textual one, we also represent images as a vector of weights. Provided we are able to extract visual words from images, it is possible to use the tf.idf formula in the same way as in the textual model. It is therefore necessary to create a visual vocabulary V = {v 1 , ..., v j , ..., v |V | } as in <ref type="bibr" coords="3,266.15,275.81,9.96,9.96" target="#b1">[2]</ref>. For that purpose, we use 3 different descriptors. The first one (meanstd) is the same as in <ref type="bibr" coords="3,349.30,287.77,9.96,9.96" target="#b4">[5]</ref>. Each image is partitioned into 16x16 cells. Each cell is described by a six dimensional vector which corresponds to the mean and the standard deviation of where R, G and B are the red, green and blue components of the cell. The second (named sif t 1 ) and third (named sif t 2 ) descriptors are based on the well known sift descriptor <ref type="bibr" coords="3,230.24,347.54,9.96,9.96" target="#b2">[3]</ref>. The sif t 1 firstly detects regions of interest using the MSER method as in <ref type="bibr" coords="3,225.44,359.50,10.51,9.96" target="#b3">[4]</ref> while the sif t 2 one uses a regular partitioning as in the meanstd descriptor.</p><p>For each of our 3 descriptors, we apply a k-means algorithm <ref type="bibr" coords="3,425.19,384.61,10.51,9.96" target="#b0">[1]</ref> to obtain a vocabulary of 10'000 visual terms. Each visual term represents a cluster of feature vectors.</p><p>Then, each image can be represented using a vector of visual terms. Local features are first calculated using one of the 3 descriptors. Then visual terms are determined by seeking, for each feature, the closest visual term (according to the euclidian distance) in the corresponding visual vocabulary.</p><p>In the same way as for textual words, the weight of each visual term is computed using a tf.idf approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Combination</head><p>In order to combine textual and visual results we use two different methods. The first one is a simple intersection between the results obtained with the textual query and with the visual one. The second one corresponds to a linear combination between the textual and the visual scores.</p><formula xml:id="formula_3" coords="3,189.61,608.93,236.13,10.39">score(q k , d i ) = αscore V (q k , d i ) + (1 -α)score T (q k , d i )</formula><p>The α parameter lets us add more or less visual information. We calculate its optimal value using the queries from the ImageCLEFwiki 2008 track as a training set.</p><p>Using the model described in the previous section, we present runs submitted to ImageCLEFwiki and the results we obtained. All the runs are entirely automatic and are summarized on table <ref type="table" coords="4,428.22,523.39,3.87,9.96" target="#tab_0">2</ref>. We define a baseline, LaHC 1, that corresponds to a pure text model. It uses only textual terms for the query and scoring of documents. We calculate the score 1 for each image using terms of the textual content. The image name or bounding characters are not considered. We do not use neither feedback nor query expansion. Since score 1 is applied, the query terms are weighted with their frequency tf .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Submitted runs</head><p>Using only the text, we perform 3 other runs: the LaHC 2 is the same as the baseline except that the query is represented by its tf.idf rather than its tf . The LaHC 9 and LaHC 10 are two other text only runs that make use of the bounding text around the image in the original wikipedia document. The LaHC 9 adds 100 characters before and after the image while the LaHC 10 adds 50 characters.</p><p>All other runs exploit both the textual and the visual information of documents. The LaHC 3, LaHC 4 and LaHC 8 are obtained after an intersection of the text only query results (LaHC 2) and the image query using the meanstd, the sif t 1 and the sif t 2 descriptors. The other runs are obtained from a linear combination of the textual and the visual scores. LaHC 5, LaHC 6, LaHC 7 and LaHC 13 use the textual scores of LaHC 2 and the visual scores of a visual descriptor (meanstd, sif t 1 and sif t 2 ). LaHC 11 and LaHC 12 combine the textual scores of LaHC 9 and LaHC 10 with the visual scores of the meanstd descriptor.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>All the obtained results are summarized in Table <ref type="table" coords="5,356.11,283.76,3.87,9.96" target="#tab_1">3</ref>. On the whole results, our team ranks 2nd on 8 participants<ref type="foot" coords="5,279.59,294.87,3.97,5.52" target="#foot_0">1</ref> . As we can see, the best results are obtained when we combine the image bounding text and the meanstd descriptor. We could have obtained better results if we had combined the image bounding text and the sif t 2 descriptor. Indeed, comparing results of text-image runs LaHC 6, LaHC 7 and LaHC 13, we can notice that the best visual descriptor is sif t 2 , followed by meanstd and sif t 1 . The last three results obtained after an intersection are the worst but if we compare them in term of precision, they are the best ones. Indeed, one document over six is relevant. As a rule, combining the textual information with the visual one always improves the results and return more relevant documents which is very encouraging. In this article we proposed improvements to our multimedia model we introduced in <ref type="bibr" coords="6,146.31,154.30,9.96,9.96" target="#b4">[5]</ref>. The first one was to use image bounding text extracted from the original documents, the second was to use sift based image descriptors for the visual part and the third one was to add a text/image combination approach. A series of thirteen runs was submitted using the ImageCLEFwiki 2009 collection. The first analysis of the results allowed to make the three following remarks. It's better to use the image bounding text than the legend only. The sift descriptor is better than our previous color descriptor provided it is calculated on a regular partitioning. The text-image combination is a winning strategy which can be implemented by linear combination of textual and visual scores.</p><p>For future work, we aim to combine the textual information with more than just one visual descriptor. Moreover as the visual information importance depends on the query, we also plan to learn a different α parameter for each query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Acknowledgements</head><p>This work was partly supported by the LIMA project<ref type="foot" coords="6,365.88,340.75,3.97,5.52" target="#foot_1">2</ref> and the Web Intelligence project<ref type="foot" coords="6,165.50,352.70,3.97,5.52" target="#foot_2">3</ref> which are 2 Rhône-Alpes region projects of ISLE cluster<ref type="foot" coords="6,419.18,352.70,3.97,5.52" target="#foot_3">4</ref> .</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,140.80,234.02,339.78,253.20"><head>Table 2 .</head><label>2</label><figDesc>LaHC 5 run TXTIMG Meanstd 0.015 score 2 legend meanstd α= 0.015 LaHC 6 run TXTIMG Meanstd 0.025 score 2 legend meanstd α= 0.025 LaHC 11 run TXTIMG 100 3 1 5 meanstd score 2 100 char meanstd α= 0.025 LaHC 12 run TXTIMG 50 3 1 5 meanstd score 2 50 char meanstd α= 0.025 LaHC 13 run TXTIMG Siftdense 0.084 score 2 legend Presentation of the runs</figDesc><table coords="4,140.80,234.02,333.79,156.61"><row><cell>run id</cell><cell>run</cell><cell>score</cell><cell>text</cell><cell cols="2">image combination</cell></row><row><cell>LaHC 1</cell><cell>LaHC TXT okapi</cell><cell cols="2">score 1 legend</cell><cell>-</cell><cell>-</cell></row><row><cell>LaHC 2</cell><cell>LaHC TXT tfidf</cell><cell cols="2">score 2 legend</cell><cell>-</cell><cell>-</cell></row><row><cell cols="6">LaHC 3 run inter TXT IMG Meanstd score 2 legend meanstd intersection</cell></row><row><cell>LaHC 4</cell><cell>run inter TXT IMG Sift</cell><cell cols="2">score 2 legend</cell><cell cols="2">sif t1 intersection</cell></row><row><cell>LaHC 7</cell><cell>run TXTIMG Sift 0.012</cell><cell cols="2">score 2 legend</cell><cell>sif t1</cell><cell>α= 0.012</cell></row><row><cell cols="4">LaHC 8 run inter TXT IMG Siftdense score 2 legend</cell><cell cols="2">sif t2 intersection</cell></row><row><cell>LaHC 9</cell><cell>run TXT 100 3 1 5</cell><cell cols="3">score 2 100 char legend</cell><cell>-</cell></row><row><cell>LaHC 10</cell><cell>run TXT 50 3 1 5</cell><cell cols="3">score 2 50 char legend</cell><cell>-</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>sif t2</cell><cell>α= 0.084</cell></row></table><note coords="4,141.42,402.53,205.93,8.97;4,141.42,413.50,167.76,8.97;4,141.42,424.45,184.17,8.97;4,141.42,435.41,154.04,8.97;4,141.42,446.37,339.16,8.97;4,151.70,457.33,84.50,8.97"><p>meanstd: regular partitioning + color descriptor sif t1: MSER detector + sift descriptor sif t2: regular partitioning + sift descriptor legend: text of the image document n char: size (n characters) of the text window around the image in the original wikipedia documents</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,173.93,439.52,267.52,169.52"><head>Table 3 .</head><label>3</label><figDesc>Presentation of the results</figDesc><table coords="5,173.93,439.52,267.52,158.60"><row><cell>rank</cell><cell>run</cell><cell cols="2">map num ret num rel ret</cell></row><row><cell cols="3">5 run TXTIMG 100 3 1 5 meanstd 0.2178 44993</cell><cell>1213</cell></row><row><cell cols="3">6 run TXTIMG 50 3 1 5 meanstd 0.2148 44993</cell><cell>1218</cell></row><row><cell>14</cell><cell cols="2">run TXTIMG Siftdense 0.084 0.1903 44993</cell><cell>1212</cell></row><row><cell>15</cell><cell>run TXT 100 3 1 5</cell><cell>0.1890 38004</cell><cell>1205</cell></row><row><cell>16</cell><cell>run TXT 50 3 1 5</cell><cell>0.1880 37041</cell><cell>1198</cell></row><row><cell>20</cell><cell cols="2">run TXTIMG Meanstd 0.025 0.1845 44993</cell><cell>1208</cell></row><row><cell>21</cell><cell>run TXTIMG Sift 0.012</cell><cell>0.1807 44995</cell><cell>1200</cell></row><row><cell>24</cell><cell cols="2">run TXTIMG Meanstd 0.015 0.1792 44993</cell><cell>1213</cell></row><row><cell>33</cell><cell>LaHC TXT tfidf</cell><cell>0.1667 35611</cell><cell>1192</cell></row><row><cell>44</cell><cell>LaHC TXT okapi</cell><cell>0.1432 35611</cell><cell>1164</cell></row><row><cell>52</cell><cell cols="2">run inter TXT IMG Siftdense 0.0365 619</cell><cell>142</cell></row><row><cell>53</cell><cell cols="2">run inter TXT IMG Meanstd 0.0338 574</cell><cell>76</cell></row><row><cell>54</cell><cell>run inter TXT IMG Sift</cell><cell>0.0321 637</cell><cell>120</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="5,144.73,656.80,188.79,8.27"><p>http://imageclef.org/2009/wikiMM-results</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="6,144.73,634.38,183.97,8.97"><p>LIMA project: http://liris.cnrs.fr/lima/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="6,144.73,645.34,258.54,8.97"><p>WI project: http://www.web-intelligence-rhone-alpes.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="6,144.73,656.30,192.88,8.97"><p>ISLE cluster: http://ksup-gu.grenet.fr/isle</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="6,138.35,409.09,342.25,8.97;6,146.92,420.05,321.04,8.97" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="6,202.12,409.09,247.34,8.97">Parallel clustering algorithms with application to climatology</title>
		<author>
			<persName coords=""><forename type="first">Halil</forename><surname>Bisgin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<pubPlace>Turkey</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Informatics Institute, Istanbul Technical University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="6,138.35,431.00,342.22,8.97;6,146.92,441.96,222.56,8.97" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,274.67,431.00,201.97,8.97">Creating efficient codebooks for visual recognition</title>
		<author>
			<persName coords=""><forename type="first">Frédéric</forename><surname>Jurie</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bill</forename><surname>Triggs</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,158.43,441.96,183.05,8.97">International Conference on Computer Vision</title>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,452.92,342.24,8.97;6,146.92,463.88,333.78,8.97;6,146.92,474.84,93.23,8.97" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,228.43,452.92,227.20,8.97">Object recognition from local scale-invariant features</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,146.92,463.88,298.46,8.97">Proceedings of the International Conference on Computer Vision ICCV</title>
		<meeting>the International Conference on Computer Vision ICCV<address><addrLine>Corfu</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="page" from="1150" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,485.80,342.22,8.97;6,146.92,496.75,333.68,8.97;6,146.92,507.72,199.37,8.97" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,262.91,496.75,157.06,8.97">A comparison of affine region detectors</title>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Mikolajczyk</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tuytelaars</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Schaffalitzky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Kadir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,428.35,496.75,52.25,8.97;6,146.92,507.72,111.44,8.97">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="43" to="72" />
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,518.68,342.23,8.97;6,146.92,529.63,264.97,8.97" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,189.56,529.63,105.34,8.97">Ujm at imageclefwiki 2008</title>
		<author>
			<persName coords=""><forename type="first">Christophe</forename><surname>Moulin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Cecile</forename><surname>Barat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mathias</forename><surname>Gry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christophe</forename><surname>Ducottet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christine</forename><surname>Largeron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,314.74,529.63,68.90,8.97">ImageCLEF 2008</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,540.59,342.23,8.97;6,146.92,551.56,330.97,8.97" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,210.78,551.56,60.10,8.97">Okapi at trec-3</title>
		<author>
			<persName coords=""><forename type="first">Stephen</forename><forename type="middle">E</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steve</forename><surname>Walker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Micheline</forename><surname>Hancock-Beaulieu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Aarron</forename><surname>Gull</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Marianna</forename><surname>Lau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,290.16,551.56,105.63,8.97">Text REtrieval Conference</title>
		<imprint>
			<date type="published" when="1994">1994</date>
			<biblScope unit="page" from="21" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,562.51,342.20,8.97;6,146.92,573.47,245.27,8.97" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="6,330.47,562.51,150.08,8.97;6,146.92,573.47,32.52,8.97">A vector space model for automatic indexing</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Gerard Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">S</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,187.61,573.47,108.43,8.97">Communations of the ACM</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="613" to="620" />
			<date type="published" when="1975">1975</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,138.35,584.43,342.24,8.97;6,146.92,595.39,175.56,8.97" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="6,185.66,584.43,124.95,8.97">Notes on the lemur tfidf model</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Zhai</surname></persName>
		</author>
		<ptr target="http://www.lemurproject.com" />
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
