<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,119.40,148.63,364.14,15.51;1,241.56,170.59,120.03,15.51">Overview of the CLEF 2009 medical image retrieval track</title>
				<funder ref="#_arbSEFu">
					<orgName type="full">American National Science Foundation</orgName>
					<orgName type="abbreviated">NSF</orgName>
				</funder>
				<funder ref="#_kBE8BwW">
					<orgName type="full">Swiss National Science Foundation (FNS)</orgName>
				</funder>
				<funder ref="#_GrU2SCH">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,100.56,203.02,79.92,10.87"><forename type="first">Henning</forename><surname>Müller</surname></persName>
							<email>henning.mueller@sim.hcuge.ch</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Applied Sciences Western Switzerland (HES-SO)</orgName>
								<address>
									<settlement>Sierre</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University Hospitals and University of Geneva</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,198.96,203.02,144.87,10.87"><forename type="first">Jayashree</forename><surname>Kalpathy-Cramer</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Oregon Health and Science University (OHSU)</orgName>
								<address>
									<settlement>Portland</settlement>
									<region>OR</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,355.80,203.02,54.14,10.87"><forename type="first">Ivan</forename><surname>Eggel</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of Applied Sciences Western Switzerland (HES-SO)</orgName>
								<address>
									<settlement>Sierre</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,421.80,203.02,76.38,10.87"><forename type="first">Steven</forename><surname>Bedrick</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Oregon Health and Science University (OHSU)</orgName>
								<address>
									<settlement>Portland</settlement>
									<region>OR</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,120.00,217.06,81.52,10.87"><forename type="first">Saïd</forename><surname>Radhouani</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Oregon Health and Science University (OHSU)</orgName>
								<address>
									<settlement>Portland</settlement>
									<region>OR</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,213.36,217.06,63.65,10.87"><forename type="first">Brian</forename><surname>Bakke</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Oregon Health and Science University (OHSU)</orgName>
								<address>
									<settlement>Portland</settlement>
									<region>OR</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,288.96,217.06,98.61,10.87"><forename type="first">Charles</forename><forename type="middle">E</forename><surname>Kahn</surname><genName>Jr</genName></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Radiology</orgName>
								<orgName type="institution">Medical College of Wisconsin</orgName>
								<address>
									<settlement>Milwaukee</settlement>
									<region>WI</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,404.04,217.06,74.07,10.87"><forename type="first">William</forename><surname>Hersh</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Oregon Health and Science University (OHSU)</orgName>
								<address>
									<settlement>Portland</settlement>
									<region>OR</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,119.40,148.63,364.14,15.51;1,241.56,170.59,120.03,15.51">Overview of the CLEF 2009 medical image retrieval track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F0F1FB34CCE016ABE57E5795589EACD0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval] : H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries Measurement, Performance, Experimentation Medical image retrieval, image retrieval, multimodal retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>2009 was the sixth year for the ImageCLEF medical retrieval task. Participation was strong again with 38 registered research groups. 17 groups submitted runs and thus participated actively in the tasks. The database in 2009 was similar to the one used in 2008, containing scientific articles from two radiology journals, Radiology and Radiographics. The size of the database was increased to a total of 74,902 images. For each image, captions and access to the full text article through the Medline PMID (PubMed Identifier) were provided. An article's PMID could be used to obtain the officially assigned MeSH (Medical Subject Headings) terms. The collection was entirely in English. However, the topics were, as in previous years, supplied in German, French, and English. Twenty-five image-based topics were provided, of which ten each were visual and mixed and five were textual. In addition, for the first time, 5 case-based topics were provided as an exploratory task. Here the unit of retrieval was intended to be the article and not the image. Case-based topics are designed to be a step closer to the clinical workflow. Clinicians often seek information about patient cases with incomplete information consisting of symptoms, findings, and a set of images. Supplying cases to a clinician from the scientific literature that are similar to the case (s)he is treating can be an important application of image retrieval in the future.</p><p>As in previous years, most groups concentrated on fully automatic retrieval. However, four groups submitted a total of seven manual or interactive runs. The interactive runs submitted this year performed quite well compared to previous years but did not show a substantial increase in performance over the automatic approaches. In previous years, multimodal combinations were the most frequent submissions. However, this year, as in 2008 only about half as many mixed runs as purely textual runs were submitted. Very few fully visual runs were submitted, and again, the ones submitted performed poorly. The best mean average precisions (MAP) were obtained using automatic textual methods. There were mixed feedback runs that had high MAP. The best early precision was also obtained using automatic textual methods, with a few mixed automatic runs also doing well. We had the opportunity to perform multiple judgments on some topics. The kappas used as the metric for inter-rater agreement were mostly quite high (¿0.7). However, one of our judges consistently had low kappas as he was significantly more lenient the colleagues. We evaluated the overall performance of groups using strict and lenient judges and found that there was high correlation even though the absolute values for the metrics were different.</p><p>We also introduced a lung nodule detection task in 2009. This task used the CT slices from the Lung Imaging Data Consortium (LIDC) which included ground truth in the form of manual annotations. The goal of the task was to create algorithms to automatically detect lung nodules. Although there seemed to be significant interest in the task as evidenced by the substantial number of registrations, only two groups submitted results with a proprietary software from a industry participant achieving impressive results.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>ImageCLEF<ref type="foot" coords="2,143.16,363.67,3.97,6.40" target="#foot_0">1</ref>  <ref type="bibr" coords="2,150.96,365.11,10.57,9.62" target="#b0">[1,</ref><ref type="bibr" coords="2,165.00,365.11,7.81,9.62" target="#b1">2,</ref><ref type="bibr" coords="2,176.29,365.11,7.81,9.62" target="#b3">4]</ref> started in 2003 as part of the Cross Language Evaluation Forum (CLEF<ref type="foot" coords="2,505.80,363.67,3.97,6.40" target="#foot_1">2</ref> , <ref type="bibr" coords="2,90.00,376.99,10.31,9.62" target="#b8">[9]</ref>). A medical image retrieval task was added in 2004 and has been held every year since <ref type="bibr" coords="2,488.52,376.99,10.57,9.62" target="#b3">[4,</ref><ref type="bibr" coords="2,502.44,376.99,7.05,9.62" target="#b6">7]</ref>. The main goal of ImageCLEF in the past has been to promote multi-modal information retrieval by combining a variety of media including text and images for more effective information retrieval. As such, it has always contained visual, textual and mixed tasks and sub-tracks. The medical image retrieval track began in 2004 as a primarily visual information retrieval task with a teaching database of 8,000 images. Since then, it progressed to a collection of over 66,000 images from several teaching collections with topics that were best suited for textual, visual and mixed methods. In 2008, images from the medical literature were used for the first time, moving the task one step closer towards applications that can be of interest in clinical scenarios. Several user studies have been performed to study the image searching behaviour of clinicians <ref type="bibr" coords="2,391.21,484.63,10.57,9.62" target="#b4">[5,</ref><ref type="bibr" coords="2,405.13,484.63,7.69,9.62" target="#b5">6,</ref><ref type="bibr" coords="2,416.17,484.63,7.05,9.62" target="#b2">3]</ref>. These studies have been used to create the task and the topics over the years. This year, for the first time, we introduced a case-based retrieval task as we continue to strive for scenarios that more closely resemble actual clinical work-flows.</p><p>This paper reports on the medical retrieval task. Additionally, other papers within ImageCLEF describe the other five tasks of ImageCLEF 2009. More information on the tasks and on how to participate in CLEF can also be found on the ImageCLEF web pages.</p><p>2 Participation, Data Sets, Tasks, Ground Truth This section describes the details concerning the set-up and the participation in the medical retrieval task in 2009. A new management system for participation in ImageCLEF was created to better manage the increasing number of registrations and submissions to the ImageCLEF benchmark in a fully electronic fashion. The interface allowed registrations for particular tasks, provided the links to the description of the data sets available, allowed submission of the results and enabled the final evaluation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Participation</head><p>In 2009, a new record of 85 research groups registered for the seven sub-tasks of ImageCLEF. For the medical retrieval task the participation remained similar to the previous year with 37 registrations. 17 of the participants submitted results to the tasks, a slight increase from 15 in 2008. The following groups submitted at least one run:</p><p>• NIH (USA);</p><p>• Liris (France);</p><p>• ISSR (Egypt) * ;</p><p>• UIIP Minsk (Belarus) * ;</p><p>• MedGIFT (Switzerland);</p><p>• Sierre (Switzerland) * ;</p><p>• SINAI (Spain);</p><p>• Miracle (Spain);</p><p>• BiTeM (Switzerland);</p><p>• York University (Canada) * ;</p><p>• AUEB (Greece);</p><p>• University of Milwaukee (USA) * ;</p><p>• University of Alicante (Spain);</p><p>• University of North Texas (USA) * ;</p><p>• OHSU (USA);</p><p>• University of Fresno (USA);</p><p>• DEU (Turkey).</p><p>Participants marked with a star had never participated in the past in a medical retrieval task, indicating that the number of first-time participants is fairly high with six among the 17 participants.</p><p>A total of 124 valid runs were submitted, 106 of which were submitted for the image-based topics while 18 for the case-based topics. The number of runs per group was limited to ten per subtask and case-based and image-based topics were seen as separate subtasks in this view. This was an increase compared to the 111 runs submitted last year.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Datasets</head><p>The database in 2009 was again made accessible by the Radiological Society of North America (RSNA 3 ). The database contained a total of 74'902 images, the largest collection yet. All images are taken from the journals Radiology and Radiographics of the RSNA. A similar database is also available via the Goldminer 4 interface. This collection constitutes an important body of medical knowledge from the peer-reviewed scientific literature including high quality images with annotations. Images are associated with journal articles and can be part of a figure. Figure captions are made available to participants as well as the part concerning a particular subfigure if available. This creates high-quality textual annotations enabling textual searching in addition to content-based retrieval. As the PubMed IDs were also made available, participants could access the MeSH (Medical Subject Headings) terms created by the National Library of Medicine for PubMed<ref type="foot" coords="4,126.96,146.11,3.97,6.40" target="#foot_4">5</ref> .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Image-Based Topics</head><p>The image-based topics were created using methods similar to previous years where realistic search topics were identified by surveying actual user needs. The starting point for this year's topics was a user study <ref type="bibr" coords="4,149.65,217.75,10.57,9.62" target="#b7">[8]</ref> conducted at Oregon Health &amp; Science University (OHSU) during early 2009. Based on qualitative methods, this study was conducted with 37 medical practitioners in order to understand the needs, both met and unmet, in medical image retrieval. The first part of the study was dedicated to the investigation of the characteristics of a large portion of the population served by medical image retrieval systems (e.g., their background, searching habits, etc.). After a demonstration of state-of-the-art image retrieval systems, the second part of the study was devoted to learning about the motivation and tasks for which the intended audience uses medical image retrieval systems (e.g., contexts in which they seek medical images, types of useful images, numbers of desired answers, etc.). In the third and last part, the participants were asked to use the demonstrated systems, trying to solve challenging queries, and provide responses to them in terms of how likely they would be to use them, which aspects they did and did not like, and which missing features they would like to see added. In total, the 37 participants used the demonstrated systems to perform a total of 95 searches using textual queries in English. We randomly selected 25 candidate queries from the 95 searches to create the topics for ImageCLEFmed 2009. We added to each candidate query 2 to 4 sample images from the previous collections of ImageCLEFmed. Then, for each topic, we provided a French and a German translation of the original textual description provided by the participants. Finally, the resulting set of the topics was categorized into three groups: 10 visual topics, 10 mixed topics, and 5 semantic topics. The entire set of topics was finally approved by a physician.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Case-Based Topics</head><p>Case-based topics were made available for the first time in 2009. The goal was to move image retrieval potentially closer to clinical routine by simulating the use case of a clinician who is in the process of diagnosing a difficult case. Providing this clinician with articles from the literature that treat cases similar to the case (s)he is working on ("similar" based on images and other clinical data on the patient) can be a valuable aide to choosing a good diagnosis or treatment.</p><p>The topics were cerated based on cases from the teaching file Casimage. This teaching file contains cases including images from radiological practice. 10 cases were pre-selected and a search with the diagnosis was performed in the ImageCLEF data set to make sure that there were at least a few matching articles. Five topics were finally chosen. The diagnosis and all information on the chosen treatment was then removed from the cases to simulate a situation of the clinician who has to diagnose the patient. In order to make the judging more consistent, the relevance judges were provided with the original diagnosis for each case.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Relevance Judgements</head><p>The relevance judgements were performed with the same on-line system as in 2008 for the imagebased topics. The system was adapted for the case-based topics showing the article title and several images appearing in the text (currently the first six, but this can be configured). Besides a short description for the judgements, a full document was prepared to describe the judging process, including what should be regarded as relevant versus non-relevant. A ternary judgement scheme was used again, wherein each image in each pool was judged to be "relevant", "partly relevant", or "non-relevant". Images clearly corresponding to all criteria were judged as "relevant", images whose relevance could not be safely confirmed but could still be possible were marked as "partly relevant", and images for which one or more criteria of the topic were not met were marked as "non-relevant". Judges were instructed in these criteria and results were manually verified during the judgement process.</p><p>We had the opportunity to perform multiple judgements on many topics, both image-based and case-based. Inter-rater agreement was assessed using the kappa metric, given as</p><formula xml:id="formula_0" coords="5,261.48,201.67,251.56,23.18">κ = P (A) -P (E) 1 -P (E)<label>(1)</label></formula><p>where P (A) is the observed agreement between judges and P (E) is the expected (random) agreement. These are calculated using a 2x2 table for the relevances of images or articles. These were calculated for both lenient where a "partly relevant" is considered relevant, and strict judgments where "partly relevant" is considered not-relevant. It is generally accepted that a kappa &lt; 0.7 is good and sufficient for an evaluation. In general the agreement between the judges was fairly high with few exceptions and the overall average κ is similar to other evaluation campaigns. Regarding the case-based topics it seems necessary to take longer for the judges but we did not receive much feedback, so all judges seemed to be satisfied with the written description on the judgments that were supplied.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>This section describes the results of ImageCLEF 2009. Runs are ordered based on the techniques used (visual, textual, mixed) and the interaction used (automatic, manual). Case-based topics and image-based topics are separated but compared in the same sections.</p><p>A more detailed evaluation of the techniques will follow in the final proceedings when more details on the techniques used for the submissions will be known. Unfortunately, information on the techniques used in the submissions is not always made available by the participants well ahead of time and in sufficient detail.</p><p>Trec eval was used for the evaluation process, and we made use of most of its performance measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Submissions</head><p>The numbers of submitting teams was slightly higher in 2009 than in 2008 with 17. The numbers of runs increased from 111 to 124. This was partly due to the fact that with the case-based topics and the image-based topics there were two more run categories.</p><p>A total of 124 runs were submitted via the electronic submission system. Scripts to check the validity of the runs were made available to participants ahead of the submission phase, so only few runs contained errors in either content or format and required changes. Common mistakes included a wrong trec eval format, use of only a subset of the topics and incorrect image identifiers. In collaboration with the participants, a large number of runs were quickly repaired, resulting in 122 valid runs taken into account for the pools.</p><p>In total, only 13 runs were "manual" or "interactive." There were only 16 "visual-only". The large majority were "text-only runs", with 59 submissions. There were 30 mixed runs Groups subsequently had the chance to evaluate additional runs themselves as the qrels were made available to participants 2 weeks ahead of the submission deadline for the working notes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Image-Based Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Visual Retrieval</head><p>The number of visual runs in 2009 was small, and the improvement in the results is not as fast as with textual retrieval techniques. 5 groups submitted a total of 16 runs in 2009, one of which was feedback. Performance as measured in MAP is very low for all these runs, reaching a maximum of 0.0136 for the best run. Both early precision and recall were quite low for the visual runs when compared to the textual runs but there were significant differences between the visual runs. The University of Minsk only submitted runs to a subset of the topics and this made their average performance look much worse than than the other runs. A more detailed per topics analysis seems necessary to really compare the systems.</p><p>Table <ref type="table" coords="6,131.28,361.87,4.98,9.62" target="#tab_0">1</ref> shows the results and particularly the large differences between the runs. Runs retrieved between 13 and 315 of 2362 possible relevant images, which is substantially lower than the poorest performing the textual runs.</p><p>Part of the performance can be explained with the extremely well annotated database that created a much larger gap between visual and textual results. The topics in ImageCLEFmed also became harder, making even the visual topics more semantic than before. This corresponds clearly to user needs. The small number of submitted visual runs also biases the pools towards the textual runs, even further widening the gap.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Textual Retrieval</head><p>Purely automatic textual retrieval had by far the largest number of runs in 2009 with 52, more than 46% of all submitted runs. Table <ref type="table" coords="6,261.15,501.79,4.98,9.62" target="#tab_1">2</ref> shows the results for all submitted automatic text runs, ordered by MAP. Most performance measures such as bpref and early precision are similar in order. Only early precision sometimes has significant differences from the ranking with MAP.</p><p>Runs from the LIRIS obtained the best results with 8 of the top 10 runs. These used conceptual language modelling with the additional use of the UMLS (Unified Medical Language System) metathesaurus. They had many runs with MAP between 0.43 and 0.41. A more detailed analysis is required with the exact techniques applied for each of the runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Multimodal Retrieval</head><p>The promotion of mixed-media retrieval has always been one of the main goals of ImageCLEF. In past years, mixed-media retrieval had the highest submission rate. In 2009 as in 2008, however, only about half as many mixed runs as purely textual runs were submitted.</p><p>Table <ref type="table" coords="6,131.76,653.71,4.98,9.62" target="#tab_2">3</ref> shows the results for all submitted runs. It is clear that, for a large number of the runs, the MAP results for the mixed retrieval submissions were very similar to those from the purely textual retrieval systems. An interesting observation is that, for some groups, the mixed-media submissions often have higher early precision than the purely textual retrieval submissions.</p><p>All runs exhibited relatively high correlation between MAP and bpref. From examining mixed-media runs which had corresponding text-only runs, it is particularly clear that combining good textual retrieval techniques with questionable visual retrieval techniques can negatively affect system performance. This demonstrates the difficulty of usefully integrating  both textual and visual information, and the fragility that such combinations can introduce into retrieval systems. The distribution of MAP for the textual runs was higher than that for the mixed runs. A significant mode exists around a MAP of 0.2 for the mixed runs, while the mode for the textual runs is at around 0.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.4">Interactive Retrieval</head><p>This year, as in previous years, interactive retrieval was only used by a very small number of participants. However, the manual and interactive runs submitted this year performed relatively well with one of the runs achieving the highest overall early precision (P5 and P10). Table <ref type="table" coords="8,480.03,628.39,4.98,9.62" target="#tab_3">4</ref> shows the results of all manual and interactive runs submitted.</p><p>There is definitly a need to promote interactive an manual retrieval further as the potential of this does not seem to have been exploited well, so far.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Case-based results</head><p>A total of six groups participated in this introductory task, submitting at total of 18 runs. The results were quite promising with one group achieving a relatively high MAP of 0.33. As with the image-based retrieval, automatic textual results achieved the best results with poor results being obtained by visual methods. Results were quite varied however with the MAP varying from 0.0025 to 0.335</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1">Visual Retrieval</head><p>Purely visual methods were not able to achieve good performance as seen in the Table <ref type="table" coords="9,476.63,399.43,4.98,9.62" target="#tab_4">5</ref> below. This is not entirely surprising as the set of sample images provided for each topic were quite varied in visual appearance and it needs to be explored how this information can be used well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2">Textual Retrieval</head><p>Textual methods were more effective in retrieving relevant articles as seen in the Table <ref type="table" coords="9,476.63,467.71,4.98,9.62" target="#tab_5">6</ref> below. Interestingly, the early precision for the best runs were not significantly higher than the MAP, unlike in the image-based topics where the early precision was substantially higher than the MAP for many runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3">Multimodal Retrieval</head><p>Unlike the image-based topics, here the multimodal runs performed quite poorly as seen in Table <ref type="table" coords="9,505.21,547.87,3.90,9.62" target="#tab_6">7</ref>. This could be due to the variety of reasons including the diversity of sample images, poor visual performance of runs for case-based topics and the fact that the two best groups did not submit runs in this category.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Relevance Judgement Analysis</head><p>A number of topics, both image-based and case-based were judged by two or even three judges. There were significant variations in the kappa metric used to evaluate the inter-rater agreement.</p><p>The kappas for the image-based topics are given below in Table <ref type="table" coords="9,390.36,653.83,3.90,9.62" target="#tab_7">8</ref>. The kappas are usually reasonably high except when involving some judges. As seen in the table, judge 12 was extremely  lenient compared to all other judges leading to extremely low kappas for any pairwise comparison involving this judge. For instance, on topic 13, judge 12 evaluated 342 images as being relevant while judge 7 (our most strict judge) only evaluated 7 images as being relevant. We discovered this during the judging process and did not use the judgements from judge 12 in creating the official qrels for any of the topics. We performed extensive evaluation of the effect of the judge's strictness in establishing relevance and found that overall, the results obtained using strict judges and those obtained lenient judges correlated well. However, results for a particular topic could be affected by the judge's parsimony in the evaluation of relevance. For the case-based topics, the kappa values were generally lower as seen in Table <ref type="table" coords="10,464.51,460.15,3.90,9.62" target="#tab_8">9</ref>. The 2x2 tables indicated that judge 4 was the most lenient and judge 7 was the strictest.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5">Lung Nodule Detection Task</head><p>We also introduced a lung nodule detection task in 2009. This task used the CT (Computed Tomography) slices from the Lung Imaging Data Consortium (LIDC). This collection consisted for 100-200 slices per study and were manually annotated by 4 clinicians. Although more than 25 groups had registered for the task and more than a dozen had downloaded the datasets, only two groups submitted runs. A commercial proprietary software package performed quite well in the task of detecting the nodules.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>The focus of many participants in this year's ImageCLEF has been text-based retrieval. The increasingly semantic topics combined with a database containing high-quality annotations in 2009 may have resulted in less impact of using visual techniques as compared to previous years. Visual runs were rare and generally poor in performance. Mixed-media runs were very similar in performance to textual runs when looking at MAP. The analysis also shows that several runs with very few relevant images have a very low average performance, whereas topics with a larger number seem to perform better.</p><p>Case-based topics were introduced for the first time and only a few groups participated with results being slightly lower than for the image-based topics.</p><p>A kappa analysis between several relevance judgements for the same topics shows that there are differences between judges but that agreement is generally high. A few judges can nevertheless have disagreeing results with all other judges, something that we need to investigate further.</p><p>For future campaign it seems important that more research on visual techniques including massive learning should be done as currently techniques do not perform well. Interactive and manual retrieval do also seem to have room for improvements and should be put forward to participants who generally prefer automatic text-based approaches.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,109.08,118.63,384.95,137.44"><head>Table 1 :</head><label>1</label><figDesc>Results of the visual runs for the medical image retrieval task.</figDesc><table coords="6,109.08,129.67,384.95,126.40"><row><cell>Run</cell><cell>Run Type</cell><cell>MAP</cell><cell>bpref</cell><cell>P5</cell><cell>P10</cell><cell>P30</cell><cell>rel ret</cell></row><row><cell>CBIR FUSION MERGE</cell><cell>Visual Automatic</cell><cell>0.01</cell><cell>0.04</cell><cell>0.08</cell><cell>0.07</cell><cell>0.05</cell><cell>295</cell></row><row><cell>medGIFT sep max</cell><cell>Visual Automatic</cell><cell>0.01</cell><cell>0.03</cell><cell>0.09</cell><cell>0.08</cell><cell>0.06</cell><cell>266</cell></row><row><cell>medGIFT sum withAR</cell><cell>Visual Automatic</cell><cell>0.01</cell><cell>0.03</cell><cell>0.09</cell><cell>0.07</cell><cell>0.05</cell><cell>262</cell></row><row><cell>CBIR FUSION CV MERGE</cell><cell>Visual Automatic</cell><cell>0.01</cell><cell>0.03</cell><cell>0.09</cell><cell>0.08</cell><cell>0.05</cell><cell>289</cell></row><row><cell>medGIFT sep sum</cell><cell>Visual Automatic</cell><cell>0.01</cell><cell>0.03</cell><cell>0.05</cell><cell>0.05</cell><cell>0.06</cell><cell>259</cell></row><row><cell>medGIFT sep max withAR</cell><cell>Visual Automatic</cell><cell>0.01</cell><cell>0.03</cell><cell>0.08</cell><cell>0.08</cell><cell>0.05</cell><cell>253</cell></row><row><cell>CBIR FUSION CATEGORY</cell><cell>Visual Automatic</cell><cell>0.01</cell><cell>0.03</cell><cell>0.06</cell><cell>0.06</cell><cell>0.04</cell><cell>315</cell></row><row><cell>medGIFT sum withNegImg</cell><cell>Visual Automatic</cell><cell>0.01</cell><cell>0.03</cell><cell>0.06</cell><cell>0.04</cell><cell>0.05</cell><cell>210</cell></row><row><cell>medGIFT max withNegImg.txt</cell><cell>Visual Automatic</cell><cell>0.01</cell><cell>0.02</cell><cell>0.06</cell><cell>0.04</cell><cell>0.04</cell><cell>201</cell></row><row><cell>clef2009</cell><cell>Visual Automatic</cell><cell>0.00</cell><cell>0.02</cell><cell>0.02</cell><cell>0.03</cell><cell>0.02</cell><cell>242</cell></row><row><cell>UIIPMinsk visual 1</cell><cell>Visual Automatic</cell><cell>0.00</cell><cell>0.01</cell><cell>0.03</cell><cell>0.02</cell><cell>0.01</cell><cell>80</cell></row><row><cell>UIIPMinsk visual 2</cell><cell>Visual Automatic</cell><cell>0.00</cell><cell>0.01</cell><cell>0.02</cell><cell>0.02</cell><cell>0.01</cell><cell>91</cell></row><row><cell>CSUFresno visual CEDD</cell><cell>Visual Automatic</cell><cell>0.00</cell><cell>0.03</cell><cell>0.04</cell><cell>0.02</cell><cell>0.02</cell><cell>162</cell></row><row><cell>CSUFresno visual CEDD</cell><cell>Visual Automatic</cell><cell>0.00</cell><cell>0.01</cell><cell>0.04</cell><cell>0.02</cell><cell>0.02</cell><cell>13</cell></row><row><cell>CSUFresno visual CEDD</cell><cell>Visual Automatic</cell><cell>0.00</cell><cell>0.02</cell><cell>0.02</cell><cell>0.01</cell><cell>0.01</cell><cell>89</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,112.08,213.67,378.95,432.40"><head>Table 2 :</head><label>2</label><figDesc>Results of the textual runs for the medical image retrieval task.</figDesc><table coords="7,112.08,224.83,378.95,421.24"><row><cell>Run</cell><cell>Run Type</cell><cell>MAP</cell><cell>bpref</cell><cell>P5</cell><cell>P10</cell><cell>P30</cell><cell>rel ret</cell></row><row><cell>LIRIS maxMPTT extMPTT</cell><cell>Text Automatic</cell><cell>0.43</cell><cell>0.46</cell><cell>0.70</cell><cell>0.66</cell><cell>0.55</cell><cell>1814</cell></row><row><cell>LIRIS maxMPTT extMPTTEF</cell><cell>Text Automatic</cell><cell>0.42</cell><cell>0.45</cell><cell>0.67</cell><cell>0.62</cell><cell>0.53</cell><cell>1801</cell></row><row><cell>LIRIS maxMPTT enMPTT</cell><cell>Text Automatic</cell><cell>0.42</cell><cell>0.44</cell><cell>0.70</cell><cell>0.68</cell><cell>0.56</cell><cell>1689</cell></row><row><cell>LIRIS maxMPTT enMMMPTTEF</cell><cell>Text Automatic</cell><cell>0.42</cell><cell>0.43</cell><cell>0.72</cell><cell>0.68</cell><cell>0.55</cell><cell>1685</cell></row><row><cell>LIRIS KL maxMPTT extMMMPTTEF</cell><cell>Text Automatic</cell><cell>0.42</cell><cell>0.44</cell><cell>0.69</cell><cell>0.64</cell><cell>0.53</cell><cell>1784</cell></row><row><cell>LIRIS KL maxMPTT enMMMPTTEF</cell><cell>Text Automatic</cell><cell>0.42</cell><cell>0.43</cell><cell>0.73</cell><cell>0.68</cell><cell>0.54</cell><cell>1678</cell></row><row><cell>LIRIS KL maxMPTT extMMMPTT</cell><cell>Text Automatic</cell><cell>0.42</cell><cell>0.44</cell><cell>0.68</cell><cell>0.62</cell><cell>0.53</cell><cell>1793</cell></row><row><cell>LIRIS KL maxMPTT enMMMPTT</cell><cell>Text Automatic</cell><cell>0.41</cell><cell>0.43</cell><cell>0.70</cell><cell>0.69</cell><cell>0.55</cell><cell>1682</cell></row><row><cell>sinai CTM t</cell><cell>Text Automatic</cell><cell>0.38</cell><cell>0.39</cell><cell>0.65</cell><cell>0.62</cell><cell>0.56</cell><cell>1884</cell></row><row><cell>LIRIS maxMPTT frTT tradMPTT</cell><cell>Text Automatic</cell><cell>0.38</cell><cell>0.41</cell><cell>0.58</cell><cell>0.58</cell><cell>0.47</cell><cell>1576</cell></row><row><cell>york.In expB2c1.0</cell><cell>Text Automatic</cell><cell>0.37</cell><cell>0.38</cell><cell>0.61</cell><cell>0.60</cell><cell>0.51</cell><cell>1762</cell></row><row><cell>sinai CT t</cell><cell>Text Automatic</cell><cell>0.36</cell><cell>0.36</cell><cell>0.58</cell><cell>0.60</cell><cell>0.54</cell><cell>1869</cell></row><row><cell>ISSR text 1</cell><cell>Text Automatic</cell><cell>0.35</cell><cell>0.36</cell><cell>0.58</cell><cell>0.56</cell><cell>0.49</cell><cell>1717</cell></row><row><cell>ceb-essie2-automatic</cell><cell>Text Automatic</cell><cell>0.35</cell><cell>0.40</cell><cell>0.65</cell><cell>0.62</cell><cell>0.54</cell><cell>1554</cell></row><row><cell>york.bm25</cell><cell>Text Automatic</cell><cell>0.35</cell><cell>0.36</cell><cell>0.60</cell><cell>0.57</cell><cell>0.48</cell><cell>1759</cell></row><row><cell>deu run1 pivoted</cell><cell>Text Automatic</cell><cell>0.34</cell><cell>0.35</cell><cell>0.58</cell><cell>0.52</cell><cell>0.45</cell><cell>1742</cell></row><row><cell>clef2009</cell><cell>Text Automatic</cell><cell>0.34</cell><cell>0.36</cell><cell>0.67</cell><cell>0.60</cell><cell>0.50</cell><cell>1803</cell></row><row><cell>ISSR Text 2</cell><cell>Text Automatic</cell><cell>0.33</cell><cell>0.35</cell><cell>0.58</cell><cell>0.52</cell><cell>0.44</cell><cell>1768</cell></row><row><cell>sinai C t</cell><cell>Text Automatic</cell><cell>0.33</cell><cell>0.36</cell><cell>0.61</cell><cell>0.57</cell><cell>0.50</cell><cell>1590</cell></row><row><cell>sinai CTM tM</cell><cell>Text Automatic</cell><cell>0.33</cell><cell>0.35</cell><cell>0.58</cell><cell>0.54</cell><cell>0.48</cell><cell>1666</cell></row><row><cell>BiTeM EN</cell><cell>Text Automatic</cell><cell>0.32</cell><cell>0.33</cell><cell>0.52</cell><cell>0.50</cell><cell>0.42</cell><cell>1752</cell></row><row><cell>sinai CM t</cell><cell>Text Automatic</cell><cell>0.31</cell><cell>0.34</cell><cell>0.62</cell><cell>0.57</cell><cell>0.54</cell><cell>1582</cell></row><row><cell>deu run2 simple</cell><cell>Text Automatic</cell><cell>0.31</cell><cell>0.34</cell><cell>0.61</cell><cell>0.53</cell><cell>0.45</cell><cell>1620</cell></row><row><cell>sinai CT tM</cell><cell>Text Automatic</cell><cell>0.31</cell><cell>0.32</cell><cell>0.51</cell><cell>0.53</cell><cell>0.44</cell><cell>1729</cell></row><row><cell>ISSR Text FR 1</cell><cell>Text Automatic</cell><cell>0.30</cell><cell>0.34</cell><cell>0.53</cell><cell>0.48</cell><cell>0.40</cell><cell>1643</cell></row><row><cell>BiTeM FRtl</cell><cell>Text Automatic</cell><cell>0.29</cell><cell>0.32</cell><cell>0.48</cell><cell>0.44</cell><cell>0.38</cell><cell>1699</cell></row><row><cell>deu simple rrank dtree</cell><cell>Text Automatic</cell><cell>0.29</cell><cell>0.32</cell><cell>0.59</cell><cell>0.51</cell><cell>0.46</cell><cell>1615</cell></row><row><cell>sinai CM tM</cell><cell>Text Automatic</cell><cell>0.28</cell><cell>0.33</cell><cell>0.54</cell><cell>0.56</cell><cell>0.47</cell><cell>1399</cell></row><row><cell>deu run3 pivot rrank dtree</cell><cell>Text Automatic</cell><cell>0.28</cell><cell>0.32</cell><cell>0.59</cell><cell>0.52</cell><cell>0.42</cell><cell>1570</cell></row><row><cell>sinai C tM</cell><cell>Text Automatic</cell><cell>0.28</cell><cell>0.32</cell><cell>0.56</cell><cell>0.52</cell><cell>0.45</cell><cell>1494</cell></row><row><cell>BiTeM FR</cell><cell>Text Automatic</cell><cell>0.28</cell><cell>0.30</cell><cell>0.46</cell><cell>0.44</cell><cell>0.37</cell><cell>1641</cell></row><row><cell>UNTtextrf1</cell><cell>Text Automatic</cell><cell>0.26</cell><cell>0.28</cell><cell>0.53</cell><cell>0.44</cell><cell>0.38</cell><cell>1762</cell></row><row><cell>UNTtextb1</cell><cell>Text Automatic</cell><cell>0.24</cell><cell>0.28</cell><cell>0.46</cell><cell>0.40</cell><cell>0.37</cell><cell>1642</cell></row><row><cell>BiTeM DEtl</cell><cell>Text Automatic</cell><cell>0.23</cell><cell>0.27</cell><cell>0.41</cell><cell>0.37</cell><cell>0.34</cell><cell>1606</cell></row><row><cell>BiTeM DE</cell><cell>Text Automatic</cell><cell>0.22</cell><cell>0.25</cell><cell>0.41</cell><cell>0.37</cell><cell>0.34</cell><cell>1545</cell></row><row><cell>BiTeM ENsy</cell><cell>Text Automatic</cell><cell>0.20</cell><cell>0.24</cell><cell>0.40</cell><cell>0.38</cell><cell>0.31</cell><cell>1387</cell></row><row><cell>ISSR Text DE 1</cell><cell>Text Automatic</cell><cell>0.20</cell><cell>0.24</cell><cell>0.42</cell><cell>0.39</cell><cell>0.30</cell><cell>1608</cell></row><row><cell>OHSU SR1</cell><cell>Text Automatic</cell><cell>0.18</cell><cell>0.22</cell><cell>0.59</cell><cell>0.54</cell><cell>0.41</cell><cell>801</cell></row><row><cell>MirEN</cell><cell>Text Automatic</cell><cell>0.17</cell><cell>0.23</cell><cell>0.62</cell><cell>0.55</cell><cell>0.39</cell><cell>912</cell></row><row><cell>MirTaxEN</cell><cell>Text Automatic</cell><cell>0.16</cell><cell>0.22</cell><cell>0.59</cell><cell>0.52</cell><cell>0.38</cell><cell>913</cell></row><row><cell>Mir</cell><cell>Text Automatic</cell><cell>0.15</cell><cell>0.21</cell><cell>0.58</cell><cell>0.47</cell><cell>0.31</cell><cell>842</cell></row><row><cell>uwmTextOnly</cell><cell>Text Automatic</cell><cell>0.13</cell><cell>0.18</cell><cell>0.44</cell><cell>0.40</cell><cell>0.31</cell><cell>572</cell></row><row><cell>Alicante-Run3</cell><cell>Text Automatic</cell><cell>0.13</cell><cell>0.16</cell><cell>0.34</cell><cell>0.36</cell><cell>0.34</cell><cell>996</cell></row><row><cell>Alicante-Run1</cell><cell>Text Automatic</cell><cell>0.13</cell><cell>0.16</cell><cell>0.38</cell><cell>0.40</cell><cell>0.35</cell><cell>958</cell></row><row><cell>MirRF0505EN</cell><cell>Text Automatic</cell><cell>0.13</cell><cell>0.18</cell><cell>0.59</cell><cell>0.51</cell><cell>0.34</cell><cell>567</cell></row><row><cell>MirTax</cell><cell>Text Automatic</cell><cell>0.13</cell><cell>0.19</cell><cell>0.50</cell><cell>0.40</cell><cell>0.29</cell><cell>843</cell></row><row><cell>ohsu j no mod</cell><cell>Text Automatic</cell><cell>0.12</cell><cell>0.18</cell><cell>0.42</cell><cell>0.38</cell><cell>0.30</cell><cell>896</cell></row><row><cell>MirRFTax0505EN</cell><cell>Text Automatic</cell><cell>0.10</cell><cell>0.15</cell><cell>0.45</cell><cell>0.36</cell><cell>0.23</cell><cell>568</cell></row><row><cell>MirRF1005EN</cell><cell>Text Automatic</cell><cell>0.09</cell><cell>0.13</cell><cell>0.54</cell><cell>0.41</cell><cell>0.23</cell><cell>459</cell></row><row><cell>MirRF0505</cell><cell>Text Automatic</cell><cell>0.07</cell><cell>0.11</cell><cell>0.43</cell><cell>0.31</cell><cell>0.21</cell><cell>430</cell></row><row><cell>MirRFTax1005EN</cell><cell>Text Automatic</cell><cell>0.07</cell><cell>0.12</cell><cell>0.41</cell><cell>0.30</cell><cell>0.18</cell><cell>470</cell></row><row><cell>MirRFTax0505</cell><cell>Text Automatic</cell><cell>0.05</cell><cell>0.09</cell><cell>0.29</cell><cell>0.22</cell><cell>0.17</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="8,99.24,118.63,404.51,217.12"><head>Table 3 :</head><label>3</label><figDesc>Results of the multimodal runs for the medical image retrieval task.</figDesc><table coords="8,99.24,129.67,404.51,206.08"><row><cell>Run</cell><cell>Run Type</cell><cell>MAP</cell><cell>bpref</cell><cell>P5</cell><cell>P10</cell><cell>P30</cell><cell>rel ret</cell></row><row><cell>deu imaged vsm</cell><cell>Mixed Automatic</cell><cell>0.37</cell><cell>0.39</cell><cell>0.63</cell><cell>0.54</cell><cell>0.48</cell><cell>1754</cell></row><row><cell>york.BO1.EdgeHistogram0.2</cell><cell>Mixed Automatic</cell><cell>0.36</cell><cell>0.37</cell><cell>0.58</cell><cell>0.58</cell><cell>0.54</cell><cell>1724</cell></row><row><cell>york.BO1.Tamura0.2</cell><cell>Mixed Automatic</cell><cell>0.35</cell><cell>0.37</cell><cell>0.62</cell><cell>0.57</cell><cell>0.51</cell><cell>1722</cell></row><row><cell cols="2">BM25b=0.75k 1=1.2k 3=8.0 ICLEFPProcess 3 Mixed Automatic</cell><cell>0.35</cell><cell>0.37</cell><cell>0.60</cell><cell>0.59</cell><cell>0.50</cell><cell>1763</cell></row><row><cell>York.BO1.colorHistogram0.2</cell><cell>Mixed Automatic</cell><cell>0.34</cell><cell>0.36</cell><cell>0.59</cell><cell>0.57</cell><cell>0.50</cell><cell>1719</cell></row><row><cell cols="2">BM25b=0.75k 1=1.2k 3=8.0 ICLEFPProcess 1 Mixed Automatic</cell><cell>0.33</cell><cell>0.35</cell><cell>0.59</cell><cell>0.57</cell><cell>0.47</cell><cell>1757</cell></row><row><cell>medGIFT0.3 withNegImg EN</cell><cell>Mixed Automatic</cell><cell>0.29</cell><cell>0.32</cell><cell>0.63</cell><cell>0.60</cell><cell>0.52</cell><cell>1176</cell></row><row><cell>Multimodal Text Rerank</cell><cell>Mixed Automatic</cell><cell>0.27</cell><cell>0.40</cell><cell>0.49</cell><cell>0.52</cell><cell>0.45</cell><cell>1553</cell></row><row><cell>UNTMixed Automatic1</cell><cell>Mixed Automatic</cell><cell>0.24</cell><cell>0.28</cell><cell>0.46</cell><cell>0.40</cell><cell>0.37</cell><cell>1659</cell></row><row><cell>medGIFT0.5 EN</cell><cell>Mixed Automatic</cell><cell>0.21</cell><cell>0.25</cell><cell>0.70</cell><cell>0.59</cell><cell>0.43</cell><cell>848</cell></row><row><cell>UNTMixed Automaticrf1</cell><cell>Mixed Automatic</cell><cell>0.19</cell><cell>0.24</cell><cell>0.50</cell><cell>0.42</cell><cell>0.37</cell><cell>1197</cell></row><row><cell>ohsu j umls</cell><cell>Mixed Automatic</cell><cell>0.18</cell><cell>0.21</cell><cell>0.71</cell><cell>0.66</cell><cell>0.42</cell><cell>591</cell></row><row><cell>ohsu j mod1</cell><cell>Mixed Automatic</cell><cell>0.17</cell><cell>0.22</cell><cell>0.59</cell><cell>0.55</cell><cell>0.38</cell><cell>943</cell></row><row><cell>OHSU SR6</cell><cell>Mixed Automatic</cell><cell>0.16</cell><cell>0.20</cell><cell>0.68</cell><cell>0.61</cell><cell>0.43</cell><cell>543</cell></row><row><cell>OHSU SR2</cell><cell>Mixed Automatic</cell><cell>0.16</cell><cell>0.21</cell><cell>0.62</cell><cell>0.54</cell><cell>0.39</cell><cell>801</cell></row><row><cell>OHSU SR3</cell><cell>Mixed Automatic</cell><cell>0.15</cell><cell>0.20</cell><cell>0.61</cell><cell>0.52</cell><cell>0.37</cell><cell>801</cell></row><row><cell>clef2009</cell><cell>Mixed Automatic</cell><cell>0.15</cell><cell>0.21</cell><cell>0.38</cell><cell>0.33</cell><cell>0.26</cell><cell>1381</cell></row><row><cell>medGIFT mix 0.5vis withNegImg</cell><cell>Mixed Automatic</cell><cell>0.14</cell><cell>0.17</cell><cell>0.56</cell><cell>0.49</cell><cell>0.33</cell><cell>547</cell></row><row><cell>Alicante-Run4</cell><cell>Mixed Automatic</cell><cell>0.13</cell><cell>0.17</cell><cell>0.31</cell><cell>0.34</cell><cell>0.33</cell><cell>992</cell></row><row><cell>uwmTextAndModality</cell><cell>Mixed Automatic</cell><cell>0.13</cell><cell>0.17</cell><cell>0.49</cell><cell>0.46</cell><cell>0.38</cell><cell>521</cell></row><row><cell>Alicante-Run5</cell><cell>Mixed Automatic</cell><cell>0.13</cell><cell>0.16</cell><cell>0.33</cell><cell>0.35</cell><cell>0.33</cell><cell>982</cell></row><row><cell>OHSU SR4</cell><cell>Mixed Automatic</cell><cell>0.11</cell><cell>0.15</cell><cell>0.60</cell><cell>0.48</cell><cell>0.31</cell><cell>381</cell></row><row><cell>OHSU SR5</cell><cell>Mixed Automatic</cell><cell>0.11</cell><cell>0.15</cell><cell>0.58</cell><cell>0.52</cell><cell>0.31</cell><cell>514</cell></row><row><cell>uwmTextAndImageDistance</cell><cell>Mixed Automatic</cell><cell>0.07</cell><cell>0.09</cell><cell>0.44</cell><cell>0.40</cell><cell>0.27</cell><cell>204</cell></row><row><cell>medGIFT sum withNegImg</cell><cell>Mixed</cell><cell>0.01</cell><cell>0.03</cell><cell>0.06</cell><cell>0.04</cell><cell>0.05</cell><cell>210</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="8,108.24,368.71,386.65,121.48"><head>Table 4 :</head><label>4</label><figDesc>Results of the interactive and manual runs for the medical image retrieval task.</figDesc><table coords="8,108.84,379.87,385.43,110.32"><row><cell>Run</cell><cell>Run Type</cell><cell>MAP</cell><cell>bpref</cell><cell>P5</cell><cell>P10</cell><cell>P30</cell><cell>rel ret</cell></row><row><cell>ceb-interactive-with-pad</cell><cell>Mixed Interactive</cell><cell>0.38</cell><cell>0.43</cell><cell>0.74</cell><cell>0.72</cell><cell>0.55</cell><cell>1545</cell></row><row><cell>In expB2c1.0 Bo1bfree</cell><cell>Mixed Interactive</cell><cell>0.37</cell><cell>0.39</cell><cell>0.62</cell><cell>0.56</cell><cell>0.51</cell><cell>1803</cell></row><row><cell>TEXT MANUAL CBIR RF</cell><cell>Mixed Interactive</cell><cell>0.04</cell><cell>0.09</cell><cell>0.28</cell><cell>0.22</cell><cell>0.14</cell><cell>496</cell></row><row><cell>BM25b=0.75k 1=1.2k 3=8.0 Bo1bfree</cell><cell>Text Interactive</cell><cell>0.37</cell><cell>0.38</cell><cell>0.61</cell><cell>0.55</cell><cell>0.50</cell><cell>1810</cell></row><row><cell>ISSR Text FR 2</cell><cell>Text Interactive</cell><cell>0.31</cell><cell>0.34</cell><cell>0.47</cell><cell>0.49</cell><cell>0.44</cell><cell>1811</cell></row><row><cell>ISSR Text 1rfb</cell><cell>Text Interactive</cell><cell>0.28</cell><cell>0.29</cell><cell>0.41</cell><cell>0.43</cell><cell>0.39</cell><cell>1604</cell></row><row><cell>ISSR Text 5</cell><cell>Text Interactive</cell><cell>0.27</cell><cell>0.29</cell><cell>0.38</cell><cell>0.43</cell><cell>0.37</cell><cell>1738</cell></row><row><cell>ISSR Text 4</cell><cell>Text Interactive</cell><cell>0.27</cell><cell>0.29</cell><cell>0.34</cell><cell>0.42</cell><cell>0.37</cell><cell>1734</cell></row><row><cell>ISSR Text DE 2</cell><cell>Text Interactive</cell><cell>0.20</cell><cell>0.22</cell><cell>0.25</cell><cell>0.25</cell><cell>0.27</cell><cell>1438</cell></row><row><cell>Alicante-Run2</cell><cell>Text Interactive</cell><cell>0.14</cell><cell>0.17</cell><cell>0.32</cell><cell>0.35</cell><cell>0.34</cell><cell>994</cell></row><row><cell>CBIR RF</cell><cell>Visual Interactive</cell><cell>0.01</cell><cell>0.03</cell><cell>0.06</cell><cell>0.05</cell><cell>0.05</cell><cell>306</cell></row><row><cell>york.BO1.MeSH.TamuraHistogram0.2</cell><cell>Mixed Manual</cell><cell>0.35</cell><cell>0.36</cell><cell>0.62</cell><cell>0.58</cell><cell>0.48</cell><cell>1760</cell></row><row><cell>Multimodal Text QE CBIR</cell><cell>Mixed Manual</cell><cell>0.04</cell><cell>0.09</cell><cell>0.27</cell><cell>0.19</cell><cell>0.13</cell><cell>456</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="9,98.76,119.11,405.47,58.36"><head>Table 5 :</head><label>5</label><figDesc>Results of the visual runs for the medical image retrieval task (Case-Based Topics).</figDesc><table coords="9,99.12,130.75,404.87,46.72"><row><cell>Run</cell><cell>Run Type</cell><cell>MAP</cell><cell>bpref</cell><cell>P5</cell><cell>P10</cell><cell>P30</cell><cell>rel ret</cell></row><row><cell>medGIFT case bySimilarity vis maxWithAR</cell><cell>Visual Automatic</cell><cell>0.02</cell><cell>0.03</cell><cell>0.04</cell><cell>0.04</cell><cell>0.05</cell><cell>41</cell></row><row><cell>medGIFT case bySimilarity vis sumWithAR</cell><cell>Visual Automatic</cell><cell>0.02</cell><cell>0.03</cell><cell>0.04</cell><cell>0.06</cell><cell>0.05</cell><cell>42</cell></row><row><cell>clef2009</cell><cell>Visual Automatic</cell><cell>0.01</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.01</cell><cell>39</cell></row><row><cell>medGIFT case byfreq vis sumWithAR</cell><cell>Visual Automatic</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.01</cell><cell>26</cell></row><row><cell>medGIFT case byfreq vis maxWithAR</cell><cell>Visual Automatic</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.01</cell><cell>26</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="9,96.00,211.03,410.99,98.08"><head>Table 6 :</head><label>6</label><figDesc>Results of the textual runs for the medical image retrieval task (Case-Based Topics).</figDesc><table coords="9,106.68,222.67,389.63,86.44"><row><cell>Run</cell><cell>Run Type</cell><cell>MAP</cell><cell>bpref</cell><cell>P5</cell><cell>P10</cell><cell>P30</cell><cell>rel ret</cell></row><row><cell>ceb-cases-essie2-automatic</cell><cell>Textual Automatic</cell><cell>0.34</cell><cell>0.28</cell><cell>0.32</cell><cell>0.34</cell><cell>0.23</cell><cell>74</cell></row><row><cell>sinai TA cbt</cell><cell>Textual Automatic</cell><cell>0.26</cell><cell>0.23</cell><cell>0.32</cell><cell>0.34</cell><cell>0.23</cell><cell>89</cell></row><row><cell>sinai TA cbtM</cell><cell>Textual Automatic</cell><cell>0.26</cell><cell>0.22</cell><cell>0.32</cell><cell>0.30</cell><cell>0.25</cell><cell>89</cell></row><row><cell>clef2009</cell><cell>Textual Automatic</cell><cell>0.19</cell><cell>0.13</cell><cell>0.32</cell><cell>0.24</cell><cell>0.19</cell><cell>93</cell></row><row><cell>HES-SO-VS txt case</cell><cell>Textual Automatic</cell><cell>0.19</cell><cell>0.15</cell><cell>0.32</cell><cell>0.32</cell><cell>0.20</cell><cell>71</cell></row><row><cell>Alicante-CaseBased-Run5</cell><cell>Textual Automatic</cell><cell>0.07</cell><cell>0.07</cell><cell>0.16</cell><cell>0.10</cell><cell>0.09</cell><cell>61</cell></row><row><cell>Alicante-CaseBased-Run2</cell><cell>Textual Automatic</cell><cell>0.05</cell><cell>0.04</cell><cell>0.08</cell><cell>0.08</cell><cell>0.07</cell><cell>58</cell></row><row><cell>Alicante-CaseBased-Run4</cell><cell>Textual Automatic</cell><cell>0.05</cell><cell>0.04</cell><cell>0.08</cell><cell>0.08</cell><cell>0.07</cell><cell>58</cell></row><row><cell>Alicante-CaseBased-Run3</cell><cell>Textual Automatic</cell><cell>0.05</cell><cell>0.04</cell><cell>0.08</cell><cell>0.08</cell><cell>0.07</cell><cell>59</cell></row><row><cell>Alicante-CaseBased-Run1</cell><cell>Textual Automatic</cell><cell>0.05</cell><cell>0.04</cell><cell>0.08</cell><cell>0.08</cell><cell>0.07</cell><cell>59</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="9,90.00,705.07,422.99,34.36"><head>Table 7 :</head><label>7</label><figDesc>Results of the multimodal runs for the medical image retrieval task (Case-Based Topics).</figDesc><table coords="9,109.20,716.71,384.59,22.72"><row><cell>Run</cell><cell>Run Type</cell><cell>MAP</cell><cell>bpref</cell><cell>P5</cell><cell>P10</cell><cell>P30</cell><cell>rel ret</cell></row><row><cell>medGIFT0.5 BySimilarity EN</cell><cell>Mixed Automatic</cell><cell>0.07</cell><cell>0.05</cell><cell>0.12</cell><cell>0.14</cell><cell>0.09</cell><cell>74</cell></row><row><cell>clef2009</cell><cell>Mixed Automatic</cell><cell>0.02</cell><cell>0.00</cell><cell>0.00</cell><cell>0.00</cell><cell>0.02</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="10,210.48,118.63,182.17,105.16"><head>Table 8 :</head><label>8</label><figDesc>Kappas for Image-Based Topics.</figDesc><table coords="10,235.56,129.31,131.98,94.48"><row><cell>Topic</cell><cell>Judge 1</cell><cell>Judge 2</cell><cell>Kappa</cell></row><row><cell>1</cell><cell>3</cell><cell>4</cell><cell>0.341</cell></row><row><cell>3</cell><cell>3</cell><cell>11</cell><cell>0.715</cell></row><row><cell>7</cell><cell>4</cell><cell>6</cell><cell>0.302</cell></row><row><cell>8</cell><cell>6</cell><cell>15</cell><cell>0.639</cell></row><row><cell>10</cell><cell>4</cell><cell>12</cell><cell>0.15</cell></row><row><cell>13</cell><cell>7</cell><cell>12</cell><cell>0.021</cell></row><row><cell>14</cell><cell>11</cell><cell>12</cell><cell>0.0298</cell></row><row><cell>15</cell><cell>6</cell><cell>7</cell><cell>0.885</cell></row><row><cell>17</cell><cell>3</cell><cell>4</cell><cell>0.821</cell></row><row><cell>18</cell><cell>4</cell><cell>15</cell><cell>0.884</cell></row><row><cell>20</cell><cell>7</cell><cell>12</cell><cell>0.0388</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="10,213.36,256.75,176.40,73.72"><head>Table 9 :</head><label>9</label><figDesc>Kappas for Case-Based Topics.</figDesc><table coords="10,239.76,267.91,123.46,62.56"><row><cell>Topic</cell><cell>judge1</cell><cell>judge2</cell><cell>Kappa</cell></row><row><cell>26</cell><cell>4</cell><cell>7</cell><cell>0.06</cell></row><row><cell>27</cell><cell>4</cell><cell>7</cell><cell>-0.10</cell></row><row><cell>28</cell><cell>4</cell><cell>11</cell><cell>0.37</cell></row><row><cell>29</cell><cell>4</cell><cell>7</cell><cell>-0.25</cell></row><row><cell>29</cell><cell>4</cell><cell>11</cell><cell>0.13</cell></row><row><cell>29</cell><cell>7</cell><cell>11</cell><cell>0.28</cell></row><row><cell>30</cell><cell>7</cell><cell>11</cell><cell>0.56</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,105.24,688.07,105.10,7.35"><p>http://www.imageclef.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="2,105.24,697.67,122.02,7.35"><p>http://www.clef-campaign.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,105.24,733.55,83.99,7.35"><p>http://www.rsna.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="3,105.24,743.03,109.30,7.35"><p>http://goldminer.arrs.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="4,105.24,735.95,92.39,7.35"><p>http://www.pubmed.gov/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="5">Acknowledgements</head><p>We would like to thank the CLEF campaign for supporting the ImageCLEF initiative. This work was partially funded by the <rs type="funder">Swiss National Science Foundation (FNS)</rs> under contracts <rs type="grantNumber">205321-109304/1</rs> and <rs type="grantNumber">PBGE22-121204</rs>, the <rs type="funder">American National Science Foundation (NSF)</rs> with grant <rs type="grantNumber">ITR-0325160</rs>, the <rs type="projectName">TrebleCLEF</rs> project and Google. We would like to thank the <rs type="institution">RSNA</rs> for supplying the images of their journals Radiology and Radiographics for the ImageCLEF campaign.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_kBE8BwW">
					<idno type="grant-number">205321-109304/1</idno>
				</org>
				<org type="funding" xml:id="_arbSEFu">
					<idno type="grant-number">PBGE22-121204</idno>
				</org>
				<org type="funded-project" xml:id="_GrU2SCH">
					<idno type="grant-number">ITR-0325160</idno>
					<orgName type="project" subtype="full">TrebleCLEF</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="11,105.48,340.75,407.56,9.62;11,105.48,352.75,407.54,9.62;11,105.48,364.63,407.54,9.62;11,105.48,376.63,140.41,9.62" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="11,263.77,352.75,231.13,9.62">The CLEF 2005 cross-language image retrieval track</title>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">M</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeffery</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,105.48,364.63,181.60,9.62">Cross Language Evaluation Forum (CLEF</title>
		<title level="s" coord="11,319.92,364.63,188.81,9.62">Springer Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2005-09">2005. September 2006</date>
			<biblScope unit="page" from="535" to="557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,105.48,396.55,407.59,9.62;11,105.48,408.55,407.57,9.62;11,105.48,420.43,407.44,9.62;11,105.48,432.43,407.49,9.62;11,105.48,444.43,366.04,9.62" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,349.40,396.55,163.67,9.62;11,105.48,408.55,139.91,9.62">The CLEF cross-language image retrieval track (ImageCLEF) 2004</title>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,354.60,420.43,158.32,9.62;11,105.48,432.43,311.57,9.62">Multilingual Information Access for Text, Speech and Images: Result of the fifth CLEF evaluation campaign</title>
		<title level="s" coord="11,495.00,432.43,17.96,9.62;11,105.48,444.43,169.59,9.62">Lecture Notes in Computer Science (LNCS</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Gareth</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Bernardo</forename><surname>Kluck</surname></persName>
		</editor>
		<editor>
			<persName><surname>Magnini</surname></persName>
		</editor>
		<meeting><address><addrLine>Bath, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3491</biblScope>
			<biblScope unit="page" from="597" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,105.48,464.35,407.63,9.62;11,105.48,476.23,407.20,9.62;11,105.48,488.23,332.79,9.62" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,468.51,464.35,44.61,9.62;11,105.48,476.23,285.83,9.62">A qualitative task analysis for developing an image retrieval test collection</title>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeffery</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Gorman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Patrick</forename><surname>Ruch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,412.92,476.23,99.76,9.62;11,105.48,488.23,168.54,9.62">ImageCLEF/MUSCLE workshop on image retrieval evaluation</title>
		<meeting><address><addrLine>Vienna, Austria</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="11" to="16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,105.49,508.15,407.53,9.62;11,105.48,520.15,407.52,9.62;11,105.48,532.03,407.48,9.62;11,105.48,544.03,346.61,9.62" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="11,304.60,520.15,208.40,9.62;11,105.48,532.03,130.90,9.62">Overview of the ImageCLEFmed 2007 medical retrieval and annotation tasks</title>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eugene</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jayashree</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">M</forename><surname>Deserno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,259.08,532.03,102.93,9.62">CLEF 2007 Proceedings</title>
		<title level="s" coord="11,440.64,532.03,72.32,9.62;11,105.48,544.03,108.75,9.62">Lecture Notes in Computer Science (LNCS</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">5152</biblScope>
			<biblScope unit="page" from="473" to="491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,105.48,563.95,407.65,9.62;11,105.48,575.95,407.56,9.62;11,105.48,587.83,407.55,9.62;11,105.48,599.83,407.18,9.62" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="11,228.14,575.95,262.17,9.62">Health care professionals&apos; image use and search behaviour</title>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christelle</forename><surname>Despont-Gros</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeffery</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christian</forename><surname>Lovis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antoine</forename><surname>Geissbuhler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,105.48,587.83,306.79,9.62;11,469.68,587.83,43.35,9.62;11,105.48,599.83,151.91,9.62">Proceedings of the Medical Informatics Europe Conference (MIE 2006)</title>
		<meeting>the Medical Informatics Europe Conference (MIE 2006)<address><addrLine>Maastricht, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2006-08">August 2006</date>
			<biblScope unit="page" from="24" to="32" />
		</imprint>
	</monogr>
	<note>Studies in Health Technology and Informatics</note>
</biblStruct>

<biblStruct coords="11,105.48,619.75,407.49,9.62;11,105.48,631.63,407.41,9.62;11,105.48,643.63,345.52,9.62" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="11,488.31,619.75,24.66,9.62;11,105.48,631.63,296.29,9.62">Using Medline queries to generate image retrieval tasks for benchmarking</title>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jayashree</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antoine</forename><surname>Geissbuhler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,425.88,631.63,87.01,9.62;11,105.48,643.63,30.02,9.62">Medical Informatics Europe</title>
		<meeting><address><addrLine>Gothenburg, Sweden</addrLine></address></meeting>
		<imprint>
			<publisher>MIE</publisher>
			<date type="published" when="2008-05">2008. May 2008</date>
			<biblScope unit="page" from="523" to="528" />
		</imprint>
	</monogr>
	<note>IOS press</note>
</biblStruct>

<biblStruct coords="11,105.48,663.55,407.55,9.62;11,105.48,675.55,407.46,9.62;11,105.48,687.43,228.14,9.62" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="11,105.48,675.55,335.03,9.62">A reference data set for the evaluation of medical image retrieval systems</title>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antoine</forename><surname>Rosset</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jean-Paul</forename><surname>Vallée</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Francois</forename><surname>Terrier</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antoine</forename><surname>Geissbuhler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,453.84,675.55,59.10,9.62;11,105.48,687.43,130.70,9.62">Computerized Medical Imaging and Graphics</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="295" to="305" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,105.48,707.35,407.49,9.62;11,105.48,719.35,407.56,9.62;11,105.48,731.35,107.77,9.62" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="11,482.77,707.35,30.21,9.62;11,105.48,719.35,229.74,9.62">Understanding and improving image retrieval in medicine</title>
		<author>
			<persName coords=""><forename type="first">Saïd</forename><surname>Radhouani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jayashree</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steven</forename><surname>Bedrick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
		<respStmt>
			<orgName>Oregon Health and Science University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct coords="12,105.48,111.67,407.32,9.62;12,105.48,123.67,407.57,9.62;12,105.48,135.55,22.93,9.62" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="12,173.89,111.67,152.98,9.62">Report on CLEF-2001 experiments</title>
		<author>
			<persName coords=""><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="12,348.12,111.67,164.68,9.62;12,105.48,123.67,154.43,9.62">Report on the CLEF Conference 2001 (Cross Language Evaluation Forum)</title>
		<meeting><address><addrLine>Darmstadt, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer LNCS</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page">2406</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
