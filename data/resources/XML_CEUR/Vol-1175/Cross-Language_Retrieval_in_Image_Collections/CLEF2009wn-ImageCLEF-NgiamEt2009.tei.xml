<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,129.14,148.86,344.72,15.15;1,237.84,170.78,127.32,15.15">I2R ImageCLEF Photo Annotation 2009 Working Notes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,234.29,204.67,61.02,8.74"><forename type="first">Jiquan</forename><surname>Ngiam</surname></persName>
							<email>jqngiam@i2r.a-star.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="institution">Institute for Infocomm Research</orgName>
								<address>
									<addrLine>1 Fusionopolis Way</addrLine>
									<postCode>138632</postCode>
									<settlement>Singapore</settlement>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,318.00,204.67,50.71,8.74"><forename type="first">Hanlin</forename><surname>Goh</surname></persName>
							<email>hlgoh@i2r.a-star.edu.sg</email>
							<affiliation key="aff0">
								<orgName type="institution">Institute for Infocomm Research</orgName>
								<address>
									<addrLine>1 Fusionopolis Way</addrLine>
									<postCode>138632</postCode>
									<settlement>Singapore</settlement>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,129.14,148.86,344.72,15.15;1,237.84,170.78,127.32,15.15">I2R ImageCLEF Photo Annotation 2009 Working Notes</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">61FAC1AC62619B82ACCBC00FE752241B</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Managment]: Languages-Query Languages Measurement, Performance, Experimentation Photo annotation, Global and local features, Support Vector Machines (SVM), feature selection</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the method that was used for our two submission runs for the ImageCLEF Photo Annotation task.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The ImageCLEF Photo Annotation 2009 task involved 53 concepts spanning from abstract concepts (aesthetics, blur) to visual elements (trees, people). Although an ontology was provided, our method did not rely on the ontology heavily, except for handling disjoint cases.</p><p>Our method follows the framework in <ref type="bibr" coords="1,274.94,550.83,10.52,8.74" target="#b8">[9]</ref> , involving Support Vector Machines and extended Gaussian Kernels over the χ 2 distance. We use a variety of global features, novel local region selectors and simple greedy feature selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Image Features 2.1 Global Features</head><p>The following global features were each computed over the entire image. Each feature essential provides a histogram for the image.</p><p>In features where a quantized HSV space was used, the following quantization parameters were employed: 12 Hue Bins, 3 Saturation Bins, 3 Value Bins. Bins were of equal width in each dimension. This results in a total of 108 bins. The choice of these parameters was motivated by <ref type="bibr" coords="1,502.49,697.71,10.52,8.74" target="#b5">[6]</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">HSV Histogram -108 dim</head><p>The quantized HSV histogram (as above) was used as a feature vector.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Color Auto Correlogram (CAC) -432 dim</head><p>We computed the CAC over a quantized HSV space with 4 distances 1,3,5,7. This gives us a feature vector of 108*4 = 432 dimensions.</p><p>For each color &amp; distance pair (c, d), we computed the probability of finding the same color at exactly distance d away. Refer to <ref type="bibr" coords="2,250.73,166.28,10.52,8.74" target="#b5">[6]</ref> for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.3">Color Coherence Vector (CCV) -216 dim</head><p>We computed the CCV over a quantized HSV space. Since there are two states -coherent and incoherent, this gives us a feature vector of 108*2 = 216 dimensions. We set the tau parameter to 1% of the image size. Refer to <ref type="bibr" coords="2,225.27,234.47,10.52,8.74" target="#b6">[7]</ref> for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.4">Census Transform (CT) -256 dim</head><p>The CT histogram is a simple transformation of each pixel into a 8-bit value based on its 8 surrounding neighbors (two states, either ¿= or ¡ its neighbor). This provides a feature vector of 256 dimensions (histogram of the CT values). Refer to <ref type="bibr" coords="2,332.01,302.67,10.52,8.74" target="#b7">[8]</ref> for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.5">Edge Orientation Histogram -37 dim</head><p>We used the LTI-Lib's Canny Edge detector to compute the edge orientation histogram. Each pixel is assigned to either an edge (with orientation) or non-edge. Orientations are quantized into 5 degree angle bins, giving a total of 36 bins for 180 degrees. An additional bin is concatenated for non-edges. This gives a final vector of 37 dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.6">Interest Point Based SIFT -500 dim</head><p>We used the SIFT binary provided by David Lowe <ref type="bibr" coords="2,304.21,427.10,10.52,8.74" target="#b4">[5]</ref> to compute SIFT descriptors. The descriptors were quantized into 500 visual words. A visual words dictionary was computed using k-Means clustering.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.7">Densely Sampled SIFT -1500 dim</head><p>We densely sampled SIFT points at 10 pixel spacings, 4 scales (4, 8, 12, 16 px radius) and 1 orientation. The points are similarly quantized into 1500 visual words by k-Means. This scheme follows that of <ref type="bibr" coords="2,155.64,519.21,9.96,8.74" target="#b0">[1]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Local Region Features</head><p>For a number of concepts, the classification problem can be framed in the Multiple Instance Learning (MIL) framework. In essence, a concept (e.g. Mountain) exists if and only if a region within the image demonstrates the concept. Hence, one is motivated to consider whether it is possible to improve performance by finding appropriate region(s) to consider in an image.</p><p>We define a local region to be a bounding box. Given a bounding box in an image, one can compute image features similar to the global features. Hence, we define a local region feature to be a feature vector that is extracted based only on region in a bounding box. Therefore, the problem of finding local region features is reduced to one of finding good bounding boxes for each image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Local Region Selectors</head><p>To find good local region selectors (bounding boxes), we frame the problem in a MIL setting. In this setting, each image is a bag-of-regions and regions are considered to be true iff they contain the target concept. Furthermore, a bag is true iff it contains a true region.</p><p>We used EM-Diverse Density <ref type="bibr" coords="2,233.07,729.32,15.50,8.74" target="#b9">[10]</ref> together with Efficient Subwindow Search (ESS) <ref type="bibr" coords="2,461.47,729.32,10.52,8.74" target="#b3">[4]</ref> to search for a target concept with good diverse density. We note that since ESS is able to consider all possible rectangular subwindows, the algorithm essentially considers all possible bounding boxes. However, multiple restarts are required since the algorithm is susceptible to local minimas.</p><p>For each concept, we learned a local region selector based on the densely sample SIFT features. From each local region, we extract only the HSV, interest point SIFT and densely sampled SIFT histograms. These three histograms form the (concept-specific) local features for each image.</p><p>3 Learning and Feature Selection</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Support Vector Machines</head><p>For the final classification, we used LIBSVM <ref type="bibr" coords="3,294.70,234.99,10.52,8.74" target="#b1">[2]</ref> with probability estimates (provided with the software). Each concept was treated separately as a individual classification task. Following <ref type="bibr" coords="3,499.71,246.94,9.96,8.74" target="#b8">[9]</ref>, we used extended Gaussian kernels with the χ 2 distance.</p><formula xml:id="formula_0" coords="3,210.71,278.27,181.57,26.88">K(S i , S j ) = f ∈f eatures 1 µ f χ 2 (f (S i ), f (S j ))</formula><p>Both local and global features were treated in the same manner. µ f is the average χ 2 distance for a particular feature; we used it to normalize the distances across different features.</p><p>We also performed experiments on cost-sensitive SVMs but the results did not vary that much.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Feature Selection</head><p>Unsurprisingly, different features work well with different concepts. To combine different features, one could incorporate weighting into the kernel function. This method is adopted by the INRIA group in their VOC2007 submission <ref type="bibr" coords="3,252.96,408.53,9.96,8.74" target="#b2">[3]</ref>. However, learning these weights is non-trivial and one often resorts to ad-hoc methods such as genetic algorithms. We chose a simpler method for feature selection in which a greedy algorithm is used. Furthermore, we do employ any partial weighting scheme for the features. Using equal error rate (ERR) as out performance measure, the algorithm is described as follows:</p><p>Greedy Algorithm The appendix contains a list of concepts and the features that were selected for each of them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Hierarchical Evaluation</head><p>While there was a new hierarchical measure introduced for the task, we did not specifically optimize for it. The lack of the annotator agreement values also made it more difficult to optimize for this new measure.</p><p>However, for the classes that were specified as disjoint, we did simple post processing on the probability estimates to ensure that exactly 1 of the concepts is ≥ 0.5. This was achieved by simply moving the probability estimates to 0.5 ± .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Observations</head><p>We noticed that the SVM was robust to optional concepts and class imbalance. For optional concepts like Sunny, the SVM was able to correctly classify many "unlabelled" data points correctly (these were classified as negative in a validation set).</p><p>The local features were useful for the following concepts: Partylife, Snow, Spring, Autumn, No Visual Season, Trees, Mountains, Macro, Portrait, Small Group, Animals, Vehicle, Overall Quality, Fancy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Submissions and Results</head><p>Two final submissions were made for this task. One used all the features available while the other used only the global features. The official results of the two runs in terms of Average Equal Error Rate (Avg. EER), Average Area Under Curve (Avg. AUC), Average Annotation Score with Annotator Agreement (Avg. AS with AA) and Average Annotation Score without Annotator Agreement (Avg. AS without AA) are reported in Table <ref type="table" coords="4,340.56,398.83,3.87,8.74" target="#tab_0">1</ref>.</p><p>Based on the Avg. EER measure, our run with all features was ranked 6 out of 74 submitted runs, while the run using only global features was ranked 11. Comparing the best runs from each group, were reported to be third in the list of twenty participating groups. Evaluating our performance based on the Average Annotation Score with and without the use of Annotator Agreement, our runs were ranked second (global features only) and third (all features).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Submission Run</head><p>Avg </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,102.18,500.18,110.91,8.74;3,102.18,520.11,269.56,8.74;3,102.18,540.04,250.55,8.74;3,102.18,559.96,314.84,8.74;3,102.18,579.89,353.39,8.74;3,102.18,599.81,293.28,8.74;3,102.18,619.74,262.29,8.74;3,102.18,639.66,195.05,8.74;3,102.18,659.59,53.16,8.74"><head>1. F = all global features 2 .</head><label>2</label><figDesc>For each feature f ∈ F : Compute error rate if f is removed 3. Remove the feature which results in best improvement 4. Repeat (2-3) until removing any feature results in worse performance 5. Consider each feature f ∈ All F eatures -F : Compute error rate if f is added 6. Consider each feature f ∈ F : Compute error rate if f is removed 7. Add or remove the feature which gives best improvement 8. Repeat (5-7) until local optima is reached 9. Return F</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,103.68,486.80,395.65,141.58"><head>Table 1 :</head><label>1</label><figDesc>Results of Runs evaluated with EER, AUC and the hierarchical measuresA Appendix: Selected Features</figDesc><table coords="4,286.62,486.80,212.71,20.69"><row><cell>. EER Avg. AUC</cell><cell>Avg. AS with AA</cell><cell>Avg. AS without AA</cell></row></table><note coords="6,101.09,745.55,214.32,8.44"><p><p>1 </p>'g' indicates global feature and 'l' indicates local feature.</p></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,110.48,685.81,402.52,8.74;4,110.48,697.77,402.52,8.74;4,110.48,709.72,118.62,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,336.33,685.81,176.67,8.74;4,110.48,697.77,127.79,8.74">Scene classification using a hybrid generative/discriminative approach</title>
		<author>
			<persName coords=""><forename type="first">Anna</forename><surname>Bosch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Andrew</forename><surname>Zisserman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Xavier</forename><surname>Muoz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,247.13,697.77,265.88,8.74;4,110.48,709.72,21.83,8.74">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="712" to="727" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,110.48,729.65,402.52,8.74;4,110.48,741.60,305.82,10.95" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="4,279.92,729.65,202.60,8.74">LIBSVM: a library for support vector machines</title>
		<author>
			<persName coords=""><forename type="first">Chih-Chung</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Chih-Jen</forename><surname>Lin</surname></persName>
		</author>
		<ptr target="http://www.csie.ntu.edu.tw/~cjlin/libsvm" />
		<imprint>
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,110.48,112.02,402.52,8.74;5,110.48,123.98,402.52,9.02;5,110.48,136.65,243.36,8.30" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,452.55,112.02,60.45,8.74;5,110.48,123.98,142.99,8.74">The PASCAL Visual Object Classes Challenge</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Everingham</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Van Gool</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">K I</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zisserman</surname></persName>
		</author>
		<ptr target="http://www.pascal-network.org/challenges/VOC/voc2007/workshop/index.html" />
	</analytic>
	<monogr>
		<title level="m" coord="5,287.03,123.98,78.57,8.74">VOC2007) Results</title>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,110.48,155.86,402.53,8.74;5,110.48,167.81,402.52,8.74;5,110.48,179.77,226.03,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,341.53,155.86,171.47,8.74;5,110.48,167.81,162.15,8.74">Beyond sliding windows: Object localization by efficient subwindow search</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">H</forename><surname>Lampert</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">B</forename><surname>Blaschko</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Hofmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,296.16,167.81,184.75,8.74;5,110.48,179.77,147.32,8.74">Computer Vision and Pattern Recognition</title>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
	</monogr>
	<note>CVPR 2008. IEEE Conference on</note>
</biblStruct>

<biblStruct coords="5,110.48,199.69,402.52,8.74;5,110.48,211.65,200.62,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,190.28,199.69,252.64,8.74">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,456.08,199.69,56.93,8.74;5,110.48,211.65,121.46,8.74">International Journal of Computer Vision</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,110.48,231.57,402.52,8.74;5,110.48,243.53,393.99,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,362.43,231.57,150.57,8.74;5,110.48,243.53,53.77,8.74">Semantic image retrieval with hsv correlograms</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ojala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Rautiainen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Matinmikko</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Aittola</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,185.60,243.53,213.72,8.74">12th Scandinavian Conference on Image Analysis</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="621" to="627" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,110.48,263.45,402.52,8.74;5,110.48,275.41,402.52,8.74;5,110.48,287.36,262.10,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="5,312.39,263.45,200.61,8.74;5,110.48,275.41,15.56,8.74">Comparing images using color coherence vectors</title>
		<author>
			<persName coords=""><forename type="first">Greg</forename><surname>Pass</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ramin</forename><surname>Zabih</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Justin</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,152.15,275.41,360.86,8.74;5,110.48,287.36,46.74,8.74">MULTIMEDIA &apos;96: Proceedings of the fourth ACM international conference on Multimedia</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="1996">1996</date>
			<biblScope unit="page" from="65" to="73" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,110.48,307.29,402.53,8.74;5,110.48,319.24,402.52,8.74;5,110.48,331.20,68.26,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,256.82,307.29,256.18,8.74;5,110.48,319.24,49.18,8.74">Where am i: Place instance and category recognition using spatial pact</title>
		<author>
			<persName coords=""><forename type="first">Jianxin</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">James</forename><forename type="middle">M</forename><surname>Rehg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,168.00,319.24,345.00,8.74;5,110.48,331.20,8.97,8.74">Computer Vision and Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note>IEEE Computer Society Conference on</note>
</biblStruct>

<biblStruct coords="5,110.48,351.12,402.52,8.74;5,110.48,363.08,402.52,8.74;5,110.48,375.03,89.11,8.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,352.74,351.12,160.26,8.74;5,110.48,363.08,286.50,8.74">Local features and kernels for classification of texture and object categories: A comprehensive study</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Marszalek</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Lazebnik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Schmid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,407.95,363.08,100.62,8.74">Int. J. Comput. Vision</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="213" to="238" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,110.48,394.96,402.52,8.74;5,110.48,406.91,398.56,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="5,257.51,394.96,251.06,8.74">Em-dd: An improved multiple-instance learning technique</title>
		<author>
			<persName coords=""><forename type="first">Qi</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sally</forename><forename type="middle">A</forename><surname>Goldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,122.93,406.91,225.02,8.74">Advances in Neural Information Processing Systems</title>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="1073" to="1080" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
