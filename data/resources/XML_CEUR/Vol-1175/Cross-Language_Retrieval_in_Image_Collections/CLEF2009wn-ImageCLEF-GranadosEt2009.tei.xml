<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,176.52,75.29,253.49,12.58">MIRACLE (FI) at ImageCLEFphoto 2009</title>
				<funder ref="#_KzrHqv4">
					<orgName type="full">Spanish R+D National Plan</orgName>
				</funder>
				<funder ref="#_VMKhPtw">
					<orgName type="full">Madrid&apos;s R+D Regional Plan</orgName>
				</funder>
				<funder ref="#_aJ7yeHT">
					<orgName type="full">Spanish Ministry of Education and Science</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,158.28,113.64,50.07,9.02"><forename type="first">R</forename><surname>Granados</surname></persName>
							<email>rgranados@fi.upm.es</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Universidad Politécnica de Madrid</orgName>
								<orgName type="institution" key="instit2">UPM</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,216.55,113.64,50.07,9.02"><forename type="first">X</forename><surname>Benavent</surname></persName>
							<email>xaro.benavent@uv.es</email>
							<affiliation key="aff1">
								<orgName type="institution">Universidad de Valencia</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,274.79,113.64,37.85,9.02"><forename type="first">R</forename><surname>Agerri</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Universidad Politécnica de Madrid</orgName>
								<orgName type="institution" key="instit2">UPM</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,320.81,113.64,73.36,9.02"><forename type="first">A</forename><surname>García-Serrano</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Universidad Nacional de Educación a Distancia</orgName>
								<orgName type="institution" key="instit2">UNED</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,402.42,113.64,40.34,9.02"><forename type="first">J</forename><forename type="middle">M</forename><surname>Goñi</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Universidad Politécnica de Madrid</orgName>
								<orgName type="institution" key="instit2">UPM</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,210.36,125.16,36.65,9.02"><forename type="first">J</forename><surname>Gomar</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Universidad de Valencia</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,255.29,125.16,38.67,9.02"><forename type="first">E</forename><surname>De Ves</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Universidad de Valencia</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,302.17,125.16,46.64,9.02"><forename type="first">J</forename><surname>Domingo</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Universidad de Valencia</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,357.06,125.16,36.07,9.02"><forename type="first">G</forename><surname>Ayala</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Universidad de Valencia</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,176.52,75.29,253.49,12.58">MIRACLE (FI) at ImageCLEFphoto 2009</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">47124D2E22514B98421BA7410EFF4CA0</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.2 Information Storage</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital libraries. H.2 [Database Management]: H.2.5 Heterogeneous Databases</term>
					<term>E.2 [Data Storage Representations] Information Retrieval, Content-Based Image Retrieval, Merged result lists, Indexing, Named Entities Recognition</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The Miracle-FI participation at ImageCLEF 2009 photo retrieval task main goal was to improve the merge of content-based and text-based techniques in our experiments. The global system includes our own implemented tool IDRA (InDexing and Retrieving Automatically), and the Valencia University CBIR system. Analyzing both "topics_part1.txt" and "topics_part2.txt" task topics files, we have built different queries files, eliminating the negative sentences with the text from title and clusterTitle or clusterDescription, one query for each cluster (or not) of each topic from 1 to 25 and one for each of the three images of each topic from 26 to 50. In the CBIR system the number of low-level features has been increased from the 68 component used at ImageCLEF 2008 up to 114 components, and in this edition only the Mahalanobis distance has been used in our experiments. Three different merging algorithms were developed in order to fuse together different results lists from visual or textual modules, different textual indexations, or cluster level results into a unique topic level results list. For the five runs submitted we observe that MirFI1, MirFI2 and MifFI3 obtain quite higher precision values than the average ones. Experiment MirFI1, our best run for precision metrics (very similar to MirFI2 and MirFI3), appears in the 16th position in R-Precision classification and in the 19th in MAP one (from a total of 84 submitted experiments). MirFI4 and MirFI5 obtain our best diversity values, appearing in position 11th (over 84) in cluster recall classification, and being the 5th best group from all the 19 participating ones.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.22" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Miracle-FI participation at ImageCLEF 2009 photo retrieval task <ref type="bibr" coords="1,355.94,648.24,16.64,9.02" target="#b15">[17]</ref> main goal was to improve the merge of content-based and text-based techniques in our experiments. The global system includes our own implemented tool IDRA (InDexing and Retrieving Automatically), and the Valencia University CBIR system.</p><p>The BELGA Collection image captions were preprocessing to build a semi-structured XML description similar to the ImageCLEFphoto08 task <ref type="bibr" coords="1,231.12,700.26,15.35,9.02" target="#b9">[11]</ref>. Also the images have been preprocessed for CBIR module because some of them have some bands on the frame of the image with color pixels of the RGB and MCY system colors. As we realize that they don't follow any established format, the solution adopted was to reduce all the images to the 90% of his real size in order to eliminate the different bands and the white pixels frames.</p><p>Analyzing both "topics_part1.txt" and "topics_part2.txt" task topics files, we have built different queries files: [qf2] "BELGAtopics-tctcd-(q-cl)-fQ.txt": one query for each cluster of each topic with the text from title, clusterTitle and clusterDescription (eliminating the negative sentences and negative clusters), [qf3] "BELGAtopics-tct-(q-cl)-fQ.txt": the same as above but just with the text from title and clusterTitle, [qf4] "BELGAtopics-topEnt(1..25)+capEnt(26..50)-(q-cl)-fQ.txt": one query for each cluster (except negatives ones) of each topic from 1 to 25 and one for each of the three images of each topic from 26 to 50, [qf5] "BELGAtopics-cap(title+desc)-(26..50)-(q-cl)-fQ.txt": one query for each one of the three images of each topic from 26 to 50, obtained from the title and description fields of the XML captions.</p><p>In the CBIR system the number of low-level features has been increased from the 68 component used at ImageCLEF 2008 up to 114 components, mainly due to the use of local color histogram descriptors that were not use last year. This edition only the Mahalanobis distance has been used in our experiments.</p><p>Three different merging algorithms were developed in order to fuse together different results lists from visual or textual modules, different textual indexations, or cluster level results into a unique topic level results list: MAXmerge (the algorithm selects the results from the N lists which have a higher relevance value), EQUImerge (the algorithm selects the first result of each query (cluster), not selected yet), and ENRICH (this merging uses two results lists, a main list and a support list, and when a concrete result appears in both lists, the relevance will be increased).</p><p>The five runs submitted were: [run1] "MirFI1_T-CT-I_TXT-IMG": launching [qf3], reordering textual results list with CBIR system, and merging both lists with the ENRICH algorithm, [run2] "MirFI2_T-CT-CD-I_TXT-IMG": the same as above, but launching  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Description</head><p>The global system (shown at Fig. <ref type="figure" coords="2,220.05,670.32,4.18,9.02" target="#fig_1">1</ref>) includes our own implemented tool IDRA (InDexing and Retrieving Automatically), and the Valencia University CBIR system. The main goal, using IDRA <ref type="bibr" coords="2,433.79,681.84,16.74,9.02" target="#b10">[12]</ref> with such a large collection, was to analyze how the obtained results from the textual module could be improved using information from the content-based module. In this year, a global strategy for all experiments has been that the Content-Based module always starts working with a selected textual results list as part of his input data (different from our participation at ImageCLEF 2008 <ref type="bibr" coords="2,226.51,727.86,14.99,9.02" target="#b9">[11]</ref>). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Collection preprocessing</head><p>ImageCLEFphoto09 task uses the so-called "BELGA Collection" which contains 498,920 images from Belga News Agency. Each photograph is accompanied by a caption composed of English text up to a few sentences in length <ref type="bibr" coords="3,99.33,124.02,10.61,9.02">[3]</ref>. Image captions are provided without a specific format. Because of this, we preprocess the captions file to build a semi-structured XML description for each image, similar to the used in the ImageCLEFphoto08 task <ref type="bibr" coords="3,89.67,147.06,10.63,9.02" target="#b0">[1]</ref>. This format includes 8 tags (docno, title, description, notes, location, date, image and thumbnail), which we try to fill preprocessing the captions texts. This preprocess consists on trying to identify in each caption the appropriate part of the text to fill the XML tags. We can see an example of this transformation in Fig. <ref type="figure" coords="3,479.20,170.04,3.77,9.02">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 2. "caption TO XML" example</head><p>The images of the database have been pre-processed for the Content-Based Image module because some of them have extra-information on the image itself. This extra-information consists of some bands on the frame of the image with color pixels of the RGB and MCY system colors. This kind of information is often used for color calibration. So that, the first attempt was to use this extra-information in order to calibrate the color images of the database. But, after a visual analysis of different images we realize that they don't follow an established format. At fig. <ref type="figure" coords="3,102.17,442.56,5.01,9.02" target="#fig_2">3</ref> different images formats are shown: two vertical color bands, two horizontal color bands, only one color band, some color bands have the two color systems (RGB and MCY), others only one of the color systems, others extra white frame of different sizes. Therefore, the solution adopted was to reduce all the images to the 90% of his real size in order to eliminate the different bands and the white pixels frames. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Queries files construction</head><p>Analyzing both "topics_part1.txt" and "topics_part2.txt" task topics files, we built different queries files to be launched against the IDRA indexation as the first step in the generation of our experiments. The IDRA queries format separated by a blank. The different queries files constructed are explained in the following using the example in Fig. <ref type="figure" coords="4,135.94,84.72,5.01,9.02" target="#fig_3">4</ref> of this year's topics (from 'Topics -part 1') shown in the official website of the task <ref type="bibr" coords="4,484.94,84.72,15.28,9.02" target="#b12">[14]</ref>.  [qf1] example -[qf2] "BELGAtopics-tctcd-(q-cl)-fQ.txt": one query for each cluster of each topic with the text from title, clusterTitle and clusterDescription. We eliminate the negative sentences (those containing words "not" or "irrelevant"). We do not include the negative clusters as "soccer -belgium -spain -beach -italynetherlands". [qf2] would contain the queries shown in Fig. <ref type="figure" coords="4,347.54,493.92,5.01,9.02">6</ref> for the topic in the example of Fig. The associated text of each query is obtained extracting the named entities (with the NER tagger module) from the clusterTitle and clusterDescription fields of the corresponding topic, in the case of topics 1 to 25, and from the associated XML files for each of the three images in the case of topics 26 to 50. In the case of the topic example in Fig. <ref type="figure" coords="5,280.16,107.76,3.74,9.02" target="#fig_3">4</ref>, the corresponding constructed queries in [qf4] would be:</p><p>0-1 soccer belgium belgium belgium soccer soccer match 0-2 spain spain soccer spain spain team soccer soccer match 0-3 beach soccer soccer soccer beach match beach match 0-4 italy soccer soccer italy italy team soccer soccer match. 0-5 soccer netherlands netherlands netherlands team soccer soccer match netherlands league 1-1 … </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">IDRA text-based index and retrieval</head><p>IDRA textual retrieval is based on the VSM approach using weighted vectors based on the TF-IDF weight.</p><p>Applying this approach, a representing vector will be calculated for each one of the image captions in the collection. The components of the vectors will be the weight values for the different words in the collection. When a query is launched, a vector for that query is also calculated and compared with all the vectors stored during the index process. This comparison will generate the ranked results list for the launched query.</p><p>The textual retrieval task architecture can be seen in the Fig. <ref type="figure" coords="5,334.48,365.22,3.76,9.02" target="#fig_1">1</ref>. Each one of the components takes care of a specific task. These tasks will be sequentially executed:</p><p>-Text Extractor. Is in charge of extracting the text from the different files. It uses the JDOM Java API to identify the content of each of the tags of the captions XML files. This API has problems with some special characters, so it is needed to carry out a pre-process of the text to eliminate them.</p><p>-Preprocess. This component process the text in two ways: o special characters deletion: characters with no statistical meaning, like punctuation marks, are eliminated. o stopwords detection: exclusion of semantic empty words from a new constructed list, different from last year one.</p><p>-XML Fields Selection. With this component, it is possible to select the desired XML tags of the captions files, which will compound the associated text describing each image. In the captions XML files there are eight different tags (DOCNO, TITLE, DESCRIPTION, NOTES, LOCATION, DATE, IMAGE and THUMBNAIL). In the index process, the selected tags from the captions XML files had been three: TITLE, DESCRIPTION, and LOCATION.</p><p>-IDRA Index. This module indexes the selected text associated with each image (its XML caption). The approach consists in calculate the weights vectors for each one of the images selected texts. Each vector is compounded by the TF-IDF weights values <ref type="bibr" coords="5,303.39,584.69,16.64,9.02" target="#b14">[16]</ref> of the different words in the collection. TF-IDF weight is a statistical measure used to evaluate how important a word is to a text in a concrete collection.</p><formula xml:id="formula_0" coords="5,129.96,624.06,109.26,27.98">⎟ ⎠ ⎞ ⎜ ⎝ ⎛ = - i j i n N t IDF TF 2 log *</formula><p>, t i,j : number of occurrences of the word t j in caption text T i . N: total number of images captions in the collection. n i : number of captions in which appears the word t i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(1)</head><p>All the weights values of each vector will be then normalized using the Euclidean distance between the elements of the vector. Therefore, the IDRA Index process update the next values for each one of the words appearing in the XML captions collection: n i : number of captions in which appears the word t i , T i : identifier of the image XML caption, t i,j : number of occurrences of the word t j in a caption text T i , idf j : inverse document frequency ( log 2 (N/n i ) ) in T i , E i : Euclidean distance in the corresponding vector used to normalize, w j,i : weight of word t j in T i .</p><p>-IDRA Search. For the query text is also calculated his weights vector in the same way as above. Now, the similarity between the query and an image caption will depend on the proximity of their associated vectors. To measure the proximity between two vectors we use the cosine.</p><formula xml:id="formula_1" coords="6,186.00,121.96,234.04,31.72">∑ ∑ ∑ = = i q i q i j i j i j i j i w w w w w w q T sim , * , , * , , , * * ) Ö cos( ) , (<label>(2)</label></formula><p>This value of similarity will be calculated between the query and all the images captions indexed, and the images will be ranked in descending order as the IDRA result list.</p><p>To index the collection, the system needs approximately 2 days to index each one of the 5 parts in which the collection was divided to be indexed. These 5 indexations processes can be executed concurrently. Queries file response time depends on the concrete queries file launched (on the large of the queries texts), but it takes over 10 hours to obtain a results file for 119 queries (119 queries at cluster level).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Named Entity Recognition (NER) functionality</head><p>The general aim of using Named Entity Recognition (NER) in our approach was to perform retrieval using the named entities extracted from both the documents (XML-structured captions as discussed in section 2.1) and the topics. Due to time constraints, only the later was used in one of the runs submitted <ref type="bibr" coords="6,406.51,314.52,26.61,9.02">([run5]</ref>).</p><p>Considering the nature of the text in the topics, namely, all words were lowercase, topics in the part 2 file, did not contain enough text, etc., would not make it easy to use an off-the-self named entity tagger, we decided instead to tag (tokenize, Part-Of-Speech and NER) the captions document as released by the imageCLEF organisers. The C&amp;C taggers <ref type="bibr" coords="6,191.59,366.54,11.71,9.02" target="#b4">[6]</ref> were used off-the-self. After that, our task was reduced to extract those unique linguistic expressions that were tagged as Location, Person or Organization.</p><p>However, we soon realized that the resulting annotation was not correctly picking up information which seems to be crucial to determine the topic of the images. More specifically, "Time" would refer to an Organization whereas the description "Time magazine correspondent" would refer to a person and, as such, the modifier correspondent seems relevant to describe the situation captured by a given image. Most of these modifiers would not be picked-up by a NER tagger because they are not in uppercase.</p><p>This turned out to be a symptom of a more general problem as presented in <ref type="bibr" coords="6,389.79,459.00,10.64,9.02" target="#b7">[9]</ref>. For tasks such as IR, it is not sufficient to have low level tools that produce high quality linguistic annotation and analysis, but it is also required that the results of the various levels of annotation be consistent with each other Our proposal aims to exploit the interaction between the various levels of annotations (POS, NER and Chunks) provided by the C&amp;C taggers in order to obtain a better bracketing of named entities. The general idea is to create foci consisting of those words or expressions marked-up as named entities. Whenever the C&amp;C tagger annotates a word as a named entity, a chunk/phrase is built around it by attaching those surrounding/satellites terms that act as modifiers of the named entity according to their POS and membership to a particular chunk. We are currently able to deal with periods and abbreviations, with prepositions, adjectives and nouns. This approach allows us to extract entities such as Paris-Roubaix race, princess Mathilde, Leonardo da Vinci international airport (instead of Leonardo da Vinci), District of Columbia, Royal Palace of Brussels, etc. The following caption (id 1470132) is illustrative of our procedure:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>"American photojournalist James Nachtwey in a file photograph from May 18 2003 as he is awarded the Dan David prize in Tel Aviv for his out standing contribution to photography. It was announced by Time magazine on Thurs day, 11 December 2003 that Nachtwey was injured in Baghdad along with Time magazine senior correspondent Michael Weisskopf when a hand grenade was thrown into a Humvee they were traveling in with the US Army. Both journalists are reported in stable condition and are being evacuated to a US military hospital in Germany."</head><p>On the one hand, the named entities annotated by the tagger for this text are: American James Nachtwey, Dan David, Tel Aviv, Baghdad, Michael Weisskopf, US Army, US, Germany, and Nachtwey. On the other, the descriptions extracted by our system are: American photojournalist James Nachtwey, Dan David prize, Tel Aviv, Baghdad, Time magazine senior correspondent Michael Weisskopf, US Army, US military hospital, Germany and Natchtwey. It is particularly noticeable that our system was able to recognize Time magazine, and that the topic of the caption is about the Dan David prize and a US military hospital in Germany. This approach was used to extract both the named entities and descriptions of all the captions. We then used the lowercase version of the entities found in the captions that were present in the part 1 file of the topics. This method was also applied to the captions corresponding to the images that formed the clusters in part 2 of the topics. They constituted the queries file [qf4] for the [run5] (see section 2.2 and 3). The total process of annotation, analysis, extraction of entities/descriptions took 87 machine hours (on a standard Pentium 4 PC).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Visual Retrieval</head><p>The VISION-Team at the Computer Science Department of the University of Valencia has its own CBIR system mainly used for relevance feedback algorithms evaluation <ref type="bibr" coords="7,311.21,196.02,10.83,9.02" target="#b6">[8,</ref><ref type="bibr" coords="7,325.41,196.02,11.89,9.02" target="#b13">15]</ref>, and that was used for ImageCLEF 2008 for the first time. The low-level features of the CBIR system have been adapted for the images of the new image database (2009) taking into account the results of the last year.</p><p>As in most CBIR systems, a feature vector represents each image. The first step at the Visual Retrieval system is extracting these features for all the images on the database as for each of the cluster query topic images for each question. We use different low-level features describing color and texture to build a vector of features. The number of low-level features has been increased from the 68 component (ImageCLEF 2008) up to 114 components at the current edition. This increment is mainly due to the use of local color histogram descriptors that were not use last year.</p><p>• Color information: Color information has been extracted calculating both local and global histograms of the images using a bin of size 10x3 on a HSV color system. Local histograms have been calculated dividing the images in four fragments of the same size. For this database, only the H (hue) component has been used so that the other values where almost zero for as it happened at the IAPR database. Therefore, a feature vector of 10 components for the global histogram, and 40 components for the local histograms represent the color information of the image. • Texture information: As it was done for the IAPR data base, six feature textures have been computed</p><p>for this repository respectively. The first three ones use code from the implementation done by Smith and Burn in Meastex <ref type="bibr" coords="7,194.87,404.94,15.55,9.02" target="#b17">[19]</ref>; the rest have been implemented by the authors. The total of texture features builds a vector of 64 components: o Gabor Convolution Energies <ref type="bibr" coords="7,260.44,427.92,15.33,9.02" target="#b8">[10]</ref>.</p><p>o Gray Level Coocurrence Matrix also known as Spatial Gray Level Dependence <ref type="bibr" coords="7,463.08,439.44,10.63,9.02" target="#b5">[7]</ref>. o Gaussian Random Markov Fields <ref type="bibr" coords="7,279.67,450.96,10.64,9.02" target="#b2">[4]</ref>.</p><p>o The granulometric distribution function, first proposed by Dougherty <ref type="bibr" coords="7,428.72,462.42,10.61,9.02" target="#b3">[5]</ref>. We have used here not the raw distribution but the coefficients that result of fitting its plot with a B-spline basis. o Finally, the Spatial Size Distribution <ref type="bibr" coords="7,292.94,485.46,10.61,9.02" target="#b1">[2]</ref>. We have used two different versions of it by using as the structuring elements for the morphological operation that get size both a horizontal and a vertical segment.</p><p>The second step is to calculate the similarity distance between the features vectors from each image on the database to each the cluster images. Last edition (ImageCLEF 2008), we tested two different metrics to calculate this distance: the Euclidean and the Mahalanobis. In all experiments better results were obtained with the Mahalanobis distance due to the fact that this measure takes into account the correlations of the data set and is scale-invariant being this feature very useful because the broad differences between the different low-level feature values. Therefore, this edition only the Mahalanobis distance has been used in our experiments. These sorted lists are passed to the merging module of the global system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Merging algorithms</head><p>Different merging algorithms were developed in order to fuse together different results lists from visual or textual modules, different textual indexations, or cluster level results into a unique topic level results list. All the 3 merging algorithms detailed here require trec_eval format <ref type="bibr" coords="7,326.59,688.74,16.74,9.02" target="#b17">[19]</ref> for input results lists, which is the format required by the ImageCLEF organization to submit the definitive runs.</p><p>MAXmerge. This algorithm is used to fuse together the N (configurable value) results lists obtained when a concrete queries file is launched against the N indexations corresponding to the N parts in which the collection was divided to be indexed. For each query, the algorithm selects the results from the N lists which have a higher relevance value for the corresponding query, independently of the list the results appears in. The maximum number of results per query in the resulting list is set up to 1000 ('max' is a configurable parameter).</p><p>EQUImerge. When a results list contains results for queries which references clusters (not topics), this algorithm is used to select the formers represents of each cluster to build a unique results list with results for queries which references topics. The algorithm selects the first result of each query-cluster, not selected yet, to build the results list for the corresponding query. A preliminary step is carried out to separate the results into several lists depending on the number of cluster (inside each topic) the results belong to. The relevance value will be decremented (configurable value 'decr') for each result starting with the original relevance value of the first selected result. The maximum number of results per query is set up to 1000 ('max' is a configurable parameter).</p><p>ENRICH. This merging uses two results lists, a main list and a support list. The merged results list will have a maximum of 1000 results per query (configurable). If a concrete result appears in both lists for the same query, the relevance of this result in the merged list will be increased in the following way:</p><p>( )  <ref type="bibr" coords="8,455.82,255.72,11.68,9.02" target="#b4">(6)</ref> Relevance values will be then normalized from 0 to 1. Every result appearing in the support list but not in the main one (for each query), will be added at the end of the corresponding list. In this case, relevance values will be normalized according with the lower value in the main list. In the last year implementation of this algorithm, this addition didn't work correctly, so this year it has been modified in a proper way. In this experiment, main and support lists are compound by a maximum of 1000 results for each query. Also the merged lists resulting will be limited to the same number of results per query.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments (submitted runs)</head><p>This campaign 5 different runs were submitted to the ImageCLEFphoto2009. All of them were based on the 5parts indexation carried out using the TITLE, DESCRIPTION and LOCATION XML tags. Runs start from the launch of some of the queries files described in section 2.2. When one of these files is launched, it is against these 5 indexations and later, the 5 obtained results lists over each indexation are merged using the MAXmerge algorithm.</p><p>-[run1] "MirFI1_T-CT-I_TXT-IMG": mixed (textual/visual) experiment launching [qf3], reordering this textual results list with content-based results, and merging both lists with the ENRICH algorithm.</p><p>-[run2] "MirFI2_T-CT-CD-I_TXT-IMG": the same as above, but launching [qf2].</p><p>- As it can be observed, all the queries files used in the submitted experiments were built at cluster level, that is, with different queries for the different clusters of a topic, as explained in the queries files construction (section 2.2). The obtained results lists will have results for each one of the clusters of each topic, and EQUImerge algorithm will be applied to fuse together the different clusters-based lists into a unique query-based one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results and concluding remarks</head><p>After the evaluation by the task organizers, obtained results for each of the submitted experiments are presented in Table <ref type="table" coords="8,107.18,713.34,3.75,9.02" target="#tab_3">1</ref>. The table shows for each run: the identifier, the mean average precision (MAP), the R-Precision, the precision at 10 and 20 first results, the number of relevant images retrieved (out of a total of 34887 relevant images in the collection), and the cluster recall at 10 and 20. Average values from all the experiments presented to the task for these metrics are also shown in the table, as well as the best value obtained for each of the metrics. MAP, R-Precision and CR@10 values are all shown in Fig. <ref type="figure" coords="9,311.82,84.72,5.01,9.02">9</ref> in order to be visually compared. At first sight, we can observe that MirFI1, is our best run for precision metrics (very similar to MirFI2 and MirFI3), and appears in the 16th position in R-Precision classification and in the 19th in MAP one (from a total of 84 submitted experiments). 19 groups participate in the task and only 6 of them obtain better precision results than our best experiment.</p><p>Regarding the diversity metrics (cluster recall at 10 an 20, CR@10 and CR@20), MirFI4 and MirFI5 obtain our best diversity values, appearing in position 11th (over 84) in cluster recall classification, and being the 5th best group from all the 19 participating ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 9. Comparison of own experiments with best and average values</head><p>Comparing obtained results from experiments MirFI1 and MirFI2, we can see that not using CD (cluster description) tag from the topics is a quite better for precision results and very similar in diversity ones. So we can say that the addition of this field in the queries construction step was not very useful. Obtained results for experiments MirFI2 and MirFI3 are almost the same. So we can conclude that the use of the ENRICH merging algorithm with the visual re-ranked results list, does not affect the results in a significant way.</p><p>MirFI3 and MirFI4 are differentiated in the way of constructing the second half of the queries (topics from 26 to 50). As explained in sections 2.2 and 3, MirFI4 extracts the text from the captions corresponding to the example images included in the second part of the topics. The evaluation of the results shows that MirFI3 obtains better precision results than MirFI4, but worse diversity ones. One reason is that the use of the captions text adds more information to the queries, which is useful for the diversity aim, is noise for the precision one.</p><p>The goal of experiment MirFI5 was to analyze if results could be improved with the use of NER techniques for the construction of the queries. The obtained precision results for this experiment was our worse ones (seems Metrics % as a lot of noise was introduced) but the addition of entities information to the queries, improves the diversity results. Experiments MirFI4 and MirFI5, also show how this additional information improves the diversity results, but makes the precision ones worse.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,275.19,309.72,249.26,9.02;2,70.92,321.24,453.63,9.02;2,70.92,332.69,453.50,9.02;2,70.92,344.21,453.58,9.02;2,70.92,355.73,453.53,9.02;2,70.92,367.19,453.71,9.02;2,70.92,378.71,453.47,9.02;2,70.92,390.23,453.66,9.02;2,70.92,401.69,334.18,9.02"><head></head><label></label><figDesc>[qf2], [run3] "MirFI3_T-CT-CD_TXT": textual experiment launching [qf2], [run4] "MirFI4_T-CT-CD-I_TXT": topics 1 to 25 as [run3], and topics 26 to 50, launching [qf5], [run5] "MirFI5_T-CT-CD-I_TXT": textual experiments with NER. [qf4]. All the queries files in the submitted experiments were built from different queries of different clusters of a topic, so the EQUImerge algorithm was applied to fuse the different clusters-based result lists into an unique one. In the results, we observe that experiment MirFI1, our best run for precision metrics (very similar to MirFI2 and MirFI3), appears in the 16th position in R-Precision classification and in the 19th in MAP one (from a total of 84 submitted experiments). MirFI4 and MirFI5 obtain our best diversity values, appearing in position 11th (over 84) in cluster recall classification, and being the 5th best group from all the 19 participating ones.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="2,248.64,605.03,98.09,9.02"><head>Fig. 1 .</head><label>1</label><figDesc>Fig. 1. System overview</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="3,154.50,652.14,286.49,9.02"><head>Fig. 3 .</head><label>3</label><figDesc>Fig. 3. Different format images from the Belga News Agency database.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="4,155.46,318.72,284.57,9.02;4,88.80,342.24,435.76,9.02;4,106.80,353.76,326.13,9.02;4,106.38,372.43,411.12,7.18;4,106.38,381.67,411.18,7.18;4,106.38,390.85,411.11,7.18;4,106.38,400.03,411.21,7.18;4,106.38,409.27,411.13,7.18;4,106.38,418.51,167.84,7.18"><head>Fig. 4 .</head><label>4</label><figDesc>Fig. 4. Example of ImageCLEFphoto09 topics (from 'Topics -part 1') -[qf1] "BELGAtopics-all-(q)-fQ.txt": one query per topic containing one stream with all the text from all the clusters (not used for runs). [qf1] would contain the query shown in Fig. 5. 0 soccer soccer belgium Relevant images contain photographs of the Belgium team in a soccer match. spain soccer Relevant images contain photographs of the Spain team in a soccer match. beach soccer contain Relevant images contain photographs of a soccer beach match. italy soccer Relevant images contain photographs of the Italy team in a soccer match. soccer netherlands Relevant images contain photographs of the Netherlands team in a soccer match or the teams in Netherlands' league. soccer -belgium -spain -beach -italy -netherlands Relevant images contain photographs of any aspects or subtopics of soccer which are not related to the above clusters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="4,256.32,435.96,82.76,9.02"><head>Fig 5 .</head><label>5</label><figDesc>Fig 5. [qf1] example</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="4,256.32,585.30,82.76,9.02;4,88.80,608.82,435.69,9.02;4,106.80,620.34,330.92,9.02;4,106.38,639.01,87.76,7.18;4,106.38,648.25,77.52,7.18;4,106.38,657.43,79.26,7.18;4,106.38,666.61,74.36,7.18;4,106.38,675.85,100.97,7.18;4,106.38,685.03,20.62,7.18"><head>4 :0- 1 1 …Fig 6 .Fig 7 .</head><label>41167</label><figDesc>Fig 6. [qf2] example -[qf3] "BELGAtopics-tct-(q-cl)-fQ.txt": the same as above but just with the text from title and clusterTitle. Fig 7. shows the constructed queries from the example topic for [qf3]. 0-1 soccer soccer Belgium 0-2 soccer spain soccer 0-3 soccer beach soccer 0-4 soccer italy soccer 0-5 soccer soccer Netherlands 1-1 …</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="5,256.32,189.96,82.76,9.02;5,88.80,213.42,435.78,9.02;5,106.80,224.94,256.26,9.02;5,403.99,224.94,120.65,9.02;5,106.80,236.40,282.64,9.02"><head>Fig 8 .</head><label>8</label><figDesc>Fig 8. [qf4] example -[qf5] "BELGAtopics-cap(title+desc)-(26..50)-(q-cl)-fQ.txt": one query for each one of the three images of each topic from 26 to 50. The text for each query is from the concatenation of the TITLE and DESCRIPTION fields of the XML files for these captions.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="8,106.80,526.56,287.82,9.02;8,88.80,544.02,435.85,9.02;8,106.80,555.54,168.30,9.02;8,88.80,573.06,435.69,9.02;8,106.80,584.52,85.54,9.02"><head></head><label></label><figDesc>[run3] "MirFI3_T-CT-CD_TXT": textual experiment launching [qf2]. -[run4] "MirFI4_T-CT-CD-I_TXT": the first part (topics 1 to 25) doing exactly the same as [run3], and the second one (26 to 50) launching [qf5]. -[run5] "MirFI5_T-CT-CD-I_TXT": textual experiments treating with NER. [qf4] is launched to obtain the results list.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="9,96.60,108.24,400.15,140.42"><head>Table 1 .</head><label>1</label><figDesc>Results for the submitted experiments.</figDesc><table coords="9,96.60,137.95,400.15,110.70"><row><cell>Run Identifier</cell><cell>MAP</cell><cell cols="6">R-Prec Prec@10 Prec@20 RelRet CR@10 CR@20</cell></row><row><cell>MirFI1_T-CT-I_TXT-IMG</cell><cell>43.78</cell><cell>51.39</cell><cell>82.00</cell><cell>81.80</cell><cell>16547</cell><cell>64.51</cell><cell>72.00</cell></row><row><cell cols="2">MirFI2_T-CT-CD-I_TXT-IMG 42.25</cell><cell>50.11</cell><cell>80.00</cell><cell>81.00</cell><cell>16301</cell><cell>63.24</cell><cell>73.41</cell></row><row><cell>MirFI3_T-CT-CD_TXT</cell><cell>42.33</cell><cell>50.12</cell><cell>80.80</cell><cell>81.40</cell><cell>16301</cell><cell>63.51</cell><cell>73.31</cell></row><row><cell>MirFI4_T-CT-CD-I_TXT</cell><cell>27.84</cell><cell>36.96</cell><cell>47.40</cell><cell>48.90</cell><cell>13627</cell><cell>69.83</cell><cell>76.76</cell></row><row><cell>MirFI5_T-CT-CD-I_TXT</cell><cell>17.33</cell><cell>29.53</cell><cell>23.60</cell><cell>26.30</cell><cell>13498</cell><cell>68.49</cell><cell>72.82</cell></row><row><cell>average</cell><cell>29.08</cell><cell>34.09</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>54.67</cell><cell>62.35</cell></row><row><cell>best</cell><cell>50.64</cell><cell>56.43</cell><cell>--</cell><cell>--</cell><cell>--</cell><cell>82.39</cell><cell>86.07</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>This work has been partially supported by the <rs type="funder">Spanish R+D National Plan</rs>, by means of the project <rs type="projectName">BRAVO (Multilingual and Multimodal Answers Advanced Search -Information Retrieval</rs>), <rs type="grantNumber">TIN2007-67407-C03-03</rs>; by the <rs type="funder">Madrid's R+D Regional Plan</rs>, by means of the project <rs type="projectName">MAVIR (Enhancing the Access and the Visibility of Networked Multilingual Information for the Community of Madrid</rs>), <rs type="grantNumber">S-0505/TIC/000267</rs>; and by the <rs type="funder">Spanish Ministry of Education and Science</rs>, by means of the project <rs type="projectName">MCYT</rs>, <rs type="grantNumber">TIC2002-03494</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_KzrHqv4">
					<idno type="grant-number">TIN2007-67407-C03-03</idno>
					<orgName type="project" subtype="full">BRAVO (Multilingual and Multimodal Answers Advanced Search -Information Retrieval</orgName>
				</org>
				<org type="funded-project" xml:id="_VMKhPtw">
					<idno type="grant-number">S-0505/TIC/000267</idno>
					<orgName type="project" subtype="full">MAVIR (Enhancing the Access and the Visibility of Networked Multilingual Information for the Community of Madrid</orgName>
				</org>
				<org type="funded-project" xml:id="_aJ7yeHT">
					<idno type="grant-number">TIC2002-03494</idno>
					<orgName type="project" subtype="full">MCYT</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="10,74.30,272.49,450.14,8.11;10,82.26,282.87,360.75,8.11" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="10,283.94,272.49,240.50,8.11;10,82.26,282.87,15.80,8.11">Overview of the ImageCLEFphoto 2008 Photographic Retrieval Task</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Arni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Grubinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,116.50,282.87,163.31,8.11">Working Notes for the CLEF 2008 Workshop</title>
		<meeting><address><addrLine>Aarhus, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-09-19">17-19 September. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,74.30,293.19,450.17,8.11;10,82.26,303.57,289.13,8.11" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="10,174.65,293.19,261.82,8.11">Spatial Size Distributions. Applications to Shape and Texture Analysis</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Ayala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Domingo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,443.47,293.19,81.01,8.11;10,82.26,303.57,151.82,8.11">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1430" to="1442" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,74.30,324.27,450.19,8.11;10,82.26,334.59,254.52,8.11" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="10,190.24,324.27,245.62,8.11">Classification of Textures using Gaussian Markov Random Fields</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Chellapa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chatterjee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,442.88,324.27,81.62,8.11;10,82.26,334.59,144.05,8.11">IEEE Transactions on Acoustics Speech and Signal Processing</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="959" to="963" />
			<date type="published" when="1985">1985</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,74.30,344.97,450.32,8.11;10,82.26,355.29,93.10,8.11" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,182.93,344.97,222.46,8.11">Gray-scale morphological granulometric texture classification</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">R</forename><surname>Dougherty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,410.98,344.97,71.20,8.11">Optical Engineering</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2713" to="2722" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,74.30,365.67,450.18,8.11;10,82.26,375.99,167.15,8.11" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="10,169.70,365.67,292.24,8.11">Wide-coverage efficient statistical parsing with CCG and log-linear models</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Clark</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Curran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,471.01,365.67,53.47,8.11;10,82.26,375.99,38.81,8.11">Computational Linguistics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="493" to="553" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,74.30,386.37,450.22,8.11;10,82.26,396.69,307.60,8.11" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,263.89,386.37,257.05,8.11">Segmentation of high-resolution urban scene using texture operators</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">W</forename><surname>Conners</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">M</forename><surname>Trivedi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">A</forename><surname>Harlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,82.26,396.69,181.25,8.11">Computer Vision, Graphics, and Image Processing</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="310" />
			<date type="published" when="1984">1984</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,74.30,407.01,450.24,8.11;10,82.26,417.39,277.93,8.11" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="10,266.87,407.01,257.67,8.11;10,82.26,417.39,81.88,8.11">A novel Bayesian framework for relevance feedback in image contentbased retrieval systems</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>De Ves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Domingo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Ayala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zuccarello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,170.34,417.39,70.14,8.11">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1622" to="1632" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,74.30,427.71,450.17,8.11;10,82.26,438.09,442.20,8.11;10,82.26,448.41,348.97,8.11" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="10,200.43,427.71,169.01,8.11">Joint parsing and named entity recognition</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">R</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,394.16,427.71,130.31,8.11;10,82.26,438.09,442.20,8.11;10,82.26,448.41,38.79,8.11">Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics</title>
		<meeting>Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics<address><addrLine>Boulder, Colorado</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computational Linguistics</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="326" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,78.43,458.79,419.87,8.11" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,151.17,458.79,131.56,8.11">Gabor filters as texture discriminator</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Fogel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Sagi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,288.60,458.79,81.15,8.11">Biological Cybernetics</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="103" to="113" />
			<date type="published" when="1989">1989</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,78.44,469.11,446.04,8.11;10,82.26,479.49,442.24,8.11;10,82.26,489.81,90.29,8.11" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="10,312.16,469.11,212.32,8.11;10,82.26,479.49,176.84,8.11">MIRACLE-FI at ImageCLEFphoto 2008: Experiences in merging text-based and content-based retrievals</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Granados</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">X</forename><surname>Benavent</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Garcia-Serrano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Goñi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,279.56,479.49,171.55,8.11">Working Notes for the CLEF 2008 Workshop</title>
		<meeting><address><addrLine>Aarhus, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008-09-19">17-19 September. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,78.42,500.19,446.00,8.11;10,82.26,510.51,442.23,8.11;10,82.26,520.89,123.46,8.11" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,276.18,500.19,244.46,8.11">La herramienta IDRA (Indexing and Retrieving Automatically)</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Granados</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ana</forename><surname>García-Serrano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">M</forename><surname>Goñi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,82.26,510.51,442.23,8.11;10,82.26,520.89,27.00,8.11">Demostración en la XXV edición del Congreso Anual de la Sociedad Española para el Procesamiento del Lenguaje Natural</title>
		<meeting><address><addrLine>SEPLN´09</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,78.43,531.21,446.07,8.11;10,82.26,541.59,442.28,8.11;10,82.26,551.91,406.99,8.11" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="10,286.81,531.21,237.69,8.11;10,82.26,541.59,104.60,8.11">The IAPR TC-12 Benchmark: A New Evaluation Resource for Visual Information Systems</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,210.69,541.59,313.84,8.11;10,82.26,551.91,234.85,8.11">Proceedings of International Workshop OntoImage&apos;2006 Language Resources for Content-Based Image Retrieval, held in conjuction with LREC&apos;06</title>
		<meeting>International Workshop OntoImage&apos;2006 Language Resources for Content-Based Image Retrieval, held in conjuction with LREC&apos;06<address><addrLine>Genoa, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006-05-22">22 May 2006 (2006</date>
			<biblScope unit="page" from="13" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,78.42,562.29,287.82,8.11" xml:id="b12">
	<monogr>
		<ptr target="http://www.imageclef.org/2009/photo" />
		<title level="m" coord="10,82.29,562.29,141.28,8.11">ImageCLEF 2009 Photo Retrieval Task</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="10,78.44,572.61,446.04,8.11;10,82.26,582.99,255.11,8.11" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="10,305.79,572.61,218.69,8.11;10,82.26,582.99,59.14,8.11">Applying logistic regression to relevance feedback in image retrieval systems</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Leon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Zuccarello</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Ayala</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>De Ves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Domingo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,147.51,582.99,70.18,8.11">Pattern Recognition</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="2621" to="2632" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,78.44,593.31,445.96,8.11;10,82.26,603.69,46.53,8.11" xml:id="b14">
	<monogr>
		<title level="m" type="main" coord="10,240.25,593.31,132.36,8.11">Introduction to information retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schtze</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<publisher>Cambridge Univ Press</publisher>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,78.42,614.01,446.00,8.11;10,82.26,624.39,155.63,8.11" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="10,233.69,614.01,262.35,8.11">Diversity in photo retrieval: overview of the ImageCLEFPhoto task 2009</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Paramita</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,502.41,614.01,22.00,8.11;10,82.26,624.39,69.77,8.11">CLEF working notes 2009</title>
		<meeting><address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,78.43,634.71,445.99,8.11;10,82.26,645.09,46.58,8.11" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,160.94,634.71,157.17,8.11">Measuring texture classification algorithms</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Burns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="10,324.88,634.71,99.44,8.11">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="1495" to="1501" />
			<date type="published" when="1997">1997</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,78.43,655.41,205.14,8.11" xml:id="b17">
	<monogr>
		<ptr target="http://trec.nist.gov/" />
		<title level="m" coord="10,82.31,655.41,126.00,8.11">Text REtrieval Conference (TREC)</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
