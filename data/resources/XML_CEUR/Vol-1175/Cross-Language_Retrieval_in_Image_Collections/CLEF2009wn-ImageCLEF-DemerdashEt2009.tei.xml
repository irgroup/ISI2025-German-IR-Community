<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,188.56,148.86,225.87,15.15">CLaC at ImageCLEF 2009</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,177.65,182.75,92.41,8.74"><forename type="first">Osama</forename><forename type="middle">El</forename><surname>Demerdash</surname></persName>
							<email>osamael@cse.concordia.ca</email>
							<affiliation key="aff0">
								<orgName type="institution">Concordia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,278.52,182.75,63.56,8.74"><forename type="first">Sabine</forename><surname>Bergler</surname></persName>
							<email>bergler@cse.concordia.ca</email>
							<affiliation key="aff0">
								<orgName type="institution">Concordia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,364.78,182.75,60.57,8.74"><forename type="first">Leila</forename><surname>Kosseim</surname></persName>
							<email>kosseim@cse.concordia.ca</email>
							<affiliation key="aff0">
								<orgName type="institution">Concordia University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,188.56,148.86,225.87,15.15">CLaC at ImageCLEF 2009</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">08CA1EB1823C3457C0B178DC60E01B2D</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries Measurement, Performance, Experimentation Pseudo-relevance feedback, Semantic retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes our participation at ImageCLEF 2009. We participated in the photographic retrieval task (ImageCLEFPhoto). Our method is based on intermedia pseudo-relevance feedback. We have enhanced the pseudo-relevance feedback mechanism by using semantic selectional restrictions. We use Terrier for text retrieval and our own simple block-based visual retrieval engine. The results obtained at image-CLEF 2009 show that our method is robust and promising. However, there is room for improvement on the visual retrieval as well as the topics without cluster descriptions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>This paper describes our participation at ImageCLEF 2009. We participated in the photographic retrieval task (ImageCLEFPhoto). This year's task targeted promoting diversity in image search. It involved an annotated image collection of approximately half a million images, and fifty queries divided into two sets: one with a subject and provided specific subtopics (clusters), while the other with only a topic. A full description of the task can be found in <ref type="bibr" coords="1,372.14,588.68,9.96,8.74" target="#b3">[4]</ref>.</p><p>We submitted four runs, aiming at evaluating our method as well as the resources used. Similar to our participation last year, our method is based on intermedia pseudo-relevance feedback. However, to in order to account for the much larger data set, we have introduced some modifications to our visual component. We have also enhanced the textual retrieval component, as well as to the pseudo-relevance feedback mechanism by using semantic selectional restrictions.</p><p>The results obtained at imageCLEF 2009 show that our method is robust and promising. However there is room for improvement on the visual retrieval as well as the topics without cluster descriptions.</p><p>The rest of this paper is organized as follows: Section 2 describes the visual retrieval component, Section 3 the text processing of the query, Section 4 the enhanced pseudo-relevance feedback and Section 5 the results we obtained at ImageCLEF 2009, then we conclude the paper. Figure <ref type="figure" coords="2,136.44,385.12,4.98,8.74" target="#fig_0">1</ref> shows the different regional divisions used to analyze the image. In order to capture different levels of detail, we divide the image into 2X2, 3X3, 4X4 blocks yielding 4, 9, 16 equal partitions respectively. Due to the the much larger size of the data set compared to the IAPR TC-12 collection (60,000 images) used in previous years, we resorted to reducing the index by eleminating some of the descriptors we used previously, such as the grey-level and gradient-magnitude descriptors. The image is first converted to the Intensity/Hue/Saturation (IHS) color space, a perceptual color space which is more intuitive and reflective of human color perception than the RGB color space. This also allows for assigning more weight to the hue component which is a better discriminating feature as shown in <ref type="bibr" coords="2,272.62,480.76,9.96,8.74" target="#b5">[6]</ref>.</p><p>As has been illustrated before in <ref type="bibr" coords="2,252.14,492.72,9.96,8.74" target="#b1">[2]</ref>, the moments of histograms are efficient approximations of the entire histogram. Therefore, for each of the three-band color histograms of the divisions, the first two moments (the mean and the average energy) as well as the standard deviation are stored in the index.</p><p>For retrieval, the different partitions are compared to their counter parts in the query images. We selected the Manhattan distance (L 1 Norm) after investigating several other measures including the Euclidean and the Mahalanobis distances, combined with a measure for the number of blocks within a minimum threshold for the distance. Since all features were represented as histograms with the same number of bins (256), no normalization was necessary. The images in the database were ranked according to their highest proximity to any of the three query images. This choice presumes that our simple features do not perform equally well on all example images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Text Retrieval</head><p>The text is tokenized and preprocessed by removing stop words (grammatical words which do not contribute to the meaning) and punctuation. The rest of the terms are converted to lower case and stemmed using the Snowball stemmer <ref type="bibr" coords="2,277.54,691.96,9.96,8.74" target="#b4">[5]</ref>.</p><p>Queries are tokenized and preprocessed similarly; stop words and punctuation are removed and the rest of the terms are stemmed. The queries consist of a topic and a cluster description when available, in addition to the expansion terms from the top visual results. Named-entities are given more weight and multiple-token named-entities are chunked into one term by adding quotes around them.</p><p>For text retrieval, we use the Terrier Information Retrieval platform, a Java-based Information Retrieval platform available from the University of Glasgow <ref type="bibr" coords="3,354.09,135.93,9.96,8.74" target="#b2">[3]</ref>. Terrier includes boolean, vectorspace and probabilistic model capabilities. We use the vector-space model, which slightly surpasses the probabilistic models in our experiments. In the vector-space model, documents and queries are represented as vectors of terms weighed by Term Frequencies multiplied by the Inverse Document Frequency (TF-IDF). Terrier also has the option of block-indexing for phrase querying which we employ. Query terms are considered unioned by Terrier in order to promote recall.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Pseudo-Relevance Feedback with Semantic Selectional Restrictions</head><p>In this phase, the query is expanded with terms potentially related to the query. Common ways for text query expansion include adding synonyms and other related terms to the query. However, according to our experiments, this approach leads to the introduction of many noisy terms. Instead, we opted for the extraction of related terms from the five highest-ranked results retrieved by the content-based system described in Section 2. For the data set in our experiments, all the terms associated with the image are extracted except for stop words. In order to expand the query without introducing noise, the candidate text is compared to the query topic. If the image is found to be potentially related to the topic, the text query is expanded with the relevant terms.</p><p>To compute the relatedness of the image annotaion to the topic, we use the minimum threshold of one common non-grammatical word, due to data sparseness. The purpose of the query expansion module is not only to augment the query by adding new candidate related terms to it, but also to enhance it by adding weights to its key terms and filtering out potentially noisy terms from expansion. We also avoid expanding the query with named entities that do not have a semantic relationship with the query. This is crucial in photographic collections, since by their nature, photographs and image queries are often bound by geographical constraints. In order to ensure that potential expansion images do not introduce conflicting geographical terms in the query, we first build a filter from the location specified in the query. We make use of WordNet <ref type="bibr" coords="3,234.22,471.64,9.96,8.74" target="#b0">[1]</ref>, a lexical database, by traversing its PartMeronym hierarchy. A PartMeronym is a relationship between two nouns where the child noun constitutes a part of the parent noun. For geographical locations, this translates by the divisions of the parent noun. For example for the USA, a traversal of the hierarchy produces the names of the states, then major cities and towns followed by specific locations. While similar filters are possible for common nouns and using other relations such as Hyponymy (sub-classes of a term), we limit the expansion to named-entities, so as to avoid the problem of disambiguation of the specific sense of the term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Results</head><p>Table <ref type="table" coords="3,117.80,598.14,4.98,8.74" target="#tab_0">1</ref> shows the results our runs obtained at ImageCLEF 2009. The first two runs are purely visual and textual respectively. The PRF run combines visual and text retrieval using Pseudorelevance feedback and separate queries for each cluster. The Combined run uses the same method as the PRF, while combining all clusters into one query. Tables <ref type="table" coords="3,372.37,634.01,4.98,8.74" target="#tab_1">2</ref> and<ref type="table" coords="3,400.36,634.01,4.98,8.74" target="#tab_2">3</ref> show the break down of these runs by query set. The text run on the queries without given clusters shows a significant degradation which might be attributed to a glitch in our system.</p><p>Our results show a significant improvement of the pseudo-relevance feedback method over the use of a single modality. We also note a significant difference between the precision and cluster recall at ten (P10 &amp; CR10) and at 20 (P20 &amp; CR20) retrieved results. Contrary to ImageCLEFPhoto 2008 the F-measure was computed this year using a cut-off of the first ten results, which was a disadvantage to our method. The MAP, GMAP and the Relevant Retrieved figures are promising and show consistency over the different topics.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>We experimented at ImageCLEF 2009 with applying semantic selectional restrictions to enhance intermedia pseudo-relevance feedback and different methods of query formulation for clustered queries. We will further analyze the results in order to understand the significance of the chosen measures, given that the precision varies significantly at different levels of recall.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,218.16,359.27,166.68,8.74;2,162.92,144.84,258.24,165.33"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Block-based Visual Features</figDesc><graphic coords="2,162.92,144.84,258.24,165.33" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,104.38,118.94,391.17,64.98"><head>Table 1 :</head><label>1</label><figDesc>Results at ImageCLEFPhoto 2009</figDesc><table coords="4,104.38,130.60,391.17,53.32"><row><cell>Description</cell><cell>P10</cell><cell>P20</cell><cell cols="5">CR10 CR20 MAP GMAP Rel Ret F-measure</cell></row><row><cell>Visual</cell><cell cols="3">0.096 0.099 0.298</cell><cell>0.434</cell><cell>0.006</cell><cell>0.0009</cell><cell>657</cell><cell>0.1452</cell></row><row><cell>Text</cell><cell cols="5">0.434 0.435 0.4187 0.4437 0.226</cell><cell>0.0069</cell><cell>9603</cell><cell>0.4262</cell></row><row><cell>With PRF</cell><cell>0.55</cell><cell cols="5">0.643 0.7027 0.8212 0.3939 0.3164</cell><cell>16600</cell><cell>0.6171</cell></row><row><cell>Combined</cell><cell cols="6">0.586 0.672 0.6605 0.7569 0.4106 0.325</cell><cell>16677</cell><cell>0.621</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,104.38,207.89,391.17,64.98"><head>Table 2 :</head><label>2</label><figDesc>Queries with Given Clusters</figDesc><table coords="4,104.38,219.55,391.17,53.32"><row><cell>Description</cell><cell>P10</cell><cell>P20</cell><cell cols="2">CR10 CR20 MAP GMAP Rel Ret F-measure</cell></row><row><cell>Visual</cell><cell cols="3">0.072 0.082 0.2603 0.3934 0.0026 0.0008</cell><cell>241</cell><cell>0.1128</cell></row><row><cell>Text</cell><cell cols="3">0.732 0.748 0.7416 0.7726 0.4274 0.3178</cell><cell>8438</cell><cell>0.7368</cell></row><row><cell>With PRF</cell><cell cols="3">0.548 0.688 0.7482 0.8772 0.4155 0.3602</cell><cell>8638</cell><cell>0.6327</cell></row><row><cell>Combined</cell><cell cols="3">0.604 0.724 0.6741 0.7702 0.4459 0.3846</cell><cell>8785</cell><cell>0.6371</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="4,104.38,296.85,391.17,64.98"><head>Table 3 :</head><label>3</label><figDesc>Queries without Given Clusters</figDesc><table coords="4,104.38,308.51,391.17,53.32"><row><cell>Description</cell><cell>P10</cell><cell>P20</cell><cell cols="3">CR10 CR20 MAP GMAP Rel Ret F-measure</cell></row><row><cell>Visual</cell><cell>0.12</cell><cell cols="2">0.116 0.3357 0.4757 0.0095 0.001</cell><cell>416</cell><cell>0.1768</cell></row><row><cell>Text</cell><cell cols="3">0.136 0.122 0.0957 0.1148 0.0247 0.0001</cell><cell>1165</cell><cell>0.1124</cell></row><row><cell>With PRF</cell><cell cols="3">0.552 0.598 0.6572 0.7652 0.3939 0.3164</cell><cell>7962</cell><cell>0.6171</cell></row><row><cell>Combined</cell><cell cols="2">0.568 0.62</cell><cell>0.6469 0.7435 0.3753 0.2747</cell><cell>7892</cell><cell>0.6049</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,105.50,499.31,407.50,8.74;4,105.50,511.26,143.24,8.74" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="4,232.12,499.31,175.73,8.74">WordNet An Electronic Lexical Database</title>
		<editor>Christiane Fellbaum</editor>
		<imprint>
			<date type="published" when="1998-05">May 1998</date>
			<publisher>The MIT Press</publisher>
			<pubPlace>Cambridge, MA ; London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,531.19,407.50,8.74;4,105.50,543.14,321.92,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,351.66,531.19,161.34,8.74;4,105.50,543.14,34.49,8.74">Image indexing using moments and wavelets</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">K</forename><surname>Mandal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Aboulnasr</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Panchanathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,148.71,543.14,194.82,8.74">IEEE Transactions on Consumer Electronics</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="557" to="565" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,563.07,407.50,8.74;4,105.50,575.03,407.51,8.74;4,105.50,586.98,302.05,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,441.80,563.07,71.19,8.74;4,105.50,575.03,251.21,8.74">Terrier: A High Performance and Scalable Information Retrieval Platform</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Amati</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,379.13,575.03,133.87,8.74;4,105.50,586.98,213.28,8.74">Proceedings of ACM SIGIR&apos;06 Workshop on Open Source Information Retrieval</title>
		<meeting>ACM SIGIR&apos;06 Workshop on Open Source Information Retrieval<address><addrLine>OSIR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006">2006. 2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,606.91,407.51,8.74;4,105.50,618.86,355.02,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,308.91,606.91,204.10,8.74;4,105.50,618.86,124.47,8.74">Diversity in Photo Retrieval: Overview of the ImageCLEFPhoto Task 2009</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Paramita</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,251.38,618.86,112.46,8.74">CLEF working notes 2009</title>
		<meeting><address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,105.50,638.79,407.51,8.74;4,105.50,650.74,151.47,8.74" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="4,186.63,638.79,203.85,8.74">Snowball: A language for stemming algorithms</title>
		<author>
			<persName coords=""><forename type="first">Martin</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001-10-16">October 2001. Accessed 16.04.2009, 18.00h</date>
		</imprint>
	</monogr>
	<note>Published online</note>
</biblStruct>

<biblStruct coords="4,105.50,670.67,407.50,8.74;4,105.50,682.62,267.85,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,287.38,670.67,109.70,8.74">Similarity of color images</title>
		<author>
			<persName coords=""><forename type="first">Markus</forename><forename type="middle">A</forename><surname>Stricker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Markus</forename><surname>Orengo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,419.15,670.67,93.85,8.74;4,105.50,682.62,168.87,8.74">Storage and Retrieval for Image and Video Databases (SPIE)</title>
		<imprint>
			<date type="published" when="1995">1995</date>
			<biblScope unit="page" from="381" to="392" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
