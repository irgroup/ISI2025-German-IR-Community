<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,96.43,148.86,410.15,15.15">Overview of the CLEF 2009 Robot Vision Track</title>
				<funder ref="#_Ts4aeAD">
					<orgName type="full">Hasler foundation</orgName>
				</funder>
				<funder ref="#_HDcFRnk">
					<orgName type="full">EU</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,164.11,181.39,83.08,10.48"><forename type="first">Barbara</forename><surname>Caputo</surname></persName>
							<email>bcaputo@idiap.ch</email>
							<affiliation key="aff0">
								<orgName type="institution">Idiap Research Institute</orgName>
								<address>
									<settlement>Martigny</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,259.07,181.39,89.33,10.48"><forename type="first">Andrzej</forename><surname>Pronobis</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Centre for Autonomous Systems</orgName>
								<orgName type="institution">Royal Institute of Technology</orgName>
								<address>
									<settlement>Stockholm</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,360.28,181.39,73.87,10.48"><forename type="first">Patric</forename><surname>Jensfelt</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Centre for Autonomous Systems</orgName>
								<orgName type="institution">Royal Institute of Technology</orgName>
								<address>
									<settlement>Stockholm</settlement>
									<country key="SE">Sweden</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,96.43,148.86,410.15,15.15">Overview of the CLEF 2009 Robot Vision Track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">9C0AABB3A695C2BDA892FF0DD8016DAB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software Measurement, Performance, Experimentation Place recognition, robot vision, robot localization</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The robot vision task has been proposed to the ImageCLEF participants for the first time in 2009. The task attracted a considerable attention, with 19 inscribed research groups, 7 groups eventually participating and a total of 27 submitted runs. The task addressed the problem of visual place recognition applied to robot topological localization. Specifically, participants were asked to classify rooms on the basis of image sequences, captured by a perspective camera mounted on a mobile robot. The sequences were acquired in an office environment, under varying illumination conditions and across a time span of almost two years. The training and validation set consisted of a subset of the IDOL2 database 1 . The test set consisted of sequences similar to those in the training and validation set, but acquired 20 months later and imaging also additional rooms. Participants were asked to build a system able to answer the question "where are you?" (I am in the kitchen, in the corridor, etc) when presented with a test sequence imaging rooms seen during training, or additional rooms that were not imaged in the training sequence. The system had to assign each test image to one of the rooms present in the training sequence, or indicate that the image came from a new room. We asked all participants to solve the problem separately for each test image (obligatory task). Additionally, results could also be reported for algorithms exploiting the temporal continuity of the image sequences (optional task).</p><p>Of the 27 runs, 21 were submitted to the obligatory task, and 6 to the optional task. The best result in the obligatory task was obtained by the Multimedia Information Retrieval Group of the University of Glasgow, UK with an approach based on local feature matching. The best result in the optional task was obtained by the Intelligent Systems and Data Mining Group (SIMD) of the University of Castilla-La Mancha, Albacete, Spain, with an approach based on local features and a particle filter.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>ImageCLEF<ref type="foot" coords="2,143.00,132.27,3.97,6.12" target="#foot_0">2</ref>  <ref type="bibr" coords="2,149.87,133.84,10.52,8.74" target="#b0">[1,</ref><ref type="bibr" coords="2,162.80,133.84,7.75,8.74" target="#b1">2,</ref><ref type="bibr" coords="2,172.96,133.84,7.75,8.74" target="#b4">5]</ref> has started in 2003 as part of the Cross Language Evaluation Forum (CLEF<ref type="foot" coords="2,505.76,132.27,3.97,6.12" target="#foot_1">3</ref> , <ref type="bibr" coords="2,90.00,145.80,10.30,8.74" target="#b5">[6]</ref>). Its main goal has been to promote research on multi-modal data annotation and information retrieval, in various application fields. As such it has always contained visual, textual and other modalities, mixed tasks and several sub tracks.</p><p>This year, for the first time, ImageCLEF has hosted a Robot Vision task. This paper reports on it, while other papers describe the other five tasks of ImageCLEF 2009. More information on the tasks and on how to participate to CLEF can also be found on the ImageCLEF web pages.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Participation</head><p>In 2009, a new record of 85 research groups registered for the seven sub tasks of ImageCLEF. Of these 85, 19 registered to the Robot Vision task. 7 of the registered groups submitted at least one run:</p><p>â€¢ Multimedia Information Retrieval Group, University of Glasgow, United Kingdom A total of 27 runs were submitted, with 21 runs submitted to the obligatory task and 6 runs submitted to the optional task. In order to encourage participation, there was no limit to the number of runs that each group could submit.</p><p>3 Data Sets, Tasks, Ground Truthing</p><p>This section describes the details concerning the setup of the robot vision task. Section 3.1 describes the dataset used. Section 3.2 gives details on the tasks proposed to the participants. Finally, section 3.3 describes briefly the algorithm used for obtaining a ground truth and the obtained results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Dataset</head><p>Training and validation set consisted of a subset of the publicly available IDOL2 database <ref type="bibr" coords="2,502.48,640.34,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="2,90.00,652.29,7.01,8.74" target="#b3">4]</ref>. An additional, previously unreleased image sequence was used for testing. The part of the IDOL2 database used for training and validation comprises 12 image sequences acquired using a MobileRobots PowerBot robot platform. The image sequences are accompanied by laser range data and odometry data; however use of that data was not permitted in the competition. The image sequences in the IDOL2 database were captured with a Canon VC-C4 perspective camera using the resolution of 320x240 pixels. The acquisition was performed in a five room subsection of a larger office environment, selected in such way that each of the five rooms represented a different functional area: a one-person office, a two-persons office, a kitchen, a corridor, and a printer area. The appearance of the rooms was captured under three different illumination conditions: in cloudy weather, in sunny weather, and at night. The robots were manually driven through each of the five rooms while continuously acquiring images and laser range scans at a rate of 5fps. Each data sample was then labelled as belonging to one of the rooms according to the position of the robot during acquisition (rather than contents of the images). Examples of images showing the interiors of the rooms, variations observed over time and caused by activity in the environment as well as introduced by changing illumination are presented in Figure <ref type="figure" coords="3,457.68,207.66,3.87,8.74" target="#fig_1">1</ref>.</p><p>The IDOL2 database was designed to test the robustness of place recognition algorithms to variations that occur over a long period of time. Therefore, the acquisition process was conducted in two phases. Two sequences were acquired for each type of illumination conditions over the time span of more than two weeks, and another two sequences for each setting were recorded 6 months later (12 sequences in total). Thus, the sequences captured variability introduced not only by illumination but also natural activities in the environment (presence/absence of people, furniture/objects relocated etc.).</p><p>The test sequences were acquired in the same environment, using the same camera setup. The acquisition was performed 20 months after the acquisition of the IDOL2 database. The sequences contain additional rooms that were not imaged in the IDOL2 database.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The Task</head><p>The robot vision task addressed the problem of visual place recognition applied to topological localization of a mobile robot. Specifically, participants were asked to determine the topological location of a robot based on images acquired with a perspective camera mounted on a robot platform.</p><p>Participants were given training data consisting of an image sequence. The training sequence was recorded using a mobile robot that was manually driven through several rooms of a typical indoor office environment. The acquisition was performed under fixed illumination conditions and at a given time. Each image in the training sequence was labeled and assigned to the room in which it was acquired.</p><p>The challenge was to build a system able to answer the question 'where are you?' (I'm in the kitchen, in the corridor, etc.) when presented with a test sequence containing images acquired in the previously observed part of the environment or in additional rooms that were not imaged in the training sequence. The test images were acquired 6-20 months later after the training sequence, possibly under different illumination settings. The system had to assign each test image to one of the rooms that were present in the training sequence or indicate that the image came from a room that was not included during training. Moreover, the system could refrain from making a decision (e.g. in the case of lack of confidence).</p><p>The algorithm had to be able to provide information about the location of the robot separately for each test image (e.g. when only some of the images from the test sequences are available or the sequences are scrambled). This corresponds to the problem of global topological localization. We called this the obligatory task. However, results can also be reported for the case when the algorithm is allowed to exploit continuity of the sequences and rely on the test images acquired before the classified image. We called this the optional task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Ground Truth</head><p>The image sequences used in the competition were annotated with ground truth. The annotations of the training and validation sequences were available to the participants, while the ground truth for the test sequence was released after the results were announced. Each image in the sequences was labelled according to the position of the robot during acquisition as belonging to one of the rooms used for training or as an unknown room. The ground truth was then used to calculate a    score indicating the performance of an algorithm on the test sequence. The following rules were used when calculating the overall score for the whole test sequence:</p><p>â€¢ 1 point was given for each correctly classified image.</p><p>â€¢ Correct detection of an unknown room was regarded as correct classification.</p><p>â€¢ 0.5 points was subtracted for each misclassified image.</p><p>â€¢ No points were given or subtracted if an image was not classified (the algorithm refrained from the decision).</p><p>A script was available to the participants that automatically calculated the score for a specified test sequence given the classification results produced by an algorithm.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>This section describes the results of the robot vision task at ImageCLEF 2009. Table <ref type="table" coords="5,466.61,626.09,4.43,8.74" target="#tab_1">1</ref>(a) shows the results for the obligatory task, while Table <ref type="table" coords="5,296.14,638.05,4.57,8.74" target="#tab_1">1</ref>(b) shows the result for the optional task. We see that the majority of runs were submitted to the obligatory task: of the 27 total submissions, 21 were submitted to the obligatory run and only 6 to the optional task. A possible explanation is that the optional task requires a higher expertise on robotics that the obligatory task, which therefore represents a very good entry point.</p><p>The submissions used a wide range of techniques, spanning from local descriptors combined with statistical methods to approaches transplanted from the language modeling community. It interesting to note though that the two groups that ranked first in the two sub tasks both used a local features based approach. This confirms a consolidated trend in the robot vision community that treats local descriptors as the off the shelf feature of choice for visual recognition.</p><p>The first robot vision task at ImageCLEF 2009 attracted a considerable attention and proved an interesting complement to the existing tasks. The approach presented by the participating groups were diverse and original, offering a fresh take on the topological localization problem. We plan to continue the task in the next years, adding laser information and odometry to the visual information, and proposing new challenges to the perspective participants.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,190.42,173.64,22.94,6.89;4,295.80,173.64,19.83,6.89;4,400.67,173.64,17.88,6.89;4,142.62,210.47,6.89,40.32;4,142.62,191.86,6.89,16.21;4,143.34,290.58,6.89,27.32;4,235.34,345.73,132.65,6.89;4,185.23,358.28,27.32,6.89;4,275.16,358.28,55.10,6.89;4,377.00,358.28,58.93,6.89;4,247.78,530.27,107.68,6.89;4,169.88,542.92,55.10,6.89;4,288.73,542.92,24.91,6.89;4,385.82,542.92,38.51,6.89;4,249.55,633.17,101.25,6.89"><head></head><label></label><figDesc>Remaining rooms (at night)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="4,90.00,654.85,423.00,8.74;4,90.00,666.81,423.00,8.74;4,90.00,678.76,97.13,8.74;4,146.44,550.54,102.09,79.29"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Examples of pictures taken from the IDOL2 database showing the interiors of the rooms, variations observed over time and caused by activity in the environment as well as introduced by changing illumination.</figDesc><graphic coords="4,146.44,550.54,102.09,79.29" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,116.53,108.86,369.94,311.47"><head>Table 1 :</head><label>1</label><figDesc>Results for each run submitted to the obligatory (a) and optional (b) tasks.</figDesc><table coords="5,202.44,108.86,198.12,284.08"><row><cell></cell><cell></cell><cell></cell><cell cols="2">(b) Optional task.</cell></row><row><cell>#</cell><cell>Group</cell><cell>Score</cell><cell cols="2"># Group Score</cell></row><row><cell cols="3">1 Glasgow 890.5</cell><cell cols="2">1 SIMD 916.5</cell></row><row><cell>2</cell><cell>Idiap</cell><cell>793.0</cell><cell cols="2">2 CVIU 884.5</cell></row><row><cell>3</cell><cell>UAIC</cell><cell>787.0</cell><cell>3</cell><cell>Idiap 853.0</cell></row><row><cell>4</cell><cell>UAIC</cell><cell>787.0</cell><cell cols="2">4 SIMD 711.0</cell></row><row><cell>5</cell><cell>CVIU</cell><cell>784.0</cell><cell cols="2">5 SIMD 711.0</cell></row><row><cell cols="3">6 Glasgow 650.5</cell><cell cols="2">6 SIMD 609.0</cell></row><row><cell>7</cell><cell>UAIC</cell><cell>599.5</cell><cell></cell><cell></cell></row><row><cell>8</cell><cell>UAIC</cell><cell>599.5</cell><cell></cell><cell></cell></row><row><cell>9</cell><cell>LSIS</cell><cell>544.0</cell><cell></cell><cell></cell></row><row><cell>10</cell><cell>SIMD</cell><cell>511.0</cell><cell></cell><cell></cell></row><row><cell>11</cell><cell>LSIS</cell><cell>509.5</cell><cell></cell><cell></cell></row><row><cell>12</cell><cell>MRIM</cell><cell>456.5</cell><cell></cell><cell></cell></row><row><cell>13</cell><cell>MRIM</cell><cell>415.0</cell><cell></cell><cell></cell></row><row><cell>14</cell><cell>MRIM</cell><cell>328.0</cell><cell></cell><cell></cell></row><row><cell>15</cell><cell>UAIC</cell><cell>296.5</cell><cell></cell><cell></cell></row><row><cell>16</cell><cell>MRIM</cell><cell>25.0</cell><cell></cell><cell></cell></row><row><cell>17</cell><cell>LSIS</cell><cell>-32.0</cell><cell></cell><cell></cell></row><row><cell>18</cell><cell>LSIS</cell><cell>-32.0</cell><cell></cell><cell></cell></row><row><cell>19</cell><cell>LSIS</cell><cell>-32.0</cell><cell></cell><cell></cell></row><row><cell>20</cell><cell>LSIS</cell><cell>-32.0</cell><cell></cell><cell></cell></row><row><cell cols="3">21 Glasgow -188.0</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_0" coords="2,105.24,731.57,105.85,6.64"><p>http://www.imageclef.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_1" coords="2,105.24,741.08,122.79,6.64"><p>http://www.clef-campaign.org/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head n="6">Acknowledgements</head><p>We would like to thank the CLEF campaign for supporting the ImageCLEF initiative. <rs type="person">B. Caputo</rs> was supported by the <rs type="projectName">EMMA</rs> project, funded by the <rs type="funder">Hasler foundation</rs>. <rs type="person">A. Pronobis</rs> and <rs type="person">P. Jensfelt</rs> were supported by the <rs type="funder">EU</rs> <rs type="programName">FP7</rs> project <rs type="grantNumber">CogX ICT-215181</rs>. The support is gratefully acknowledged.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_Ts4aeAD">
					<orgName type="project" subtype="full">EMMA</orgName>
				</org>
				<org type="funding" xml:id="_HDcFRnk">
					<idno type="grant-number">CogX ICT-215181</idno>
					<orgName type="program" subtype="full">FP7</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,105.50,327.06,407.50,8.74;6,105.50,339.02,407.50,8.74;6,105.50,350.97,407.50,8.74;6,105.50,362.93,140.11,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,263.76,339.02,231.04,8.74">The CLEF 2005 cross-language image retrieval track</title>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>MÃ¼ller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">M</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeffery</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,105.50,350.97,181.71,8.74">Cross Language Evaluation Forum (CLEF</title>
		<title level="s" coord="6,319.93,350.97,188.79,8.74">Springer Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2005-09">2005. September 2006</date>
			<biblScope unit="page" from="535" to="557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,382.85,407.50,8.74;6,105.50,394.81,407.50,8.74;6,105.50,406.76,407.50,8.74;6,105.50,418.72,407.51,8.74;6,105.50,430.67,365.82,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,349.35,382.85,163.65,8.74;6,105.50,394.81,139.74,8.74">The CLEF cross-language image retrieval track (ImageCLEF) 2004</title>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>MÃ¼ller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,354.64,406.76,158.35,8.74;6,105.50,418.72,311.72,8.74">Multilingual Information Access for Text, Speech and Images: Result of the fifth CLEF evaluation campaign</title>
		<title level="s" coord="6,495.04,418.72,17.96,8.74;6,105.50,430.67,169.50,8.74">Lecture Notes in Computer Science (LNCS</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Gareth</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Bernardo</forename><surname>Kluck</surname></persName>
		</editor>
		<editor>
			<persName><surname>Magnini</surname></persName>
		</editor>
		<meeting><address><addrLine>Bath, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3491</biblScope>
			<biblScope unit="page" from="597" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,450.60,407.50,8.74;6,105.50,462.55,407.51,8.74;6,105.50,475.22,143.99,8.30" xml:id="b2">
	<monogr>
		<title level="m" type="main" coord="6,339.08,450.60,119.31,8.74">The KTH-IDOL2 database</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pronobis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Jensfelt</surname></persName>
		</author>
		<idno>CVAP304</idno>
		<ptr target="http://www.cas.kth.se/IDOL/" />
		<imprint>
			<date type="published" when="2006-10">October 2006</date>
		</imprint>
		<respStmt>
			<orgName>Kungliga Tekniska Hoegskolan, CVAP/CAS</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical Report</note>
</biblStruct>

<biblStruct coords="6,105.50,494.43,407.50,8.74;6,105.50,506.39,407.50,8.74;6,105.50,518.34,318.40,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,319.87,494.43,193.13,8.74;6,105.50,506.39,96.29,8.74">Incremental learning for place recognition in dynamic environments</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Pronobis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Caputo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Jensfelt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,223.88,506.39,289.11,8.74;6,105.50,518.34,151.31,8.74">Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS07)</title>
		<meeting>the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS07)<address><addrLine>San Diego, CA, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007-10">October 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,538.27,407.50,8.74;6,105.50,550.22,407.50,8.74;6,105.50,562.18,407.50,8.74;6,105.50,574.13,346.39,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,304.57,550.22,208.43,8.74;6,105.50,562.18,130.78,8.74">Overview of the ImageCLEFmed 2007 medical retrieval and annotation tasks</title>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>MÃ¼ller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eugene</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jayashree</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">M</forename><surname>Deserno</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,259.07,562.18,103.02,8.74">CLEF 2007 Proceedings</title>
		<title level="s" coord="6,440.60,562.18,72.40,8.74;6,105.50,574.13,108.75,8.74">Lecture Notes in Computer Science (LNCS</title>
		<meeting><address><addrLine>Budapest, Hungary</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">5152</biblScope>
			<biblScope unit="page" from="473" to="491" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.50,594.06,407.50,8.74;6,105.50,606.01,407.51,8.74;6,105.50,617.97,22.69,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,173.94,594.06,152.86,8.74">Report on CLEF-2001 experiments</title>
		<author>
			<persName coords=""><forename type="first">Jacques</forename><surname>Savoy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,348.16,594.06,164.84,8.74;6,105.50,606.01,154.42,8.74">Report on the CLEF Conference 2001 (Cross Language Evaluation Forum)</title>
		<meeting><address><addrLine>Darmstadt, Germany</addrLine></address></meeting>
		<imprint>
			<publisher>Springer LNCS</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page">2406</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
