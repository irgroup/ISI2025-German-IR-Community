<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,183.03,148.86,236.94,15.15;1,99.05,170.78,404.90,15.15">MMIS at ImageCLEF 2009: Non-parametric Density Estimation Algorithms</title>
				<funder ref="#_VjV8c5Z">
					<orgName type="full">EU Pharos</orgName>
				</funder>
				<funder>
					<orgName type="full">Santander Corporation</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,191.81,204.67,68.93,8.74"><forename type="first">Ainhoa</forename><surname>Llorente</surname></persName>
							<email>a.llorente@open.ac.uk</email>
						</author>
						<author>
							<persName coords="1,268.36,204.67,63.23,8.74"><forename type="first">Suzanne</forename><surname>Little</surname></persName>
							<email>s.little@open.ac.uk</email>
						</author>
						<author>
							<persName coords="1,354.29,204.67,56.89,8.74"><forename type="first">Stefan</forename><surname>Rüger</surname></persName>
							<email>s.rueger@open.ac.uk</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Knowledge Media Institute</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">The Open University</orgName>
								<address>
									<addrLine>Milton Keynes</addrLine>
									<postCode>MK7 6AA</postCode>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,183.03,148.86,236.94,15.15;1,99.05,170.78,404.90,15.15">MMIS at ImageCLEF 2009: Non-parametric Density Estimation Algorithms</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">6B46E56A9FD0126D7FCEFD9880E4B7B7</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>I.4 [Image Processing and Computer Vision]: I.4.8 Scene Analysis</term>
					<term>I.4.9 Applications Algorithms, Experimentation, Performance, Measurement Content Based Image Retrieval, Object Recognition, Thesauruses</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents the work of the MMIS group done at ImageCLEF 2009. We submitted five different runs to the Photo Annotation task. These runs were based on two non-parametric density estimation models. The first one evaluates a set of visual features and proposes a better, weighted set of features. The second approach uses keyword correlation to compute semantic similarity measures using several knowledge sources. The knowledge sources used are, the training set of the collection, Google Web search engine, WordNet and Wikipedia. Evaluation of results is done under two different metrics, one based on ROC curves and the other in a hierarchical measure proposed by the organisers. Our results are quite encouraging; under the first metric our best run was located between the median and the top quartile and under the second metric our best run was between the first quartile and the median.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>In this paper, we describe the experiments performed by the MMIS group at ImageCLEF 2009. We participated in the Large Scale Visual Concept Detection and Annotation Task. The main goal of this task is, as described in <ref type="bibr" coords="1,223.43,673.91,14.61,8.74" target="#b12">[13]</ref>, given a training set of 5,000 images manually annotated with words coming from a vocabulary of 53 visual concepts, to automatically provide annotations for a test set of 13,000 images. The visual concepts are organized in a small ontology so participants may take advantage of the hierarchical order of the concepts and the relations among them for better accomplishing the annotation task. Another important goal of this year competition is to reflect about the influence of large amount of data and concepts in the annotation task and about whether or not an ontology can help.</p><p>We submitted five runs in total. Each one of them is based on a different non-parametric density estimation model but placing emphasis on different aspect of the research field. For instance, the run MMIS 33 2 1245434554581.txt is evaluating a sequence of possible image feature selections in order to propose a better, weighted set of features while the other four runs MMIS 33 2 1245586552541.txt, MMIS 33 2 1245601239738.txt, MMIS 33 2 1245611281967.txt, and, MMIS 33 2 1245674693001.txt attempt to improve a baseline probabilistic model taking advantage of the correlation between keywords computing semantic similarities measures using different knowledge bases.</p><p>Evaluation of results have been done under two different metrics, one is based on ROC curves <ref type="bibr" coords="2,502.48,207.66,10.52,8.74" target="#b3">[4]</ref> and proposes as measures Equal Error Rate (EER) and the Area under Curve (AUC) while the second metric is the hierarchical measure proposed by <ref type="bibr" coords="2,333.92,231.57,15.50,8.74" target="#b13">[14]</ref> that considers the relations between concepts and the agreement of annotators on concepts. All in all, our results are quite encouraging, under the first metric our best run was located between the median and the top quartile and under the second metric our best run was between the first quartile and the median.</p><p>The rest of this paper is organised as follows. Section 2 provides an introduction on nonparametric density estimation. Section 3 describes the first approach followed while Section 4 illustrates the second one. Then, our evaluation results are discussed in Section 5. Finally, Section 6 shows our conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Non-parametric Density Estimation</head><p>Both approaches followed in this research are variations of the probabilistic framework developed by Yavlinsky et al. <ref type="bibr" coords="2,175.54,381.98,15.50,8.74" target="#b15">[16]</ref> who used global features together with a non-parametric density estimation. This approach is based on the Bayes rule being the ultimate goal to model f (x|ω) for each annotation keyword ω, being x a feature vector representing a test image. The non-parametric approach is employed because the distributions of image features have irregular shapes that do not resemble a priori any simple parametric form.</p><p>The function f (x|ω) is estimated following a kernel k based approach as represented in:</p><formula xml:id="formula_0" coords="2,241.66,461.44,271.34,30.32">f (x|ω) = 1 nC n i=1 k x -x (i) ω h ,<label>(1)</label></formula><p>where x</p><p>(1)</p><formula xml:id="formula_1" coords="2,125.53,498.85,33.96,12.46">ω , x<label>(2)</label></formula><p>ω ,..., x</p><p>ω , is a sample of feature vectors from the training set labelled with the keyword ω and x = (x 1 , ..., x d ) is a vector of real-valued image features.</p><p>The approach explained in Section 3 places a d-dimensional Laplacian kernel over point x (i) as expressed in:</p><formula xml:id="formula_3" coords="2,252.59,558.68,260.42,30.55">k L (t; h) = d l=1 1 h l e - t l h l ,<label>(2)</label></formula><p>while the approach described in Section 4 uses a Gaussian kernel as shown in:</p><formula xml:id="formula_4" coords="2,235.99,616.74,272.76,30.55">k G (t; h) = d l=1 1 √ 2πh l e -1 2 ( t l h l ) 2 , (<label>3</label></formula><formula xml:id="formula_5" coords="2,508.76,627.15,4.24,8.74">)</formula><p>where t = x-x (i) and h l is the bandwidth of the kernel which is set by scaling the sample standard deviation of feature component l by the same constant λ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Image Features</head><p>A key aspect of the non-parametric density estimation approach is the global visual features used. The algorithm described in Section 3 used four features: CIELAB and HSV colour descriptors combined with Tamura and Gabor texture descriptors while our second algorithm 4 combines the CIELAB color feature with the Tamura texture. CIE L*a*b* (CIELAB) <ref type="bibr" coords="3,212.79,135.93,10.52,8.74" target="#b6">[7]</ref> is the most complete colour space specified by the International Commission on Illumination (CIE). Its three coordinates represent the lightness of the colour (L*), its position between red/magenta and green (a*) and its position between yellow and blue (b*). The histogram was calculated over two bins for each coordinate.</p><p>HSV is a cylindrical colour space with H (hue) being the angular, S (saturation) the radial and V (brightness) the height component. The H, S and V axes are subdivided linearly (rather than by geometric volume) into two bins each. The HSV colour histogram is normalised so that this components add up to one.</p><p>The Tamura texture feature <ref type="bibr" coords="3,233.00,231.57,15.50,8.74" target="#b14">[15]</ref> is computed using three main texture features called "contrast", "coarseness", and "directionality". Contrast aims to capture the dynamic range of grey levels in an image. Coarseness has a direct relationship to scale and repetition rates and it was considered by Tamura et al. as the most fundamental texture feature and finally, directionality is a global property over a region. The histogram was calculated over two bins for each feature.</p><p>The process for extracting each of these features is as follows, each image is divided into nine equal rectangular tiles, the mean and second central moment feature per channel are calculated in each tile. The resulting feature vector is obtained after concatenating all the vectors extracted in each tile.</p><p>The final feature extracted is a texture descriptor produced by applying a Gabor filter to enable filtering in the frequency and spatial domain. Our implementation is based on <ref type="bibr" coords="3,429.01,351.12,14.61,8.74" target="#b9">[10]</ref>. To each image we applied a bank of four orientation and six scale sensitive filters that map each image point to a point in the frequency domain. This feature was calculated on the whole image rather than using the tiling approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Weighted Global Features</head><p>The original implementation of this algorithm used two features: CIELAB and Tamura. Subsequent work evaluated a sequence of possible feature selections <ref type="bibr" coords="3,360.01,453.71,10.52,8.74" target="#b7">[8]</ref> and proposed a better, weighted set of features. The feature sets to be evaluated were constructed based on information from existing literature about visual feature selection and attempted to avoid descreasing performance due to redundant features or multi-variate prediction.</p><p>The feature set proposed from this set of evaluations added two additional features, HSV colour and Gabor texture, to the original CIELAB and Tamura descriptors. These features were weighted at CIELAB -0.75, HSV -0.5, Tamura -0.5 and Gabor -0.5. This set improved the mean average precision when evaluated on the standard Corel5k dataset <ref type="bibr" coords="3,409.50,537.40,10.52,8.74" target="#b2">[3]</ref> and the IAPR TC12 dataset used for ImageCLEF 2006 <ref type="bibr" coords="3,242.49,549.35,9.96,8.74" target="#b5">[6]</ref>.</p><p>The run is labelled MMIS 33 2 1245434554581.txt and is based on the approach used in <ref type="bibr" coords="3,90.00,573.26,14.61,8.74" target="#b15">[16]</ref>. The four chosen features were extracted from the training set to train the non-parametric density estimation annotator which then provided the probability of each concept being present in the test image. Manhattan distance was used for all features.</p><p>This algorithm represented a straight-forward approach that exploited only the global low-level features and the supervised learning of a prediction model. We predicted that this set of features would provide a good coverage of the colour and texture space and sufficient details without placing an excessive calculation burden on the system. Initial tests using ten-fold cross-validation on the training set re-enforced this expectation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Exploiting Word Correlations to Compute Semantic Similarities</head><p>The early attempts in automated image annotation were focused on algorithms that explored the correlation between words and image features. More recently, there are some efforts which attempt to benefit from exploiting the correlation between words computing semantic similarity measures. Among the many uses of the concept "semantic similarity", we refer to the definition by Miller and Charles <ref type="bibr" coords="4,126.01,135.93,15.50,8.74" target="#b10">[11]</ref> who consider it as the degree of contextual interchangeability or the degree to which one word can be replaced by another in a certain context. Consequently, two words are similar if they refer to entities that are likely to co-occur together like "mountains" and "vegetation", "beach" and "water", "buildings" and "road", etc. In this research we will use indistinctly the term semantic similarity and semantic relatedness. This non-parametric density estimation model exploits the statistical correlation between words by computing semantic similarity measures using different knowledge bases. We propose four versions of this model that differ on the knowledge base used as source of information and the semantic similarity measure employed. The knowledge bases used are, the training set of the collection, Google Web search engine, WordNet, and Wikipedia. The semantic similarity measures used are explained in Section 4.2.</p><p>The process can be described as follows. We calculate the probability value of each concept being present in each image of the test set following the non-parametric density estimation described in Section 2. Then, a statistical keyword correlation is computed using the corresponding knowledge base. With the help of the semantic similarity measures and applying some rules the accuracy of the final annotations is improved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Parameter Estimation</head><p>We divided the dataset into three parts: a training set, a validation set and a test set. The validation test is used to find the parameters of the model. Thus, we performed a 10-fold cross validation on the training set. After that, the training and validation set are merged to form a new training set of 5,000 images that is used to predict the annotations in the test set of 13,000 images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Submitted Runs</head><p>In this subsection, we describe the four submitted runs based on this approach: MMIS 33 2 1245586552541.txt This run is based on the approach developed in <ref type="bibr" coords="4,457.18,475.56,10.52,8.74" target="#b8">[9]</ref> where the training set is computed to generate a co-occurrence matrix that represents the probabilities of the frequency of two vocabulary words appearing together in a given image. This algorithm was previously tested on the Corel5k collection and in the collection provided by the last edition of ImageCLEF, in 2008.</p><p>MMIS 33 2 1245611281967.txt The semantic similarity measure used in this run is called web-based semantic relatedness measure as it uses Google Web search engine as knowledge base. It was developed by Gracia and Mena <ref type="bibr" coords="4,304.01,567.22,10.52,8.74" target="#b4">[5]</ref> who defined the semantic relatedness between the concepts x and y, as: rel(x, y) = e -2 NWD(x,y) ,</p><p>where N W D stands for Normalized Web Distance which is a generalisation of the Normalized Google Distance (see Equation <ref type="formula" coords="4,257.02,622.91,4.43,8.74" target="#formula_7">5</ref>) extended to any web-based search engine as source of frequencies. The Normalized Google Distance (NGD) between two terms x and y, was expressed by Cilibrasi and Vitányi <ref type="bibr" coords="4,268.44,646.82,10.52,8.74" target="#b1">[2]</ref> as:</p><formula xml:id="formula_7" coords="4,203.68,671.23,309.32,22.31">NGD(x, y) = max{log f (x), log f (y)} -log f (x, y) log N -min{log f (x), log f (y)} ,<label>(5)</label></formula><p>where f (x) and f (y) are the counts for search terms x and y using Google and f (x, y) is, the number of web pages found on which both x and y occur. N is the total number of web pages searched by Google which, in 2007, was estimated to be more than 8bn pages.</p><p>MMIS 33 2 1245674693001.txt This run uses the adapted Lesk measure applied to WordNet proposed by Banerjee and Pedersen in <ref type="bibr" coords="5,284.46,123.98,9.96,8.74" target="#b0">[1]</ref>. They defined the extended gloss overlap measure which computes the relatedness between two synsets c 1 and c 2 by comparing the glosses of synsets related to them through explicit relations provided by WordNet:</p><formula xml:id="formula_8" coords="5,181.40,171.10,331.60,9.65">rel(c 1 , c 2 ) = score(R 1 (c 1 ), R 2 (c 2 )), ∀(R 1 , R 2 ) ∈ relP airs.<label>(6)</label></formula><p>Thus, the set relP airs is defined as follows:</p><formula xml:id="formula_9" coords="5,121.68,216.08,391.32,20.69">relP airs = {(R 1 , R 2 ) | R 1 , R 2 ∈ rels; if (R 1 , R 2 ) ∈ relP airs, then(R 1 , R 2 ) ∈ relP airs},<label>(7)</label></formula><p>being rels a non-empty set of relations that consists of one or more of the following relations:</p><formula xml:id="formula_10" coords="5,206.91,261.77,301.85,8.74">rels ⊂ {r | r is a relation def ined in W ordN et}. (<label>8</label></formula><formula xml:id="formula_11" coords="5,508.76,261.77,4.24,8.74">)</formula><p>MMIS 33 2 1245601239738.txt This run computes the semantic relatedness between two concepts applying the Wikipedia measure defined by Milne and Witten. In <ref type="bibr" coords="5,430.03,299.45,14.61,8.74" target="#b11">[12]</ref>, they proposed their Wikipedia Link-based Measure (WLM) which extracts semantic relatedness measure between two concepts using the hyperlink structure of Wikipedia. The semantic relatedness between concepts x and y is estimated by the angle between the vectors of the links found between the Wikipedia articles whose title matches each one of the concepts:</p><formula xml:id="formula_12" coords="5,273.03,367.14,239.97,22.31">rel(x, y) = x • y | x| • | y| ,<label>(9)</label></formula><p>where the vectors for article x and y are built using link counts weighted by the probability of each link occurring, as seen in:</p><formula xml:id="formula_13" coords="5,221.43,434.66,291.57,9.65">x = (w(x → l 1 ), w(x → l 2 ), ..., w(x → l n )) ,<label>(10)</label></formula><p>and, in: y = (w(y → l 1 ), w(y → l 2 ), ..., w(y</p><formula xml:id="formula_14" coords="5,372.27,468.39,140.73,9.65">→ l n )) .<label>(11)</label></formula><p>Thus, the weighted value w for the link a → b can be defined as:</p><formula xml:id="formula_15" coords="5,224.74,506.32,283.83,30.55">w(a → b) = |a → b| • log t x=l t |x → b| , (<label>12</label></formula><formula xml:id="formula_16" coords="5,508.57,516.73,4.43,8.74">)</formula><p>being t is the total number of articles within Wikipedia.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Evaluation Measures and Results</head><p>We used two metrics to determine the quality of the annotations. The first metric is based on ROC curves <ref type="bibr" coords="5,120.73,614.14,9.96,8.74" target="#b3">[4]</ref>. Initially, a receiver operating characteristic (ROC) curve was used in signal detection theory to plot the sensitivity versus (1 -specificity) for a binary classifier as its discrimination threshold is varied. Later on, ROC curves were applied to information retrieval in order to represent the fraction of true positives (TP) against the fraction of false positives (FP) in a binary classifier. The Equal Error Rate (EER) is the error rate at the threshold where FP=FN. The area under the ROC curve, AUC, is equal to the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one. Note that, the lower the EER, the better the annotations.</p><p>In Table <ref type="table" coords="5,143.22,709.78,3.87,8.74">1</ref>, we show the results for all our submitted runs under the EER and AUC metric. Our best run corresponds to MMIS 33 2 1245434554581.txt that follows the first approach of weighted global features. This run achieved a reasonable EER across all concepts of just over 31% which was consistent with the predicted performance from our earlier ten-fold cross validation. shows that the ten best concepts identified by this annotator are those which have previously performed well using only global visual features. With the exception of "Underexposed", the best performing concepts belong to fairly common visual categories, primarily landscape elements.</p><p>Regarding the four runs based on keyword correlation, we observe that the best performance is achieved using the training set as corpora. Not surprisingly, the second best is the run based on Google Normalized Distance that uses Google Web search engine as knowledge source. This is due to the fact that both approaches do not reply on a prior disambiguation process like WordNet and Wikipedia.</p><p>The worst result corresponds to the run based on Wikipedia. The reasons behind it might be found in the strong dependency of the semantic relatedness measure on doing a proper word disambiguation. The disambiguation in Wikipedia is automatically performed by selecting the sense of the word more probable according to the content store on Wikipedia database.</p><p>The 53 concepts of the proposed vocabulary belong to one of the following categories: Scene description, Seasons, Place, Landscape Elements, Time of the day, Picture representation, Illumination, Quality Blurring, Picture Objects, and Quality Aesthetics.</p><p>Most of the categories do not correspond to real visual features and the best way of predicting them is making use of the "exif" metadata. As our focus is on visual features we have not incorporated them in any of our algorithms. Consequently, we predicted and posteriorly checked, lower results for concepts classified into categories such as Seasons, Time of the day, Picture representation, Illumination, Quality Blurring and specially, the most subjective one, Quality Aesthetics.</p><p>The second metric is the proposed hierarchical measure <ref type="bibr" coords="6,342.22,684.05,15.50,8.74" target="#b13">[14]</ref> that considers the relations between concepts and the agreement of annotators on concepts. In Table <ref type="table" coords="6,369.36,696.01,3.87,8.74" target="#tab_2">3</ref>, the results of all our submitted runs are shown. The best run is the one based on Google Web search engine followed by the cooccurrence, and WordNet approaches. This makes sense as all these runs are employing semantic similarity measures on external ontologies, which is exactly the criteria that the hierarchical score attempts to evaluate. The run which applied weighted global features relied less on the hierarchical </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusions</head><p>While it is difficult to make conclusive statements about the submitted runs as the differences in their performance are minimal, the results do re-enforce previous expectations. The performance of our best run (according to EER) supports previous findings about the impact of feature selection and weighting on the non-parametric density algorithm as it outperforms the other four runs which used the original features.</p><p>With respect to the second metric (hierarchical measure), the best runs are those that use as knowledge base the training set and Google Web search engine because the rest of the approaches (WordNet and Wikipedia) have been penalised as a result of the prior disambiguation process that follow.</p><p>Interestingly the metric to distinguish the performance of annotators based on measurement of the hierarchical distribution isolates the feature weighting run. This alternative method of ranking performance gives valuable insight into the influence and impact of the analysis of hierarchical labels in image annotation. It is likely that annotators that achieve a higher ranking using the hierarchical measure have better distribution across the concepts. Further analysis is needed to determine if annotators with a better hierarchical measure are also more robust overall.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,480.54,745.64,32.46,8.74"><head>Table 2 Table 1 :</head><label>21</label><figDesc>EER and AUC results for all the runs of MMIS group</figDesc><table coords="6,183.43,140.17,232.82,82.89"><row><cell>Algorithm</cell><cell>EER</cell><cell>AUC</cell></row><row><cell>Random</cell><cell cols="2">0.500280 0.499307</cell></row><row><cell cols="3">MMIS 33 2 1245434554581.txt 0.312366 0.744231</cell></row><row><cell cols="3">MMIS 33 2 1245586552541.txt 0.352478 0.689410</cell></row><row><cell cols="3">MMIS 33 2 1245601239738.txt 0.356945 0.684821</cell></row><row><cell cols="3">MMIS 33 2 1245611281967.txt 0.352485 0.689407</cell></row><row><cell cols="3">MMIS 33 2 1245674693001.txt 0.352612 0.689342</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,200.53,256.71,201.94,153.54"><head>Table 2 :</head><label>2</label><figDesc>Top 10 best concepts best MMIS run</figDesc><table coords="6,210.56,277.95,178.55,132.30"><row><cell>Concept</cell><cell>EER</cell><cell>AUC</cell></row><row><cell>Sunset-Sunrise</cell><cell cols="2">0.181372 0.889386</cell></row><row><cell>Clouds</cell><cell cols="2">0.192238 0.875234</cell></row><row><cell>Underexposed</cell><cell cols="2">0.207616 0.871133</cell></row><row><cell>Sky</cell><cell cols="2">0.211369 0.865876</cell></row><row><cell>Night</cell><cell cols="2">0.212004 0.860332</cell></row><row><cell>Sea</cell><cell cols="2">0.213746 0.854027</cell></row><row><cell>Mountains</cell><cell cols="2">0.217231 0.846818</cell></row><row><cell cols="3">Landscape-Nature 0.225471 0.84186</cell></row><row><cell>Desert</cell><cell cols="2">0.232747 0.810619</cell></row><row><cell>Food</cell><cell cols="2">0.251319 0.828054</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="7,90.00,118.94,378.59,145.19"><head>Table 3 :</head><label>3</label><figDesc>Average Annotation Score for all the runs of MMIS group</figDesc><table coords="7,90.00,140.17,378.59,123.95"><row><cell>Algorithm</cell><cell cols="2">With Annotator Without Annotator</cell></row><row><cell>Random</cell><cell>0.3843171</cell><cell>0.35097164</cell></row><row><cell>MMIS 33 2 1245434554581.txt</cell><cell>0.5479666</cell><cell>0.49800622</cell></row><row><cell>MMIS 33 2 1245586552541.txt</cell><cell>0.6179764</cell><cell>0.57577974</cell></row><row><cell>MMIS 33 2 1245601239738.txt</cell><cell>0.4205571</cell><cell>0.35027474</cell></row><row><cell>MMIS 33 2 1245611281967.txt</cell><cell>0.6180272</cell><cell>0.57583610</cell></row><row><cell>MMIS 33 2 1245674693001.txt</cell><cell>0.6172693</cell><cell>0.57497290</cell></row><row><cell cols="2">information and therefore did not perform as well using the metric.</cell><cell></cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments.</head><p>This work was partially funded by the <rs type="funder">EU Pharos</rs> project (<rs type="grantNumber">IST-FP6-45035</rs>) and by <rs type="funder">Santander Corporation</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_VjV8c5Z">
					<idno type="grant-number">IST-FP6-45035</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="7,110.48,587.00,402.52,8.74;7,110.48,598.96,389.61,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="7,242.49,587.00,266.30,8.74">Extended gloss overlaps as a measure of semantic relatedness</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Pedersen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,122.93,598.96,347.13,8.74">Proceedings of the Eighteenth International Conference on Artificial Intelligence</title>
		<meeting>the Eighteenth International Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,617.70,402.52,8.74;7,110.48,629.65,240.75,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="7,265.17,617.70,135.93,8.74">The Google similarity distance</title>
		<author>
			<persName coords=""><forename type="first">Rudi</forename><surname>Cilibrasi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Vitanyi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,413.27,617.70,99.73,8.74;7,110.48,629.65,143.78,8.74">IEEE Transactions on Knowledge and Data Engineering</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="370" to="383" />
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,648.39,402.52,8.74;7,110.48,660.35,402.52,8.74;7,110.48,672.30,292.84,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="7,431.66,648.39,81.34,8.74;7,110.48,660.35,316.92,8.74">Object recognition as machine translation: Learning a lexicon for a fixed image vocabulary</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Duygulu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Kobus</forename><surname>Barnard</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">F G</forename><surname>De Freitas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">David</forename><forename type="middle">A</forename><surname>Forsyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,451.09,660.35,61.91,8.74;7,110.48,672.30,199.24,8.74">Proceedings of the European Conference on Computer Vision</title>
		<meeting>the European Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="97" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,691.04,402.52,8.74;7,110.48,703.00,22.69,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="7,173.93,691.04,142.77,8.74">An introduction to ROC analysis</title>
		<author>
			<persName coords=""><forename type="first">Tom</forename><surname>Fawcett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,324.85,691.04,117.84,8.74">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="861" to="874" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,721.73,402.52,8.74;7,110.48,733.69,402.52,8.74;7,110.48,745.64,90.83,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="7,263.98,721.73,190.12,8.74">Web-based measure of semantic relatedness</title>
		<author>
			<persName coords=""><forename type="first">Jorge</forename><surname>Gracia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Eduardo</forename><surname>Mena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,477.09,721.73,35.91,8.74;7,110.48,733.69,338.50,8.74">Proceedings of 9th International Conference on Web Information Systems Engineering</title>
		<meeting>9th International Conference on Web Information Systems Engineering</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="volume">5175</biblScope>
			<biblScope unit="page" from="136" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,112.02,402.52,8.74;8,110.48,123.98,402.52,8.74;8,110.48,135.93,267.00,8.74" xml:id="b5">
	<monogr>
		<title level="m" type="main" coord="8,202.85,112.02,305.31,8.74">Analysis and Evaluation of Visual Information Systems Performance</title>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Grubinger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<pubPlace>Melbourne, Australia</pubPlace>
		</imprint>
		<respStmt>
			<orgName>School of Computer Science and Mathematics, Faculty of Health, Engineering and Science, Victoria University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">PhD thesis</note>
</biblStruct>

<biblStruct coords="8,110.48,155.86,402.52,8.74;8,110.48,167.81,125.37,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,218.86,155.86,208.81,8.74">Mathematical morphology in the CIELAB space</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanbury</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Serra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,436.02,155.86,76.98,8.74;8,110.48,167.81,41.52,8.74">Image Analysis &amp; Stereology</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="201" to="206" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,187.74,402.53,8.74;8,110.48,199.69,402.52,8.74;8,110.48,211.65,111.44,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,263.39,187.74,249.62,8.74;8,110.48,199.69,24.67,8.74">Conservation of effort in feature selection for image annotation</title>
		<author>
			<persName coords=""><forename type="first">Suzanne</forename><surname>Little</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stefan</forename><surname>Rueger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,156.18,199.69,279.63,8.74">IEEE Workshop on Multimedia Signals Processing (MMSP2009)</title>
		<meeting><address><addrLine>Rio De Janeiro, Brazil</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-07">October 5-7 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,231.57,402.52,8.74;8,110.48,243.53,402.52,8.74;8,110.48,255.48,116.84,8.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,264.03,231.57,248.97,8.74;8,110.48,243.53,45.29,8.74">Using second order statistics to enhance automated image annotation</title>
		<author>
			<persName coords=""><forename type="first">Ainhoa</forename><surname>Llorente</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stefan</forename><surname>Rüger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,175.25,243.53,299.87,8.74">Proceedings of the 31st European Conference on Information Retrieval</title>
		<meeting>the 31st European Conference on Information Retrieval</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
			<biblScope unit="volume">5478</biblScope>
			<biblScope unit="page" from="570" to="577" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,275.41,402.52,8.74;8,110.48,287.36,341.60,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,230.40,275.41,249.19,8.74">Texture features for browsing and retireval of image data</title>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Manjunath</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Ma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,488.89,275.41,24.11,8.74;8,110.48,287.36,257.88,8.74">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="837" to="842" />
			<date type="published" when="1996">1996</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,307.29,402.52,8.74;8,110.48,319.24,222.33,8.74" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="8,287.45,307.29,185.28,8.74">Contextual correlates of semantic similarity</title>
		<author>
			<persName coords=""><forename type="first">George</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Walter</forename><forename type="middle">G</forename><surname>Charles</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,479.89,307.29,33.11,8.74;8,110.48,319.24,158.22,8.74">Journal of Language and Cognitive Processes</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="1991">1991</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,339.17,402.52,8.74;8,110.48,351.12,402.52,8.74;8,110.48,363.08,79.21,8.74" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="8,232.97,339.17,280.03,8.74;8,110.48,351.12,87.70,8.74">An effective, low-cost measure of semantic relatedness obtained from wikipedia links</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Milne</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">H</forename><surname>Witten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,219.14,351.12,293.86,8.74;8,110.48,363.08,49.11,8.74">Proceedings of the first AAAI Workshop on Wikipedia and Artifical Intellegence</title>
		<meeting>the first AAAI Workshop on Wikipedia and Artifical Intellegence</meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,383.00,402.52,8.74;8,110.48,394.96,402.52,8.74;8,110.48,406.91,58.21,8.74" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="8,265.13,383.00,247.87,8.74;8,110.48,394.96,134.26,8.74">Overview of the CLEF 2009 Large Scale -Visual Concept Detection and Annotation Task</title>
		<author>
			<persName coords=""><forename type="first">Stefanie</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Dunker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,264.22,394.96,214.17,8.74">Cross-Language Evaluation Forum Working Notes</title>
		<meeting><address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,426.84,402.52,8.74;8,110.48,438.79,402.52,8.74;8,110.48,450.75,163.75,8.74" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="8,302.02,426.84,210.98,8.74;8,110.48,438.79,68.12,8.74">Multilabel classification evaluation using ontology information</title>
		<author>
			<persName coords=""><forename type="first">Stefanie</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hanna</forename><surname>Lukashevich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,202.31,438.79,310.69,8.74;8,110.48,450.75,132.27,8.74">Proceedings of ESWC Workshop on Inductive Reasoning and Machine Learning on the Semantic Web</title>
		<meeting>ESWC Workshop on Inductive Reasoning and Machine Learning on the Semantic Web</meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,470.68,402.52,8.74;8,110.48,482.63,325.17,8.74" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="8,284.58,470.68,224.01,8.74">Textural features corresponding to visual perception</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Tamura</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mori</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Yamawaki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,110.48,482.63,233.31,8.74">IEEE Transactions on Systems, Man and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="460" to="473" />
			<date type="published" when="1978">1978</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,110.48,502.56,402.52,8.74;8,110.48,514.51,402.52,8.74;8,110.48,526.47,333.92,8.74" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="8,357.48,502.56,155.53,8.74;8,110.48,514.51,262.88,8.74">Automated image annotation using global features and robust nonparametric density estimation</title>
		<author>
			<persName coords=""><forename type="first">Alexei</forename><surname>Yavlinsky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Edward</forename><surname>Schofield</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Stefan</forename><surname>Rüger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,395.27,514.51,117.73,8.74;8,110.48,526.47,235.62,8.74">Proceedings of the International ACM Conference on Image and Video Retrieval</title>
		<meeting>the International ACM Conference on Image and Video Retrieval</meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="507" to="517" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
