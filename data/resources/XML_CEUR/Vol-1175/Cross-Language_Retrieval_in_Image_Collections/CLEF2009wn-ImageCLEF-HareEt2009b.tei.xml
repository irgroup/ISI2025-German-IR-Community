<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,95.64,148.86,411.72,15.15;1,102.04,170.78,398.93,15.15">IAM@ImageCLEFPhotoAnnotation 2009: Naïve application of a linear-algebraic semantic space</title>
				<funder ref="#_u8YCDc4">
					<orgName type="full">Autonomous Province of Trento (Italy)</orgName>
				</funder>
				<funder ref="#_ARDaxRr">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,229.71,204.67,74.33,8.74"><forename type="first">Jonathon</forename><forename type="middle">S</forename><surname>Hare</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronics and Computer Science</orgName>
								<orgName type="laboratory">Intelligence Agents Multimedia Group</orgName>
								<orgName type="institution">University of Southampton</orgName>
								<address>
									<settlement>Southampton</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,312.07,204.67,61.22,8.74"><forename type="first">Paul</forename><forename type="middle">H</forename><surname>Lewis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronics and Computer Science</orgName>
								<orgName type="laboratory">Intelligence Agents Multimedia Group</orgName>
								<orgName type="institution">University of Southampton</orgName>
								<address>
									<settlement>Southampton</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,95.64,148.86,411.72,15.15;1,102.04,170.78,398.93,15.15">IAM@ImageCLEFPhotoAnnotation 2009: Naïve application of a linear-algebraic semantic space</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">D81FC73CFDEB4E988DA2D309A0EA0E6E</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval</term>
					<term>H.3.1 [Information Storage and Retrieval]: Content Analysis and Indexing</term>
					<term>H.3.4 [Information Storage and Retrieval]: Systems and Software-Performance Evaluation</term>
					<term>I.4.9 [Artificial Intelligence]: Applications</term>
					<term>I.2.6 [Artificial Intelligence]: Learning Automatic Annotation, Performance, Experimentation Image Content Analysis, Data Fusion, Semantic Space</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes Southampton's submissions to the 2009 ImageCLEF photo annotation task. For the task we used an annotation system based on the idea of constructing semantic spaces, which was developed previously at Southampton. To represent the image content, we used a combination of different SIFT and Colour-SIFT features detected using the difference-of-Gaussian and MSER techniques. These features were converted into a visual term representation by applying vector quantisation using a codebook learnt from a hierarchical k-means clustering. In terms of EER and AUC, the annotator performs reasonably well, however, it struggles when evaluated using the hierarchical measure proposed for the task, due to the way the annotation confidences are thresholded.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The ImageCLEF 2009 photo annotation task set the challenge of automatically annotating 13000 images with 53 annotation concepts. The allowable training data was limited to a set of 5000 images pre-labelled with the concepts. The images themselves were drawn from the MIR Flickr 25000 image collection <ref type="bibr" coords="1,193.11,672.37,9.96,8.74" target="#b3">[4]</ref>. Southampton's submissions to the task used a previously developed annotation system, with a combination of visual term features created from local descriptors of salient interest regions.</p><p>As with many automatic annotation approaches, the methodology applied to this task involved extracting feature vectors for each of the images, and then feeding the features of a training set, together with annotations to a machine learning system. The machine learning system attempts to learn low-level relationships between all of the features and annotations. Once the training phase is complete, features from un-annotated images can be fed into the system to use the learnt relations to get predictions of annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Visual Features</head><p>The images were represented by vectors of visual-term occurrences <ref type="bibr" coords="2,390.36,239.89,14.61,8.74" target="#b10">[11]</ref>. The visual-terms were created by finding interest points and extracting local feature descriptors, and then quantising to a pre-determined codebook. For the experiments in this task we used a combination of multiscale difference-of-Gaussian interest regions with SIFT features <ref type="bibr" coords="2,369.97,275.76,9.96,8.74" target="#b5">[6]</ref>, MSER regions <ref type="bibr" coords="2,453.21,275.76,10.52,8.74" target="#b6">[7]</ref> with SIFT features, and MSER regions with colour-SIFT features <ref type="bibr" coords="2,330.99,287.72,9.96,8.74" target="#b0">[1]</ref>. Each of the three region/feature combinations had its own 3125 term codebook created by applying hierarchical k-means <ref type="bibr" coords="2,463.24,299.67,10.52,8.74" target="#b7">[8]</ref> (5 levels with 5 clusters per node). The codebook size was not optimised in any way, and was chosen based on a best guess basis from previous experience with these feature morphologies and the machine learning technique described in the next subsection. The final image representation was created by appending the term-occurrence vectors from each of the region/feature representations to create a vector with 9375 dimensions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Machine Learning</head><p>The machine-learning component is based on a linear-algebraic semantic space <ref type="bibr" coords="2,440.16,405.72,10.52,8.74" target="#b2">[3,</ref><ref type="bibr" coords="2,454.39,405.72,7.01,8.74" target="#b1">2]</ref>, which is a development and generalisation of a text indexing technique called Cross-Language Latent Semantic Indexing <ref type="bibr" coords="2,144.11,429.63,9.96,8.74" target="#b4">[5]</ref>. This technique produces a vector space into which both visual-terms and keyword terms are mapped along with the images. Un-annotated images can then be projected into this space. Annotation was performed by projecting the test images into the space, and ranking the possible annotations based on their cosine similarity.</p><p>The use of the cosine similarity measure gives each possible annotation a score between -1 and 1; however, these scores are not themselves all that informative. A higher score does mean more confidence in an annotation, but only when considered against all the other annotations. For the purposes of evaluating the annotator using the EER and AUC measures this is not too much of a problem -we can just scale the scores to the 0..1 range (i.e add one and divide by two). However, as will be discussed in the next section, the hierarchical scoring measure <ref type="bibr" coords="2,90.00,549.19,15.50,8.74" target="#b9">[10]</ref> thresholds the annotation confidences at 0.5 to produce a binary indication of present/notpresent. Unfortunately, for the semantic space this poses a big problem as the position of the threshold should ideally be set differently for each image, based on confidences of all the predicted annotations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments, Results and Discussion</head><p>We submitted three different runs to the task organisers. The first run was trained on the raw annotations. The second included a partial expansion of the annotation hierarchy <ref type="bibr" coords="2,460.66,651.77,10.52,8.74" target="#b8">[9]</ref> provided by the organisers, based on the non-abstract nodes (i.e. if Lake=true then water=true). The third included a full expansion of the hierarchy. The hierarchical expansion just means that a few extra annotation terms are fed into the machine learning component together with the leaf-node annotations already present for the image in question. The run titles and settings are shown in Table <ref type="table" coords="2,117.40,711.55,3.87,8.74" target="#tab_0">1</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run Title Description</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preliminary Results Analysis</head><p>The two runs that included the hierarchical information did not perform as well (based on average EER and AUC) as the one based on the raw annotations. Looking at the EER scores for each annotation term, the hierarchical methods were consistently worse performing. For these reasons the results for these runs will not be discussed further.</p><p>The EER and AUC scores are summarised in Table <ref type="table" coords="3,330.58,424.29,3.87,8.74" target="#tab_1">2</ref>. Our scores are better than the averages of the other participants, however, they are still a fair way off of the top scores. Using a semantic space approach for annotation, from past experience, we expect that there will be a large diversity in the performance for different terms. This is due to differences in the amount of training data for each term, and also the amount of visual diversity that might be associated with a term. For example, visually specific annotation terms require less training data than diverse ones. Table <ref type="table" coords="3,508.02,484.06,4.98,8.74" target="#tab_2">3</ref> shows the top-and bottom-most 5 annotation terms. It is interesting that the worst performing terms are those that are rather general and unspecific. The top performing terms all have very specific visual representations.</p><p>Table <ref type="table" coords="3,132.22,531.88,4.98,8.74" target="#tab_3">4</ref> shows the results of our annotator using the hierarchical measure <ref type="bibr" coords="3,427.22,531.88,14.61,8.74" target="#b9">[10]</ref>. Unfortunately, because this scoring measure performs a binary thresholding operation on the confidence scores, </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Computational Performance and Implementation Details</head><p>The feature extraction phase was performed in parallel (4 images being processed at once) on a quad core machine (Intel Core 2 Quad @ 2.66Ghz, 8G ram, Redhat Enterprise 5.3). The time for image processing varied based on both the size of the image, and the image content. Timings for a typical image from the training set are shown in Table <ref type="table" coords="4,339.54,361.58,3.87,8.74" target="#tab_4">5</ref>.</p><p>Training the semantic space took approximately 1 hour on a dual quad core 2.8GHz Xeon workstation running Mac OS X (the semantic space code is single threaded, so only uses a single core). We would estimate that no more than 1G of ram was used during the semantic space training phase. Projecting all the test image in bulk took under 2 minutes, and it took about 5 minutes to generate annotations for all the 13000 images; so, in general, it took less than .05s to get from a list of visual terms to the suggested annotations for a single image.</p><p>Implementation. The semantic-space software is written in C and makes use of Doug Rohde's SVDLIBC 1 for efficiently performing the large sparse SVD. The feature detector and descriptor software is written in C and C++. The image processing components were driven by a standard UNIX make file, which enabled easy parallelisation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Conclusions</head><p>For this task we applied an older technique for automatically annotating images using a semantic space. The performance of the technique in terms of EER and AUC is fairly competitive, however, the technique does not mesh well with the hierarchical scoring measure proposed for this task. The semantic space technique is reasonably computationally efficient; the most time is spent processing the images to extract features. In our experiments, the use of the hierarchy did not lead to any improvement in the annotation quality.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,136.55,125.17,329.90,166.04"><head>Table 1 :</head><label>1</label><figDesc>IAM Southampton 30 2 1245438072355.txt Raw annotations IAM Southampton 30 2 1245519187248.txt Partial hierarchical expansion IAM Southampton 30 2 1245519327555.txt Full hierarchical expansion Description of submitted runs</figDesc><table coords="3,170.23,204.33,262.54,86.87"><row><cell>Technique</cell><cell>EER AUC</cell></row><row><cell>Mean</cell><cell>0.373 0.553</cell></row><row><cell>Median</cell><cell>0.372 0.673</cell></row><row><cell>Min</cell><cell>0.234 0.070</cell></row><row><cell>Max</cell><cell>0.526 0.839</cell></row><row><cell>Random</cell><cell>0.500 0.499</cell></row><row><cell cols="2">IAM Southampton 30 2 1245438072355.txt 0.330 0.715</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,90.00,314.29,423.00,20.69"><head>Table 2 :</head><label>2</label><figDesc>Summary of averaged EER and AUC scores over all annotation terms. The summary statistics were calculated using only for the best run of each participant.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,202.75,574.44,197.51,168.11"><head>Table 3 :</head><label>3</label><figDesc>Best and worst annotations by EER the performance of our technique measures at the lower end of the spectrum of results from the different participants. As previously discussed, the semantic space annotation approach doesn't really permit the global setting of such a threshold.</figDesc><table coords="3,238.22,574.44,126.57,136.29"><row><cell>Annotation Term EER</cell></row><row><cell>Sunset-Sunrise 0.232</cell></row><row><cell>Landscape-Nature 0.234</cell></row><row><cell>Night 0.237</cell></row><row><cell>Sea 0.243</cell></row><row><cell>Mountains 0.249</cell></row><row><cell>Aesthetic-Impression 0.416</cell></row><row><cell>Overall-Quality 0.436</cell></row><row><cell>Neutral-Illumination 0.466</cell></row><row><cell>Sports 0.470</cell></row><row><cell>Fancy 0.478</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,193.31,267.86,216.38,8.74"><head>Table 4 :</head><label>4</label><figDesc>Summary of averaged hierarchical scores</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="4,97.40,602.68,408.20,149.76"><head>Table 5 :</head><label>5</label><figDesc>1 http://tedlab.mit.edu/ ~dr/SVDLIBC/ Approximate timings for feature extraction on a typical image from the training set.</figDesc><table coords="4,295.15,633.74,137.92,8.77"><row><cell>Feature</cell><cell>Time</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The authors wish to thank the <rs type="institution">European Union</rs>, which supported this work under the <rs type="programName">Seventh Framework project</rs> <rs type="projectName">LivingKnowledge</rs> (<rs type="grantNumber">IST-FP7-231126</rs>) and the <rs type="projectName">LiveMemories</rs> project, graciously funded by the <rs type="funder">Autonomous Province of Trento (Italy)</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_ARDaxRr">
					<idno type="grant-number">IST-FP7-231126</idno>
					<orgName type="project" subtype="full">LivingKnowledge</orgName>
					<orgName type="program" subtype="full">Seventh Framework project</orgName>
				</org>
				<org type="funded-project" xml:id="_u8YCDc4">
					<orgName type="project" subtype="full">LiveMemories</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="5,110.48,257.42,402.52,8.74;5,110.48,269.37,337.22,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="5,340.55,257.42,172.45,8.74;5,110.48,269.37,41.09,8.74">Performance evaluation of local colour invariants</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gertjan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jan-Mark</forename><surname>Burghouts</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Geusebroek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,160.09,269.37,188.81,8.74">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="48" to="62" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,110.48,289.30,402.52,8.74;5,110.48,301.25,402.52,8.74;5,110.48,313.21,297.55,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="5,442.13,289.30,70.87,8.74;5,110.48,301.25,402.52,8.74;5,110.48,313.21,58.65,8.74">Semantic spaces revisited: investigating the performance of auto-annotation and semantic retrieval using semantic spaces</title>
		<author>
			<persName coords=""><forename type="first">Jonathan</forename><forename type="middle">S</forename><surname>Hare</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Sina</forename><surname>Samangooei</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><forename type="middle">H</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><forename type="middle">S</forename><surname>Nixon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,190.28,313.21,67.99,8.74">ACM CIVR &apos;08</title>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008-07">July 2008</date>
			<biblScope unit="page" from="359" to="368" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,110.48,333.14,402.52,8.74;5,110.48,345.09,402.52,8.74;5,110.48,357.05,402.52,8.74;5,110.48,369.00,123.54,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="5,470.43,333.14,42.57,8.74;5,110.48,345.09,309.00,8.74">A Linear-Algebraic Technique with an Application in Semantic Image Retrieval</title>
		<author>
			<persName coords=""><forename type="first">Jonathon</forename><forename type="middle">S</forename><surname>Hare</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><forename type="middle">H</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">B</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Christine</forename><forename type="middle">J</forename><surname>Enser</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Sandom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,359.16,357.05,47.74,8.74">CIVR 2006</title>
		<editor>
			<persName><forename type="first">Hari</forename><surname>Sundaram</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Milind</forename><surname>Naphade</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">John</forename><forename type="middle">R</forename><surname>Smith</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Yong</forename><surname>Rui</surname></persName>
		</editor>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="volume">4071</biblScope>
			<biblScope unit="page" from="31" to="40" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,110.48,388.93,402.52,8.74;5,110.48,400.88,402.52,8.74;5,110.48,412.84,149.19,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="5,292.01,388.93,152.15,8.74">The mir flickr retrieval evaluation</title>
		<author>
			<persName coords=""><forename type="first">Mark</forename><forename type="middle">J</forename><surname>Huiskes</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Lew</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,471.64,388.93,41.36,8.74;5,110.48,400.88,398.37,8.74">MIR &apos;08: Proceedings of the 2008 ACM International Conference on Multimedia Information Retrieval</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,110.48,432.76,402.52,8.74;5,110.48,444.72,402.52,8.74;5,110.48,456.67,402.52,8.74;5,110.48,468.63,321.04,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="5,264.63,432.76,248.37,8.74;5,110.48,444.72,105.68,8.74">Fully automatic cross-language document retrieval using latent semantic indexing</title>
		<author>
			<persName coords=""><forename type="first">T K</forename><surname>Landauer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M L</forename><surname>Littman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,238.82,444.72,274.18,8.74;5,110.48,456.67,252.38,8.74">Proceedings of the Sixth Annual Conference of the UW Centre for the New Oxford English Dictionary and Text Research</title>
		<meeting>the Sixth Annual Conference of the UW Centre for the New Oxford English Dictionary and Text Research<address><addrLine>Waterloo, Ontario, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1990-10">October 1990</date>
			<biblScope unit="page" from="31" to="38" />
		</imprint>
		<respStmt>
			<orgName>UW Centre for the New OED and Text Research</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="5,110.48,488.55,402.52,8.74;5,110.48,500.51,61.04,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="5,169.70,488.55,246.10,8.74">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="5,425.05,488.55,21.10,8.74">IJCV</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004-01">January 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,110.48,520.43,402.52,8.74;5,110.48,532.39,402.52,8.74;5,110.48,544.34,218.80,8.74" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="5,389.78,520.43,123.22,8.74;5,110.48,532.39,173.67,8.74">Robust wide baseline stereo from maximally stable extremal regions</title>
		<author>
			<persName coords=""><forename type="first">Jiri</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ondrej</forename><surname>Chum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tomás</forename><surname>Pajdla</surname></persName>
		</author>
		<editor>Paul L. Rosin and A. David Marshall</editor>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>BMVC. British Machine Vision Association</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,110.48,564.27,402.52,8.74;5,110.48,576.22,100.79,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="5,267.06,564.27,183.70,8.74">Scalable recognition with a vocabulary tree</title>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Nister</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henrik</forename><surname>Stewenius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,481.67,564.27,25.06,8.74">CVPR</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="2161" to="2168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,110.48,596.15,402.52,8.74;5,110.48,608.10,366.79,8.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="5,263.92,596.15,249.09,8.74;5,110.48,608.10,136.12,8.74">Overview of the CLEF 2009 Large Scale -Visual Concept Detection and Annotation Task</title>
		<author>
			<persName coords=""><forename type="first">Stefanie</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Dunker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,268.13,608.10,112.23,8.74">CLEF working notes 2009</title>
		<meeting><address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,110.48,628.03,402.52,8.74;5,110.48,639.98,402.52,8.74;5,110.48,651.94,402.52,8.74;5,110.48,663.90,331.24,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="5,294.46,628.03,218.54,8.74;5,110.48,639.98,48.99,8.74">Multilabel classification evaluation using ontology information</title>
		<author>
			<persName coords=""><forename type="first">Stefanie</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Hanna</forename><surname>Lukashevich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,233.37,651.94,279.63,8.74;5,110.48,663.90,192.12,8.74">Proceedings of the First ESWC Workshop on Inductive Reasoning and Machine Learning on the Semantic Web</title>
		<editor>
			<persName><forename type="first">Nicola</forename><surname>Claudia D'amato</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Marko</forename><surname>Fanizzi</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Agnieszka</forename><surname>Grobelnik</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Vojtech</forename><surname>Lawrynowicz</surname></persName>
		</editor>
		<editor>
			<persName><surname>Svátek</surname></persName>
		</editor>
		<meeting>the First ESWC Workshop on Inductive Reasoning and Machine Learning on the Semantic Web<address><addrLine>Heraklion, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-06">June 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="5,110.48,683.82,402.52,8.74;5,110.48,695.78,217.41,8.74" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="5,231.63,683.82,281.36,8.74;5,110.48,695.78,25.43,8.74">Video google: A text retrieval approach to object matching in videos</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="5,157.02,695.78,22.62,8.74">ICCV</title>
		<imprint>
			<date type="published" when="2003-10">October 2003</date>
			<biblScope unit="page" from="1470" to="1477" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
