<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,102.35,148.86,398.29,15.15;1,117.46,170.78,368.07,15.15">IAM@ImageCLEFphoto 2009: Experiments on Maximising Diversity using Image Features</title>
				<funder ref="#_SuYuvfV">
					<orgName type="full">Autonomous Province of Trento (Italy)</orgName>
				</funder>
				<funder ref="#_HqE4U6P">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,186.61,204.67,74.33,8.74"><forename type="first">Jonathon</forename><forename type="middle">S</forename><surname>Hare</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronics and Computer Science</orgName>
								<orgName type="laboratory">Intelligence Agents Multimedia Group</orgName>
								<orgName type="institution">University of Southampton</orgName>
								<address>
									<settlement>Southampton</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,268.97,204.67,77.67,8.74"><forename type="first">David</forename><forename type="middle">P</forename><surname>Dupplaw</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronics and Computer Science</orgName>
								<orgName type="laboratory">Intelligence Agents Multimedia Group</orgName>
								<orgName type="institution">University of Southampton</orgName>
								<address>
									<settlement>Southampton</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,355.18,204.67,61.21,8.74"><forename type="first">Paul</forename><forename type="middle">H</forename><surname>Lewis</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Electronics and Computer Science</orgName>
								<orgName type="laboratory">Intelligence Agents Multimedia Group</orgName>
								<orgName type="institution">University of Southampton</orgName>
								<address>
									<settlement>Southampton</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,102.35,148.86,398.29,15.15;1,117.46,170.78,368.07,15.15">IAM@ImageCLEFphoto 2009: Experiments on Maximising Diversity using Image Features</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">21AE30D25BCDF5B80388415136E50465</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:20+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software Image search, Diversity, Measurement, Performance, Experimentation Image Content Analysis, Data Fusion, Content-based Image Retrieval</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper describes the diversity enabled retrieval system constructed at Southampton for the ImageCLEFphoto 2009 task. The retrieval system used Terrier as the underlying textual indexing and retrieval system, and combined it with a technique for re-ranking the results by maximising the visual dissimilarity of retrieved images. The results show that our visual re-ranking methods does indeed work at increasing the diversity in the top results, however, at the same time it causes a slight drop in precision. The text-based approach designed for handling the 'part 1 topics' of the task is also shown to perform very well.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The 2009 ImageCLEF photo retrieval task <ref type="bibr" coords="1,281.50,588.68,10.52,8.74" target="#b8">[9]</ref> aimed to promote diversity in image search. The was performed using a set of nearly 500,000 captioned images provided by the Belga photo agency. The task incorporated two separate query types. The part 1 topics were described as a main topic (i.e. 'David Beckham'), together with a set of clusters or sub-topics (i.e. 'Manchester United', 'Real Madrid', etc.). The part 1 topics also included detailed information about what might be expected in the results of a search for each of the clusters. The part 2 topics provided a single topic with no context. Both part 1 and 2 topics included example images which could be used for content-based search or classification.</p><p>In the 2009 ImageCLEF photo retrieval task, Southampton's baseline system used standard text retrieval techniques for the part 2 topics. The baseline handling of the part 1 topics augmented the standard text search with multiple sub-queries (one per cluster) followed by a merge phase in order to build a complete ranking for the topic. On top of the baseline system we developed a reranking procedure for the results lists that leveraged visual features extracted from the images and attempted to re-order the list such that the first images in the list were highly visually dissimilar.</p><p>The overall methodology for tackling the task involved building a baseline retrieval system using only the textual captions, and then augmenting the search results generated by the baseline system with information extracted from the actual content of the images in order to promote a diverse spectrum of different images near the top of the ranked search results. Each of the different aspects of this methodology is described below.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Text-based Baseline System</head><p>The Terrier text retrieval system <ref type="bibr" coords="2,241.12,227.94,9.96,8.74" target="#b7">[8]</ref>, developed at the University of Glasgow, was used as the underlying text search technology for our submissions. In particular, we adapted Terrier to index the image captions, and modified the search algorithm based on the particular query formulations in the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Indexing of Captions</head><p>The caption tokeniser was configured to tokenise all of the text in the input record after the document identifier. The tokeniser took any non-alphanumeric character, or run of non-alphanumeric characters, as being a token separator. Each token was converted to lowercase, and tokens with more than four digits or three consecutive instances of the same letter were rejected. Tokens matching the standard Terrier list of stopwords were also discarded. For experimentation, we build two separated indices; one with the Porter Stemmer <ref type="bibr" coords="2,301.52,367.87,15.50,8.74" target="#b9">[10]</ref> feature enabled, and another without.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Retrieval using the Indexed Captions</head><p>For retrieval, Terrier was configured to use the standard TF-IDF weighting model (based on Robertson's definition of TF and the standard Sparck-Jones IDF definition <ref type="bibr" coords="2,416.36,424.11,10.30,8.74" target="#b2">[3]</ref>). Within the photo retrieval task, there were two sets of queries or topics. Each query in the first set contained a title, together with a number of explicit clusters, which themselves included a title ("clusterTitle"), description ("clusterDesc") and sample images. The second set of queries only contained a single title together with three sample images relevant to that title. The retrieval methods we used were necessarily different for the two sets of query modalities, however, the search and retrieval process is completely automatically driven by the provided topic files.</p><p>Part 1 topics. This year, we only considered the cluster titles for building our search. Because the cluster titles also contained the terms used in the overall topic title, for the purposes of reporting it is assumed that that the topic title is used as well. For each of the topics, a three stage process was used to generate the results:</p><p>1. Convert each "clusterTitle" into a Terrier query such that all words with a '-' must not appear anywhere in the captions of the returned images, and all the remaining words must appear in the captions of the result documents.</p><p>2. Query the index using each of the generated queries from the cluster titles in turn and store the results.</p><p>3. Merge the results lists in a round-robin fashion, ignoring the scores assigned by Terrier (i.e. just using ranked position). The top ranked results from each of the sub-queries will come first, followed by the second most relevant images, and so on. Duplicate images (i.e. those retrieved from more than one of the searches) are also filtered, so only the higher ranking example is retained. At this point we also gave each image an arbitrary score based on its position in the sub-query search; in our implementation all of the top-ranked images from the sub-queries scored 4000 and the second ranking images scored 3999, etc.</p><p>Part 2 topics. The second set of queries was processed in a much simpler manner; basically, results were generated by feeding the title into a Terrier query (marking all terms in the title field as required, as in the part 1 topics). No attempt to improving diversity by further analysis of the textual information was made for these topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Enhancing Result-set Diversity with Image Features</head><p>We hypothesise that the use of image features could give a large boost to the diversity of a result set. In particular, in our approach we developed a technique that re-ranks a list of search results by maximising the visual dissimilarity of the top-ranking images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1">Image Features</head><p>The image feature used in the submitted experiments was a visual-term representation based on quantised SIFT features extracted from a multiscale difference-of-Gaussian pyramid <ref type="bibr" coords="3,476.96,274.31,9.96,8.74" target="#b3">[4]</ref>. The features were quantised to a vocabulary of 3125 terms <ref type="bibr" coords="3,343.07,286.27,15.50,8.74" target="#b10">[11,</ref><ref type="bibr" coords="3,363.44,286.27,7.01,8.74" target="#b1">2]</ref>. The codebook for the vector quantiser was learnt using a hierarchical K-means algorithm <ref type="bibr" coords="3,351.82,298.22,10.52,8.74" target="#b5">[6]</ref> (5 levels with 5 clusters per node); Due to time constraints, we used a pre-existing codebook that we had previously trained on the 5000 training images from ImageCLEF 2009 photo annotation task <ref type="bibr" coords="3,384.23,322.13,9.96,8.74" target="#b6">[7]</ref>. We also generated similar features using the MSER algorithm <ref type="bibr" coords="3,245.02,334.09,10.52,8.74" target="#b4">[5]</ref> coupled with quantised SIFT and Colour-SIFT <ref type="bibr" coords="3,462.90,334.09,10.52,8.74" target="#b0">[1]</ref> features, however, again for time reasons these were not included in the submitted results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.2">Re-ranking Algorithm</head><p>In order to try and improve the diversity of the result set, we propose a technique that incorporates visual information into the ranking. The proposed algorithm works by maximising the distance between the set of already re-ranked images, R, and an image from the ranked list of images retrieved from the text-based search, I. The distance between the feature-vectors of a set of images, R, and the feature-vector from a single image, f q , is calculated using Equation <ref type="formula" coords="3,481.69,438.15,3.87,8.74" target="#formula_0">1</ref>. The function d(., .) in Equation 1 can be any distance function that compares two vectors; in this work we chose to use the Euclidean distance.</p><formula xml:id="formula_0" coords="3,247.60,485.97,265.39,20.14">D(f q , R) = fr∈R d(f q , f r )<label>(1)</label></formula><p>Algorithm 1 shows the steps taken to re-order the results from a text-based search using image feature-vectors. The output is a list containing all of the input images, but in a different order. Note that the algorithm treats the first input image as a special key, and that that image will also appear in the rank 1 position in the output.  <ref type="formula" coords="3,359.62,667.31,4.43,8.74" target="#formula_0">1</ref>) is maximised Add I x to R and remove it from I return R end Application to Part 1 Topics. In our experiments, we applied the visual re-ranking procedure individually to each of the results sets formed from the sub-searches created from the cluster titles. The re-ranked sub-result-sets were then merged as with the text-based search for part 1 topics.</p><p>Application to Part 2 Topics. Re-ranking of the results was simply a matter of applying the algorithm to the result set formed through the part 2 topics text search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experiments, Results and Discussion</head><p>We submitted four runs to the task organisers. The run parameters were configured by controlling the application of the Porter Stemmer in the text indexing and retrieval stage, and applying, or not applying, the visual re-ranking. The run titles and their configurations can be seen in Table <ref type="table" coords="4,90.00,264.41,3.87,8.74">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Diversity Re-ranking Configuration Terrier Configuration Porter Stemmer</head><p>No Stemming None SOTON1 T CT TXT SOTON2 T CT TXT Visual Features SOTON1 T CT TXT IMG SOTON2 T CT TXT IMG Table <ref type="table" coords="4,118.89,354.62,3.87,8.74">1</ref>: Matrix showing the configurations of our submitted experimental runs. The mean, median, min and max are calculated over all the submitted results from each of the participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Preliminary Results Analysis</head><p>Table <ref type="table" coords="4,117.24,426.75,4.98,8.74" target="#tab_0">2</ref> shows a summary of Southampton's results calculated over all the topics from both parts 1 and 2. All of the results are significantly above the mean scores calculated from averaging the results of all runs submitted by all participants. However, the MAP scores in particular are still significantly below the maximum achieved by other participants.</p><p>The results show that the application of the visual re-ranking algorithm causes a drop in precision, which is however traded off by an increase in the cluster recall, implying a higher diversity in the ranked results. Turning off the Porter stemmer gives a slight boost in precision.</p><p>We hypothesise that turning off the stemmer has this effect because a number of the queries contained names of entities which would be adversely affected by the stemmer, and produce many irrelevant images in the result set. As an example, consider the topic which contained the term "fortis". Using the Porter stemmer, this is indexed as "forti". Unfortunately, the number "forty" is also indexed as "forti", and so searching for "fortis" will include many irrelevant results from images that had nothing to do with "fortis", but did have "forty" in their captions.</p><p>Results from only the part 1 topics are shown in Table <ref type="table" coords="4,340.66,582.16,3.87,8.74" target="#tab_1">3</ref>. The table shows that the run entitled 'SOTON2 T CT TXT' achieved the highest F-measure (which measures the combined precision and cluster recall after 10 retrieved documents) and P10 scores from all the submitted results. Again, the effect of the visual re-ranking is to increase cluster recall, but decrease precision. Turning off the stemmer gives a slight precision boost (in the first few retrieved documents) and also boosts cluster recall slightly.</p><p>In the part 2 topic results shown in Table <ref type="table" coords="4,299.67,653.89,3.87,8.74" target="#tab_2">4</ref>, the trend of increased cluster recall with the addition of the visual re-ranking holds true. The same is true of the stemming; disabling stemming increases precision slightly. One difference with the part 1 results however, is that the F-measure statistic reports slightly better results with stemming enabled. Run Name S V MAP F-measure P@10 P@20 CR@10 CR@20 Mean 0. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion, Conclusions and Future Possibilities</head><p>The multiple sub-query and merge approach for the part 1 topics clearly works very well. The approach taken for the part 2 topics suffers from a lack of precision in the retrieved result sets from the text retrieval. The visual re-ranking algorithm described in section 1 has been shown to work as planned through the increased cluster recall scores it is able to produce; however, at the same time it causes a drop in F-measure because precision at the top-end of the result list also drops. One possible remedy to this problem would be to improve the precision of baseline text retrieval system so that fewer irrelevant images get passed into the re-ranking algorithm. Another possible approach would be to incorporate the retrieval score of the text-retrieval phase into the re-ranking so that images that were predicted to be more relevant still appear higher in the final result list.</p><p>Turning off the Porter stemmer gives a small boost in performance. We need to do some more analysis of the results, however, we hypothesise that the reasons are attributable to the problem of stemming named entities as described earlier. A future modification to the textual indexing and query processors might be to incorporate natural language processing (NLP) techniques to automatically detect named entities and not stem them, whilst still using stemming for other words.</p><p>In the experiments described in this paper we only used a single form of visual feature. It would be interesting to repeat the experiments in the future using a broader spectrum of visual features, and to also look at combining various features. There are also possibilities for using the sample images that were provided as part of the topic specification to help drive the search using both content-based techniques, and perhaps query expansion or automatic relevance feedback using information in the captions belonging to those images.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,97.47,575.68,270.20,8.77;3,104.94,589.32,323.69,9.68;3,104.94,601.28,221.48,9.68;3,104.94,617.52,27.21,8.77;3,120.29,628.06,115.08,8.74;3,120.29,640.01,251.16,9.65;3,120.29,656.23,108.83,8.77;3,135.63,667.31,220.67,9.65"><head>Algorithm 1 :</head><label>1</label><figDesc>Re-ranking by maximising visual dissimilarity. input : A ranked list of n images, I = I 1 ...I n , from the text-based search output: A re-ranked list of n images, R = R 1 ...R n begin Construct an empty list R Add the first element of I, I 1 , to R, and remove it from I while I is not empty do Find I x from I such that D(I x , R) (from Equation</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,95.98,157.60,411.80,314.39"><head>Table 2 :</head><label>2</label><figDesc>Summary of results over all part 1 and part 2 queries.</figDesc><table coords="5,95.98,157.60,411.80,314.39"><row><cell></cell><cell>294</cell><cell>0.585</cell><cell>0.655 0.455</cell><cell>0.547</cell><cell>0.623</cell></row><row><cell>Median</cell><cell>0.330</cell><cell>0.629</cell><cell>0.754 0.506</cell><cell>0.557</cell><cell>0.641</cell></row><row><cell>Min</cell><cell>0.003</cell><cell>0.095</cell><cell>0.068 0.019</cell><cell>0.158</cell><cell>0.206</cell></row><row><cell>Max</cell><cell>0.506</cell><cell>0.809</cell><cell>0.848 0.691</cell><cell>0.824</cell><cell>0.862</cell></row><row><cell>SOTON1 T CT TXT</cell><cell>y n 0.372</cell><cell>0.720</cell><cell>0.802 0.648</cell><cell>0.653</cell><cell>0.718</cell></row><row><cell cols="2">SOTON1 T CT TXT IMG y y 0.332</cell><cell>0.716</cell><cell>0.720 0.567</cell><cell>0.711</cell><cell>0.770</cell></row><row><cell>SOTON2 T CT TXT</cell><cell>n n 0.379</cell><cell>0.729</cell><cell>0.824 0.649</cell><cell>0.654</cell><cell>0.711</cell></row><row><cell cols="2">SOTON2 T CT TXT IMG n y 0.339</cell><cell>0.727</cell><cell>0.746 0.566</cell><cell>0.745</cell><cell>0.767</cell></row><row><cell>Run Name</cell><cell cols="5">S V MAP F-measure P@10 P@20 CR@10 CR@20</cell></row><row><cell>Mean</cell><cell>0.297</cell><cell>0.600</cell><cell>0.677 0.448</cell><cell>0.558</cell><cell>0.640</cell></row><row><cell>Median</cell><cell>0.347</cell><cell>0.639</cell><cell>0.768 0.533</cell><cell>0.574</cell><cell>0.646</cell></row><row><cell>Min</cell><cell>0.001</cell><cell>0.033</cell><cell>0.028 0.010</cell><cell>0.041</cell><cell>0.072</cell></row><row><cell>Max</cell><cell>0.513</cell><cell>0.818</cell><cell>0.868 0.658</cell><cell>0.829</cell><cell>0.877</cell></row><row><cell>SOTON1 T CT TXT</cell><cell>y n 0.361</cell><cell>0.784</cell><cell>0.824 0.603</cell><cell>0.747</cell><cell>0.810</cell></row><row><cell cols="2">SOTON1 T CT TXT IMG y y 0.322</cell><cell>0.776</cell><cell>0.760 0.535</cell><cell>0.793</cell><cell>0.832</cell></row><row><cell>SOTON2 T CT TXT</cell><cell>n n 0.371</cell><cell>0.818</cell><cell>0.868 0.601</cell><cell>0.773</cell><cell>0.820</cell></row><row><cell cols="2">SOTON2 T CT TXT IMG n y 0.333</cell><cell>0.805</cell><cell>0.804 0.528</cell><cell>0.806</cell><cell>0.842</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="5,95.98,495.08,411.80,194.10"><head>Table 3 :</head><label>3</label><figDesc>Summary of results for all part 1 queries.</figDesc><table coords="5,95.98,579.62,411.80,109.56"><row><cell>Run Name</cell><cell cols="5">S V MAP F-measure P@10 P@20 CR@10 CR@20</cell></row><row><cell>Mean</cell><cell>0.288</cell><cell>0.569</cell><cell>0.632 0.460</cell><cell>0.542</cell><cell>0.614</cell></row><row><cell>Median</cell><cell>0.307</cell><cell>0.639</cell><cell>0.740 0.496</cell><cell>0.574</cell><cell>0.642</cell></row><row><cell>Min</cell><cell>0.001</cell><cell>0.102</cell><cell>0.072 0.017</cell><cell>0.096</cell><cell>0.115</cell></row><row><cell>Max</cell><cell>0.530</cell><cell>0.819</cell><cell>0.836 0.724</cell><cell>0.819</cell><cell>0.876</cell></row><row><cell>SOTON1 T CT TXT</cell><cell>y n 0.383</cell><cell>0.652</cell><cell>0.780 0.693</cell><cell>0.560</cell><cell>0.626</cell></row><row><cell cols="2">SOTON1 T CT TXT IMG y y 0.342</cell><cell>0.653</cell><cell>0.680 0.600</cell><cell>0.629</cell><cell>0.708</cell></row><row><cell>SOTON2 T CT TXT</cell><cell>n n 0.387</cell><cell>0.635</cell><cell>0.780 0.696</cell><cell>0.594</cell><cell>0.602</cell></row><row><cell cols="2">SOTON2 T CT TXT IMG n y 0.345</cell><cell>0.648</cell><cell>0.688 0.604</cell><cell>0.613</cell><cell>0.692</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,191.62,712.27,219.76,8.74"><head>Table 4 :</head><label>4</label><figDesc>Summary of results for all part 2 queries.</figDesc><table /></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p>The authors wish to thank the <rs type="institution">European Union</rs>, which supported this work under the <rs type="programName">Seventh Framework project</rs> <rs type="projectName">LivingKnowledge</rs> (<rs type="grantNumber">IST-FP7-231126</rs>) and the <rs type="projectName">LiveMemories</rs> project, graciously funded by the <rs type="funder">Autonomous Province of Trento (Italy)</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_HqE4U6P">
					<idno type="grant-number">IST-FP7-231126</idno>
					<orgName type="project" subtype="full">LivingKnowledge</orgName>
					<orgName type="program" subtype="full">Seventh Framework project</orgName>
				</org>
				<org type="funded-project" xml:id="_SuYuvfV">
					<orgName type="project" subtype="full">LiveMemories</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,110.48,518.34,402.52,8.74;6,110.48,530.30,337.23,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,340.55,518.34,172.45,8.74;6,110.48,530.30,41.09,8.74">Performance evaluation of local colour invariants</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Gertjan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jan-Mark</forename><surname>Burghouts</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Geusebroek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,160.09,530.30,188.81,8.74">Computer Vision and Image Understanding</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="48" to="62" />
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,550.22,402.52,8.74;6,110.48,562.18,402.52,8.74;6,110.48,574.13,402.52,8.74;6,110.48,586.09,106.32,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,281.69,550.22,231.31,8.74;6,110.48,562.18,117.72,8.74">On image retrieval using salient regions with vectorspaces and latent semantics</title>
		<author>
			<persName coords=""><forename type="first">Jonathon</forename><forename type="middle">S</forename><surname>Hare</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><forename type="middle">H</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,455.64,574.13,23.32,8.74">LNCS</title>
		<editor>
			<persName><forename type="first">Kheng</forename><surname>Wee</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><forename type="middle">S</forename><surname>Leow</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Tat-Seng</forename><surname>Lew</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Wei-Ying</forename><surname>Chua</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Lekha</forename><surname>Ma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Erwin</forename><forename type="middle">M</forename><surname>Chaisorn</surname></persName>
		</editor>
		<editor>
			<persName><surname>Bakker</surname></persName>
		</editor>
		<imprint>
			<biblScope unit="volume">3568</biblScope>
			<biblScope unit="page" from="540" to="549" />
			<date type="published" when="2005">2005</date>
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,606.01,402.52,8.74;6,110.48,617.97,229.66,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,209.43,606.01,303.57,8.74;6,110.48,617.97,34.67,8.74">A statistical interpretation of term specificity and its application in retrieval</title>
		<author>
			<persName coords=""><forename type="first">Karen</forename><surname>Spärck</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jones</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,153.42,617.97,112.08,8.74">Journal of Documentation</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="11" to="21" />
			<date type="published" when="1972">1972</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,637.90,402.52,8.74;6,110.48,649.85,61.04,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,169.70,637.90,246.10,8.74">Distinctive image features from scale-invariant keypoints</title>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,425.05,637.90,21.10,8.74">IJCV</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="91" to="110" />
			<date type="published" when="2004-01">January 2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,669.78,402.52,8.74;6,110.48,681.73,402.52,8.74;6,110.48,693.69,218.80,8.74" xml:id="b4">
	<monogr>
		<title level="m" type="main" coord="6,389.78,669.78,123.22,8.74;6,110.48,681.73,173.67,8.74">Robust wide baseline stereo from maximally stable extremal regions</title>
		<author>
			<persName coords=""><forename type="first">Jiri</forename><surname>Matas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ondrej</forename><surname>Chum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Martin</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Tomás</forename><surname>Pajdla</surname></persName>
		</author>
		<editor>Paul L. Rosin and A. David Marshall</editor>
		<imprint>
			<date type="published" when="2002">2002</date>
			<publisher>BMVC. British Machine Vision Association</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,110.48,713.61,402.52,8.74;6,110.48,725.57,100.79,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,267.06,713.61,183.70,8.74">Scalable recognition with a vocabulary tree</title>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Nister</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henrik</forename><surname>Stewenius</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,481.67,713.61,25.06,8.74">CVPR</title>
		<imprint>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="2161" to="2168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,112.02,402.52,8.74;7,110.48,123.98,366.79,8.74" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="7,263.92,112.02,249.09,8.74;7,110.48,123.98,136.12,8.74">Overview of the CLEF 2009 Large Scale -Visual Concept Detection and Annotation Task</title>
		<author>
			<persName coords=""><forename type="first">Stefanie</forename><surname>Nowak</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Peter</forename><surname>Dunker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,268.13,123.98,112.23,8.74">CLEF working notes 2009</title>
		<meeting><address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,143.90,402.52,8.74;7,110.48,155.86,402.52,8.74;7,110.48,167.81,87.11,8.74" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="7,351.43,143.90,124.71,8.74">Research directions in terrier</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Ounis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Lioma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Plachouras</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,483.95,143.90,29.05,8.74;7,110.48,155.86,248.78,8.74">Novatica/UPGRADE Special Issue on Web Information Access</title>
		<editor>
			<persName><forename type="first">Ricardo</forename><surname>Baeza-Yates</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note>Invited Paper</note>
</biblStruct>

<biblStruct coords="7,110.48,187.74,402.52,8.74;7,110.48,199.69,381.04,8.74" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="7,349.88,187.74,163.12,8.74;7,110.48,199.69,150.49,8.74">Diversity in photo retrieval: overview of the ImageCLEFPhoto task 2009</title>
		<author>
			<persName coords=""><forename type="first">Monica</forename><surname>Paramita</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,282.38,199.69,112.23,8.74">CLEF working notes 2009</title>
		<meeting><address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,219.62,340.91,8.74" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="7,170.30,219.62,140.77,8.74">An algorithm for suffix stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="7,319.65,219.62,34.40,8.74">Program</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="7,110.48,239.54,402.52,8.74;7,110.48,251.50,217.41,8.74" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="7,231.63,239.54,281.36,8.74;7,110.48,251.50,25.43,8.74">Video google: A text retrieval approach to object matching in videos</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Sivic</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Zisserman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="7,157.02,251.50,22.62,8.74">ICCV</title>
		<imprint>
			<date type="published" when="2003-10">October 2003</date>
			<biblScope unit="page" from="1470" to="1477" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
