<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,211.94,74.37,171.59,12.52;1,161.31,90.45,272.68,12.52">Diversity in Photo Retrieval: Overview of the ImageCLEFPhoto Task 2009</title>
				<funder ref="#_xkj9jnE">
					<orgName type="full">European Commission</orgName>
				</funder>
				<funder>
					<orgName type="full">TrebleCLEF Coordination Action</orgName>
				</funder>
				<funder ref="#_bnH6GAu">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,178.23,121.41,97.04,8.88"><forename type="first">Monica</forename><forename type="middle">Lestari</forename><surname>Paramita</surname></persName>
							<email>m.paramita@sheffield.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,282.04,121.41,65.81,8.88"><forename type="first">Mark</forename><surname>Sanderson</surname></persName>
							<email>m.sanderson@sheffield.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,367.23,121.41,49.72,8.88"><forename type="first">Paul</forename><surname>Clough</surname></persName>
							<email>p.d.clough@sheffield.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Sheffield</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,211.94,74.37,171.59,12.52;1,161.31,90.45,272.68,12.52">Diversity in Photo Retrieval: Overview of the ImageCLEFPhoto Task 2009</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">A238BFD5546D2798E3F2835ED5F07255</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Management]: Languages-Query Languages Measurement, Performance, Experimentation Performance Evaluation, Image Retrieval, Diversity, Clustering</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The ImageCLEF Photo Retrieval Task 2009 focused on image retrieval and diversity. A new collection was utilised in this task consisting of approximately half a million images with English annotations. Queries were based on analysing search query logs and two different types were released: one containing information about image clusters; the other without. A total of 19 participants submitted 84 runs. Evaluation, based on Precision at rank 10 and Cluster Recall at rank 10, showed that participants were able to generate runs of high diversity and relevance. Findings show that submissions based on using mixed modalities performed best compared to those using only concept-based or content-based retrieval methods. The selection of query fields was also shown to affect retrieval performance. Submissions not using the cluster information performed worse with respect to diversity than those using this information. This paper summarises the ImageCLEFPhoto task for 2009.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The ImageCLEFPhoto task is part of the CLEF evaluation campaign, the focus for the past two years being promoting diversity within image retrieval. The task originally began in 2003 and has since attracted participants from many institutions worldwide. For the past three years, ImageCLEFPhoto has used a dataset of 20,000 general photos called the IAPR TC-12 Benchmark. In 2008, we adapted this collection to enable the evaluation of diversity in image retrieval results. We recognised that this setup had limitations and therefore moved to using a larger and more realistic collection of photos (and associated search query logs) from Belga<ref type="foot" coords="1,453.24,530.89,3.24,5.78" target="#foot_0">1</ref> , a Belgian press agency. Even though photos in this collection have English-only annotations and hence provide little challenge to cross-language information retrieval systems, there are other characteristics of the dataset which provide new challenges to participating groups (explained in Section 1.1). The resources created for the 2009 task have given us the opportunity to study diversity for image retrieval in more depth.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Evaluation Scenario</head><p>Given a set of information needs (topics), participants were tasked with finding not only relevant images, but also generating ranked lists that promote diversity. To make the task harder, we released two types of queries: the first type of query included written information about the specific requirement for diversity (represented as clusters); queries of the second type contained a more conventional title and example relevant images. In the former type of query participants were required to retrieve diverse results with some indication of what types of clusters were being sought; in the latter type of query little evidence was given for what kind of diversity was required. Evaluation gave more credence to runs that presented diverse results without sacrificing precision than those exhibiting less diversity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Evaluation Objectives for 2009</head><p>The Photo Retrieval task in 2009 was focused at studying diversity further. Using resources from Belga, we provided a much larger collection, containing just under half a million images, compared to 20,000 images provided in 2008. We also obtained statistics on popular queries submitted to the Belga website in 2008 <ref type="bibr" coords="2,510.24,115.17,10.69,8.88" target="#b0">[1]</ref>, which we exploited to create representative queries for this diversity task. We experimented with different ways of specifying the need for diversity which was given to participants, and this year decided to release half of the queries without any indication of diversity required or expected. We were interested in addressing the following research questions:</p><p>• Can results be diverse without sacrificing relevance?</p><p>• How much will knowing about query clusters a priori help increase diversity in image search results?</p><p>• Which approaches should be used to maximize diversity and relevance for image search results?</p><p>These research questions will be discussed further in section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Evaluation Framework</head><p>One of the major challenges for participants of the 2009 ImageCLEFPhoto task was a new collection which was 25 times larger than that used for 2008. Query creation was based completely on query log data, which helped to make the retrieval scenario as realistic as possible <ref type="bibr" coords="2,276.14,301.39,10.69,8.88" target="#b1">[2]</ref>. We believe this new collection will provide a framework in which to conduct a more thorough analysis of diversity in image retrieval.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Document Collection</head><p>The collection consists of 498,920 images with English-only annotations (i.e. captions) describing the content of the image. However, different to the structured annotations of 2008, the annotations in this collection are presented in an unstructured way (Table <ref type="table" coords="2,253.84,376.27,3.59,8.88" target="#tab_0">1</ref>). This increases the challenge for participants as they must automatically extract information about the location, date, photographic source, etc of the image as a part of the indexing and retrieval process. The photos cover a wide-ranging time period, and there are many cases where pictures have not been orientated correctly, thereby increasing the challenge for content-based retrieval methods.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Query Topics</head><p>Based on search query logs from Belga, 50 example topics were generated and released as two query types (as mentioned previously). From this set, we randomly chose 25 queries to be released with information including the title, cluster title, cluster description and image (example) as shown in Table <ref type="table" coords="2,400.59,637.12,3.76,8.88">2</ref>. We refer to these queries as Query Part 1. In this example, participants can notice that this result about 'Clinton' requires 3 different clusters, which are 'Hillary Clinton', 'Obama Clinton' and 'Bill Clinton'. Results covering other aspects of "Clinton", such as Chelsea Clinton or Clinton Cards, will not be counted towards the final diversity score. More information about these clusters and the method used to produce them can be found in <ref type="bibr" coords="2,418.34,683.20,10.69,8.88" target="#b1">[2]</ref>.</p><p>Given that one might argue that the diversity result in Query Part 1 could be relatively easy to produce as detailed information about the different sub-topics is provided as part of the query topic and there are often in practice instances when little or no query log information is available to indicate possible clusters, we released 25 queries containing no information about the kind of diversity expected (referred to as Query Part 2). An example of this query type is given in Table <ref type="table" coords="3,257.68,73.17,3.76,8.88">3</ref>. It should be noted that information about the cluster titles and description were also based on Belga's query logs. However, we did not release any of this information to the participants. The list of 50 topics used in this collection is given in Table <ref type="table" coords="3,318.02,471.90,3.77,8.88" target="#tab_2">4</ref>. Since Belga is a press agency based in Belgium, there are a large number of queries which contain the names of Belgian politicians, Belgian football clubs and members of the Belgian royal family. Other queries, however, are more general such as Beckham, Obama, etc. There are some queries which are very broad and under-specified (e.g. Belgium); others are highly ambiguous (e.g. Prince and Euro). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Relevance Assessments</head><p>Relevance assessments were performed using the DIRECT (Distributed Information Retrieval Evaluation Campaign Tool)<ref type="foot" coords="4,138.99,101.44,3.24,5.78" target="#foot_1">2</ref> , a system which enables assessors to work in a collaborative environment. We hired 25 assessors to be involved in this process and assessments were divided into 2 phases: in the first phase, assessors were asked to identify images relevant to a given query. Information about all relevant clusters to the topic was given to assessors to ensure they were aware of the scope of relevant images for a query. The number of relevant images for each query resulting from this stage is shown in Figure <ref type="figure" coords="4,338.05,149.72,3.76,8.88">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1. Number of relevant documents per query</head><p>Having queries from different types shown in Table <ref type="table" coords="4,288.14,461.22,3.76,8.88" target="#tab_2">4</ref>, we then analysed the number of relevant documents in each type. This data, shown in Table <ref type="table" coords="4,223.72,472.74,3.76,8.88" target="#tab_3">5</ref>, illustrates that under specified queries have the highest average number of relevant documents. After a set of relevant images were found, for the second stage different assessors were asked to find images relevant to each cluster (some images could belong to multiple clusters). Since topics varied widely in content and diversity, the number of relevant images varied from 1 to 1,266 for each cluster. Initially, there were 206 clusters created for the 50 queries, but this number dropped to 198 as there were 8 clusters with no relevant images which had to be deleted. There are an average number of 208.49 relevant documents for each cluster, with a standard deviation of 280.59. The distribution of clusters is shown in Figure <ref type="figure" coords="4,404.77,675.16,3.76,8.88" target="#fig_1">2</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Generating the Results</head><p>The method for generating results from participant's submissions was similar to that used in 2008 <ref type="bibr" coords="5,490.45,334.99,10.69,8.88" target="#b2">[3]</ref>. The precision of each run (P@10) was evaluated using trec_eval and cluster recall (CR@10) was used to measure diversity. Since the maximum number of clusters was set to 10 [2], we focussed evaluation on P@10 and CR@10. The F 1 score calculates the harmonic mean of these two measures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Overview of Participation and Submissions</head><p>A total of 44 different institutions registered for the ImageCLEFPhoto task (the highest number of applications ever received for this task). From this number, 19 institutions from 10 different countries finally submitted runs to the evaluation. Due to the large number of runs received last year, we limited the number of submitted runs to 5 per participant. A total of 84 runs were submitted and evaluated (some groups submitted less than 5 runs).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Overview of Submissions</head><p>The participating groups for 2009 are listed in Table <ref type="table" coords="5,291.86,486.66,3.76,8.88">8</ref>. From the 24 groups participating in the 2008 task, 15 groups returned and were involved this year (Returning). We also received four new participants who joined this task for the first time (New).</p><p>Participants were asked to specify the query fields used in their search and the modality of the runs. Query fields were described as T (Title), CT (Cluster Title), CD (Cluster Description) and I (Image). The modality was described as TXT (text-based search only), IMG (content-based image search only) or TXT-IMG (both text and content-based image search). The range of approaches is shown in Tables 6 and 7 and summarised in Figure <ref type="figure" coords="5,506.52,565.73,3.76,8.88">3</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Results</head><p>This section provides an overview of the results based on the type of queries and modalities used to generate the runs. As mentioned in the previous section, we used P@10 to calculate the fraction of relevant documents in the top 10 and CR@10 to evaluate diversity, which calculates the proportion of subtopics retrieved in the top 10 documents as shown below:</p><p>( )</p><formula xml:id="formula_0" coords="7,213.26,140.71,159.26,31.99">A K i i n d subtopics K at recall Cluster U 1 = ≡ -</formula><p>The F 1 score was used to calculate the harmonic mean of P@10 and CR@10, to enable the results to be sorted by one single measure: </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Results across all Queries</head><p>The top 10 runs computed across all 50 queries (ranked in descending order of F 1 score) are shown in Table <ref type="table" coords="7,504.73,277.87,3.76,8.88" target="#tab_7">9</ref>. Looking at the top 10 runs, we observe that highest effectiveness is reached using mixed modality (text and image) and using information from the query title, cluster title and the image content itself. The scores for P@10, CR@10 and F 1 in this year's task are notably higher than the evaluation last year. Moreover, the number of relevant images in this year's task was higher. Having two different types of queries, we analysed how participants dealt with the different queries. Tables <ref type="table" coords="7,276.98,516.17,10.02,8.88" target="#tab_8">10</ref> and<ref type="table" coords="7,306.50,516.17,9.90,8.88" target="#tab_9">11</ref> summarise the top 10 runs in each of query types. Different compared to results presented previously, it is interesting to see that the top run in Queries Part 1 used only text retrieval approaches. Even though the CR@10 score was lower than most of the runs, it obtained the highest F 1 score due to a high P@10 score. The uses of tags vary within results, but the top 9 runs consistently use both title and cluster title. We therefore conclude that the use of title and cluster title do help the participants to achieve a good score in both precision and cluster recall.</p><p>In the queries part two, participants did not have access to cluster information. We specifically intended this to see how well the system finds diverse results without any hints. The results of the top runs in queries part 2 is shown in Table <ref type="table" coords="8,135.15,129.21,8.38,8.88" target="#tab_9">11</ref>. It is shown in the table that the top 9 runs use information from example images, which shows that example images and their annotations might have given useful hints to detect diversity. To analyse this further, we divided the runs which used the Image field and those which did not, and found that the average CR@10 scores were 0.5571 and 0.5270 respectively. We conclude that having example images helps to identify diversity and present a more diverse set of results.</p><p>Comparing the CR@10 scores in the top 10 runs of Queries Part 1 and Queries Part 2, the scores in the latter group were lower, which implied that systems did not find as many diverse results when cluster information was not available. The F 1 scores from these top 10 were also lower, but they only differed slightly compared to the Queries Part 1. We also calculated the magnitude of difference between results for different query types (shown in Table <ref type="table" coords="8,108.28,451.26,7.90,8.88" target="#tab_10">12</ref>). This indicates that on average runs do perform lower in Query Part 2, however the difference is small and not sufficient to conclude that runs will be less diverse if cluster titles are not available (p=0.146). It is important to understand that not all the runs in Query Part 1 use the cluster title. To analyse how useful the "Cluster Title" (CT) information is, we divided the runs of Query Part 1 based on the use of CT field. The mean and standard deviation of P@10, CR@10 and the F 1 scores is shown in Table <ref type="table" coords="8,397.45,566.57,10.02,8.88" target="#tab_11">13</ref> (the highest score shown in italics). Table <ref type="table" coords="8,96.52,693.40,10.02,8.88" target="#tab_11">13</ref> provides more evidence that the Cluster Title field has an important role in identifying diversity. When Cluster Title is not being used, the F 1 scores of both Query Part 1 and Query Part 2 do not differ significantly. Figure <ref type="figure" coords="8,101.31,716.32,4.98,8.88">3</ref> shows a scatter plot of F 1 scores for each query type. Using a two-tailed paired t-test, the scores between Queries Part 1 and Queries Part 2 were found to be significantly different (p=0.02). There is also a significant correlation between the scores: the Pearson correlation coefficient equals 0.691.</p><p>We evaluated the same test on the runs using Cluster Title only to the runs in Query Part 2, and found that they are also significantly different (p=0.003), the Pearson correlation coefficient equals 0.745. However, when the same evaluation was being performed on runs not using Cluster Title, the difference in scores was not significant (p=0.053), although obtaining a Pearson correlation coefficient of 0.963. Table <ref type="table" coords="9,96.52,373.63,9.90,8.88" target="#tab_12">14</ref> summarises the results across all queries (mean scores). According to these results, highest scores from the three conditions are obtained when the query has full information about potential diversity. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="2,281.90,460.62,47.65,8.88;2,281.90,483.66,242.60,8.88;2,281.89,495.18,242.37,8.88;2,281.90,506.69,242.56,8.88;2,281.90,518.09,242.36,8.88;2,281.90,529.61,242.36,8.88;2,281.90,541.13,242.49,8.88;2,281.90,552.65,236.09,8.88"><head></head><label></label><figDesc>, BELGIUM: Lots of people pictured during a commemoration for the victims of the knife attack in Sint-Gilles, Dendermonde, Belgium, on Monday 26 January 2009. Last friday 20-Year old Kim De Gelder killed three people, one adult and two childs, in a knife attack at the children's day care center "Fabeltjesland" in Dendermonde. BELGA PHOTO BENOIT DOPPAGNE</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,207.86,299.64,179.41,8.03"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Distribution of clusters in the queries</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="9,168.51,357.36,258.12,8.94"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Scatter plot for F 1 scores of each run between query types</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="2,227.66,432.35,140.00,8.03"><head>Table 1 . Example image and caption</head><label>1</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="3,234.02,113.66,127.25,252.09"><head>Table 2 . Example of Query Part 1Table 3 . Example of Query Part 2</head><label>23</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="3,70.95,535.42,453.48,220.98"><head>Table 4 . Overall list of topics used in the 2009 task Query Part 1 Query Part 2</head><label>4</label><figDesc></figDesc><table coords="3,73.83,576.89,423.44,152.87"><row><cell>1</cell><cell>leterme</cell><cell>14 princess**</cell><cell>26 obama*</cell><cell>39 beckham*</cell></row><row><cell>2</cell><cell>fortis</cell><cell>15 monaco**</cell><cell>27 anderlecht</cell><cell>40 prince**</cell></row><row><cell>3</cell><cell>brussels**</cell><cell>16 queen**</cell><cell>28 mathilde</cell><cell>41 princess mathilde</cell></row><row><cell>4</cell><cell>belgium**</cell><cell>17 tom boonen</cell><cell>29 boonen</cell><cell>42 mika*</cell></row><row><cell>5</cell><cell>charleroi</cell><cell>18 bulgaria**</cell><cell>30 china**</cell><cell>43 ellen degeneres</cell></row><row><cell>6</cell><cell>vandeurzen</cell><cell>19 kim clijsters</cell><cell>31 hellebaut</cell><cell>44 henin</cell></row><row><cell>7</cell><cell>gevaert</cell><cell>20 standard</cell><cell>32 nadal</cell><cell>45 arsenal</cell></row><row><cell>8</cell><cell>koekelberg</cell><cell>21 princess maxima</cell><cell>33 snow**</cell><cell>46 tennis**</cell></row><row><cell>9</cell><cell>daerden</cell><cell>22 club brugge</cell><cell>34 spain**</cell><cell>47 ronaldo*</cell></row><row><cell cols="2">10 borlee*</cell><cell>23 royals**</cell><cell>35 strike**</cell><cell>48 king**</cell></row><row><cell cols="2">11 olympic**</cell><cell>24 paola*</cell><cell>36 euro*</cell><cell>49 madonna</cell></row><row><cell cols="2">12 clinton*</cell><cell>25 mary*</cell><cell>37 paris**</cell><cell>50 chelsea</cell></row><row><cell cols="2">13 martens*</cell><cell></cell><cell>38 rochus</cell><cell></cell></row></table><note coords="3,70.95,735.88,453.48,8.88;3,70.96,747.51,43.24,8.88"><p>* = ambiguous, ** = under-specified queries, bold queries: queries with more than 677 (median) relevant documents</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="4,74.07,505.78,439.81,97.39"><head>Table 5 . Number of relevant documents in each type All Queries Ambiguous Queries Under Specified Queries Other Queries Number of Queries</head><label>5</label><figDesc></figDesc><table coords="4,74.07,540.29,423.02,62.88"><row><cell></cell><cell>50</cell><cell>10</cell><cell>16</cell><cell>24</cell></row><row><cell>Average Doc</cell><cell>697.74</cell><cell>490</cell><cell>1050.19</cell><cell>549.33</cell></row><row><cell>Min</cell><cell>2</cell><cell>35</cell><cell>246</cell><cell>2</cell></row><row><cell>Max</cell><cell>2210</cell><cell>1052</cell><cell>2210</cell><cell>1563</cell></row><row><cell>Standard Dev</cell><cell>512.16</cell><cell>366.28</cell><cell>459.29</cell><cell>490.5</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="5,158.07,587.14,288.95,154.53"><head>Table 6 . Choice of query fields</head><label>6</label><figDesc></figDesc><table coords="5,158.07,611.62,288.95,130.06"><row><cell>Query Fields</cell><cell>Number of Runs</cell></row><row><cell>T</cell><cell>17</cell></row><row><cell>T-CT-CD-I</cell><cell>15</cell></row><row><cell>T-CT</cell><cell>15</cell></row><row><cell>T-CT-I</cell><cell>9</cell></row><row><cell>T-CT-CD</cell><cell>9</cell></row><row><cell>I</cell><cell>8</cell></row><row><cell>T-I</cell><cell>7</cell></row><row><cell>CT-I</cell><cell>2</cell></row><row><cell>CT</cell><cell>2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="6,91.59,73.22,388.90,259.89"><head>Table 7 . Modality of the runs</head><label>7</label><figDesc></figDesc><table coords="6,91.59,90.74,388.90,21.11"><row><cell>Modality</cell><cell>TXT-IMG</cell><cell>TXT</cell><cell>IMG</cell></row><row><cell>Number of Runs</cell><cell>36</cell><cell>41</cell><cell>7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="6,76.95,325.08,428.81,342.92"><head>Summary of query fields used in submitted runs Table 8. Participating groups</head><label></label><figDesc></figDesc><table coords="6,76.95,375.59,428.81,292.40"><row><cell cols="2">No Group ID</cell><cell>Institution</cell><cell>Country</cell><cell cols="2">Runs Status</cell></row><row><cell>1</cell><cell>Alicante</cell><cell>University of Alicante</cell><cell>Spain</cell><cell>5</cell><cell>Returning</cell></row><row><cell>2</cell><cell>Budapest-ACAD</cell><cell>Hungarian Academy of Science, Budapest</cell><cell>Hungary</cell><cell>5</cell><cell>Returning</cell></row><row><cell>3</cell><cell>Chemnitz</cell><cell>Computer Science, Trinity College, Dublin</cell><cell>Ireland</cell><cell>4</cell><cell>Returning</cell></row><row><cell>4</cell><cell>CLAC-Lab</cell><cell>Computational Linguistics at Concordia (CLAC)</cell><cell>Canada</cell><cell>4</cell><cell>Returning</cell></row><row><cell></cell><cell></cell><cell>Lab, Concordia University, Montreal</cell><cell></cell><cell></cell><cell></cell></row><row><cell>5</cell><cell>CWI</cell><cell>Interactive Information Access</cell><cell>Netherlands</cell><cell>5</cell><cell>New</cell></row><row><cell>6</cell><cell>Daedalus</cell><cell>Computer Science Faculty, Daedalus, Madrid</cell><cell>Spain</cell><cell>5</cell><cell>Returning</cell></row><row><cell>7</cell><cell>Glasgow</cell><cell>Multimedia IR, University of Glasgow</cell><cell>UK</cell><cell>5</cell><cell>Returning</cell></row><row><cell>8</cell><cell>Grenoble</cell><cell>Lab. Informatique Grenoble</cell><cell>France</cell><cell>4</cell><cell>Returning</cell></row><row><cell>9</cell><cell>INAOE</cell><cell>Language Tech</cell><cell>Mexico</cell><cell>5</cell><cell>Returning</cell></row><row><cell cols="2">10 InfoComm</cell><cell>Institution for InfoComm Research</cell><cell>Singapore</cell><cell>5</cell><cell>Returning</cell></row><row><cell cols="2">11 INRIA</cell><cell>LEAR Team</cell><cell>France</cell><cell>5</cell><cell>New</cell></row><row><cell cols="2">12 Jaen</cell><cell>Intelligent Systems, University of Jaen</cell><cell>Spain</cell><cell>4</cell><cell>Returning</cell></row><row><cell cols="2">13 Miracle-GSI</cell><cell>Intelligent System Group, Daedalus, Madrid</cell><cell>Spain</cell><cell>3</cell><cell>Returning</cell></row><row><cell cols="2">14 Ottawa</cell><cell>NLP, AI.I.Cuza U. of IASI</cell><cell>Canada</cell><cell>5</cell><cell>Returning</cell></row><row><cell cols="2">15 Southampton</cell><cell>Electronics and Computer Science, University of</cell><cell>UK</cell><cell>4</cell><cell>New</cell></row><row><cell></cell><cell></cell><cell>Southampton</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">16 UPMC-LIP6</cell><cell>Department of Computer Science, Laboratoire</cell><cell>France</cell><cell>5</cell><cell>Returning</cell></row><row><cell></cell><cell></cell><cell>d'Informatique de Paris 6</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">17 USTV-LSIS</cell><cell>System and Information Sciences Lab, France</cell><cell>France</cell><cell>2</cell><cell>Returning</cell></row><row><cell cols="2">18 Wroclaw</cell><cell>Wroclaw University of Technology</cell><cell>Poland</cell><cell>5</cell><cell>New</cell></row><row><cell cols="2">19 XEROX-SAS</cell><cell>XEROX Research</cell><cell>France</cell><cell>4</cell><cell>Returning</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7" coords="7,78.39,299.28,432.02,155.50"><head>Table 9 . Systems with highest F 1 score for all queries</head><label>9</label><figDesc></figDesc><table coords="7,78.39,317.04,432.02,137.74"><row><cell cols="2">No Group</cell><cell>Run Name</cell><cell>Query</cell><cell cols="2">Modality P@10</cell><cell>CR@10</cell><cell>F 1</cell></row><row><cell>1</cell><cell>XEROX-SAS</cell><cell>XRCEXKNND</cell><cell>T-CT-I</cell><cell>TXT-IMG</cell><cell>0.794</cell><cell>0.8239</cell><cell>0.8087</cell></row><row><cell>2</cell><cell>XEROX-SAS</cell><cell>XRCECLUST</cell><cell>T-CT-I</cell><cell>TXT-IMG</cell><cell>0.772</cell><cell>0.8177</cell><cell>0.7942</cell></row><row><cell>3</cell><cell>XEROX-SAS</cell><cell>KNND</cell><cell>T-CT-I</cell><cell>TXT-IMG</cell><cell>0.8</cell><cell>0.7273</cell><cell>0.7619</cell></row><row><cell>4</cell><cell>INRIA</cell><cell>LEAR5_TI_TXTIMG</cell><cell>T-I</cell><cell>TXT-IMG</cell><cell>0.798</cell><cell>0.7289</cell><cell>0.7619</cell></row><row><cell>5</cell><cell>INRIA</cell><cell>LEAR1_TI_TXTIMG</cell><cell>T-I</cell><cell>TXT-IMG</cell><cell>0.776</cell><cell>0.7409</cell><cell>0.7580</cell></row><row><cell>6</cell><cell>InfoComm</cell><cell>LRI2R_TI_TXT</cell><cell>T-I</cell><cell>TXT</cell><cell>0.848</cell><cell>0.6710</cell><cell>0.7492</cell></row><row><cell>7</cell><cell>XEROX-SAS</cell><cell>XRCE1</cell><cell>T-CT-I</cell><cell>TXT-IMG</cell><cell>0.78</cell><cell>0.7110</cell><cell>0.7439</cell></row><row><cell>8</cell><cell>INRIA</cell><cell>LEAR2_TI_TXTIMG</cell><cell>T-I</cell><cell>TXT-IMG</cell><cell>0.772</cell><cell>0.7055</cell><cell>0.7373</cell></row><row><cell>9</cell><cell>Southampton</cell><cell>SOTON2_T_CT_TXT</cell><cell>T-CT</cell><cell>TXT</cell><cell>0.824</cell><cell>0.6544</cell><cell>0.7294</cell></row><row><cell>10</cell><cell>Southampton</cell><cell>SOTON2_T_CT_TXT_IMG</cell><cell>T-CT</cell><cell>TXT-IMG</cell><cell>0.746</cell><cell>0.7095</cell><cell>0.7273</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="7,77.19,537.58,433.70,156.46"><head>Table 10 . Systems with highest F 1 score for Queries Part 1 No Group Run Name Query Modality P@10 CR@10 F 1</head><label>10</label><figDesc></figDesc><table coords="7,78.27,569.14,432.62,124.90"><row><cell>1</cell><cell>Southampton</cell><cell>SOTON2_T_CT_TXT</cell><cell>T-CT</cell><cell>TXT</cell><cell>0.868</cell><cell>0.7730</cell><cell>0.8178</cell></row><row><cell>2</cell><cell>Southampton</cell><cell>SOTON2_T_CT_TXT_IMG</cell><cell>T-CT</cell><cell>TXT-IMG</cell><cell>0.804</cell><cell>0.8063</cell><cell>0.8052</cell></row><row><cell>3</cell><cell>XEROX-SAS</cell><cell>KNND</cell><cell>T-CT-I</cell><cell>TXT-IMG</cell><cell>0.768</cell><cell>0.8289</cell><cell>0.7973</cell></row><row><cell>4</cell><cell>XEROX-SAS</cell><cell>XRCE1</cell><cell>T-CT-I</cell><cell>TXT-IMG</cell><cell>0.768</cell><cell>0.8289</cell><cell>0.7973</cell></row><row><cell>5</cell><cell>XEROX-SAS</cell><cell>XRCECLUST</cell><cell>T-CT-I</cell><cell>TXT-IMG</cell><cell>0.768</cell><cell>0.8289</cell><cell>0.7973</cell></row><row><cell>6</cell><cell>XEROX-SAS</cell><cell>XRCEXKNND</cell><cell>T-CT-I</cell><cell>TXT-IMG</cell><cell>0.768</cell><cell>0.8289</cell><cell>0.7973</cell></row><row><cell>7</cell><cell>Southampton</cell><cell>SOTON1_T_CT_TXT</cell><cell>T-CT</cell><cell>TXT</cell><cell>0.824</cell><cell>0.7470</cell><cell>0.7836</cell></row><row><cell>8</cell><cell>InfoComm</cell><cell>LRI2R_TCT_TXT</cell><cell>T-CT</cell><cell>TXT</cell><cell>0.828</cell><cell>0.7329</cell><cell>0.7776</cell></row><row><cell>9</cell><cell>Southampton</cell><cell>SOTON1_T_CT_TXT_IMG</cell><cell>T-CT</cell><cell>TXT-IMG</cell><cell>0.76</cell><cell>0.7933</cell><cell>0.7763</cell></row><row><cell cols="2">10 INRIA</cell><cell>LEAR1_TI_TXTIMG</cell><cell>T-I</cell><cell>TXT-IMG</cell><cell>0.772</cell><cell>0.7779</cell><cell>0.7749</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="8,70.95,150.73,439.34,172.98"><head>Table 11 . Systems with highest F 1 score for Queries Part 2</head><label>11</label><figDesc>submitted results for 24 out of 25 queries. Score shown is the average of the submitted queries only.</figDesc><table coords="8,76.35,168.49,433.94,136.54"><row><cell cols="2">No Group</cell><cell>Run Name</cell><cell>Query</cell><cell>Modality</cell><cell>P@10</cell><cell>CR@10</cell><cell>F 1</cell></row><row><cell>1</cell><cell>XEROX-SAS</cell><cell>XRCEXKNND</cell><cell>T-I</cell><cell>TXT-IMG</cell><cell>0.82</cell><cell>0.8189</cell><cell>0.8194</cell></row><row><cell>2</cell><cell>XEROX-SAS</cell><cell>XRCECLUST</cell><cell>T-I</cell><cell>TXT-IMG</cell><cell>0.776</cell><cell>0.8066</cell><cell>0.7910</cell></row><row><cell>3</cell><cell>InfoComm</cell><cell>LRI2R_TI_TXT</cell><cell>T-I</cell><cell>TXT</cell><cell>0.828</cell><cell>0.6901</cell><cell>0.7528</cell></row><row><cell>4</cell><cell>INRIA</cell><cell>LEAR5_TI_TXTIMG</cell><cell>T-I</cell><cell>TXT-IMG</cell><cell>0.756</cell><cell>0.7399</cell><cell>0.7479</cell></row><row><cell>5</cell><cell>INRIA</cell><cell>LEAR1_TI_TXTIMG</cell><cell>T-I</cell><cell>TXT-IMG</cell><cell>0.78</cell><cell>0.7039</cell><cell>0.7400</cell></row><row><cell>6</cell><cell>GRENOBLE</cell><cell>LIG3_TI_TXTIMG*</cell><cell>T-I</cell><cell>TXT-IMG</cell><cell>0.7708</cell><cell>0.6711</cell><cell>0.7175</cell></row><row><cell>7</cell><cell>XEROX-SAS</cell><cell>KNND</cell><cell>T-I</cell><cell>TXT-IMG</cell><cell>0.832</cell><cell>0.6257</cell><cell>0.7143</cell></row><row><cell>8</cell><cell>INRIA</cell><cell>LEAR2_TI_TXTIMG</cell><cell>T-I</cell><cell>TXT-IMG</cell><cell>0.728</cell><cell>0.6849</cell><cell>0.7058</cell></row><row><cell>9</cell><cell>GRENOBLE</cell><cell>LIG4_TCTITXTIMG</cell><cell>T-I</cell><cell>TXT-IMG</cell><cell>0.792</cell><cell>0.6268</cell><cell>0.6998</cell></row><row><cell cols="2">10 GLASGOW</cell><cell>GLASGOW4</cell><cell>T</cell><cell>TXT</cell><cell>0.76</cell><cell>0.6401</cell><cell>0.6949</cell></row></table><note coords="8,70.95,314.83,4.98,8.88"><p>*</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10" coords="8,138.39,484.31,318.51,42.46"><head>Table 12 . Cluster Recall score difference between Queries Part 1 and Queries Part 2</head><label>12</label><figDesc></figDesc><table coords="8,204.74,503.50,183.52,23.27"><row><cell>Mean</cell><cell>StDev</cell><cell>Max</cell><cell>Min</cell></row><row><cell>-0.0234</cell><cell>0.1454</cell><cell>0.2893</cell><cell>-0.6459</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11" coords="8,70.95,599.62,445.46,78.22"><head>Table 13 . Comparison of CR@10 scores</head><label>13</label><figDesc></figDesc><table coords="8,70.95,617.57,445.46,60.27"><row><cell>Queries</cell><cell>Number of Runs</cell><cell>Mean</cell><cell>P@10</cell><cell>SD</cell><cell cols="2">CR@10 Mean</cell><cell>SD</cell><cell>Mean</cell><cell>F 1</cell><cell>SD</cell></row><row><cell>Query part 1 with CT</cell><cell>52</cell><cell>0.6845</cell><cell></cell><cell>0.2</cell><cell>0.5939</cell><cell cols="2">0.1592</cell><cell>0.6249</cell><cell></cell><cell>0.1701</cell></row><row><cell>Query part 1 without CT</cell><cell>32</cell><cell>0.6641</cell><cell></cell><cell>0.2539</cell><cell>0.5006</cell><cell cols="2">0.1574</cell><cell>0.5581</cell><cell></cell><cell>0.1962</cell></row><row><cell>Query part 2</cell><cell>84</cell><cell>0.6315</cell><cell></cell><cell>0.2185</cell><cell>0.5415</cell><cell cols="2">0.1334</cell><cell>0.5693</cell><cell></cell><cell>0.1729</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12" coords="9,70.95,406.67,438.02,346.64"><head>Table 14 . Summary of results across all queries</head><label>14</label><figDesc></figDesc><table coords="9,70.95,424.62,438.02,60.15"><row><cell>Queries</cell><cell>Mean</cell><cell>P@10</cell><cell>SD</cell><cell>Mean</cell><cell>CR@10</cell><cell>SD</cell><cell>Mean</cell><cell>F 1</cell><cell>SD</cell></row><row><cell>All Queries</cell><cell>0.655</cell><cell></cell><cell>0.2088</cell><cell>0.5467</cell><cell></cell><cell>0.1368</cell><cell>0.5848</cell><cell></cell><cell>0.1659</cell></row><row><cell>Query Part 1</cell><cell>0.6768</cell><cell></cell><cell>0.2208</cell><cell>0.5583</cell><cell></cell><cell>0.1641</cell><cell>0.5995</cell><cell></cell><cell>0.1823</cell></row><row><cell>Query Part 2</cell><cell>0.6315</cell><cell></cell><cell>0.2185</cell><cell>0.5415</cell><cell></cell><cell>0.1334</cell><cell>0.5693</cell><cell></cell><cell>0.1729</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13" coords="9,216.99,745.28,198.04,8.03"><head>Scatter plot for mean CR@10 scores for each query</head><label></label><figDesc></figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,76.71,747.51,167.38,8.88"><p>Belga Press Agency: http://www.belga.be</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="4,75.51,749.29,75.81,7.17"><p>http://direct.dei.unipd.it</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>We would like to thank <rs type="institution">Belga Press Agency</rs> for providing us the collection and query logs and <rs type="person">Theodora Tsikrika</rs> for the preprocessed queries which we used as the basis for this research.</p><p>The work reported has been partially supported by the <rs type="funder">TrebleCLEF Coordination Action</rs>, within FP7 of the <rs type="funder">European Commission</rs>, Theme <rs type="grantNumber">ICT-1-4-1</rs> <rs type="projectName">Digital Libraries and Technology Enhanced Learning</rs> (Contract <rs type="grantNumber">215231</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_xkj9jnE">
					<idno type="grant-number">ICT-1-4-1</idno>
					<orgName type="project" subtype="full">Digital Libraries and Technology Enhanced Learning</orgName>
				</org>
				<org type="funding" xml:id="_bnH6GAu">
					<idno type="grant-number">215231</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We also analysed whether the number of clusters have any effect on the diversity score. To measure this factor, we calculated the mean CR@10 for all of the runs. These scores are then plotted based on the number of clusters contained in each specified query. This scatter plot, shown in Figure <ref type="figure" coords="10,354.01,96.09,3.76,8.88">5</ref>, has a Pearson correlation coefficient of -0.600, confirming that the more clusters a query contains, the lower the CR@10 score is.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Results by Retrieval Modality</head><p>In this section, we will present an overview result of runs using different modalities. According to Table <ref type="table" coords="10,155.32,263.35,8.38,8.88">15</ref>, both the precision and cluster recall scores are highest if systems use both low-level features based on the content of an image and its associated text. The mean of the runs using image content only (IMG) is drastically lower based on the P@10 score; however the gap decreases when considering only the CR@10 score. Further research should be carried out to improve runs using content-based approaches only, as the best run using this approach had the lowest F 1 score (0.218) compared to TXT (0.351) and TXT-IMG (0.297).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Approaches Used by Participants</head><p>Having known that the mixed modality performs best, we were also interested to see the best combination of query fields to maximize the F 1 score of the runs. We therefore calculated the mean of each combination and modality and the result is shown in Table <ref type="table" coords="10,238.84,384.42,9.90,8.88">16</ref> with the highest score for each modality shown in italic. It is interesting to note that the highest F 1 score was different for each modality. A combination of T-CT-I had the highest score in TXT-IMG modality. In the TXT modality, a combination of T-I scored the highest, with T-CT-I following on the second place. However, since only one run used the T-I, it was not enough to provide a conclusion about the best run. Calculating the average F 1 score regardless of diversity shows that the best runs are achieved using a combination of Title, Cluster Title and Image. Using all tags in the queries resulted in the worst performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusions</head><p>This paper has reported the ImageCLEF Photo Retrieval Task for 2009. Still focusing on the topic of diversity, this year's task introduced new challenges to the participants, mainly through the use of a much larger collection of images than used in previous years and by other tasks. Queries were released as two 'types': the first type of queries included information about the kind of diversity expected in the results; the second type of queries not providing this level of detail.</p><p>The number of registering participants in this year was the highest of all the ImageCLEFPhoto tasks since 2003. Nineteen participants submitted a total of 84 runs, which were then categorised based on the query fields used to find information, and the modalities being used. The result showed that participants were able to present a diverse result without sacrificing precision. In addition, results showed the following:</p><p>• Information about the cluster title is essential for providing diverse results, as this enables participants to correctly present images based on each cluster. When the cluster information was not being used, the cluster recall score is proven to drop, which showed that participants need better approach to predict the diversity need in it.</p><p>• A combination of Title, Cluster Title and Image was proven to maximize the diversity and relevance of the search engine.</p><p>• Using mixed modality (text and image) in the runs managed to achieve the highest F 1 compared to using only text or image features alone.</p><p>Considering the increasing interest of participants in ImageCLEFPhoto, the creation of the new collection was seen as a big achievement in providing a more realistic framework for the analysis of diversity and evaluation of retrieval systems aimed at promoting diverse results. The findings from this new collection were found to be promising and we plan to make use of other diversity algorithms in the future to enable evaluation to be done more thoroughly.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="11,88.95,439.62,247.99,8.88" xml:id="b0">
	<monogr>
		<title level="m" type="main" coord="11,163.47,439.62,148.36,8.88">Queries Submitted by Belga Users in</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Tsikrika</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2009. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,88.95,451.14,435.41,8.88;11,88.95,462.66,435.53,8.88;11,88.95,474.18,141.79,8.88" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="11,315.61,451.14,208.75,8.88;11,88.95,462.66,33.25,8.88">Developing a Test Collection to Support Diversity Analysis</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Paramita</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="11,130.23,462.66,369.24,8.88">SIGIR 2009 Workshop: Redundancy, Diversity, and Interdependent Document Relevance</title>
		<meeting><address><addrLine>Boston, Massachusetts, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-07-23">2009. July 23rd</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="11,88.95,485.70,435.51,8.88;11,88.95,497.22,261.43,8.88" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="11,355.21,485.70,169.26,8.88;11,88.95,497.22,112.47,8.88">Overview of the ImageCLEFPhoto 2008 Photographic Retrieval Task</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Arni</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Grubinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="11,208.36,497.22,137.17,8.88">Cross Language Evaluation Forum</title>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
