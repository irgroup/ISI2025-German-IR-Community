<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,121.27,148.86,360.46,15.15;1,203.55,170.78,195.90,15.15">Clustering for text and image-based photo retrieval at CLEF 2009</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,239.86,204.67,41.23,8.74"><forename type="first">Qian</forename><surname>Zhu</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Technology and Engineering</orgName>
								<orgName type="institution">University of Ottawa</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,303.78,204.67,59.36,8.74"><forename type="first">Diana</forename><surname>Inkpen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">School of Information Technology and Engineering</orgName>
								<orgName type="institution">University of Ottawa</orgName>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,121.27,148.86,360.46,15.15;1,203.55,170.78,195.90,15.15">Clustering for text and image-based photo retrieval at CLEF 2009</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">5852153D338126690CFF74E9F1CB6304</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software</term>
					<term>H.3.7 Digital Libraries</term>
					<term>H.2.3 [Database Managment]: Languages-Query Languages Measurement, Performance, Experimentation Information retrieval, image retrieval, photographs, text retrieval, k-means clustering, SIFT, Lucene, FIRE</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>For this year's Image CLEF Photo Retrieval task, we have prepared 5 submission runs to help us assess the effectiveness of 1) image content-based retrieval, and 2) textbased retrieval. We investigate whether the clustering of results can increase diversity by returning as many different clusters of images in the results as possible. Our image system uses the FIRE engine to extract image features such as color, texture, and shape from a database consisting of more than half a million images. The text-retrieval backend uses Lucene to extract texts from image annotations, title, and cluster tags. Our results reveal that among the three image features, color yields the highest retrieval precision, followed by shape, then texture. A combination of color extraction with text retrieval has the potential to increase precision, but only to a certain extent. Clustering also improves diversity in one of our clustering runs.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The goal of this year's Image CLEF event is to promote the diversity of search results through presenting relevant images from as many clusters as possible. Such cluster may focus on the location where the image was taken, the subject matter, the event, the time, etc. Our database consists of an unprecedented 498,920 newspaper images, courtesy of the Belgium news agency, each containing a picture, a title, a short description of the image, and a time stamp. Handling a database of such size is already a feat on its own. Each of our 50 queries consists of up to 3 sample images (each having a description and a picture). We may use the text, the image, or both parts as query for the retrieval task. In addition, our queries are divided into two parts: part 1 (25 queries) provides the cluster titles for each query to help us cluster the results; part 2 does not provide any cluster hints. For more details about the task see <ref type="bibr" coords="1,380.27,742.11,9.96,8.74" target="#b0">[1]</ref>.</p><p>The University of Ottawa team has developed a system for text-based retrieval, and image content-based retrieval. In the sections that follow, we describe each system, compare their retrieval effectiveness, and investigate whether or not clustering helps increase the diversity of results. We have used the k-means clustering algorithm. Then we describe two ways to incorporate clusters into the resulting ranking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">System Description</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Text-based retrieval system</head><p>This system is running on the Lucene search engine that searches through a document collection based on the frequency of query terms in the document (tf-idf measure). In our system, the image annotations, titles, and tags are indexed. To further improve the search results, we undertook two additional steps: stemming and query expansion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1">Stemming</head><p>It has been shown that stemming can slightly improve retrieval scores. Stemming means removing the suffixes of words, such as -ly, -ing, -ed, -s, etc, which sometime maybe overlooked by the system. As a pre-processing step prior to building the index, we converted all words into their stemmed form by running the Porter Stemming algorithm <ref type="bibr" coords="2,347.15,351.01,9.96,8.74" target="#b1">[2]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2">Query Expansion</head><p>In addition to using the image title as our query, we also expanded the query using the terms that appear in the description section of the 3 sample images. This was used in last year's competition, and has been shown to work well <ref type="bibr" coords="2,244.91,419.20,9.96,8.74" target="#b2">[3]</ref>. However, when this method is used, we should keep in mind that not all terms are introduced to the query equally. Otherwise, irrelevant documents may appear in our ranking due to expanded irrelevant query terms. We therefore give each term some weight, as determined by the frequency of the term in the description tag of 3 sample images. The words that appeared many times will have a higher weight in the expanded query. The LucQE library <ref type="bibr" coords="2,122.59,478.98,10.52,8.74" target="#b3">[4]</ref> provides a good implementation of the weighted query expansion done using the Rocchio's method. This method produces the modified query m:</p><formula xml:id="formula_0" coords="2,246.27,522.26,109.56,28.89">q m = α q 0 + β 1 |D| dj inD d j</formula><p>where: q 0 is the original query vector (i.e., the image title); D is the set of known relevant documents (i.e., the description of sample images); d j is the frequency vector for a relevant document j in D. We used the following parameters from Rocchio's method: α = 1.0, β = 0.75.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Image content-based retrieval system</head><p>The wealth of image data provides us with an excellent opportunity to assess different image retrieval methods. The image database is the largest we have tested to date, and we shall see how our system performed under such a heavy load. Our system extracted 3 image features from each image: color, Tamura texture, and scale invariant feature transform (SIFT) <ref type="bibr" coords="2,422.53,691.09,9.96,8.74" target="#b4">[5]</ref>.</p><p>Of particular interest is the SIFT feature, which is a feature related to shapes. This local image feature extracts particular interest points from the image which are highly distinctive, relatively stable to scale, and invariable to rotations and minor changes in illumination and noises. Images are first applied a Gaussian-blur filter at different levels, producing successively blurred images.</p><p>The differences between the blurred images are calculated based on the Difference of Gaussians (DoG) technique. And from the extremes of DoG, local interest points are derived. We have found a front-end SIFT extraction tool (called extractsift) from the FIRE image retrieval package <ref type="bibr" coords="3,90.00,147.89,9.96,8.74" target="#b5">[6]</ref>. This extraction uses Andrea Vedaldi's implementation of the SIFT algorithm <ref type="bibr" coords="3,447.99,147.89,9.96,8.74" target="#b6">[7]</ref>.</p><p>Because feature extraction was a very lengthy process, some time-saving tricks were needed. In particular, the SIFT extraction takes 10 sec/image on an Athlon 64 3.0GHz dual-core system, which is simply too long. So we have reduced the size of all images by 50% to allow us to finish the tasks in reasonable time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">K-means clustering</head><p>To investigate the effect of clustering documents, we employed the k-means clustering algorithm on the documents retrieved from the query-expanded text retrieval system. The version of the algorithm we used can be found in <ref type="bibr" coords="3,255.81,265.89,9.96,8.74" target="#b7">[8]</ref>. Only the top 50 retrieved documents participate in clustering, because expanding this clustering range risks introducing irrelevant document to the top of the ranking. Additionally, the clustering is based on the 10 most frequent terms in each document, and the number of clusters (k) is chosen as 10, as well. This combination of settings have been shown to work best, because setting k too high may risk losing precision at the expense of cluster recall, while setting k too low improves precision at the expense of sacrificing cluster variety.</p><p>It is important to mention that clustered documents are re-inserted into the ranking in a way that increases the diversity of results. Two ways of doing this are proposed:</p><p>1) Cluster-by-cluster: Clusters are ranked in descending order by the average similarity score of documents in the cluster. Then, documents in the top scored cluster are all inserted to the ranking, followed by the next top score cluster, etc.</p><p>2) Interleaved: Again clusters are ranked in descending order. Differently from above, only one document from each cluster is inserted into the ranking at a time. When all clusters have contributed at least one document to the ranking, the method begins inserting the second document into the ranking. This is what we hope to be the better way.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Experimental Results</head><p>Table <ref type="table" coords="3,116.83,499.99,4.98,8.74">1</ref> lists the results of our 5 submitted runs on the 50 test queries. For each query, precision at depth R (where R=5, 10, 20, 30, 100), the mean average precision (MAP), and the cluster recall (CR) at different depths are reported.</p><p>Table <ref type="table" coords="3,122.06,547.78,4.46,8.77">1</ref>. Results of the five submitted runs. Modality indicates whether the retrieval is based on image features or texts. P stands for precision. MAP stands for mean average precision. For each image run, only one feature was investigated. CR means cluster diversity. The run Color was based on full-size images which had a maximum of 512px in either width or height. The runs Sift and Tamura were based on 50% reduced size images. For the two text-based runs, both runs involved k-means clustering (k=10). Clusters Interleaved used the interleaved way to insert clusters into the ranking, whereas Clusters NonInterleaved used the other way, as described previously. Stemming and query expansion were also applied to the text runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Run Name</head><p>Modality P@5 P@10 P@20 P@30 P@100 MAP Due to the limitation of 5 submission runs per participant, we were not able to try out the combination of text and image retrieval systems. But we anticipate that the combination run will generate improved scores, because of the following evidences. First, it is evident that content-based image retrieval alone cannot achieve good performance, because the precision values are simply too low. However, we notice that the precision at depth 5 is the highest for image retrieval, suggesting that perhaps these documents could be added to the text results to boost its performance.</p><p>Second, we often have the same text retrieval score for two or more retrieved documents, which makes ranking difficult. If the image retrieval score is combined with text retrieval using careful weighting, it becomes much easier to assign the ranking. Previous work shows that a weighting scheme of 85% text score + 15% image score raises the precision by about 0.03, comparing with text-only retrieval system <ref type="bibr" coords="4,204.74,354.28,9.96,8.74" target="#b2">[3]</ref>.</p><p>Among the 3 image features tested, color is the best feature, followed closely by SIFT, and then by the Tamura texture. The striking similarities between the precision of SIFT and Tamura runs seem to reflect a baseline performance that might resemble random retrieval. Alternatively, their low precision scores might be explained by the reduced sizes of image, which might have eliminated too many details needed for extractions.</p><p>Lastly, clustering of documents can tip the ranking to favor either precision (all documents of a cluster are located at top positions) or diversity (interleaving insertion of cluster documents). This is clearly seen in the Clusters Interleaved and Clusters NonInterleaved runs.</p></div>		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="4,110.48,504.69,402.52,8.74;4,110.48,516.65,321.28,8.74" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="4,283.32,504.69,229.68,8.74;4,110.48,516.65,77.55,8.74">Diversity in photo retrieval: overview of the Image-CLEF Photo task</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Paramita</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Sanderson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Clough</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,217.36,516.65,117.59,8.74">CLEF Working Notes 2009</title>
		<meeting><address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009">2009. 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,110.48,536.57,337.27,8.74" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="4,169.76,536.57,140.77,8.74">An algorithm for suffix stripping</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">F</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,318.01,536.57,36.55,8.74">Program</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="130" to="137" />
			<date type="published" when="1980">1980</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,110.48,556.50,402.52,8.74;4,110.48,568.45,287.45,8.74" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="4,332.90,556.50,180.10,8.74;4,110.48,568.45,26.71,8.74">Clustering for Photo Retrieval at Image CLEF</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Inkpen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Stogaitis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Deguire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Alzghool</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,166.52,568.45,117.59,8.74">CLEF Working Notes 2008</title>
		<meeting><address><addrLine>Aarhus, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,110.48,588.38,402.52,8.74;4,110.48,600.33,387.24,8.74" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="4,163.11,588.38,349.89,8.74;4,110.48,600.33,120.91,8.74">The application of fuzzy logic to the construction of the ranking function of information retrieval system</title>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Rubens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="4,239.36,600.33,187.81,8.74">Computer Modelling and New Technologies</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="20" to="27" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,110.48,620.26,402.52,8.74;4,110.48,632.21,254.26,8.74" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="4,153.73,620.26,232.60,8.74">Object recognition from local scale-invariant features</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Lowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,394.27,620.26,118.72,8.74;4,110.48,632.21,168.82,8.74">Proceedings of the International Conference on Computer Vision</title>
		<meeting>the International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="1999">1999</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="1150" to="1157" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="4,110.48,652.14,402.52,8.74;4,110.48,664.09,216.66,8.74" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="4,253.43,652.14,259.56,8.74;4,110.48,664.09,45.16,8.74">FIRE -Flexible Image Retrieval Engine</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Keysers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Ney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="4,163.48,664.09,73.38,8.74">CLEF Workshop</title>
		<imprint>
			<date type="published" when="2004">2004</date>
			<biblScope unit="volume">3491</biblScope>
			<biblScope unit="page" from="688" to="698" />
		</imprint>
	</monogr>
	<note>ImageCLEF 2004 Evaluation</note>
</biblStruct>

<biblStruct coords="4,110.48,684.02,402.52,8.74;4,110.48,695.97,52.42,8.74" xml:id="b6">
	<monogr>
		<title level="m" type="main" coord="4,157.88,684.02,257.65,8.74">An open implementation of the SIFT detector and descriptor</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Vedaldi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
		</imprint>
	</monogr>
	<note type="report_type">UCLA CSD technical report</note>
</biblStruct>

<biblStruct coords="4,110.48,715.90,402.52,8.74;4,110.48,727.85,375.78,8.74" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="4,174.06,715.90,266.05,8.74">K-means cluster analysis algorithm implementation in Java</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sivaraman</surname></persName>
		</author>
		<ptr target="http://www.codecodex.com/wiki/index.php?title=K-meansclusteranalysisalgorithm" />
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
