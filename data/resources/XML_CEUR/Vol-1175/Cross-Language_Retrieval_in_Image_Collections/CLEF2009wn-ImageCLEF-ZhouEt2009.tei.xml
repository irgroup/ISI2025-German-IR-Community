<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,122.64,148.63,357.84,15.51">The MedGIFT group at ImageCLEF 2009</title>
				<funder ref="#_CCcsKvP">
					<orgName type="full">European Union</orgName>
				</funder>
				<funder ref="#_AXqCH7b">
					<orgName type="full">Swiss National Science Foundation</orgName>
				</funder>
				<funder ref="#_YqdvkWk">
					<orgName type="full">unknown</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName coords="1,207.60,182.47,41.31,9.62"><forename type="first">Xin</forename><surname>Zhou</surname></persName>
							<email>xin.zhou@sim.hcuge.ch</email>
							<affiliation key="aff0">
								<orgName type="department">Medical Informatics</orgName>
								<orgName type="institution">Geneva University Hospitals and University of Geneva</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,259.44,182.47,46.21,9.62"><forename type="first">Ivan</forename><surname>Eggel</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">University of Applied Sciences Western Switzerland (HES-SO)</orgName>
								<address>
									<settlement>Sierre</settlement>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,316.08,182.47,68.12,9.62"><forename type="first">Henning</forename><surname>Müller</surname></persName>
						</author>
						<title level="a" type="main" coord="1,122.64,148.63,357.84,15.51">The MedGIFT group at ImageCLEF 2009</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">B091E9DBDFD66AADFA0185399037D761</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>Image Retrieval, image classification, medical imaging Image Retrieval, Image Classification, Medical Imaging</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>MedGIFT is a medical imaging research group of the Geneva University Hospitals and the University of Geneva, Switzerland. Since 2004, the medGIFT group has participated in the ImageCLEF benchmark each year, focusing mainly on the medical imaging tasks.</p><p>For the medical image retrieval task, two existing retrieval engines were used: the GNU Image Finding Tool (GIFT) as image retrieval engine and Apache Lucene as textual retrieval engine. To improve the retrieval performance, automatic query expansion was used. In total, 13 runs were submitted as well for the image-based topics and the case-based topics. The baseline setup used for the past five years already obtained the best result among all our visual submissions.</p><p>For the medical image annotation task, two approaches were tested. One approach is using GIFT for image retrieval and kNN (k-Nearest Neighbors) for the classification, which was already used for the past 5 years. The second approach used Scale-Invariant Feature Transform (SIFT) technology with a Support Vector Machine (SVM) classifier. Three runs were submitted in total, two with the GIFT-kNN-based approach and one using a combination of the SIFT-SVM-based approach and GIFT-kNN-based approach. For the medical image classification task, the GIFT-kNN-based approach gives stable results, although not in the quality of the best groups. The SIFT-SVMbased approach implementation did not achieve the expected better performance. We think that the SVM kernel may be a key factor that requires further optimization.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="612.0" lry="792.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>A medical retrieval task has been part of ImageCLEF<ref type="foot" coords="1,328.20,705.34,3.97,4.84" target="#foot_0">1</ref> since 2004 <ref type="bibr" coords="1,384.59,706.51,10.45,9.62" target="#b0">[1,</ref><ref type="bibr" coords="1,398.76,706.51,7.81,9.62" target="#b1">2,</ref><ref type="bibr" coords="1,410.16,706.51,7.81,9.62" target="#b4">5]</ref> (Image retrieval task at the Cross Language Evaluation Forum). The MedGIFT 2 research group has participated in all these competitions using the same technology as a baseline and trying to improve the performance of this baseline over time using simple modifications. The GIFT <ref type="foot" coords="2,382.20,122.50,3.97,4.84" target="#foot_2">3</ref> (GNU Image Finding Tool, <ref type="bibr" coords="2,90.00,135.55,10.83,9.62" target="#b5">[6]</ref>) has been the technology used for visual information retrieval. Visual runs using GIFT have also been made available to other participants of ImageCLEF who do not possess visual retrieval technology.</p><p>For textual retrieval the Lucene<ref type="foot" coords="2,245.64,170.26,3.97,4.84" target="#foot_3">4</ref> system was employed in 2009. The full text of the articles was indexed and the query texts were not treated for the retrieval at all but used as they were given.</p><p>More information concerning the setup and the collections of the medical retrieval task of 2009 can be red in <ref type="bibr" coords="2,152.05,219.31,10.00,9.62" target="#b3">[4]</ref>. The following sections describe first the retrieval tools used, and then present the results in comparison with the best techniques of the ImageCLEF benchmark.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Retrieval Tools Reused</head><p>This section describes the basic technologies used for retrieval. The modifications to the base technologies will be detailed in the results section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Text Retrieval Approach</head><p>The text retrieval approach used in 2009 is based on the Apache Lucene retrieval engine. No specific terms such as MeSH (Medical Subject Headings) were used. Only one textual run was submitted. Five mixed visual/textual runs were submitted combining the textual retrieval with visual retrieval in various ways. The texts were indexed entirely from the html which contains the articles used by ImageCLEFmed task, removing all links and metadata keeping only the text. The query text was not modified, either.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Visual Retrieval Techniques</head><p>GIFT has been used for the visual retrieval for the past five years. This tool is open source and can be used by other participants of ImageCLEF as well. The goal of using the standard GIFT is also to provide a baseline to facilitate the evaluation of other techniques. GIFT uses a simple partitioning of the image into fixed regions to obtain local features.</p><p>The performance obtained by GIFT remained limited over the past years. Various strategies were applied in order to improve the results. Aspect-ratio was integrated as feature and simple query expansion with the most similar images was added for the retrieval task <ref type="bibr" coords="2,435.60,521.83,10.00,9.62" target="#b2">[3]</ref>. For the annotation task a technique to treat the annotation axes of the multi-axial IRMA (Image Retrieval in Medical Applications) code of the images separately was employed <ref type="bibr" coords="2,407.05,545.71,9.91,9.62" target="#b7">[7]</ref>, and also a dynamic kNN approach for classification <ref type="bibr" coords="2,231.50,557.71,9.91,9.62" target="#b8">[8]</ref>. The strategies used in ImageCLEFmed 2009 are detailed in Section 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Results</head><p>In this section the results and technical details for the two medical tasks of ImageCLEF 2009 are detailed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Medical Image Retrieval Task</head><p>All the runs submitted for evaluation are based on visual retrieval using GIFT with 8 gray levels as this had consistently given best results in past years. Various strategies to improve the results were tried out. An simple improvement strategy is to separately query the images belonging to one topic as these images are quite often dissimilar. Then, the result can be combined in a late fusion. Another approach is to supply images of other topics as negative feedback assuming that this can create more discriminative queries.</p><p>The following steps were thus performed:</p><p>• for each topic, the similarities between all query image pairs were calculated;</p><p>• based on the similarity between the images pairs, queries are treated either as a query of multiple images or as several separate queries;</p><p>• for each topic, a random selection of 2 images from other topics were added as negative feedback;</p><p>In total, 16 automatic runs were submitted. 10 runs were submitted for the image-based retrieval topics and 6 for the case-based topics. These runs can be divided into 2 textual, 10 visual, and 4 mixed runs. Run identifiers are composed of the strategies applied to the run. The following list explains the labels and their meaning.</p><p>• txt : textual;</p><p>• vis: visual;</p><p>• mix : mixed;</p><p>• sep: separate queries for the various images of a topic;</p><p>• withAR: aspect ratio added as feature;</p><p>• withNegImg: query expansion with negative examples of other topics;</p><p>• sum: simple sum to combine scores of several queries;</p><p>• max : maximum score of an image is taken to combine several queries;</p><p>• 0.x for mixed runs, 0.x is the weight for the visual retrieval and (1-0.x) for the textual retrieval;</p><p>• EN the language used for textual retrieval is English;</p><p>• BySim For the case-based topics the similarity score of images appearing in the case is used;</p><p>• ByFreq For the case-based topics the frequency of images of a case in the first 1000 results is used.</p><p>Results for the medical retrieval task are shown in two parts. The results of 25 image-based topics are shown in Table <ref type="table" coords="3,173.29,569.95,4.98,9.62" target="#tab_0">1</ref> and those of the case-based topics (topics 26-30) are shown in Table <ref type="table" coords="3,477.01,569.95,3.90,9.62" target="#tab_1">2</ref>. Mean average precision (MAP), binary preference (Bpref), and early precisions (P10, P30) were selected for our tables. The ImageCLEFmed 2009 retrieval task has an unbalanced number of visual, mixed, and textual runs. We submitted no manual or feedback runs at all.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.1">Image-Based Topics</head><p>As in past years, most of the submissions are textual or mixed and only few groups worked on improving the visual runs. Only 5 groups submitted a total of 15 visual runs. All our runs and the best runs in each category can be seen in Table <ref type="table" coords="3,320.17,673.99,4.98,9.62" target="#tab_0">1</ref> Our best visual run is the standard GIFT with 8 gray levels that was not submitted for the competition but has actually the best MAP. The other submitted runs give worse results but in general the performance of all runs is rather low with a MAP below 2%. Also the other measures such as early precision and number of relevant images found are much lower for the purely visual runs. None of the visual runs obtains extremely good results. A total of 52 textual runs were submitted. We only submitted a single textual run using an extremely simple strategy of Lucene with no pre-treatment of neither queries nor documents. The results looking at MAP are not as good as other approaches but early precision is fairly good and looking at the simplicity of the approach this is rather surprising. The performance is above the average of the textual runs.</p><p>In total, 25 mixed runs were submitted. We submitted three mixed runs that have a large variety of combination strategies. It can be seen that the combination strategy has a very strong influence on the results. Our best mixed run is slightly better in early precision than our text runs but worse in all other measures. In early precision our mixed run can rival the best runs submitted and reaches the second overall position.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2">Case-based topics</head><p>In Table <ref type="table" coords="4,128.52,643.63,3.90,9.62" target="#tab_1">2</ref>, all our runs for the case-based topics are shown and the best run of the competition for comparison. Again it can be seen that the pure text retrieval has by far the best results, despite the simplicity of our approach. Our mixed approach was worse in all categories. The purely visual runs have a fairly low MAP similar to the image-based topics and even the early precision was rather low.</p><p>In both the viaul and mixed categories our system perfromed best but this is also partly due to the low participation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Medical Image Annotation</head><p>For the medical image annotation task 6 groups submitted in total 18 runs. The medGIFT group submitted 3 runs. Two runs used the same strategy as in the past 2 years using GIFT as a basic retrieval technology, then adding aspect ratio to the similarity score. For classification the 5 nearest neighbors (5NN) was used. More details on the strategy can also be found in <ref type="bibr" coords="5,488.06,276.67,10.45,9.62" target="#b7">[7,</ref><ref type="bibr" coords="5,502.46,276.67,7.05,9.62" target="#b8">8]</ref>.</p><p>One run was submitted to test a SIFT-SVM based approach. The standard Gaussian kernel is used for the SVM classifier. Another run combined the results of the SVM run and a standard run. The results obtained by the three submitted runs are shown in Table <ref type="table" coords="5,426.25,312.43,3.90,9.62" target="#tab_2">3</ref>. The simple 5NN approach using GIFT with 8 grey levels gave consistently the best results over all tasks. The test of the SVM classifier did not reach the performance hoped for but much if this can be due to the lack of optimization performed on the level of the Kernel. The results of GIFT can not be seen as much more than a simple baseline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>Textual runs significantly out-performed visual runs, which was coherent with past experiences. Even using the basic Lucene with no pretreatment obtained fairly good results compared to the much more complex approaches of other groups. Since 2004 GIFT with 8 gray levels has been used as a baseline. Generally, the result obtained were below the average MAP of purely visual runs. The strategy to perform separate queries for each query image of a topic increased early precision but decreased MAP: Using aspect ration for the retrieval has a slight influence on early precision but is otherwise not better. Combinations of text and visual result can obtain a higher early precision. For the image annotation task a new SVM-based strategy was employed but did not increase results at all. The basic GIFT strategy still had our best results but not comparable with the results of the best groups. The combination of using GIFT features and SIFT did not improve results either. Using a small number of results for the combination does not seem appropriate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Conclusion</head><p>The paper summarized the participation of the medGIFT group in ImageCLEF2009. The medical image retrieval and medical image annotation tasks were addressed. Results show that textual retrieval techniques outperfrom visual techniques but that visual retrieval can be an addition to improve early precision of retrieval.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="4,96.00,118.63,414.15,199.94"><head>Table 1 :</head><label>1</label><figDesc>Results of the runs for the image-based retrieval topics.</figDesc><table coords="4,96.00,140.35,414.15,178.22"><row><cell>Run</cell><cell cols="2">run type MAP</cell><cell>Bpref</cell><cell>P10</cell><cell>P30</cell><cell>num rel ret</cell></row><row><cell>best textual</cell><cell cols="5">Textual 0.4293 0.4568 0.664 0.552</cell><cell>1814</cell></row><row><cell>HES-SO-VS txt EN</cell><cell cols="5">Textual 0.3179 0.3498 0.600 0.4987</cell><cell>1462</cell></row><row><cell>best visual run</cell><cell>Visual</cell><cell cols="4">0.0136 0.0363 0.072 0.0507</cell><cell>295</cell></row><row><cell>medGIFT vis GIFT8</cell><cell>Visual</cell><cell cols="4">0.0153 0.0347 0.068 0.0467</cell><cell>284</cell></row><row><cell>medGIFT vis sep max</cell><cell>Visual</cell><cell cols="4">0.0131 0.0276 0.076 0.056</cell><cell>266</cell></row><row><cell>medGIFT vis sep sum withAR</cell><cell>Visual</cell><cell cols="4">0.013 0.0303 0.072 0.052</cell><cell>262</cell></row><row><cell>medGIFT vis sep sum</cell><cell>Visual</cell><cell cols="4">0.0114 0.0282 0.052 0.0573</cell><cell>259</cell></row><row><cell>medGIFT vis sep max withAR</cell><cell>Visual</cell><cell cols="4">0.0102 0.0303 0.076 0.0547</cell><cell>253</cell></row><row><cell>medGIFT vis sum withNegImg</cell><cell>Visual</cell><cell cols="4">0.0098 0.028 0.044 0.053</cell><cell>210</cell></row><row><cell>medGIFT vis max withNegImg</cell><cell>Visual</cell><cell cols="4">0.0079 0.0248 0.044 0.044</cell><cell>201</cell></row><row><cell>best mixed run</cell><cell>Mixed</cell><cell cols="4">0.3682 0.386 0.544 0.4827</cell><cell>1754</cell></row><row><cell>medGIFT mix 0.3withNegImg EN</cell><cell>Mixed</cell><cell>0.29</cell><cell cols="3">0.3216 0.604 0.516</cell><cell>1176</cell></row><row><cell>medGIFT mix 0.5 EN</cell><cell>Mixed</cell><cell cols="4">0.2097 0.2456 0.592 0.4293</cell><cell>848</cell></row><row><cell>medGIFT mix 0.5withNegImg EN</cell><cell>Mixed</cell><cell cols="4">0.1354 0.1691 0.488 0.3267</cell><cell>547</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,96.96,351.67,409.11,105.86"><head>Table 2 :</head><label>2</label><figDesc>Results of the runs for the case-based retrieval topics.</figDesc><table coords="4,96.96,363.43,409.11,94.10"><row><cell>Run</cell><cell cols="2">run type MAP</cell><cell cols="2">Bpref P10</cell><cell>P30</cell><cell>num rel ret</cell></row><row><cell>best run</cell><cell cols="5">Textual 0.3355 0.2766 0.34 0.2267</cell><cell>74</cell></row><row><cell>HES-SO-VS txt case</cell><cell cols="4">Textual 0.1906 0.1531 0.32</cell><cell>0.2</cell><cell>71</cell></row><row><cell>medGIFT mix 0.5BySim EN</cell><cell>Mixed</cell><cell cols="4">0.0655 0.0488 0.14 0.0867</cell><cell>74</cell></row><row><cell>medGIFT vis maxBySim withAR</cell><cell>Visual</cell><cell>0.021</cell><cell cols="3">0.029 0.04 0.0533</cell><cell>41</cell></row><row><cell>medGIFT vis sumBySim withAR</cell><cell>Visual</cell><cell>0.019</cell><cell cols="3">0.026 0.06 0.0533</cell><cell>42</cell></row><row><cell>medGIFT vis maxByFreq withAR</cell><cell>Visual</cell><cell cols="2">0.0025 0.0035</cell><cell>0</cell><cell>0.0067</cell><cell>26</cell></row><row><cell>medGIFT vis sumByFreq withAR</cell><cell>Visual</cell><cell cols="2">0.0025 0.0035</cell><cell>0</cell><cell>0.0067</cell><cell>26</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,130.20,118.63,342.93,69.50"><head>Table 3 :</head><label>3</label><figDesc>Results of the runs submitted to the medical image annotation task.</figDesc><table coords="5,130.20,130.27,342.93,57.86"><row><cell>run ID</cell><cell cols="2">2005 2006</cell><cell>2007</cell><cell>2008</cell><cell>SUM</cell></row><row><cell>best system</cell><cell>356</cell><cell>263</cell><cell>64.3</cell><cell>169.5</cell><cell>852.8</cell></row><row><cell cols="2">GE GIFT8 AR0.2 vdca5 th0.5.run 618</cell><cell>507</cell><cell cols="3">190.73 317.53 1633.26</cell></row><row><cell cols="2">GE GIFT16 AR0.1 vdca5 th0.5.run 641</cell><cell>527</cell><cell cols="3">210.93 380.41 1759.34</cell></row><row><cell>GE GIFT8 SIFT commun.run</cell><cell cols="5">791.5 612.5 272.69 420.91 2097.6</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="1,105.24,737.39,105.10,7.35"><p>http://www.imageclef.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="1,105.24,746.87,134.73,7.35"><p>http://www.sim.hcuge.ch/medgift/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="2,105.24,737.39,138.93,7.35"><p>http://www.gnu.org/software/gift/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="2,105.24,746.87,105.10,7.35"><p>http://lucene.apache.org/</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This study was partially supported by the <rs type="funder">Swiss National Science Foundation</rs> (Grant <rs type="grantNumber">200020-118638/1</rs>), the <rs type="projectName">HES SO</rs> with the <rs type="projectName">BeMeVIS</rs> project, and the <rs type="funder">European Union</rs> in the <rs type="programName">6th Framework Program</rs> through the <rs type="projectName">KnowARC project</rs> (Grant <rs type="grantNumber">IST 032691</rs>).</p></div>
			</div>
			<listOrg type="funding">
				<org type="funded-project" xml:id="_AXqCH7b">
					<idno type="grant-number">200020-118638/1</idno>
					<orgName type="project" subtype="full">HES SO</orgName>
				</org>
				<org type="funded-project" xml:id="_CCcsKvP">
					<orgName type="project" subtype="full">BeMeVIS</orgName>
					<orgName type="program" subtype="full">6th Framework Program</orgName>
				</org>
				<org type="funded-project" xml:id="_YqdvkWk">
					<idno type="grant-number">IST 032691</idno>
					<orgName type="project" subtype="full">KnowARC project</orgName>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="6,105.48,133.51,407.56,9.62;6,105.48,145.51,407.54,9.62;6,105.48,157.39,407.54,9.62;6,105.48,169.39,140.41,9.62" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="6,263.77,145.51,231.13,9.62">The CLEF 2005 cross-language image retrieval track</title>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Michael</forename><surname>Grubinger</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thomas</forename><forename type="middle">M</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jeffery</forename><surname>Jensen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,105.48,157.39,181.60,9.62">Cross Language Evaluation Forum (CLEF</title>
		<title level="s" coord="6,319.92,157.39,188.81,9.62">Springer Lecture Notes in Computer Science</title>
		<imprint>
			<date type="published" when="2005-09">2005. September 2006</date>
			<biblScope unit="page" from="535" to="557" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.48,189.31,407.59,9.62;6,105.48,201.31,407.57,9.62;6,105.48,213.19,407.44,9.62;6,105.48,225.19,407.49,9.62;6,105.48,237.07,366.04,9.62" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="6,349.40,189.31,163.67,9.62;6,105.48,201.31,139.91,9.62">The CLEF cross-language image retrieval track (ImageCLEF) 2004</title>
		<author>
			<persName coords=""><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Mark</forename><surname>Sanderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,354.60,213.19,158.32,9.62;6,105.48,225.19,311.57,9.62">Multilingual Information Access for Text, Speech and Images: Result of the fifth CLEF evaluation campaign</title>
		<title level="s" coord="6,495.00,225.19,17.96,9.62;6,105.48,237.07,169.59,9.62">Lecture Notes in Computer Science (LNCS</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Gareth</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Bernardo</forename><surname>Kluck</surname></persName>
		</editor>
		<editor>
			<persName><surname>Magnini</surname></persName>
		</editor>
		<meeting><address><addrLine>Bath, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2005">2005</date>
			<biblScope unit="volume">3491</biblScope>
			<biblScope unit="page" from="597" to="613" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.48,257.11,407.60,9.62;6,105.48,268.99,407.29,9.62;6,105.48,280.99,159.87,9.62" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="6,348.72,257.11,164.37,9.62;6,105.48,268.99,136.43,9.62">Learning a frequency-based weighting for medical image classification</title>
		<author>
			<persName coords=""><forename type="first">Tobias</forename><surname>Gass</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Antoine</forename><surname>Geissbuhler</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,264.96,268.99,182.79,9.62">Medical Imaging and Medical Informatics</title>
		<meeting><address><addrLine>MIMI; Beijing, China</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007">2007. 2007</date>
			<biblScope unit="page" from="137" to="147" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.48,300.91,407.56,9.62;6,105.48,312.79,407.62,9.62;6,105.48,324.79,407.54,9.62;6,105.48,336.79,107.76,9.62" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="6,353.57,312.79,159.53,9.62;6,105.48,324.79,56.08,9.62">Overview of the 2009 medical image retrieval task</title>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jayashree</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Ivan</forename><surname>Eggers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steven</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Radhouani</forename><surname>Said</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Brian</forename><surname>Bakke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Charles</forename><forename type="middle">E</forename><surname>Kahn</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,183.84,324.79,293.03,9.62">Working Notes of CLEF 2009 (Cross Language Evaluation Forum)</title>
		<meeting><address><addrLine>Corfu, Greece</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-09">September 2009</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.48,356.71,407.57,9.62;6,105.48,368.59,407.65,9.62;6,105.48,380.59,407.48,9.62;6,105.48,392.59,407.37,9.62;6,105.48,404.47,407.53,9.62;6,105.48,416.47,407.54,9.62;6,105.48,428.35,125.54,9.62" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="6,237.86,368.59,275.26,9.62;6,105.48,380.59,16.71,9.62">Overview of the ImageCLEFmed 2008 medical image retrieval task</title>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Jayashree</forename><surname>Kalpathy-Cramer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Charles</forename><forename type="middle">E</forename><surname>Kahn</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Hatt</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Steven</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">William</forename><surname>Hersh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,490.44,392.59,22.41,9.62;6,105.48,404.47,407.53,9.62;6,105.48,416.47,150.07,9.62">Evaluating Systems for Multilingual and Multimodal Information Access -9th Workshop of the Cross-Language Evaluation Forum</title>
		<title level="s" coord="6,265.32,416.47,157.35,9.62">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">Carol</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Danilo</forename><surname>Giampiccolo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Vivien</forename><surname>Petras</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Julio</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Anselmo</forename><surname>Peñas</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thomas</forename><surname>Deselaers</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Thomas</forename><surname>Mandl</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Gareth</forename><surname>Jones</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Mikko</forename><surname>Kurimo</surname></persName>
		</editor>
		<meeting><address><addrLine>Aarhus, Denmark</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009-09">September 2009 -</date>
		</imprint>
	</monogr>
	<note>to appear</note>
</biblStruct>

<biblStruct coords="6,105.48,448.39,407.66,9.62;6,105.48,460.27,407.56,9.62;6,105.48,472.27,408.07,9.62;6,105.48,484.15,48.97,9.62" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="6,421.83,448.39,91.31,9.62;6,105.48,460.27,231.13,9.62">Content-based query of image databases: inspirations from text retrieval</title>
		<author>
			<persName coords=""><forename type="first">David</forename><surname>Mcg</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Wolfgang</forename><surname>Squire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Thierry</forename><surname>Müller</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Pun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,479.28,460.27,33.75,9.62;6,105.48,472.27,330.46,9.62">Selected Papers from The 11th Scandinavian Conference on Image Analysis SCIA &apos;99)</title>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1193" to="1198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,158.64,484.15,137.93,9.62" xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">K</forename><surname>Ersboll</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Johansen</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.48,504.07,407.47,9.62;6,105.48,516.07,407.65,9.62;6,105.48,528.07,104.30,9.62" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="6,370.27,504.07,142.68,9.62;6,105.48,516.07,260.17,9.62">Hierarchical classification using a frequency-based weighting and simple visual features</title>
		<author>
			<persName coords=""><forename type="first">Xin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Adrien</forename><surname>Depeursinge</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="6,384.36,516.07,124.69,9.62">Pattern Recognition Letters</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">15</biblScope>
			<biblScope unit="page" from="2011" to="2017" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="6,105.48,547.99,407.55,9.62;6,105.48,559.87,407.70,9.62;6,105.48,571.87,97.72,9.62" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="6,326.24,547.99,165.16,9.62">The medgift group at imageclef 2008</title>
		<author>
			<persName coords=""><forename type="first">Xin</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Julien</forename><surname>Gobeill</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Henning</forename><surname>Müller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="6,105.48,559.87,101.49,9.62">CLEF 2008 Proceedings</title>
		<title level="s" coord="6,214.44,559.87,182.32,9.62">Lecture Notes in Computer Science (LNCS</title>
		<meeting><address><addrLine>Aarhus, Denmark</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009 -submitted</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
