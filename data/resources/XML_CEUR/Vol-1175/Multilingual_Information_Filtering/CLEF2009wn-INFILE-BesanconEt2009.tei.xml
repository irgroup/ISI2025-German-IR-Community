<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,148.50,69.36,298.48,19.93">Overview of CLEF 2009 INFILE track</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,144.80,104.31,88.80,13.28"><forename type="first">Romaric</forename><surname>Besançon</surname></persName>
							<email>romaric.besancon@cea.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">CEA LIST</orgName>
								<address>
									<addrLine>18, route du panorama BP 6</addrLine>
									<postCode>92265</postCode>
									<settlement>Fontenay aux Roses</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Université de Lille</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,247.72,104.31,96.21,13.28"><forename type="first">Stéphane</forename><surname>Chaudiron</surname></persName>
							<email>stephane.chaudiron@univ-lille3.fr</email>
						</author>
						<author>
							<persName coords="1,363.43,104.31,81.88,13.28"><forename type="first">Djamel</forename><surname>Mostefa+</surname></persName>
							<email>mostefa@elda.org</email>
						</author>
						<author>
							<persName coords="1,174.80,119.41,66.88,13.28"><forename type="first">Ismaïl</forename><surname>Timimi</surname></persName>
							<email>ismail.timimi@univ-lille3.fr</email>
						</author>
						<author>
							<persName coords="1,261.81,119.41,79.25,13.28"><forename type="first">Khalid</forename><surname>Choukri+</surname></persName>
							<email>choukri@elda.org</email>
						</author>
						<author>
							<persName coords="1,349.52,119.41,68.63,13.28"><forename type="first">Meriama</forename><surname>Laïb</surname></persName>
							<email>meriama.laib@cea.fr</email>
							<affiliation key="aff0">
								<orgName type="institution">CEA LIST</orgName>
								<address>
									<addrLine>18, route du panorama BP 6</addrLine>
									<postCode>92265</postCode>
									<settlement>Fontenay aux Roses</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Université de Lille</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">GERiiCO Domaine univ</orgName>
								<address>
									<addrLine>du Pont de Bois 55-57, +ELDA rue Brillat Savarin</addrLine>
									<postCode>60149 -59653, 75013</postCode>
									<settlement>BP, Villeneuve d&apos;Ascq cedex, Paris</settlement>
									<country>France, France</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,148.50,69.36,298.48,19.93">Overview of CLEF 2009 INFILE track</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="MD5">F9049F7AA3B34BE6E6C89B59EC3C50BB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T15:21+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>H.3 [Information Storage and Retrieval]: H.3.1 Content Analysis and Indexing</term>
					<term>H.3.3 Information Search and Retrieval</term>
					<term>H.3.4 Systems and Software Measurement, Performance, Experimentation, Algorithms Information Filtering, Competitive Intelligence num, title, desc, narr, keywords, sample DateID, NewsItemID, Slugline, Headline, DataContent, Country, City, FileName num, title, desc, narr, keywords, sample DateID, NewsItemID, Slugline, Headline, DataContent, Country, City, FileName num, title, desc, narr, keywords, sample DateID, NewsItemID, Slugline, Headline, DataContent, Country, City, FileName num, title, desc, narr, keywords, sample</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The INFILE@CLEF 2009 track is the second run of this track on the evaluation of cross-language adaptive filtering systems. It uses the same corpus as the 2008 track, composed of 300,000 newswires from Agence France Presse (AFP) in three languages: Arabic, English and French, and a set of 50 topics in general and specific domain (scientific and technological information). We proposed this year two tasks : a batch filtering task and an interactive task to test adaptive methods. Results for the two tasks are presented in this paper.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.0" lry="842.0"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The purpose of the INFILE (INformation FILtering Evaluation) track is to evaluate cross-language adaptive filtering systems, i.e. the ability of automated systems to successfully separate relevant and non-relevant documents in an incoming stream of textual information with respect to a given profile, the document and profile being possibly written in different languages. The INFILE track has first been run as a pilot track in CLEF 2008 campaign <ref type="bibr" coords="1,427.10,634.81,105.75,13.28">[Besançon et al, 2008]</ref>. Due to some delays in the organization, the participation in the 2008 was weak (only one participant submitted results), so we decided to propose to rerun the campaign in 2009, using the same document collection and topics. The INFILE project is funded by the French National Research Agency and co-organized by the CEA LIST, ELDA and the University of Lille3-GERiiCO. Information filtering in the INFILE track is considered in the context of competitive intelligence: in this context, the evaluation protocol of the campaign has been designed with a particular attention to the context of use of filtering systems by real professional users. Even if the campaign is mainly a technological oriented evaluation process, we adapted the protocol and the metrics, as close as possible, to how a normal user would proceed, including through some interaction and adaptation of his system. The INFILE campaign can mainly be seen as a cross-lingual pursuit of the TREC 2002 Adaptive Filtering task <ref type="bibr" coords="2,125.80,102.71,156.79,13.28" target="#b8">[Robertson and Soboroff, 2002]</ref> (adaptive filtering track has been run from 2000 to 2002), with a particular interest in the correspondence of the protocol with the ground truth of competitive intelligence (CI) professionals. In this goal, we asked CI professionals to write the topics according to their experience in the domain. Other related campaigns are the Topic Detection and Tracking (TDT) campaigns from 1998 to 2004 <ref type="bibr" coords="2,56.80,178.41,140.44,13.28" target="#b3">[Fiscus and Wheatley, 2004]</ref>, but in the TDT campaigns, focus was mainly on topics defined as "events", with a fine granularity level, and often temporally restricted, whereas in <ref type="bibr" coords="2,459.21,193.61,78.89,13.28;2,56.80,208.71,76.91,13.28">INFILE (similar to TREC 2002)</ref>, topics are of long-term interest and supposed to be stable, which can induce different techniques, even if some studies show that some models can be efficiently trained to have good performance on both tasks <ref type="bibr" coords="2,213.80,239.01,88.13,13.28" target="#b16">[Yang et al., 2005]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Description of the tasks</head><p>In addition to the adaptive filtering task already proposed in 2008 <ref type="bibr" coords="2,400.82,291.31,113.05,13.28">[Besançon et al, 2008]</ref>, we introduced in 2009 the possibility to test batch filtering systems.</p><p>For both tasks, the document collection consists in a set of newswire articles provided by the Agence France Presse (AFP) and covering recent years, the topic set is composed of two different kinds of profiles, one concerning general news and events, and a second one on scientific and technological subjects. The filtering process may be crosslingual: English, French and Arabic are available for the documents and topics, and participants may be evaluated on monolingual runs, bilingual runs, or multilingual runs (with several target languages). The purpose of the information filtering process is to associate documents in an incoming stream to zero, one or several topics: Filtering systems must provide a Boolean decision for each document with respect to each topic.</p><p>For the batch filtering task, participants are provided with the whole document collection and must return the list of relevant documents for each topic (since the filtering process supposes a binary decision for each document, the document list does no need to be ranked).</p><p>For the adaptive filtering task, the evaluation is performed using an automatic interactive process, with a simulated user feedback: systems are allowed for each document considered relevant to a topic to ask for a feedback on this decision (i.e. ask if the document was indeed relevant for the topic or not), and can modify their behaviour according to the answer. The feedback is allowed only on kept document, there is no relevance feedback possible on discarded documents. In order to simulate the limited patience of the user, a limited number of feedbacks is allowed: this number has been fixed in 2009 to 200 feedbacks (it was 50 in 2008; but most participants considered this insufficient). The adaptive filtering task uses an interactive client-server protocol, that is described in more details in <ref type="bibr" coords="2,143.50,685.21,106.36,13.28">[Besançon et al.,2008]</ref>.</p><p>The batch filtering task has been run from April 2 nd (document collections and topics made available to the participants) to June 1 st (run submission), and the adaptive filtering task has been run from June 3 rd to July 10 th .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Test collections</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">The topics</head><p>A set of 50 profiles has been prepared, covering two different categories: the first group (30 topics) deals with general news and events concerning national and international affairs, sports, politics etc and the second one (20 topics) deals with scientific and technological subjects. The scientific topics were developed by CI professionals from INIST<ref type="foot" coords="3,292.80,160.56,3.50,7.75" target="#foot_0">1</ref> , ARIST Nord Pas de Calais<ref type="foot" coords="3,435.00,160.56,3.50,7.75" target="#foot_1">2</ref> , Digiport<ref type="foot" coords="3,485.80,160.56,3.50,7.75" target="#foot_2">3</ref> and OTO Research<ref type="foot" coords="3,100.80,175.66,3.50,7.75" target="#foot_3">4</ref> . The topics were developed in both English and French. The Arabic version has been translated from English and French by native speakers.</p><p>Topics are defined with the following elements: a unique identifier, a title (6 words max.), describing the topic in a few words, a description (20 words max.), corresponding to a sentencelong description, a narrative (60 words max.), corresponding to the description of what should be considered a relevant document and possibly what should not, keywords (up to 5) and an example of relevant text (120 words max.), taken from a document that is not in the collection (typically from the web).</p><p>Each record of the structure in the different languages correspond to translations, except for the samples which need to be extracted from real documents. An example of topic in the three languages is presented in Fig. <ref type="figure" coords="3,202.10,357.71,4.50,13.28" target="#fig_0">1</ref>. &lt;top&gt; &lt;num&gt;147&lt;/num&gt; &lt;title&gt;Care management of Alzheimer disease&lt;/title&gt; &lt;desc&gt;News in the care management of Alzheimer disease by families, society and politics&lt;/desc&gt; &lt;narr&gt;Relevant documents will highlight differents aspects of Alzheimer disease management: -human involvement of carers : families, health workers -financial means: nursing facilities, diverse grants to carerspolitical decisions leading to guidelines for optimal management of this great public health problem &lt;/narr&gt; &lt;keywords&gt; &lt;keyword&gt;Alzheimer disease&lt;/keyword&gt; &lt;keyword&gt;Dementia &lt;/keyword&gt; &lt;keyword&gt;Care management &lt;/keyword&gt; &lt;keyword&gt;Family support &lt;/keyword&gt; &lt;keyword&gt;Public health&lt;/keyword&gt; &lt;/keywords&gt; &lt;sample&gt;The AAMR/IASSID practice guidelines, developed by an international workgroup, provide guidance for stage-related care management of Alzheimer's disease, and suggestions for the training and education of carers, peers, clinicians and programme staff. The guidelines suggest a three-step intervention activity process, that includes: (1) recognizing changes; (2) conducting...&lt;/sample&gt; &lt;/top&gt; &lt;top&gt; &lt;num&gt;147&lt;/num&gt; &lt;title&gt;Prise en charge de la maladie d'Alzheimer&lt;/title&gt; &lt;desc&gt;Actualités dans le domaine de la prise en charge de la maladie d'Alzheimer, tant au niveau des familles, de la société qu'au niveau des choix politiques&lt;/desc&gt; &lt;narr&gt;Les documents pertinents présenteront les divers aspects de la prise en charge de la maladie d'Alzheimer : -moyens humains mis en jeu : familles, personnels de santé -moyens financiers : structures d'accueil, aides diverses aux malades et aux aidants -décisions politiques avec établissement de recommandations permettant d'encadrer de façon optimale ce problème majeur de santé publique &lt;/narr&gt; &lt;keywords&gt; &lt;keyword&gt;Maladie d'Alzheimer&lt;/keyword&gt; &lt;keyword&gt;Démence &lt;/keyword&gt; &lt;keyword&gt;Prise en charge &lt;/keyword&gt; &lt;keyword&gt;Aide aux familles &lt;/keyword&gt; &lt;keyword&gt;Santé publique &lt;/keyword&gt; &lt;/keywords&gt; &lt;sample&gt;Un an après l'entrée en vigueur du plan ministériel, un rapport de l'OPEPS rendu public le 12 juillet 2005 dresse un bilan assez sévère de la prise en charge de la maladie d'Alzheimer et des maladies apparentées. Selon l'OPEPS*, la politique de prévention des facteurs de risque est insuffisante, .  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">The document collection</head><p>The INFILE corpus is provided by the Agence France Presse (AFP) for research purpose. We used newswire articles in 3 languages: Arabic, English and French<ref type="foot" coords="4,363.40,93.16,3.50,7.75" target="#foot_4">5</ref> and a 3 years period <ref type="bibr" coords="4,478.49,93.31,27.27,13.28">(2004)</ref><ref type="bibr" coords="4,505.76,93.31,5.45,13.28">(2005)</ref><ref type="bibr" coords="4,511.21,93.31,27.27,13.28">(2006)</ref> which represents a collection of about one and half million newswires for around 10 GB, from which 100,000 documents of each language have been selected to be used for the INFILE filtering test. News articles are encoded in XML format and follow the News Markup Language (NewsML) specifications <ref type="foot" coords="4,122.80,153.76,3.50,7.75" target="#foot_5">6</ref> . An example of document in English is given in Fig. <ref type="figure" coords="4,387.49,153.91,4.50,13.28">2</ref>. All fields are available to the systems and can be used in the filtering process (including keywords, categorization...). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fig. 2 Exemple of document in the INFILE collection</head><p>Since we need to provide a real-time simulated feedback to the participants, we need to have the identification of relevant documents prior to the campaign, as in <ref type="bibr" coords="5,379.00,72.41,154.53,13.28" target="#b10">[Soboroff and Robertson, 2002]</ref>. The method used to build the collection of documents with the knowledge of the relevant documents is presented in details in <ref type="bibr" coords="5,240.75,102.71,109.67,13.28">[Besançon et al.,2008]</ref>. A summary of this method is given here. We used a set of 4 search engines (Lucene<ref type="foot" coords="5,275.50,132.76,3.50,7.75" target="#foot_6">7</ref> , Indri<ref type="foot" coords="5,310.20,132.76,3.50,7.75" target="#foot_7">8</ref> , Zettair<ref type="foot" coords="5,353.60,132.76,3.50,7.75" target="#foot_8">9</ref> and the search engine developed at CEA-LIST) to index the complete collection of 1.4 million documents. Each search engine has been queried using different fields of the topics, which provides us with a pool of runs. We first selected the first 10 retrieved documents of each run, and these documents were assessed manually. We then iterate using a Mixture of Experts model, computing a score for each run according to the current assessment and using this score to weight the choice of the next documents to assess. The final document collection is then built by taking all documents that are relevant to at least one topic (core relevant corpus), all documents that have been assessed and judged not relevant (difficult corpus: documents are not relevant, but share something in common with at least one topic, since they have been retrieved by at least one search engine), and a set of documents taken randomly in the rest of the collection (filler corpus, with documents that have not been retrieved by any search engines for any topic, which should limit the number of relevant documents in the corpus that have not been assessed).</p><p>Statistics on the number of assessed documents and relevant documents is presented in Table <ref type="table" coords="5,507.44,345.11,4.50,13.28" target="#tab_2">1</ref>. The repartition of relevant documents across topics is presented in Fig3.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Metrics</head><p>The results returned by the participants are binary decisions on the association of a document with a profile. The results, for a given profile, can then be summarized in a contingency On these data, a set of standard evaluation measures is computed:</p><p>• Precision, defined as P= a ab</p><p>• Recall , defined as R= a ac</p><p>• F-measure, which is a standard combination of precision and recall <ref type="bibr" coords="6,406.90,196.01,113.00,13.28">[Van Rijsbergen, 1979]</ref> depending on a parameter α , and defined as We used the standard value α =0 . 5 , which gives the same importance to precision and recall (F-measure is then the harmonic mean of the two values).</p><p>Following the TREC Filtering tracks <ref type="bibr" coords="6,244.40,325.61,47.21,13.28" target="#b4">[Hull and</ref><ref type="bibr" coords="6,296.11,325.61,159.64,13.28">Roberston, 1999, Robertson and</ref><ref type="bibr" coords="6,460.35,325.61,78.18,13.28">Soboroff, 2002]</ref> and the TDT 2004 Adaptive tracking task <ref type="bibr" coords="6,263.10,340.81,137.14,13.28" target="#b3">[Fiscus and Wheatley, 2004]</ref>, we also consider the linear utility, defined as where w 1 is the importance given to a relevant document retrieved and w 2 is the cost of an non relevant document retrieved. Linear utility is bounded positively (to 1 for a perfect filtering), but unbounded negatively (negative values depend on the number of relevant documents for a profile). Hence, the average value on all profiles would give too much importance to the few profiles on which a systems would perform poorly. To be able to average the value, the measure is scaled as follows:</p><p>where u m a x is the maximum value of the utility and u m i n a parameter considered to be the minimum utility value under which a user would not even consider the following documents for the profile. In the INFILE campaign, we used the values w 1 =1 , w 2 =0 .5 , u m i n =-0 . 5 (same as in TREC 2002). We considered last year the detection cost measure (from the Topic Detection and Tracking campaigns <ref type="bibr" coords="6,112.30,642.11,62.79,13.28">[NIST, 1998]</ref>), but we do not present this score in this paper (we found that detection cost values were often low and not really discriminant between participants). To compute average scores, the values are first computed for each profile and then averaged. In order to measure the adaptivity of the systems in the adaptive filtering track, the measures are also computed at different times in the process, each 10,000 documents, and an evolution curve of the different values across time is presented. Additionally, we use the two following measures, introduced last year in INFILE: the first one is an originality measure, defined as a comparative measure corresponding to the number of relevant documents the system uniquely retrieves (among participants). It gives more importance to systems F= 1</p><formula xml:id="formula_0" coords="6,232.40,228.81,128.11,298.15">α 1 P  1-α  1 R u=w 1 ×a-w 2 ×b u n = max u u m a x ,u m i n -u m i n 1-u m i n</formula><p>that use innovative and promising technologies that retrieve "difficult" documents.</p><p>The second one is an anticipation measure, designed to give more interest to systems that can find the first document in a given profile. This measure is motivated in CI by the interest of being at the cutting edge of a domain, and not missing the first information to be reactive. It is measured by the inverse rank of the first relevant document detected (in the list of the documents), averaged on all profiles. The measure is similar to the mean reciprocal rank (MRR) used for instance in Question Answering Evaluation <ref type="bibr" coords="7,173.90,148.11,85.03,13.28">[Voorhees, 1999]</ref>, but is not computed on the ranked list of retrieved documents but on the chronological list of the relevant documents.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Overview of the results</head><p>On the 9 participants registered for both tasks, 5 submitted results : 3 participants submitted results for the batch filtering task (a total of 9 runs), 2 for the interactive filtering task (3 runs). Participants were different for the two tasks. Table <ref type="table" coords="7,243.41,245.81,6.00,13.28" target="#tab_2">1</ref> present the participant list.</p><p>Table <ref type="table" coords="7,274.60,354.01,6.00,13.28" target="#tab_2">1</ref> Participant list Concerning the languages, 6 runs out of 9 are monolingual English for the batch filtering task, 3 are multilingual from English to French/English. For the interactive task, one run is monolingual English, one is monolingual French, and one is bilingual French to English. Table <ref type="table" coords="7,454.07,414.61,6.00,13.28">2</ref> summarizes the total number of runs for each language pair. No participant submitted runs with Arabic as source or target language.</p><p>Table <ref type="table" coords="7,156.00,524.81,6.00,13.28">2</ref> Repartition of runs according to the source and target languages</p><p>The runs and their characteristics are presented in Table <ref type="table" coords="7,328.43,555.11,4.50,13.28" target="#tab_4">3</ref>. Evaluation scores for the runs in the batch filtering task are presented in Table <ref type="table" coords="8,449.48,72.41,4.50,13.28">4</ref>, gathered by the target language (multilingual runs appears in several groups, in order to present the individual scores on each target language). Best result is obtained on monolignual English, but for the only participant that tried multilingual runs, the results obtained for the different target languages (English and French) are comparable.</p><p>Table <ref type="table" coords="8,193.20,477.81,6.00,13.28">4</ref> Scores for batch filtering runs, sorted by F-score Scores for the runs in the adaptive filtering task are presented in Table <ref type="table" coords="8,397.01,508.11,4.50,13.28" target="#tab_5">5</ref>. The scores are worse than the scores obtained on the batch filtering results, but the language pairs and the participants are not the same. We also note than both batch and adaptive results for the INFILE 2009 campaign are worse than the results obtained for the adaptive task in the INFILE 2008 edition. originality scores for every run that has the same target language (i.e. the number of relevant documents that this particular run uniquely retrieves). Since this global comparison may not be fair for participants who submitted several runs, which are presumably variants of the same technique and will share most of the relevant retrieved documents, we present in the lower part of the table the originality scores using only one run for each participant (we chose the run with the best recall score). We see here that participant with lower F-scores can have a better originality score. However, due to the small number of participants, the relevance of the originality score is arguable in this context, since it seems to be strongly linked to the difference of the recall score.</p><p>Table <ref type="table" coords="9,266.60,489.31,6.00,13.28">6</ref> Originality scores</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Conclusion</head><p>The INFILE campaign has been organized for the second time this year in CLEF, to evaluate adaptive filtering systems in a cross-language environment. The document and topic collection were the same as the 2008 edition of the INFILE@CLEF track. Two tasks have been proposed: a batch filtering task and an adaptive filtering task, that used an original setup to simulate the incoming of newswires documents, and the interaction of a user through a simulated feedback. We had this year more participants than last year and more results to analyze. However, the innovative crosslingual aspect of the task has still not really been explored, since most runs were monolingual English and no participant used the Arabic topics or documents. The lack of participation for the adaptive task is also disappointing since it does not provide enough data to compare batch techniques to adaptive techniques and does not allow to conclude on the interest of the use of the used feedback on the documents. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,126.00,700.61,343.46,13.28"><head>Fig. 1</head><label>1</label><figDesc>Fig. 1 An example of topic for the INFILE track, in the three languages</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,129.70,640.01,336.15,13.28"><head>Fig. 3</head><label>3</label><figDesc>Fig. 3 Number of relevant documents for each topic, in each language</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,70.50,202.07,452.76,505.66"><head></head><label></label><figDesc>June 15 (AFP) -The Israeli security service said Wednesday it had arrested four Palestinian teenage boys who were preparing to carry out suicide bombings.Shin Beth said the four, aged 16 and 17, belonged to the Fatah movement. It said they planned to hit targets in Israel or Israeli troops.&lt;/p&gt; &lt;p&gt;Four other young adults, also accused of Fatah membership, were picked up in Nablus in the north of the West Bank some weeks ago.&lt;/p&gt; &lt;p&gt;Shin Beth said the network was financed by the Shiite Lebanese Hezbollah group.</figDesc><table coords="4,70.50,202.07,425.60,505.66"><row><cell>&lt;NewsML Version="1.1"&gt;</cell></row><row><cell>&lt;NewsEnvelope&gt;</cell></row><row><cell>&lt;TransmissionId&gt;807&lt;/TransmissionId&gt;</cell></row><row><cell>&lt;DateAndTime&gt;20050615T212137Z&lt;/DateAndTime&gt;[...]</cell></row><row><cell>&lt;/NewsEnvelope&gt;</cell></row><row><cell>&lt;NewsItem&gt;</cell></row><row><cell>&lt;Identification&gt;</cell></row><row><cell>&lt;NewsIdentifier&gt;</cell></row><row><cell>&lt;ProviderId&gt;afp.com&lt;/ProviderId&gt;</cell></row><row><cell>&lt;DateId&gt;20050615&lt;/DateId&gt;</cell></row><row><cell>&lt;NewsItemId&gt;TX-SGE-DPE59&lt;/NewsItemId&gt;</cell></row><row><cell>&lt;RevisionId PreviousRevision="0" Update="N"&gt;1&lt;/RevisionId&gt;</cell></row><row><cell>&lt;PublicIdentifier&gt;urn:newsml:afp.com:20050615:TX-SGE-DPE59:1&lt;/PublicIdentifier&gt;</cell></row><row><cell>&lt;/NewsIdentifier&gt;</cell></row><row><cell>&lt;NameLabel&gt;Mideast-unrest-Israel-Palestinians&lt;/NameLabel&gt;</cell></row><row><cell>&lt;/Identification&gt;</cell></row><row><cell>&lt;NewsManagement&gt;[...]&lt;/NewsManagement&gt;</cell></row><row><cell>&lt;NewsComponent&gt;</cell></row><row><cell>&lt;TopicSet FormalName="NewsTopics"&gt;</cell></row><row><cell>&lt;/TopicSet&gt;</cell></row><row><cell>&lt;NewsLines&gt;</cell></row><row><cell>&lt;SlugLine&gt;Mideast-unrest-Israel-Palestinians&lt;/SlugLine&gt;</cell></row><row><cell>&lt;HeadLine&gt;Israel says teenage would-be suicide bombers held&lt;/HeadLine&gt;</cell></row><row><cell>&lt;/NewsLines&gt;</cell></row><row><cell>&lt;AdministrativeMetadata&gt;[...]&lt;/AdministrativeMetadata&gt;</cell></row><row><cell>&lt;DescriptiveMetadata&gt;</cell></row><row><cell>&lt;Language FormalName="en"/&gt;</cell></row><row><cell>&lt;SubjectCode&gt;&lt;Subject FormalName="11999000"/&gt;&lt;/SubjectCode&gt;</cell></row><row><cell>&lt;SubjectCode&gt;&lt;Subject FormalName="INT" Vocabulary="urn:newsml:afp.com:20011001:AFPCatCodes:1"/&gt;&lt;/SubjectCode&gt;</cell></row><row><cell>&lt;Location&gt;</cell></row><row><cell>&lt;Property FormalName="Country" Value="ISR"/&gt;</cell></row><row><cell>&lt;Property FormalName="City" Value="JERUS"/&gt;</cell></row><row><cell>&lt;/Location&gt;</cell></row><row><cell>&lt;/DescriptiveMetadata&gt;</cell></row><row><cell>&lt;ContentItem&gt;</cell></row><row><cell>&lt;MediaType FormalName="Text"/&gt;</cell></row><row><cell>&lt;Format FormalName="NITF3.1-body.content"/&gt;</cell></row><row><cell>&lt;Characteristics&gt;&lt;Property FormalName="Words" Value="89"/&gt;&lt;/Characteristics&gt;</cell></row><row><cell>&lt;DataContent&gt;</cell></row><row><cell>&lt;p&gt;JERUSALEM, &lt;/p&gt;</cell></row><row><cell>&lt;p&gt;ms/sj/gk&lt;/p&gt;</cell></row><row><cell>&lt;/DataContent&gt;</cell></row><row><cell>&lt;/ContentItem&gt;</cell></row><row><cell>&lt;/NewsComponent&gt;</cell></row><row><cell>&lt;/NewsItem&gt;</cell></row><row><cell>&lt;/NewsML&gt;</cell></row></table><note coords="4,86.21,376.87,374.19,8.86;4,86.21,386.07,368.09,8.86;4,86.21,395.27,366.39,8.86;4,86.21,404.47,386.39,8.86"><p>&lt;Topic Duid="topic1"&gt;&lt;TopicType FormalName="SlugKeyword"/&gt;&lt;Description&gt;Mideast&lt;/Description&gt;&lt;/Topic&gt; &lt;Topic Duid="topic2"&gt;&lt;TopicType FormalName="SlugKeyword"/&gt;&lt;Description&gt;unrest&lt;/Description&gt;&lt;/Topic&gt; &lt;Topic Duid="topic3"&gt;&lt;TopicType FormalName="SlugKeyword"/&gt;&lt;Description&gt;Israel&lt;/Description&gt;&lt;/Topic&gt; &lt;Topic Duid="topic4"&gt;&lt;TopicType FormalName="SlugKeyword"/&gt;&lt;Description&gt;Palestinians&lt;/Description&gt;&lt;/Topic&gt;</p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="5,116.70,464.21,359.24,28.38"><head>Table 1</head><label>1</label><figDesc>Statistics on the number of assessed documents and the number of relevant documents, in each language</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="5,62.40,385.85,473.60,350.04"><head></head><label></label><figDesc>table of the form:</figDesc><table coords="5,62.40,385.85,473.60,247.15"><row><cell></cell><cell></cell><cell>Relevant</cell><cell cols="2">Not Relevant</cell><cell></cell><cell></cell></row><row><cell cols="2">Retrieved</cell><cell>a</cell><cell>b</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Not Retrieved</cell><cell>c</cell><cell>d</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="4">number of documents assessed number of relevant documents avg number of relevant docs / topic std deviation on number of relevant docs / topic [min,max] number of relevant docs / topics</cell><cell>eng 7312 1597 31,94 28,45 [0,107]</cell><cell>fre 7886 2421 48,42 47,82 [0,202]</cell><cell>ara 5124 1195 23,9 23,08 [0,101]</cell></row><row><cell>200</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>eng</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>fre</cell></row><row><cell>150</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ara</cell></row><row><cell>100</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>50</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>101 102</cell><cell>103 104 105 106 107 108</cell><cell>109 110 111 112 113</cell><cell>114 115 116 117 118 119</cell><cell>120 121 122 123 124 125 126 127 128 129 130</cell><cell cols="2">131 132 133 134 135 136 137 138 139 140 141</cell><cell>142 143 144 145 146 147 148 149 150</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="7,57.60,275.65,445.63,504.74"><head>Table 3</head><label>3</label><figDesc>The runs, by team and by run name, and their characteristics</figDesc><table coords="7,57.60,275.65,445.63,487.90"><row><cell></cell><cell cols="3">team name institute</cell><cell></cell><cell></cell><cell></cell><cell>country</cell></row><row><cell></cell><cell>IMAG</cell><cell cols="6">Institut Informatique et Mathématiques Appliquées de Grenoble</cell><cell>France</cell></row><row><cell></cell><cell>SINAI</cell><cell cols="3">University of Jaen</cell><cell></cell><cell></cell><cell>Spain</cell></row><row><cell></cell><cell>UAIC</cell><cell cols="5">Universitatea Alexandru Ioan Cuza of IASI</cell><cell>Romania</cell></row><row><cell></cell><cell cols="4">HossurTech société CADEGE</cell><cell></cell><cell></cell><cell>France</cell></row><row><cell></cell><cell>UOWD</cell><cell cols="5">University of Wollongong (Comp.Sci &amp; Engineering)</cell><cell>Dubai</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">nb runs english French Arabic English 10 3 0 French 1 1 0 Arabic 0 0 0</cell></row><row><cell>team</cell><cell>run</cell><cell></cell><cell>task</cell><cell cols="3">source target topic fields</cell><cell>document fields</cell></row><row><cell>IMAG</cell><cell>IMAG_1</cell><cell></cell><cell>batch</cell><cell>eng</cell><cell>eng</cell><cell>all</cell><cell>all</cell></row><row><cell>IMAG</cell><cell>IMAG_2</cell><cell></cell><cell>batch</cell><cell>eng</cell><cell>eng</cell><cell>all</cell><cell>all</cell></row><row><cell>IMAG</cell><cell>IMAG_3</cell><cell></cell><cell>batch</cell><cell>eng</cell><cell>eng</cell><cell>all</cell><cell>all</cell></row><row><cell>UAIC</cell><cell>uaic_1</cell><cell></cell><cell>batch</cell><cell>eng</cell><cell>eng</cell><cell></cell></row><row><cell>UAIC</cell><cell>uaic_2</cell><cell></cell><cell>batch</cell><cell>eng</cell><cell>eng-fre</cell><cell></cell></row><row><cell>UAIC</cell><cell>uaic_3</cell><cell></cell><cell>batch</cell><cell>eng</cell><cell>eng-fre</cell><cell></cell></row><row><cell>UAIC</cell><cell>uaic_4</cell><cell></cell><cell>batch</cell><cell>eng</cell><cell>eng-fre</cell><cell></cell><cell>Headline, DataContent, FileName</cell></row><row><cell>SINAI</cell><cell>topics_1</cell><cell></cell><cell>batch</cell><cell>eng</cell><cell>eng</cell><cell></cell></row><row><cell>SINAI</cell><cell cols="2">googlenews_2</cell><cell>batch</cell><cell>eng</cell><cell>eng</cell><cell></cell></row><row><cell cols="5">HossurTech hossur-tech-001 adaptive fre</cell><cell>eng</cell><cell>all</cell></row><row><cell cols="5">HossurTech hossur-tech-004 adaptive fre UOWD base adaptive eng</cell><cell>fre eng</cell><cell>all title,desc</cell><cell>DataContent</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="8,50.50,162.85,493.57,610.04"><head>Table 5</head><label>5</label><figDesc>Scores for adaptive filtering runs Results for originality measure are presented in Table 6. The upper part of the table present</figDesc><table coords="8,50.50,162.85,493.57,561.86"><row><cell cols="2">monolingual english</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">team run</cell><cell cols="7">num_rel num_rel_ret precision recall F-score Utility anticipation</cell></row><row><cell cols="2">IMAG IMAG_1</cell><cell>1597</cell><cell>413</cell><cell>0,26</cell><cell>0,30</cell><cell>0,21</cell><cell>0,21</cell><cell>0,43</cell></row><row><cell cols="2">UAIC uaic_4</cell><cell>1597</cell><cell>1267</cell><cell>0,09</cell><cell>0,66</cell><cell>0,13</cell><cell>0,05</cell><cell>0,73</cell></row><row><cell cols="2">UAIC uaic_1</cell><cell>1597</cell><cell>1331</cell><cell>0,06</cell><cell>0,69</cell><cell>0,09</cell><cell>0,03</cell><cell>0,75</cell></row><row><cell cols="2">UAIC uaic_2</cell><cell>1597</cell><cell>1331</cell><cell>0,06</cell><cell>0,69</cell><cell>0,09</cell><cell>0,03</cell><cell>0,75</cell></row><row><cell cols="2">UAIC uaic_3</cell><cell>1597</cell><cell>1507</cell><cell>0,06</cell><cell>0,82</cell><cell>0,09</cell><cell>0,03</cell><cell>0,86</cell></row><row><cell cols="2">IMAG IMAG_2</cell><cell>1597</cell><cell>109</cell><cell>0,13</cell><cell>0,09</cell><cell>0,07</cell><cell>0,16</cell><cell>0,22</cell></row><row><cell cols="2">IMAG IMAG_3</cell><cell>1597</cell><cell>66</cell><cell>0,16</cell><cell>0,06</cell><cell>0,07</cell><cell>0,22</cell><cell>0,14</cell></row><row><cell cols="2">SINAI topics_1</cell><cell>1597</cell><cell>940</cell><cell>0,02</cell><cell>0,50</cell><cell>0,04</cell><cell>0,00</cell><cell>0,57</cell></row><row><cell cols="2">SINAI googlenews_2</cell><cell>1597</cell><cell>196</cell><cell>0,01</cell><cell>0,08</cell><cell>0,01</cell><cell>0,13</cell><cell>0,10</cell></row><row><cell cols="3">crosslingual english french</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">team run</cell><cell cols="7">num_rel num_rel_ret precision recall F-score Utility anticipation</cell></row><row><cell cols="2">UAIC uaic_4</cell><cell>2421</cell><cell>1120</cell><cell>0,09</cell><cell>0,44</cell><cell>0,12</cell><cell>0,05</cell><cell>0,58</cell></row><row><cell cols="2">UAIC uaic_3</cell><cell>2421</cell><cell>1905</cell><cell>0,06</cell><cell>0,75</cell><cell>0,10</cell><cell>0,03</cell><cell>0,83</cell></row><row><cell cols="2">UAIC uaic_2</cell><cell>2421</cell><cell>1614</cell><cell>0,06</cell><cell>0,67</cell><cell>0,09</cell><cell>0,02</cell><cell>0,76</cell></row><row><cell cols="3">multilingual english english/french</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">team run</cell><cell cols="7">num_rel num_rel_ret precision recall F-score Utility anticipation</cell></row><row><cell cols="2">UAIC uaic_4</cell><cell>4018</cell><cell>2387</cell><cell>0,07</cell><cell>0,56</cell><cell>0,11</cell><cell>0,02</cell><cell>0,72</cell></row><row><cell cols="2">UAIC uaic_3</cell><cell>4018</cell><cell>3412</cell><cell>0,05</cell><cell>0,81</cell><cell>0,08</cell><cell>0,02</cell><cell>0,85</cell></row><row><cell cols="2">UAIC uaic_2</cell><cell>4018</cell><cell>2945</cell><cell>0,05</cell><cell>0,70</cell><cell>0,07</cell><cell>0,02</cell><cell>0,80</cell></row><row><cell cols="2">monolingual english</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>team</cell><cell>run</cell><cell cols="7">num_rel num_rel_ret precision recall F-score Utility anticipation</cell></row><row><cell>UOWD</cell><cell>base</cell><cell>1597</cell><cell>20</cell><cell>0,00</cell><cell>0,01</cell><cell>0,01</cell><cell>0,03</cell><cell>0,05</cell></row><row><cell cols="2">monolingual french</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>team</cell><cell>run</cell><cell cols="7">num_rel num_rel_ret precision recall F-score Utility anticipation</cell></row><row><cell cols="2">HossurTech hossur-tech-004</cell><cell>2421</cell><cell>790</cell><cell>0,05</cell><cell>0,31</cell><cell>0,06</cell><cell>0,05</cell><cell>0,53</cell></row><row><cell cols="3">crosslingual french  english</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>team</cell><cell>run</cell><cell cols="7">num_rel num_rel_ret precision recall F-score Utility anticipation</cell></row><row><cell cols="2">HossurTech hossur-tech-001</cell><cell>1597</cell><cell>819</cell><cell>0,10</cell><cell>0,45</cell><cell>0,10</cell><cell>0,07</cell><cell>0,59</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="3,73.40,739.49,374.67,11.07"><p>the French Institute for Scientific and Technical Information Center, http://international.inist.fr/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,73.40,750.99,353.67,11.07"><p>Agence Régionale d'Information Stratégique et Technologique, http://www.aristnpdc.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="3,73.40,762.59,93.80,11.07"><p>http://www.digiport.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="3,73.40,774.09,104.07,11.07"><p>http://www.otoresearch.fr/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="4,71.00,739.49,466.33,11.07;4,71.00,750.99,394.40,11.07"><p>Newswires in different languages are not translations from a language to another (it is not an aligned corpus): the same information is generally rewritten to match the interest of the audience in the corresponding country.</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="4,71.00,762.59,458.40,11.07;4,71.00,774.09,433.67,11.07"><p>NewsML is an XML standard designed to provide a media-independent, structural framework for multi-media news. NewsML was developed by the International Press Telecommunications Council. see http://www.newsml.org/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="5,71.00,750.99,94.20,11.07"><p>http://lucene.apache.org</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7" coords="5,71.00,762.59,133.97,11.07"><p>http://www.lemurproject.org/indri</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9" xml:id="foot_8" coords="5,71.00,774.09,134.53,11.07"><p>http://www.seg.rmit.edu.au/zettair</p></note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="10,62.42,57.21,102.39,13.28" xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Besancon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,167.81,57.21,360.64,13.28;10,85.20,71.01,433.56,13.28;10,85.20,84.81,56.59,13.28" xml:id="b1">
	<monogr>
		<title level="m" type="main" coord="10,134.80,71.01,315.94,13.28">Overview of CLEF 2008 INFILE Pilot Track, Overview of CLEF</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Besancon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Chaudiron</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Mostefa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Hamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Timimi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Choukri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008. 2008</date>
		</imprint>
	</monogr>
	<note type="report_type">INFILE Pilot Track</note>
</biblStruct>

<biblStruct coords="10,61.75,98.61,133.07,13.28" xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Wheatley</forename><surname>Fiscus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,197.82,98.61,292.31,13.28;10,85.20,112.41,198.60,13.28" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="10,369.44,98.61,120.70,13.28;10,85.20,112.41,103.34,13.28">Overview of the tdt 2004 evaluation and results</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Fiscus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Wheatley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,208.82,112.41,36.25,13.28">TDT&apos;02</title>
		<imprint>
			<date type="published" when="2004">2004</date>
		</imprint>
		<respStmt>
			<orgName>NIST</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="10,61.86,126.21,126.94,13.28" xml:id="b4">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Roberston</forename><surname>Hull</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,191.80,126.21,346.19,13.28;10,85.20,140.01,356.88,13.28" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="10,360.10,126.21,173.37,13.28">The trec-8 filtering track final report</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Hull</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Roberston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,98.20,140.01,305.46,13.28">Proceedings of the Eighth Text REtrieval Conference (TREC-8)</title>
		<meeting>the Eighth Text REtrieval Conference (TREC-8)</meeting>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,124.48,153.81,371.51,13.28;10,85.20,167.61,350.12,13.28" xml:id="b6">
	<monogr>
		<ptr target="http://www.nist.gov/speech/tests/tdt/1998/doc/tdt2.eval.plan.98.v3.7.pdf" />
		<title level="m" coord="10,192.17,153.81,299.10,13.28">The topic detection and tracking phase 2 (tdt2) evaluation plan</title>
		<imprint>
			<date type="published" when="1998">1998</date>
		</imprint>
		<respStmt>
			<orgName>NIST</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="10,62.13,181.41,148.05,13.28" xml:id="b7">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Soboroff</forename><surname>Robertson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,213.18,181.41,320.18,13.28;10,85.20,195.21,421.20,13.28" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="10,398.16,181.41,135.20,13.28;10,85.20,195.21,27.08,13.28">The trec 2002 filtering track report</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,132.79,195.21,335.75,13.28">Proceedings of The Eleventh Text Retrieval Conference (TREC 2002)</title>
		<meeting>The Eleventh Text Retrieval Conference (TREC 2002)</meeting>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,61.99,209.01,148.20,13.28" xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Robertson</forename><surname>Soboroff</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,213.18,209.01,296.51,13.28;10,85.20,222.81,438.11,13.28;10,85.20,236.61,63.59,13.28" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="10,398.16,209.01,111.53,13.28;10,85.20,222.81,109.91,13.28">Building a filtering test collection for trec 2002</title>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Robertson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,216.50,222.81,306.80,13.28;10,85.20,236.61,25.83,13.28">Proceedings of The Eleventh Text Retrieval Conference (TREC 2002)</title>
		<meeting>The Eleventh Text Retrieval Conference (TREC 2002)</meeting>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,62.80,250.41,107.00,13.28" xml:id="b11">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Van Rijsbergen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,172.80,250.41,352.21,13.28" xml:id="b12">
	<monogr>
		<title level="m" type="main" coord="10,305.81,250.41,102.42,13.28">Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Van Rijsbergen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
			<pubPlace>Butterworths, London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,62.10,264.21,78.70,13.28" xml:id="b13">
	<monogr>
		<title/>
		<author>
			<persName coords=""><surname>Voorhees</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,143.80,264.21,385.18,13.28;10,85.20,278.01,282.18,13.28" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="10,247.10,264.21,202.70,13.28">The trec-8 question answering track report</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,470.40,264.21,58.57,13.28;10,85.20,278.01,243.84,13.28">Proceedings of the Eighth Text REtrieval Conference (TREC-8)</title>
		<meeting>the Eighth Text REtrieval Conference (TREC-8)</meeting>
		<imprint>
			<publisher>NIST</publisher>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,62.80,291.81,84.30,13.28" xml:id="b15">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Yang</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2005">2005</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="10,150.10,291.81,360.55,13.28;10,85.20,305.61,408.46,13.28;10,85.20,319.41,446.05,13.28;10,85.20,333.21,153.22,13.28" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="10,399.41,291.81,111.24,13.28;10,85.20,305.61,238.92,13.28">Robustness of adaptive filtering methods in a cross-benchmark evaluation</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Yoo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Kisiel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="10,345.12,305.61,148.54,13.28;10,85.20,319.41,441.77,13.28">Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval</title>
		<meeting>the 28th annual international ACM SIGIR conference on Research and development in information retrieval<address><addrLine>Salvador, Brazil</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005">2005</date>
			<biblScope unit="page" from="98" to="105" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
