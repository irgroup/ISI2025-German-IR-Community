<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,387.40,15.42;1,89.29,106.66,416.55,15.42;1,88.78,128.58,40.40,15.43;1,89.29,150.91,227.87,11.96">MASON-NLP at eRisk 2023: Deep Learning-Based Detection of Depression Symptoms from Social Media Texts Notebook for the MasonNLP Lab at CLEF 2023</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,176.82,95.22,11.96"><forename type="first">Fardin</forename><forename type="middle">Ahsan</forename><surname>Sakib</surname></persName>
							<email>fsakib@gmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">George Mason University</orgName>
								<address>
									<settlement>Fairfax</settlement>
									<region>VA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,202.68,176.82,113.65,11.96"><forename type="first">Ahnaf</forename><forename type="middle">Atef</forename><surname>Choudhury</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">George Mason University</orgName>
								<address>
									<settlement>Fairfax</settlement>
									<region>VA</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,352.83,176.82,69.99,11.96"><forename type="first">Ozlem</forename><surname>Uzuner</surname></persName>
							<email>ouzuner@gmu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">George Mason University</orgName>
								<address>
									<settlement>Fairfax</settlement>
									<region>VA</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,387.40,15.42;1,89.29,106.66,416.55,15.42;1,88.78,128.58,40.40,15.43;1,89.29,150.91,227.87,11.96">MASON-NLP at eRisk 2023: Deep Learning-Based Detection of Depression Symptoms from Social Media Texts Notebook for the MasonNLP Lab at CLEF 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">A36DA66B5C631DE5C462F413C170DE08</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>depression detection</term>
					<term>early risk prediction</term>
					<term>mental health</term>
					<term>natural language processing</term>
					<term>information retrieval</term>
					<term>CEUR-WS</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Depression is a mental health disorder that has a profound impact on people's lives. Recent research suggests that signs of depression can be detected in the way individuals communicate, both through spoken words and written texts. In particular, social media posts are a rich and convenient text source that we may examine for depressive symptoms. The Beck Depression Inventory (BDI) Questionnaire, which is frequently used to gauge the severity of depression, is one instrument that can aid in this study. We can narrow our study to only those symptoms since each BDI question is linked to a particular depressive symptom. It's important to remember that not everyone with depression exhibits all symptoms at once, but rather a combination of them. Therefore, it is extremely useful to be able to determine if a sentence or a piece of user-generated content is pertinent to a certain condition. With this in mind, the eRisk 2023 Task 1 was designed to do exactly that: assess the relevance of different sentences to the symptoms of depression as outlined in the BDI questionnaire. This report is all about how our team, Mason-NLP, participated in this subtask, which involved identifying sentences related to different depression symptoms. We used a deep learning approach that incorporated MentalBERT, RoBERTa, and LSTM. Despite our efforts, the evaluation results were lower than expected, underscoring the challenges inherent in ranking sentences from an extensive dataset about depression, which necessitates both appropriate methodological choices and significant computational resources. We anticipate that future iterations of this shared task will yield improved results as our understanding and techniques evolve.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Depression is an increasingly prevalent mental health condition, particularly among teens and younger individuals <ref type="bibr" coords="1,183.08,543.64,11.58,10.91" target="#b0">[1]</ref>. Each year, millions are affected by this debilitating condition, yet a substantial proportion do not seek medical attention, due to either lack of awareness or the stigma associated with mental health disorders <ref type="bibr" coords="1,295.99,570.74,11.28,10.91" target="#b1">[2]</ref>. This untreated condition can have profound personal and social implications, potentially leading to severe consequences such as substance abuse <ref type="bibr" coords="1,117.31,597.84,12.84,10.91" target="#b2">[3]</ref> or even suicide <ref type="bibr" coords="1,202.56,597.84,11.43,10.91" target="#b3">[4]</ref>.</p><p>Language is more than a medium for communication; it's a reflection of various aspects of our lives. Language can unveil a multitude of insights about us, ranging from our age and gender to our upbringing and mental state <ref type="bibr" coords="2,232.92,114.06,11.28,10.91" target="#b4">[5]</ref>. Evidence suggests a correlation between language use and mental health <ref type="bibr" coords="2,152.50,127.61,11.32,10.91" target="#b5">[6]</ref>, positioning natural language processing (NLP) as a potent tool for analyzing depression symptoms. Indeed, recent research indicates the efficacy of these techniques in detecting signs and symptoms of various mental health conditions <ref type="bibr" coords="2,387.41,154.71,11.43,10.91" target="#b6">[7]</ref>.</p><p>In today's digital age, a large proportion of people, especially youth and teens, actively use social media <ref type="bibr" coords="2,147.69,181.81,11.51,10.91" target="#b7">[8]</ref>. This widespread use, and the potential correlation between increased social media interaction and depression, opens up possibilities for mental health analysis <ref type="bibr" coords="2,461.00,195.36,11.47,10.91" target="#b8">[9]</ref>. Social media serves as a platform for individuals to communicate, share thoughts and experiences, and engage in topic-specific channels like subreddits. Particularly, channels related to mental health and depression can provide valuable insights when analyzed with state-of-the-art NLP techniques <ref type="bibr" coords="2,140.24,249.56,11.36,10.91" target="#b6">[7,</ref><ref type="bibr" coords="2,154.32,249.56,12.32,10.91" target="#b9">10]</ref>.</p><p>Early detection of depression symptoms is essential since it allows for timely intervention and lowers the risk of serious effects <ref type="bibr" coords="2,254.73,276.66,16.26,10.91" target="#b10">[11]</ref>. With their wealth of user-generated content, social media platforms can be a powerful tool for this early detection <ref type="bibr" coords="2,365.32,290.20,11.23,10.91" target="#b6">[7,</ref><ref type="bibr" coords="2,379.23,290.20,12.23,10.91" target="#b9">10]</ref>. If it is possible to extract words from social media posts that are pertinent to depressive symptoms, preventative steps to treat probable mental health issues could be taken <ref type="bibr" coords="2,315.03,317.30,16.25,10.91" target="#b11">[12]</ref>.</p><p>We give a thorough explanation of our participation in eRisk 2023 Task 1 in our publication. This project focuses on identifying early risks on the internet, and in particular, our task comprises ranking user data into sentences depending on how closely they correspond to symptoms of depression as identified by the Beck Depression Inventory (BDI) Questionnaire. Please see <ref type="bibr" coords="2,136.01,385.05,17.78,10.91" target="#b12">[13]</ref> for further details regarding the task and a detailed summary of the evaluations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Dataset</head><p>Our system was trained utilizing two distinct datasets: 1) the official dataset for the eRisk 2023 Task 1, and 2) the "Depression: Reddit Dataset" from Kaggle <ref type="bibr" coords="2,352.59,457.22,18.45,10.91" target="#b13">[14]</ref>.</p><p>The official dataset for the eRisk 2023 Task 1, derived from previous eRisk data, was formatted in accordance with Text REtrieval Conference(TREC) <ref type="bibr" coords="2,329.16,484.32,20.66,10.91" target="#b14">[15]</ref> guidelines. This dataset consisted of a collection of user documents, with 3,107 unique users contributing to a total of 3,807,115 sentences. On average, each user had approximately 1,225 sentences associated with their profile.</p><p>However, inherent challenges with this data source existed due to its nature. Derived from informal social media posts, the sentences often lacked cohesiveness, contained spelling and grammatical errors, and frequently included internet shorthand. Additionally, the presence of links, images, references to other users, and a high volume of sentences irrelevant to the task at hand posed further complexities. Therefore, identifying pertinent sentences within this extensive corpus presented a significant challenge.</p><p>The second dataset, the "Depression: Reddit Dataset" from Kaggle, comprised raw data scraped from various mental health-related subreddits. Post-scraping, the data was cleaned and processed using different NLP techniques to prepare it for depression classification. This dataset contained 7,731 sentences, each associated with a binary label: '1' representing depression- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Methodology and experimental setup</head><p>Our methodology leveraged three models in a dual-stage approach, as described in Figure <ref type="figure" coords="3,499.57,433.49,3.81,10.91" target="#fig_0">1</ref>, aimed at accelerating system performance. We will first present a summary of each model before diving into the specifics of our technique.</p><p>MentalBERT MentalBERT <ref type="bibr" coords="3,218.49,489.35,21.67,10.91" target="#b15">[16]</ref> is a pre-trained language model for mental healthcare pretrained on mental health data. Specifically, the pretraining data was collected from Reddit <ref type="bibr" coords="3,487.00,502.90,16.15,10.91" target="#b16">[17]</ref>, especially from Mental Health related subreddits, like "r/depression", "r/Anxiety", "r/bipolar" etc. The pretrained model was evaluated on various mental health detection tasks such as depression and stress detection. The empricial results show that pretraining with a mental health corpus improves classification performance.</p><p>RoBERTa RoBERTa <ref type="bibr" coords="3,184.63,585.86,21.04,10.91" target="#b17">[18]</ref>, short for Robustly Optimized BERT Pretraining Approach is a variant of BERT that enhances the pretraining process by adjusting key hyperparameters and training on a larger dataset. Unlike BERT, RoBERTa omits the next sentence prediction objective, focusing only on the masked language modeling task, and uses a dynamic masking pattern rather than a static one. Additionally, RoBERTa uses larger batch sizes during training. The changes incorporated in RoBERTa have led to superior performance over BERT on a variety of natural language understanding tasks, making it a powerful model for various applications in the field of natural language processing. LSTM Long Short-Term Memory (LSTM) <ref type="bibr" coords="4,280.51,129.27,20.57,10.91" target="#b18">[19]</ref> is a type of Recurrent Neural Network (RNN) used for processing and predicting time-series and sequential data. LSTMs manage long-term dependencies through a unique architecture involving a cell state and three gates: input, forget, and output gates. This architecture effectively mitigates the vanishing gradient problem seen in traditional RNNs, allowing LSTMs to learn and remember information over extended sequence lengths. This makes them ideal for tasks like handwriting or speech recognition and other sequence-to-sequence learning tasks.</p><p>The task at hand necessitated a bifurcated approach for optimal efficiency, with the primary objective of curtailing the data sample size. This reduction was principally motivated by the simultaneous application of multiple models in conjunction with the MentalBERT pre-trained model. These additional models were deployed during an exploratory phase, with the objective of identifying the most appropriate model for our system's architecture. Nevertheless, due to constraints in computational resources, executing multiple models on the comprehensive dataset, comprised of 3.8 million data points, resulted in considerable time consumption during both the training and testing phases. Consequently, to counteract this issue, a decision was made to eliminate sentences that were irrelevant to depressive symptoms. This strategy aimed to expedite the process of identifying a model that was best suited for our system.</p><p>The first phase of our task, therefore, concentrated on a standardized dataset specifically related to depression, sourced from the renowned data science platform, Kaggle. This depressionoriented dataset was employed to train a binary-model system designed to exclude sentences unrelated to depression.</p><p>The dual-model system comprised a transformer model, RoBERTa, as its initial component. After its training with the depression-specific dataset from Kaggle, RoBERTa demonstrated high accuracy of 92%. on the validation data. This model was subsequently used to categorize sentences associated with depression, thereby reducing the data samples from 3,807,115 to a more manageable 830,151.</p><p>To further refine the sentence pool, the RoBERTa model's output was passed to the second component of our ensemble: a unidirectional, single-layer Long Short-Term Memory (LSTM) model. Also trained on the Kaggle dataset, this LSTM model contained 128 parameters and had a 20% dropout rate, along with one fully connected layer leading to a sigmoid function. Trained over 20 epochs, the LSTM model achieved an impressive validation data accuracy of 97%. After processing the RoBERTa model's reduced data, the LSTM model further diminished the sample size from 830,151 to 305,118, thus producing a more relevant and manageable dataset.</p><p>The second phase of our task, following the successful reduction of the initial dataset from 3,807,115 to 305,118 pertinent sentences, entailed a detailed comparison process. Each sentence from the reduced dataset was compared with a set of 21 distinct depression symptoms. Each symptom was articulated through four variations, yielding 84 unique sentences (21 symptoms * 4 variations) representing the depression symptom spectrum.</p><p>This comparison was conducted using cosine similarity, a metric capturing the cosine of the angle between two vectors-in our context, signifying the similarity between each sample sentence and the symptom sentence. We utilized a pre-trained model, MentalBERT, specifically chosen due to its relevance to our task. Trained on mental health-related datasets, MentalBERT is adept at interpreting and analyzing text in this specific domain.</p><p>For computation, sentences were tokenized, divided into constituent words or phrases, facilitating their input into the model. This tokenization was optimized through padding and CUDA <ref type="bibr" coords="5,121.19,154.71,16.25,10.91" target="#b19">[20]</ref>, an application programming interface model created by NVIDIA[21], resulting in accelerated processing through GPU power utilization. Each sentence, irrespective of length, was represented by an equal number of tokens. Following tokenization, embeddings for each token were computed. These embeddings transformed discrete tokens into continuous vectors, capturing semantic meaning and making them suitable for processing by machine learning models. Mean pooling was then applied to these embeddings, down-sampling the output. The mean-pooled sentence-embedded tokens were subsequently normalized, ensuring the vectors had a norm of one, ready to be input into the cosine similarity metric model.</p><p>Each sentence was compared with the 84 symptom sentences as it passed through the model, generating 84 cosine similarity scores for each sentence. The highest score among these represented the closest match, and the corresponding symptom was then mapped as the identified symptom for the given sample sentence. For each symptom, the similarity scores of the mapped sentences were arranged in descending order, retaining only the top 1,000 sentences for each symptom.</p><p>To sum up, the methodology developed in this research effectively amalgamates machine learning (ML) and natural language processing (NLP) techniques to handle an extensive dataset related to depression. Commencing with a sizeable, heterogeneous dataset, we applied ensemble learning models to pare down the sample to a manageable size. Subsequently, we leveraged sentence transformers and cosine similarity measures to assign each sentence to the most closely matching symptom of depression. This sophisticated two-stage approach, which combines several machine learning models with cosine similarity, furnished us with an effective and efficient method for processing large-scale depression-related data. Notably, the success of this approach underscores the potential of integrating multiple machine learning techniques to improve the processing and analysis of large and complex datasets in the field of mental health.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results and Discussion</head><p>In this section, we present the results of our participation in the eRisk 2023 Task 1 as well as discuss potential reasons for the performance of our model. Given the task's nature as an Information Retrieval challenge, there was no designated test dataset. Instead, three independent assessors, a trained psychologist and two experts in early risk technologies, evaluated the results. The assessors assigned relevance scores based on two criteria: '1' for sentences relevant to a BDI symptom, and '0' for sentences not relevant or not conveying any information about a BDI symptom.</p><p>Various standard performance metrics were reported, including Average Precision (AP), R-Precision, Precision at 10, and Normalized Discounted Cumulative Gain (NDCG) at 1000, based on two aggregation criteria: unanimity and majority voting. The results are reported in Table <ref type="table" coords="5,115.79,660.46,5.07,10.91" target="#tab_0">1</ref> and Table <ref type="table" coords="5,169.56,660.46,3.74,10.91" target="#tab_1">2</ref>. Our system, which employed MentalBERT, obtained scores of 0.035, 0.072, 0.286, and 0.117 in AP, R-Precision, Precision at 10, and NDCG at 1000 respectively under majority voting. Under unanimity aggregation, our scores were lower: 0.024, 0.054, 0.190, and 0.099 respectively. The top-performing systems in the task significantly outperformed our model.</p><p>While our expectations were higher given MentalBERT's domain-specific training, we can identify several potential factors that might have influenced our system's performance: Training Data: While MentalBERT is pre-trained on a mental health data corpus, it may not resonate perfectly with the nuances of the BDI Questionnaire, which focuses on subjective experiences of depression symptoms. That's why it might have struggled to accurately assess relevance.</p><p>Evaluation Criteria: The utilized metrics (AP, R-Precision, Precision at 10, and NDCG at 1000) favor systems retrieving relevant sentences ranked high. If our system retrieved relevant sentences ranked lower, it would negatively affect these scores.</p><p>Model Tuning and Parameters: Models often require task-specific tuning and adjustment. Finetuning MentalBERT or adjusting its parameters for this task might have enhanced performance.</p><p>Unanimity vs. Majority Voting: Our system's better performance in majority voting suggests it might be detecting more ambiguous or less agreed-upon symptom instances, leading to lower performance when higher agreement levels are required.</p><p>These insights provide useful direction for future work and refinement of our approach.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion and Future Work</head><p>This paper has documented the approach and outcomes of MASON-NLP's submission for the eRisk 2023 Task 1, employing a two-step methodology utilizing ROBERTA, MentalBERT and LSTM to retrieve sentences pertinent to BDI symptoms from a sizeable Reddit dataset.</p><p>In conclusion, the demonstrated performance of our methodology, albeit reasonable, did not match up to the top-tier teams, underlining room for improvement. The Mental BERT model's capacity to resonate with the task requirements could be optimized through fine-tuning using task-specific data, which emerges as an immediate future direction.</p><p>Understanding the nuances of evaluation metrics and aligning our strategies to maximize these metrics could lead to significant gains in performance. A closer inspection of our model's performance under unanimity aggregation criteria, followed by strategies to improve in this area, also warrants attention.</p><p>In essence, our future work will focus on learning from this experience and making informed, strategic modifications to our approach to enhance its effectiveness in identifying BDI symptoms from social media text data. This study's insights underscore the challenges and possibilities inherent in leveraging AI for mental health, underlining its significance in the ongoing dialogue around technology's role in healthcare.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="3,89.29,323.72,140.96,8.93;3,110.13,84.19,375.01,226.96"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Methodology Flowchart</figDesc><graphic coords="3,110.13,84.19,375.01,226.96" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="6,88.99,90.49,457.58,489.43"><head>Table 1</head><label>1</label><figDesc>Ranking-based evaluation:majority voting. Our results(Mason-NLP) compared with other teams' results. The best results are bolded.</figDesc><table coords="6,95.27,127.91,451.31,452.00"><row><cell>Team</cell><cell>Run</cell><cell>AP</cell><cell cols="3">R-PREC P@10 NDCG@1000</cell></row><row><cell>Mason-NLP</cell><cell>MentalBert</cell><cell cols="2">0.035 0.072</cell><cell>0.286</cell><cell>0.117</cell></row><row><cell>Formula-ML</cell><cell>SentenceTrainsformers_0.25</cell><cell cols="2">0.319 0.375</cell><cell cols="2">0.861 0.596</cell></row><row><cell>Formula-ML</cell><cell>SentenceTrainsformers_0.1</cell><cell cols="2">0.308 0.359</cell><cell cols="2">0.861 0.584</cell></row><row><cell>Formula-ML</cell><cell>result2</cell><cell cols="2">0.086 0.170</cell><cell>0.457</cell><cell>0.277</cell></row><row><cell>Formula-ML</cell><cell>word2vec_0.1</cell><cell cols="2">0.092 0.176</cell><cell>0.5</cell><cell>0.285</cell></row><row><cell cols="2">OBSER-MENH salida-distilroberta-90-cos</cell><cell cols="2">0.294 0.359</cell><cell>0.814</cell><cell>0.578</cell></row><row><cell cols="2">OBSER-MENH salida-mpnet-90-cos</cell><cell cols="2">0.265 0.333</cell><cell>0.805</cell><cell>0.550</cell></row><row><cell cols="2">OBSER-MENH salida-mpnet-21-cos</cell><cell cols="2">0.120 0.207</cell><cell>0.471</cell><cell>0.365</cell></row><row><cell cols="2">OBSER-MENH salida-distilroberta-21-cos</cell><cell cols="2">0.158 0.249</cell><cell>0.543</cell><cell>0.418</cell></row><row><cell cols="2">OBSER-MENH salida-mini12-21-cos</cell><cell cols="2">0.114 0.184</cell><cell>0.305</cell><cell>0.329</cell></row><row><cell>uOttawa</cell><cell>USESim</cell><cell cols="2">0.160 0.248</cell><cell>0.600</cell><cell>0.382</cell></row><row><cell>uOttawa</cell><cell>Glove100Sim</cell><cell cols="2">0.017 0.052</cell><cell>0.195</cell><cell>0.105</cell></row><row><cell>uOttawa</cell><cell>RobertaSim</cell><cell cols="2">0.033 0.080</cell><cell>0.329</cell><cell>0.150</cell></row><row><cell>uOttawa</cell><cell>GloveSim</cell><cell cols="2">0.011 0.038</cell><cell>0.162</cell><cell>0.075</cell></row><row><cell>uOttawa</cell><cell>BertSim</cell><cell cols="2">0.084 0.150</cell><cell>0.505</cell><cell>0.271</cell></row><row><cell>BLUE</cell><cell>SemSearchOnBDI2Queries</cell><cell cols="2">0.104 0.126</cell><cell>0.781</cell><cell>0.211</cell></row><row><cell>BLUE</cell><cell cols="3">SemSearchOnGeneratedQueriesMentalRoberta 0.029 0.063</cell><cell>0.367</cell><cell>0.105</cell></row><row><cell>BLUE</cell><cell>SemSearchOnBDI2QueriesMentalRoberta</cell><cell cols="2">0.027 0.044</cell><cell>0.386</cell><cell>0.089</cell></row><row><cell>BLUE</cell><cell>SemSearchOnGeneratedQueries</cell><cell cols="2">0.052 0.074</cell><cell>0.586</cell><cell>0.139</cell></row><row><cell>BLUE</cell><cell>SemSearchOnAllQueries</cell><cell cols="2">0.065 0.086</cell><cell>0.629</cell><cell>0.160</cell></row><row><cell>NailP</cell><cell>T1_M2</cell><cell cols="2">0.095 0.146</cell><cell>0.519</cell><cell>0.226</cell></row><row><cell>NailP</cell><cell>T1_M4</cell><cell cols="2">0.095 0.146</cell><cell>0.519</cell><cell>0.221</cell></row><row><cell>NailP</cell><cell>T1_M3</cell><cell cols="2">0.073 0.114</cell><cell>0.471</cell><cell>0.180</cell></row><row><cell>NailP</cell><cell>T1_M5</cell><cell cols="2">0.089 0.140</cell><cell>0.486</cell><cell>0.223</cell></row><row><cell>NailP</cell><cell>T1_M1</cell><cell cols="2">0.074 0.114</cell><cell>0.471</cell><cell>0.189</cell></row><row><cell>RELAI</cell><cell>bm25|mpnetbase</cell><cell cols="2">0.048 0.081</cell><cell>0.538</cell><cell>0.140</cell></row><row><cell>RELAI</cell><cell>BM25</cell><cell cols="2">0.016 0.061</cell><cell>0.043</cell><cell>0.145</cell></row><row><cell>RELAI</cell><cell>bm25|mpnetbase_simcse</cell><cell cols="2">0.030 0.066</cell><cell>0.390</cell><cell>0.114</cell></row><row><cell>RELAI</cell><cell>bm25|mpnetqa_simcse</cell><cell cols="2">0.027 0.063</cell><cell>0.376</cell><cell>0.109</cell></row><row><cell>RELAI</cell><cell>bm25|mpnetqa</cell><cell cols="2">0.038 0.075</cell><cell>0.438</cell><cell>0.126</cell></row><row><cell>UNSL</cell><cell>Prompting-Classifier</cell><cell cols="2">0.036 0.090</cell><cell>0.229</cell><cell>0.180</cell></row><row><cell>UNSL</cell><cell>Similarity-AVG</cell><cell cols="2">0.001 0.008</cell><cell>0.010</cell><cell>0.016</cell></row><row><cell>UNSL</cell><cell>Similarity-MAX</cell><cell cols="2">0.001 0.011</cell><cell>0.019</cell><cell>0.019</cell></row><row><cell>UMU</cell><cell>LexiconMultilingualSentenceTransformer</cell><cell cols="2">0.073 0.140</cell><cell>0.495</cell><cell>0.222</cell></row><row><cell>UMU</cell><cell>LexiconSentenceTransformer</cell><cell cols="2">0.054 0.122</cell><cell>0.362</cell><cell>0.191</cell></row><row><cell>GMU</cell><cell>FAST-DCMN-COS-INJECT</cell><cell cols="2">0.001 0.002</cell><cell>0.014</cell><cell>0.004</cell></row><row><cell>GMU</cell><cell>FAST-DCMN-COS-INJECT_FULL</cell><cell cols="2">0.001 0.003</cell><cell>0.014</cell><cell>0.005</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="7,88.99,90.49,457.58,489.43"><head>Table 2</head><label>2</label><figDesc>Ranking-based evaluation: unanimity. Our results(Mason-NLP) compared with other teams' results.</figDesc><table coords="7,494.20,102.49,11.78,8.87"><row><cell>The</cell></row></table></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct coords="8,112.66,515.85,393.32,10.91;8,112.66,529.40,96.43,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,333.82,515.85,116.26,10.91">Depression in adolescence</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Thapar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Collishaw</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">S</forename><surname>Pine</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">K</forename><surname>Thapar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,458.70,515.85,47.28,10.91">The lancet</title>
		<imprint>
			<biblScope unit="volume">379</biblScope>
			<biblScope unit="page" from="1056" to="1067" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,542.95,394.53,10.91;8,112.66,556.50,394.62,10.91;8,112.66,570.05,393.98,10.91;8,112.41,583.60,48.96,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,342.28,556.50,165.00,10.91;8,112.66,570.05,230.30,10.91">Barriers to mental health treatment: results from the who world mental health surveys</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">H</forename><surname>Andrade</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Alonso</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Mneimneh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Wells</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Al-Hamzawi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Borges</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Bromet</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Bruffaerts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>De Girolamo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">De</forename><surname>Graaf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,354.77,570.05,107.09,10.91">Psychological medicine</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="1303" to="1317" />
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,597.15,393.61,10.91;8,112.28,610.69,187.66,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,155.01,597.15,239.36,10.91">Chronic stress, drug use, and vulnerability to addiction</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sinha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,402.61,597.15,103.66,10.91;8,112.28,610.69,93.58,10.91">Annals of the new York Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">1141</biblScope>
			<biblScope unit="page" from="105" to="130" />
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,624.24,393.33,10.91;8,112.66,637.79,393.53,10.91;8,112.66,651.34,131.15,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,349.70,624.24,156.28,10.91;8,112.66,637.79,338.54,10.91">Mental disorders, comorbidity and suicidal behavior: results from the national comorbidity survey replication</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">K</forename><surname>Nock</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Hwang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">A</forename><surname>Sampson</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">C</forename><surname>Kessler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,460.43,637.79,45.76,10.91;8,112.66,651.34,47.21,10.91">Molecular psychiatry</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="868" to="876" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,86.97,393.33,10.91;9,112.66,100.52,339.33,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="9,325.60,86.97,180.39,10.91;9,112.66,100.52,116.18,10.91">Psychological aspects of natural language use: Our words, our selves</title>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">W</forename><surname>Pennebaker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">R</forename><surname>Mehl</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><forename type="middle">G</forename><surname>Niederhoffer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,236.89,100.52,131.16,10.91">Annual review of psychology</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="547" to="577" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,114.06,395.17,10.91;9,112.66,127.61,393.98,10.91;9,112.66,141.16,28.67,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="9,265.69,114.06,242.14,10.91;9,112.66,127.61,143.00,10.91">The psychological meaning of words: Liwc and computerized text analysis methods</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">R</forename><surname>Tausczik</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">W</forename><surname>Pennebaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,267.29,127.61,194.92,10.91">Journal of language and social psychology</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="24" to="54" />
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,154.71,393.33,10.91;9,112.66,168.26,395.00,10.91;9,112.41,181.81,28.67,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="9,291.36,154.71,214.63,10.91;9,112.66,168.26,61.92,10.91">Social media as a measurement tool of depression in populations</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">De</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Counts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,197.70,168.26,263.65,10.91">Proceedings of the 5th annual ACM web science conference</title>
		<meeting>the 5th annual ACM web science conference</meeting>
		<imprint>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="47" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,195.36,305.71,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="9,159.46,195.36,81.89,10.91">Social media usage</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Perrin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,249.88,195.36,89.62,10.91">Pew research center</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page" from="52" to="68" />
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,208.91,395.01,10.91;9,112.66,222.46,393.33,10.91;9,112.66,236.01,252.98,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="9,213.07,222.46,292.91,10.91;9,112.66,236.01,56.01,10.91">Association between social media use and depression among us young adults</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">Y</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">E</forename><surname>Sidani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Shensa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Radovic</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">B</forename><surname>Colditz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">L</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">M</forename><surname>Giles</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">A</forename><surname>Primack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,176.78,236.01,104.92,10.91">Depression and anxiety</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="323" to="331" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,249.56,393.33,10.91;9,112.66,263.11,393.32,10.91;9,112.66,276.66,393.32,10.91;9,112.66,290.20,174.05,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="9,374.95,249.56,131.04,10.91;9,112.66,263.11,317.33,10.91">From adhd to sad: Analyzing the language of mental health on twitter through self-reported diagnoses</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Coppersmith</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Dredze</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Harman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Hollingshead</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,452.89,263.11,53.09,10.91;9,112.66,276.66,393.32,10.91;9,112.66,290.20,102.16,10.91">Proceedings of the 2nd workshop on computational linguistics and clinical psychology: from linguistic signal to clinical reality</title>
		<meeting>the 2nd workshop on computational linguistics and clinical psychology: from linguistic signal to clinical reality</meeting>
		<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="1" to="10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,303.75,393.33,10.91;9,112.66,317.30,393.33,10.91;9,112.66,330.85,268.20,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,425.05,303.75,80.94,10.91;9,112.66,317.30,393.33,10.91;9,112.66,330.85,98.35,10.91">How effective are cognitive behavior therapies for major depression and anxiety disorders? a meta-analytic update of the evidence</title>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Cuijpers</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">A</forename><surname>Cristea</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Karyotaki</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Reijnders</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Huibers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,219.52,330.85,77.40,10.91">World psychiatry</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="245" to="258" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,344.40,394.53,10.91;9,112.66,357.95,393.33,10.91;9,112.66,371.50,231.95,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="9,324.64,357.95,181.35,10.91;9,112.66,371.50,40.81,10.91">Digital trajectories to care in first-episode psychosis</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">L</forename><surname>Birnbaum</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">F</forename><surname>Rizvi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Faber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Addington</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">U</forename><surname>Correll</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Gerber</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><forename type="middle">C</forename><surname>Lahti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">L</forename><surname>Loewy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">H</forename><surname>Mathalon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">A</forename><surname>Nelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,161.94,371.50,88.59,10.91">Psychiatric Services</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="1259" to="1263" />
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,385.05,393.60,10.91;9,112.66,398.60,393.33,10.91;9,112.66,412.15,393.53,10.91;9,112.66,425.70,233.60,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,350.49,385.05,155.77,10.91;9,112.66,398.60,112.14,10.91">Overview of erisk 2023: Early risk prediction on the internet</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mart√≠n Rodilla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,247.41,398.60,258.58,10.91;9,112.66,412.15,348.05,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction. 14th International Conference of the CLEF Association, CLEF 2023</title>
		<meeting><address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,439.25,395.01,10.91;9,112.66,452.79,241.30,10.91" xml:id="b13">
	<monogr>
		<author>
			<persName coords=""><surname>Kaggle</surname></persName>
		</author>
		<ptr target="https://www.kaggle.com" />
		<title level="m" coord="9,147.13,439.25,264.22,10.91">Kaggle: Your Machine Learning and Data Science Community</title>
		<imprint>
			<date type="published" when="2023-07-03">2023. 3rd July 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,466.34,395.01,10.91;9,112.66,479.89,22.22,10.91" xml:id="b14">
	<monogr>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">I</forename></persName>
		</author>
		<ptr target="https://trec.nist.gov/" />
		<title level="m" coord="9,145.00,466.34,237.50,10.91">Standards, Technology, Text retrieval conference (trec)</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,493.44,395.17,10.91;9,112.66,506.99,395.01,10.91" xml:id="b15">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Joshi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Zettlemoyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Stoyanov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="9,137.85,506.99,241.29,10.91">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,520.54,395.01,10.91;9,112.66,534.09,151.06,10.91" xml:id="b16">
	<monogr>
		<ptr target="https://www.reddit.com" />
		<title level="m" coord="9,183.52,520.54,137.37,10.91">The Front Page of the Internet</title>
		<imprint>
			<date type="published" when="2023-07-03">2023. 3rd July 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,547.64,393.33,10.91;9,112.66,561.19,349.92,10.91" xml:id="b17">
	<monogr>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Ansari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Fu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Tiwari</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Cambria</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2110.15621</idno>
		<title level="m" coord="9,367.46,547.64,138.52,10.91;9,112.66,561.19,219.99,10.91">Mentalbert: Publicly available pretrained language models for mental healthcare</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,574.74,393.33,10.91;9,112.66,588.29,285.38,10.91" xml:id="b18">
	<monogr>
		<title level="m" type="main" coord="9,263.34,574.74,242.64,10.91;9,112.66,588.29,154.98,10.91">Understanding lstm -a tutorial into long short-term memory recurrent neural networks</title>
		<author>
			<persName coords=""><forename type="first">R</forename><forename type="middle">C</forename><surname>Staudemeyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">R</forename><surname>Morris</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1909.09586</idno>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,601.84,393.32,10.91;9,112.66,615.39,176.48,10.91" xml:id="b19">
	<monogr>
		<ptr target="https://developer.nvidia.com/cuda-toolkit" />
		<title level="m" coord="9,205.74,601.84,62.52,10.91">CUDA Toolkit</title>
		<imprint>
			<date type="published" when="2023-07-03">2023. 3rd July 2023</date>
		</imprint>
		<respStmt>
			<orgName>Nvidia Corporation</orgName>
		</respStmt>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
