<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,88.69,84.74,417.17,15.42;1,89.29,106.66,302.27,15.42">A Natural Language Processing Based Risk Prediction Framework for Pathological Gambling</title>
				<funder ref="#_3wRPGA2">
					<orgName type="full">Indian Institute of Science Education and Research Bhopal, India</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,88.87,134.97,50.61,11.96"><forename type="first">Abu</forename><surname>Talha</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Data Science and Engineering</orgName>
								<orgName type="institution">Indian Institute of Science Education and Research</orgName>
								<address>
									<settlement>Bhopal</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName coords="1,152.12,134.97,66.05,11.96"><forename type="first">Tanmay</forename><surname>Basu</surname></persName>
							<email>tanmay@iiserb.ac.in</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Data Science and Engineering</orgName>
								<orgName type="institution">Indian Institute of Science Education and Research</orgName>
								<address>
									<settlement>Bhopal</settlement>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,88.69,84.74,417.17,15.42;1,89.29,106.66,302.27,15.42">A Natural Language Processing Based Risk Prediction Framework for Pathological Gambling</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">ED2834051226AA69C2A92B876DD31036</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:34+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Bio NLP</term>
					<term>Information Extraction</term>
					<term>Text Classification</term>
					<term>Mental Health</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Task 2 of eRisk 2023 shared-tasks challenge at Conference and Labs of the Evaluation Forum (CLEF) was to focus on the early detection of pathological gambling via sequential text processing over social media conversations. The challenge organizers have released different datasets, consisting of social media posts and questionnaires, for all three tasks. The BioNLP research group at the Indian Institute of Science Education and Research Bhopal (IISERB) participated in task 2 of the challenge and submitted five runs that for five different text mining frameworks. The performance of different text classification frameworks and their effectiveness in detecting signs of pathological gambling are demonstrated in this paper. Several classifiers and feature engineering schemes are combined to build individual frameworks. The features from free text are generated following the bag of words model and transformer based embeddings methods. Subsequently, adaptive boosting, logistic regression, support vector machine, and transformer based classifiers were used to identify the signs of pathological gambling from the social media posts. The experimental analysis demonstrates that the support vector machine and adaptive boosting classifier respectively using the entropy and TF-IDF weighting scheme of the bag of words outperforms the other methods on the training set. Furthermore, the adaptive boosting classifier following TF-IDF-based weighting scheme achieves the best precision score among all other submissions of task 2 of erisk 2023. However, the rest of the frameworks could not achieve reasonable performance which needs to be introspected in future.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The area of research related to the early prediction of signs of mental illness through social media analysis is fascinating and demanding in the Internet age. Pathological Gambling or Gambling Disorder (GD), is a condition that is marked by persistent and repetitive gambling habits, causing notable distress or disruption <ref type="bibr" coords="1,287.96,517.94,11.30,10.91" target="#b0">[1]</ref>. The estimated prevalence of GD is around 0.5 % of the adult population in the United States, while other countries have similar or potentially higher numbers <ref type="bibr" coords="1,163.72,545.04,11.53,10.91" target="#b0">[1]</ref>. Individuals with pathological gambling are neither frequently identified nor treated for their condition. It is common for pathological gambling to coincide with other psychiatric disorders, such as mood, anxiety, attention deficit, and substance use disorders <ref type="bibr" coords="1,492.45,572.14,11.41,10.91" target="#b1">[2]</ref>. Moreover, pathological gambling is closely linked to other forms of addiction, as it was the first non-substance addiction to be officially recognized <ref type="bibr" coords="2,342.33,86.97,11.55,10.91" target="#b2">[3]</ref>. With the advent of social media, we interact a lot on different social media for different purposes. Hence various social media like Reddit, Twitter, Facebook, etc. have become valuable resources for conducting research to identify the signs of various mental illnesses <ref type="bibr" coords="2,282.70,127.61,11.23,10.91" target="#b3">[4,</ref><ref type="bibr" coords="2,296.16,127.61,7.42,10.91" target="#b4">5,</ref><ref type="bibr" coords="2,305.82,127.61,7.49,10.91" target="#b5">6]</ref>. The CLEF eRisk group has been organizing various shared tasks over the last few years for early prediction of risks of various disorders using the conversations of different subjects over Reddit<ref type="foot" coords="2,343.86,152.96,3.71,7.97" target="#foot_0">1</ref> , a popular social media <ref type="bibr" coords="2,456.66,154.71,11.41,10.91" target="#b6">[7,</ref><ref type="bibr" coords="2,470.78,154.71,7.49,10.91" target="#b7">8,</ref><ref type="bibr" coords="2,480.99,154.71,7.49,10.91" target="#b8">9,</ref><ref type="bibr" coords="2,491.19,154.71,12.36,10.91" target="#b9">10]</ref>. The eRisk 2023 lab <ref type="bibr" coords="2,172.59,168.26,17.76,10.91" target="#b10">[11]</ref> had announced three tasks, where the second task is an early prediction of signs of pathological gambling. The data used for the same shared task last year in eRisk 2021 and 2022 has been released as the training data for task 2 of eRisk 2023. This paper introduce five different frameworks that were developed to address the issue of early prediction of signs of pathological gambling using conversations over social media.</p><p>We have explored various frameworks by combining different feature engineering schemes and text classification techniques and evaluated their performance on the given training data. Therefore the best five frameworks were implemented on the given test data submitted to the task organizers for evaluation. The goal of these frameworks is to analyze the conversations of individual subjects in the given training corpus to train a classifier to classify the subjects into pathological gambling and control groups. The performance of a text classification technique is highly dependent on significant text features and their relationship to derive a semantic interpretation. Hence both the conventional bag of words model and the latest transformer-based models were used to generate text features. The term frequency and inverse frequency (TF-IDF) based term weighting scheme <ref type="bibr" coords="2,221.01,357.95,16.31,10.91" target="#b11">[12,</ref><ref type="bibr" coords="2,239.81,357.95,13.95,10.91" target="#b12">13]</ref> and entropy based term weighting scheme <ref type="bibr" coords="2,443.26,357.95,16.30,10.91" target="#b13">[14,</ref><ref type="bibr" coords="2,462.06,357.95,12.50,10.91" target="#b14">15,</ref><ref type="bibr" coords="2,477.04,357.95,12.50,10.91" target="#b15">16,</ref><ref type="bibr" coords="2,492.03,357.95,13.95,10.91" target="#b16">17]</ref> have been used for the bag of words model. Moreover, three different attention layer based transformer models, viz., BERT (Bidirectional Encoder Representations from Transformers) <ref type="bibr" coords="2,89.29,398.60,16.41,10.91" target="#b17">[18]</ref>, Longformer <ref type="bibr" coords="2,162.44,398.60,19.92,10.91" target="#b18">[19]</ref>, RoBERTa <ref type="bibr" coords="2,228.79,398.60,22.06,10.91" target="#b19">[20]</ref> were used to generate semantic features from the given training data. Subsequently, the performance of adaptive boosting (Ada-Boost) <ref type="bibr" coords="2,449.84,412.15,16.41,10.91" target="#b20">[21]</ref>, logistic regression (LR), Random Forest (RF), K-Nearest Neighbors (KNN) and support vector machine (SVM) <ref type="bibr" coords="2,118.93,439.25,17.75,10.91" target="#b21">[22]</ref> classifiers have been explored on the training corpus using the bag of words features following both TF-IDF and entropy-based weighting schemes. Furthermore, the performance of individual transformer-based embeddings has been tested using the pre-trained sequence classification framework of individual models.</p><p>The results show that the SVM classifier using the entropy based term weighting scheme of the bag of words model outperforms all other frameworks on the training data in terms of precision, recall and F1 score. The Ada-Boost classifier using entropy based weighting scheme of bag of words achieved the highest precision score among all submissions for Task 2 of eRisk 2023 challenge on the test data, but it could not perform well on the training set. However, few of the proposed models e.g., Ada-Boost using entropy achieved decent recall and F1 score on the training set, but they could not achieve reasonable performance on test corpus, which needs to be examined in future. The paper is organized as follows. Section 2 explains the proposed frameworks for identifying pathological gambling over social media conversations. The experimental evaluation is presented in section ??. The conclusions and significant findings are described in section 5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Proposed Frameworks</head><p>Several text classification frameworks have been explored to identify pathological gambling using the conversation of individual subjects over social media data from Reddit. The corpora released by the organizers consist of documents containing the posts of Reddit users over a period along with corresponding dates and titles in XML format <ref type="bibr" coords="3,368.21,151.93,16.08,10.91" target="#b10">[11]</ref>. Note that conversations of each subject are composed in one XML file along with other information. All conversations of a subject are extracted from an XML file and merged together disregarding the timestamp and title. Hence the corpus used in the proposed frameworks to train individual classifiers only contains free text conversations of different users. We have combined different feature engineering and text classification techniques to identify pathological gamblers using the training corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Feature Engineering</head><p>We have used both the classical bag of words model and transformer architecture based models for generating features from the conversations of individual Reddit users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.1.">Features Generated by Bag Of Words Model</head><p>The bag of Words (BOW) model is a classical text feature extraction model, which considers each unique term of a corpus as a feature and finds the weight of a term following different schemes <ref type="bibr" coords="3,130.61,357.50,16.41,10.91" target="#b22">[23]</ref>. Thus each document in a corpus is generally represented by a vector, whose length is equal to the number of unique terms, also known as vocabulary <ref type="bibr" coords="3,421.30,371.05,16.38,10.91" target="#b22">[23]</ref>. Two different terms weighting schemes are used here, viz, term frequency and inverse document frequency (TF-IDF) based term weighting scheme <ref type="bibr" coords="3,261.89,398.15,16.31,10.91" target="#b11">[12,</ref><ref type="bibr" coords="3,280.92,398.15,13.95,10.91" target="#b22">23]</ref> and Entropy-based term weighting scheme <ref type="bibr" coords="3,488.22,398.15,17.76,10.91" target="#b14">[15]</ref> as these methods had performed well in similar tasks <ref type="bibr" coords="3,324.02,411.70,16.30,10.91" target="#b23">[24,</ref><ref type="bibr" coords="3,343.04,411.70,12.50,10.91" target="#b12">13,</ref><ref type="bibr" coords="3,358.25,411.70,12.50,10.91" target="#b15">16,</ref><ref type="bibr" coords="3,373.46,411.70,12.23,10.91" target="#b16">17]</ref>. TF-IDF weighting scheme assigns the weight of the term as follows:</p><formula xml:id="formula_0" coords="3,220.18,441.98,282.60,26.48">TF-IDF(term ğ‘– ) = ğ‘¡ğ‘“ ğ‘–ğ‘— Ã— log (ï¸‚ ğ‘ ğ‘‘ğ‘“ ğ‘– )ï¸‚ (<label>1</label></formula><formula xml:id="formula_1" coords="3,502.78,449.62,3.86,10.91">)</formula><p>where N is the total number of documents in the corpus, ğ‘¡ğ‘“ ğ‘–ğ‘— is the frequency of ğ‘– ğ‘¡â„ term in the ğ‘— ğ‘¡â„ document of the corpus, and ğ‘‘ğ‘“ ğ‘– is known as document frequency of the ğ‘– ğ‘¡â„ term, which is the number of documents in which the ğ‘– ğ‘¡â„ term appears <ref type="bibr" coords="3,362.72,502.55,16.41,10.91" target="#b22">[23]</ref>. Many researchers use the entropy-based term weighting technique to form a term-document matrix from a text collection <ref type="bibr" coords="3,89.29,529.65,16.30,10.91" target="#b12">[13,</ref><ref type="bibr" coords="3,108.25,529.65,12.50,10.91" target="#b14">15,</ref><ref type="bibr" coords="3,123.40,529.65,12.50,10.91" target="#b15">16,</ref><ref type="bibr" coords="3,138.55,529.65,12.23,10.91" target="#b16">17]</ref>. This method is developed in the spirit that the more important term is the more frequent one that occurs in fewer documents, taking the distribution of the term over the corpus into account <ref type="bibr" coords="3,149.40,556.75,16.41,10.91" target="#b14">[15]</ref>. The weight of a term in a document is determined by the entropy of the term frequency of the term in that document <ref type="bibr" coords="3,292.57,570.30,16.28,10.91" target="#b14">[15]</ref>. The weight (ğ‘Š ğ‘–ğ‘— ) of the ğ‘– ğ‘¡â„ term in the ğ‘— ğ‘¡â„ document is defined by the Entropy<ref type="foot" coords="3,248.74,582.09,3.71,7.97" target="#foot_1">2</ref>  <ref type="bibr" coords="3,255.67,583.85,16.43,10.91" target="#b14">[15,</ref><ref type="bibr" coords="3,274.83,583.85,14.03,10.91" target="#b15">16]</ref> model as follows:</p><formula xml:id="formula_2" coords="3,130.46,601.68,197.14,42.12">ğ‘Š ğ‘–ğ‘— = log (ï¸€ ğ‘¡ğ‘“ ğ‘–ğ‘— + 1 )ï¸€ Ã— (ï¸ƒ 1 + ğ‘ âˆ‘ï¸€ ğ‘—=1 ğ‘ƒ ğ‘–ğ‘— log ğ‘ƒ ğ‘–ğ‘— log(ğ‘ + 1)</formula><p>)ï¸ƒ</p><p>, where,</p><formula xml:id="formula_3" coords="3,400.54,619.30,102.24,41.95">ğ‘ƒ ğ‘–ğ‘— = ğ‘¡ğ‘“ ğ‘–ğ‘— ğ‘ âˆ‘ï¸€ ğ‘—=1 ğ‘¡ğ‘“ ğ‘–ğ‘— (<label>2</label></formula><formula xml:id="formula_4" coords="3,502.78,626.01,3.86,10.91">)</formula><p>Here N is the total number of documents in the corpus and ğ‘¡ğ‘“ ğ‘–ğ‘— is the frequency of ğ‘– ğ‘¡â„ term in the ğ‘— ğ‘¡â„ document of the corpus. Generally BOW model generates a lot of terms which makes the term-document matrix sparse and high dimensional which can badly affect the performance of the text classifiers <ref type="bibr" coords="4,171.24,127.61,16.17,10.91" target="#b16">[17]</ref>. Hence ğœ’ 2 -statistic-based term selection technique was used to identify essential terms from the term-document matrix, which is a widely used technique for term selection <ref type="bibr" coords="4,131.03,154.71,16.36,10.91" target="#b12">[13,</ref><ref type="bibr" coords="4,150.13,154.71,12.52,10.91" target="#b15">16,</ref><ref type="bibr" coords="4,165.38,154.71,12.27,10.91" target="#b24">25]</ref>. We have used different thresholds to choose the best terms following the ğœ’ 2 -statistic and evaluated the performance of individual classifiers using this set of terms on the training corpus. The best set of terms for individual classifiers is used for experiments on the test data. The ğœ’ 2 -statistic for term selection is used for both TF-IDF and Entropy-based term weighting schemes in the experiments in section 4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.2.">Features Generated by Transformer Based Architecture</head><p>Some transformer architecture-based methods were used for identifying the signs of pathological gamblers by generating relevant embeddings using the conversations of individual users. We need to capture the long range dependency and context of the conversations effectively. Bidirectional Encoder Representations from Transformers (BERT) is a contextualized word representation model based on a masked language model and pre-trained using bidirectional transformers on general domain corpora i.e., English Wikipedia and books <ref type="bibr" coords="4,422.12,325.98,16.21,10.91" target="#b17">[18]</ref>. Moreover, we have used RoBERTa <ref type="bibr" coords="4,182.13,339.53,18.04,10.91" target="#b19">[20]</ref> model, an extension of BERT which was initially trained on a news corpus by fixing some specific parameters and training strategies of BERT <ref type="bibr" coords="4,411.65,353.08,16.09,10.91" target="#b19">[20]</ref>. The Longformer model <ref type="bibr" coords="4,118.76,366.63,17.76,10.91" target="#b18">[19]</ref> has significant advantages over BERT to identify long-term dependency in the given texts <ref type="bibr" coords="4,113.07,380.18,16.16,10.91" target="#b16">[17]</ref>. As the conversations of individual subjects are recorded over a period of time in the training corpus, Longformer may be useful to identify long-term dependency between different conversations. The parameters of the pre-trained BERT, RoBERTa, and Longformer models were fine-tuned using the given training corpus to generate the embeddings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Methods for Text Classification</head><p>Adaptive Boosting (Ada-Boost), Logistic Regression, Random Forest, K-Nearest Neighbors, and Support Vector Machine (SVM) classifiers were implemented to identify pathological gamblers by using the conversations in the training corpus. It should be noted that these classification methods were implemented using bag of words following both Entropy and TF-IDF-based weighting schemes. In order to identify significant parameters for individual classifiers, the grid search technique<ref type="foot" coords="4,188.39,536.55,3.71,7.97" target="#foot_2">3</ref> was used following 10-fold cross-validation method on the training corpus. Furthermore, we have explored the performance of pre-trained BERT, RoBERTa, and Longformer models from the Hugging Face repository<ref type="foot" coords="4,331.05,563.64,3.71,7.97" target="#foot_3">4</ref> using the training corpus.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experimental Setup</head><p>The training data for individual subjects were released in XML format with identity, timestamp, and postings with the ground truth. The proposed frameworks were evaluated using the training data. In the test corpus, 103 users were marked as pathological gamblers and 2071 users were marked as the control group <ref type="bibr" coords="5,215.70,100.52,16.09,10.91" target="#b10">[11]</ref>. These training and test corpora statistics clearly indicate that the control group has a very high number of instances compared to the pathological gamblers. We have submitted five runs using the following five different frameworks as mentioned in Table <ref type="table" coords="5,115.98,270.15,3.77,10.91" target="#tab_0">1</ref>. The performance of different feature engineering techniques and the classifiers were evaluated following 10 fold cross-validation method on the training corpus. Based on these performances, the five best frameworks were chosen, which were applied to the test corpus and submitted as five runs in Table <ref type="table" coords="5,246.21,310.80,3.70,10.91" target="#tab_1">2</ref>. Scikit-learn<ref type="foot" coords="5,307.54,309.05,3.71,7.97" target="#foot_4">5</ref> libraries were used to implement AdaBoost, K-Nearest Neighbor, Logistic Regression, Random Forest, and SVM classifiers. The balanced weighting scheme of individual classes was used for each classifier to overcome the effect of the control group over the pathological gambling class. This weighting scheme as implemented in Scikit-learn automatically adjusts weights of individual classes inversely proportional to the class frequencies in the training data<ref type="foot" coords="5,249.77,376.79,3.71,7.97" target="#foot_5">6</ref>  <ref type="bibr" coords="5,256.70,378.55,16.09,10.91" target="#b16">[17]</ref>. The pretrained embeddings of BERT <ref type="foot" coords="5,439.30,376.79,3.71,7.97" target="#foot_6">7</ref> , Longformer<ref type="foot" coords="5,500.63,376.79,3.71,7.97" target="#foot_7">8</ref> , and RoBERTa 9 were used from the HuggingFace library.</p><p>The performance of the proposed frameworks was evaluated in terms of precision, recall, and f-measure using the training corpus <ref type="bibr" coords="5,275.42,419.20,16.41,10.91" target="#b12">[13]</ref>. The performance of the best five frameworks using the test corpus was evaluated by the organizers in terms of precision, recall, f-measure, and ERDE 5 <ref type="bibr" coords="5,142.10,446.29,16.25,10.91" target="#b25">[26]</ref>, ERDE 50 <ref type="bibr" coords="5,200.31,446.29,16.25,10.91" target="#b25">[26]</ref>, latency ğ‘‡ ğ‘ƒ <ref type="bibr" coords="5,270.43,446.29,11.43,10.91" target="#b8">[9]</ref>, speed <ref type="bibr" coords="5,316.54,446.29,12.84,10.91" target="#b8">[9]</ref> and latency-weighted F1 score <ref type="bibr" coords="5,470.29,446.29,11.43,10.91" target="#b8">[9]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results and Discussion</head><p>The performances of classifiers using different feature engineering schemes are presented in Table <ref type="table" coords="5,115.53,518.47,5.02,10.91" target="#tab_1">2</ref> in terms of precision, recall, and F1 scores. These results demonstrate valuable insights for evaluating the effectiveness of different frameworks. Subsequently, the top three frameworks were determined based on f-measure scores from Table <ref type="table" coords="5,331.29,545.57,3.66,10.91" target="#tab_1">2</ref>. These frameworks were implemented on the test corpus and the corresponding results are reported in Table <ref type="table" coords="5,393.01,559.12,4.97,10.91">3</ref> and Table <ref type="table" coords="5,444.81,559.12,4.97,10.91">4</ref> as published by the organizers <ref type="bibr" coords="5,172.11,572.67,16.41,10.91" target="#b10">[11]</ref>. Analysis of Table <ref type="table" coords="5,279.52,572.67,5.17,10.91" target="#tab_1">2</ref> reveals that SVM using both entropy-based and TF-IDF based term weighting schemes outperform the other frameworks in terms of precision, recall and f-measure. Table <ref type="table" coords="5,211.61,599.76,5.04,10.91" target="#tab_1">2</ref> also shows that Ada-Boost using both entropy-based and TF-IDF based term weighting schemes performs reasonably well than all other classifiers except SVM on the training corpus. Hence these four frameworks have been executed on the test corpus. Note that none of the transformer based models i.e., BERT, RoBERTa and Longformer could even identify a single pathological gambler in the training corpus, however, we still implement the Longformer model on the test corpus as it generally identify long term dependencies in text. In fact, its performance was improved when performed on the test corpus, which can be see from Table <ref type="table" coords="6,141.53,576.25,3.81,10.91">3</ref>. Note that the hyper-parameters of only the final layer of BERT, RoBERTa and Longformer models are fine-tuned using the given training corpus due to time constraints. As the pathological gambling cases are very few in compare to the control group, the transformer based models which are pre-trained on Books and Wikipedia, could not identify the semantic interpretation of the conversations of the pathological gamblers. This may be the reason that the transformer based models could not identify even a single case of pathological gambling from the validation data and hence their precision, recall and F1-score are 0 in Table <ref type="table" coords="6,463.72,657.55,3.71,10.91" target="#tab_1">2</ref>. Table <ref type="table" coords="6,500.95,657.55,5.03,10.91">3</ref> </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="5,88.99,143.07,394.27,97.13"><head>Table 1</head><label>1</label><figDesc>Summary of Five Different Runs</figDesc><table coords="5,112.01,171.16,371.25,69.04"><row><cell>Runs</cell><cell>Frameworks</cell><cell>Number of Features</cell></row><row><cell cols="2">BioNLP-IISERB 0 Entropy Based Features and SVM Classifier</cell><cell>5000</cell></row><row><cell cols="2">BioNLP-IISERB 1 TF-IDF Based Features and SVM Classifier</cell><cell>5000</cell></row><row><cell cols="2">BioNLP-IISERB 2 Entropy Based Features and AdaBoost Classifier</cell><cell>5000</cell></row><row><cell cols="2">BioNLP-IISERB 3 TF-IDF Based Features and AdaBoost Classifier</cell><cell>500</cell></row><row><cell cols="2">BioNLP-IISERB 4 Longformer Model</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="6,88.99,90.49,411.59,380.11"><head>Table 2</head><label>2</label><figDesc>Performance of different frameworks on the training corpus</figDesc><table coords="6,88.99,118.58,411.59,352.02"><row><cell>Feature Types</cell><cell></cell><cell cols="2">Classifier</cell><cell></cell><cell></cell><cell cols="3">Precision Recall F1 Score</cell></row><row><cell cols="4">Bag of words following Entropy AdaBoost</cell><cell></cell><cell></cell><cell>0.52</cell><cell>0.81</cell><cell>0.63</cell></row><row><cell cols="2">based term weighting scheme</cell><cell cols="3">Logistic Regression</cell><cell></cell><cell>0.57</cell><cell>0.81</cell><cell>0.67</cell></row><row><cell cols="2">(Using given training data)</cell><cell cols="4">Support Vector Machine</cell><cell>0.71</cell><cell>0.81</cell><cell>0.76</cell></row><row><cell></cell><cell></cell><cell cols="3">Random Forest</cell><cell></cell><cell>0.75</cell><cell>0.57</cell><cell>0.65</cell></row><row><cell></cell><cell></cell><cell cols="3">Decision Tree</cell><cell></cell><cell>0.26</cell><cell>0.71</cell><cell>0.38</cell></row><row><cell cols="4">Bag of words following TF-IDF AdaBoost</cell><cell></cell><cell></cell><cell>0.71</cell><cell>0.71</cell><cell>0.71</cell></row><row><cell cols="2">based term weighting scheme</cell><cell cols="3">Logistic Regression</cell><cell></cell><cell>0.47</cell><cell>0.76</cell><cell>0.58</cell></row><row><cell cols="2">(Using given training data)</cell><cell cols="4">Support Vector Machine</cell><cell>0.71</cell><cell>0.71</cell><cell>0.71</cell></row><row><cell></cell><cell></cell><cell cols="4">K-Nearest Neighbor(KNN)</cell><cell>0.56</cell><cell>0.24</cell><cell>0.33</cell></row><row><cell></cell><cell></cell><cell cols="3">Decision Tree</cell><cell></cell><cell>0.47</cell><cell>0.71</cell><cell>0.57</cell></row><row><cell></cell><cell></cell><cell cols="2">BERT</cell><cell></cell><cell></cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell cols="2">Features based on transformer</cell><cell cols="2">RoBERTa</cell><cell></cell><cell></cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell cols="2">(Using given training data)</cell><cell cols="3">Longformer</cell><cell></cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>Table 3</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">Decision-based evaluation on test data</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Runs</cell><cell>P</cell><cell>R</cell><cell cols="5">F1 ERDE 5 ERDE 50 latency ğ‘‡ ğ‘ƒ speed</cell><cell>latency</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>weighted F1</cell></row><row><cell>BioNLP-IISERB 0</cell><cell cols="4">0.933 0.68 0.787 0.038</cell><cell>0.037</cell><cell>62.0</cell><cell>0.766</cell><cell>0.603</cell></row><row><cell>(Entropy+BOW+SVM)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>BioNLP-IISERB 1</cell><cell cols="4">0.938 0.592 0.726 0.042</cell><cell>0.042</cell><cell>62.0</cell><cell>0.766</cell><cell>0.557</cell></row><row><cell>(TFIDF+BOW+SVM)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>BioNLP-IISERB 2</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0.047</cell><cell>0.047</cell><cell>-</cell><cell>-</cell><cell>-</cell></row><row><cell>(Entropy+BOW+AdaBoost)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>BioNLP-IISERB 3</cell><cell cols="4">1.000 0.049 0.093 0.045</cell><cell>0.045</cell><cell>1.0</cell><cell>1.000</cell><cell>0.093</cell></row><row><cell>(TFIDF+BOW+AdaBoost)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>BioNLP-IISERB 4</cell><cell cols="4">1.000 0.039 0.075 0.047</cell><cell>0.046</cell><cell>19.0</cell><cell>0.930</cell><cell>0.070</cell></row><row><cell>(Longformer)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="2,92.57,670.99,90.34,8.97"><p>https://www.reddit.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="3,92.57,671.27,241.37,8.97"><p>https://radimrehurek.com/gensim/models/logentropy_model.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="4,92.57,660.08,343.37,8.97"><p>https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="4,92.57,671.04,84.73,8.97"><p>https://huggingface.co/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5" xml:id="foot_4" coords="5,92.57,627.19,199.52,8.97"><p>http://scikit-learn.org/stable/supervised_learning.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6" xml:id="foot_5" coords="5,92.57,638.15,379.97,8.97"><p>https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7" xml:id="foot_6" coords="5,92.57,649.11,152.16,8.97"><p>https://huggingface.co/bert-base-uncased</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8" xml:id="foot_7" coords="5,92.57,660.07,192.90,8.97"><p>https://huggingface.co/allenai/longformer-base-4096</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgements</head><p><rs type="person">Abu Talha</rs> and <rs type="person">Tanmay Basu</rs> acknowledge the support of the seed funding (<rs type="grantNumber">PPW/R&amp;D/2010006</rs>) provided by <rs type="funder">Indian Institute of Science Education and Research Bhopal, India</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_3wRPGA2">
					<idno type="grant-number">PPW/R&amp;D/2010006</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>SVM) AdaBoost) AdaBoost) P@10 0.40 0.00 0.00 0.00 0.10 1 NDCG@10 0.60 0.00 0.00 0.00 0.10 NDCG@100 0.14 0.02 0.03 0.05 0.10 P@10 0.00 0.00 0.00 0.00 0.00 100 NDCG@10 0.00 0.00 0.00 0.00 0.00 NDCG@100 0.00 0.00 0.00 0.00 0.00 P@10 0.00 0.00 0.00 0.00 0.00 500 NDCG@10 0.00 0.00 0.00 0.00 0.00 NDCG@100 0.00 0.00 0.00 0.00 0.00 P@10 0.00 0.00 0.00 0.00 0.00 1000 NDCG@10 0.00 0.00 0.00 0.00 0.00 NDCG@100 0.00 0.00 0.00 0.00 0.00 and Table <ref type="table" coords="7,136.18,332.72,5.17,10.91">4</ref> [27] respectively show the decision based and ranking based results of five runs on the test corpus as released by the organizers <ref type="bibr" coords="7,305.30,346.27,16.35,10.91" target="#b10">[11]</ref>. The ranking based results of five of our runs are poor as we could not submit results for many stages due to a technical constraint. The decision based results are presented in Table <ref type="table" coords="7,285.67,373.37,4.97,10.91">3</ref> in terms of precision, recall, f-measure, ğ¸ğ‘…ğ·ğ¸ 5 , and ğ¸ğ‘…ğ·ğ¸ 50 , latency ğ‘‡ ğ‘ƒ , latency weighted F1 and speed. It can be see from Table <ref type="table" coords="7,456.48,386.92,5.04,10.91">3</ref> that SVM using entropy based term weighting scheme for bag of words performs best among all five runs, however, this model could not achieve a place among the top five runs of eRisk 2023 in terms of all evaluation techniques. Ada-Boost classifier achieve the best precision and latency ğ‘‡ ğ‘ƒ scores and speed among all the runs in the shared task, but this method could not perform well in terms of recall, f-measure and ERDE. The Longformer model also achieve the best precision score among all the runs in the shared task, but it could not perform well in terms of other evaluation techniques. It can be observed from Table <ref type="table" coords="7,324.67,481.76,5.02,10.91">3</ref> that the precision scores of all five runs are sound, whereas the recall scores are not reasonable. This indicate that our frameworks have produced many false negative cases, that means, many pathological gambling cases are wrongly identified as control group, which is a limitation of the proposed frameworks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>The objective of Task 2 in the eRisk 2023 challenge is to create text-mining tools for the early detection of signs of pathological gambling on social media. In order to achieve this goal, various text mining frameworks have been constructed by using different types of text feature engineering schemes. Based on the experimental results, the Ada-Boost classifier using the bag of words following the conventional TF-IDF weighting scheme performed better than all other runs in the shared tasks in terms of precision. It is worth noting that pre-trained BERT, RoBERTa, and Longformer models were further trained using the given training corpus, which is reasonably small to properly fine-tune necessary parameters. Hence the performance of the transformer-based model is not reasonably well like the classical bag of words model. In the future, we plan to develop transformer-based embeddings from scratch by collecting huge amounts of conversations over social media, which can be further tuned for a downstream task, like pathological gambling. Moreover, none of the proposed frameworks consider the timestamps of individual posts of individual users and hence they could not capture the temporal information of individual conversations, which may be another reason for the poor performance of most of these models. We aim to incorporate the temporal information as an input to be used to train a classification model as a future plan.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="8,112.66,326.16,394.53,10.91;8,112.66,339.71,328.95,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="8,158.73,339.71,80.53,10.91">Gambling disorder</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">N</forename><surname>Potenza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><forename type="middle">M</forename><surname>Balodis</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Derevensky</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><forename type="middle">E</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">M</forename><surname>Petry</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Verdejo-Garcia</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">W</forename><surname>Yip</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,247.45,339.71,141.57,10.91">Nature reviews Disease primers</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">51</biblScope>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,353.26,393.98,10.91;8,112.41,366.81,38.81,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="8,325.29,353.26,99.18,10.91">Pathological gambling</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">N</forename><surname>Potenza</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><forename type="middle">R</forename><surname>Kosten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><forename type="middle">J</forename><surname>Rounsaville</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,434.97,353.26,22.54,10.91">Jama</title>
		<imprint>
			<biblScope unit="volume">286</biblScope>
			<biblScope unit="page" from="141" to="144" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,380.36,393.33,10.91;8,112.66,393.91,257.69,10.91" xml:id="b2">
	<analytic>
		<title level="a" type="main" coord="8,287.15,380.36,218.84,10.91;8,112.66,393.91,38.98,10.91">A review of gambling disorder and substance use disorders</title>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">J</forename><surname>Rash</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Weinstock</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Van Patten</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,159.90,393.91,154.62,10.91">Substance abuse and rehabilitation</title>
		<imprint>
			<biblScope unit="page" from="3" to="13" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,407.46,393.33,10.91;8,112.66,421.01,139.58,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="8,361.08,407.46,144.91,10.91;8,112.66,421.01,22.74,10.91">Predicting depression via social media</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">De</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Gamon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Counts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,148.42,421.01,35.11,10.91">ICWSM</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,434.55,393.33,10.91;8,112.66,448.10,394.53,10.91;8,112.66,461.65,70.43,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="8,291.36,434.55,214.63,10.91;8,112.66,448.10,62.80,10.91">Social media as a measurement tool of depression in populations</title>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">De</forename><surname>Choudhury</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Counts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Horvitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,198.80,448.10,274.60,10.91">Proceedings of the 5th Annual ACM Web Science Conference</title>
		<meeting>the 5th Annual ACM Web Science Conference</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="47" to="56" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,475.20,393.33,10.91;8,112.66,488.75,279.16,10.91" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="8,161.41,475.20,344.58,10.91;8,112.66,488.75,27.30,10.91">Machine learning and natural language processing in mental health: systematic review</title>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="8,148.44,488.75,160.92,10.91">Journal of Medical Internet Research</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page">15708</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,502.30,393.33,10.91;8,112.66,515.85,393.33,10.91;8,112.66,529.40,319.84,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="8,283.28,502.30,222.70,10.91;8,112.66,515.85,52.47,10.91">Overview of erisk 2019: Early risk prediction on the internet</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,193.57,515.85,312.42,10.91;8,112.66,529.40,188.80,10.91">Proceedings of the International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<meeting>the International Conference of the Cross-Language Evaluation Forum for European Languages</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="340" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,542.95,393.33,10.91;8,112.66,556.50,393.33,10.91;8,112.66,570.05,319.84,10.91" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="8,283.28,542.95,222.70,10.91;8,112.66,556.50,52.47,10.91">Overview of erisk 2020: Early risk prediction on the internet</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,193.57,556.50,312.42,10.91;8,112.66,570.05,188.80,10.91">Proceedings of the International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<meeting>the International Conference of the Cross-Language Evaluation Forum for European Languages</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="272" to="287" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="8,112.66,583.60,393.60,10.91;8,112.66,597.15,393.33,10.91;8,112.66,610.69,336.62,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="8,368.45,583.60,82.44,10.91;8,482.17,583.60,24.09,10.91;8,112.66,597.15,136.35,10.91">Early risk prediction on the internet</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Martin-Rodilla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,274.04,597.15,231.95,10.91;8,112.66,610.69,263.46,10.91">Proceedings of the International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<meeting>the International Conference of the Cross-Language Evaluation Forum for European Languages</meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note>Overview of erisk</note>
</biblStruct>

<biblStruct coords="8,112.66,624.24,393.60,10.91;8,112.66,637.79,394.53,10.91;8,112.66,651.34,394.52,10.91;8,112.66,664.89,286.34,10.91" xml:id="b9">
	<analytic>
		<title level="a" type="main" coord="8,368.45,624.24,137.81,10.91;8,112.66,637.79,131.77,10.91">Overview of erisk 2022: Early risk prediction on the internet</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>MartÃ­n-Rodilla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="8,267.13,637.79,240.05,10.91;8,112.66,651.34,389.92,10.91">Proceedings of Experimental IR Meets Multilinguality, Multimodality, and Interaction: 13th International Conference of the CLEF Association</title>
		<meeting>Experimental IR Meets Multilinguality, Multimodality, and Interaction: 13th International Conference of the CLEF Association<address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">September 5-8, 2022. 2022</date>
			<biblScope unit="page" from="233" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,86.97,393.60,10.91;9,112.66,100.52,394.53,10.91;9,112.66,114.06,394.52,10.91;9,112.33,127.61,163.02,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="9,368.45,86.97,137.81,10.91;9,112.66,100.52,131.77,10.91">Overview of erisk 2023: Early risk prediction on the internet</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>MartÃ­n-Rodilla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,267.13,100.52,240.05,10.91;9,112.66,114.06,389.92,10.91">Proceedings of Experimental IR Meets Multilinguality, Multimodality, and Interaction: 14th International Conference of the CLEF Association</title>
		<meeting>Experimental IR Meets Multilinguality, Multimodality, and Interaction: 14th International Conference of the CLEF Association<address><addrLine>Thessaloniki, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,141.16,394.84,10.91" xml:id="b11">
	<monogr>
		<title level="m" type="main" coord="9,215.47,141.16,200.30,10.91">Introduction to Modern Information Retrieval</title>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">J</forename><surname>Mcgill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983">1983</date>
			<publisher>McGraw Hill</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,154.71,393.61,10.91;9,112.66,168.26,395.00,10.91" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="9,293.24,154.71,213.03,10.91;9,112.66,168.26,271.02,10.91">A sentence classification framework to identify geometric errors in radiation therapy from relevant literature</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Goldsworthy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Gkoutos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,391.55,168.26,53.46,10.91">Information</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page">139</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,181.81,394.53,10.91;9,112.66,195.36,172.60,10.91" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="9,210.17,181.81,292.21,10.91">Web page feature selection and classification using neural networks</title>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Selamat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Omatu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,112.66,195.36,93.74,10.91">Information Sciences</title>
		<imprint>
			<biblScope unit="volume">158</biblScope>
			<biblScope unit="page" from="69" to="88" />
			<date type="published" when="2004">2004</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,208.91,394.53,10.91;9,112.66,222.46,393.33,10.91;9,112.66,236.01,134.32,10.91" xml:id="b14">
	<analytic>
		<title level="a" type="main" coord="9,112.66,222.46,328.30,10.91">Modified frequency-based term weighting schemes for text classification</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Sabbah</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Selamat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">H</forename><surname>Selamat</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><forename type="middle">S</forename><surname>Al-Anzi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">H</forename><surname>Viedma</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Krejcar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Fujita</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,449.29,222.46,56.69,10.91;9,112.66,236.01,50.39,10.91">Applied Soft Computing</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="page" from="193" to="206" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,249.56,393.33,10.91;9,112.66,263.11,393.33,10.91;9,112.66,276.66,229.92,10.91" xml:id="b15">
	<analytic>
		<title level="a" type="main" coord="9,219.79,249.56,286.19,10.91;9,112.66,263.11,229.29,10.91">Exploring the performance of baseline text mining frameworks for early prediction of self harm over social media</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><forename type="middle">V</forename><surname>Gkoutos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,375.23,263.11,130.76,10.91;9,112.66,276.66,142.09,10.91">Proceedings of International Conference of CLEF Association</title>
		<meeting>International Conference of CLEF Association</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="928" to="937" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,290.20,395.17,10.91;9,112.66,303.75,393.61,10.91;9,112.66,317.30,394.53,10.91;9,112.66,330.85,394.61,10.91;9,112.41,344.40,338.41,10.91" xml:id="b16">
	<analytic>
		<title level="a" type="main" coord="9,310.13,290.20,197.69,10.91;9,112.66,303.75,393.61,10.91;9,112.66,317.30,389.52,10.91">Nlp-iiserb@erisk2022: Exploring the potential of bag of words, document embeddings and transformer based framework for early prediction of eating disorder, depression and pathological gambling over social media</title>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Srivastava</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><forename type="middle">S</forename><surname>Lijin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Sruthi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Basu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,127.18,330.85,380.09,10.91;9,112.41,344.40,242.04,10.91">Proceedings of Experimental IR Meets Multilinguality, Multimodality, and Interaction: 13th International Conference of the CLEF Association</title>
		<meeting>Experimental IR Meets Multilinguality, Multimodality, and Interaction: 13th International Conference of the CLEF Association<address><addrLine>Bologna, Italy</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,357.95,393.33,10.91;9,112.66,371.50,363.59,10.91" xml:id="b17">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M.-W</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Toutanova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Bert</forename></persName>
		</author>
		<idno type="arXiv">arXiv:1810.04805</idno>
		<title level="m" coord="9,353.43,357.95,152.55,10.91;9,112.66,371.50,181.08,10.91">Pre-training of deep bidirectional transformers for language understanding</title>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,385.05,393.59,10.91;9,112.66,398.60,146.44,10.91" xml:id="b18">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Beltagy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">E</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Cohan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2004.05150</idno>
		<title level="m" coord="9,268.64,385.05,203.75,10.91">Longformer: The long-document transformer</title>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,412.15,393.33,10.91;9,112.66,425.70,107.17,10.91" xml:id="b19">
	<monogr>
		<author>
			<persName coords=""><forename type="first">Y</forename><forename type="middle">E A</forename><surname>Liu</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1907.11692</idno>
		<title level="m" coord="9,169.78,412.15,258.99,10.91">Roberta: A robustly optimized bert pretraining approach</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,439.25,393.61,10.91;9,112.66,452.79,179.74,10.91" xml:id="b20">
	<analytic>
		<title level="a" type="main" coord="9,249.42,439.25,140.03,10.91">A short introduction to boosting</title>
		<author>
			<persName coords=""><forename type="first">Y</forename><surname>Freund</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Schapire</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">N</forename><surname>Abe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,397.86,439.25,108.41,10.91;9,112.66,452.79,111.93,10.91">Journal-Japanese Society For Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">1612</biblScope>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,466.34,393.33,10.91;9,112.66,479.89,303.29,10.91" xml:id="b21">
	<analytic>
		<title level="a" type="main" coord="9,205.22,466.34,300.77,10.91;9,112.66,479.89,55.98,10.91">Support vector machine active learning with applications to text classification</title>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,176.56,479.89,170.67,10.91">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="45" to="66" />
			<date type="published" when="2001">2001</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,493.44,393.33,10.91;9,112.66,506.99,149.50,10.91" xml:id="b22">
	<monogr>
		<author>
			<persName coords=""><forename type="first">C</forename><forename type="middle">D</forename><surname>Manning</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Raghavan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Schutze</surname></persName>
		</author>
		<title level="m" coord="9,290.59,493.44,160.79,10.91">Introduction to Information Retrieval</title>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,520.54,393.71,10.91;9,112.66,534.09,393.32,10.91;9,112.66,547.64,300.88,10.91" xml:id="b23">
	<monogr>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Kalyan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Jayaswal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Goyal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Pettifer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><forename type="middle">R</forename><surname>Jonnalagadda</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1606.06424</idno>
		<title level="m" coord="9,498.63,520.54,7.73,10.91;9,112.66,534.09,393.32,10.91;9,112.66,547.64,118.55,10.91">A novel framework to expedite systematic reviews by automatically building information extraction training corpora</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="9,112.66,561.19,394.53,10.91;9,112.66,574.74,342.82,10.91" xml:id="b24">
	<analytic>
		<title level="a" type="main" coord="9,199.57,561.19,303.32,10.91">A supervised term selection technique for effective text categorization</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Murthy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="9,112.66,574.74,263.96,10.91">International Journal of Machine Learning and Cybernetics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="877" to="892" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,588.29,393.33,10.91;9,112.66,601.84,393.33,10.91;9,112.66,615.39,152.07,10.91" xml:id="b25">
	<analytic>
		<title level="a" type="main" coord="9,237.35,588.29,268.63,10.91;9,112.66,601.84,12.86,10.91">A test collection for research on depression and language use</title>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,148.34,601.84,357.65,10.91;9,112.66,615.39,44.89,10.91">International Conference of the Cross-Language Evaluation Forum for European Languages</title>
		<imprint>
			<publisher>CLEF</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="28" to="39" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="9,112.66,628.93,393.33,10.91;9,112.66,642.48,393.33,10.91;9,112.66,656.03,168.28,10.91" xml:id="b26">
	<analytic>
		<title level="a" type="main" coord="9,349.17,628.93,21.30,10.91;9,398.47,628.93,107.52,10.91;9,112.66,642.48,188.88,10.91">Depression, pathological gambling, and eating disorder challenges</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Parapar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>MartÃ­n-Rodilla</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Crestani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="9,332.13,642.48,173.85,10.91;9,112.66,656.03,38.01,10.91">European Conference on Information Retrieval</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023. 2023</date>
			<biblScope unit="page" from="585" to="592" />
		</imprint>
	</monogr>
	<note>erisk</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
