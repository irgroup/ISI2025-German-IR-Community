<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,403.99,15.42;1,89.29,106.66,394.42,15.42;1,89.29,129.00,220.08,11.96">Extended Overview of the CLEF-2023 LongEval Lab on Longitudinal Evaluation of Model Performance Notebook for the LongEval Lab at CLEF 2023</title>
				<funder ref="#_Yew6PKG">
					<orgName type="full">Austrian Science Fund (FWF</orgName>
				</funder>
				<funder ref="#_Fk5g2yA">
					<orgName type="full">Agence Nationale de la Recherche</orgName>
					<orgName type="abbreviated">ANR</orgName>
				</funder>
				<funder ref="#_ZVcaKHf">
					<orgName type="full">The Alan Turing Institute</orgName>
				</funder>
				<funder ref="#_faQV25B #_WBt5Gyh">
					<orgName type="full">Ministry of Education, Youth and Sports of the Czech Republic</orgName>
				</funder>
				<funder ref="#_jg4f9f8">
					<orgName type="full">UKRI/EPSRC Turing</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,154.90,77.77,11.96"><forename type="first">Rabab</forename><surname>Alkhalifa</surname></persName>
							<email>raalkhalifa@iau.edu.sa</email>
							<affiliation key="aff0">
								<orgName type="institution">Queen Mary University of London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Imam Abdulrahman Bin Faisal University</orgName>
								<address>
									<country>SA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,196.49,154.90,49.97,11.96"><forename type="first">Iman</forename><surname>Bilal</surname></persName>
							<email>iman.bilal@warwick.ac.uk</email>
							<affiliation key="aff2">
								<orgName type="institution">University of Warwick</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,264.63,154.90,89.96,11.96"><forename type="first">Hsuvas</forename><surname>Borkakoty</surname></persName>
							<email>borkakotyh@cardiff.ac.uk</email>
							<affiliation key="aff3">
								<orgName type="institution">Cardiff University</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,372.76,154.90,114.84,11.96"><forename type="first">Jose</forename><surname>Camacho-Collados</surname></persName>
							<email>camachocolladosj@cardiff.ac.uk</email>
							<affiliation key="aff3">
								<orgName type="institution">Cardiff University</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,168.85,83.35,11.96"><forename type="first">Romain</forename><surname>Deveaud</surname></persName>
							<email>r.deveaud@qwant.com</email>
							<affiliation key="aff4">
								<orgName type="institution">Alan Turing Institute</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,196.79,168.85,78.71,11.96"><forename type="first">Alaa</forename><surname>El-Ebshihy</surname></persName>
							<email>alaa.el-ebshihy@tuwien.ac.at</email>
							<affiliation key="aff8">
								<orgName type="department">Data Science Studio</orgName>
								<orgName type="institution">Research Studios Austria</orgName>
								<address>
									<settlement>Vienna</settlement>
								</address>
							</affiliation>
							<affiliation key="aff9">
								<orgName type="institution">AT</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,293.67,168.85,96.80,11.96"><forename type="first">Luis</forename><surname>Espinosa-Anke</surname></persName>
							<email>espinosa-ankel@cardiff.ac.uk</email>
							<affiliation key="aff3">
								<orgName type="institution">Cardiff University</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff12">
								<orgName type="laboratory">AMPLYFI</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,182.79,114.70,11.96"><forename type="first">Gabriela</forename><surname>Gonzalez-Saez</surname></persName>
							<email>gabriela-nicole.gonzalez-saez@univ-grenoble-alpes.fr</email>
							<affiliation key="aff6">
								<orgName type="laboratory">Grenoble INP</orgName>
								<orgName type="institution" key="instit1">Univ. Grenoble Alpes</orgName>
								<orgName type="institution" key="instit2">CNRSInstitute of Engineering Univ. Grenoble Alpes.)</orgName>
								<orgName type="institution" key="instit3">LIG</orgName>
								<address>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,222.15,182.79,90.36,11.96"><forename type="first">Petra</forename><surname>Galu≈°ƒç√°kov√°</surname></persName>
							<email>petra.galuscakova@univ-grenoble-alpes.fr</email>
							<affiliation key="aff6">
								<orgName type="laboratory">Grenoble INP</orgName>
								<orgName type="institution" key="instit1">Univ. Grenoble Alpes</orgName>
								<orgName type="institution" key="instit2">CNRSInstitute of Engineering Univ. Grenoble Alpes.)</orgName>
								<orgName type="institution" key="instit3">LIG</orgName>
								<address>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,336.66,182.79,88.23,11.96"><forename type="first">Lorraine</forename><surname>Goeuriot</surname></persName>
							<email>lorraine.goeuriot@univ-grenoble-alpes.fr</email>
							<affiliation key="aff6">
								<orgName type="laboratory">Grenoble INP</orgName>
								<orgName type="institution" key="instit1">Univ. Grenoble Alpes</orgName>
								<orgName type="institution" key="instit2">CNRSInstitute of Engineering Univ. Grenoble Alpes.)</orgName>
								<orgName type="institution" key="instit3">LIG</orgName>
								<address>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,196.74,76.43,11.96"><forename type="first">Elena</forename><surname>Kochkina</surname></persName>
							<email>e.kochkina@qmul.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">Queen Mary University of London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">Alan Turing Institute</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,189.17,196.74,67.48,11.96"><forename type="first">Maria</forename><surname>Liakata</surname></persName>
							<email>m.liakata@qmul.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">Queen Mary University of London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of Warwick</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="institution">Alan Turing Institute</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,285.37,196.74,77.05,11.96"><forename type="first">Daniel</forename><surname>Loureiro</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">Cardiff University</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,380.59,196.74,84.26,11.96"><forename type="first">Philippe</forename><surname>Mulhem</surname></persName>
							<email>philippe.mulhem@imag.fr</email>
							<affiliation key="aff6">
								<orgName type="laboratory">Grenoble INP</orgName>
								<orgName type="institution" key="instit1">Univ. Grenoble Alpes</orgName>
								<orgName type="institution" key="instit2">CNRSInstitute of Engineering Univ. Grenoble Alpes.)</orgName>
								<orgName type="institution" key="instit3">LIG</orgName>
								<address>
									<settlement>Grenoble</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,210.69,60.66,11.96"><forename type="first">Florina</forename><surname>Piroi</surname></persName>
							<email>lorina.piroi@researchstudio.at</email>
							<affiliation key="aff8">
								<orgName type="department">Data Science Studio</orgName>
								<orgName type="institution">Research Studios Austria</orgName>
								<address>
									<settlement>Vienna</settlement>
								</address>
							</affiliation>
							<affiliation key="aff9">
								<orgName type="institution">AT</orgName>
							</affiliation>
						</author>
						<author>
							<persName coords="1,168.09,210.69,63.29,11.96"><forename type="first">Martin</forename><surname>Popel</surname></persName>
							<email>popel@ufal.mff.cuni.cz</email>
							<affiliation key="aff10">
								<orgName type="institution">Charles University</orgName>
								<address>
									<settlement>Prague</settlement>
									<country key="CZ">Czech Republic</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,253.05,210.69,90.32,11.96"><forename type="first">Christophe</forename><surname>Servan</surname></persName>
							<email>c.servan@qwant.com</email>
							<affiliation key="aff5">
								<address>
									<settlement>Qwant</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
							<affiliation key="aff11">
								<orgName type="institution" key="instit1">Paris-Saclay University</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<address>
									<region>LISN</region>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,370.33,210.69,126.10,11.96"><forename type="first">Harish</forename><forename type="middle">Tayyar</forename><surname>Madabushi</surname></persName>
							<affiliation key="aff7">
								<orgName type="institution">University of Bath</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,113.26,224.64,79.02,11.96"><forename type="first">Arkaitz</forename><surname>Zubiaga</surname></persName>
							<email>zubiaga@qmul.ac.uk</email>
							<affiliation key="aff0">
								<orgName type="institution">Queen Mary University of London</orgName>
								<address>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,403.99,15.42;1,89.29,106.66,394.42,15.42;1,89.29,129.00,220.08,11.96">Extended Overview of the CLEF-2023 LongEval Lab on Longitudinal Evaluation of Model Performance Notebook for the LongEval Lab at CLEF 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">450E2D50836F2AF68334C0FD46DC4FD1</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Evaluation</term>
					<term>Temporal Persistence</term>
					<term>Temporal Generalisability</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We describe the first edition of the LongEval CLEF 2023 shared task. This lab evaluates the temporal persistence of Information Retrieval (IR) systems and Text Classifiers. Task 1 requires IR systems to run on corpora acquired at several timestamps, and evaluates the drop in system quality (NDCG) along these timestamps. Task 2 tackles binary sentiment classification at different points in time, and evaluates the performance drop for different temporal gaps. Overall, 37 teams registered for Task 1 and 25 for Task 2. Ultimately, 14 and 4 teams participated in Task 1 and Task 2, respectively.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="22" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="23" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Time is a dimension that is often overlooked when conducting Information Retrieval (IR) experiments, especially when static data sets are utilized. Some data sets, like CORD19, are collected at different points in time, showing differences in the set of documents from one collection time to another. Recent research <ref type="bibr" coords="2,295.78,151.93,13.00,10.91" target="#b0">[1]</ref> has demonstrated models trained on data pertaining to a particular time period struggle to keep their performance levels when applied on test data that is distant in time.</p><p>With the aim of tackling this challenge of making models have persistent quality over time, the objective of the LongEval lab is twofold: (i) to explore the extent to which temporal differences over time, as reflected in the evolution of evaluation datasets, results in the deterioration of the performance of information retrieval and classification systems, and (ii) to propose improved methods that mitigate performance drop by making models more robust over time.</p><p>The LongEval lab <ref type="bibr" coords="2,179.88,260.32,12.73,10.91" target="#b1">[2]</ref> took place as part of the Conference and Labs of the Evaluation Forum (CLEF) 2023, and consisted in two separate tasks: (i) Task 1, focused on information retrieval, and (ii) Task 2, focused on text classification for sentiment analysis. Both tasks provided labeled datasets enabling analysis and evaluation of models over longitudinally evolving data.</p><p>In this paper, we add details to <ref type="bibr" coords="2,236.71,314.52,11.29,10.91" target="#b1">[2]</ref>, by focusing on the datasets statistics, and on analysing in details the overal partyicipant runs and results for each task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Task 1 -Retrieval</head><p>The goal of the retrieval task is to explore the effect of changes in datasets on retrieval of text documents. More specifically, we focus on a setup in which the datasets are evolving. This means, that one dataset can be acquired from another by adding, removing (and replacing) a limited number of documents and queries. We explore two main scenarios and the setup of the task thus reflects the details of these two problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A single system in an evolving setup</head><p>We explore how one selected system behaves if we evaluate it using several collections, which evolve along the time. Specifically, we explore the effect of changes in datasets on retrieval performances in a Web search domain. In this domain, the documents, queries and also the perception of relevance naturally continuously evolves and Web search engines need to deal with this situation. The evaluation in this scenario is thus very specific and should take into account the evolving nature of the data. Evaluation should ideally reflect the changes in the collection and especially signal substantial changes that could lead to performance drop.This would allow to re-train the search engine model then and only when it is really necessary, and enable much more efficient overall training.</p><p>This problem emerges also with the popularity of neural networks. The stability of the performance of the neural networks seems to be lower than in the case of the statistical model. Moreover, the performance strongly depends on the data used for training the neural model. One objective of the task is to explore the behavior of the neural system in the evolving data scenario.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison of multiple systems in an evolving setup</head><p>While in the first point, we explore a single system, comparison of this systems with multiple systems across evolving collections, should provide more information about systems stability and robustness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Description of the task</head><p>The task datasets were created over sequential time periods, which allows doing observations at different time stamps ùë°, and most importantly, comparing the performance across different time stamps ùë° and ùë° ‚Ä≤ . Two sub-tasks are organized as follows: A) Short-term (ST) Persistence task that aim to assess the performance difference between ùë° and ùë° ‚Ä≤ when ùë° ‚Ä≤ occurs right after or shortly after ùë° B) Long-term (LT) Persistence task that aim to examine the performance difference between two ùë° and ùë° ‚Ä≤‚Ä≤ , when ùë° ‚Ä≤‚Ä≤ occurs several months after ùë° (and thus |ùë° ‚Ä≤‚Ä≤ -ùë°| &gt; |ùë° ‚Ä≤ -ùë°|). In addition to this, we provide Within-time (WT) dataset, which contains the same documents (but different queries) as the training data. This data are used as a control group and applied to measure a change against the training data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Dataset</head><p>Data for this task were provided by the French search engine Qwant. They consist of the queries issued by the users of this search engine, cleaned Web documents, which were 1) selected to correspond to the queries, and 2) to add additional noise, and relevance judgments, which were created using a click model. The dataset is fully described in Galu≈°ƒç√°kov√° et al. <ref type="bibr" coords="3,432.59,389.54,11.39,10.91" target="#b2">[3]</ref>. We provided training data, which included 672 train queries, with corresponding 9,656 assessments and 1,570,734 Web pages. In addition to this, the training data included the 98 heldout WT queries. All training and heldout data were collected during June 2022. Test data were split into two collections, each corresponding to a single sub-task. The data for the short-term persistence sub-task was collected over July 2022 and this dataset contains 1,593,376 documents and 882 queries. The data for the long-term persistence sub-task was collected over September 2022 and this dataset consists of 1,081,334 documents and 923 queries. All the datasets are freely available at Lindat/Clarin. The data we collected is mostly in French therefore, to help participants, the LongEval data set for the Retrieval task also contains automatic translations into English of both queries and documents. The document and query overlap ratios between the collections is given by Table <ref type="table" coords="3,480.60,656.03,5.17,10.91" target="#tab_0">1</ref> and Table <ref type="table" coords="3,115.37,669.58,3.67,10.91" target="#tab_1">2</ref>. Queries for the Heldout collections were selected not to overlap with the Train queries and the these two collections share all the documents. The overlap between the Heldout/Train collection is surprisingly high, especially in terms of documents.</p><p>To evaluate the submissions we use two different sets of relevance judgments: a) the judgments acquired by the click model, based on the raw clicks of the users; and b) manual relevance judgment on a pooled query subset. As the manual evaluations are ongoing, in this paper we only report the relevance judgments acquired from the click model. For evaluating both subtasks, we use the NDCG measure (calculated for each dataset), as well as the drop between the ST and LT collection against the training data (WT collection).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Submissions</head><p>14 teams submitted their systems to the Retrieval task. 12 of these teams submitted the results into both Short-term and Long-term retrieval sub-tasks, two teams only submitted the results for the Short-term retrieval sub-tasks. As per the requirements, all participating teams needed to submit their systems also on the within-time dataset, which was created at the same dataframe as the training data, which allows measuring relative drop between the datasets. All teams, except one, which submitted 4 systems, decided to submit 5 systems. Together, with 4 baseline runs provided by the Universit√© Grenoble Alpes (marked as UGA), this creates a pool of 73 systems available on the within-time (WT, corresponding to the Heldout queries runs on the Train corpus) and short-term (ST) collections and 63 systems available on the long-term collection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Absolute Scores</head><p>Table <ref type="table" coords="4,117.18,501.21,5.17,10.91">3</ref> gives the overview of NDCG and MAP scores for each submitted run on different datasets (WT, ST, LT). For each run, the columns of the table indicate which language was used (English, French, or both), whether any neural approach was involved (values yes/no), and whether a single or a combination of several approaches was used (values yes/no). We show NDCG score histograms for these runs, in decreasing order, for each dataset, showing whether a run uses any neural approach (green for yes, yellow for no) in Figure <ref type="figure" coords="4,404.70,568.96,3.71,10.91" target="#fig_1">1</ref>, and whether the run uses a combination of more than a single approach (orange for yes, cyan for no) in Figure <ref type="figure" coords="4,483.44,582.51,3.67,10.91">2</ref>, for both WT and ST collections. This information was acquired from the participants through a questionnaire the participants had to fill for each submitted run. Figure <ref type="figure" coords="4,399.96,609.61,4.97,10.91">3</ref> shows which language each made use of.</p><p>From Table <ref type="table" coords="4,154.55,636.71,5.17,10.91">3</ref> we see that the systems which did best for the WT data are also among the top for the ST and LT datasets. For instance, the best system on WT, according to the NDCG measure, (FADERIC_Fr-BM25-S50-LS-S-F-SC-R20W6), is ranked best also on ST, and considering    the systems that obtained a non-zero evaluation for the two tasks, the best system considering NDCG on WT, SQUID_SEARCHERAI, is also the best on ST and LT datasets. This finding does not hold for the MAP measures: considering the systems that participated to the two tasks, the best system for MAP in WT, CLOSE_SBERT_BM25, is the second best on the ST dataset and the fourth best on the LT dataset. An explanation may come from the fact that the NDCG emphasizes on the top ranked documents of the runs.</p><p>We describe now the methods used in the top-3 runs, according to the NDCG evaluation measure, for each WT, ST and LT. For the WT Dataset Heldout queries, the top systems are:</p><p>1. CLOSE_SBERT_BM25 from the CLOSE team: The system uses query variant generated from GPT using dedicated prompts, and applies sentence BERT to rerank the initial BM25 results. 2. gwca_lightstem-phrase-qexp from de GWCA team: this systems uses a French stoplist and stemmer, a query expression is composed of the original text, phrases extracted from the query, and text generated using GPT 3.5. 3. SQUID_SEARCHERAI from the Squid team: this systems relies on Lucene indexing and searcher on French documents and queries. It uses several fields for the documents (title/url/body) with different boost values, and expands the queries with synonyms from GPT 3.5.</p><p>For the ST Dataset, the top-3 systems are:</p><p>1. FADERIC_Fr-BM25-S50-LS-S-F-SC-R20W6 from the FADERIC team. The matching is based on BM25, fine-tuned on the training set. The query processing use the Lucene fuzzy matching, able to allow partial match of words, and integrate synomyms expansion.</p><p>A reranking fuses linearly the BM25 scores and BERT for the 20 top BM25 documents. Though the runs from the FADERIC team achieve the highest NDCG scores on the ST collection, unfortunately the scores achieved on the LT collection is zero, presumably due to an error. 2. FADERIC_Fr-BM25-S50-LS-S-F-R30 from the FADERIC team. This run is similar to the one above, the differences rely on the number of document reranked (here 30) and a different weight of BM25 score in the linear combination. 3. SQUID_SEARCHERAI from the Squid team, already described above.</p><p>For the LT Dataset, the top-3 systems are:</p><p>1. CLOSE_SBERT_BM25 from the CLOSE team, already described; 2. SQUID_W2V from the Squid team: this system relies on Lucene indexing and searcher on french documents and queries. It uses several fields for the documents (title/url/body) with different boost values, and expands the queries with word2Vec similar terms. 3. SQUID_SEARCHERAI from the Squid team, already described above. Thus, the best approaches all rely to some extent on query expansion techniques, and integrate at one point or another embeddings or Large Language Models. The best results use French documents and queries. The effect of the translation provided by the lab has a clear impact. This remark is exemplified by the UGA baselines: the UGA_BM25_French outperforms the UGA_BM25_English default, and similarly the reranking using T5 French run (UGA_T5_French) outperforms its English counterpart (UGA_T5_English).</p><p>Considering the Figures <ref type="figure" coords="6,206.81,609.97,4.97,10.91">2</ref> and<ref type="figure" coords="6,232.81,609.97,3.66,10.91">3</ref>, we see that the shape of the distribution of the NDCG values are similar for the WT and ST datasets. However, the best systems have higher performances on WT than on ST: 13 runs on the WT dataset are above 0.4, while only 7 on the ST dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5.">Changes in the Scores</head><p>The main part of the task is to see the changes in the scores between the collections. All collections were created using the same approach and procedure and have a high overlap in terms of both queries and documents. In Table <ref type="table" coords="8,301.17,134.63,3.78,10.91" target="#tab_2">4</ref>, we thus provide the relative drops between the collections ST and WT and between the collections LT and WT. The definition of the value "WT-ST" NDCG change is defined, for a run ùëü as:</p><formula xml:id="formula_0" coords="8,249.75,181.96,95.77,17.76">NDCG ùëä ùëá (ùëü)-NDCG ùëÜùëá (ùëü) NDCG ùëä ùëá (ùëü)</formula><p>For "WT-LT" the formula is:</p><formula xml:id="formula_1" coords="8,249.64,227.46,95.99,17.76">NDCG ùëä ùëá (ùëü)-NDCG ùêøùëá (ùëü) NDCG ùëä ùëá (ùëü)</formula><p>With such definitions, large negative values for columns "WT-ST" and "WT-LT" mean that the systems are able to generalize well on the new test collections, as the WT heldout queries are processed on the same document corpus as the training data, which is not the case of the ST and LT datasets.</p><p>What we see in Table <ref type="table" coords="8,204.24,308.32,5.17,10.91" target="#tab_2">4</ref> is that the systems that are the more robust to the evolution of test collection are not the top ones: for instance the NEON_3b run is almost at the bottom on Table <ref type="table" coords="8,116.72,335.42,5.17,10.91" target="#tab_3">5</ref> but does increase its NDCG values at ST, as well as at LT. We also see that the best systems according to NDCG at ST, FADERIC_Fr-BM25-S50-LS-S-F-SC-R20W6, FADERIC_Fr-BM25-S50-LS-S-F-R30 and SQUID_SEARCHERAI, are stable or decreasing their NDCG values at ST.</p><p>On average (last line of Table <ref type="table" coords="8,237.13,389.61,3.65,10.91" target="#tab_2">4</ref>), the systems increase less their results on ST than on LT, which is surprising. This surprising point will need further explorations as it looks contradictory to what we were expecting, as there are more differences between WT and LT than between ST and WT datasets (see Tables <ref type="table" coords="8,235.21,430.26,5.17,10.91" target="#tab_0">1</ref> and<ref type="table" coords="8,262.70,430.26,3.65,10.91" target="#tab_1">2</ref>). Another element worth noticing is that the NDCG changes WT-ST and WT-LT behave consistently: for most of the systems the absolute value for WT-ST is smaller than the absolute value of WT-LT.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6.">Run Rankings</head><p>We have so far studied our first problem, which was a comparison of performance of a single system in an evolving setup. Next, we would like to study how do the submitted runs compare to each other, either in terms of the absolute NDCG scores achieved on the collections, or in terms of NDCG changes between the collections. For this, we display the ranking of runs according in all these tasks, see Table <ref type="table" coords="8,211.70,561.19,3.74,10.91" target="#tab_3">5</ref>.</p><p>In addition, we also calculated the Pearson correlation between the rankings. The correlation between the rankings (in terms of NDCG scores) achieved on WT and ST is very high (0.95). The correlation between both WT and ST and between ST and LT rankings is slightly lower -0.71 and 0.70, respectively. This corresponds with the high overlaps of the documents and also queries between WT and ST collections and slightly smaller overlaps of the LT collection.</p><p>The correlation between the ranking according to the NDCG score achieved on the WT dataset and the ranking of the performance change is negative. The Pearson correlation is -0.65 for the ST dataset and -0.51 on the LT dataset. This means that the better the system initially  performs, harder it is to improve it. Not surprisingly, there is thus also a negative correlation between the ranking achieved on the ST dataset and the ranking of the change between the ST and WT dataset (-0.42). However, there is no such correlation (0.05) between the ranking achieved on the LT dataset and ranking of the change between the WT and LT datasets. We also provided the normalized results to the participants. The normalization was done according to Urbano et al. <ref type="bibr" coords="11,203.46,154.71,12.84,10.91" target="#b3">[4]</ref> and the mean and standard deviation of the scores of all submitted runs were calculated. These scores were then used to calculate the score in normal distribution and this score was subsequently shifted using CDF into 0-1 space. However, the correlation of the original ranking and ranking according to the normalized values is highly correlated: 0.93, 0.95, and 0.88 for WT, ST and LT datasets, respectively. We thus further do not work with the normalized results.</p><p>Last, we calculated a combination of both rankings (ranking in terms of absolute values and ranking in terms of change). For this, we first calculated a Borda count of the ranking in terms of absolute values and Borda count of the ranking in terms of relative change and then we simply summed these two Borda counts: these results are displayed in two last columns in the Table <ref type="table" coords="11,133.32,290.20,3.76,10.91" target="#tab_3">5</ref>. As the correlation between the absolute performance and performance change is negative, the best performing runs in terms of this measure are often mediocre in one measure and well performing in the another -for instance seupd2223-hiball_BERT run achieves high performance change, while it is mediocre in terms of NDCG achieved on ST dataset.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7.">Queries Overview</head><p>We further investigate performance on the provided queries. Due to the space reason, we only investigate the queries in WT dataset, but these queries should be also well representative for the full collection, what is also confirmed by the overlap with other query sets (see Table <ref type="table" coords="11,487.15,407.68,3.57,10.91" target="#tab_1">2</ref>).</p><p>Overview of the scores achieved for the queries in the WT collection is displayed in Figure <ref type="figure" coords="11,500.33,421.23,3.67,10.91" target="#fig_4">4</ref>. The figure shows minimum performance (by any submitted run), 25%, quantile, 75% quantile and the maximum achieved NDCG score. Due to a relatively large number of runs, the range of the scores achieved is typically quite large and for some of the queries it even ranges between 0 and 1. The high diversity of the achieved scores might be even pronounced by that around half of the runs use their original French version, while the second half uses the English translations (some of them use both). Some of the worst performing queries are very general (the police, taxes, test car, Office) and can thus be expected to be ambiguous. Two worst performing queries (Purple Potato and gateau mascarpone) do not have any relevant documents in the qrels. As the number of relevant documents is relatively similar for all the queries in the heldout collection (between 2 and 8), the qrels have a limited effect on the hardness of the query. There are 2 queries with more than 10 relevant documents in the collection (potato salad, and emeraude space) and though they are in the top 30 of the easiest queries, neither of them is in the top 15 easiest queries. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.8.">Manual relevance judgments acquisition</head><p>The official evaluation results of LongEVal IR task rely on automatic assessments generated from clic models <ref type="bibr" coords="12,168.55,422.08,11.59,10.91" target="#b2">[3]</ref>. However, in a second step, it was decided to acquire classical manual relevance judgments.</p><p>To do that, we used the open source Doctag annotation tool <ref type="bibr" coords="12,370.69,449.17,12.89,10.91" target="#b4">[5]</ref> on a sample of 150 queries: we selected randomly 50 queries from each of the test sets (heldout, short term and long term queries). Doctag provides a customizable and portable platform specifically designed for Information Retrieval (IR) evaluation. To perform manual relevance judgments using Doctag, annotators utilize its web-based interface. They access the tool and interact with its annotation functionalities, including the assignment of labels to indicate document relevance to specific queries. Annotators view the documents and associate appropriate relevance labels (Fig. <ref type="figure" coords="12,484.53,530.47,3.57,10.91" target="#fig_5">5</ref>).</p><p>The documents annotated come from a pooling of the participants runs <ref type="bibr" coords="12,407.83,544.02,11.28,10.91" target="#b5">[6]</ref>. For the annotation to remain tractable, we conducted a stratified sampling and selected 150 queries for evaluation: all documents retrieved by any of the 63 systems among top 5 documents, 50% of top 5-10 and 25% of top 10-30, are respectively assessed by the annotators. 19,678 documents from the original dataset were then assessed. The average number of assessments per query is around 130. To perform the manual annotation and assess document relevance for the corresponding queries, we assigned subsets of the document dataset to a team of 37 annotators. To ensure an efficient workflow, we set up 10 dedicated online servers where Doctag was deployed. Each annotator was assigned to a specific server to perform the annotation tasks. This distributed setup allowed for parallel processing, enabling annotators to work simultaneously and collaborate effectively within their assigned subsets.</p><p>In the course of the ongoing annotation process applied to the dataset under examination, we have currently recorded an aggregate of 14,953 judgments. These judgments span across four distinct categories: 'Relevant', 'Not Relevant', 'Partially Relevant', and 'I Don't Know'. Preliminary analysis of the data indicates a propensity among annotators to categorize the query-document pairs predominantly in the 'Not Relevant' category. Figure <ref type="figure" coords="13,441.76,334.24,5.17,10.91" target="#fig_6">6</ref> presents the judgment distribution for the top 30 queries in terms of document count. What we see in the Figure <ref type="figure" coords="13,120.50,361.34,5.10,10.91" target="#fig_6">6</ref> is that the number of relevant documents is very large for some queries (with a peak over 100 relevant documents), even larger that the non-relevant documents. This large number of relevant documents is much larger than the threshold considered for the selection of queries from the clic model <ref type="bibr" coords="13,176.15,401.98,11.28,10.91" target="#b2">[3]</ref>. The impact of such differences on the evaluations will be studied before the LongEval Workshop at CLEF.</p><p>Further evaluation rounds utilizing the collected data are currently in progress, and the full implications of these results will become more apparent upon the completion of the evaluation process. We will utilize the annotated documents and relevance annotations from the queries to construct one aggregated ùëÑùëüùëíùëô file. With this Qrel file, we will run the evaluation using trec_eval<ref type="foot" coords="13,129.72,481.52,3.71,7.97" target="#foot_0">1</ref> on the participants runs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.9.">Discussion and conclusion</head><p>This task was a first attempt at collectively investigate the impact of the evolution of the data on search system's performances. Having 14 participating teams submitting runs confirmed that this topic was of interest to the community.</p><p>The dataset released for this task consisted in a sequence of test collections corresponding to different times. The collections were composed of documents and queries coming from Qwant, and relevance judgment coming from a click model and manual assessment. While the manual assessment is ongoing at the time of the paper's publication, performances of participants' submitted runs were measured using the click logs.</p><p>The results show that the best approaches were based on query expansion techniques, and embeddings or Large Language Models. The effect of the translation of the documents and queries provided by the lab has a clear impact: the best results were obtained on the original French data.</p><p>Since each subset had substantial overlaps, the correlations between systems rankings was pretty high. As for the robustness of the systems towards dataset changes, we observed that the systems that are the more robust to the evolution of test collection were not the best performing ones.</p><p>Further evaluations will be carried out in the near future with the manual assessment of the pooled sets. A thorough analysis of the results will be necessary to study the impact of queries on the results (their nature, topic, difficulty, etc.). Further analysis work will be necessary to fully establish the robustness of the systems and the specific impact of dataset evolution on the performances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Task 2 -Classification</head><p>As the meanings of words and phrases evolve over time, sentiment classifiers may struggle to accurately capture the changing linguistic landscape <ref type="bibr" coords="15,322.04,124.83,11.31,10.91" target="#b6">[7]</ref>, resulting in decreased effectiveness in capturing sentiments expressed in text. Recent research shows that this is particularly the case when one is dealing with social media data <ref type="bibr" coords="15,283.54,151.93,11.44,10.91" target="#b7">[8]</ref>. Understanding the extent of this performance drop and its implications is crucial for maintaining accuracy and reliable sentiment analysis models in the face of linguistic drift. The objective of this task aimed to quantitatively measure the performance degradation of sentiment classifiers over time, providing insights into the impact of language evolution on sentiment analysis tasks and identifying strategies to mitigate the effects of temporal dynamics. Participants of this task were invited to submit classification outputs of their systems that attempted to mitigate the temporal performance drop.</p><p>The aim of Task 2 was ultimately to answer the following research questions:</p><p>‚Ä¢</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RQ1: What types of models offer better short-term temporal persistence? ‚Ä¢ RQ2: What types of models offer better long-term temporal persistence? ‚Ä¢ RQ3: What types of models offer better overall temporal persistence?</head><p>To assess the extent of the performance drop of models in shorter and longer temporal gaps, we provided training data pertaining to a specific year (2016), as well as test datasets pertaining to a close (2018) and a more distant (2021) year. In addition to measuring performance in each of these years separately, this setup enabled evaluating relative performance drops by comparing performance across years.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Description of the task</head><p>In this section, we introduce the task of temporal persistence classification, as the focus of a recent shared task <ref type="bibr" coords="15,183.94,439.08,11.58,10.91" target="#b8">[9]</ref>. The goal of this task was to develop classifiers that can effectively mitigate performance drops over short and long periods of time compared to a test set from the same time frame as the training data.</p><p>The shared task was in turn divided into two sub-tasks: Sub-Task 1: Short-Term Persistence: In this sub-task, participants were asked to develop models that demonstrated performance persistence over short periods of time. Specifically, the performance of the models was expected to be maintained within a temporal gap of two years between the training and test data.</p><p>Sub-Task 2: Long-Term Persistence: This sub-task focused on developing models that demonstrated performance persistence over a longer period of time. The classifiers were expected to mitigate performance drops over a temporal gap of five years between the training and test data.</p><p>By providing a comprehensive training dataset, two practice sets, and three testing sets, the shared competition aimed to stimulate the development of classifiers that can effectively handle temporal variations and maintain performance persistence over different time distances. Participants were expected to submit solutions for both sub-tasks, showcasing their ability to address the challenges of temporal variations in performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Dataset</head><p>In this section, we present the process of constructing our final annotated corpus for the task. The large-scale dataset TM-Senti was originally described in Yin et al. <ref type="bibr" coords="16,412.92,121.08,16.29,10.91" target="#b9">[10]</ref>, from which we extract samples that we use in this shared task. TM-Senti was chosen for the task as it provided a sufficiently longitudinal dataset (covering multiple years) and for using a consistent data collection and annotation strategy, which means that only the temporal evolution of data changes with other potentially confounding factors removed.</p><p>Temporal granularity. In the shared task, the training set covered a time period with a gap of 2 years, from 2014 to 2016. For the practice sets, within and distance time sets were introduced. The Practice-2016 set had a time gap of 0 years from the training data, given that it overlapped with the training period. In addition, the Practice-2018 set was also provided as a distant test set to practice with, having a temporal gap of two years from the training data.</p><p>For the test sets, the within set had a time gap of 0 years, covering the same period as the within Practice-2016 set. The Test-short set had a time gap of 2 years, coinciding with the distant Practice-2018 set. Lastly, the Test-long set had a time gap of 5 years, representing a long-term evaluation scenario.</p><p>By using these different time gaps, the shared task aimed to assess the models' performance persistence over varying temporal distances from the training data.</p><p>Un-labelled data. The data was sampled from Twitter using the Twitter academic API. Then, duplicates and near duplicates were removed. We also enforced a diversity of users and removed tweets from most frequent users with bot-like behaviour. Finally, user mentions were replaced by '@user' for anonymization, except for verified users that remained unchanged. For all these preprocessing steps, we relied on the same pipeline and script used by Loureiro et al. <ref type="bibr" coords="16,89.29,405.62,16.25,10.91" target="#b10">[11]</ref>.</p><p>Test set annotation. The test set was annotated using Amazon Mechanical Turk (AMT) <ref type="foot" coords="16,501.03,417.41,3.71,7.97" target="#foot_1">2</ref> . AMT candidate workers were filtered based on them successfully passsing two qualification tasks. The first, built-in in the system, seeks to find workers with certain experience and located in English-speaking countries to ensure, to a certain extent, high command of the English language and high familiarity with AMT. The second qualification task consisted in presenting each candidate annotator with 5 tweets, and only workers that correctly annotated 3 or more were allowed to proceed to the actual annotation task.</p><p>In total, we annotated 4,032 tweets, divided into 1874 for positive, 741 neutral and 1417 negative. Each tweet was annotated by 5 different workers, and the tweet's final label was decided by computing the mode of the array of annotations. Table <ref type="table" coords="16,394.59,541.11,5.17,10.91">6</ref> shows instances of the dataset, with labels and number of agreements between 5 and 3. In terms of overall statistics, 8.5% of the tweets were annotated with full agreement, 22.8% with 4 annotators agreeing, 46% with 3 agreements, and the remaining 22.5% with 2 agreements, which were mostly decided between positive and neutral, and negative and neutral.</p><p>Data preprocessing we preprocess our dataset to ensure its quality with respect to the following criteria:</p><p>‚Ä¢ Diversity: All retweets and replies are eliminated.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 6</head><p>Tweets where 5, 4 and 3 annotators agreed. Tweets labeled as neutral tend to be factual or posing questions, whereas high agreement positive and negative tweets tend to be more emotional, occasionally backed by the use of stronger words.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>#agree</head><p>Tweet Label ‚Ä¢ Consistency: We prioritise posts written in English and impose a length restriction such that all posts contain at least 5 words and are at most 140 character long. ‚Ä¢ Fluency: Posts containing URL links are eliminated. In addition, we select posts which contain at least one stop word as a proxy for fluency.</p><p>Before sampling, all emojis and emoticons are deleted from the body of text. Data sampling. In the second stage, we sample from the preprocessed data previously obtained. As we aim for a well-balanced annotated set, the sampling strategy is defined in terms of: 1) sentiment distribution, 2) time span and 3) post length. For 1), we use the distant labels provided by Yin et al. <ref type="bibr" coords="17,218.06,428.32,17.91,10.91" target="#b9">[10]</ref> to obtain a balanced distribution between the negative and positive classes. For 2), we sample an equal number of posts for each month within the specified temporal window in each dataset. Finally for 3), we partition the data into four bins with respect to the word length of each post ( i.e., each post falls into one of the following bins: <ref type="bibr" coords="17,446.52,468.96,11.40,10.91" target="#b4">[5,</ref><ref type="bibr" coords="17,457.92,468.96,11.40,10.91" target="#b9">10)</ref>, <ref type="bibr" coords="17,475.61,468.96,15.79,10.91" target="#b9">[10,</ref><ref type="bibr" coords="17,491.40,468.96,11.84,10.91">15)</ref>, <ref type="bibr" coords="17,89.29,482.51,17.04,10.91">[15,</ref><ref type="bibr" coords="17,106.33,482.51,12.78,10.91">20)</ref> and <ref type="bibr" coords="17,140.99,482.51,37.78,10.91">[20, 20+]</ref>) and uniformly sample from each bin.</p><p>The resulting distribution of data is shown in Table <ref type="table" coords="17,331.33,496.06,3.74,10.91" target="#tab_4">7</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Evaluation</head><p>The performance of the submissions was evaluated in two ways:</p><p>1. Macro-averaged F1-score: This metric measured the overall F1-score on the testing set for the sentiment classification sub-task. The F1-score combines precision and recall to provide a balanced measure of model performance. A higher F1-score indicated better performance in terms of both positive and negative sentiment classification.</p><formula xml:id="formula_2" coords="18,229.62,193.72,277.02,24.43">ùêπ -ùëöùëéùëêùëüùëú = 2 ‚Ä¢ ùëùùëüùëíùëêùëñùë†ùëñùëúùëõ ‚Ä¢ ùëüùëíùëêùëéùëôùëô ùëùùëüùëíùëêùëñùë†ùëñùëúùëõ + ùëüùëíùëêùëéùëôùëô<label>(1)</label></formula><p>2. Relative Performance Drop (RPD): This metric quantified the difference in performance between the "within-period" data and the short-or long-term distant testing sets. RPD was computed as the difference in performance scores between two sets. A negative RPD value indicated a drop in performance compared to the "within-period" data, while a positive value suggested an improvement.</p><formula xml:id="formula_3" coords="18,250.15,301.75,256.49,30.47">ùëÖùëÉ ùê∑ = ùëì ùë†ùëêùëúùëüùëíùë° ùëó -ùëì ùë†ùëêùëúùëüùëíùë° 0 ùëì ùë†ùëêùëúùëüùëíùë° 0<label>(2)</label></formula><p>Where ùë° 0 represents performance when time gap is 0; ùë° ùëó represents performance when time gap is short or long as in was introduced in previous work <ref type="bibr" coords="18,401.90,351.18,16.25,10.91" target="#b11">[12]</ref>.</p><p>The submissions were ranked primarily based on the macro-averaged F1-score. This ranking approach emphasized the overall performance of the sentiment classification models on the testing set. The higher the macro-averaged F1-score, the higher the ranking of the submission.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Results</head><p>Our shared task consisted of two subtasks: Short-term persistence (Sub-task A) and Longterm persistence (Sub-task B). Sub-task A focused on developing models that demonstrated performance persistence within a two-year gap from the training data, while Sub-task B required models that exhibited performance persistence over a longer period, surpassing the two-year gap. Additionally, an unlabeled corpora covering all periods of training, development, and testing was provided to teams interested in data-centric approaches. Along with the data, participating teams received python-based baseline code, and evaluation scripts <ref type="foot" coords="18,446.63,530.42,3.71,7.97" target="#foot_2">3</ref> . The shared task progressed through two phases and results are discussed in the following paragraphs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Practice phase</head><p>The initial phase was the practice phase, where participants received three distantly annotated sets, training set, within time practice set and short-term practice set. The training set was used for model training, while the two labeled practice set allowed participants to refine their systems before the subsequent phase. Moreover, we limited the sharing practice sets to withintime (Practice-2016) and single distance practice sets the short-term set (Practice-2018). This decision was made because participants were requested to take part in both sub-tasks and reduce over-fitting. The results of this phase were not considered in final models ranking. As it can be seen from Table <ref type="table" coords="19,227.64,219.27,3.70,10.91" target="#tab_5">8</ref>, Pablojmed showcased outstanding performance, surpassing the Baseline model with the highest scores in F1 Score Within (0.8244) and F1 Score Short (0.7976), as well as the highest Overall Score (0.811). saroyehun also demonstrated remarkable performance achieving the lowest Overall Drop (-0.0310), as well as outperforming the Baseline model in F1 Score Within (0.8170) and F1 Score Short (0.7917). The results highlight the potential of both Pablojmed and saroyehun's submissions for enhancing the baseline model's results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Evaluation phase</head><p>During the evaluation phase, participants were provided with three human-annotated testing sets, namely Test-within, Test-short and Test-long (See 3.2 for datasets details). The performance of participants on this phase was used to determine the overall rankings on the task. Short-term temporal persistence: From Table <ref type="table" coords="19,317.95,520.54,3.71,10.91" target="#tab_6">9</ref>, we can see that still the Baseline model is the best for achieving the highest short-term F1 Score (0.6839) among all the teams, indicating that RoBERTA architecture has a better performance in capturing short-term patterns compared to the other models. In same time, Cordyceps obtained the lowest short-term RPD value (-0.0656), suggesting a smaller drop in performance compared to the Baseline model. This indicates that Cordyceps may offer better short-term temporal persistence despite not having the highest Short-term F1 Score.</p><p>Long-term temporal persistence: In term of long-term persistence, Pablojmed achieved the highest f score (0.6971), indicating better performance in capturing long-term patterns compared to the other models. However, when considering the long-term RPD measure, pakapro obtained the lowest value (-0.0243), suggesting a smaller drop in performance compared to the other models. This suggests that pessimistic models as in pakapro may provide a relatively stable long-term temporal persistence despite not having the highest long-term F1 Score. Although Pablojmed obtained the highest F1 Score Long (0.6971), the model that offers better long-term temporal persistence, considering RPD, is pakapro. Despite its lower F1 Score Long (0.4910), pakapro achieved the smallest long-term RPD (-0.0243) compared to the other models. This suggests that pakapro maintains its performance more consistently over a longer period, indicating better long-term temporal persistence.</p><p>Overall temporal persistence: Considering the overall scores, Pablojmed achieved the highest overall score (0.7029) with (-0.0708) overall indicating better overall temporal persistence compared to the other models. However, pakapro offers better overall temporal persistence based on the Overall Drop metric. Indicating that pakapro's approach may be more persistent over time in our case despite its low F1 Scores. Overall, the best model is Pablojmed demonstrating better overall F score and higher temporal persistence than Baseline model. Additionally, the Baseline model performed best in short-term temporal persistence, and pakapro shows promise for long-term temporal persistence despite not having the highest long-term F1 Score.</p><p>Systems temporal ranking: The Baseline model, ranks first in within-time and shortterm F1 Score but drops to fourth place in long-term F1 Score. Pablojmed and Cordyceps interchange the second and third positions in both the within-time F1 Score and short-term F1 Score categories. This suggests a relatively consistent ranking between these two models within these specific categories. saroyehun consistently ranks fourth in both within-time F1 Score and short-term F1 Score. pakapro shows worst performance among all and ranks fifth in all three F scores demonstrate consistent performance across different timeframes compared to the other models.</p><p>It is important to note that ranking consistency varies across the different measures. We can see that low RPD does not indicate better performance rather stable metric over different sets. For example, if we look at the RPD metric, we see that pakapro achieves the best ranking in long-term and Overall Drop. This indicates a lower drop in performance over longer timeframes. However, when considering the F1 Score, pakapro ranks fifth in all three categories: F1 Score Within, F1 Score Short, and F1 Score Long. This demonstrates that a low RPD does not necessarily indicate better performance in terms of F1 Score.</p><p>In all cases, submitted systems demonstrated their highest performance when evaluated using the within-time held-out set. Moreover, the overall performance of participating teams seems to have dropped between the practice phase and the final evaluation phase. Given that participants are likely to have submitted their best models from the practice phase, it might be the case that this drop is a result of participants having overoptimism on the practice set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7.">Discussion</head><p>Only two out of the four teams have submitted technical reports for their used models. In the following, we delve into the discussion and interpretation of the findings concerning the three research questions we raised in relation to our classification task. These interpretations are solely based on the evaluation matrix, which is further explained in Section 3.3.</p><p>‚Ä¢ Regarding RQ1, which aimed to identify the types of models offering better short-term temporal persistence, we observed that the Baseline model achieved the highest shortterm F1 Score among all the teams. This indicates its strong performance in maintaining consistency over a shorter time frame compared to its initial performance using within-time set. Additionally, when examining the short-term RPD values, we found that Cordyceps exhibited the smallest drop in performance compared to the Baseline model.</p><p>‚Ä¢ Regarding RQ2, which investigated the models offering better long-term temporal persistence, we observed that Pablojmed achieved the highest F1 Score for the long-term. This indicates its superior ability to maintain performance over an extended period. Notably, pakapro demonstrated a smaller long-term RPD compared to the other models, suggesting its potential for maintaining performance stability over time. ‚Ä¢ Regarding RQ3, this research question aimed to identify the models offering better overall temporal persistence. In this regard, Pablojmed ranked as the top performing system, achieving the highest overall score. Its relatively low overall RPD further supports its consistency across different time frames. Interestingly, pakapro demonstrated promising results for long-term temporal persistence, despite not achieving the highest long-term F1 Score.</p><p>By delving into the evaluation matrix results, we provided insights into the performance trends observed among the participating systems. However, it is essential to acknowledge that the absence of the submission from a certain number of systems may have influenced the overall interpretation of the findings. To address this limitation, we made our leaderbored available for future submissions in Codalab <ref type="foot" coords="21,226.33,384.41,3.71,7.97" target="#foot_3">4</ref> . This should ensure more robust and unbiased assessment for the temporal persistence of text classifiers within the research community.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.8.">Conclusion</head><p>Overall findings highlight the importance of evaluating temporal persistence in model performance. The identified models showcase varying levels of persistence in both short-term and long-term persistence. These insights provide valuable guidance for future research and development efforts aimed at improving temporal consistency in machine learning models. In future shared tasks, we aim to incorporate evolving training sets as well as expanding out temporal persistence investigation to more tasks including stance detection and topic categorization.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="5,89.29,237.54,416.94,8.93;5,89.29,249.54,103.67,8.87;5,90.13,276.35,137.51,85.03"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Overview of the systems which use a neural approach (green) and which do not use any neural approach (yellow).</figDesc><graphic coords="5,90.13,276.35,137.51,85.03" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="5,89.29,385.89,416.69,8.93;5,89.29,397.90,121.62,8.87;5,90.13,424.70,137.50,85.24"><head>Figure 2 :Figure 3 :</head><label>23</label><figDesc>Figure 2: Overview of the systems which use a single approach (orange) and which use a combination of multiple approaches (cyan)</figDesc><graphic coords="5,90.13,424.70,137.50,85.24" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="12,89.29,314.49,416.69,8.93;12,89.29,326.49,416.94,8.87;12,89.29,338.45,416.69,8.87;12,89.29,350.41,54.06,8.87;12,89.29,84.19,416.67,222.87"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Queries in the WT dataset. The maximum and minimum values achieved by the pooled systems are marked by the thin bar, the 25% and 75% percentiles of the scores are marked with the thick bar. We show English translations of the queries in the graph. Queries are sorted according to the mean performance.</figDesc><graphic coords="12,89.29,84.19,416.67,222.87" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="13,89.29,216.93,416.70,8.93;13,89.29,228.94,286.82,8.87;13,151.80,84.19,291.68,126.16"><head>Figure 5 :</head><label>5</label><figDesc>Figure 5: Screenshot from Doctag main page. Labels annotation is done associating to each document one label that expresses the relevance of that document for that topic.</figDesc><graphic coords="13,151.80,84.19,291.68,126.16" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6" coords="14,89.29,402.14,416.69,8.93;14,89.29,414.15,405.90,8.87;14,89.29,84.19,416.70,311.37"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: The distribution of judgment votes for the top 30 queries based on document count. Resulting counts of 'Relevant' (green), 'Not Relevant' (red), and 'Partially Relevant' (orange) votes are shown.</figDesc><graphic coords="14,89.29,84.19,416.70,311.37" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7" coords="17,89.29,175.40,4.63,8.87;17,137.38,163.45,193.49,8.87;17,484.60,163.45,14.21,8.87;17,137.38,175.40,91.17,8.87;17,484.60,175.40,14.85,8.87;17,137.38,187.36,228.17,8.87;17,484.60,187.36,15.23,8.87;17,89.29,216.74,4.63,8.87;17,137.38,204.79,209.18,8.87;17,484.60,204.79,14.21,8.87;17,137.38,216.74,243.80,8.87;17,484.60,216.74,14.85,8.87;17,137.38,228.70,362.45,8.87;17,89.29,258.09,4.63,8.87;17,137.38,246.13,204.45,8.87;17,484.60,246.13,14.21,8.87;17,137.38,258.09,251.48,8.87;17,484.60,258.09,14.85,8.87;17,137.38,270.04,224.90,8.87;17,484.60,270.04,15.23,8.87"><head>5 I</head><label>5</label><figDesc>say this a lot But I m just so in love with Evan pos Online classes r a joke neg Shout out to me for living 17 minutes away from school neu 4 Honestly just a Hi from you already makes my day pos Been one of them weeks and I just want to burst out crying neg What s your fave throwback song to jam out to on Thursdays I have too many tbt neu 3 Not a good idea to mix everything but great night pos just had the worst nightmare I don t want to go back to sleep neg Waiting to find a man that can dance like Chris Brown neu</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="3,88.99,553.91,417.00,83.78"><head>Table 1</head><label>1</label><figDesc>Ratio of documents shared between the collections, row vs. column, i.e. 0.99 means that 99% of documents in the Heldout/Train (WT) collection is shared with the Short-term (ST) collection.</figDesc><table coords="3,170.79,596.68,251.71,41.01"><row><cell></cell><cell cols="3">Heldout (WT)/Train Short (ST) Long (LT)</cell></row><row><cell>Heldout (WT)/Train</cell><cell>1.00</cell><cell>0.97</cell><cell>0.94</cell></row><row><cell>Short (ST)</cell><cell>0.99</cell><cell>1.00</cell><cell>0.96</cell></row><row><cell>Long (LT)</cell><cell>0.65</cell><cell>0.65</cell><cell>1.00</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="4,88.99,90.49,328.07,81.62"><head>Table 2</head><label>2</label><figDesc>Ratio of the queries shared between the collections, rows vs. columns.</figDesc><table coords="4,178.22,121.63,238.84,50.48"><row><cell></cell><cell cols="4">Heldout (WT) Train Short (ST) Long (LT)</cell></row><row><cell>Heldout (WT)</cell><cell>-</cell><cell>0.00</cell><cell>0.04</cell><cell>0.03</cell></row><row><cell>Train</cell><cell>0.00</cell><cell>-</cell><cell>0.24</cell><cell>0.18</cell></row><row><cell>Short (ST)</cell><cell>0.32</cell><cell>0.31</cell><cell>-</cell><cell>0.23</cell></row><row><cell>Long (LT)</cell><cell>0.28</cell><cell>0.24</cell><cell>0.24</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" coords="9,88.99,92.62,417.26,579.58"><head>Table 4</head><label>4</label><figDesc>Changes in the NDCG scores. Table is sorted according to the highest change between the ST and WT collection.</figDesc><table coords="9,316.38,133.06,102.97,5.36"><row><cell>NDCG</cell><cell>NDCG Change</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="10,88.99,90.49,417.26,619.37"><head>Table 5</head><label>5</label><figDesc>Ranking of the submitted systems in terms of NDCG scores (columns 2-4), absolute changes in NDCG scores between WT and ST dataset (column 5), absolute changes in NDCG scores between WT and LT dataset (column 6). Column 7 shows the sum of the Borda count applied to ranking on ST dataset and Borda count of ranking change between ST and WT dataset. Column 8 shows the same value, but for the LT dataset. The darker color means better performance.</figDesc><table coords="10,97.64,169.02,398.50,540.84"><row><cell>System</cell><cell>Ranking</cell><cell>Ranking</cell><cell>Ranking</cell><cell>Ranking</cell><cell>Ranking</cell><cell>Perf(ST)</cell><cell cols="2">Perf(LT)</cell></row><row><cell></cell><cell>NDCG WT</cell><cell>NDCG ST</cell><cell>NDCG LT</cell><cell>NDCG</cell><cell>NDCG</cell><cell>+ Change</cell><cell>+</cell><cell>Change</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Change</cell><cell>Change</cell><cell>(ST-WT)</cell><cell cols="2">(LT-WT)</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>ST-WT</cell><cell>LT-WT</cell><cell></cell><cell></cell></row><row><cell>seupd2223-hiball_BERT</cell><cell>34</cell><cell>29</cell><cell>64</cell><cell>4</cell><cell>62</cell><cell>113</cell><cell>0</cell></row><row><cell>UGA_T5_English</cell><cell>46</cell><cell>37</cell><cell>30</cell><cell>3</cell><cell>3</cell><cell>106</cell><cell>93</cell></row><row><cell>FADERIC_En-BM25-S50-KS-S-F-SP-R30</cell><cell>38</cell><cell>33</cell><cell>31</cell><cell>9</cell><cell>22</cell><cell>104</cell><cell>73</cell></row><row><cell>IRC_d2q+BM25</cell><cell>52</cell><cell>40</cell><cell>33</cell><cell>2</cell><cell>2</cell><cell>104</cell><cell>91</cell></row><row><cell>FADERIC_Fr-BM25-S50-LS-S-F-SC-R20W6</cell><cell>5</cell><cell>1</cell><cell>62</cell><cell>42</cell><cell>62</cell><cell>103</cell><cell>2</cell></row><row><cell>DARDS_BM25FRENCHBASE</cell><cell>18</cell><cell>13</cell><cell>13</cell><cell>34</cell><cell>34</cell><cell>99</cell><cell>79</cell></row><row><cell>IRC_BM25+colBERT</cell><cell>47</cell><cell>39</cell><cell>34</cell><cell>11</cell><cell>8</cell><cell>96</cell><cell>84</cell></row><row><cell>IRC_BM25+monoT5</cell><cell>37</cell><cell>36</cell><cell>28</cell><cell>14</cell><cell>9</cell><cell>96</cell><cell>89</cell></row><row><cell>soup_kbase</cell><cell>58</cell><cell>47</cell><cell>42</cell><cell>5</cell><cell>7</cell><cell>94</cell><cell>77</cell></row><row><cell>FADERIC_Fr-BM25-S50-LS-S-F-R30</cell><cell>9</cell><cell>2</cell><cell>63</cell><cell>51</cell><cell>62</cell><cell>93</cell><cell>1</cell></row><row><cell>SQUID_BOOST</cell><cell>25</cell><cell>24</cell><cell>20</cell><cell>29</cell><cell>29</cell><cell>93</cell><cell>77</cell></row><row><cell>CLOSE_RERANKING_ENGLISH</cell><cell>35</cell><cell>35</cell><cell>29</cell><cell>20</cell><cell>18</cell><cell>91</cell><cell>79</cell></row><row><cell>soup_kml</cell><cell>56</cell><cell>46</cell><cell>40</cell><cell>10</cell><cell>5</cell><cell>90</cell><cell>81</cell></row><row><cell>soup_kngml</cell><cell>57</cell><cell>49</cell><cell>41</cell><cell>7</cell><cell>4</cell><cell>90</cell><cell>81</cell></row><row><cell>CLOSE_QUEREXPANSION</cell><cell>23</cell><cell>21</cell><cell>19</cell><cell>37</cell><cell>41</cell><cell>88</cell><cell>66</cell></row><row><cell>DARDS_BM25FRENCHSPAM</cell><cell>24</cell><cell>25</cell><cell>21</cell><cell>35</cell><cell>39</cell><cell>86</cell><cell>66</cell></row><row><cell>RAFJAM_BasicRuns</cell><cell>22</cell><cell>19</cell><cell>16</cell><cell>41</cell><cell>36</cell><cell>86</cell><cell>74</cell></row><row><cell>FADERIC_Fr-BM25T-S50-LS-S-F</cell><cell>13</cell><cell>9</cell><cell>8</cell><cell>52</cell><cell>40</cell><cell>85</cell><cell>78</cell></row><row><cell>HIBALL_AI-MERGED</cell><cell>62</cell><cell>53</cell><cell>64</cell><cell>8</cell><cell>62</cell><cell>85</cell><cell>0</cell></row><row><cell>semicolon_frenchAnalyzerFrStopNum</cell><cell>16</cell><cell>15</cell><cell>64</cell><cell>46</cell><cell>62</cell><cell>85</cell><cell>0</cell></row><row><cell>semicolon_frenchAnalyzerFrStopWord</cell><cell>15</cell><cell>14</cell><cell>64</cell><cell>47</cell><cell>62</cell><cell>85</cell><cell>0</cell></row><row><cell>seupd2223-JIHUMING-07_fr_fr</cell><cell>31</cell><cell>31</cell><cell>27</cell><cell>30</cell><cell>26</cell><cell>85</cell><cell>73</cell></row><row><cell>RAFJAM_SynQERuns</cell><cell>33</cell><cell>34</cell><cell>32</cell><cell>28</cell><cell>37</cell><cell>84</cell><cell>57</cell></row><row><cell>seupd2223-JIHUMING-08_fr_fr_3gram</cell><cell>30</cell><cell>30</cell><cell>26</cell><cell>33</cell><cell>28</cell><cell>83</cell><cell>72</cell></row><row><cell>DARDS_BM25FRENCHBOOSTURL</cell><cell>17</cell><cell>16</cell><cell>11</cell><cell>48</cell><cell>33</cell><cell>82</cell><cell>82</cell></row><row><cell>seupd2223-hiball_BASELINE</cell><cell>51</cell><cell>45</cell><cell>64</cell><cell>19</cell><cell>62</cell><cell>82</cell><cell>0</cell></row><row><cell>FADERIC_Fr-BM25-S50-LS-S-F-SC</cell><cell>10</cell><cell>8</cell><cell>7</cell><cell>57</cell><cell>42</cell><cell>81</cell><cell>77</cell></row><row><cell>ows-bm25-10-variants-prompt-2</cell><cell>66</cell><cell>59</cell><cell>49</cell><cell>6</cell><cell>6</cell><cell>81</cell><cell>71</cell></row><row><cell>SQUID_SEARCHERAI</cell><cell>3</cell><cell>3</cell><cell>1</cell><cell>63</cell><cell>52</cell><cell>80</cell><cell>73</cell></row><row><cell>CLOSE_RERANKING</cell><cell>6</cell><cell>7</cell><cell>9</cell><cell>60</cell><cell>53</cell><cell>79</cell><cell>64</cell></row><row><cell>semicolon_fusedRankAllEnglish</cell><cell>43</cell><cell>42</cell><cell>64</cell><cell>25</cell><cell>62</cell><cell>79</cell><cell>0</cell></row><row><cell>seupd2223-JIHUMING-09_fr_fr_4gram</cell><cell>29</cell><cell>28</cell><cell>25</cell><cell>39</cell><cell>32</cell><cell>79</cell><cell>69</cell></row><row><cell>seupd2223-JIHUMING-12_fr_fr_4gram_ner</cell><cell>48</cell><cell>43</cell><cell>39</cell><cell>24</cell><cell>24</cell><cell>79</cell><cell>63</cell></row><row><cell>seupd2223-hiball_RRF60</cell><cell>60</cell><cell>55</cell><cell>64</cell><cell>13</cell><cell>62</cell><cell>78</cell><cell>0</cell></row><row><cell>soup_lng</cell><cell>55</cell><cell>52</cell><cell>45</cell><cell>16</cell><cell>13</cell><cell>78</cell><cell>68</cell></row><row><cell>SQUID_W2V</cell><cell>4</cell><cell>6</cell><cell>2</cell><cell>62</cell><cell>49</cell><cell>78</cell><cell>75</cell></row><row><cell>semicolon_porter2-1p4-eng</cell><cell>53</cell><cell>51</cell><cell>64</cell><cell>18</cell><cell>62</cell><cell>77</cell><cell>0</cell></row><row><cell>UGA_BM25_English</cell><cell>59</cell><cell>54</cell><cell>43</cell><cell>15</cell><cell>10</cell><cell>77</cell><cell>73</cell></row><row><cell>gwca_lightstem-phrase-qexp-rerank3f</cell><cell>14</cell><cell>17</cell><cell>12</cell><cell>53</cell><cell>35</cell><cell>76</cell><cell>79</cell></row><row><cell>NEON_3b</cell><cell>72</cell><cell>69</cell><cell>59</cell><cell>1</cell><cell>1</cell><cell>76</cell><cell>66</cell></row><row><cell>CLOSE_SBERT_BM25</cell><cell>1</cell><cell>4</cell><cell>4</cell><cell>67</cell><cell>58</cell><cell>75</cell><cell>64</cell></row><row><cell>gwca_lightstem-phrase</cell><cell>12</cell><cell>12</cell><cell>10</cell><cell>59</cell><cell>50</cell><cell>75</cell><cell>66</cell></row><row><cell>gwca_lightstem-phrase-qexp</cell><cell>2</cell><cell>5</cell><cell>3</cell><cell>66</cell><cell>54</cell><cell>75</cell><cell>69</cell></row><row><cell>DARDS_BM25FRENCHRERANK100</cell><cell>21</cell><cell>22</cell><cell>18</cell><cell>50</cell><cell>43</cell><cell>74</cell><cell>65</cell></row><row><cell>seupd2223-JIHUMING-10_fr_fr_5gram</cell><cell>28</cell><cell>27</cell><cell>22</cell><cell>45</cell><cell>31</cell><cell>74</cell><cell>73</cell></row><row><cell>ows-bm25-5-variants-prompt-2</cell><cell>67</cell><cell>62</cell><cell>52</cell><cell>12</cell><cell>12</cell><cell>72</cell><cell>62</cell></row><row><cell>SQUID_BasicSearcher</cell><cell>8</cell><cell>10</cell><cell>5</cell><cell>64</cell><cell>47</cell><cell>72</cell><cell>74</cell></row><row><cell>IRC_E5_base</cell><cell>45</cell><cell>44</cell><cell>37</cell><cell>31</cell><cell>19</cell><cell>71</cell><cell>70</cell></row><row><cell>IRC_RRF(BM25+Bo1-XSqrA_M-PL2)</cell><cell>50</cell><cell>48</cell><cell>38</cell><cell>27</cell><cell>21</cell><cell>71</cell><cell>67</cell></row><row><cell>UGA_BM25_French</cell><cell>26</cell><cell>26</cell><cell>23</cell><cell>49</cell><cell>45</cell><cell>71</cell><cell>58</cell></row><row><cell>gwca_word2vec-nostem</cell><cell>19</cell><cell>20</cell><cell>15</cell><cell>56</cell><cell>44</cell><cell>70</cell><cell>67</cell></row><row><cell>SQUID_W2VRerank</cell><cell>7</cell><cell>11</cell><cell>6</cell><cell>65</cell><cell>48</cell><cell>70</cell><cell>72</cell></row><row><cell>UGA_T5_French</cell><cell>20</cell><cell>23</cell><cell>17</cell><cell>55</cell><cell>38</cell><cell>68</cell><cell>71</cell></row><row><cell>soup_kmls</cell><cell>54</cell><cell>56</cell><cell>44</cell><cell>23</cell><cell>16</cell><cell>67</cell><cell>66</cell></row><row><cell>ows-pl2-10-variants-prompt-2</cell><cell>64</cell><cell>61</cell><cell>46</cell><cell>21</cell><cell>15</cell><cell>64</cell><cell>65</cell></row><row><cell>semicolon_Ngram34</cell><cell>49</cell><cell>50</cell><cell>64</cell><cell>32</cell><cell>62</cell><cell>64</cell><cell>0</cell></row><row><cell>gwca_lightstem-phrase-qexp-rerank2f</cell><cell>11</cell><cell>18</cell><cell>14</cell><cell>69</cell><cell>56</cell><cell>59</cell><cell>56</cell></row><row><cell>ows-pl2-5-variants-prompt-2</cell><cell>65</cell><cell>65</cell><cell>47</cell><cell>22</cell><cell>14</cell><cell>59</cell><cell>65</cell></row><row><cell>NEON_4b</cell><cell>71</cell><cell>72</cell><cell>61</cell><cell>17</cell><cell>11</cell><cell>57</cell><cell>54</cell></row><row><cell>ows-lgd-10-variants-prompt-2</cell><cell>61</cell><cell>64</cell><cell>48</cell><cell>26</cell><cell>20</cell><cell>56</cell><cell>58</cell></row><row><cell>DARDS_BM25TRANSLATEDQUERIES</cell><cell>36</cell><cell>41</cell><cell>35</cell><cell>54</cell><cell>30</cell><cell>51</cell><cell>61</cell></row><row><cell>RAFJAM_AllQERuns</cell><cell>32</cell><cell>38</cell><cell>36</cell><cell>58</cell><cell>51</cell><cell>50</cell><cell>39</cell></row><row><cell>RAFJAM_PseudoRelQERuns</cell><cell>27</cell><cell>32</cell><cell>24</cell><cell>68</cell><cell>46</cell><cell>46</cell><cell>56</cell></row><row><cell>CLOSE_JSCLEANER_BM25</cell><cell>63</cell><cell>67</cell><cell>56</cell><cell>40</cell><cell>25</cell><cell>39</cell><cell>45</cell></row><row><cell>NEON_2br</cell><cell>70</cell><cell>71</cell><cell>60</cell><cell>36</cell><cell>27</cell><cell>39</cell><cell>39</cell></row><row><cell>NEON_1a</cell><cell>69</cell><cell>70</cell><cell>58</cell><cell>38</cell><cell>17</cell><cell>38</cell><cell>51</cell></row><row><cell>NEON_1b</cell><cell>68</cell><cell>68</cell><cell>57</cell><cell>44</cell><cell>23</cell><cell>34</cell><cell>46</cell></row><row><cell>HIBALL_AI-FIXED</cell><cell>73</cell><cell>73</cell><cell>64</cell><cell>43</cell><cell>62</cell><cell>30</cell><cell>0</cell></row><row><cell>QEVALS_LMDirichlet</cell><cell>44</cell><cell>57</cell><cell>55</cell><cell>61</cell><cell>55</cell><cell>28</cell><cell>16</cell></row><row><cell>QEVALS_BM25DFLT</cell><cell>40</cell><cell>58</cell><cell>50</cell><cell>71</cell><cell>59</cell><cell>17</cell><cell>17</cell></row><row><cell>QEVALS_BM25CSTM</cell><cell>42</cell><cell>60</cell><cell>51</cell><cell>70</cell><cell>57</cell><cell>16</cell><cell>18</cell></row><row><cell>QEVALS_IB</cell><cell>39</cell><cell>63</cell><cell>53</cell><cell>73</cell><cell>61</cell><cell>10</cell><cell>12</cell></row><row><cell>QEVALS_DFR</cell><cell>41</cell><cell>66</cell><cell>54</cell><cell>72</cell><cell>60</cell><cell>8</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="17,88.99,525.07,319.52,109.88"><head>Table 7</head><label>7</label><figDesc>Dataset statistics summary of training, practice and testing sets.</figDesc><table coords="17,186.76,553.11,221.75,81.84"><row><cell>Dataset</cell><cell>Time Period</cell><cell>Size</cell></row><row><cell>Training</cell><cell cols="2">Feb 2014 -Dec 2016 49608</cell></row><row><cell cols="2">Practice-2016 [within] Jan 2016 -Dec 2016</cell><cell>1344</cell></row><row><cell cols="2">Practice-2018 [distant] Jan 2018 -Dec 2018</cell><cell>1344</cell></row><row><cell>Test-within</cell><cell>Jan 2016 -Dec 2016</cell><cell>908</cell></row><row><cell>Test-short</cell><cell>Jan 2018 -Dec 2018</cell><cell>908</cell></row><row><cell>Test-long</cell><cell>Jan 2021 -Aug 2021</cell><cell>908</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="19,88.99,129.17,388.75,74.10"><head>Table 8</head><label>8</label><figDesc>Performance comparison for practice set</figDesc><table coords="19,117.53,157.21,360.22,46.06"><row><cell cols="5">Team Name F1 Score Within F1 Score Short Overall Drop Overall Score</cell></row><row><cell>Pablojmed</cell><cell>0.8244 (1)</cell><cell>0.7976 (1)</cell><cell>-0.0325 (2)</cell><cell>0.811</cell></row><row><cell>saroyehun</cell><cell>0.8170 (2)</cell><cell>0.7917 (2)</cell><cell>-0.0310 (1)</cell><cell>0.8043</cell></row><row><cell>Baseline</cell><cell>0.7879 (3)</cell><cell>0.7611 (3)</cell><cell>-0.0340 (3)</cell><cell>0.7745</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="19,88.99,392.32,393.95,112.33"><head>Table 9</head><label>9</label><figDesc>Performance comparison for evaluation set.</figDesc><table coords="19,105.13,420.16,377.82,84.49"><row><cell>Team Name</cell><cell>F1 Score Within</cell><cell>F1 Score Short</cell><cell>F1 Score Long</cell><cell>RPD Within-Short</cell><cell>RPD Within-Long</cell><cell>Overall Drop</cell><cell>Overall Score</cell></row><row><cell cols="2">Pablojmed 0.7377 (2)</cell><cell>0.6739 (3)</cell><cell>0.6971 (1)</cell><cell cols="4">-0.0866 (5) -0.0550 (3) -0.0708 (4) 0.7029</cell></row><row><cell>Baseline</cell><cell>0.7459 (1)</cell><cell>0.6839 (1)</cell><cell>0.6549 (4)</cell><cell cols="4">-0.0830 (4) -0.1220 (5) -0.1025 (5) 0.6949</cell></row><row><cell cols="2">Cordyceps 0.7246 (3)</cell><cell>0.6771 (2)</cell><cell>0.6751 (3)</cell><cell cols="4">-0.0656 (1) -0.0683 (4) -0.0669 (3) 0.6923</cell></row><row><cell cols="2">saroyehun 0.7203 (4)</cell><cell>0.6674 (4)</cell><cell>0.6874 (2)</cell><cell cols="4">-0.0735 (2) -0.0457 (2) -0.0596 (2) 0.6917</cell></row><row><cell>pakapro</cell><cell>0.5033 (5)</cell><cell>0.4648 (5)</cell><cell>0.4910 (5)</cell><cell cols="4">-0.0765 (3) -0.0243 (1) -0.0504 (1) 0.4863</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="13,92.57,671.02,110.54,8.97"><p>https://trec.nist.gov/trec_eval/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2" xml:id="foot_1" coords="16,92.57,671.04,91.27,8.97"><p>https://www.mturk.com/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3" xml:id="foot_2" coords="18,92.57,671.04,111.53,8.97"><p>https://clef-longeval.github.io/</p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4" xml:id="foot_3" coords="21,92.57,671.03,185.10,8.97"><p>https://codalab.lisn.upsaclay.fr/competitions/12762</p></note>
		</body>
		<back>

			<div type="acknowledgement">
<div><head>Acknowledgments</head><p>This work is supported by the <rs type="programName">ANR Kodicare bi-lateral</rs> project, grant <rs type="grantNumber">ANR-19-CE23-0029</rs> of the <rs type="funder">French Agence Nationale de la Recherche</rs>, and by the <rs type="funder">Austrian Science Fund (FWF</rs>, grant <rs type="grantNumber">I4471-N</rs>). This work is also supported by a <rs type="funder">UKRI/EPSRC Turing</rs> <rs type="grantName">AI Fellowship</rs> to <rs type="person">Maria Liakata</rs> (grant no. <rs type="grantNumber">EP/V030302/1</rs>) and <rs type="funder">The Alan Turing Institute</rs> (grant no. <rs type="grantNumber">EP/N510129/1</rs>) through project funding and its <rs type="programName">Enrichment PhD Scheme</rs> for <rs type="person">Iman Bilal</rs>. This work has been using services provided by the <rs type="projectName">LINDAT/CLARIAH-CZ Research Infrastructure</rs> (https://lindat.cz), supported by the <rs type="funder">Ministry of Education, Youth and Sports of the Czech Republic</rs> (Project No. <rs type="grantNumber">LM2018101</rs>) and has been also supported by the <rs type="funder">Ministry of Education, Youth and Sports of the Czech Republic</rs>, Project No. <rs type="grantNumber">LM2018101 LINDAT/CLARIAH-CZ</rs>.</p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_Fk5g2yA">
					<idno type="grant-number">ANR-19-CE23-0029</idno>
					<orgName type="program" subtype="full">ANR Kodicare bi-lateral</orgName>
				</org>
				<org type="funding" xml:id="_Yew6PKG">
					<idno type="grant-number">I4471-N</idno>
				</org>
				<org type="funding" xml:id="_jg4f9f8">
					<idno type="grant-number">EP/V030302/1</idno>
					<orgName type="grant-name">AI Fellowship</orgName>
				</org>
				<org type="funded-project" xml:id="_ZVcaKHf">
					<idno type="grant-number">EP/N510129/1</idno>
					<orgName type="project" subtype="full">LINDAT/CLARIAH-CZ Research Infrastructure</orgName>
					<orgName type="program" subtype="full">Enrichment PhD Scheme</orgName>
				</org>
				<org type="funding" xml:id="_faQV25B">
					<idno type="grant-number">LM2018101</idno>
				</org>
				<org type="funding" xml:id="_WBt5Gyh">
					<idno type="grant-number">LM2018101 LINDAT/CLARIAH-CZ</idno>
				</org>
			</listOrg>
			<div type="references">

				<listBibl>

<biblStruct coords="22,112.66,172.69,394.53,10.91;22,112.66,186.24,395.17,10.91;22,112.66,199.79,394.52,10.91;22,112.66,213.34,395.01,10.91;22,112.66,226.89,362.24,10.91" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="22,112.66,186.24,245.46,10.91">Synthetic target domain supervision for open retrieval qa</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Gangi Reddy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Sultan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Sil</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">V</forename><surname>Castelli</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Florian</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Roukos</surname></persName>
		</author>
		<idno type="DOI">10.1145/3404835.3463085</idno>
		<ptr target="https://doi.org/10.1145/3404835.3463085.doi:10.1145/3404835.3463085" />
	</analytic>
	<monogr>
		<title level="m" coord="22,379.55,186.24,128.28,10.91;22,112.66,199.79,394.52,10.91;22,112.66,213.34,39.38,10.91">Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;21</title>
		<meeting>the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;21<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="1793" to="1797" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,112.66,240.44,394.53,10.91;22,112.66,253.99,394.52,10.91;22,112.66,267.54,394.53,10.91;22,112.66,281.08,394.52,10.91;22,112.66,294.63,393.33,10.91;22,112.66,308.18,393.33,10.91;22,112.66,321.73,321.57,10.91" xml:id="b1">
	<analytic>
		<title level="a" type="main" coord="22,112.66,281.08,389.62,10.91">Overview of the clef-2023 longeval lab on longitudinal evaluation of model performance</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Alkhalifa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Bilal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Borkakoty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Camacho-Collados</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Deveaud</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>El-Ebshihy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Espinosa-Anke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gonzalez-Saez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Galu≈°ƒç√°kov√°</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kochkina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Liakata</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Loureiro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">T</forename><surname>Madabushi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mulhem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Piroi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Popel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Servan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zubiaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="22,127.14,294.63,378.84,10.91;22,112.66,308.18,327.16,10.91">Experimental IR Meets Multilinguality, Multimodality, and Interaction. Proceedings of the Fourteenth International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="22,471.85,308.18,34.14,10.91;22,112.66,321.73,148.46,10.91">Lecture Notes in Computer Science (LNCS</title>
		<meeting><address><addrLine>Thessaliniki, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,112.66,335.28,394.53,10.91;22,112.66,348.83,393.33,10.91;22,112.66,362.38,174.58,10.91" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Galu≈°ƒç√°kov√°</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Deveaud</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gonzalez-Saez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mulhem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Piroi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Popel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.03229</idno>
		<title level="m" coord="22,112.66,348.83,393.33,10.91;22,112.66,362.38,44.62,10.91">Longeval-retrieval: French-english dynamic test collection for continuous web search evaluation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,112.66,375.93,395.16,10.91;22,112.66,389.48,394.52,10.91;22,112.66,403.03,90.72,10.91" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="22,258.72,375.93,199.98,10.91">A New Perspective on Score Standardization</title>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Urbano</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Lima</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Hanjalic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="22,482.12,375.93,25.70,10.91;22,112.66,389.48,390.32,10.91">International ACM SIGIR Conference on Research and Development in Information Retrieval</title>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="1061" to="1064" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,112.66,416.58,393.33,10.91;22,112.66,430.13,393.32,10.91;22,112.66,443.67,393.33,10.91;22,112.41,457.22,316.64,10.91" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="22,270.66,416.58,235.33,10.91;22,112.66,430.13,60.74,10.91">Doctag: A customizable annotation tool for ground truth creation</title>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Giachelle</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">O</forename><surname>Irrera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Silvello</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="22,196.57,430.13,309.42,10.91;22,112.66,443.67,88.74,10.91">Advances in Information Retrieval: 44th European Conference on IR Research, ECIR 2022</title>
		<title level="s" coord="22,380.93,443.67,86.34,10.91;22,152.11,458.24,146.73,9.72">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Stavanger, Norway</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2022">April 10-14, 2022. 2022</date>
			<biblScope unit="volume">13186</biblScope>
			<biblScope unit="page" from="288" to="293" />
		</imprint>
	</monogr>
	<note>Proceedings, Part II</note>
</biblStruct>

<biblStruct coords="22,112.66,470.77,395.17,10.91;22,112.66,484.32,394.51,10.91;22,112.66,500.31,117.15,7.90" xml:id="b5">
	<monogr>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Harman</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-36415-0_7</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-36415-0_7.doi:10.1007/978-3-642-36415-0_7" />
		<title level="m" coord="22,175.90,470.77,110.28,10.91">TREC-Style Evaluations</title>
		<meeting><address><addrLine>Berlin Heidelberg, Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="97" to="115" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,112.66,511.42,393.32,10.91;22,112.66,524.97,339.14,10.91" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="22,223.75,511.42,282.23,10.91;22,112.66,524.97,82.51,10.91">Capturing stance dynamics in social media: open challenges and research directions</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Alkhalifa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zubiaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="22,203.32,524.97,192.63,10.91">International Journal of Digital Humanities</title>
		<imprint>
			<biblScope unit="page" from="1" to="21" />
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,112.66,538.52,393.33,10.91;22,112.66,552.07,307.44,10.91" xml:id="b7">
	<monogr>
		<title level="m" type="main" coord="22,290.13,538.52,215.86,10.91;22,112.66,552.07,125.91,10.91">Building for tomorrow: Assessing the temporal persistence of text classifiers</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Alkhalifa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kochkina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zubiaga</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2205.05435</idno>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="22,112.66,565.62,394.53,10.91;22,112.66,579.17,394.52,10.91;22,112.66,592.72,394.53,10.91;22,112.66,606.27,394.53,10.91;22,112.66,619.81,393.33,10.91;22,112.33,633.36,375.08,10.91" xml:id="b8">
	<analytic>
		<title level="a" type="main" coord="22,112.66,606.27,320.92,10.91">Longeval: Longitudinal evaluation of model performance at clef 2023</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Alkhalifa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Bilal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Borkakoty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Camacho-Collados</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Deveaud</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>El-Ebshihy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Espinosa-Anke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gonzalez-Saez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Galu≈°ƒç√°kov√°</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kochkina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Liakata</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Loureiro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Tayyar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Madabushi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Mulhem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Piroi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Popel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Servan</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Zubiaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="22,142.21,633.36,151.66,10.91">Advances in Information Retrieval</title>
		<editor>
			<persName><forename type="first">J</forename><surname>Kamps</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Crestani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Maistro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Joho</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Davis</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Gurrin</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">U</forename><surname>Kruschwitz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Caputo</surname></persName>
		</editor>
		<meeting><address><addrLine>Switzerland, Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer Nature</publisher>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="22,112.66,646.91,393.33,10.91;23,112.66,86.97,393.33,10.91;23,112.33,100.52,29.19,10.91" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">W</forename><surname>Yin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Alkhalifa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zubiaga</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2108.13898</idno>
		<title level="m" coord="22,254.09,646.91,251.90,10.91;23,112.66,86.97,243.47,10.91">The emojification of sentiment on social media: Collection and analysis of a longitudinal twitter sentiment dataset</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="23,112.66,114.06,394.62,10.91;23,112.66,127.61,393.32,10.91;23,112.66,141.16,393.54,10.91;23,112.66,154.71,395.01,10.91;23,112.66,168.26,285.64,10.91" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="23,461.68,114.06,45.60,10.91;23,112.66,127.61,181.63,10.91">TimeLMs: Diachronic language models from Twitter</title>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Loureiro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Barbieri</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Espinosa Anke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Camacho-Collados</surname></persName>
		</author>
		<idno type="DOI">10.18653/v1/2022.acl-demo.25</idno>
		<ptr target="https://aclanthology.org/2022.acl-demo.25.doi:10.18653/v1/2022.acl-demo.25" />
	</analytic>
	<monogr>
		<title level="m" coord="23,317.02,127.61,188.96,10.91;23,112.66,141.16,393.54,10.91;23,112.66,154.71,116.05,10.91">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, Association for Computational Linguistics</title>
		<meeting>the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, Association for Computational Linguistics<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2022">2022</date>
			<biblScope unit="page" from="251" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,112.66,181.81,393.60,10.91;23,112.66,195.36,393.33,10.91;23,112.66,208.91,192.57,10.91" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="23,292.74,181.81,213.52,10.91;23,112.66,195.36,126.12,10.91">Opinions are made to be changed: Temporally adaptive stance classification</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Alkhalifa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kochkina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zubiaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="23,261.17,195.36,244.82,10.91;23,112.66,208.91,114.32,10.91">Proceedings of the 2021 Workshop on Open Challenges in Online Social Networks</title>
		<meeting>the 2021 Workshop on Open Challenges in Online Social Networks</meeting>
		<imprint>
			<date type="published" when="2021">2021</date>
			<biblScope unit="page" from="27" to="32" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
