<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" coord="1,89.29,84.74,416.53,15.42;1,88.78,106.66,213.52,15.42;1,89.29,132.57,220.08,5.42">SEUPD@CLEF: Team NEON. A Memoryless Approach To Longitudinal Evaluation Notebook for the LongEval Lab at CLEF 2023</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName coords="1,89.29,158.47,77.97,5.42"><forename type="first">Simone</forename><surname>Bortolin</surname></persName>
							<email>simone.bortolin.1@studenti.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,179.85,158.47,68.93,5.42"><forename type="first">Gioele</forename><surname>Ceccon</surname></persName>
							<email>gioele.ceccon@studenti.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,261.36,158.47,60.96,5.42"><forename type="first">Gil</forename><surname>Czaczkes</surname></persName>
							<email>gil.czaczkes@studenti.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,334.91,158.47,91.32,5.42"><forename type="first">Alessandra</forename><surname>Pastore</surname></persName>
							<email>alessandra.pastore.2@studenti.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,438.82,158.47,61.78,5.42"><forename type="first">Pietro</forename><surname>Renna</surname></persName>
							<email>pietro.renna@studenti.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,89.29,172.42,77.02,5.42"><forename type="first">Giovanni</forename><surname>Zerbo</surname></persName>
							<email>giovanni.zerbo@studenti.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName coords="1,197.30,172.42,60.31,5.42"><forename type="first">Nicola</forename><surname>Ferro</surname></persName>
							<email>ferro@dei.unipd.it</email>
							<affiliation key="aff0">
								<orgName type="institution">University of Padua</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" coord="1,89.29,84.74,416.53,15.42;1,88.78,106.66,213.52,15.42;1,89.29,132.57,220.08,5.42">SEUPD@CLEF: Team NEON. A Memoryless Approach To Longitudinal Evaluation Notebook for the LongEval Lab at CLEF 2023</title>
					</analytic>
					<monogr>
						<idno type="ISSN">1613-0073</idno>
					</monogr>
					<idno type="MD5">4D147E13146796D077D059C72A9757BB</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.0" ident="GROBID" when="2024-06-26T16:35+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Information Retrieval</term>
					<term>Search Engine</term>
					<term>LongEval CLEF 2023</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper presents a possible approach for the LongEval Lab of the CLEF 2023 conference concerning Longitudinal Evaluation of Model Performance. Studies have shown that the performance of Information Retrieval systems decreases as the time gap between the test data and the training data increases. The LongEval Lab focuses on the development of a robust temporal IR system that improves such performance.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<facsimile>
		<surface n="1" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="2" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="3" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="4" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="5" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="6" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="7" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="8" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="9" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="10" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="11" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="12" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="13" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="14" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="15" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="16" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="17" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="18" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="19" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="20" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="21" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="22" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="23" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="24" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
		<surface n="25" ulx="0.0" uly="0.0" lrx="595.276" lry="841.89"/>
	</facsimile>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Information retrieval is nowadays an indispensable tool for almost everyone, helping people to obtain all kind of information in a quick and effective way.</p><p>This report describes an Information Retrieval System developed for the Search Engines course at the University of Padua, and it is related to Task 1 of the Longitudinal Evaluation of Model Performance (LongEval) lab for CLEF 2023 <ref type="bibr" coords="1,309.78,426.41,12.73,4.94" target="#b0">[1]</ref> conference. As stated on <ref type="bibr" coords="1,436.03,426.41,11.33,4.94" target="#b0">[1]</ref>, the primary goal for developing this system is to improve the model's performance as the test data are collected further away in time from the train data. The train collection is a large data set based on the Qwant <ref type="bibr" coords="1,153.34,467.06,12.84,4.94" target="#b1">[2]</ref> click model and random documents from the Qwant index.</p><p>The task is divided into two sub-tasks regarding short-term and long-term persistence to better test the robustness of our system.</p><p>The paper is organized as follows:</p><p>• Section 3 describes our approach;</p><p>• Section 4 explains our experimental setup;</p><p>• Section 5 discusses our main findings;</p><p>• Section 6 draws some conclusions and outlooks for future work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">System Architecture</head><p>The IR system is based on the latest current version of Apache Lucene (9.5.0). This library represents the state-of-the-art and it is also used by major IR systems, such as those based on Elasticsearch. For this reason, the architecture is based on the four core elements of this library and the main structure is presented in fig. <ref type="figure" coords="3,278.02,151.45,3.74,4.94" target="#fig_0">1</ref>.</p><p>To test different configurations for the produced model, the system is developed to take in input different parameters and behave differently for each of them, so that it is easier to produce different runs to compare.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Document in TREC Form</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Read Content</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analyze Document NEONAnalyzer</head><p>IndexDocument Index Directory</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Query in TREC Form</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Read Content</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>NEONAnalyzer</head><p>Analyze Query </p><note type="other">Run Query</note></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Parser</head><p>NEONParser is the parser developed to manage the parsing of the documents in the LongEval collection. Based on the code analyzed in the Search Engine course, it extends the abstract class DocumentParser, an Iterable class used to run through the whole corpus, and reads one document at a time, provided in the TREC format. While reading, it removes the HTML tags and collects the information needed to create the corresponding ParsedDocument object, which is made of two fields:</p><p>ID: contains the ID of the document.</p><p>BODY: contains the textual content of the document.</p><p>These objects are then used by the system to create the index.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Analyzer</head><p>The developed Analyzer is called NEONAnalyzer, which extends the abstract Analyzer provided by the Apache Lucene library. The Tokenizer source is obtained using StandardTokenizer from Apache Lucene, and then the returned TokenStream is modified by applying both standard and custom filters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">French and English processing: additional filters</head><p>These are additional filters that are used together with the ones of Section 3.3 to form a particular implementation of the system. Since the English dataset is an automatic translation of the French documents, some terms were not fully translated and maintained their original French form (e.g. chalor, challoire). Accordingly, to improve the indexing of these words, a French Filter is incorporated in certain runs.</p><p>• French Minimal Stem Filter: standard filter provided by the Apache Lucene library. It's designed to perform minimal stemming on French text. • Lovins Stem Filter: Custom filter that implements the Lovins stemmer.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">Query expansion: WordNet and WuPalmer similarity</head><p>There is a portion of code in NEONAnalyzer that is specialized in dealing with query strings. After applying the filters discussed in Section 3.3, to perform query expansion the analyzer applies a POS tagger and then a custom filter that deals with the synonyms.</p><p>• OpenNLP POS Filter: standard filter provided by the Apache Lucene library. It works by tagging all terms as a normal POS filter, using Machine Learning for the processing of Natural Language. • OpenNLP POS Tagging To WordNet POS Tagging Converter: custom filter that relies on the POS list used in the Penn Treebank Project <ref type="bibr" coords="6,367.88,373.45,17.91,4.94" target="#b18">[19]</ref> to detect different types of entities. • Synonym Filter and Synonym Add Token Filter: custom filters that rely on the WordNet database <ref type="bibr" coords="6,200.79,415.45,17.95,4.94" target="#b15">[16]</ref> and the Wu &amp; Palmer similarity function <ref type="bibr" coords="6,407.29,415.45,17.95,4.94" target="#b19">[20]</ref> to find synonyms up to a given maximum number. In particular, the constant value of 2 was chosen to prevent excessive noise from being added to the queries, which could cause the system to retrieve irrelevant documents. These two filters differ in the way they emit the synonyms as tokens:</p><p>-SynonymFilter emits for every token it parses a single token, composed by the original word followed by its synonyms (if any) separated by a slash. -SynonymAddTokenFilter emits the token in input and one separated token for its synonyms (if any), tagged with the string "synonym" to recognize them during the search phase.</p><p>In the end, it was decided to use SynonymAddTokenFilter since it allowed an easier integration of the synonyms management into the system.</p><p>Created at Princeton University, WordNet is a lexical database for the English language. It is a semantic network consisting of a large collection of words (called "synsets") that are organized based on their meanings and relationships with other words. Each synset contains a group of words that are synonyms of each other and share a common meaning, as well as a definition and examples of how the words can be used in context. WordNet then works by organizing words into hierarchies of semantic relationships, such as hypernyms (words that are more general than a given word) and hyponyms (words that are more specific than a given word). In particular, WordNet consists of four sub-nets, one each for nouns, verbs, adjectives, and adverbs, connecting words from the same Part Of Speech (POS).</p><p>In order to use WordNet within the filters, the 3.1 Prolog version of the database has been downloaded and fed to a SynonymMap object, a fast hash map used to retrieve synonyms from any specified lowercase word which is provided by the wordnet package of Lucene.</p><p>To obtain a more precise use of synonyms, it has been decided to retain only the top two words with a score greater than a given threshold value of 0.9 (if specified as input), along with the original token, for the Wu &amp; Palmer similarity function that was implemented.</p><p>WuPalmer similarity is a method for measuring the similarity between two words based on their synsets in a semantic network (such as WordNet). The idea behind it is that two words with similar meanings should have synsets that are close to each other in the network. Thus, the method is based on the notion of depth in a semantic network, which is the number of edges that must be traversed to get from one synset to another. The WuPalmer similarity between two synsets is then defined as the depth of their lowest common subsumer (LCS) divided by the sum of their depths in the network. This means that the LCS is the most specific synset that is an ancestor of both senses in the network. The result is a number between 0 and 1, where 1 indicates perfect similarity and 0 indicates no similarity.</p><p>To implement the WuPalmer Similarity, the MIT Java Wordnet Interface (JWI) <ref type="bibr" coords="7,466.67,334.11,18.06,4.94" target="#b20">[21]</ref> was adopted. JWI is a library used to access and manipulate the WordNet database: it provides a set of classes and methods for accessing WordNet data, including synsets, words, and relationships between them. It also allows to perform various operations on the data, such as searching for words or synsets and retrieving hypernyms and hyponyms. Since the JWI implementation does not accept a Prolog database like the one discussed above, it was downloaded the specific database file, as requested in the JWI documentation.</p><p>Furthermore, because WordNet is divided into four subnets -one for each of the previously specified POS tags -it was necessary to:</p><p>1. Use OpenNLPPOSFilter to attach the POS tag to each token; 2. Use OpenNLPPOSTaggingToWordNetPOSTaggingConverter filter to convert the tags into the ones accepted by the JWI; 3. Feed the tokens to SynonymFilter/SynonymAddTokenFilter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Indexer</head><p>The developed Indexer (DirectoryIndexer) deals with the indexing of the parsed documents by storing their most interesting features, which will be then used during the search process. In particular, for each document, the two extracted fields are the ones created by NEONParser (Section 3.2):</p><p>• The ID field; • The BODY field.</p><p>After the tokenization, for each BODY field the following features are saved inside the index:</p><p>• For each term in the field, its document frequency and its position;</p><p>• The term vector (a distinct data structure from the inverted index that can be accessed during search) contains: -Terms frequency; -Terms position; -Terms payload (if any), which represents any additional data associated with each term, that is the word2vec FastText array.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">FastText: Indexer and Query Expansion</head><p>FastText is an open-source library designed by Facebook's AI Research (FAIR) used for word embeddings and text classifications <ref type="bibr" coords="8,254.53,228.44,16.41,4.94" target="#b14">[15]</ref>, needed in order to improve the search for similar words, along with a FuzzyQuery<ref type="foot" coords="8,238.99,239.36,3.71,3.61" target="#foot_0">1</ref> .</p><p>For every token in the indexer, a related vector is added to the payload. This vector is automatically generated by FastText. Then for every token in the query, a FuzzyQuery is generated so that the search involves the token itself and similar words at character level (e.g. tax, taxation, taxi). Then the cosine similarity is used to match query vector and indexer vector to find a correlation and update the query score.</p><p>The goal of FastText is not to generate synonyms on-the-fly but to search for words correlated at character level.</p><p>• It works both at word level and sentence level allowing sentences with the same words but in different order to generate similar vectors (unlike word2vec models). • It uses a hierarchical softMax classifier with a binary tree; • Like word2vec models, it uses negative sampling to update the parameter. Specifically, it has been implemented with the JFastText library <ref type="bibr" coords="8,394.63,431.20,16.18,4.94" target="#b21">[22]</ref>, using the actual last available version (0.9.2) with pre-trained word vectors <ref type="bibr" coords="8,335.39,444.75,16.50,4.94" target="#b22">[23,</ref><ref type="bibr" coords="8,354.63,444.75,14.07,4.94" target="#b23">24]</ref> and using a vector of 50 floats for each word.</p><p>This vector is obtained by a resize of the original vector of 300 elements using the tools provided by FastText.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Searcher</head><p>The implemented custom searcher is specialized according to the various ways it is trained: in particular, it branches differently according to the presence or absence of FastText (Section 3.5).</p><p>Initially, the method creates a BooleanQuery object for each topic, using the QueryParser to parse the query.</p><p>If FastText is present, a FuzzyQuery 1 is created for each word and merged in a single query to be searched together with the payload. Due to efficiency reasons, this does not search for very different words with a similar vector, instead, it should find relatively similar words.</p><p>If FastText is absent, a query structure is generated based on the combinations of possible words returned by the analyzer. Through a specific procedure that generates all the possible combinations, several queries are then created and merged: one containing all the words and the other containing some of them. The algorithm that computes the combinations of the words is based on the idea that any combination can be represented by a number (in binary form) which indicates whether the element will be present or not.</p><p>Example: Let array = {𝐴, 𝐵, 𝐶}. The combination 𝑐(array, 5) is: 5 = 101 → {𝐴, 𝐶}. So, iterating over the combinations, which are enumerated over the numbers in range ⟨0, . . . , 2 𝑛-1 ⟩ where 𝑛 is the size of 𝑎𝑟𝑟𝑎𝑦, the system gets the element corresponding to the number through bit-to-bit operators, which index is represented by the binary representation of the combination.</p><p>If WordNet is enabled, synonyms are added to the queries, with a SynonymQuery object. Also, if re-ranking is enabled, the method computes a re-ranking score for each document using the Jaccard Similarity measure (Section 3.6.1) and then sorts the documents based on this score. Finally, the method writes the top retrieved documents to a run file.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.1.">Re-ranking and Jaccard similarity</head><p>The re-ranking method developed is based on the weighted Jaccard similarity measure, which yields a value in [0, 1]. The purpose of this implementation was to take into account the term frequency when ranking the documents.</p><p>While the Jaccard similarity is a measure of similarity between two sets of items (like the sets of terms corresponding to a query and a document):</p><formula xml:id="formula_0" coords="9,253.61,389.74,86.87,24.43">J(𝐴, 𝐵) = |𝐴 ∩ 𝐵| |𝐴 ∪ 𝐵|</formula><p>the weighted one computes the similarity between a query and a document taking into account the weights of the terms in the documents and in the query, computed using the TF-IDF scheme (with relative frequency):</p><formula xml:id="formula_1" coords="9,209.59,470.45,297.05,58.86">Jw(𝑄, 𝐷) = ∑︁ 𝑡∈𝑄∩𝐷 min (︁ 𝑤 (𝑄) 𝑡 , 𝑤 (𝐷) 𝑡 )︁ ∑︁ 𝑡∈𝑄∩𝐷 max (︁ 𝑤 (𝑄) 𝑡 , 𝑤 (𝐷) 𝑡 )︁<label>(1)</label></formula><p>where:</p><formula xml:id="formula_2" coords="9,107.28,557.29,190.62,56.81">• 𝑄 is the set of query terms • 𝐷 is the set of document terms • 𝑤 (𝑄) 𝑡 is the weight of term 𝑡 in the query • 𝑤 (𝐷) 𝑡</formula><p>is the weight of term 𝑡 in the document The idea behind Equation ( <ref type="formula" coords="9,221.34,625.43,3.86,4.94" target="#formula_1">1</ref>) is the following:</p><p>• The numerator computes the sum of the minimum weights of each term that appears both in the query and the document. This measures the extent to which the query and the document share the smallest weight for each term.</p><p>• The denominator computes the sum of the maximum weights of each term that appears both in the query and the document. This measures the overall importance of the terms that appear both in the query and the document.</p><p>To implement this method, the Term Vector was stored for each document. Consequently, the terms within a document could be accessed and their TF-IDF weights could be computed by providing a document ID.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experimental Setup</head><p>Collection The used experimental collection is provided by the commercial search engine Qwant and is designed to reflect the changes of the Web across time, by providing evolving document and query sets.</p><p>In particular, the system was developed over the experimental collection given as training data for Task 1 of the LongEval CLEF 2023 Lab <ref type="bibr" coords="10,322.35,284.25,11.28,4.94" target="#b0">[1]</ref>. The training data is divided into three fundamental categories:</p><p>• Queries: provided by the users of Qwant, 672 train queries and 98 heldout queries to be used as test set. Both sets are provided in trec and tsv format. • Corpora: it consists of 1,570,734 documents representing web pages collected in June 2022 using the Qwant click model and the given queries. These documents are provided both in JSON and trec format. • Relevance Judgments: 9656 corresponding assessments stored in a qrels file.</p><p>It's important to point out that all the documents and the queries contained in this collection were originally collected in French and subsequently translated into English using the CUBBITT system. Even if the collection contains both versions, it was decided to work with the English one because of the lack of knowledge of the French language of the team. Given the nature of the translation, when the choice was made it was also taken into account a loss in precision of the system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evaluation measures</head><p>The evaluation tools used during the development of the system are:</p><p>• TRECeval: to compute the performance measures.</p><p>• Luke: to inspect the indexes created by Lucene.</p><p>The main evaluation measures used to check the system during the various phases of development are:</p><p>• MAP (Mean Average Precision): it allowed to understand the behavior and effectiveness of the system. • Interpolated precision-recall curve: it enabled the comparison of runs produced from different versions of a system. • nDCG (Normalized Discounted Cumulative Gain): it enabled the measurement of the system's effectiveness while considering the ideal run.</p><p>Repository: https://bitbucket.org/upd-dei-stud-prj/seupd2223-neon/src/master/ Hardware used Computers, mainly Windows-based, with 6th to 12th generation processors, 16+ GB RAM and at least 1 TB SSD. No hardware acceleration or computing clusters were used. The run were all performed in human time (less than 24 hours).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results and Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Training results</head><p>In order to test the system and assess the impact of its components over the MAP measure, many runs were produced over the given training collection, with every one of them representing the results obtained by a specific implementation of the system. It's worth noting that the BM25 was used for every run as similarity.</p><p>In particular, the following implementations of the system were tried:</p><p>• WordNet: run provided by the system implementing the query expansion described in Section 3.3.2; • Basic: run provided by the base system, without any further implementation described in Section 3.3; • FastText + WordNet: run provided by the system implementing FastText and the query expansion described in Sections 3.3.2 and 3.5; • FastText: run provided by the system implementing FastText described in Section 3.5;</p><p>• WordNet + Stems: run provided by the system implementing the query expansion, using the French and English processing described in Sections 3.3.1 and 3.3.2; • Stems: run provided by the system using the French and English processing described in Section 3.3.1; • FastText + WordNet + stems: run provided by the system using the French and English processing described in Sections 3.3.1, 3.3.2 and 3.5, implementing FastText and the query expansion; • FastText + stems: run provided by the system implementing FastText, using the French and English processing described in Sections 3.3.1 and 3.5.</p><p>For each system, we performed both a run with re-ranking and one without. Re-ranking is described in Section 3.6.1</p><p>Considering Table <ref type="table" coords="11,184.20,532.41,3.74,4.94" target="#tab_0">1</ref>, some considerations are:</p><p>• The re-ranking implemented seems to be detrimental to the performances of the system since all the runs score better results without it. Probably, this happens because the method fails to assess and compare the true nature of the documents; • The basic system scores the best result; • The systems (with and without re-ranking) implementing both FastText and the query expansion score the worst results.</p><p>A comparison between all the different runs is made with the use of the Interpolated Precision-Recall Curves, whose aim is to show how the runs perform in terms of Precision and Recall. It is immediate to notice from both Figures <ref type="figure" coords="11,275.96,672.84,5.16,4.94">2</ref> and<ref type="figure" coords="11,303.26,672.84,5.16,4.94" target="#fig_1">3</ref>  recall, indicating an inverse relationship between the two measures: this means that the higher the recall, the lower the precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>that precision decreases with an increasing</head><p>Considering the different runs in the two graphs, it is worth mentioning that the basic model is always among the top-performing ones. This suggests that the more processing is applied to the input documents, the more the performance of the system decreases. This is contrary to the expected outcome for a system that utilizes filters, identifies synonyms, and utilizes FastText, either in combination or individually, as depicted in the two graphs for both runs with and without re-ranking.</p><p>Given the above discussion, it was decided to consider the following runs for the LongEval competition:</p><p>• WordNet without re-ranking (call 1a in  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Test results</head><p>The runs selected in Section 5.1 have been tested over the following collections and set of queries provided by the LongEval Lab <ref type="bibr" coords="15,260.68,124.35,11.56,4.94" target="#b0">[1]</ref>: Using the provided relevance judgments, the MAP and nDCG scores are calculated for each run in relation to the three separate test sets. Moreover, for each test set, two groups of boxplots are computed for each set, respectively, by aggregating the Average Precision (AP) values and the nDCG scores of each query within the run. In each group, the runs are shown in descending order of MAP (boxplots group a) and nDCG (boxplots group b). Then, a comparison between the nDCG values of the different runs of the three test sets is performed using the following statistical techniques: Two-way ANOVA Test: check if the factors Topic and run are statistically significant, and so, if they are significantly influencing the results. The discussion about the results is done considering a 5% level of significance, and it is performed on both MAP and nDCG measures;</p><formula xml:id="formula_3" coords="15,107.28,146.86,100.07,4.94">• Collection composed</formula><p>Tukey HSD test for multiple comparison adjustment: it is used to compare different runs performances, for each pair of runs, and it is particularly useful to check which specific groups means differ (or are similar) to each other. It is performed only with respect to the nDCG measure.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1.">Heldout: June 2022</head><p>Table <ref type="table" coords="16,114.85,473.64,4.97,4.94" target="#tab_3">2</ref> displays the results obtained by the runs produced by the systems tested with the queries of the Heldout set.</p><p>In Figure <ref type="figure" coords="16,142.07,500.74,4.97,4.94" target="#fig_2">4</ref> is reported the MAP value and the nDCG value of each run in a boxplot. Based on the observation, it can be concluded that there is no substantial distinction between the runs. Some general considerations true for both Figure <ref type="figure" coords="16,321.17,527.84,10.06,4.94" target="#fig_2">4a</ref> and Figure <ref type="figure" coords="16,384.17,527.84,10.45,4.94" target="#fig_2">4b</ref> are:</p><p>• The medians are almost the same for the 5 distributions. In particular, it's evident how similar the median of runs 1a (WordNet without re-ranking) and 1b (Basic without reranking) are; • The distributions are very similar to each other, although run 3b (Stems without reranking) and run 4b (FastText + stems without re-ranking) have more extreme outliers.</p><p>The Two-way ANOVA test performed for MAP (Table <ref type="table" coords="16,343.65,628.42,4.16,4.94" target="#tab_4">3</ref>) and nDCG (Table <ref type="table" coords="16,434.73,628.42,4.16,4.94" target="#tab_5">4</ref>) suggests that:</p><p>• Topics are significant for both MAP and nDCG results;</p><p>• Runs are significant only for the nDCG results. Furthermore, the Tukey HSD test in Figure <ref type="figure" coords="17,295.89,438.36,5.12,4.94">5</ref> is showing that runs are showing similarities between each others. In particular, the graph is highlighting two similar groups of intervals in the pairwise:</p><p>• Run 1a is similar to run 1b (WordNet without re-ranking), run 2b (Basic without reranking), run 3b (Stems without re-ranking), run 4b (FastText + stems without re-ranking). These pairwise comparisons are the most significant; • Run 1b and run 2br (FastText with re-ranking) are similar to each other, and they are showing the same behavior when compared with run 3b, run 4b. These pairwise comparisons are less significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2.">Short-term: July 2022</head><p>Table <ref type="table" coords="17,114.85,615.37,4.97,4.94" target="#tab_6">5</ref> displays the results obtained by the runs produced by the systems tested with the queries of the short-term set.</p><p>In Figure <ref type="figure" coords="17,143.56,642.47,5.13,4.94">6</ref> is reported the MAP value and the nDCG value of each run in a boxplot. Based on the observation, it shows again that the distributions are almost the same.</p><p>In particular, it's possible to make a comparison with what has been shown in Figure <ref type="figure" coords="17,481.07,669.57,3.82,4.94" target="#fig_2">4</ref>:</p><p>- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>95% family-wise confidence level</head><p>Differences in mean levels of run • The runs show overall more outliers characterized by even more extreme values, which makes sense looking at the higher values in Table <ref type="table" coords="18,337.88,620.64,3.69,4.94" target="#tab_6">5</ref>. It's worth noting a concentration of AP outliers in the range between 0.5 and 0.75 for all the different runs.</p><p>The Two-way ANOVA test performed for MAP (Table <ref type="table" coords="18,343.65,653.81,4.16,4.94" target="#tab_8">6</ref>) and nDCG (Table <ref type="table" coords="18,434.73,653.81,4.16,4.94" target="#tab_9">7</ref>) suggests that:</p><p>• Topics are significant for both MAP and nDCG results; • Runs are significant only for both MAP and nDCG results.</p><p>Furthermore, the Tukey HSD test in Figure <ref type="figure" coords="19,295.89,458.10,5.12,4.94">7</ref> is showing that runs are showing similarities between each others. As happened in Section 5.2.1, the graph is highlighting again two similar groups of intervals in the pairwise:</p><p>• Run 1a (WordNet without re-ranking) is similar to run 1b (Basic without re-ranking), run 2br (FastText with re-ranking), run 3b (Stems without re-ranking), run 4b (FastText + stems without re-ranking). These pairwise comparisons are the most significant; • Run 1b and run 2br are similar to each other, and they are showing the same behavior when compared with run 3b, run 4b. These pairwise comparisons are less significant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.3.">Long-term: September 2022</head><p>Table <ref type="table" coords="19,114.85,618.65,4.97,4.94">8</ref> displays the results obtained by the runs produced by the systems tested with the queries of the long-term set.</p><p>As can be seen in Figure <ref type="figure" coords="19,210.45,645.75,3.70,4.94">8</ref>, the runs are similar to each other. However, the distributions are slightly different for the 5 runs.</p><p>In particular, some general considerations are:</p><p>-2e- </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>95% family-wise confidence level</head><p>Differences in mean levels of run </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>95% family-wise confidence level</head><p>Differences in mean levels of run </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Failure Analysis</head><p>The main problem in this system is that it finds few relevant results, for example in model 1a it does not find tax, even though the search key is taxation. In models 1b (Basic without re-ranking), 2br (FastText with re-ranking), 3a (Stems without re-ranking), 4a (FastText + stems without re-ranking) this specific case is solved, despite this, numerous similar cases remain.</p><p>Limiting the number of relevant documents to 50 (otherwise re-ranking becomes impossible) makes it necessary to compute a score that reflects the real importance of a word or synonym. However, this comes out to be a problem. Furthermore, it has been seen that comparing the runs on most queries the results are almost the same. For example the runs on query q062222425 return almost the same order of documents with similar scores, whereas for query q062214361 they return most of the same documents, often in a slightly different order, and lastly regarding query q062211403 the top-ranked results are the same among the runs, only those from the 30th onwards change. We can generally classify queries in these 3 cases.</p><p>In addition, models 1b, 2a, 3a, 4a compared to model 1a only improve the results for certain cases, however, the improvement is not generalized since they do not change the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Discussion</head><p>Overall the system presented in this document implements some interesting techniques, for example, a lot of filters were implemented in order to make it possible to compare them and select the ones achieving better results for the runs. According to the results, the system that achieves better performance is the one that uses only essential filters. Nevertheless, some queries that do not achieve any result with the essential system, gain some improvements using specific filters. Despite that, the overall system performs better without these specific filters.</p><p>As already noticed, most of the runs returns the same documents with similar scores. Furthermore, as can be seen in Tables 2, 5 and 8, the MAP and nDCG values in each table are almost the same. It is important to highlight that the values for both these measures increase over time, with the highest scores being observed for the September's collection. This last consideration leads to the conclusion that the developed system well performs with data further away in time from the training data, that was the final goal the system was intended to achieve.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions and Future Work</head><p>This system presents many flaws, but taking it as a starting point, there are several ways to improve it:</p><p>• Develop a re-ranking method that better suits the system • Integrate in a more comprehensive way the synonyms generated through the query expansion • Implement a more refined tokenization system (for example, one that deals with hyphens) • Transform it into a 3-way re-ranking system: i.e. a first query that searches many more documents, a second query for selection and re-ranking, and then finally a re-ranking similar to the one we implemented Other interesting features that could be developed are specific filters for relevant cases that do not worsen the overall performance, based on the ones already developed. Secondly, since WordNet has not been updated in the last 10 years, FastText could be an alternative to it in order to generate synonyms on the fly. Developing these mentioned features would surely increase the performance of this system. Furthermore, working with the French collection should give the system a boost to its precision, overcoming the translation issues, and it is also important to highlight that this dataset and the LongEval task would require the use of a machine learning statistic model able to find more suitable correspondences.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0" coords="4,89.29,625.61,214.17,8.93"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: Representation of the system architecture</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1" coords="14,89.29,590.06,290.85,8.93"><head>Figure 3 :</head><label>3</label><figDesc>Figure 3: Interpolated Precision-Recall curves for runs with re-ranking</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2" coords="16,89.29,412.21,158.90,8.93"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Boxplot for Heldout set runs</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3" coords="18,89.29,317.65,167.59,8.93"><head>Figure 5 :Figure 6 :</head><label>56</label><figDesc>Figure 5: Tukey's results for Heldout set</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4" coords="20,89.29,317.65,179.54,8.93"><head>Figure 7 :Figure 8 :</head><label>78</label><figDesc>Figure 7: Tukey's results for Short-term set</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5" coords="22,89.29,317.65,177.58,8.93"><head>Figure 9 :</head><label>9</label><figDesc>Figure 9: Tukey's results for Long-term set</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" coords="12,88.99,90.49,384.51,160.15"><head>Table 1</head><label>1</label><figDesc>Summary statistics for the runs</figDesc><table coords="12,121.78,123.44,351.72,127.20"><row><cell></cell><cell cols="3">without re-ranking</cell><cell></cell><cell cols="2">with re-ranking</cell></row><row><cell></cell><cell cols="6">run id MAP time (s) run id MAP time (s)</cell></row><row><cell>WordNet</cell><cell>1a</cell><cell>0.1405</cell><cell>30</cell><cell>1ar</cell><cell>0.1291</cell><cell>69</cell></row><row><cell>basic</cell><cell>1b</cell><cell>0.1459</cell><cell>12</cell><cell>1br</cell><cell>0.1345</cell><cell>58</cell></row><row><cell>FastText + WordNet</cell><cell>2a</cell><cell>0.1253</cell><cell>496</cell><cell>2ar</cell><cell>0.1136</cell><cell>700</cell></row><row><cell>FastText</cell><cell>2b</cell><cell>0.1387</cell><cell>383</cell><cell>2br</cell><cell>0.1344</cell><cell>584</cell></row><row><cell>WordNet + stems</cell><cell>3a</cell><cell>0.1402</cell><cell>27</cell><cell>3ar</cell><cell>0.1302</cell><cell>69</cell></row><row><cell>stems</cell><cell>3b</cell><cell>0.1435</cell><cell>11</cell><cell>3br</cell><cell>0.1336</cell><cell>55</cell></row><row><cell>FastText + WordNet + stems</cell><cell>4a</cell><cell>0.1174</cell><cell>566</cell><cell>4ar</cell><cell>0.1066</cell><cell>566</cell></row><row><cell>FastText + stems</cell><cell>4b</cell><cell>0.1307</cell><cell>487</cell><cell>4br</cell><cell>0.1192</cell><cell>560</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" coords="12,107.28,425.06,255.33,64.56"><head>table 1</head><label>1</label><figDesc></figDesc><table coords="12,320.74,425.06,7.27,4.94"><row><cell>);</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" coords="16,88.99,90.49,399.06,305.59"><head>Table 2</head><label>2</label><figDesc>MAP and nDCG values for the runs tested over the collection of June 2022</figDesc><table coords="16,197.24,122.81,200.79,74.12"><row><cell></cell><cell cols="2">run id MAP nDCG</cell></row><row><cell>basic</cell><cell>1b</cell><cell>0.1338 0.2269</cell></row><row><cell>WordNet</cell><cell>1a</cell><cell>0.1287 0.2201</cell></row><row><cell>FastText + re-ranking</cell><cell>2br</cell><cell>0.1279 0.2177</cell></row><row><cell>stems</cell><cell>3b</cell><cell>0.1226 0.2017</cell></row><row><cell>FastText + stems</cell><cell>4b</cell><cell>0.1213 0.2054</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4" coords="17,88.99,90.49,334.21,83.16"><head>Table 3</head><label>3</label><figDesc>Results of Two-way ANOVA test over MAP of runs and queries of the Heldout set</figDesc><table coords="17,173.90,123.39,247.48,50.26"><row><cell></cell><cell cols="5">Df Sum Sq Mean Sq F value Pr(&gt;F)</cell></row><row><cell cols="2">Topics 97</cell><cell>13.492</cell><cell>0.13910</cell><cell>27.368</cell><cell>&lt;2e-16</cell></row><row><cell>runs</cell><cell>4</cell><cell>0.003</cell><cell>0.00087</cell><cell>0.171</cell><cell>0.953</cell></row><row><cell cols="2">Residuals 370</cell><cell>1.881</cell><cell>0.00508</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5" coords="17,88.99,195.90,339.87,83.16"><head>Table 4</head><label>4</label><figDesc>Results of Two-way ANOVA test over nDCG of runs and queries of the Heldout set</figDesc><table coords="17,170.33,228.80,254.63,50.26"><row><cell cols="3">Df Sum Sq Mean Sq</cell><cell>F value</cell><cell>Pr(&gt;F)</cell></row><row><cell>Topics 97</cell><cell>29.13</cell><cell>0.3004</cell><cell cols="2">7.416e+28 &lt;2e-16</cell></row><row><cell>4</cell><cell>0.0</cell><cell>0.0000</cell><cell>2.502e+00</cell><cell>0.042</cell></row><row><cell>Residuals 388</cell><cell>&lt;2e-16</cell><cell>&lt;2e-16</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6" coords="17,88.99,301.32,309.04,107.07"><head>Table 5</head><label>5</label><figDesc>MAP and nDCG values for the runs tested over the collection of July 2022</figDesc><table coords="17,197.24,334.27,200.79,74.12"><row><cell></cell><cell cols="2">run id MAP nDCG</cell></row><row><cell>basic</cell><cell>1b</cell><cell>0.1390 0.2294</cell></row><row><cell>stems</cell><cell>3b</cell><cell>0.1384 0.2260</cell></row><row><cell>WordNet</cell><cell>1a</cell><cell>0.1356 0.2241</cell></row><row><cell>FastText + stems</cell><cell>4b</cell><cell>0.1324 0.2187</cell></row><row><cell>FastText + re-ranking</cell><cell>2br</cell><cell>0.1319 0.2219</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8" coords="19,88.99,90.49,336.21,83.16"><head>Table 6</head><label>6</label><figDesc>Results of Two-way ANOVA test over MAP runs and queries of the Short-term set</figDesc><table coords="19,170.07,123.39,255.13,50.26"><row><cell></cell><cell>Df</cell><cell cols="4">Sum Sq Mean Sq F value Pr(&gt;F)</cell></row><row><cell>Topics</cell><cell>877</cell><cell>176.17</cell><cell>0.20088</cell><cell>72.506</cell><cell>&lt;2e-16</cell></row><row><cell>runs</cell><cell>4</cell><cell>0.04</cell><cell>0.00969</cell><cell>3.497</cell><cell>0.00741</cell></row><row><cell cols="2">Residuals 3501</cell><cell>9.70</cell><cell>0.00277</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9" coords="19,88.99,195.48,351.83,212.06"><head>Table 7</head><label>7</label><figDesc>Results of Two-way ANOVA test over nDCG of runs and queries of the Short-term set</figDesc><table coords="19,88.99,228.38,338.27,179.16"><row><cell></cell><cell>Df</cell><cell cols="3">Sum Sq Mean Sq</cell><cell>F value</cell><cell>Pr(&gt;F)</cell></row><row><cell cols="2">Topics 875</cell><cell>281.5</cell><cell>0.3217</cell><cell></cell><cell cols="2">1.262e+27 &lt;2e-16</cell></row><row><cell>runs</cell><cell>4</cell><cell>0.0</cell><cell>0.0000</cell><cell></cell><cell>6.000e-02</cell><cell>0.993</cell></row><row><cell cols="2">Residuals 3500</cell><cell>&lt;2e-16</cell><cell>&lt;2e-16</cell><cell></cell><cell>-</cell><cell>-</cell></row><row><cell>Table 8</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="7">MAP and nDCG values for the runs tested over the collection of September 2022</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">run id MAP nDCG</cell></row><row><cell></cell><cell></cell><cell>basic</cell><cell>1b</cell><cell cols="2">0.1478 0.2430</cell></row><row><cell></cell><cell></cell><cell>WordNet</cell><cell>1a</cell><cell cols="2">0.1446 0.2393</cell></row><row><cell></cell><cell></cell><cell>stems</cell><cell>3b</cell><cell cols="2">0.1442 0.2387</cell></row><row><cell cols="3">FastText + re-ranking</cell><cell>2br</cell><cell cols="2">0.1351 0.2282</cell></row><row><cell></cell><cell cols="2">FastText + stems</cell><cell>4b</cell><cell cols="2">0.1347 0.2276</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_0" coords="8,92.57,640.16,413.41,6.49;8,92.57,651.79,413.41,4.06;8,92.57,662.75,413.42,4.06;8,92.57,673.71,46.80,4.06"><p>FuzzyQuery is a type of query in the Apache Lucene search library that allows you to search for terms that are similar to a specified term based on their Damerau-Levenshtein distance. Damerau-Levenshtein is a measure of the minimum number of single-character edits (insertions, deletions, or substitutions) required to transform one string into another.</p></note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>The Two-way ANOVA tests performed for MAP (Table <ref type="table" coords="21,345.17,309.03,4.11,4.94">9</ref>) and nDCG (Table <ref type="table" coords="21,435.28,309.03,8.82,4.94">10</ref>) suggest that:</p><p>• Topics are significant for both MAP and nDCG results;</p><p>• Runs are significant only for the MAP results.</p><p>The Tukey HSD test for the Long-Term set in Figure <ref type="figure" coords="21,332.52,368.97,5.00,4.94">9</ref> is showing again that runs are similar between each others. The graph is leading to the same conclusions obtained in Section 5.2.1 and Section 5.2.2:</p><p>• Run 1a (WordNet without re-ranking) is similar to run 1b, (Basic without re-ranking) run 2br (FastText with re-ranking), run 3b (Stems without re-ranking), run 4b (FastText + stems without re-ranking). These pairwise comparisons are the most significant; • Run 1b and run 2br are similar to each other, and they are showing the same behavior when compared with run 3b, run 4b. These pairwise comparisons are less significant.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct coords="23,112.66,554.66,394.53,4.94;23,112.66,568.21,394.52,4.94;23,112.66,581.76,394.53,4.94;23,112.66,595.31,394.52,4.94;23,112.66,608.86,393.33,4.94;23,112.66,622.40,393.33,4.94;23,112.66,635.95,321.57,4.94" xml:id="b0">
	<analytic>
		<title level="a" type="main" coord="23,112.66,595.31,389.62,4.94">Overview of the clef-2023 longeval lab on longitudinal evaluation of model performance</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Alkhalifa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Bilal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Borkakoty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Camacho-Collados</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Deveaud</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>El-Ebshihy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Espinosa-Anke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gonzalez-Saez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Galuscakova</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kochkina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Liakata</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Loureiro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><forename type="middle">T</forename><surname>Madabushi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mulhem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Piroi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Popel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Servan</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zubiaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="23,127.14,608.86,378.84,4.94;23,112.66,622.40,327.16,4.94">Experimental IR Meets Multilinguality, Multimodality, and Interaction. Proceedings of the Fourteenth International Conference of the CLEF Association (CLEF</title>
		<title level="s" coord="23,471.85,622.40,34.14,4.94;23,112.66,635.95,148.46,4.94">Lecture Notes in Computer Science (LNCS</title>
		<meeting><address><addrLine>Thessaliniki, Greece</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023">2023. 2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="23,112.66,649.50,206.38,4.94" xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">Qwant</forename><surname>Qwant</surname></persName>
		</author>
		<ptr target="https://www.qwant.com" />
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,90.23,394.53,4.94;24,112.66,103.78,393.33,4.94;24,112.66,116.51,174.58,7.90" xml:id="b2">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Galuščáková</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Deveaud</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gonzalez-Saez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Mulhem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Piroi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Popel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2303.03229</idno>
		<title level="m" coord="24,112.66,103.78,393.33,4.94;24,112.66,117.33,44.62,4.94">Longeval-retrieval: French-english dynamic test collection for continuous web search evaluation</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,130.88,393.33,4.94;24,112.66,144.43,387.03,4.94" xml:id="b3">
	<analytic>
		<title level="a" type="main" coord="24,290.13,130.88,215.86,4.94;24,112.66,144.43,125.91,4.94">Building for tomorrow: Assessing the temporal persistence of text classifiers</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Alkhalifa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kochkina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Zubiaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="24,246.31,144.43,175.43,4.94">Information Processing &amp; Management</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page">103200</biblScope>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,157.97,394.53,4.94;24,112.66,171.52,394.52,4.94;24,112.66,185.07,394.53,4.94;24,112.66,198.62,393.33,4.94;24,112.66,212.17,394.53,4.94;24,112.66,225.72,394.52,4.94;24,112.66,239.27,80.57,4.94" xml:id="b4">
	<analytic>
		<title level="a" type="main" coord="24,112.66,198.62,312.53,4.94">Longeval: Longitudinal evaluation of model performance at clef 2023</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Alkhalifa</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Bilal</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Borkakoty</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Camacho-Collados</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Deveaud</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>El-Ebshihy</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Espinosa-Anke</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Gonzalez-Saez</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Galuščáková</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kochkina</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Liakata</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Loureiro</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Tayyar</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Madabushi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">F</forename><surname>Mulhem</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Piroi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Popel</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Servan</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Zubiaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="24,450.02,198.62,55.97,4.94;24,112.66,212.17,389.90,4.94">Advances in Information Retrieval: 45th European Conference on Information Retrieval, ECIR 2023</title>
		<meeting><address><addrLine>Dublin, Ireland; Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2023">April 2-6, 2023. 2023</date>
			<biblScope unit="volume">III</biblScope>
			<biblScope unit="page" from="499" to="505" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,252.82,393.33,4.94;24,112.41,266.37,393.57,4.94;24,112.66,279.92,395.01,4.94;24,112.41,293.47,48.96,4.94" xml:id="b5">
	<analytic>
		<title level="a" type="main" coord="24,195.66,252.82,206.68,4.94">Finally, a downloadable test collection of tweets</title>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Sequiera</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="24,424.97,252.82,81.02,4.94;24,112.41,266.37,393.57,4.94;24,112.66,279.92,83.89,4.94">Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;17</title>
		<meeting>the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR &apos;17<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1225" to="1228" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,307.02,327.47,4.94" xml:id="b6">
	<analytic>
		<title level="a" type="main" coord="24,185.79,307.02,114.79,4.94">The trec 2005 robust track</title>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="24,308.71,307.02,57.63,4.94">SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="41" to="48" />
			<date type="published" when="2006">2006</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,320.56,394.53,4.94;24,112.66,334.11,393.33,4.94;24,112.66,347.66,152.12,4.94" xml:id="b7">
	<analytic>
		<title level="a" type="main" coord="24,220.13,334.11,285.86,4.94;24,112.66,347.66,41.60,4.94">Trec-covid: Constructing a pandemic information retrieval test collection</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Alam</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Bedrick</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Demner-Fushman</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">W</forename><forename type="middle">R</forename><surname>Hersh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Lo</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Soboroff</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><forename type="middle">L</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j" coord="24,162.35,347.66,57.63,4.94">SIGIR Forum</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,361.21,393.98,4.94;24,112.66,374.76,68.32,4.94" xml:id="b8">
	<monogr>
		<author>
			<persName coords=""><forename type="first">E</forename><forename type="middle">M</forename><surname>Voorhees</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><forename type="middle">K</forename><surname>Harman</surname></persName>
		</author>
		<title level="m" coord="24,251.71,361.21,219.99,4.94">Overview of the seventh text retrieval conference</title>
		<imprint>
			<date type="published" when="1999">1999</date>
		</imprint>
	</monogr>
	<note>trec-7) [on-line</note>
</biblStruct>

<biblStruct coords="24,112.66,388.31,271.34,4.94" xml:id="b9">
	<monogr>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Braschler</surname></persName>
		</author>
		<title level="m" coord="24,174.69,388.31,136.04,4.94">Clef 2000 -overview of results</title>
		<imprint>
			<date type="published" when="2001">2001</date>
			<biblScope unit="page" from="9" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,401.86,394.53,4.94;24,112.66,415.41,393.53,4.94;24,112.66,428.96,235.56,4.94" xml:id="b10">
	<analytic>
		<title level="a" type="main" coord="24,179.00,401.86,141.75,4.94">Clef 2001 -overview of results</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Braschler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="24,186.39,415.41,273.34,4.94">Evaluation of Cross-Language Information Retrieval Systems</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Kluck</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg, Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="9" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,442.51,394.53,4.94;24,112.66,456.06,393.33,4.94;24,112.66,469.61,205.73,4.94" xml:id="b11">
	<analytic>
		<title level="a" type="main" coord="24,179.00,442.51,141.75,4.94">Clef 2002 -overview of results</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Braschler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="24,190.88,456.06,235.78,4.94">Advances in Cross-Language Information Retrieval</title>
		<editor>
			<persName><forename type="first">C</forename><surname>Peters</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Gonzalo</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Kluck</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg, Berlin, Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2003">2003</date>
			<biblScope unit="page" from="9" to="27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,483.16,393.33,4.94;24,112.66,496.70,394.53,4.94;24,112.33,510.25,394.86,4.94;24,112.66,523.80,394.53,4.94;24,112.66,537.35,394.53,4.94;24,112.66,550.90,313.06,4.94" xml:id="b12">
	<analytic>
		<title level="a" type="main" coord="24,431.10,483.16,74.89,4.94;24,112.66,496.70,118.87,4.94">Overview of the clef ehealth evaluation lab</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Neveol</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<ptr target="https://eprints.qut.edu.au/98864/" />
	</analytic>
	<monogr>
		<title level="m" coord="24,333.22,510.25,173.97,4.94;24,112.66,523.80,394.53,4.94;24,112.66,537.35,46.48,4.94">Experimental IR Meets Multilinguality, Multimodality, and Interaction: 7th International Conference of the CLEF Association, CLEF 2016</title>
		<title level="s" coord="24,230.47,537.35,159.44,4.94">Lecture Notes in Computer Science</title>
		<editor>
			<persName><forename type="first">N</forename><surname>Fuhr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">K</forename><surname>Balog</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Ferro</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">B</forename><surname>Larsen</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Quaresma</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">T</forename><surname>Goncalves</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Cappellato</surname></persName>
		</editor>
		<meeting><address><addrLine>Switzerland</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="volume">9822</biblScope>
			<biblScope unit="page" from="255" to="266" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,564.45,394.53,4.94;24,112.66,578.00,394.62,4.94;24,112.66,591.55,394.53,4.94;24,112.66,605.10,393.33,4.94;24,112.66,618.65,320.67,4.94" xml:id="b13">
	<analytic>
		<title level="a" type="main" coord="24,261.29,578.00,200.24,4.94">Overview of the clef ehealth evaluation lab</title>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Kelly</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Suominen</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Goeuriot</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Neves</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Kanoulas</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">D</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Azzopardi</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">R</forename><surname>Spijker</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">G</forename><surname>Zuccon</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">H</forename><surname>Scells</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="24,245.56,605.10,260.42,4.94;24,112.66,618.65,47.12,4.94">Experimental IR Meets Multilinguality, Multimodality, and Interaction</title>
		<editor>
			<persName><forename type="first">F</forename><surname>Crestani</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">M</forename><surname>Braschler</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">J</forename><surname>Savoy</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">A</forename><surname>Rauber</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">H</forename><surname>Müller</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Losada</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">G</forename><surname>Heinatz</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">L</forename><surname>Bürki</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">N</forename><surname>Cappellato</surname></persName>
		</editor>
		<editor>
			<persName><surname>Ferro</surname></persName>
		</editor>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2019">2019. 2019</date>
			<biblScope unit="page" from="322" to="339" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,632.20,393.33,4.94;24,112.66,645.75,233.34,4.94" xml:id="b14">
	<monogr>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1607.04606</idno>
		<title level="m" coord="24,331.70,632.20,174.29,4.94;24,112.66,645.75,50.99,4.94">Enriching word vectors with subword information</title>
		<imprint>
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct coords="24,112.66,659.29,372.66,4.94" xml:id="b15">
	<monogr>
		<title level="m" type="main" coord="24,209.73,659.29,79.37,4.94">WordNet database</title>
		<ptr target="https://wordnet.princeton.edu/" />
		<imprint>
			<date type="published" when="2000">2000-2023</date>
		</imprint>
		<respStmt>
			<orgName>Princeton University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct coords="24,112.66,672.84,299.26,4.94" xml:id="b16">
	<monogr>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Palotti</surname></persName>
		</author>
		<ptr target="https://github.com/joaopalotti/trectools" />
		<title level="m" coord="24,155.54,672.84,45.09,4.94">TRECtools</title>
		<imprint>
			<date type="published" when="2023">2023</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,112.66,90.23,294.85,4.94" xml:id="b17">
	<monogr>
		<author>
			<persName coords=""><forename type="first">I</forename><surname>Brigadir</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">J</forename><surname>Nothman</surname></persName>
		</author>
		<title level="m" coord="25,217.64,90.23,160.33,4.94">igorbrigadir/stopwords: First release</title>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,112.66,103.78,394.54,4.94;25,112.66,117.33,393.86,4.94;25,112.66,130.88,90.50,4.94" xml:id="b18">
	<monogr>
		<title/>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">P</forename><surname>Marcus</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">B</forename><surname>Santorini</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><forename type="middle">A</forename><surname>Marcinkiewicz</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">Penn</forename><surname>Treebank</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><forename type="middle">O S</forename></persName>
		</author>
		<ptr target="https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html" />
		<imprint>
			<date type="published" when="1989">1989-1992</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,112.66,144.43,393.32,4.94;25,112.66,157.97,235.24,4.94" xml:id="b19">
	<monogr>
		<title level="m" type="main" coord="25,195.91,144.43,310.07,4.94;25,112.66,157.97,45.78,4.94">Java Libraries for Accessing the Princeton Wordnet: Comparison and Evaluation</title>
		<author>
			<persName coords=""><forename type="first">Z</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Palmer</surname></persName>
		</author>
		<ptr target="https://aclanthology.org/P94-1019/" />
		<imprint>
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,112.66,171.52,393.33,4.94;25,112.66,185.07,223.72,4.94" xml:id="b20">
	<monogr>
		<title level="m" type="main" coord="25,200.89,171.52,305.10,4.94;25,112.66,185.07,45.78,4.94">Java Libraries for Accessing the Princeton Wordnet: Comparison and Evaluation</title>
		<author>
			<persName coords=""><forename type="first">M</forename><surname>Finlayson</surname></persName>
		</author>
		<author>
			<persName coords=""><surname>Alan</surname></persName>
		</author>
		<ptr target="http://projects.csail.mit.edu/jwi/" />
		<imprint>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,112.66,198.62,394.04,4.94;25,112.66,212.17,124.44,4.94" xml:id="b21">
	<monogr>
		<author>
			<persName coords=""><forename type="first">K</forename><surname>Vinh</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">S</forename><surname>Carsten</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">L</forename><surname>Théo</surname></persName>
		</author>
		<ptr target="https://github.com/stroppycow/JFastText" />
		<title level="m" coord="25,249.95,198.62,161.26,4.94">Jfasttext: Java interface for fasttext</title>
		<imprint>
			<date type="published" when="2022">2022</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,112.66,225.72,393.33,4.94;25,112.66,239.27,393.33,4.94;25,112.66,252.82,245.73,4.94" xml:id="b22">
	<analytic>
		<title level="a" type="main" coord="25,390.99,225.72,115.00,4.94;25,112.66,239.27,147.69,4.94">Advances in pre-training distributed word representations</title>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">C</forename><surname>Puhrsch</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="25,287.45,239.27,218.54,4.94;25,112.66,252.82,215.99,4.94">Proceedings of the International Conference on Language Resources and Evaluation (LREC 2018)</title>
		<meeting>the International Conference on Language Resources and Evaluation (LREC 2018)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct coords="25,112.66,266.37,393.57,4.94;25,112.66,279.92,393.33,4.94;25,112.66,293.47,133.31,4.94" xml:id="b23">
	<analytic>
		<title level="a" type="main" coord="25,369.49,266.37,136.74,4.94;25,112.66,279.92,42.76,4.94">Learning word vectors for 157 languages</title>
		<author>
			<persName coords=""><forename type="first">E</forename><surname>Grave</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Bojanowski</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">P</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">A</forename><surname>Joulin</surname></persName>
		</author>
		<author>
			<persName coords=""><forename type="first">T</forename><surname>Mikolov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" coord="25,178.86,279.92,327.13,4.94;25,112.66,293.47,103.57,4.94">Proceedings of the International Conference on Language Resources and Evaluation (LREC 2018)</title>
		<meeting>the International Conference on Language Resources and Evaluation (LREC 2018)</meeting>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
